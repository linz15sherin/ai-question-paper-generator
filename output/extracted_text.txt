
--- Page 1 ---

SEVENTH EDITION
Database System Concepts
Abraham Silberschatz
Henry F. Korth
S. Sudarshan

--- Page 2 ---

silberschatz6e_fm_i-ii.indd Page i 12/3/09 2:51:50 PM user /Users/user/Desktop/Temp Work/00November_2009/24:11:09/VYN/silberschatz
DATABASE
SYSTEM CONCEPTS
S ESVI XE TNHT H E DE IDTIITOI NO N
Abraham Silberschatz
Yale University
Henry F. Korth
Lehigh University
S. Sudarshan
Indian Institute of Technology, Bombay
TM

--- Page 3 ---

DATABASE SYSTEM CONCEPTS, SEVENTH EDITION
Published by McGraw-Hill Education, 2 Penn Plaza, New York, NY 10121. Copyright © 2020 by
McGraw-Hill Education. All rights reserved. Printed in the United States of America. Previous
editions © 2011, 2006, and 2002. No part of this publication may be reproduced or distributed in
any form or by any means, or stored in a database or retrieval system, without the prior written
consent of McGraw-Hill Education, including, but not limited to, in any network or other
electronic storage or transmission, or broadcast for distance learning.
Some ancillaries, including electronic and print components, may not be available to customers
outside the United States.
This book is printed on acid-free paper.
1 2 3 4 5 6 7 8 9 LCR 21 20 19
ISBN 978-0-07-802215-9 (bound edition)
MHID 0-07-802215-0 (bound edition)
ISBN 978-1-260-51504-6 (loose-leaf edition)
MHID 1-260-51504-4 (loose-leaf edition)
Portfolio Manager: Thomas Scaife Ph.D.
Product Developers: Tina Bower & Megan Platt
Marketing Manager: Shannon O’Donnell
Content Project Managers: Laura Bies & Sandra Schnee
Buyer: Susan K. Culbertson
Design: Egzon Shaqiri
Content Licensing Specialists: Shawntel Schmitt & Lorraine Buczek
Cover Image: © Pavel Nesvadba/Shutterstock
Compositor: Aptara®, Inc.
All credits appearing on page or at the end of the book are considered to be an extension
of the copyright page.
Library of Congress Cataloging-in-Publication Data
Names: Silberschatz, Abraham, author. | Korth, Henry F., author. | Sudarshan, S., author.
Title: Database system concepts/Abraham Silberschatz, Yale University, Henry F. Korth,
Lehigh University, S. Sudarshan, Indian Institute of Technology, Bombay.
Description: Seventh edition. | New York, NY: McGraw-Hill, [2020] | Includes bibliographical
references.
Identifiers: LCCN 2018060474 | ISBN 9780078022159 (alk. paper) | ISBN 0078022150 (alk. paper)
Subjects: LCSH: Database management.
Classification: LCC QA76.9.D3 S5637 2020 | DDC 005.74—dc23 LC record available at
https://lccn.loc.gov/2018060474
The Internet addresses listed in the text were accurate at the time of publication. The inclusion of
a website does not indicate an endorsement by the authors or McGraw-Hill Education, and
McGraw-Hill Education does not guarantee the accuracy of the information presented at these sites.
mheducation.com/highered

--- Page 4 ---

Tomeineschatzi,Valerie
herparentsandmydearfriends,SteveandMaryAnne
andinmemoryofmyparents,JosephandVera
AviSilberschatz
Tomywife,Joan
mychildren,AbigailandJoseph
mymother,Frances
andinmemoryofmyfather,Henry
HankKorth
Tomywife,Sita
mychildren,MadhurandAdvaith
andmymother,Indira
S.Sudarshan

--- Page 6 ---

About the Authors
Abraham(Avi)SilberschatzistheSidneyJ.WeinbergProfessorofComputerScience
at Yale University. Prior to coming to Yale in 2003, he was the vice president of the
Information Sciences Research Center at Bell Labs. He previously held an endowed
professorshipattheUniversityofTexasatAustin,wherehetaughtuntil1993.Silber-
schatzisafellowoftheACM,afellowoftheIEEE,andamemberoftheConnecticut
AcademyofScienceandEngineering.Hereceivedthe2002IEEETaylorL.BoothEd-
ucation Award, the 1998 ACM Karl V. Karlstrom Outstanding Educator Award, and
the1997ACMSIGMODContributionAward.SilberschatzwasawardedtheBellLab-
oratories President’s Award three times, in 1998, 1999 and 2004. His writings have
appeared in numerous journals, conferences, workshops, and book chapters. He has
obtainedover48patentsandover24grants.HeisanauthorofthetextbookOperating
SystemConcepts.
Henry F. (Hank) Korth is a Professor of Computer Science and Engineering and co-
directoroftheComputerScienceandBusinessprogramatLehighUniversity.Priorto
joining Lehigh, he was director of Database Principles Research at Bell Labs, a vice
presidentofPanasonicTechnologies,anassociateprofessorattheUniversityofTexas
atAustin,andaresearchstaffmemberatIBMResearch.KorthisafellowoftheACM
andoftheIEEEandawinnerofthe10-YearAwardattheVLDBConference.Hisnumer-
ousresearchpublicationsspanawiderangeofaspectsofdatabasesystems,including
transaction management in parallel and distributed systems, real-time systems, query
processing, and the influence on these areas from modern computing architectures.
Most recently, his research has addressed issues in the application of blockchains in
enterprisedatabases.
S. Sudarshan is currently the Subrao M. Nilekani Chair Professor at the Indian Insti-
tute of Technology, Bombay. He received his Ph.D. at the University of Wisconsin in
1992,andhewasamemberofthetechnicalstaffatBellLabsbeforejoiningIITBom-
bay. Sudarshan is a fellow of the ACM. His research spans several areas of database
systems, with a focus on query processing and query optimization. His paper on key-
wordsearchindatabasespublishedin2002wontheIEEEICDEMostInfluentialPaper
Award in 2012, and his work on main-memory databases received the Bell Laborato-
riesPresident’sAwardin1999.Hiscurrentresearchareasincludetestingandgrading
ofSQLqueries,optimizationofdatabaseapplicationsbyrewritingofimperativecode,
and query optimization for parallel databases. He has published over 100 papers and
obtained15patents.

--- Page 8 ---

Contents
Chapter 1 Introduction
1.1 Database-SystemApplications 1 1.7 DatabaseandApplicationArchitecture 21
1.2 PurposeofDatabaseSystems 5 1.8 DatabaseUsersandAdministrators 24
1.3 ViewofData 8 1.9 HistoryofDatabaseSystems 25
1.4 DatabaseLanguages 13 1.10 Summary 29
1.5 DatabaseDesign 17 Exercises 31
1.6 DatabaseEngine 18 FurtherReading 33
PART ONE RELATIONAL LANGUAGES
Chapter 2 Introductiontothe RelationalModel
2.1 StructureofRelationalDatabases 37 2.6 TheRelationalAlgebra 48
2.2 DatabaseSchema 41 2.7 Summary 58
2.3 Keys 43 Exercises 60
2.4 SchemaDiagrams 46 FurtherReading 63
2.5 RelationalQueryLanguages 47
Chapter 3 IntroductiontoSQL
3.1 OverviewoftheSQLQueryLanguage 65 3.7 AggregateFunctions 91
3.2 SQLDataDefinition 66 3.8 NestedSubqueries 98
3.3 BasicStructureofSQLQueries 71 3.9 ModificationoftheDatabase 108
3.4 AdditionalBasicOperations 79 3.10 Summary 114
3.5 SetOperations 85 Exercises 115
3.6 NullValues 89 FurtherReading 124
vii

--- Page 9 ---

viii Contents
Chapter4 IntermediateSQL
4.1 JoinExpressions 125 4.6 IndexDefinitioninSQL 164
4.2 Views 137 4.7 Authorization 165
4.3 Transactions 143 4.8 Summary 173
4.4 IntegrityConstraints 145 Exercises 176
4.5 SQLDataTypesandSchemas 153 FurtherReading 180
Chapter5 Advanced SQL
5.1 AccessingSQLfromaProgramming 5.5 AdvancedAggregationFeatures 219
Language 183 5.6 Summary 231
5.2 FunctionsandProcedures 198 Exercises 232
5.3 Triggers 206 FurtherReading 238
5.4 RecursiveQueries 213
PART TWO DATABASE DESIGN
Chapter6 DatabaseDesignUsingtheE-RModel
6.1 OverviewoftheDesignProcess 241 6.8 ExtendedE-RFeatures 271
6.2 TheEntity-RelationshipModel 244 6.9 Entity-RelationshipDesignIssues 279
6.3 ComplexAttributes 249 6.10 AlternativeNotationsforModeling
6.4 MappingCardinalities 252 Data 285
6.5 PrimaryKey 256 6.11 OtherAspectsofDatabaseDesign 291
6.6 RemovingRedundantAttributesinEntity 6.12 Summary 292
Sets 261 Exercises 294
6.7 ReducingE-RDiagramstoRelational FurtherReading 300
Schemas 264
Chapter7 RelationalDatabaseDesign
7.1 FeaturesofGoodRelationalDesigns 303 7.7 MoreNormalForms 341
7.2 DecompositionUsingFunctional 7.8 AtomicDomainsandFirstNormal
Dependencies 308 Form 342
7.3 NormalForms 313 7.9 Database-DesignProcess 343
7.4 Functional-DependencyTheory 320 7.10 ModelingTemporalData 347
7.5 AlgorithmsforDecompositionUsing 7.11 Summary 351
FunctionalDependencies 330 Exercises 353
7.6 DecompositionUsingMultivalued FurtherReading 360
Dependencies 336

--- Page 10 ---

Contents ix
PART THREE APPLICATION DESIGN AND
DEVELOPMENT
Chapter 8 ComplexDataTypes
8.1 Semi-structuredData 365 8.5 Summary 394
8.2 ObjectOrientation 376 Exercises 397
8.3 TextualData 382 FurtherReading 401
8.4 SpatialData 387
Chapter 9 ApplicationDevelopment
9.1 ApplicationProgramsandUser 9.7 ApplicationPerformance 434
Interfaces 403 9.8 ApplicationSecurity 437
9.2 WebFundamentals 405 9.9 EncryptionandItsApplications 447
9.3 Servlets 411 9.10 Summary 453
9.4 AlternativeServer-SideFrameworks 416 Exercises 455
9.5 Client-SideCodeandWebServices 421 FurtherReading 462
9.6 ApplicationArchitectures 429
PART FOUR BIG DATA ANALYTICS
Chapter 10 Big Data
10.1 Motivation 467 10.5 StreamingData 500
10.2 BigDataStorageSystems 472 10.6 GraphDatabases 508
10.3 TheMapReduceParadigm 483 10.7 Summary 511
10.4 BeyondMapReduce:Algebraic Exercises 513
Operations 494 FurtherReading 516
Chapter 11 DataAnalytics
11.1 OverviewofAnalytics 519 11.5 Summary 550
11.2 DataWarehousing 521 Exercises 552
11.3 OnlineAnalyticalProcessing 527 FurtherReading 555
11.4 DataMining 540

--- Page 11 ---

x Contents
PART FIVE STORAGE MANAGEMENT AND
INDEXING
Chapter 12 Physical StorageSystems
12.1 OverviewofPhysicalStorageMedia 559 12.6 Disk-BlockAccess 577
12.2 StorageInterfaces 562 12.7 Summary 580
12.3 MagneticDisks 563 Exercises 582
12.4 FlashMemory 567 FurtherReading 584
12.5 RAID 570
Chapter 13 DataStorageStructures
13.1 DatabaseStorageArchitecture 587 13.7 StorageOrganizationinMain-Memory
13.2 FileOrganization 588 Databases 615
13.3 OrganizationofRecordsinFiles 595 13.8 Summary 617
13.4 Data-DictionaryStorage 602 Exercises 619
13.5 DatabaseBuffer 604 FurtherReading 621
13.6 Column-OrientedStorage 611
Chapter 14 Indexing
14.1 BasicConcepts 623 14.8 Write-OptimizedIndexStructures 665
14.2 OrderedIndices 625 14.9 BitmapIndices 670
14.3 B+-TreeIndexFiles 634 14.10 IndexingofSpatialandTemporalData 672
14.4 B+-TreeExtensions 650 14.11 Summary 677
14.5 HashIndices 658 Exercises 679
14.6 Multiple-KeyAccess 661 FurtherReading 683
14.7 CreationofIndices 664
PART SIX QUERY PROCESSING AND
OPTIMIZATION
Chapter 15 QueryProcessing
15.1 Overview 689 15.7 EvaluationofExpressions 724
15.2 MeasuresofQueryCost 692 15.8 QueryProcessinginMemory 731
15.3 SelectionOperation 695 15.9 Summary 734
15.4 Sorting 701 Exercises 736
15.5 JoinOperation 704 FurtherReading 740
15.6 OtherOperations 719

--- Page 12 ---

Contents xi
Chapter 16 QueryOptimization
16.1 Overview 743 16.5 MaterializedViews 778
16.2 TransformationofRelational 16.6 AdvancedTopicsinQuery
Expressions 747 Optimization 783
16.3 EstimatingStatisticsofExpression 16.7 Summary 787
Results 757 Exercises 789
16.4 ChoiceofEvaluationPlans 766 FurtherReading 794
PART SEVEN TRANSACTION MANAGEMENT
Chapter 17 Transactions
17.1 TransactionConcept 799 17.8 TransactionIsolationLevels 821
17.2 ASimpleTransactionModel 801 17.9 ImplementationofIsolationLevels 823
17.3 StorageStructure 804 17.10 TransactionsasSQLStatements 826
17.4 TransactionAtomicityandDurability 805 17.11 Summary 828
17.5 TransactionIsolation 807 Exercises 831
17.6 Serializability 812 FurtherReading 834
17.7 TransactionIsolationandAtomicity 819
Chapter 18 ConcurrencyControl
18.1 Lock-BasedProtocols 835 18.8 SnapshotIsolation 872
18.2 DeadlockHandling 849 18.9 WeakLevelsofConsistencyin
18.3 MultipleGranularity 853 Practice 880
18.4 InsertOperations,DeleteOperations,and 18.10 AdvancedTopicsinConcurrency
PredicateReads 857 Control 883
18.5 Timestamp-BasedProtocols 861 18.11 Summary 894
18.6 Validation-BasedProtocols 866 Exercises 899
18.7 MultiversionSchemes 869 FurtherReading 904
Chapter 19 RecoverySystem
19.1 FailureClassification 907 19.8 EarlyLockReleaseandLogicalUndo
19.2 Storage 908 Operations 935
19.3 RecoveryandAtomicity 912 19.9 ARIES 941
19.4 RecoveryAlgorithm 922 19.10 RecoveryinMain-MemoryDatabases 947
19.5 BufferManagement 926 19.11 Summary 948
19.6 FailurewithLossofNon-Volatile Exercises 952
Storage 930 FurtherReading 956
19.7 HighAvailabilityUsingRemoteBackup
Systems 931

--- Page 13 ---

xii Contents
PART EIGHT PARALLEL AND DISTRIBUTED
DATABASES
Chapter 20 Database-SystemArchitectures
20.1 Overview 961 20.6 TransactionProcessinginParalleland
20.2 CentralizedDatabaseSystems 962 DistributedSystems 989
20.3 ServerSystemArchitectures 963 20.7 Cloud-BasedServices 990
20.4 ParallelSystems 970 20.8 Summary 995
20.5 DistributedSystems 986 Exercises 998
FurtherReading 1001
Chapter 21 ParallelandDistributedStorage
21.1 Overview 1003 21.6 DistributedFileSystems 1019
21.2 DataPartitioning 1004 21.7 ParallelKey-ValueStores 1023
21.3 DealingwithSkewinPartitioning 1007 21.8 Summary 1032
21.4 Replication 1013 Exercises 1033
21.5 ParallelIndexing 1017 FurtherReading 1036
Chapter 22 ParallelandDistributedQueryProcessing
22.1 Overview 1039 22.7 QueryOptimizationforParallel
22.2 ParallelSort 1041 Execution 1064
22.3 ParallelJoin 1043 22.8 ParallelProcessingofStreamingData 1070
22.4 OtherOperations 1048 22.9 DistributedQueryProcessing 1076
22.5 ParallelEvaluationofQueryPlans 1052 22.10 Summary 1086
22.6 QueryProcessingonShared-Memory Exercises 1089
Architectures 1061 FurtherReading 1093
Chapter 23 ParallelandDistributedTransactionProcessing
23.1 DistributedTransactions 1098 23.6 ReplicationwithWeakDegreesof
23.2 CommitProtocols 1100 Consistency 1133
23.3 ConcurrencyControlinDistributed 23.7 CoordinatorSelection 1146
Databases 1111 23.8 ConsensusinDistributedSystems 1150
23.4 Replication 1121 23.9 Summary 1162
23.5 ExtendedConcurrencyControl Exercises 1165
Protocols 1129 FurtherReading 1168

--- Page 14 ---

Contents xiii
PART NINE ADVANCED TOPICS
Chapter24 Advanced IndexingTechniques
24.1 BloomFilter 1175 24.5 HashIndices 1190
24.2 Log-StructuredMergeTreeand 24.6 Summary 1203
Variants 1176 Exercises 1205
24.3 BitmapIndices 1182 FurtherReading 1206
24.4 IndexingofSpatialData 1186
Chapter25 Advanced Application Development
25.1 PerformanceTuning 1210 25.5 DistributedDirectorySystems 1240
25.2 PerformanceBenchmarks 1230 25.6 Summary 1243
25.3 OtherIssuesinApplication Exercises 1245
Development 1234 FurtherReading 1248
25.4 Standardization 1237
Chapter26 BlockchainDatabases
26.1 Overview 1252 26.6 SmartContracts 1269
26.2 BlockchainProperties 1254 26.7 PerformanceEnhancement 1274
26.3 AchievingBlockchainPropertiesvia 26.8 EmergingApplications 1276
CryptographicHashFunctions 1259 26.9 Summary 1279
26.4 Consensus 1263 Exercises 1280
26.5 DataManagementinaBlockchain 1267 FurtherReading 1282
PART TEN APPENDIX A
Appendix A DetailedUniversitySchema 1287
Index 1299
PART ELEVEN ONLINE CHAPTERS
Chapter27 FormalRelationalQueryLanguages
Chapter28 Advanced RelationalDatabaseDesign
Chapter29 Object-BasedDatabases
Chapter30 XML
Chapter31 InformationRetrieval
Chapter32 PostgreSQL

--- Page 16 ---

Preface
Database management has evolved from a specializedcomputer applicationto a cen-
tralcomponentofvirtuallyallenterprises,and,asaresult,knowledgeaboutdatabase
systemshasbecomeanessentialpartofaneducationincomputerscience.Inthistext,
wepresentthefundamentalconceptsofdatabasemanagement.Theseconceptsinclude
aspectsofdatabasedesign,databaselanguages,anddatabase-systemimplementation.
This text is intended for a first course in databases at the junior or senior under-
graduate, or first-year graduate, level. In addition to basic material for a first course,
the text contains advanced material that can be used for course supplements, or as
introductorymaterialforanadvancedcourse.
We assume only a familiarity with basic data structures, computer organization,
and a high-level programming language such as Java, C, C++, or Python. We present
conceptsasintuitivedescriptions,manyofwhicharebasedonourrunningexampleof
a university. Important theoreticalresults are covered, but formal proofs are omitted.
Inplaceofproofs,figuresandexamplesareusedtosuggestwhyaresultistrue.Formal
descriptions and proofs of theoretical results may be found in research papers and
advancedtextsthatarereferencedinthebibliographicalnotes.
The fundamental concepts and algorithms covered in the book are often based
on those used in existing commercial or experimental database systems. Our aim is
to present these concepts and algorithms in a general setting that is not tied to one
particulardatabasesystem,thoughwedoprovidereferencestospecificsystemswhere
appropriate.
Inthis,theseventheditionofDatabaseSystemConcepts,wehaveretainedtheover-
allstyleoftheprioreditionswhileevolvingthecontentandorganizationtoreflectthe
changesthatareoccurringinthewaydatabasesaredesigned,managed,andused.One
suchmajorchangeistheextensiveuseof“BigData”systems.Wehavealsotakeninto
accounttrendsintheteachingofdatabaseconceptsandmadeadaptationstofacilitate
thesetrendswhereappropriate.
xv

--- Page 17 ---

xvi Preface
Amongthenotablechangesinthiseditionare:
• Extensive coverage of Big Data systems, from the user perspective (Chapter 10),
as well as from an internal perspective (Chapter 20 through Chapter 23), with
extensiveadditionsandmodificationscomparedtothesixthedition.
• A new chapter entitled “Blockchain Databases” (Chapter 26) that introduces
blockchain technology and its growing role in enterprise applications. An im-
portant focus in this chapter is the interaction between blockchain systems and
databasesystems.
• Updates to all chapters covering database internals (Chapter 12 through Chap-
ter 19) to reflect current-generation technology, such as solid-state disks, main-
memorydatabases,multi-coresystems,andcolumn-stores.
• Enhanced coverage of semi-structured data management using JSON, RDF, and
SPARQL(Section8.1).
• Updatedcoverageoftemporaldata(inSection7.10),dataanalytics(Chapter11),
and advanced indexing techniques such as write-optimized indices (Section 14.8
andSection24.2).
• Reorganizationandupdateofchapterstobettersupportcourseswithasignificant
hands-on component (which we strongly recommend for any database course),
including use of current-generation application development tools and Big Data
systemssuchasApacheHadoopandSpark.
These and other updates have arisen from the many comments and suggestions we
havereceivedfromreadersofthesixthedition,ourstudentsatYaleUniversity,Lehigh
University, and IIT Bombay, and our own observations and analyses of developments
indatabasetechnology.
Content of This Book
Thetextisorganizedinelevenmajorparts.
• Overview(Chapter1).Chapter1providesageneraloverviewofthenatureandpur-
pose of database systems. We explain how the concept of a database system has
developed, what the common features of database systems are, what a database
system does for the user, and how a database system interfaces with operating
systems. We also introducean example database application:a universityorgani-
zationconsistingofmultipledepartments,instructors,students,andcourses.This
application is used as a running example throughout the book. This chapter is
motivational,historical,andexplanatoryinnature.

--- Page 18 ---

Preface xvii
• Part 1: Relational Model and SQL (Chapter 2 through Chapter 5). Chapter 2 in-
troduces the relational model of data, covering basic concepts such as the struc-
tureofrelationaldatabases,databaseschemas,keys, schemadiagrams,relational
querylanguages,relationaloperations,andtherelationalalgebra.Chapter3,Chap-
ter 4, and Chapter 5 focus on the most influential of the user-oriented relational
languages: SQL. The chapters in this part describe data manipulation: queries,
updates, insertions, and deletions, assuming a schema design has been provided.
Althoughdata-definitionsyntaxiscoveredindetailhere,schemadesignissuesare
deferredtoPart2.
• Part 2: Database Design (Chapter 6 and Chapter 7). Chapter 6 provides an
overview of the database-design process and a detailed description of the entity-
relationship data model. The entity-relationshipdata model provides a high-level
viewoftheissuesindatabasedesignandoftheproblemsencounteredincapturing
thesemanticsofrealisticapplicationswithintheconstraintsofadatamodel.UML
class-diagram notation is also covered in this chapter. Chapter 7 introduces rela-
tionaldatabasedesign.Thetheoryoffunctionaldependenciesandnormalization
is covered, with emphasis on the motivation and intuitive understanding of each
normalform.Thischapterbeginswithanoverviewofrelationaldesignandrelies
on an intuitive understanding of logical implication of functional dependencies.
Thisallowstheconceptofnormalizationtobeintroducedpriortofullcoverageof
functional-dependencytheory,whichispresentedlaterinthechapter.Instructors
maychoosetouseonlythisinitialcoveragewithoutlossofcontinuity.Instructors
covering the entire chapter will benefit from students having a good understand-
ingofnormalizationconceptstomotivatethemtolearnsomeofthechallenging
concepts of functional-dependency theory. The chapter ends with a section on
modelingoftemporaldata.
• Part3:ApplicationDesignandDevelopment(Chapter8andChapter9).Chapter
8 discusses several complex data types that are particularly important for appli-
cationdesignanddevelopment,includingsemi-structureddata,object-baseddata,
textualdata,andspatialdata.AlthoughthepopularityofXMLinadatabasecon-
texthasbeendiminishing,weretainanintroductiontoXML,whileaddingcoverage
ofJSON,RDF,andSPARQL.Chapter9discussestoolsandtechnologiesthatare
used tobuild interactive web-based and mobiledatabase applications.This chap-
terincludesdetailedcoverage onboththeserversideandtheclientside.Among
the topics covered are servlets, JSP, Django, JavaScript, and web services. Also
discussed are application architecture, object-relational mapping systems includ-
ingHibernateandDjango,performance(includingcachingusingmemcachedand
Redis),andtheuniquechallengesinensuringweb-applicationsecurity.
• Part 4: Big Data Analytics (Chapter 10 and Chapter 11). Chapter 10 provides
an overview of large-scale data-analytic applications, with a focus on how those
applications place distinctdemands on data management compared with the de-

--- Page 19 ---

xviii Preface
mandsoftraditionaldatabaseapplications.Thechapterthendiscusseshowthose
demands are addressed. Among the topics covered are Big Data storage systems
including distributed file systems, key-value stores and NoSQL systems, MapRe-
duce,ApacheSpark,streamingdata,andgraphdatabases.Theconnectionofthese
systems and concepts with database concepts introduced earlier is emphasized.
Chapter11discussesthestructureanduseofsystemsdesignedforlarge-scaledata
analysis.Afterfirstexplainingtheconceptsofdataanalytics,businessintelligence,
anddecisionsupport,thechapterdiscussesthestructureofadatawarehouseand
theprocessofgatheringdataintoawarehouse. Thechapternextcoversusage of
warehouse data in OLAP applications followed by a survey of data-mining algo-
rithmsandtechniques.
• Part5:StorageManagementandIndexing(Chapter12throughChapter14).Chap-
ter 12 deals with storage devices and how the properties of those devices influ-
encedatabasephysicalorganizationandperformance.Chapter13dealswithdata-
storagestructures,includingfileorganizationandbuffermanagement.Avarietyof
data-accesstechniquesarepresentedinChapter14.Multilevelindex-basedaccess
isdescribed,culminatingindetailedcoverageofB+-trees.Thechapterthencovers
indexstructuresforapplicationswheretheB+-treestructureislessappropriate,in-
cludingwrite-optimizedindicessuchasLSMtreesandbuffertrees,bitmapindices,
andtheindexingofspatialdatausingk-dtrees,quadtreesandR-trees.
• Part 6: Query Processing and Optimization (Chapter 15 and Chapter 16). Chap-
ter 15 and Chapter 16 address query-evaluation algorithms and query optimiza-
tion.Chapter15focusesonalgorithmsfortheimplementationofdatabaseopera-
tions,particularlythewiderangeofjoinalgorithms,whicharedesignedtoworkon
verylargedatathatmaynotfitinmain-memory.Queryprocessingtechniquesfor
main-memorydatabasesarealsocoveredinthischapter.Chapter16coversquery
optimization, starting by showing how query plans can be transformed to other
equivalent plans by using transformation rules. The chapter then describes how
to generate estimates of query execution costs, and how to efficiently find query
executionplanswiththelowestcost.
• Part 7: Transaction Management (Chapter 17 through Chapter 19). Chapter 17
focuses on the fundamentals of a transaction-processing system: atomicity, con-
sistency, isolation, and durability. It provides an overview of the methods used
toensuretheseproperties,includinglog-basedrecoveryandconcurrencycontrol
using locking, timestamp-based techniques, and snapshot isolation. Courses re-
quiring only a survey of the transaction concept can use Chapter 17 on its own
withouttheotherchaptersinthispart;thosechaptersprovidesignificantlygreater
depth.Chapter18focusesonconcurrencycontrolandpresentsseveraltechniques
for ensuring serializability, includinglocking, timestamping, and optimistic (vali-
dation) techniques. Multiversion concurrency control techniques, including the
widelyused snapshotisolationtechnique,and anextension ofthetechniquethat

--- Page 20 ---

Preface xix
guarantees serializability, are also covered. This chapter also includes discussion
of weak levels of consistency, concurrency on index structures, concurrency in
main-memory database systems, long-duration transactions, operation-level con-
currency, and real-time transaction processing. Chapter 19 covers the primary
techniquesforensuringcorrecttransactionexecutiondespitesystem crashesand
storagefailures.Thesetechniquesincludelogs,checkpoints,anddatabasedumps,
aswellashighavailabilityusingremotebackupsystems.Recoverywithearlylock
release,andthewidelyusedARIESalgorithmarealsopresented.Thischapterin-
cludes discussion of recovery in main-memory database systems and the use of
NVRAM.
• Part 8: Parallel and Distributed Databases (Chapter 20 through Chapter 23).
Chapter 20 covers computer-system architecture, and describes the influence of
the underlying computer system on the database system. We discuss centralized
systems, client–server systems, parallel and distributed architectures, and cloud-
based systems in this chapter. The remaining three chapters in this part address
distinct aspects of parallel and distributed databases, with Chapter 21 covering
storageandindexing,Chapter22coveringqueryprocessing,andChapter23cov-
eringtransactionmanagement.Chapter21includesdiscussionofpartitioningand
data skew, replication, parallel indexing, distributed file systems (including the
Hadoopfilesystem),andparallelkey-valuestores.Chapter22includesdiscussion
ofparallelismbothamongmultiplequeriesandwithinasinglequery.Itcoverspar-
allelanddistributedsortandjoin,MapReduce,pipelining,theVolcanoexchange-
operator model,thread-levelparallelism,streamingdata, and the optimizationof
geographically distributed queries. Chapter 23 includes discussion of traditional
distributedconsensussuchastwo-phasecommitandmoresophisticatedsolutions
includingPaxosandRaft.Itcoversavarietyofalgorithmsfordistributedconcur-
rency control, including replica management and weaker degrees of consistency.
Thetrade-offsimpliedbytheCAPtheoremarediscussedalongwiththemeansof
detectinginconsistencyusingversionvectorsandMerkletrees.
• Part 9: Advanced Topics (Chapter 24 through Chapter 26). Chapter 24 expands
upon the coverage of indexing in Chapter 14 with detailed coverage of the LSM
treeand itsvariants, bitmapindices,spatial indexing,and dynamichashing tech-
niques.Chapter25expandsupon thecoverage ofChapter9withadiscussionof
performance tuning, benchmarking, testing, and migration from legacy systems,
standardization,anddistributeddirectorysystems.Chapter26looksatblockchain
technology from a database perspective. It describes blockchain data structures
and theuse of cryptographichash functions and public-keyencryption toensure
the blockchain properties of anonymity, irrefutability, and tamper resistance. It
describes and compares the distributed consensus algorithms used to ensure de-
centralization, including proof-of-work, proof-of-stake, and Byzantine consensus.
Much of the chapter focuses on the features that make blockchain an important
database concept,includingthe role of permisssioned blockchains,the encoding

--- Page 21 ---

xx Preface
of business logic and agreements in smart contracts, and interoperability across
blockchains. Techniques for achieving database-scale transaction-processing per-
formance are discussed. A final section surveys current and contemplated enter-
priseblockchainapplications.
• Part10:Appendix.AppendixApresentsdetailsofouruniversityschema,including
thefullschema,DDL,andallthetables.
• Part 11: Online Chapters (Chapter 27 through Chapter 32) available online at
db-book.com. We provide six chapters that cover material that is of historical
nature or is advanced; these chapters are available only online. Chapter 27 cov-
ers “pure” query languages: the tuple and domain relational calculus and Data-
log, which has a syntax modeled after the Prolog language. Chapter 28 covers
advancedtopicsinrelationaldatabasedesign,includingthetheoryofmultivalued
dependencies and fourth normal form, as well as higher normal forms. Chapter
29coversobject-baseddatabasesandmorecomplexdatatypessuchasarray,and
multisettypes,aswellastablesthatarenotin1NF.Chapter30expandsonthecov-
erage in Chapter8ofXML.Chapter 31coversinformationretrieval,whichdeals
withqueryingofunstructuredtextualdata.Chapter32providesanoverviewofthe
PostgreSQLdatabasesystem,andistargetedatcoursesfocusingondatabaseinter-
nals.Thechapterislikelytobeparticularlyusefulforsupportingstudentprojects
thatworkwiththeopen-sourcecodebaseofthePostgreSQLdatabase.
At the end of each chapter we provide references in a section titled Further Reading.
This section is intentionally abbreviated and provides references that allow students
to continue their study of the material covered in the chapter or to learn about new
developments in the area covered by the chapter. On occasion, the further reading
section includes original source papers that have become classics of which everyone
should be aware.Detailedbibliographicalnotes for eachchapter are availableonline,
and provide references for readers who wish to go into further depth on any of the
topicscoveredinthechapter.
The Seventh Edition
The production of this seventh edition has been guided by the many comments and
suggestionswereceivedconcerningtheearliereditions,byourownobservationswhile
teachingatYaleUniversity,LehighUniversity,andIITBombay,andbyouranalysisof
thedirectionsinwhichdatabasetechnologyisevolving.
Weprovidedalistofthemajornewfeaturesofthiseditionearlierinthispreface;
these include coverage of extensive coverage of Big Data, updates to all chapters to
reflectcurrentgenerationhardwaretechnology,semi-structureddatamanagement,ad-
vancedindexingtechniques,andanewchapteronblockchaindatabases.Beyondthese
major changes, we revised the material in each chapter, bringing the older material

--- Page 22 ---

Preface xxi
up-to-date,addingdiscussionsonrecentdevelopmentsindatabasetechnology,andim-
provingdescriptionsoftopicsthatstudentsfounddifficulttounderstand.Wehavealso
addednewexercisesandupdatedreferences.
Forinstructorswhopreviouslyusedthesixthedition,welistthemoresignificant
changesbelow:
• RelationalalgebrahasbeenmovedintoChapter2,tohelpstudentsbetterunder-
stand relational operations that form the basis of query languages such as SQL.
Deepercoverageofrelationalalgebraalsoaidsinunderstandingthealgebraicop-
eratorsneededfordiscussionlaterofqueryprocessingandoptimization.Thetwo
variants of the relational calculus are now in an online chapter, since we believe
theyarenowofvalueonlytomoretheoreticallyorientedcourses,andcanbeomit-
tedbymostdatabasecourses.
• TheSQLchaptersnowincludemoredetailsofdatabase-systemspecificSQLvari-
ations, to aid students carrying out practical assignments. Connections between
SQL and the multiset relational algebra are also covered in more detail. Chapter
4 now covers all the material concerning joins, whereas previously natural join
wasintheprecedingchapter.Coverageofsequencesusedtogenerateuniquekey
values, and coverage of row-level security have also been added to this chapter.
RecentextensionstotheJDBCAPIthatareparticularlyusefularenowcoveredin
Chapter5;coverageofOLAPhasbeenmovedfromthischaptertoChapter11.
• Chapter 6 has been modified to cover E-R diagrams along with E-R concepts, in-
steadoffirstcoveringtheconceptsandthenintroducingE-Rdiagramsaswasdone
in earlier editions. We believe this will help students better comprehend the E-R
model.
• Chapter 7 now has improved coverage of temporal data modeling, including
SQL:2011temporaldatabasefeatures.
• Chapter 8 is a new chapter that covers complex data types, including semi-
structureddata,suchasXML,JSON,RDF,andSPARQL,object-baseddata,textual
data,andspatialdata.Object-baseddatabases,XML,andinformationretrievalon
textualdatawerecoveredindetailinthesixthedition;thesetopicshavebeenab-
breviated and covered in Chapter 8, while the original chapters from the sixth
editionhavenowbeenmadeavailableonline.
• Chapter 9 has been significantly updated to reflect modern application devel-
opment tools and techniques, including extended coverage of JavaScript and
JavaScriptlibrariesforbuildingdynamicwebinterfaces,applicationdevelopment
inPythonusingtheDjangoframework,coverageofwebservices,anddisconnec-
tion operations using HTML5. Object-relation mapping using Django has been
added,asalsodiscussionoftechniquesfordevelopinghigh-performanceapplica-
tionsthatcanhandlelargetransactionloads.

--- Page 23 ---

xxii Preface
• Chapter 10 is a new chapter on Big Data, covering Big Data concepts and tools
from a user perspective. Big Data storage systems, the MapReduce paradigm,
Apache Hadoop and Apache Spark, and streamingand graph databases are cov-
ered in this chapter. The goal is to enable readers to use Big Data systems, with
onlyasummarycoverage ofwhathappensbehindthescenes.BigDatainternals
arecoveredindetailinlaterchapters.
• The chapter on storage and file structure has been split into two chapters. Chap-
ter 12 whichcoversstorage has been updated withnew technology, includingex-
pandedcoverageofflashmemory,column-orientedstorage,andstorageorganiza-
tioninmain-memorydatabases.Chapter13,whichcoversdatastoragestructures
hasbeenexpanded,andnowcoversdetailssuchasfree-spacemaps,partitioning,
andmostimportantlycolumn-orientedstorage.
• Chapter14onindexingnowcoverswrite-optimizedindexstructuresincludingthe
LSM tree and its variants, and the buffer tree, which are seeing increasingusage.
Spatialindicesarenowcoveredbrieflyinthischapter.Moredetailedcoverageof
LSM trees and spatial indices is provided in Chapter 24, which covers advanced
indexingtechniques.BitmapindicesarenowcoveredinbriefinChapter14,while
more detailed coverage has been moved to Chapter 24. Dynamic hashing tech-
niques have been moved into Chapter 24, since they are of limited practical im-
portancetoday.
• Chapter15onqueryprocessinghassignificantlyexpandedcoverageofpipelining
inqueryprocessing,newmaterialonqueryprocessinginmain-memory,including
querycompilation,aswellasbriefcoverageofspatialjoins.Chapter16onquery
optimizationhas more examples of equivalence rules for operators such as outer
joins and aggregates, has updated material on statistics for cost estimation, an
improved presentation of the join-order optimization algorithm. Techniques for
decorrelatingnested subqueries using semijoin and antijoin operations have also
beenadded.
• Chapter 18 on concurrency control has new material on concurrency control in
main-memory.Chapter 19 on recovery now gives more importance to high avail-
abilityusingremotebackupsystems.
• Ourcoverageofparallelanddistributeddatabaseshasbeencompletelyrevamped.
Becauseoftheevolutionofthesetwoareasintoacontinuumfromlow-levelparal-
lelismtogeographicallydistributedsystems,wenowpresentthesetopicstogether.
° Chapter20ondatabasearchitectureshasbeensignificantlyupdatedfromthe
earlier edition, including new material on practical interconnection networks
like the tree-like (or fat-tree) architecture, and significantly expanded and up-
datedmaterialonshared-memoryarchitecturesandcachecoherency.Thereis
anentirelynewsectiononcloud-basedservices,coveringvirtualmachinesand
containers,platform-as-a-service,software-as-a-service,andelasticity.

--- Page 24 ---

Preface xxiii
° Chapter 21 covers parallel and distributed storage; while a few parts of this
chapter were present in the sixth edition, such as partitioning techniques, ev-
erythingelseinthischapterisnew.
° Chapter22coversparallelanddistributedqueryprocessing.Againonlyafew
sectionsofthischapter,suchasparallelalgorithmsforsorting,join,andafew
otherrelationaloperations,werepresentinthesixthedition,almosteverything
elseinthischapterisnew.
° Chapter23coversparallelanddistributedtransactionprocessing.Afewparts
ofthischapter,suchasthesectionson2PC,persistentmessaging,andconcur-
rency control in distributed databases, are new but almost everything else in
thischapterisnew.
Asinthesixthedition,wefacilitatethefollowingofourrunningexamplebylisting
thedatabaseschemaandthesamplerelationinstancesforouruniversitydatabaseto-
getherinAppendixAaswellaswheretheyareusedinthevariousregularchapters.In
addition,weprovide,onourwebsitedb-book.com,SQLdata-definitionstatementsfor
theentireexample,alongwithSQLstatementstocreateourexamplerelationinstances.
Thisencouragesstudentstorunexamplequeriesdirectlyonadatabasesystemandto
experimentwithmodifyingthosequeries.Alltopicsnotlistedaboveareupdatedfrom
thesixthedition,thoughtheiroverallorganizationisrelativelyunchanged.
End of Chapter Material
Each chapter has a list of review terms, in addition to a summary, which can help
readersreviewkeytopicscoveredinthechapter.
As in the sixth edition, the exercises are divided into two sets: practice exercises
andexercises.Thesolutionsforthepracticeexercisesarepubliclyavailableontheweb
siteofthebook. Studentsareencouragedtosolve thepracticeexercisesontheirown
and later use the solutions on the web site to check their own solutions. Solutions to
theotherexercisesareavailableonlytoinstructors(see“Instructor’sNote,”below,for
informationonhowtogetthesolutions).
Many chapters have a tools section at the end of the chapter that provides infor-
mation on software tools related to the topic of the chapter; some of these tools can
beusedforlaboratoryexercises.SQLDDLandsampledatafortheuniversitydatabase
andotherrelationsusedintheexercisesareavailableonthewebsiteofthebookand
canbeusedforlaboratoryexercises.
Instructor’s Note
It is possible to design courses by using various subsets of the chapters. Some of the
chapters can also be covered in an order different from their order in the book. We
outlinesomeofthepossibilitieshere:

--- Page 25 ---

xxiv Preface
• Chapter5(AdvancedSQL).Thischaptercanbeskippedordeferredtolaterwith-
outlossofcontinuity.WeexpectmostcourseswillcoveratleastSection5.1.1early,
asJDBCislikelytobeausefultoolinstudentprojects.
• Chapter6(E-RModel).ThischaptercanbecoveredaheadofChapter3,Chapter
4,andChapter5ifyousodesire,sinceChapter6doesnothaveanydependency
on SQL. However, for courses with a programming emphasis, a richer variety of
laboratory exercisesis possible afterstudying SQL,and we recommendthat SQL
becoveredbeforedatabasedesignforsuchcourses.
• Chapter 15 (Query Processing) and Chapter 16 (Query Optimization). These
chapters can be omitted from an introductory course without affecting coverage
ofanyotherchapter.
• Part7(TransactionManagement).Ourcoverageconsistsofanoverview(Chapter
17) followed by chapterswith details. You might choose to use Chapter 17 while
omitting Chapter 18 and Chapter 19, if you defer these latter chapters to an ad-
vancedcourse.
• Part8(ParallelandDistributedDatabases).Ourcoverageconsistsofanoverview
(Chapter 20), followed by chapters on the topics of storage, query processing,
andtransactions.YoumightchoosetouseChapter20whileomittingChapter21
throughChapter23ifyoudefertheselatterchapterstoanadvancedcourse.
• Part11(Onlinechapters).Chapter27(Formal-RelationalQueryLanguages).This
chaptercanbecoveredimmediatelyafterChapter2,aheadofSQL.Alternatively,
this chapter may be omitted from an introductory course. The five other online
chapters(Advanced RelationalDatabase Design, Object-Based Databases, XML,
InformationRetrieval,andPostgreSQL)canbeusedasself-studymaterialoromit-
tedfromanintroductorycourse.
Modelcoursesyllabi,basedonthetext,canbefoundonthewebsiteofthebook.
Web Site and Teaching Supplements
AwebsiteforthebookisavailableattheURL:db-book.com.Thewebsitecontains:
• Slidescoveringallthechaptersofthebook.
• Answerstothepracticeexercises.
• Thesixonlinechapters.
• Laboratory material, including SQL DDL and sample data for the university
schema and other relations used in exercises, and instructions for setting up and
usingvariousdatabasesystemsandtools.
• Anup-to-dateerratalist.

--- Page 26 ---

Preface xxv
Thefollowingadditionalmaterialisavailableonlytofaculty:
• Aninstructor’smanualcontainingsolutionstoallexercisesinthebook.
• Aquestionbankcontainingextraexercises.
For more information about how to get a copy of the instructor’s manual and the
question bank, please send an email message to sem@mheducation.com. In the
United States, you may call 800-338-3987. The McGraw-Hill web site for this book
iswww.mhhe.com/silberschatz.
Contacting Us
Wehaveendeavoredtoeliminatetypos,bugs,andthelikefromthetext.But,asinnew
releases of software, bugs almost surely remain; an up-to-date errata list is accessible
from the book’s web site. We would appreciate it if you would notify us of any errors
oromissionsinthebookthatarenotonthecurrentlistoferrata.
We would be glad to receive suggestions on improvements to the book. We also
welcome any contributions to the book web site that could be of use to other read-
ers,suchasprogrammingexercises,projectsuggestions,onlinelabsandtutorials,and
teachingtips.
Email should be addressed to db-book-authors@cs.yale.edu. Any other corre-
spondenceshouldbesenttoAviSilberschatz,DepartmentofComputerScience,Yale
University,51ProspectStreet,P.O.Box208285,NewHaven,CT06520-8285USA.
Acknowledgments
Manypeoplehavehelpeduswiththisseventhedition,aswellaswiththeprevioussix
editionsfromwhichitisderived,andweareindebtedtoallofthem.
SeventhEdition
• Ioannis Alagiannis and Renata Borovica-Gajic for writing Chapter 32 on the
PostgreSQLdatabase,whichisavailableonline.Thechapterisacompleterewrite
of the PostgreSQL chapter in the 6th edition, which was authored by Anastasia
Ailamaki, Sailesh Krishnamurthy, Spiros Papadimitriou, Bianca Schroeder, Karl
Schnaitter,andGavinSherry.
• JudiPaigeforherhelpingeneratingfigures,presentationslides,andwithhandling
thecopy-editingmaterial.
• Mark Wogahn for making sure that the software to produce the book, including
LaTeXmacrosandfonts,workedproperly.

--- Page 27 ---

xxvi Preface
• SriramSrinivasanfordiscussionsandfeedbackthathaveimmenselybenefitedthe
chaptersonparallelanddistributeddatabases.
• N.L.Sardaforhisinsightfulfeedbackonthesixthedition,andonsomesections
oftheseventhedition.
• BikashChandraandVenkateshEmanifortheirhelpwithupdatestotheapplica-
tiondevelopmentchapter,includingcreationofsamplecode.
• Students at IIT Bombay, particularly Ashish Mithole, for their feedback on draft
versionsofthechaptersonparallelanddistributeddatabases.
• StudentsatYale,Lehigh,andIITBombay,fortheircommentsonthesixthedition.
• Jeffrey Anthony, partner and CTO, Synaptic; and Lehigh students Corey Ca-
plan (now co-founder, Leavitt Innovations); Gregory Cheng; Timothy LaRowe;
and Aaron Rotem for comments and suggestions that have benefited the new
blockchainchapter.
Previous Editions
• Hakan Jakobsson (Oracle), for writing the chapter on the Oracle database sys-
tem in the sixth edition; Sriram Padmanabhan (IBM), for writingthe chapterde-
scribingthe IBM DB2database system in the sixth edition;and SameetAgarwal,
Jos´eA.Blakeley,ThierryD’Hers,GeraldHinson,DirkMyers,VaqarPirzada,Bill
Ramos, Balaji Rathakrishnan, Michael Rys, Florian Waas, and Michael Zwilling
for writing the chapter describing the Microsoft SQL Server database system in
thesixthedition;andinparticularJos´eBlakeley,whosadlyisnolongeramongst
us, for coordinating and editing the chapter; and C´esar Galindo-Legaria, Goetz
Graefe,KalenDelaney,andThomasCaseyfortheircontributionstotheprevious
editionoftheMicrosoftSQLServerchapter.Thesechapters,however,arenotpart
oftheseventhedition.
• Anastasia Ailamaki, Sailesh Krishnamurthy, Spiros Papadimitriou, Bianca
Schroeder, Karl Schnaitter, and Gavin Sherry for writing the chapter on
PostgreSQLinthesixthedition.
• Daniel Abadi for reviewing the table of contents of the fifth edition and helping
withtheneworganization.
• Steve Dolins,UniversityofFlorida;RolandoFernanez,George WashingtonUni-
versity;FrantisekFranek,McMasterUniversity;LatifurKhan,UniversityofTexas
at Dallas; Sanjay Madria, Missouri University of Science and Technology; Aris
Ouksel,UniversityofIllinois;andRichardSnodgrass,UniversityofWaterloo;who
servedasreviewersofthebookandwhosecommentshelpedusgreatlyinformu-
latingthesixthedition.

--- Page 28 ---

Preface xxvii
• JudiPaigeforherhelpingeneratingfiguresandpresentationslides.
• Mark Wogahn for making sure that the software to produce the book, including
LaTeXmacrosandfonts,workedproperly.
• N.L.Sardaforfeedbackthathelpedusimproveseveralchapters.VikramPudifor
motivatingustoreplacetheearlierbankschema;andShetalShahforfeedbackon
severalchapters.
• StudentsatYale,Lehigh,andIITBombay,fortheircommentsonthefifthedition,
aswellasonpreprintsofthesixthedition.
• ChenLiandSharadMehrotraforprovidingmaterialonJDBCandsecurityforthe
fifthedition.
• MarilynTurnamianandNandprasadJoshiprovidedsecretarialassistanceforthe
fifth edition,and Marilyn alsoprepared an earlydraft ofthe cover design for the
fifthedition.
• LynDupr´ecopyeditedthethirdeditionandSaraStrandtmaneditedthetextofthe
thirdedition.
• Nilesh Dalvi, Sumit Sanghai, Gaurav Bhalotia, Arvind Hulgeri K. V. Raghavan,
Prateek Kapadia, Sara Strandtman, Greg Speegle, and Dawn Bezviner helped to
preparetheinstructor’smanualforearliereditions.
• Theideaofusingshipsaspartofthecoverconceptwasoriginallysuggestedtous
byBruceStephan.
• The following people offered suggestions and comments for the fifth and earlier
editions of the book. R. B. Abhyankar, Hani Abu-Salem, Jamel R. Alsabbagh,
Raj Ashar, Don Batory, Phil Bernhard, Christian Breimann, Gavin M. Bierman,
JanekBogucki,HaranBoral,PaulBourgeois,PhilBohannon,RobertBrazile,Yuri
Breitbart, Ramzi Bualuan, Michael Carey, Soumen Chakrabarti, Tom Chappell,
Zhengxin Chen, Y. C. Chin, Jan Chomicki, Laurens Damen, Prasanna Dhan-
dapani, Qin Ding, Valentin Dinu, J. Edwards, Christos Faloutsos, Homma Far-
ian, Alan Fekete, Frantisek Franek, Shashi Gadia, Hector Garcia-Molina, Goetz
Graefe, Jim Gray, Le Gruenwald, Eitan M. Gurari, William Hankley, Bruce
Hillyer, Ron Hitchens, Chad Hogg, Arvind Hulgeri, Yannis Ioannidis, Zheng Ji-
aping, Randy M. Kaplan, Graham J. L. Kemp, Rami Khouri, Hyoung-Joo Kim,
WonKim,HenryKorth(fatherofHenryF.),CarolKroll,HaeChoonLee,Sang-
Won Lee, Irwin Levinstein, Mark Llewellyn, Gary Lindstrom, Ling Liu, Dave
Maier,KeithMarzullo,MartyMaskarinec,FletcherMattox,SharadMehrotra,Jim
Melton,AlbertoMendelzon,AmiMotro,BhagirathNarahari,Yiu-KaiDennisNg,
Thanh-DuyNguyen,AnilNigam,CyrilOrji,MeralOzsoyoglu,D.B.Phatak,Juan
AltmayerPizzorno,BrucePorter,SunilPrabhakar,JimPeterson,K.V.Raghavan,
Nahid Rahman, Rajarshi Rakshit, Krithi Ramamritham, Mike Reiter, Greg Ric-

--- Page 29 ---

xxviii Preface
cardi,OdinaldoRodriguez,MarkRoth,MarekRusinkiewicz,MichaelRys,Sunita
Sarawagi, N. L. Sarda, Patrick Schmid, Nikhil Sethi, S. Seshadri, Stewart Shen,
Shashi Shekhar, AmitSheth, Max Smolens, NanditSoparkar, Greg Speegle, Jeff
Storey, Dilys Thomas, Prem Thomas, Tim Wahls, Anita Whitehall, Christopher
Wilson,MarianneWinslett,WeiningZhang,andLiuZhenming.
PersonalNotes
Sudarshanwouldliketoacknowledgehiswife,Sita,forherlove,patience,andsupport,
andchildrenMadhurandAdvaithfortheirloveandjoiedevivre.Hankwouldliketo
acknowledge his wife, Joan, and hischildren,Abby and Joe, for theirlove and under-
standing. Avi would like to acknowledge Valerie for her love, patience, and support
duringtherevisionofthisbook.
A.S.
H.F.K.
S.S.

--- Page 30 ---

1
CHAPTER
Introduction
A database-management system (DBMS) is a collection of interrelated data and a set
of programs to access those data. The collection of data, usually referred to as the
database,containsinformationrelevanttoanenterprise.TheprimarygoalofaDBMS
is to provide a way to store and retrieve database information that is both convenient
andefficient.
Database systems are designed to manage large bodies of information. Manage-
ment of data involves both defining structures for storage of information and provid-
ingmechanismsforthemanipulationofinformation.Inaddition,thedatabasesystem
must ensure the safety of the information stored, despite system crashes or attempts
atunauthorizedaccess.Ifdataaretobesharedamongseveralusers,thesystem must
avoidpossibleanomalousresults.
Because information is so important in most organizations, computer scientists
have developed a large body of concepts and techniques for managing data. These
concepts and techniques form the focus of this book. This chapter briefly introduces
theprinciplesofdatabasesystems.
1.1 Database-System Applications
Theearliestdatabasesystemsaroseinthe1960sinresponsetothecomputerizedman-
agement of commercial data. Those earlier applications were relatively simple com-
pared to modern database applications. Modern applications include highly sophisti-
cated,worldwideenterprises.
All database applications, old and new, share important common elements. The
central aspect of the application is not a program performing some calculation, but
ratherthedatathemselves.Today,someofthemostvaluablecorporationsarevaluable
not because of their physical assets, but rather because of the information they own.
Imagine a bank without its data on accounts and customers or a social-network site
that loses the connections among its users. Such companies’ value would be almost
totallylostundersuchcircumstances.
1

--- Page 31 ---

2 Chapter1 Introduction
Databasesystemsareusedtomanagecollectionsofdatathat:
• arehighlyvaluable,
• arerelativelylarge,and
• areaccessedbymultipleusersandapplications,oftenatthesametime.
The first database applications had only simple, precisely formatted, structured
data.Today,databaseapplicationsmayincludedatawithcomplexrelationshipsanda
morevariablestructure.Asanexampleofanapplicationwithstructureddata,consider
auniversity’srecordsregardingcourses,students,andcourseregistration.Theuniver-
sity keeps the same type of information about each course: course-identifier,title, de-
partment,coursenumber,etc.,andsimilarlyforstudents:student-identifier,name,ad-
dress,phone,etc.Courseregistrationisacollectionofpairs:onecourseidentifierand
onestudentidentifier.Informationofthissorthasastandard,repeatingstructureand
is representative of the type of database applications that go back to the 1960s. Con-
trastthissimpleuniversitydatabaseapplicationwithasocial-networkingsite.Usersof
thesitepostvaryingtypesofinformationaboutthemselvesrangingfromsimpleitems
suchasnameordateofbirth,tocomplexpostsconsistingoftext,images,videos,and
linkstootherusers.Thereisonlyalimitedamountofcommonstructureamongthese
data.Bothoftheseapplications,however,sharethebasicfeaturesofadatabase.
Modern database systems exploit commonalities in the structure of data to gain
efficiency but also allow for weakly structured data and for data whose formats are
highlyvariable.Asaresult,adatabasesystemisalarge,complexsoftwaresystemwhose
taskistomanagealarge,complexcollectionofdata.
Managing complexity is challenging, not only in the management of data but in
any domain. Key to the management of complexity is the concept of abstraction. Ab-
stractionallowsapersontouseacomplexdeviceorsystemwithouthavingtoknowthe
details of how that device or system is constructed. A person is able, for example, to
driveacarbyknowinghowtooperateitscontrols.However,thedriverdoesnotneed
toknowhowthemotorwasbuiltnorhowitoperates.Allthedriverneedstoknowisan
abstraction ofwhatthe motordoes. Similarly,for alarge, complexcollectionofdata,
a database system provides a simpler, abstract view of the information so that users
andapplicationprogrammersdonotneedtobeawareoftheunderlyingdetailsofhow
dataarestoredandorganized.Byprovidingahighlevelofabstraction,adatabasesys-
temmakesitpossibleforanenterprisetocombinedataofvarioustypesintoaunified
repositoryoftheinformationneededtoruntheenterprise.
Herearesomerepresentativeapplications:
• EnterpriseInformation
° Sales:Forcustomer,product,andpurchaseinformation.

--- Page 32 ---

1.1 Database-SystemApplications 3
° Accounting: For payments, receipts, account balances, assets, and other ac-
countinginformation.
° Humanresources:Forinformationaboutemployees,salaries,payrolltaxes,and
benefits,andforgenerationofpaychecks.
• Manufacturing:Formanagementofthesupplychainandfortrackingproduction
ofitemsinfactories,inventoriesofitemsinwarehousesandstores,andordersfor
items.
• BankingandFinance
° Banking:Forcustomerinformation,accounts,loans,andbankingtransactions.
° Credit card transactions: For purchases on credit cards and generation of
monthlystatements.
° Finance:Forstoringinformationaboutholdings,sales,andpurchasesoffinan-
cial instruments such as stocks and bonds; also for storing real-time market
datatoenableonlinetradingbycustomersandautomatedtradingbythefirm.
• Universities:Forstudentinformation,courseregistrations,andgrades(inaddition
tostandardenterpriseinformationsuchashumanresourcesandaccounting).
• Airlines:Forreservationsandscheduleinformation.Airlineswereamongthefirst
tousedatabasesinageographicallydistributedmanner.
• Telecommunication:Forkeepingrecordsofcalls,texts,anddatausage,generating
monthlybills,maintainingbalancesonprepaidcallingcards,andstoringinforma-
tionaboutthecommunicationnetworks.
• Web-basedservices
° Social-media:Forkeepingrecordsofusers,connectionsbetweenusers(suchas
friend/followsinformation),postsmadebyusers,rating/likeinformationabout
posts,etc.
° Onlineretailers:Forkeepingrecordsofsalesdataandordersasforanyretailer,
butalsofortrackingauser’sproductviews,searchterms,etc.,forthepurpose
ofidentifyingthebestitemstorecommendtothatuser.
° Online advertisements: Forkeepingrecordsof clickhistorytoenabletargeted
advertisements, product suggestions, news articles, etc. People access such
databases every time they do a web search, make an online purchase, or ac-
cessasocial-networkingsite.
• Document databases: For maintaining collections of new articles, patents, pub-
lishedresearchpapers,etc.
• Navigationsystems:Formaintainingthelocationsofvariesplacesofinterestalong
withtheexactroutesofroads,trainsystems,buses,etc.

--- Page 33 ---

4 Chapter1 Introduction
Asthislistillustrates,databasesformanessentialpartnotonlyofeveryenterprisebut
alsoofalargepartofaperson’sdailyactivities.
The ways in which people interact with databases has changed over time. Early
databases were maintained as back-office systems with which users interacted via
printedreportsandpaperformsforinput.Asdatabasesystemsbecamemoresophisti-
cated,betterlanguagesweredevelopedforprogrammerstouseininteractingwiththe
data, along with user interfaces that allowed end users within the enterprise to query
andupdatedata.
Asthesupportforprogrammerinteractionwithdatabasesimproved,andcomputer
hardwareperformanceincreasedevenashardwarecostsdecreased,moresophisticated
applicationsemergedthatbroughtdatabasedataintomoredirectcontactnotonlywith
end users within an enterprise but also with the general public. Whereas once bank
customershadtointeractwithatellerforeverytransaction,automated-tellermachines
(ATMs)alloweddirectcustomerinteraction.Today,virtuallyeveryenterpriseemploys
webapplicationsormobileapplicationstoallowitscustomerstointeractdirectlywith
theenterprise’sdatabase,and,thus,withtheenterpriseitself.
The user, or customer, can focus on the product or service without being aware
of the details of the large database that makes the interaction possible. For instance,
whenyoureadasocial-mediapost,oraccessanonlinebookstoreandbrowseabookor
musiccollection,youareaccessingdatastoredinadatabase.Whenyouenteranorder
online,yourorderisstoredinadatabase.Whenyouaccessabankwebsiteandretrieve
your bank balance and transaction information,the informationisretrievedfrom the
bank’s database system. When you access a web site, information about you may be
retrievedfromadatabasetoselectwhichadvertisementsyoushouldsee.Almostevery
interaction with a smartphone results in some sort of database access. Furthermore,
dataaboutyourwebaccessesmaybestoredinadatabase.
Thus,althoughuserinterfaceshidedetailsofaccesstoadatabase,andmostpeople
are not even aware they are dealing with a database, accessing databases forms an
essentialpartofalmosteveryone’slifetoday.
Broadlyspeaking,therearetwomodesinwhichdatabasesareused.
• The first mode is to support online transaction processing, where a large number
of users use the database, with each user retrieving relatively small amounts of
data,andperformingsmallupdates. Thisistheprimarymodeofuse forthevast
majorityofusersofdatabaseapplicationssuchasthosethatweoutlinedearlier.
• The second mode is to support data analytics, that is, the processing of data to
drawconclusions,and inferrulesordecisionprocedures,whicharethen used to
drivebusinessdecisions.
Forexample, banks need to decidewhetherto give a loan to aloan applicant,
onlineadvertisersneedtodecidewhichadvertisementtoshowtoaparticularuser.
These tasks are addressed in two steps. First, data-analysis techniquesattempt to
automatically discover rules and patterns from data and create predictive models.
These modelstake as input attributes (“features”) of individuals, and output pre-

--- Page 34 ---

1.2 PurposeofDatabaseSystems 5
dictionssuchaslikelihoodofpayingbackaloan,orclickingonanadvertisement,
whicharethenusedtomakethebusinessdecision.
As another example, manufacturers and retailers need to make decisions on
whatitemstomanufactureororderinwhatquantities;thesedecisionsaredriven
significantlybytechniquesforanalyzingpastdata,andpredictingtrends.Thecost
ofmakingwrongdecisionscanbeveryhigh,andorganizationsarethereforewilling
toinvestalotofmoneytogatherorpurchaserequireddata,andbuildsystemsthat
canusethedatatomakeaccuratepredictions.
Thefieldofdataminingcombinesknowledge-discoverytechniquesinventedby
artificial intelligence researchers and statistical analysts with efficient implemen-
tationtechniquesthatenablethemtobeusedonextremelylargedatabases.
1.2 Purpose of Database Systems
Tounderstandthepurposeofdatabasesystems,considerpartofauniversityorganiza-
tionthat,amongotherdata,keepsinformationaboutallinstructors,students,depart-
ments,andcourseofferings.Onewaytokeeptheinformationonacomputeristostore
it in operating-system files. To allow users to manipulate the information, the system
hasanumberofapplicationprogramsthatmanipulatethefiles,includingprogramsto:
• Addnewstudents,instructors,andcourses.
• Registerstudentsforcoursesandgenerateclassrosters.
• Assigngradestostudents,computegradepointaverages(GPA),andgeneratetran-
scripts.
Programmersdeveloptheseapplicationprogramstomeettheneedsoftheuniversity.
New application programs are added to the system as the need arises. For exam-
ple,supposethatauniversitydecidestocreateanewmajor.Asaresult,theuniversity
creates a new department and creates new permanent files (or adds information to
existing files) to record information about all the instructors in the department, stu-
dents in that major, course offerings, degree requirements, and so on. The university
mayhavetowritenewapplicationprogramstodealwithrulesspecifictothenewma-
jor.Newapplicationprogramsmayalsohavetobewrittentohandlenewrulesinthe
university.Thus,astimegoesby,thesystemacquiresmorefilesandmoreapplication
programs.
Thistypicalfile-processingsystemissupportedbyaconventionaloperatingsystem.
Thesystemstorespermanentrecordsinvariousfiles,anditneedsdifferentapplication
programstoextractrecordsfrom,andaddrecordsto,theappropriatefiles.
Keeping organizational information in a file-processing system has a number of
majordisadvantages:

--- Page 35 ---

6 Chapter1 Introduction
• Data redundancy and inconsistency. Since different programmers create the files
and application programs over a long period, the various files are likely to have
differentstructures,andtheprogramsmaybewritteninseveralprogramminglan-
guages.Moreover,thesameinformationmaybeduplicatedinseveralplaces(files).
For example, if a student has a double major (say, music and mathematics), the
addressandtelephonenumberofthatstudentmayappearinafilethatconsistsof
studentrecordsofstudentsintheMusicdepartmentandinafilethatconsistsof
studentrecordsofstudentsintheMathematicsdepartment.Thisredundancyleads
to higher storage and access cost. In addition, it may lead to data inconsistency;
that is, the various copies of the same data may no longer agree. For example, a
changed student address may be reflected in the Music department records but
notelsewhereinthesystem.
• Difficulty in accessing data. Suppose that one of the university clerks needs to
find out the names of all students who live within a particular postal-code area.
The clerk asks the data-processing department to generate such a list. Because
the designers of the original system did not anticipate this request, there is no
applicationprogramonhandtomeetit.Thereis,however,anapplicationprogram
togeneratethelistofallstudents.Theuniversityclerknowhastwochoices:either
obtainthelistofallstudentsandextracttheneededinformationmanuallyorask
a programmer to write the necessary application program. Both alternatives are
obviouslyunsatisfactory.Supposethatsuchaprogramiswrittenandthat,several
dayslater,thesameclerkneedstotrimthatlisttoincludeonlythosestudentswho
havetakenatleast60credithours.Asexpected,aprogramtogeneratesuchalist
doesnotexist.Again,theclerkhastheprecedingtwooptions,neitherofwhichis
satisfactory.
Thepointhereisthatconventionalfile-processingenvironmentsdonotallow
neededdatatoberetrievedinaconvenientandefficientmanner.Moreresponsive
data-retrievalsystemsarerequiredforgeneraluse.
• Dataisolation. Because dataarescatteredinvariousfiles,and filesmaybe indif-
ferentformats,writingnewapplicationprogramstoretrievetheappropriatedata
isdifficult.
• Integrityproblems.Thedatavaluesstoredinthedatabasemustsatisfycertaintypes
of consistency constraints. Suppose the university maintains an account for each
department, and records the balance amount in eachaccount. Suppose also that
the university requires that the account balance of a department may never fall
below zero. Developers enforce these constraints in the system by adding appro-
priate code in the various application programs. However, when new constraints
are added, it is difficult to change the programs to enforce them. The problem is
compoundedwhenconstraintsinvolveseveraldataitemsfromdifferentfiles.
• Atomicityproblems.Acomputersystem,likeanyotherdevice,issubjecttofailure.
Inmanyapplications,itiscrucialthat,ifafailureoccurs,thedataberestoredtothe

--- Page 36 ---

1.2 PurposeofDatabaseSystems 7
consistentstatethatexistedpriortothefailure.Considerabankingsystemwitha
programtotransfer$500fromaccountAtoaccountB.Ifasystem failureoccurs
during the execution of the program, it is possible that the $500 was removed
from the balance of account A but was not credited to the balance of account
B, resulting in an inconsistent database state. Clearly, it is essential to database
consistencythateitherboththecreditanddebitoccur,orthatneitheroccur.That
is,thefundstransfermustbeatomic—itmusthappeninitsentiretyornotatall.It
isdifficulttoensureatomicityinaconventionalfile-processingsystem.
• Concurrent-access anomalies. For the sake of overall performance of the system
andfasterresponse,manysystemsallowmultipleuserstoupdatethedatasimulta-
neously.Indeed,today,thelargestinternetretailersmayhavemillionsofaccesses
perdaytotheirdatabyshoppers.Insuchanenvironment,interactionofconcur-
rentupdates ispossibleandmayresultininconsistentdata.ConsideraccountA,
with a balance of $10,000. If two bank clerks debit the account balance (by say
$500and$100,respectively)ofaccountAatalmostexactlythesametime,there-
sultoftheconcurrentexecutionsmayleavetheaccountbalanceinanincorrect(or
inconsistent) state. Suppose that the programs executing on behalf of each with-
drawalreadtheoldbalance,reducethatvaluebytheamountbeingwithdrawn,and
write the result back. If the two programs run concurrently, they may both read
the value $10,000, and write back $9500 and $9900, respectively. Depending on
whichonewritesthevaluelast,thebalanceofaccountAmaycontaineither$9500
or$9900,ratherthanthecorrectvalueof$9400.Toguardagainstthispossibility,
the system must maintain some form of supervision. But supervision is difficult
toprovidebecausedatamaybeaccessedbymanydifferentapplicationprograms
thathavenotbeencoordinatedpreviously.
As another example, suppose a registration program maintains a count of
studentsregisteredforacourseinordertoenforcelimitsonthenumberofstudents
registered.Whenastudentregisters,theprogramreadsthecurrentcountforthe
courses,verifiesthatthecountisnotalreadyatthelimit,addsonetothecount,and
storesthecountbackinthedatabase.Supposetwostudentsregisterconcurrently,
withthecountat39.Thetwoprogramexecutionsmaybothreadthevalue39,and
both would then write back 40, leading to an incorrect increase of only 1, even
though two students successfully registered for the course and the count should
be 41. Furthermore, suppose the course registration limit was 40; in the above
case both students would be able toregister, leadingtoa violationof the limitof
40students.
• Securityproblems.Noteveryuserofthedatabasesystemshouldbeabletoaccess
all the data. For example, in a university, payroll personnel need to see only that
part of the database that has financial information. They do not need access to
informationaboutacademicrecords.Butsinceapplicationprogramsareaddedto
thefile-processingsysteminanadhocmanner,enforcingsuchsecurityconstraints
isdifficult.

--- Page 37 ---

8 Chapter1 Introduction
These difficulties, among others, prompted both the initial development of
databasesystemsandthetransitionoffile-basedapplicationstodatabasesystems,back
inthe1960sand1970s.
In what follows, we shall see the concepts and algorithms that enable database
systemstosolvetheproblemswithfile-processingsystems.Inmostofthisbook,weuse
auniversityorganizationasarunningexampleofatypicaldata-processingapplication.
1.3 View of Data
Adatabasesystemisacollectionofinterrelateddataandasetofprogramsthatallow
users to access and modify these data. A major purpose of a database system is to
provideuserswithanabstractviewofthedata.Thatis,thesystemhidescertaindetails
ofhowthedataarestoredandmaintained.
1.3.1 Data Models
Underlyingthestructureofadatabaseisthedatamodel:acollectionofconceptualtools
fordescribingdata,datarelationships,datasemantics,andconsistencyconstraints.
There are a number of different data models that we shall cover in the text. The
datamodelscanbeclassifiedintofourdifferentcategories:
• RelationalModel.Therelationalmodelusesacollectionoftablestorepresentboth
dataandtherelationshipsamongthosedata.Eachtablehasmultiplecolumns,and
eachcolumnhasauniquename.Tablesarealsoknownasrelations.Therelational
modelisanexampleofarecord-basedmodel.Record-basedmodelsaresonamed
because the database is structured in fixed-format records of several types. Each
tablecontainsrecordsofaparticulartype.Eachrecordtypedefinesafixednumber
offields,orattributes.Thecolumnsofthetablecorrespondtotheattributesofthe
record type. The relational data model is the most widely used data model, and
a vast majority of current database systems are based on the relational model.
Chapter2andChapter7covertherelationalmodelindetail.
• Entity-RelationshipModel.Theentity-relationship(E-R)datamodelusesacollec-
tionofbasicobjects,calledentities,andrelationshipsamongtheseobjects.Anen-
tity is a “thing” or “object” in the real world that is distinguishable from other
objects.Theentity-relationshipmodeliswidelyusedindatabasedesign.Chapter
6exploresitindetail.
• Semi-structured Data Model. The semi-structured data model permits the specifi-
cation of data where individual data items of the same type may have different
setsofattributes. Thisisincontrasttothedatamodelsmentionedearlier,where
everydataitemofaparticulartypemusthavethesamesetofattributes.JSON and
ExtensibleMarkupLanguage(XML)arewidelyusedsemi-structureddatarepresen-
tations.Semi-structureddatamodelsareexploredindetailinChapter8.

--- Page 38 ---

1.3 ViewofData 9
• Object-BasedDataModel.Object-orientedprogramming(especiallyinJava,C++,
or C#) has become the dominant software-development methodology. This led
initiallytothedevelopmentofadistinctobject-orienteddatamodel,buttodaythe
concept of objects is well integrated into relational databases. Standards exist to
storeobjectsinrelationaltables.Databasesystems allowprocedurestobestored
inthedatabase system andexecuted bythedatabase system. Thiscanbe seenas
extendingtherelationalmodelwithnotionsofencapsulation,methods,andobject
identity.Object-baseddatamodelsaresummarizedinChapter8.
Alargeportionofthistextisfocusedontherelationalmodelbecauseitservesas
thefoundationformostdatabaseapplications.
1.3.2 Relational Data Model
Intherelationalmodel,dataarerepresentedintheformoftables.Eachtablehasmul-
tiplecolumns,andeachcolumnhasaunique name.Eachrowofthetable represents
onepieceofinformation.Figure1.1presentsasamplerelationaldatabasecomprising
two tables: one shows details of university instructors and the other shows details of
thevariousuniversitydepartments.
The first table, the instructor table, shows, for example, that an instructor named
Einstein with ID 22222 is a member of the Physics department and has an annual
salaryof$95,000.Thesecondtable,department,shows,forexample,thattheBiology
departmentislocatedintheWatsonbuildingandhasabudgetof$90,000.Ofcourse,
a real-world university would have many more departments and instructors. We use
smalltablesinthetexttoillustrateconcepts.Alargerexampleforthesameschemais
availableonline.
1.3.3 Data Abstraction
Forthesystemtobeusable,itmustretrievedataefficiently.Theneedforefficiencyhas
leddatabasesystemdeveloperstousecomplexdatastructurestorepresentdatainthe
database.Sincemanydatabase-systemusersarenotcomputertrained,developershide
thecomplexityfromusersthroughseverallevelsofdataabstraction,tosimplifyusers’
interactionswiththesystem:
• Physical level. The lowest level of abstraction describes how the data are actually
stored.Thephysicalleveldescribescomplexlow-leveldatastructuresindetail.
• Logical level. The next-higher level of abstraction describes what data are stored
in the database, and what relationships exist among those data. The logical level
thusdescribestheentiredatabaseintermsofasmallnumberofrelativelysimple
structures. Although implementation of the simple structures at the logical level
mayinvolvecomplexphysical-levelstructures,theuserofthelogicalleveldoesnot
need to be aware of this complexity. This is referred to as physical data indepen-

--- Page 39 ---

10 Chapter1 Introduction
ID name dept name salary
22222 Einstein Physics 95000
12121 Wu Finance 90000
32343 ElSaid History 60000
45565 Katz Comp.Sci. 75000
98345 Kim Elec.Eng. 80000
76766 Crick Biology 72000
10101 Srinivasan Comp.Sci. 65000
58583 Califieri History 62000
83821 Brandt Comp.Sci. 92000
15151 Mozart Music 40000
33456 Gold Physics 87000
76543 Singh Finance 80000
(a)Theinstructor table
dept name building budget
Comp.Sci. Taylor 100000
Biology Watson 90000
Elec.Eng. Taylor 85000
Music Packard 80000
Finance Painter 120000
History Painter 50000
Physics Watson 70000
(b)Thedepartmenttable
Figure 1.1 Asamplerelationaldatabase.
dence.Databaseadministrators,whomustdecidewhatinformationtokeepinthe
database,usethelogicallevelofabstraction.
• View level. The highest level of abstraction describes only part of the entire
database.Eventhoughthelogicallevelusessimplerstructures,complexityremains
becauseofthevarietyofinformationstoredinalargedatabase.Manyusersofthe
databasesystemdonotneedallthisinformation;instead,theyneedtoaccessonly
apartofthedatabase.Theviewlevelofabstractionexiststosimplifytheirinterac-
tionwiththesystem.Thesystemmayprovidemanyviewsforthesamedatabase.
Figure1.2showstherelationshipamongthethreelevelsofabstraction.
An important feature of data models, such as the relational model, is that they
hidesuchlow-levelimplementationdetailsfromnotjustdatabaseusers,butevenfrom

--- Page 40 ---

1.3 ViewofData 11
view level
…
view 1 view 2 view n
logical
level
physical
level
Figure 1.2 Thethreelevelsofdataabstraction.
database-application developers. The database system allows application developers
to store and retrieve data using the abstractions of the data model, and converts the
abstractoperationsintooperationsonthelow-levelimplementation.
An analogy to the concept of data types in programming languages may clarify
the distinction among levels of abstraction. Many high-level programming languages
supportthenotionofastructuredtype.Wemaydescribethetypeofarecordabstractly
asfollows:1
typeinstructor =record
ID:char(5);
name:char(20);
dept name:char(20);
salary:numeric(8,2);
end;
Thiscodedefinesanewrecordtypecalledinstructor withfourfields.Eachfieldhasa
name and a type associated with it. For example, char(20) specifies a string with 20
characters, while numeric(8,2) specifies a number with 8 digits, two of which are to
therightofthedecimalpoint.Auniversityorganizationmayhaveseveralsuchrecord
types,including:
• department,withfieldsdept name,building,andbudget.
• course,withfieldscourse id,title,dept name,andcredits.
• student,withfieldsID,name,dept name,andtot cred.
1Theactualtypedeclarationdependsonthelanguagebeingused.CandC++usestructdeclarations.Javadoesnot
havesuchadeclaration,butasimpleclasscanbedefinedtothesameeffect.

--- Page 41 ---

12 Chapter1 Introduction
Atthephysicallevel,aninstructor,department,orstudentrecordcanbedescribed
as a block of consecutive bytes. The compiler hides thislevel of detailfrom program-
mers.Similarly,thedatabasesystemhidesmanyofthelowest-levelstoragedetailsfrom
database programmers.Databaseadministrators,ontheotherhand,maybeawareof
certain details of the physical organization of the data. For example, there are many
possiblewaystostoretablesinfiles.Onewayistostoreatableasasequenceofrecords
in a file, with a special character (such as a comma) used to delimit the different at-
tributesofarecord,andanotherspecialcharacter(suchasanew-linecharacter)may
be used to delimitrecords. If all attributes have fixed length, the lengths of attributes
maybestoredseparately,anddelimitersmaybeomittedfromthefile.Variablelength
attributescouldbehandledbystoringthelength,followedbythedata.Databasesuse
a type of data structure called an index to support efficient retrieval of records; these
tooformpartofthephysicallevel.
At the logical level, each such record is described by a type definition, as in the
previous code segment. The interrelationship of these record types is also defined at
the logical level; a requirement that the dept name value of an instructor record must
appearinthedepartmenttableisanexampleofsuchaninterrelationship.Programmers
using a programming language work at this level of abstraction. Similarly, database
administratorsusuallyworkatthislevelofabstraction.
Finally,attheviewlevel,computerusersseeasetofapplicationprogramsthathide
detailsofthedatatypes.Attheviewlevel,severalviewsofthedatabasearedefined,and
adatabaseuserseessomeoralloftheseviews.Inadditiontohidingdetailsofthelogical
levelofthedatabase,theviewsalsoprovideasecuritymechanismtopreventusersfrom
accessingcertainpartsofthedatabase.Forexample, clerksintheuniversityregistrar
officecanseeonlythatpartofthedatabasethathasinformationaboutstudents;they
cannotaccessinformationaboutsalariesofinstructors.
1.3.4 Instances and Schemas
Databases change over time as information is inserted and deleted. The collection of
informationstoredinthedatabaseataparticularmomentiscalledaninstanceofthe
database. The overall design of the database is called the database schema. The con-
cept of database schemas and instances can be understood by analogy to a program
written in a programming language. A database schema corresponds to the variable
declarations (along with associated type definitions) in a program. Each variable has
aparticularvalueatagiveninstant.Thevaluesofthevariablesinaprogramatapoint
intimecorrespondtoaninstanceofadatabaseschema.
Database systems haveseveralschemas,partitionedaccordingtothelevelsofab-
straction.Thephysicalschemadescribesthedatabasedesignatthephysicallevel,while
the logical schema describes the database design at the logical level. A database may
alsohaveseveralschemasattheviewlevel,sometimescalledsubschemas,thatdescribe
differentviewsofthedatabase.
Ofthese,thelogicalschemaisbyfarthemostimportant intermsof itseffecton
application programs, since programmers construct applications by using the logical

--- Page 42 ---

1.4 DatabaseLanguages 13
schema.Thephysicalschemaishiddenbeneaththelogicalschemaandcanusuallybe
changedeasilywithoutaffectingapplicationprograms.Applicationprogramsaresaid
to exhibit physical data independence if they do not depend on the physical schema
andthusneednotberewrittenifthephysicalschemachanges.
We also note that it is possible to create schemas that have problems, such as
unnecessarilyduplicatedinformation.Forexample, suppose westore thedepartment
budgetasanattributeoftheinstructor record.Then,wheneverthevalueofthebudget
foradepartment(saythePhysicsdepartment)changes,thatchangemustbereflected
intherecordsofallinstructorsassociatedwiththedepartment.InChapter7,weshall
studyhowtodistinguishgoodschemadesignsfrombadschemadesigns.
Traditionally, logical schemas were changed infrequently, if at all. Many newer
database applications, however, require more flexible logical schemas where, for ex-
ample,differentrecordsinasinglerelationmayhavedifferentattributes.
1.4 Database Languages
A database system provides a data-definition language (DDL) to specify the database
schema and a data-manipulation language (DML) to express database queries and up-
dates.Inpractice,thedata-definitionanddata-manipulationlanguagesarenottwosep-
arate languages;insteadtheysimplyformpartsofasingledatabase language,suchas
the SQL language. Almost all relational database systems employ the SQL language,
whichwecoveringreatdetailinChapter3,Chapter4,andChapter5.
1.4.1 Data-Definition Language
We specify a database schema by a set of definitions expressed by a special language
called a data-definition language (DDL). The DDL is also used to specify additional
propertiesofthedata.
Wespecifythestoragestructureandaccessmethodsusedbythedatabasesystem
by a set of statements in a special type of DDL called a data storage and definition
language.Thesestatementsdefinetheimplementationdetailsofthedatabaseschemas,
whichareusuallyhiddenfromtheusers.
Thedatavaluesstoredinthedatabasemustsatisfycertainconsistencyconstraints.
Forexample,supposetheuniversityrequiresthattheaccountbalanceofadepartment
must never be negative. The DDL provides facilities to specify such constraints. The
databasesystemcheckstheseconstraintseverytimethedatabaseisupdated.Ingeneral,
aconstraintcanbeanarbitrarypredicatepertainingtothedatabase.However,arbitrary
predicatesmaybecostlytotest.Thus,databasesystemsimplementonlythoseintegrity
constraintsthatcanbetestedwithminimaloverhead:
• Domain Constraints. A domain of possible values must be associated with every
attribute(forexample,integertypes,charactertypes,date/timetypes).Declaring
anattribute tobeofaparticulardomainactsasaconstraintonthevaluesthatit

--- Page 43 ---

14 Chapter1 Introduction
cantake.Domainconstraintsarethemostelementaryformofintegrityconstraint.
Theyaretestedeasilybythesystemwheneveranewdataitemisenteredintothe
database.
• Referential Integrity. There are cases where we wish to ensure that a value that
appears in one relation for a given set of attributes also appears in a certain set
of attributes in another relation (referential integrity). For example, the depart-
mentlistedforeachcoursemustbeonethatactuallyexistsintheuniversity.More
precisely, the dept name value in a course record must appear in the deptname
attribute of some record of the department relation. Database modifications can
cause violations of referential integrity. When a referential-integrity constraint is
violated,thenormalprocedureistorejecttheactionthatcausedtheviolation.
• Authorization.Wemaywanttodifferentiateamongtheusersasfarasthetypeof
accesstheyarepermittedonvariousdatavaluesinthedatabase.Thesedifferentia-
tionsareexpressedintermsofauthorization,themostcommonbeing:readautho-
rization,whichallowsreading,butnotmodification,ofdata;insertauthorization,
which allows insertion of new data, but not modification of existing data; update
authorization,whichallowsmodification,butnotdeletion,ofdata;anddeleteau-
thorization, whichallows deletionof data. We may assign the user all,none, or a
combinationofthesetypesofauthorization.
TheprocessingofDDLstatements, just likethoseofanyotherprogramminglan-
guage,generatessomeoutput.TheoutputoftheDDLisplacedinthedatadictionary,
which contains metadata—that is, data about data. The data dictionary is considered
tobeaspecialtypeoftablethatcanbeaccessedandupdatedonlybythedatabasesys-
temitself(notaregularuser).Thedatabasesystemconsultsthedatadictionarybefore
readingormodifyingactualdata.
1.4.2 The SQL Data-Definition Language
SQLprovidesarichDDLthatallowsonetodefinetableswithdatatypesandintegrity
constraints.
Forinstance,thefollowingSQLDDLstatementdefinesthedepartmenttable:
createtabledepartment
(dept name char(20),
building char(15),
budget numeric(12,2));
Execution of the preceding DDL statement creates the department table with three
columns:dept name,building,andbudget,eachofwhichhasaspecificdatatypeasso-
ciatedwithit.WediscussdatatypesinmoredetailinChapter3.
TheSQLDDLalsosupportsanumberoftypesofintegrityconstraints.Forexam-
ple,onecanspecifythatthedept nameattributevalueisaprimarykey,ensuringthatno

--- Page 44 ---

1.4 DatabaseLanguages 15
two departments can have the same department name. As another example, one can
specifythatthedept nameattributevalueappearinginanyinstructor recordmustalso
appear in thedept nameattribute of some record of the department table. We discuss
SQLsupportforintegrityconstraintsandauthorizationsinChapter3andChapter4.
1.4.3 Data-Manipulation Language
Adata-manipulationlanguage(DML)isalanguagethatenablesuserstoaccessorma-
nipulatedataasorganizedbytheappropriatedatamodel.Thetypesofaccessare:
• Retrievalofinformationstoredinthedatabase.
• Insertionofnewinformationintothedatabase.
• Deletionofinformationfromthedatabase.
• Modificationofinformationstoredinthedatabase.
Therearebasicallytwotypesofdata-manipulationlanguage:
• Procedural DMLs require a user to specify what data are needed and how to get
thosedata.
• DeclarativeDMLs(alsoreferredtoasnonproceduralDMLs)requireausertospec-
ifywhatdataareneededwithoutspecifyinghowtogetthosedata.
Declarative DMLs are usually easier to learn and use than are procedural DMLs.
However,sinceauserdoesnothavetospecifyhowtogetthedata,thedatabasesystem
hastofigureoutanefficientmeansofaccessingdata.
A query is a statement requesting the retrieval of information. The portion of a
DMLthatinvolvesinformationretrievaliscalledaquerylanguage.Althoughtechnically
incorrect,itiscommonpracticetousethetermsquerylanguageanddata-manipulation
languagesynonymously.
There are a number of database query languages in use, either commercially or
experimentally. We study the most widely used query language, SQL, in Chapter 3
throughChapter5.
ThelevelsofabstractionthatwediscussedinSection1.3applynotonlytodefining
orstructuringdata,butalsotomanipulatingdata.Atthephysicallevel,wemustdefine
algorithms that allow efficient access to data. At higher levels of abstraction, we em-
phasizeeaseofuse.Thegoalistoallowhumanstointeractefficientlywiththesystem.
The query processor component of the database system (which we study in Chapter
15 and Chapter 16) translates DML queries into sequences of actions at the physical
levelofthedatabase system. InChapter22,westudytheprocessingofqueriesinthe
increasinglycommonparallelanddistributedsettings.

--- Page 45 ---

16 Chapter1 Introduction
1.4.4 The SQL Data-Manipulation Language
TheSQLquerylanguageisnonprocedural.Aquerytakesasinputseveraltables(pos-
siblyonlyone)andalwaysreturnsasingletable.HereisanexampleofanSQLquery
thatfindsthenamesofallinstructorsintheHistorydepartment:
selectinstructor.name
frominstructor
whereinstructor.dept name='History';
The query specifies that those rows from the table instructor where the dept name is
Historymustberetrieved,andthenameattributeoftheserowsmustbedisplayed.The
resultofexecutingthisqueryisatablewithasinglecolumnlabelednameandasetof
rows,eachofwhichcontainsthenameofaninstructorwhosedept nameisHistory.If
thequeryisrunonthetableinFigure1.1,theresultconsistsoftworows,onewiththe
nameElSaidandtheotherwiththenameCalifieri.
Queriesmayinvolveinformationfrommorethanonetable.Forinstance,thefol-
lowingqueryfindstheinstructorIDanddepartmentnameofallinstructorsassociated
withadepartmentwithabudgetofmorethan$95,000.
selectinstructor.ID,department.dept name
frominstructor,department
whereinstructor.deptname=department.dept nameand
department.budget>95000;
IftheprecedingquerywererunonthetablesinFigure1.1,thesystemwouldfindthat
therearetwodepartmentswithabudgetofgreaterthan$95,000—Computer Science
andFinance;therearefiveinstructorsinthesedepartments.Thus,theresultconsistsof
atablewithtwocolumns(ID,dept name)andfiverows:(12121,Finance),(45565,Com-
puterScience),(10101, ComputerScience),(83821, ComputerScience),and(76543,
Finance).
1.4.5 Database Access from Application Programs
Non-proceduralquerylanguagessuchasSQLarenotaspowerfulasauniversalTuring
machine;thatis,therearesomecomputationsthatarepossibleusingageneral-purpose
programminglanguagebutarenotpossibleusingSQL.SQLalsodoesnotsupportac-
tionssuchasinputfromusers,outputtodisplays,orcommunicationoverthenetwork.
Such computations and actions must be written in a host language, such as C/C++,
Java, or Python, with embedded SQL queries that access the data in the database.
Application programs are programs that are used to interact with the database in this
fashion. Examples in a university system are programs that allow students to register
forcourses,generateclassrosters,calculatestudentGPA,generatepayrollchecks,and
performothertasks.

--- Page 46 ---

1.5 DatabaseDesign 17
To access the database, DML statements need to be sent from the host to the
database where they will be executed. This is most commonly done by using an
application-program interface (set of procedures) that can be used to send DML and
DDL statements to the database and retrieve the results. The Open Database Con-
nectivity(ODBC)standard definesapplicationprogram interfacesforuse withCand
several other languages. The Java Database Connectivity (JDBC) standard defines a
correspondinginterfacefortheJavalanguage.
1.5 Database Design
Database systems are designed to manage large bodies of information. These large
bodiesofinformationdonotexistinisolation.Theyarepartoftheoperationofsome
enterprisewhoseendproductmaybeinformationfromthedatabaseormaybesome
deviceorserviceforwhichthedatabaseplaysonlyasupportingrole.
Databasedesignmainlyinvolvesthedesignofthedatabaseschema.Thedesignof
a complete database application environment that meets the needs of the enterprise
beingmodeledrequiresattentiontoabroadersetofissues.Inthistext,wefocusonthe
writingofdatabasequeriesandthedesignofdatabaseschemas,butdiscussapplication
designlater,inChapter9.
A high-level data model provides the database designer with a conceptual frame-
work in which to specify the data requirements of the database users and how the
database willbe structured to fulfillthese requirements.Theinitialphase of database
design,then, istocharacterize fullythe dataneedsof the prospective database users.
The database designerneedstointeractextensively withdomainexperts and users to
carryoutthistask.Theoutcomeofthisphaseisaspecificationofuserrequirements.
Next,thedesignerchoosesadatamodel,andbyapplyingtheconceptsofthecho-
sendatamodel,translatestheserequirementsintoaconceptualschemaofthedatabase.
Theschemadevelopedatthisconceptual-designphaseprovidesadetailedoverviewof
theenterprise.Thedesignerreviewstheschematoconfirmthatalldatarequirements
are indeed satisfied and are not in conflict with one another. The designer can also
examine the design to remove any redundant features. The focus at this point is on
describingthedataandtheirrelationships,ratherthanonspecifyingphysicalstorage
details.
Intermsoftherelationalmodel,theconceptual-designprocessinvolvesdecisions
onwhatattributeswewanttocaptureinthedatabaseandhowtogrouptheseattributes
to form the various tables. The “what” part is basically a business decision, and we
shall not discuss it further in this text. The “how” part is mainly a computer-science
problem.Thereareprincipallytwoways totackletheproblem.Thefirstoneistouse
the entity-relationship model (Chapter 6); the other is to employ a set of algorithms
(collectively known as normalization that takes as input the set of all attributes and
generatesasetoftables(Chapter7).
Afullydevelopedconceptualschemaindicatesthefunctionalrequirementsofthe
enterprise.Inaspecificationoffunctionalrequirements,usersdescribethekindsofoper-

--- Page 47 ---

18 Chapter1 Introduction
ations(ortransactions)thatwillbeperformedonthedata.Exampleoperationsinclude
modifying or updating data, searching for and retrieving specific data, and deleting
data.Atthisstageofconceptualdesign,thedesignercanreviewtheschematoensure
itmeetsfunctionalrequirements.
The process of moving from an abstract data model to the implementation of
the database proceeds in two final design phases. In the logical-design phase, the de-
signermapsthehigh-levelconceptualschemaontotheimplementationdatamodelof
the database system that will be used. The designer uses the resulting system-specific
databaseschemainthesubsequentphysical-designphase,inwhichthephysicalfeatures
ofthedatabasearespecified.Thesefeaturesincludetheformoffileorganizationand
theinternalstoragestructures;theyarediscussedinChapter13.
1.6 Database Engine
Adatabasesystemispartitionedintomodulesthatdealwitheachoftheresponsibilities
oftheoverallsystem.Thefunctionalcomponentsofadatabasesystemcanbebroadly
dividedintothestoragemanager,thequeryprocessorcomponents,andthetransaction
managementcomponent.
The storage manager is important because databases typically require a large
amountofstoragespace.Corporatedatabasescommonlyrangeinsizefromhundreds
of gigabytes to terabytes of data. A gigabyte is approximately 1 billion bytes, or 1000
megabytes (more precisely, 1024 megabytes), while a terabyte is approximately 1 tril-
lion bytes or 1 million megabytes (more precisely, 1024 gigabytes). The largest enter-
prises have databases that reachintothe multi-petabyte range (a petabyte is 1024 ter-
abytes).Sincethemainmemoryofcomputerscannotstorethismuchinformation,and
sincethecontentsofmainmemoryarelostinasystemcrash,theinformationisstored
ondisks.Dataaremovedbetweendiskstorageandmainmemoryasneeded.Sincethe
movementofdatatoandfromdiskisslowrelativetothespeedofthecentralprocess-
ingunit,itisimperativethatthedatabasesystemstructurethedatasoastominimize
the need to move data between diskand main memory. Increasingly,solid-state disks
(SSDs) are being used for database storage. SSDs are faster than traditional disks but
alsomorecostly.
Thequeryprocessorisimportantbecauseithelpsthedatabasesystemtosimplify
andfacilitateaccesstodata.Thequeryprocessorallowsdatabaseuserstoobtaingood
performance while being able to work at the view level and not be burdened with un-
derstandingthephysical-leveldetailsoftheimplementationofthesystem.Itisthejob
of the database system to translate updates and queries written in a nonprocedural
language, at the logical level, into an efficient sequence of operations at the physical
level.
Thetransactionmanagerisimportantbecauseitallowsapplicationdevelopersto
treatasequenceofdatabaseaccessesasiftheywereasingleunitthateitherhappensin
itsentiretyornotatall.Thispermitsapplicationdeveloperstothinkatahigherlevelof

--- Page 48 ---

1.6 DatabaseEngine 19
abstractionabouttheapplicationwithoutneedingtobeconcernedwiththelower-level
detailsofmanagingtheeffectsofconcurrentaccesstothedataandofsystemfailures.
While database engines were traditionally centralized computer systems, today
parallel processing is key for handling very large amounts of data efficiently. Modern
databaseenginespayalotofattentiontoparalleldatastorage andparallelquerypro-
cessing.
1.6.1 Storage Manager
Thestoragemanageristhecomponentofadatabasesystemthatprovidestheinterface
between the low-level data stored in the database and the application programs and
queriessubmittedtothesystem.Thestoragemanagerisresponsiblefortheinteraction
withthefilemanager.Therawdataarestoredonthediskusingthefilesystemprovided
by the operating system. The storage manager translates the various DML statements
intolow-levelfile-systemcommands.Thus,thestoragemanagerisresponsibleforstor-
ing,retrieving,andupdatingdatainthedatabase.
Thestoragemanagercomponentsinclude:
• Authorization and integrity manager, which tests for the satisfaction of integrity
constraintsandcheckstheauthorityofuserstoaccessdata.
• Transactionmanager,whichensuresthatthedatabaseremainsinaconsistent(cor-
rect)statedespitesystemfailures,andthatconcurrenttransactionexecutionspro-
ceedwithoutconflicts.
• Filemanager,whichmanagestheallocationofspaceondiskstorageandthedata
structuresusedtorepresentinformationstoredondisk.
• Buffermanager,whichisresponsibleforfetchingdatafromdiskstorageintomain
memory,anddecidingwhatdatatocacheinmainmemory.Thebuffermanageris
acriticalpartofthedatabasesystem,sinceitenablesthedatabasetohandledata
sizesthataremuchlargerthanthesizeofmainmemory.
The storage manager implements several data structures as part of the physical
systemimplementation:
• Datafiles,whichstorethedatabaseitself.
• Data dictionary, which stores metadata about the structure of the database, in
particulartheschemaofthedatabase.
• Indices,whichcanprovidefastaccesstodataitems.Liketheindexinthistextbook,
adatabaseindexprovidespointerstothosedataitemsthatholdaparticularvalue.
Forexample,wecoulduseanindextofindtheinstructor recordwithaparticular
ID,orallinstructor recordswithaparticularname.

--- Page 49 ---

20 Chapter1 Introduction
We discuss storage media, file structures, and buffer management in Chapter 12 and
Chapter13.MethodsofaccessingdataefficientlyarediscussedinChapter14.
1.6.2 The Query Processor
Thequeryprocessorcomponentsinclude:
• DDL interpreter, which interprets DDL statements and records the definitions in
thedatadictionary.
• DMLcompiler,whichtranslatesDMLstatementsinaquerylanguageintoaneval-
uation plan consisting of low-level instructions that the query-evaluation engine
understands.
A query can usually be translated into any of a number of alternative evalua-
tion plans that all give the same result. The DML compiler also performs query
optimization;thatis,itpicksthelowestcostevaluationplanfromamongthealter-
natives.
• Query evaluation engine, which executes low-level instructions generated by the
DMLcompiler.
QueryevaluationiscoveredinChapter15,whilethemethodsbywhichthequeryopti-
mizerchoosesfromamongthepossibleevaluationstrategiesarediscussedinChapter
16.
1.6.3 Transaction Management
Often,severaloperationsonthedatabaseformasinglelogicalunitofwork.Anexam-
pleisafundstransfer,asinSection1.2,inwhichoneaccountAisdebitedandanother
accountBiscredited.Clearly,itisessentialthateitherboththecreditanddebitoccur,
or that neither occur. That is, the funds transfer must happen in its entirety or not at
all.Thisall-or-nonerequirementiscalledatomicity.Inaddition,itisessentialthatthe
executionofthe fundstransfer preserves theconsistencyofthedatabase. Thatis,the
valueofthesumofthebalancesofAandBmustbepreserved.Thiscorrectnessrequire-
ment is called consistency. Finally, after the successful execution of a funds transfer,
thenewvaluesofthebalancesofaccountsAandBmustpersist,despitethepossibility
ofsystemfailure.Thispersistencerequirementiscalleddurability.
A transaction is a collectionof operations thatperforms a single logical function
inadatabaseapplication.Eachtransactionisaunitofbothatomicityandconsistency.
Thus,werequirethattransactionsdonotviolateanydatabase-consistencyconstraints.
That is, if the database was consistent when a transaction started, the database must
be consistent when the transaction successfully terminates. However, during the exe-
cution of a transaction, it may be necessary temporarily to allow inconsistency, since

--- Page 50 ---

1.7 DatabaseandApplicationArchitecture 21
eitherthedebitofAorthecreditofB mustbedonebeforetheother.Thistemporary
inconsistency,althoughnecessary,mayleadtodifficultyifafailureoccurs.
Itistheprogrammer’sresponsibilitytoproperlydefinethevarioustransactionsso
that each preserves the consistency of the database. For example, the transaction to
transfer funds from account A to account B could be defined to be composed of two
separateprograms:onethatdebitsaccountAandanotherthatcreditsaccountB.The
executionofthesetwoprogramsoneaftertheotherwillindeedpreserveconsistency.
However, each program by itself does not transform the database from a consistent
statetoanewconsistentstate.Thus,thoseprogramsarenottransactions.
Ensuring the atomicity and durability properties is the responsibility of the
databasesystemitself—specifically,oftherecoverymanager.Intheabsenceoffailures,
all transactions complete successfully, and atomicity is achieved easily. However, be-
cause of various types of failure,a transaction may not always complete its execution
successfully.Ifwearetoensuretheatomicityproperty,afailedtransactionmusthave
noeffectonthestateofthedatabase.Thus,thedatabasemustberestoredtothestate
inwhichitwasbeforethetransactioninquestionstartedexecuting.Thedatabasesys-
temmustthereforeperformfailurerecovery,thatis,itmustdetectsystemfailuresand
restorethedatabasetothestatethatexistedpriortotheoccurrenceofthefailure.
Finally, when several transactions update the database concurrently, the consis-
tency of data may no longer be preserved, even though each individualtransaction is
correct.Itistheresponsibilityoftheconcurrency-controlmanagertocontroltheinter-
action among the concurrenttransactions, to ensure the consistency of the database.
Thetransactionmanagerconsistsoftheconcurrency-controlmanagerandtherecovery
manager.
ThebasicconceptsoftransactionprocessingarecoveredinChapter17.Theman-
agementofconcurrenttransactionsiscoveredinChapter18.Chapter19coversfailure
recoveryindetail.
The concept of a transaction has been applied broadly in database systems and
applications. While the initial use of transactions was in financial applications, the
concept is now used in real-time applications in telecommunication, as well as in the
managementoflong-durationactivitiessuchasproductdesignoradministrativework-
flows.
1.7 Database and Application Architecture
We are now in a position to provide a single picture of the various components of a
database system and the connections among them. Figure 1.3 shows the architecture
ofadatabasesystemthatrunsonacentralizedservermachine.Thefiguresummarizes
howdifferenttypesofusersinteractwithadatabase,andhowthedifferentcomponents
ofadatabaseengineareconnectedtoeachother.
The centralized architecture shown in Figure 1.3 is applicable to shared-memory
serverarchitectures,whichhavemultipleCPUsandexploitparallelprocessing,butall

--- Page 51 ---

22 Chapter1 Introduction
naive users sophisticated
application database
(tellers, agents, users
programmers administrators
web users) (analysts)
use write use use
application application query administration
interfaces programs tools tools
compiler and
DML queries DDL interpreter
linker
application
program DML compiler
object code and organizer
query evaluation
engine
query processor
buffer manager file manager authorization transaction
and integrity manager
manager
storage manager
disk storage
indices data dictionary
data statistical data
Figure 1.3 Systemstructure.
the CPUs access a common shared memory. To scale up to even larger data volumes
andevenhigherprocessingspeeds,paralleldatabasesaredesignedtorunonacluster
consistingofmultiplemachines.Further,distributeddatabasesallowdatastorage and
queryprocessingacrossmultiplegeographicallyseparatedmachines.

--- Page 52 ---

1.7 DatabaseandApplicationArchitecture 23
InChapter20,wecoverthegeneralstructureofmoderncomputersystems,witha
focusonparallelsystemarchitectures.Chapter21andChapter22describehowquery
processingcanbeimplementedtoexploitparallelanddistributedprocessing.Chapter
23 presents a number of issues that arise in processing transactions in a parallel or a
distributeddatabaseanddescribeshowtodealwitheachissue.Theissuesincludehow
tostoredata,howtoensureatomicityoftransactionsthatexecuteatmultiplesites,how
to perform concurrency control, and how to provide high availabilityin the presence
offailures.
Wenowconsiderthearchitectureofapplicationsthatusedatabasesastheirback-
end. Database applications can be partitioned into two or three parts, as shown in
Figure1.4.Earlier-generationdatabaseapplicationsusedatwo-tierarchitecture,where
theapplicationresidesattheclientmachine,andinvokesdatabasesystemfunctionality
attheservermachinethroughquerylanguagestatements.
In contrast, modern database applications use a three-tier architecture,where the
clientmachineactsasmerelyafrontendanddoesnotcontainanydirectdatabasecalls;
webbrowsersandmobileapplicationsarethemostcommonlyusedapplicationclients
today.Thefrontendcommunicateswithanapplicationserver.Theapplicationserver,
inturn,communicateswithadatabasesystemtoaccessdata.Thebusinesslogicofthe
application,whichsayswhatactionstocarryoutunderwhatconditions,isembedded
in the application server, instead of being distributed across multiple clients. Three-
tier applications provide better security as well as better performance than two-tier
applications.
user user
client
application application client
network network
application server
database system
server
database system
(a) Two-tier architecture (b) Three-tier architecture
Figure 1.4 Two-tierandthree-tierarchitectures.

--- Page 53 ---

24 Chapter1 Introduction
1.8 Database Users and Administrators
A primary goal of a database system is to retrieve information from and store new
information in the database. People who work with a database can be categorized as
databaseusersordatabaseadministrators.
1.8.1 Database Users and User Interfaces
Therearefourdifferenttypes ofdatabase-system users,differentiatedbythe waythey
expecttointeractwiththesystem.Differenttypesofuserinterfaceshavebeendesigned
forthedifferenttypesofusers.
• Na¨ıveusersareunsophisticateduserswhointeractwiththesystembyusingprede-
fineduserinterfaces,suchaswebormobileapplications.Thetypicaluserinterface
forna¨ıveusersisaformsinterface,wheretheusercanfillinappropriatefieldsof
theform.Na¨ıveusersmayalsoviewreadreportsgeneratedfromthedatabase.
Asanexample,considerastudent,whoduringclassregistrationperiod,wishes
to register for a class by using a web interface. Such a user connects to a web
application program that runs at a web server. The application first verifies the
identity of the user and then allows her to access a form where she enters the
desired information. The form information is sent back to the web application
at the server, which then determines if there is room in the class (by retrieving
informationfromthedatabase)andifsoaddsthestudentinformationtotheclass
rosterinthedatabase.
• Application programmers are computer professionals who write application pro-
grams.Applicationprogrammerscanchoosefrommanytoolstodevelopuserin-
terfaces.
• Sophisticated users interact with the system without writing programs. Instead,
they form theirrequests eitherusing a database query language or by using tools
suchasdataanalysissoftware.Analystswhosubmitqueriestoexploredatainthe
databasefallinthiscategory.
1.8.2 Database Administrator
One of the main reasons for using DBMSs is to have central control of both the data
andtheprogramsthataccessthosedata.Apersonwhohassuchcentralcontrolover
thesystemiscalledadatabaseadministrator(DBA).ThefunctionsofaDBAinclude:
• Schema definition. The DBA creates the original database schema by executing a
setofdatadefinitionstatementsintheDDL.
• Storagestructureandaccess-methoddefinition.TheDBAmayspecifysomeparam-
eterspertainingtothephysicalorganizationofthedataandtheindicestobecre-
ated.

--- Page 54 ---

1.9 HistoryofDatabaseSystems 25
• Schemaandphysical-organizationmodification.TheDBAcarriesoutchangestothe
schema and physical organization to reflect the changing needs of the organiza-
tion,ortoalterthephysicalorganizationtoimproveperformance.
• Grantingofauthorizationfordataaccess.Bygrantingdifferenttypesofauthoriza-
tion,thedatabaseadministratorcanregulatewhichpartsofthedatabasevarious
userscanaccess.Theauthorizationinformationiskeptinaspecialsystem struc-
turethatthedatabasesystem consultswheneverausertriestoaccessthedatain
thesystem.
• Routine maintenance. Examples of the database administrator’s routine mainte-
nanceactivitiesare:
° Periodically backing up the database onto remote servers, to prevent loss of
dataincaseofdisasterssuchasflooding.
° Ensuring that enough free disk space is available for normal operations, and
upgradingdiskspaceasrequired.
° Monitoringjobsrunningonthedatabaseandensuringthatperformanceisnot
degradedbyveryexpensivetaskssubmittedbysomeusers.
1.9 History of Database Systems
Informationprocessingdrivesthegrowthofcomputers,asithasfromtheearliestdays
ofcommercialcomputers. Infact,automationofdataprocessingtasks predatescom-
puters.Punchedcards,inventedbyHermanHollerith,wereusedattheverybeginning
ofthetwentiethcenturytorecordU.S.censusdata,andmechanicalsystemswereused
to process the cards and tabulate results. Punched cards were later widely used as a
meansofenteringdataintocomputers.
Techniquesfordatastorageandprocessinghaveevolvedovertheyears:
• 1950s and early 1960s: Magnetic tapes were developed for data storage. Data-
processing tasks such as payroll were automated, with data stored on tapes. Pro-
cessingofdataconsistedofreadingdatafromoneormoretapesandwritingdata
to a new tape. Data could also be input from punched card decks and output
to printers. For example, salary raises were processed by entering the raises on
punchedcardsandreadingthepunchedcarddeckinsynchronizationwithatape
containingthemastersalarydetails.Therecordshadtobeinthesamesortedor-
der.Thesalaryraiseswouldbeaddedtothesalaryreadfromthemastertapeand
writtentoanewtape;thenewtapewouldbecomethenewmastertape.
Tapes (and card decks) could be read only sequentially, and data sizes were
much larger than main memory; thus, data-processing programs were forced to

--- Page 55 ---

26 Chapter1 Introduction
process data in a particular order by reading and merging data from tapes and
carddecks.
• Late1960sandearly1970s:Widespreaduseofharddisksinthelate1960schanged
thescenariofordataprocessinggreatly,sinceharddisksalloweddirectaccessto
data.Thepositionofdataondiskwasimmaterial,sinceanylocationondiskcould
beaccessedinjusttensofmilliseconds.Datawerethusfreedfromthetyrannyof
sequentiality.Withtheadventofdisks,thenetworkandhierarchicaldatamodels
weredeveloped,whichalloweddatastructuressuchaslistsandtreestobestored
ondisk.Programmerscouldconstructandmanipulatethesedatastructures.
AlandmarkpaperbyEdgarCoddin1970definedtherelationalmodelandnon-
proceduralwaysofqueryingdataintherelationalmodel,andrelationaldatabases
wereborn.Thesimplicityoftherelationalmodelandthepossibilityofhidingim-
plementationdetailscompletelyfromtheprogrammerwereenticingindeed.Codd
laterwontheprestigiousAssociationofComputingMachineryTuringAwardfor
hiswork.
• Late1970sand1980s:Althoughacademicallyinteresting,therelationalmodelwas
notusedinpracticeinitiallybecauseofitsperceivedperformancedisadvantages;
relational databases could not match the performance of existing network and
hierarchical databases. That changed with System R, a groundbreaking project
at IBM Research that developed techniques for the construction of an efficient
relationaldatabase system. The fully functional System R prototype led to IBM’s
firstrelationaldatabaseproduct,SQL/DS.Atthesametime,theIngressystemwas
beingdevelopedattheUniversityofCaliforniaatBerkeley.Itledtoacommercial
productof the same name. Alsoaround thistime,the first version of Oracle was
released.Initialcommercialrelationaldatabasesystems,suchasIBMDB2,Oracle,
Ingres, and DEC Rdb, played a major role in advancing techniques for efficient
processingofdeclarativequeries.
Bytheearly1980s,relationaldatabaseshadbecomecompetitivewithnetwork
and hierarchical database systems even in the area of performance. Relational
databases were so easy to use that they eventually replaced network and hierar-
chicaldatabases.Programmersusingthoseoldermodelswereforcedtodealwith
many low-level implementation details, and they had to code their queries in a
procedural fashion. Most importantly, they had to keep efficiency in mind when
designing their programs, which involved a lot of effort. In contrast, in a rela-
tionaldatabase,almostalltheselow-leveltasksarecarriedoutautomaticallybythe
database system, leavingthe programmerfree to workat alogicallevel.Sinceat-
tainingdominanceinthe1980s,therelationalmodelhasreignedsupremeamong
datamodels.
The 1980s also saw much research on parallel and distributed databases, as
wellasinitialworkonobject-orienteddatabases.

--- Page 56 ---

1.9 HistoryofDatabaseSystems 27
• 1990s: The SQL language was designed primarily for decision support applica-
tions, which are query-intensive, yet the mainstay of databases in the 1980s was
transaction-processingapplications,whichareupdate-intensive.
In the early 1990s, decision support and querying re-emerged as a major ap-
plicationareafordatabases.Toolsforanalyzinglargeamountsofdatasawalarge
growthinusage.Manydatabasevendorsintroducedparalleldatabaseproductsin
thisperiod.Databasevendorsalsobegantoaddobject-relationalsupporttotheir
databases.
The major event of the 1990s was the explosive growth of the World Wide
Web.Databasesweredeployedmuchmoreextensivelythaneverbefore.Database
systemsnowhadtosupportveryhightransaction-processingrates,aswellasvery
highreliabilityand24×7availability(availability24hoursaday,7daysaweek,
meaning no downtime for scheduled maintenance activities). Database systems
alsohadtosupportwebinterfacestodata.
• 2000s: The types of data stored in database systems evolved rapidly during this
period. Semi-structured data became increasingly important. XML emerged as a
data-exchangestandard. JSON,amorecompactdata-exchangeformatwellsuited
forstoringobjectsfromJavaScriptorotherprogramminglanguagessubsequently
grew increasingly important. Increasingly, such data were stored in relational
database systems as support for the XML and JSON formats was added to the
major commercialsystems. Spatial data (that is, data that include geographic in-
formation)sawwidespreaduseinnavigationsystemsandadvancedapplications.
Databasesystemsaddedsupportforsuchdata.
Open-sourcedatabasesystems,notablyPostgreSQLandMySQL sawincreased
use. “Auto-admin” features were added to database systems in order to allow au-
tomatic reconfiguration to adapt to changing workloads. This helped reduce the
humanworkloadinadministeringadatabase.
Socialnetworkplatformsgrewatarapidpace,creatinganeedtomanagedata
aboutconnectionsbetweenpeopleandtheirposteddata,thatdidnotfitwellinto
atabularrow-and-columnformat.Thisledtothedevelopmentofgraphdatabases.
In the latter part of the decade, the use of data analytics and data mining in
enterprises became ubiquitous. Database systems were developed specifically to
servethismarket.Thesesystemsfeaturedphysicaldataorganizationssuitablefor
analyticprocessing,suchas“column-stores,”inwhichtablesarestoredbycolumn
ratherthanthetraditionalrow-orientedstorageofthemajorcommercialdatabase
systems.
The huge volumes of data, as well as the fact that much of the data used for
analytics was textual or semi-structured, led to the development of programming
frameworks,suchasmap-reduce,tofacilitateapplicationprogrammers’useofpar-
allelisminanalyzingdata.Intime,support forthesefeaturesmigratedintotradi-
tionaldatabasesystems.Eveninthelate2010s,debatecontinuedinthedatabase

--- Page 57 ---

28 Chapter1 Introduction
research community over the relative merits of a single database system serving
both traditional transaction processing applications and the newer data-analysis
applicationsversusmaintainingseparatesystemsfortheseroles.
The variety of new data-intensive applications and the need for rapid devel-
opment, particularly by startup firms, led to “NoSQL” systems that provide a
lightweightformofdatamanagement.Thenamewasderivedfromthosesystems’
lackofsupportfortheubiquitousdatabasequerylanguageSQL,thoughthename
isnowoftenviewedasmeaning“notonlySQL.”Thelackofahigh-levelquerylan-
guagebasedontherelationalmodelgaveprogrammersgreaterflexibilitytowork
withnewtypesofdata.Thelackoftraditionaldatabasesystems’supportforstrict
data consistency provided more flexibility in an application’s use of distributed
data stores. The NoSQL model of “eventual consistency” allowed for distributed
copies of data to be inconsistent as long they would eventually converge in the
absenceoffurtherupdates.
• 2010s:ThelimitationsofNoSQLsystems,suchaslackofsupportforconsistency,
and lack of support for declarative querying, were found acceptable by many ap-
plications(e.g., social networks), in return for the benefits they provided such as
scalability and availability. However, by the early 2010s it was clear that the lim-
itations made life significantly more complicated for programmers and database
administrators. As a result, these systems evolved to provide features to support
stricter notions of consistency, while continuing to support high scalability and
availability. Additionally, these systems increasingly support higher levels of ab-
stractiontoavoidtheneedforprogrammerstohavetoreimplementfeaturesthat
arestandardinatraditionaldatabasesystem.
Enterprisesareincreasinglyoutsourcingthestorageandmanagementoftheir
data. Rather than maintaining in-house systems and expertise, enterprises may
store their data in “cloud” services that host data for various clients in multiple,
widelydistributedserverfarms.Dataaredeliveredtousersviaweb-basedservices.
Otherenterprisesareoutsourcingnotonlythestorageoftheirdatabutalsowhole
applications. In such cases, termed “software as a service,” the vendor not only
stores the data for an enterprise but also runs (and maintains) the application
software. These trends result in significant savings in costs, but they create new
issuesnotonlyinresponsibilityforsecuritybreaches,butalsoindataownership,
particularlyincaseswhereagovernmentrequestsaccesstodata.
The huge influence of data and data analytics in dailylife has made the man-
agement of data a frequent aspect of the news. There is an unresolved tradeoff
between an individual’s right of privacy and society’s need to know. Various na-
tionalgovernmentshaveputregulationsonprivacyinplace.High-profilesecurity
breaches have created a public awareness of the challenges in cybersecurity and
therisksofstoringdata.

--- Page 58 ---

1.10 Summary 29
1.10 Summary
• A database-management system (DBMS) consists of a collection of interrelated
data and a collection of programs to access those data. The data describe one
particularenterprise.
• TheprimarygoalofaDBMSistoprovideanenvironmentthatisbothconvenient
andefficientforpeopletouseinretrievingandstoringinformation.
• Database systems are ubiquitous today, and most people interact, either directly
orindirectly,withdatabasesmanytimeseveryday.
• Databasesystemsaredesignedtostorelargebodiesofinformation.Themanage-
ment of data involves both the definition of structures for the storage of infor-
mationandtheprovisionofmechanismsforthemanipulationofinformation.In
addition,thedatabasesystemmustprovideforthesafetyoftheinformationstored
inthefaceofsystemcrashesorattemptsatunauthorizedaccess.Ifdataaretobe
sharedamongseveralusers,thesystemmustavoidpossibleanomalousresults.
• Amajorpurposeofadatabasesystemistoprovideuserswithanabstractviewof
the data. That is, the system hides certain details of how the data are stored and
maintained.
• Underlyingthestructureofadatabaseisthedatamodel:acollectionofconceptual
toolsfordescribingdata,datarelationships,datasemantics,anddataconstraints.
• The relational data model is the most widely deployed model for storing data in
databases. Otherdatamodelsaretheobject-orientedmodel,theobject-relational
model,andsemi-structureddatamodels.
• Adata-manipulationlanguage(DML)isalanguagethatenablesuserstoaccessor
manipulatedata.NonproceduralDMLs,whichrequireausertospecifyonlywhat
dataareneeded,withoutspecifyingexactlyhowtogetthosedata,arewidelyused
today.
• Adata-definitionlanguage(DDL)isalanguageforspecifyingthedatabaseschema
andotherpropertiesofthedata.
• Database design mainly involves the design of the database schema. The entity-
relationship(E-R) data model is a widelyused model for database design. It pro-
vides a convenient graphical representation to view data, relationships, and con-
straints.
• Adatabasesystemhasseveralsubsystems.
° The storage manager subsystem provides the interface between the low-level
datastoredinthedatabaseandtheapplicationprogramsandqueriessubmitted
tothesystem.

--- Page 59 ---

30 Chapter1 Introduction
° The query processor subsystem compiles and executes DDL and DML state-
ments.
• Transaction management ensures that the database remains in a consistent (cor-
rect) state despite system failures. The transaction manager ensures that concur-
renttransactionexecutionsproceedwithoutconflicts.
• Thearchitectureofadatabasesystemisgreatlyinfluencedbytheunderlyingcom-
putersystemonwhichthedatabasesystemruns.Databasesystemscanbecentral-
ized,orparallel,involvingmultiplemachines.Distributeddatabasesspanmultiple
geographicallyseparatedmachines.
• Database applications are typically broken up into a front-end part that runs at
clientmachinesandapartthatrunsatthebackend.Intwo-tierarchitectures,the
frontenddirectlycommunicateswithadatabaserunningatthebackend.Inthree-
tierarchitectures,the backend part isitselfbroken up intoan application server
andadatabaseserver.
• There are four different types of database-system users, differentiated by the way
theyexpecttointeractwiththesystem.Differenttypesofuserinterfaceshavebeen
designedforthedifferenttypesofusers.
• Data-analysistechniquesattempttoautomaticallydiscoverrulesandpatternsfrom
data.Thefieldofdataminingcombinesknowledge-discoverytechniquesinvented
by artificial intelligence researchers and statistical analysts with efficient imple-
mentationtechniquesthatenablethemtobeusedonextremelylargedatabases.
Review Terms
• Database-managementsystem • Instance
(DBMS) • Schema
• Database-systemapplications
° Physicalschema
• Onlinetransactionprocessing
• Dataanalytics ° Logicalschema
• File-processingsystems ° Subschema
• Datainconsistency • Physicaldataindependence
• Consistencyconstraints • Datamodels
• Dataabstraction
° Entity-relationshipmodel
° Physicallevel ° Relationaldatamodel
° Logicallevel ° Semi-structureddatamodel
° Viewlevel ° Object-baseddatamodel

--- Page 60 ---

PracticeExercises 31
• Databaselanguages ⋄Transactionmanager
⋄Filemanager
° Data-definitionlanguage
⋄Buffermanager
° Data-manipulationlanguage
⋄Datafiles
⋄ ProceduralDML
⋄Datadictionary
⋄ DeclarativeDML
⋄Indices
⋄ nonproceduralDML
° Queryprocessor
° Querylanguage
⋄DDLinterpreter
• Data-definitionlanguage
⋄DMLcompiler
° DomainConstraints ⋄Queryoptimization
° ReferentialIntegrity ⋄Queryevaluationengine
° Authorization ° Transactions
⋄ Readauthorization ⋄Atomicity
⋄ Insertauthorization ⋄Consistency
⋄ Updateauthorization ⋄Durability
⋄ Deleteauthorization ⋄Recoverymanager
• Metadata ⋄Failurerecovery
• Applicationprogram ⋄Concurrency-controlmanager
• Databasedesign • DatabaseArchitecture
° Conceptualdesign ° Centralized
° Normalization ° Parallel
° Specification of functional re- ° Distributed
quirements
• DatabaseApplicationArchitecture
° Physical-designphase
° Two-tier
• DatabaseEngine
° Three-tier
° Storagemanager
° Applicationserver
⋄ Authorization and integrity
manager • Databaseadministrator(DBA)
Practice Exercises
1.1 Thischapterhasdescribedseveralmajoradvantagesofadatabasesystem.What
aretwodisadvantages?
1.2 List five ways in which the type declaration system of a language such as Java
orC++differsfromthedatadefinitionlanguageusedinadatabase.

--- Page 61 ---

32 Chapter1 Introduction
1.3 Listsixmajorstepsthatyouwouldtakeinsettingupadatabaseforaparticular
enterprise.
1.4 SupposeyouwanttobuildavideositesimilartoYouTube.Considereachofthe
pointslistedinSection1.2asdisadvantagesofkeepingdatainafile-processing
system. Discuss the relevance of each of these points to the storage of actual
videodata,andtometadataaboutthevideo,suchastitle,theuserwhouploaded
it,tags,andwhichusersviewedit.
1.5 Keyword queriesused in websearch arequite differentfrom database queries.
Listkeydifferencesbetweenthetwo,intermsofthewaythequeriesarespecified
andintermsofwhatistheresultofaquery.
Exercises
1.6 Listfourapplicationsyouhaveusedthatmostlikelyemployedadatabasesystem
tostorepersistentdata.
1.7 Listfoursignificantdifferencesbetweenafile-processingsystemandaDBMS.
1.8 Explain the concept of physical data independence and its importance in
databasesystems.
1.9 List five responsibilities of a database-management system. For each responsi-
bility, explain the problems that would arise if the responsibility were not dis-
charged.
1.10 Listatleasttworeasonswhydatabasesystemssupportdatamanipulationusing
adeclarativequerylanguagesuchasSQL,insteadofjustprovidingalibraryof
CorC++functionstocarryoutdatamanipulation.
1.11 Assumethattwostudentsaretryingtoregisterforacourseinwhichthereisonly
one open seat. What component of a database system prevents both students
frombeinggiventhatlastseat?
1.12 Explainthedifferencebetweentwo-tierandthree-tierapplicationarchitectures.
Whichisbettersuitedforwebapplications?Why?
1.13 Listtwofeaturesdevelopedinthe2000sandthathelpdatabasesystemshandle
data-analyticsworkloads.
1.14 Explain why NoSQL systems emerged in the 2000s, and briefly contrast their
featureswithtraditionaldatabasesystems.
1.15 Describeatleastthreetablesthatmightbeusedtostoreinformationinasocial-
networkingsystemsuchasFacebook.

--- Page 62 ---

FurtherReading 33
Tools
There are a large number of commercial database systems in use today.
The major ones include: IBM DB2 (www.ibm.com/software/data/db2), Ora-
cle (www.oracle.com), Microsoft SQL Server (www.microsoft.com/sql), IBM In-
formix (www.ibm.com/software/data/informix), SAP Adaptive Server Enterprise
(formerly Sybase) (www.sap.com/products/sybase-ase.html), and SAP HANA
(www.sap.com/products/hana.html). Some of these systems are available free for
personalornon-commercialuse,orfordevelopment,butarenotfreeforactualdeploy-
ment.
Therearealsoanumberoffree/publicdomaindatabasesystems;widelyusedones
includeMySQL(www.mysql.com), PostgreSQL(www.postgresql.org),andtheem-
beddeddatabaseSQLite(www.sqlite.org).
Amorecompletelistoflinkstovendorwebsitesandotherinformationisavailable
fromthehomepageofthisbook,atdb-book.com.
Further Reading
[Codd (1970)] is the landmark paper that introduced the relational model. Textbook
coverageofdatabasesystemsisprovidedby[O’NeilandO’Neil(2000)],[Ramakrish-
nan and Gehrke (2002)], [Date (2003)], [Kifer et al. (2005)], [Garcia-Molina et al.
(2008)],and[ElmasriandNavathe(2016)],inadditiontothistextbook,
Areviewofaccomplishmentsindatabasemanagementandanassessmentoffuture
researchchallengesappearsin[Abadietal.(2016)].ThehomepageoftheACMSpecial
InterestGrouponManagementofData(www.acm.org/sigmod)providesawealthof
informationaboutdatabaseresearch.Databasevendorwebsites(seetheToolssection
above)providedetailsabouttheirrespectiveproducts.
Bibliography
[Abadietal.(2016)] D. Abadi, R. Agrawal, A. Ailamaki, M. Balazinska, P. A. Bernstein,
M.J.Carey,S.Chaudhuri,J.Dean,A.Doan,M.J.Franklin,J.Gehrke,L.M.Haas,A.Y.
Halevy,J.M.Hellerstein,Y.E.Ioannidis,H.Jagadish,D.Kossmann,S.Madden,S.Mehro-
tra, T. Milo, J. F. Naughton, R. Ramakrishnan, V. Markl, C. Olston, B. C. Ooi, C. RÂ´e,
D. Suciu, M. Stonebraker, T. Walter, and J. Widom, “The Beckman Report on Database
Research”,CommunicationsoftheACM,Volume59,Number2(2016),pages92–99.
[Codd(1970)] E.F.Codd,“ARelationalModelforLargeSharedDataBanks”,Communi-
cationsoftheACM,Volume13,Number6(1970),pages377–387.
[Date(2003)] C.J.Date,AnIntroductiontoDatabaseSystems,8thedition,AddisonWesley
(2003).

--- Page 63 ---

34 Chapter1 Introduction
[ElmasriandNavathe(2016)] R.ElmasriandS.B.Navathe,FundamentalsofDatabaseSys-
tems,7thedition,AddisonWesley(2016).
[Garcia-Molinaetal.(2008)] H.Garcia-Molina, J.D.Ullman, andJ.D.Widom,Database
Systems:TheCompleteBook,2ndedition,PrenticeHall(2008).
[Kiferetal.(2005)] M.Kifer,A.Bernstein,andP.Lewis,DatabaseSystems:AnApplication
OrientedApproach,CompleteVersion,2ndedition,AddisonWesley(2005).
[O’NeilandO’Neil(2000)] P.O’NeilandE.O’Neil,Database:Principles,Programming,Per-
formance,2ndedition,MorganKaufmann(2000).
[RamakrishnanandGehrke(2002)] R.RamakrishnanandJ.Gehrke,DatabaseManagement
Systems,3rdedition,McGrawHill(2002).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 64 ---

1
PART
RELATIONAL LANGUAGES
Adatamodelisacollectionofconceptualtoolsfordescribingdata,datarelationships,
datasemantics,andconsistencyconstraints.Therelationalmodelusesacollectionof
tables to represent both data and the relationships among those data. Its conceptual
simplicityhasledtoitswidespreadadoption;todayavastmajorityofdatabaseproducts
are based on the relational model. The relational model describes data at the logical
andviewlevels,abstractingawaylow-leveldetailsofdatastorage.
Tomakedatafromarelationaldatabaseavailabletousers,wehavetoaddresshow
users specify requests for retrieving and updating data. Several query languages have
beendevelopedforthistask,whicharecoveredinthispart.
Chapter2introducesthebasicconceptsunderlyingrelationaldatabases,including
the coverage of relational algebra—a formal query language that forms the basis for
SQL.ThelanguageSQListhemostwidelyusedrelationalquerylanguagetodayandis
coveredingreatdetailinthispart.
Chapter 3 provides an overview of the SQL query language, including the SQL
datadefinition,thebasicstructureofSQLqueries,setoperations,aggregatefunctions,
nestedsubqueries,andmodificationofthedatabase.
Chapter4providesfurtherdetailsofSQL,includingjoinexpressions,views,trans-
actions, integrity constraints that are enforced by the database, and authorization
mechanismsthatcontrolwhataccessandupdateactionscanbecarriedoutbyauser.
Chapter5coversadvancedtopicsrelatedtoSQLincludingaccesstoSQLfrompro-
gramminglanguages, functions, procedures,triggers, recursivequeries, and advanced
aggregationfeatures.
35

--- Page 66 ---

2
CHAPTER
Introduction to the Relational
Model
Therelationalmodelremainstheprimarydatamodelforcommercialdata-processing
applications.Itattaineditsprimarypositionbecauseofitssimplicity,whicheasesthe
job of the programmer, compared to earlier data models such as the network model
or the hierarchical model. It has retained this position by incorporating various new
featuresandcapabilitiesoveritshalf-centuryofexistence.Amongthoseadditionsare
object-relationalfeaturessuchascomplexdatatypesandstoredprocedures,supportfor
XML data, and various tools to support semi-structured data. The relational model’s
independence from any specific underlying low-level data structures has allowed it to
persistdespitetheadventofnewapproachestodatastorage,includingmoderncolumn-
storesthataredesignedforlarge-scaledatamining.
Inthischapter,wefirststudythefundamentalsoftherelationalmodel.Asubstan-
tialtheoryexistsforrelationaldatabases.InChapter6andChapter7,weshallexamine
aspectsofdatabasetheorythathelpinthedesignofrelationaldatabaseschemas,while
in Chapter 15 and Chapter 16 we discuss aspects of the theory dealing with efficient
processing of queries. In Chapter 27, we study aspects of formal relational languages
beyondourbasiccoverageinthischapter.
2.1 Structure of Relational Databases
A relational database consists of a collection of tables, each of which is assigned a
unique name. For example, consider the instructor table of Figure 2.1, which stores
informationaboutinstructors.Thetablehasfourcolumnheaders:ID,name,dept name,
andsalary.Eachrowofthistablerecordsinformationaboutaninstructor,consistingof
theinstructor’sID,name,dept name,andsalary.Similarly,thecoursetableofFigure2.2
storesinformationaboutcourses,consistingofacourse id,title,dept name,andcredits,
foreachcourse.NotethateachinstructorisidentifiedbythevalueofthecolumnID,
whileeachcourseisidentifiedbythevalueofthecolumncourse id.
37

--- Page 67 ---

38 Chapter2 IntroductiontotheRelationalModel
ID name dept name salary
10101 Srinivasan Comp.Sci. 65000
12121 Wu Finance 90000
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 ElSaid History 60000
33456 Gold Physics 87000
45565 Katz Comp.Sci. 75000
58583 Califieri History 62000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp.Sci. 92000
98345 Kim Elec.Eng. 80000
Figure 2.1 Theinstructor relation.
Figure2.3showsathirdtable,prereq,whichstorestheprerequisitecoursesforeach
course.Thetablehastwocolumns,course idandprereq id.Eachrowconsistsofapair
ofcourseidentifierssuchthatthesecondcourseisaprerequisiteforthefirstcourse.
Thus, a row in the prereq table indicates that two courses are related in the sense
thatonecourseisaprerequisitefortheother.Asanotherexample,whenweconsider
thetableinstructor,arowinthetablecanbethoughtofasrepresentingtherelationship
course id title dept name credits
BIO-101 Intro.toBiology Biology 4
BIO-301 Genetics Biology 4
BIO-399 ComputationalBiology Biology 3
CS-101 Intro.toComputerScience Comp.Sci. 4
CS-190 GameDesign Comp.Sci. 4
CS-315 Robotics Comp.Sci. 3
CS-319 ImageProcessing Comp.Sci. 3
CS-347 DatabaseSystemConcepts Comp.Sci. 3
EE-181 Intro.toDigitalSystems Elec.Eng. 3
FIN-201 InvestmentBanking Finance 3
HIS-351 WorldHistory History 3
MU-199 MusicVideoProduction Music 3
PHY-101 PhysicalPrinciples Physics 4
Figure 2.2 Thecourse relation.

--- Page 68 ---

2.1 StructureofRelationalDatabases 39
course id prereq id
BIO-301 BIO-101
BIO-399 BIO-101
CS-190 CS-101
CS-315 CS-101
CS-319 CS-101
CS-347 CS-101
EE-181 PHY-101
Figure 2.3 Theprereqrelation.
between a specified ID and the corresponding values for name, dept name, and salary
values.
Ingeneral,arowinatablerepresentsarelationshipamongasetofvalues.Sincea
tableisacollectionofsuchrelationships,thereisaclosecorrespondencebetweenthe
concept of table and the mathematical concept of relation, from which the relational
datamodeltakesitsname.Inmathematicalterminology,atupleissimplyasequence
(orlist)ofvalues.Arelationshipbetweennvaluesisrepresentedmathematicallybyan
n-tupleofvalues,thatis,atuplewithnvalues,whichcorrespondstoarowinatable.
Thus,intherelationalmodelthetermrelationisusedtorefertoatable,whilethe
termtupleisusedtorefertoarow.Similarly,thetermattributereferstoacolumnofa
table.
Examining Figure 2.1, we can see that the relation instructor has four attributes:
ID,name,dept name,andsalary.
We use the term relation instance torefer toa specificinstance of arelation,that
is,containingaspecificsetofrows.Theinstanceofinstructor showninFigure2.1has
12tuples,correspondingto12instructors.
In this chapter, we shall be using a number of different relations to illustrate the
various conceptsunderlyingthe relational data model.These relationsrepresentpart
of a university. To simplify our presentation, we exclude much of the data an actual
universitydatabasewouldcontain.Weshalldiscusscriteriafortheappropriatenessof
relationalstructuresingreatdetailinChapter6andChapter7.
Theorderinwhichtuplesappearinarelationisirrelevant,sincearelationisaset
oftuples.Thus,whetherthetuplesofarelationarelistedinsortedorder,asinFigure
2.1,orareunsorted, asinFigure2.4,doesnotmatter;therelationsinthetwofigures
are the same, since both contain the same set of tuples. For ease of exposition, we
generallyshowtherelationssortedbytheirfirstattribute.
Foreachattributeofarelation,thereisasetofpermittedvalues,calledthedomain
of that attribute. Thus, the domain of the salary attribute of the instructor relation is
thesetofallpossiblesalaryvalues,whilethedomainofthenameattributeisthesetof
allpossibleinstructornames.

--- Page 69 ---

40 Chapter2 IntroductiontotheRelationalModel
ID name dept name salary
22222 Einstein Physics 95000
12121 Wu Finance 90000
32343 ElSaid History 60000
45565 Katz Comp.Sci. 75000
98345 Kim Elec.Eng. 80000
76766 Crick Biology 72000
10101 Srinivasan Comp.Sci. 65000
58583 Califieri History 62000
83821 Brandt Comp.Sci. 92000
15151 Mozart Music 40000
33456 Gold Physics 87000
76543 Singh Finance 80000
Figure 2.4 Unsorteddisplayoftheinstructor relation.
We require that, for all relations r, the domains of all attributes of r be atomic.
A domain is atomic if elements of the domain are considered to be indivisible units.
For example, suppose the table instructor had an attribute phone number, which can
store a set of phone numbers corresponding to the instructor. Then the domain of
phone number wouldnotbe atomic,sinceanelementofthedomainisasetofphone
numbers,andithassubparts,namely,theindividualphonenumbersintheset.
Theimportantissueisnotwhatthedomainitselfis,butratherhowweusedomain
elementsinourdatabase.Supposenowthatthephone numberattributestoresasingle
phonenumber.Eventhen,ifwesplitthevaluefromthephonenumberattributeintoa
countrycode,anareacode,andalocalnumber,wewouldbetreatingitasanon-atomic
value.Ifwetreateachphonenumberasasingleindivisibleunit,thentheattributephone
number wouldhaveanatomicdomain.
Thenullvalueisaspecialvaluethatsignifiesthatthevalueisunknownordoesnot
exist.Forexample,supposeasbeforethatweincludetheattributephone numberinthe
instructor relation. It may be that an instructor does not have a phone number at all,
orthatthetelephonenumberisunlisted.Wewouldthenhavetousethenullvalueto
signify thatthe value isunknown ordoes notexist. We shall see laterthatnull values
cause a number of difficulties when we access or update the database, and thus they
shouldbeeliminatedifatallpossible.Weshallassumenullvaluesareabsentinitially,
andinSection3.6wedescribetheeffectofnullsondifferentoperations.
Therelativelystrictstructureofrelationsresultsinseveralimportantpracticalad-
vantages in the storage and processing of data, as we shall see. That strict structure
is suitable for well-defined and relatively static applications, but it is less suitable for
applicationswherenotonlydatabutalsothetypesandstructureofthosedatachange
overtime.Amodernenterpriseneedstofindagoodbalancebetweentheefficiencies
ofstructureddataandthosesituationswhereapredeterminedstructureislimiting.

--- Page 70 ---

2.2 DatabaseSchema 41
2.2 Database Schema
When we talk about a database, we must differentiate between the database schema,
whichisthelogicaldesignofthedatabase,andthedatabaseinstance,whichisasnap-
shotofthedatainthedatabaseatagiveninstantintime.
The concept of a relation corresponds to the programming-language notion of
a variable, while the concept of a relation schema corresponds to the programming-
languagenotionoftypedefinition.
Ingeneral,arelationschemaconsistsofalistofattributesandtheircorresponding
domains.Weshallnotbeconcernedabouttheprecisedefinitionofthedomainofeach
attributeuntilwediscusstheSQLlanguageinChapter3.
The conceptof a relationinstance corresponds to the programming-language no-
tionofavalueofavariable.Thevalueofagivenvariablemaychangewithtime;simi-
larlythecontentsofarelationinstancemaychangewithtimeastherelationisupdated.
Incontrast,theschemaofarelationdoesnotgenerallychange.
Although itisimportant to know the differencebetween a relationschemaand a
relationinstance, we often use the same name, such as instructor, torefer to both the
schema and the instance. Where required, we explicitly refer to the schema or to the
instance,forexample“theinstructorschema,”or“aninstanceoftheinstructorrelation.”
However,whereitisclearwhetherwemeantheschemaortheinstance,wesimplyuse
therelationname.
ConsiderthedepartmentrelationofFigure2.5.Theschemaforthatrelationis:
department(dept name,building,budget)
Note that the attribute dept name appears in both the instructor schema and the
department schema. This duplication is not a coincidence. Rather, using common at-
tributes in relation schemas is one way of relating tuples of distinct relations. For ex-
ample,suppose wewishtofindtheinformationaboutalltheinstructorswhoworkin
theWatson building.Welookfirstatthedepartment relationtofindthedept nameof
all the departments housed in Watson. Then, for each such department, we look in
dept name building budget
Biology Watson 90000
Comp.Sci. Taylor 100000
Elec.Eng. Taylor 85000
Finance Painter 120000
History Painter 50000
Music Packard 80000
Physics Watson 70000
Figure 2.5 The department relation.

--- Page 71 ---

42 Chapter2 IntroductiontotheRelationalModel
course id sec id semester year building room number time slot id
BIO-101 1 Summer 2017 Painter 514 B
BIO-301 1 Summer 2018 Painter 514 A
CS-101 1 Fall 2017 Packard 101 H
CS-101 1 Spring 2018 Packard 101 F
CS-190 1 Spring 2017 Taylor 3128 E
CS-190 2 Spring 2017 Taylor 3128 A
CS-315 1 Spring 2018 Watson 120 D
CS-319 1 Spring 2018 Watson 100 B
CS-319 2 Spring 2018 Taylor 3128 C
CS-347 1 Fall 2017 Taylor 3128 A
EE-181 1 Spring 2017 Taylor 3128 C
FIN-201 1 Spring 2018 Packard 101 B
HIS-351 1 Spring 2018 Painter 514 C
MU-199 1 Spring 2018 Packard 101 D
PHY-101 1 Fall 2017 Watson 100 A
Figure 2.6 Thesectionrelation.
theinstructor relationtofindtheinformationabouttheinstructorassociatedwiththe
correspondingdept name.
Each course in a university may be offered multiple times, across different
semesters, or even within a semester. We need a relation to describe each individual
offering,orsection,oftheclass.Theschemais:
section(course id,sec id,semester,year,building,room number,time slot id)
Figure2.6showsasampleinstanceofthesectionrelation.
We need a relation to describe the association between instructors and the class
sectionsthattheyteach.Therelationschematodescribethisassociationis:
teaches(ID,course id,sec id,semester,year)
Figure2.7showsasampleinstanceoftheteachesrelation.
Asyoucanimagine,therearemanymorerelationsmaintainedinarealuniversity
database. In addition to those relations we have listed already, instructor, department,
course,section,prereq,andteaches,weusethefollowingrelationsinthistext:
• student(ID,name,dept name,tot cred)
• advisor (s id,i id)
• takes(ID,course id,sec id,semester,year,grade)

--- Page 72 ---

2.3 Keys 43
ID course id sec id semester year
10101 CS-101 1 Fall 2017
10101 CS-315 1 Spring 2018
10101 CS-347 1 Fall 2017
12121 FIN-201 1 Spring 2018
15151 MU-199 1 Spring 2018
22222 PHY-101 1 Fall 2017
32343 HIS-351 1 Spring 2018
45565 CS-101 1 Spring 2018
45565 CS-319 1 Spring 2018
76766 BIO-101 1 Summer 2017
76766 BIO-301 1 Summer 2018
83821 CS-190 1 Spring 2017
83821 CS-190 2 Spring 2017
83821 CS-319 2 Spring 2018
98345 EE-181 1 Spring 2017
Figure 2.7 Theteachesrelation.
• classroom(building,room number,capacity)
• time slot(time slot id,day,start time,end time)
2.3 Keys
We must have a way to specify how tuples within a given relation are distinguished.
Thisisexpressedintermsoftheirattributes.Thatis,thevaluesoftheattributevalues
ofatuplemustbesuchthattheycanuniquelyidentifythetuple.Inotherwords,notwo
tuplesinarelationareallowedtohaveexactlythesamevalueforallattributes.1
A superkey is a set of one or more attributes that, taken collectively, allow us to
identify uniquely a tuple in the relation. For example, the ID attribute of the relation
instructor is sufficient to distinguish one instructor tuple from another. Thus, ID is a
superkey.Thenameattributeofinstructor,ontheotherhand,isnotasuperkey,because
severalinstructorsmighthavethesamename.
Formally, let R denote the set of attributes in the schema of relation r. If we say
thatasubsetK ofRisasuperkeyforr,wearerestrictingconsiderationtoinstancesof
relationsr inwhichnotwodistincttupleshavethesamevaluesonallattributesinK.
Thatis,ift andt areinr andt ≠ t ,thent .K ≠ t .K.
1 2 1 2 1 2
1Commercialdatabasesystemsrelaxtherequirementthatarelationisasetandinsteadallowduplicatetuples.Thisis
discussedfurtherinChapter3.

--- Page 73 ---

44 Chapter2 IntroductiontotheRelationalModel
A superkey may contain extraneous attributes. For example, the combination of
IDandnameisasuperkeyfortherelationinstructor.IfK isasuperkey,thensoisany
superset of K. We are often interested in superkeys for which no proper subset is a
superkey.Suchminimalsuperkeysarecalledcandidatekeys.
Itispossiblethatseveraldistinctsetsofattributescouldserveasacandidatekey.
Supposethatacombinationofnameanddept nameissufficienttodistinguishamong
membersoftheinstructorrelation.Then,both{ID}and{name,dept name}arecandidate
keys. Although the attributes ID and name together can distinguish instructor tuples,
their combination, {ID, name}, does not form a candidate key, since the attribute ID
aloneisacandidatekey.
Weshallusethetermprimarykeytodenoteacandidatekeythatischosenbythe
databasedesignerastheprincipalmeansofidentifyingtupleswithinarelation.Akey
(whetherprimary,candidate,orsuper)isapropertyoftheentirerelation,ratherthan
of the individualtuples. Anytwoindividualtuples inthe relationare prohibited from
havingthesamevalueonthekeyattributesatthesametime.Thedesignationofakey
representsaconstraintinthereal-worldenterprisebeingmodeled.Thus,primarykeys
arealsoreferredtoasprimarykeyconstraints.
It is customary to list the primary key attributes of a relation schema before the
otherattributes;forexample,thedept nameattributeofdepartmentislistedfirst,since
itistheprimarykey.Primarykeyattributesarealsounderlined.
Considertheclassroomrelation:
classroom(building,room number,capacity)
Heretheprimarykeyconsistsoftwoattributes,building androom number,whichare
underlinedtoindicatetheyarepartoftheprimarykey.Neitherattribute byitselfcan
uniquely identify a classroom, although together they uniquely identify a classroom.
Alsoconsiderthetime slotrelation:
time slot(time slot id,day,start time,end time)
Eachsectionhasanassociatedtime slot id.Thetime slotrelationprovidesinformation
on which days of the week, and at what times, a particular time slot id meets. For ex-
ample,time slot id 'A'maymeetfrom8.00AMto8.50AMonMondays,Wednesdays,
andFridays.Itispossibleforatimeslottohavemultiplesessionswithinasingleday,at
differenttimes,sothetime slot id anddaytogetherdonotuniquelyidentifythetuple.
Theprimarykeyofthetime slotrelationthusconsistsoftheattributestime slot id,day,
and start time, since these three attributes together uniquely identify a time slot for a
course.
Primarykeysmustbechosenwithcare.Aswenoted,thenameofapersonisinsuffi-
cient,becausetheremaybemanypeoplewiththesamename.IntheUnitedStates,the
socialsecuritynumberattributeofapersonwouldbeacandidatekey.Sincenon-U.S.
residents usually do not have social security numbers, international enterprises must

--- Page 74 ---

2.3 Keys 45
generatetheirownuniqueidentifiers.Analternativeistousesomeuniquecombination
ofotherattributesasakey.
The primary key should be chosen such that its attribute values are never, or are
veryrarely,changed.Forinstance,theaddressfieldofaperson should notbe partof
theprimarykey,sinceitislikelytochange.Socialsecuritynumbers,ontheotherhand,
are guaranteed never to change. Unique identifiersgenerated by enterprises generally
donotchange,exceptiftwoenterprisesmerge;insuchacasethesameidentifiermay
havebeenissuedbybothenterprises,andareallocationofidentifiersmayberequired
tomakesuretheyareunique.
Figure2.8showsthecompletesetofrelationsthatweuseinoursampleuniversity
schema,withprimary-keyattributesunderlined.
Next, we consider another type of constraint on the contents of relations, called
foreign-key constraints. Consider the attribute dept name of the instructor relation. It
wouldnotmakesenseforatupleininstructortohaveavaluefordept namethatdoesnot
correspondtoadepartmentinthedepartmentrelation.Thus,inanydatabaseinstance,
givenanytuple,sayt ,fromtheinstructorrelation,theremustbesometuple,sayt ,in
a b
thedepartmentrelationsuchthatthevalueofthedept nameattributeoft isthesame
a
asthevalueoftheprimarykey,dept name,oft .
b
A foreign-key constraint from attribute(s) A of relation r to the primary-key B of
1
relationr statesthatonanydatabaseinstance,thevalueofAforeachtupleinr must
2 1
alsobethevalueofBforsometupleinr .AttributesetAiscalledaforeignkeyfromr ,
2 1
referencing r . The relation r is also called the referencingrelation of the foreign-key
2 1
constraint,andr iscalledthereferencedrelation.
2
Forexample, theattribute dept namein instructor isaforeignkey from instructor,
referencingdepartment;notethatdept nameistheprimarykeyofdepartment.Similarly,
classroom(building,room number,capacity)
department(dept name,building,budget)
course(course id,title,dept name,credits)
instructor(ID,name,dept name,salary)
section(course id,sec id,semester,year,building,room number,time slot id)
teaches(ID,course id,sec id,semester,year)
student(ID,name,dept name,tot cred)
takes(ID,course id,sec id,semester,year,grade)
advisor(s ID,i ID)
time slot(time slot id,day,start time,end time)
prereq(course id,prereq id)
Figure 2.8 Schemaoftheuniversitydatabase.

--- Page 75 ---

46 Chapter2 IntroductiontotheRelationalModel
theattributesbuildingandroom numberofthesectionrelationtogetherformaforeign
keyreferencingtheclassroomrelation.
Note that in a foreign-key constraint, the referenced attribute(s) must be the pri-
marykeyofthereferencedrelation.Themoregeneralcase,areferential-integritycon-
straint,relaxestherequirementthatthereferencedattributesformtheprimarykeyof
thereferencedrelation.
As an example, consider the values in the time slot id attribute of the section re-
lation. We require that these values must exist in the time slot id attribute of the time
slotrelation.Sucharequirementisanexampleofareferentialintegrityconstraint.In
general,areferentialintegrityconstraintrequiresthatthevaluesappearinginspecified
attributesofanytupleinthereferencingrelationalsoappearinspecifiedattributesof
atleastonetupleinthereferencedrelation.
Notethattime slotdoesnotformaprimarykeyofthetime slotrelation,althoughit
isapartoftheprimarykey;thus,wecannotuseaforeign-keyconstrainttoenforcethe
aboveconstraint.Infact,foreign-keyconstraintsareaspecialcaseofreferentialintegrity
constraints, where the referenced attributes form the primary key of the referenced
relation. Database systems today typically support foreign-key constraints, but they
donotsupportreferentialintegrityconstraintswherethereferencedattributeisnota
primarykey.
2.4 Schema Diagrams
A database schema, along with primary key and foreign-key constraints, can be de-
picted by schema diagrams. Figure 2.9 shows the schema diagram for our university
organization.Eachrelationappearsasabox,withtherelationnameatthetopinblue
andtheattributeslistedinsidethebox.
Primary-key attributes are shown underlined. Foreign-key constraints appear as
arrowsfromtheforeign-keyattributesofthereferencingrelationtotheprimarykeyof
the referencedrelation.We use atwo-headed arrow,instead of asingle-headedarrow,
to indicate a referential integrity constraint that is not a foreign-key constraints. In
Figure2.9,thelinewithatwo-headedarrowfromtime slot id inthesectionrelationto
time slot id inthetime slot relationrepresentsthereferentialintegrityconstraintfrom
section.time slot id totime slot.time slot id.
Many database systems provide design tools with a graphical user interface for
creating schema diagrams.2 We shall discuss a differentdiagrammatic representation
of schemas, called the entity-relationship diagram, at length in Chapter 6; although
therearesomesimilaritiesinappearance,thesetwonotationsarequitedifferent,and
shouldnotbeconfusedforoneanother.
2Thetwo-headedarrownotationtorepresentreferentialintegrityconstraintshasbeenintroducedbyusandisnot
supportedbyanytoolasfarasweknow;thenotationsforprimaryandforeignkeys,however,arewidelyused.

--- Page 76 ---

2.5 RelationalQueryLanguages 47
student
takes
ID ID
course_id name
sec_id dept_name
semester tot_cred
year
grade
section course
course_id course_id department advisor
s s y e e e c m a _ r e id ster time_slot t d c i r e t e l p e d t_ it n s ame d bu ep il t d _ i n n a g me s i_ _ i i d d
building budget
room_number time_slot_id
time_slot_id day
start_time
end_time
prereq instructor
classroom
course_id ID
building prereq_id name
room_number dept_name
capacity teaches salary
ID
course_id
sec_id
semester
year
Figure 2.9 Schemadiagramfortheuniversitydatabase.
2.5 Relational Query Languages
Aquerylanguageisalanguageinwhichauserrequestsinformationfromthedatabase.
These languages are usually on a level higher than that of a standard programming
language.Querylanguagescanbecategorizedasimperative,functional,ordeclarative.
In an imperative query language, the user instructs the system to perform a specific
sequenceofoperationsonthedatabasetocomputethedesiredresult;suchlanguages
usuallyhaveanotionofstatevariables,whichareupdatedinthecourseofthecompu-
tation.
In a functional query language, the computation is expressed as the evaluation of
functionsthatmayoperateondatainthedatabaseorontheresultsofotherfunctions;
functionsareside-effectfree,andtheydonotupdatetheprogramstate.3 Inadeclara-
tivequerylanguage,theuserdescribesthedesiredinformationwithoutgivingaspecific
sequenceofstepsorfunctioncallsforobtainingthatinformation;thedesiredinforma-
tion is typicallydescribed using some form of mathematicallogic. It is the job of the
databasesystemtofigureouthowtoobtainthedesiredinformation.
3Thetermprocedurallanguagehasbeenusedinearliereditionsofthebooktorefertolanguagesbasedonprocedure
invocations,whichincludefunctionallanguages;however,thetermisalsowidelyusedtorefertoimperativelanguages.
Toavoidconfusionwenolongerusetheterm.

--- Page 77 ---

48 Chapter2 IntroductiontotheRelationalModel
Thereareanumberof“pure”querylanguages.
• The relational algebra, which we describe in Section 2.6, is a functional query
language.4 TherelationalalgebraformsthetheoreticalbasisoftheSQLquerylan-
guage.
• Thetuplerelationalcalculusanddomainrelationalcalculus,whichwedescribein
Chapter27(availableonline)aredeclarative.
Thesequerylanguagesareterseandformal,lackingthe“syntacticsugar”ofcommercial
languages, buttheyillustrate thefundamentaltechniquesforextractingdatafromthe
database.
Query languages used in practice, such as the SQL query language, include ele-
ments of the imperative, functional, and declarative approaches. We study the very
widelyusedquerylanguageSQLinChapter3throughChapter5.
2.6 The Relational Algebra
Therelationalalgebraconsistsofasetofoperationsthattake oneortworelationsas
inputandproduceanewrelationastheirresult.
Some ofthese operations, such asthe select,project,and renameoperations, are
called unary operations because they operate on one relation. The other operations,
suchasunion,Cartesianproduct,andsetdifference,operateonpairsofrelationsand
are,therefore,calledbinaryoperations.
AlthoughtherelationalalgebraoperationsformthebasisforthewidelyusedSQL
querylanguage,databasesystemsdonotallowuserstowritequeriesinrelationalalge-
bra. However,thereareimplementationsofrelationalalgebrathathavebeenbuiltfor
studentstopracticerelationalalgebraqueries.Thewebsiteofourbook,db-book.com,
underthelinktitledLaboratoryMaterial,providespointerstoafewsuchimplementa-
tions.
It is worth recalling at this point that since a relation is a set of tuples, relations
cannot contain duplicate tuples. In practice, however, tables in database systems are
permitted to contain duplicates unless a specific constraint prohibits it. But, in dis-
cussing the formal relational algebra, we require that duplicates be eliminated, as is
required by the mathematical definition of a set. In Chapter 3 we discuss how rela-
tional algebra can be extended to work on multisets, which are sets that can contain
duplicates.
4Unlikemodernfunctionallanguages,relationalalgebrasupportsonlyasmallnumberofpredefinedfunctions,which
defineanalgebraonrelations.

--- Page 78 ---

2.6 TheRelationalAlgebra 49
ID name dept name salary
22222 Einstein Physics 95000
33456 Gold Physics 87000
Figure 2.10 Resultofσ deptname=“Physics” (instructor).
2.6.1 The Select Operation
Theselectoperationselectstuplesthatsatisfyagivenpredicate.Weusethelowercase
Greeklettersigma(σ) todenote selection.The predicateappears asasubscript toσ.
Theargumentrelationisinparenthesesaftertheσ.Thus,toselectthosetuplesofthe
instructor relationwheretheinstructorisinthe“Physics”department,wewrite:
σ (instructor)
deptname=“Physics”
If the instructor relation is as shown in Figure 2.1, then the relation that results
fromtheprecedingqueryisasshowninFigure2.10.
Wecanfindallinstructorswithsalarygreaterthan$90,000bywriting:
σ (instructor)
salary>90000
Ingeneral,weallowcomparisonsusing=,≠,<,≤,>,and≥intheselectionpred-
icate.Furthermore,wecancombineseveralpredicatesintoalargerpredicatebyusing
the connectives and (∧), or (∨), and not (¬). Thus, to find the instructors in Physics
withasalarygreaterthan$90,000,wewrite:
σ (instructor)
deptname=“Physics”∧salary>90000
Theselectionpredicatemayincludecomparisonsbetweentwoattributes.Toillus-
trate,considertherelationdepartment.Tofindalldepartmentswhosenameisthesame
astheirbuildingname,wecanwrite:
σ (department)
deptname=building
2.6.2 The Project Operation
Supposewewanttolistallinstructors’ID,name,andsalary,butwedonotcareabout
the dept name. The project operation allows us to produce this relation. The project
operationisaunaryoperationthatreturnsitsargumentrelation,withcertainattributes
leftout.Sincearelationisaset,anyduplicaterowsareeliminated.Projectionisdenoted
bytheuppercaseGreekletterpi(Π).Welistthoseattributesthatwewishtoappearin
theresultasasubscripttoΠ.Theargumentrelationfollowsinparentheses.Wewrite
thequerytoproducesuchalistas:
Π (instructor)
ID,name,salary
Figure2.11showstherelationthatresultsfromthisquery.

--- Page 79 ---

50 Chapter2 IntroductiontotheRelationalModel
ID name salary
10101 Srinivasan 65000
12121 Wu 90000
15151 Mozart 40000
22222 Einstein 95000
32343 ElSaid 60000
33456 Gold 87000
45565 Katz 75000
58583 Califieri 62000
76543 Singh 80000
76766 Crick 72000
83821 Brandt 92000
98345 Kim 80000
Figure 2.11 ResultofΠ ID,name,salary (instructor).
ThebasicversionoftheprojectoperatorΠ (E)allowsonlyattributenamestobe
L
presentinthelistL.Ageneralizedversionoftheoperatorallowsexpressionsinvolving
attributestoappearinthelistL.Forexample,wecoulduse:
Π (instructor)
ID,name,salary∕12
togetthemonthlysalaryofeachinstructor.
2.6.3 Composition of Relational Operations
The fact that the result of a relational operation is itself a relation is important. Con-
sider the more complicated query “Find the names of all instructors in the Physics
department.”Wewrite:
Π (σ (instructor))
name deptname=“Physics”
Noticethat,insteadofgivingthenameofarelationastheargumentoftheprojection
operation,wegiveanexpressionthatevaluatestoarelation.
In general, since the result of a relational-algebra operation is of the same type
(relation)asitsinputs, relational-algebraoperations canbe composed togetherintoa
relational-algebra expression. Composing relational-algebra operations into relational-
algebraexpressionsisjustlikecomposingarithmeticoperations(suchas+,−,∗,and
÷)intoarithmeticexpressions.
2.6.4 The Cartesian-Product Operation
The Cartesian-product operation, denoted by a cross (×), allows us to combine infor-
mation from any two relations. We write the Cartesian product of relations r and r
1 2
asr ×r .
1 2

--- Page 80 ---

2.6 TheRelationalAlgebra 51
instructor.ID name deptname salary teaches.ID courseid secid semester year
10101 Srinivasan Comp.Sci. 65000 10101 CS-101 1 Fall 2017
10101 Srinivasan Comp.Sci. 65000 10101 CS-315 1 Spring 2018
10101 Srinivasan Comp.Sci. 65000 10101 CS-347 1 Fall 2017
10101 Srinivasan Comp.Sci. 65000 12121 FIN-201 1 Spring 2018
10101 Srinivasan Comp.Sci. 65000 15151 MU-199 1 Spring 2018
10101 Srinivasan Comp.Sci. 65000 22222 PHY-101 1 Fall 2017
... ... ... ... ... ... ... ... ...
... ... ... ... ... ... ... ... ...
12121 Wu Finance 90000 10101 CS-101 1 Fall 2017
12121 Wu Finance 90000 10101 CS-315 1 Spring 2018
12121 Wu Finance 90000 10101 CS-347 1 Fall 2017
12121 Wu Finance 90000 12121 FIN-201 1 Spring 2018
12121 Wu Finance 90000 15151 MU-199 1 Spring 2018
12121 Wu Finance 90000 22222 PHY-101 1 Fall 2017
... ... ... ... ... ... ... ... ...
... ... ... ... ... ... ... ... ...
15151 Mozart Music 40000 10101 CS-101 1 Fall 2017
15151 Mozart Music 40000 10101 CS-315 1 Spring 2018
15151 Mozart Music 40000 10101 CS-347 1 Fall 2017
15151 Mozart Music 40000 12121 FIN-201 1 Spring 2018
15151 Mozart Music 40000 15151 MU-199 1 Spring 2018
15151 Mozart Music 40000 22222 PHY-101 1 Fall 2017
... ... ... ... ... ... ... ... ...
... ... ... ... ... ... ... ... ...
22222 Einstein Physics 95000 10101 CS-101 1 Fall 2017
22222 Einstein Physics 95000 10101 CS-315 1 Spring 2018
22222 Einstein Physics 95000 10101 CS-347 1 Fall 2017
22222 Einstein Physics 95000 12121 FIN-201 1 Spring 2018
22222 Einstein Physics 95000 15151 MU-199 1 Spring 2018
22222 Einstein Physics 95000 22222 PHY-101 1 Fall 2017
... ... ... ... ... ... ... ... ...
... ... ... ... ... ... ... ... ...
Figure 2.12 ResultoftheCartesianproductinstructor ×teaches.
ACartesianproductofdatabaserelationsdiffersinitsdefinitionslightlyfromthe
mathematical definition of a Cartesian product of sets. Instead of r × r producing
1 2
pairs(t ,t )oftuplesfromr andr ,therelationalalgebraconcatenatest andt into
1 2 1 2 1 2
asingletuple,asshowninFigure2.12.
Since the same attribute name may appear in the schemas of both r and r , we
1 2
needtodeviseanamingschematodistinguishbetweentheseattributes.Wedosohere
byattachingtoanattributethenameoftherelationfromwhichtheattributeoriginally
came.Forexample,therelationschemaforr = instructor ×teachesis:
(instructor.ID,instructor.name,instructor.dept name,instructor.salary,
teaches.ID,teaches.course id,teaches.sec id,teaches.semester,teaches.year)

--- Page 81 ---

52 Chapter2 IntroductiontotheRelationalModel
Withthisschema,wecandistinguishinstructor.IDfromteaches.ID.Forthoseattributes
that appear in only one of the two schemas, we shall usually drop the relation-name
prefix.Thissimplificationdoesnotleadtoanyambiguity.Wecanthenwritetherelation
schemaforr as:
(instructor.ID,name,dept name,salary,
teaches.ID,course id,sec id,semester,year)
This naming convention requires that the relations that are the arguments of the
Cartesian-product operation have distinct names. This requirement causes problems
insomecases,suchaswhentheCartesianproductofarelationwithitselfisdesired.A
similarproblemarisesifweusetheresultofarelational-algebraexpressioninaCarte-
sian product, since we shall need a name for the relation so that we can refer to the
relation’sattributes.InSection2.6.8,weseehowtoavoidtheseproblemsbyusingthe
renameoperation.
Now that we know the relation schema for r = instructor × teaches, what tuples
appearinr?Asyoumaysuspect,weconstructatupleofr outofeachpossiblepairof
tuples: one from theinstructor relation(Figure2.1) and onefrom theteaches relation
(Figure2.7).Thus,risalargerelation,asyoucanseefromFigure2.12,whichincludes
onlyaportionofthetuplesthatmakeupr.
Assume that we have n tuples in instructor and n tuples in teaches. Then, there
1 2
are n ∗ n ways of choosing a pair of tuples—one tuple from each relation; so there
1 2
aren ∗ n tuplesinr.Inparticularforourexample, forsometuples t inr, itmaybe
1 2
thatthetwoIDvalues,instructor.IDandteaches.ID,aredifferent.
In general, if we have relations r (R ) and r (R ), then r × r is a relationr(R)
1 1 2 2 1 2
whoseschemaRistheconcatenationoftheschemasR andR .Relationrcontainsall
1 2
tuplestforwhichthereisatuplet inr andatuplet inr forwhichtandt havethe
1 1 2 2 1
samevalueontheattributesinR andtandt havethesamevalueontheattributesin
1 2
R .
2
2.6.5 The Join Operation
Supposewewanttofindtheinformationaboutallinstructorstogetherwiththecourse
id of all courses they have taught. We need the information in both the instructor
relationandtheteachesrelationtocomputetherequiredresult.TheCartesianproduct
ofinstructorandteachesdoesbringtogetherinformationfromboththeserelations,but
unfortunatelytheCartesianproductassociateseveryinstructorwitheverycoursethat
wastaught,regardlessofwhetherthatinstructortaughtthatcourse.
SincetheCartesian-productoperationassociateseverytupleofinstructorwithevery
tupleofteaches,weknow thatifaninstructorhastaughtacourse(asrecordedinthe
teaches relation), then there is some tuple in instructor × teaches that contains her
nameandsatisfiesinstructor.ID=teaches.ID.So,ifwewrite:
σ (instructor × teaches)
instructor.ID=teaches.ID
we get only those tuples of instructor × teaches that pertain to instructors and the
coursesthattheytaught.

--- Page 82 ---

2.6 TheRelationalAlgebra 53
instructor.ID name deptname salary teaches.ID courseid secid semester year
10101 Srinivasan Comp.Sci. 65000 10101 CS-101 1 Fall 2017
10101 Srinivasan Comp.Sci. 65000 10101 CS-315 1 Spring 2018
10101 Srinivasan Comp.Sci. 65000 10101 CS-347 1 Fall 2017
12121 Wu Finance 90000 12121 FIN-201 1 Spring 2018
15151 Mozart Music 40000 15151 MU-199 1 Spring 2018
22222 Einstein Physics 95000 22222 PHY-101 1 Fall 2017
32343 ElSaid History 60000 32343 HIS-351 1 Spring 2018
45565 Katz Comp.Sci. 75000 45565 CS-101 1 Spring 2018
45565 Katz Comp.Sci. 75000 45565 CS-319 1 Spring 2018
76766 Crick Biology 72000 76766 BIO-101 1 Summer 2017
76766 Crick Biology 72000 76766 BIO-301 1 Summer 2018
83821 Brandt Comp.Sci. 92000 83821 CS-190 1 Spring 2017
83821 Brandt Comp.Sci. 92000 83821 CS-190 2 Spring 2017
83821 Brandt Comp.Sci. 92000 83821 CS-319 2 Spring 2018
98345 Kim Elec.Eng. 80000 98345 EE-181 1 Spring 2017
Figure 2.13 Resultofσ instructor.ID=teaches.ID (instructor × teaches).
TheresultofthisexpressionisshowninFigure2.13.ObservethatinstructorsGold,
Califieri,andSinghdonotteachanycourse(asrecordedintheteachesrelation),and
thereforedonotappearintheresult.
Notethatthisexpressionresultsintheduplicationoftheinstructor’sID.Thiscan
beeasilyhandledbyaddingaprojectiontoeliminatethecolumnteaches.ID.
Thejoinoperation allowsustocombineaselectionandaCartesian productinto
asingleoperation.
Consider relations r(R) and s(S), and let θ be a predicate on attributes in the
schemaR∪S.Thejoinoperationr ⋈ sisdefinedasfollows:
θ
r ⋈ s = σ (r × s)
θ θ
Thus, σ (instructor × teaches) can equivalently be written as
instructor.ID=teaches.ID
instructor ⋈ teaches.
instructor.ID=teaches.ID
2.6.6 Set Operations
Consider a query to find the set of all courses taught in the Fall 2017 semester, the
Spring 2018 semester, or both. The information is contained in the section relation
(Figure2.6).TofindthesetofallcoursestaughtintheFall2017semester,wewrite:
Π (σ (section))
courseid semester=“Fall”∧year=2017
TofindthesetofallcoursestaughtintheSpring2018semester,wewrite:
Π (σ (section))
courseid semester=“Spring”∧year=2018

--- Page 83 ---

54 Chapter2 IntroductiontotheRelationalModel
Toanswerthequery,weneedtheunionofthesetwosets;thatis,weneedallcourse
idsthatappearineitherorbothofthetworelations.Wefindthesedatabythebinary
operationunion,denoted,asinsettheory,by∪.Sotheexpressionneededis:
Π (σ (section))∪
courseid semester=“Fall”∧year=2017
Π (σ (section))
courseid semester=“Spring”∧year=2018
TheresultrelationforthisqueryappearsinFigure2.14.Noticethatthereareeight
tuples in the result, even though there are three distinct courses offered in the Fall
2017semesterandsixdistinctcoursesofferedintheSpring2018semester.Sincerela-
tionsaresets,duplicatevaluessuchasCS-101,whichisofferedinbothsemesters,are
replacedbyasingleoccurrence.
Observe that, in our example, we took the union of two sets, both of which con-
sistedofcourse id values.Ingeneral,foraunionoperationtomakesense:
1. We must ensure that the input relations to the union operation have the same
number of attributes; the number of attributes of a relation is referred to as its
arity.
2. Whentheattributeshaveassociatedtypes,thetypesoftheithattributesofboth
inputrelationsmustbethesame,foreachi.
Suchrelationsarereferredtoascompatiblerelations.
Forexample,itwouldnotmakesensetotaketheunionoftheinstructorandsection
relations,sincetheyhavedifferentnumbersofattributes.Andeventhoughtheinstruc-
tor andthestudent relationsbothhavearity4,their4thattributes,namely,salaryand
tot cred, are of two differenttypes. The union of these two attributes would not make
senseinmostsituations.
Theintersectionoperation,denotedby∩,allowsustofindtuplesthatareinboth
theinputrelations.Theexpressionr∩sproducesarelationcontainingthosetuplesin
course id
CS-101
CS-315
CS-319
CS-347
FIN-201
HIS-351
MU-199
PHY-101
Figure 2.14 CoursesofferedineitherFall2017,Spring2018,orbothsemesters.

--- Page 84 ---

2.6 TheRelationalAlgebra 55
course id
CS-101
Figure 2.15 CoursesofferedinboththeFall2017andSpring2018semesters.
raswellasins.Aswiththeunionoperation,wemustensurethatintersectionisdone
betweencompatiblerelations.
SupposethatwewishtofindthesetofallcoursestaughtinboththeFall2017and
theSpring2018semesters.Usingsetintersection,wecanwrite
Π (σ (section))∩
courseid semester=“Fall”∧year=2017
Π (σ (section))
courseid semester=“Spring”∧year=2018
TheresultrelationforthisqueryappearsinFigure2.15.
Theset-differenceoperation,denotedby−,allowsustofindtuplesthatareinone
relation but are not in another. The expression r − s produces a relation containing
thosetuplesinr butnotins.
WecanfindallthecoursestaughtintheFall2017semesterbutnotinSpring2018
semesterbywriting:
Π (σ (section)) −
courseid semester=“Fall”∧year=2017
Π (σ (section))
courseid semester=“Spring”∧year=2018
TheresultrelationforthisqueryappearsinFigure2.16.
Aswiththeunionoperation,wemustensurethatsetdifferencesaretakenbetween
compatiblerelations.
2.6.7 The Assignment Operation
Itisconvenientattimestowritearelational-algebraexpressionbyassigningpartsofit
to temporary relation variables. The assignment operation, denoted by ←, works like
assignmentinaprogramminglanguage.Toillustratethisoperation,considerthequery
tofindcoursesthatrun inFall2017 aswellasSpring2018, whichwesawearlier.We
couldwriteitas:
course id
CS-347
PHY-101
Figure 2.16 CoursesofferedintheFall2017semesterbutnotinSpring2018
semester.

--- Page 85 ---

56 Chapter2 IntroductiontotheRelationalModel
courses fall 2017 ← Π (σ (section))
courseid semester=“Fall”∧year=2017
courses spring 2018← Π (σ (section))
courseid semester=“Spring”∧year=2018
courses fall 2017 ∩courses spring 2018
Thefinallineabovedisplaysthequeryresult.Theprecedingtwolinesassignthequery
resulttoatemporaryrelation.Theevaluationofanassignmentdoesnotresultinany
relationbeingdisplayedtotheuser.Rather,theresultoftheexpressiontotherightof
the ← is assigned to the relation variable on the left of the ←. This relation variable
maybeusedinsubsequentexpressions.
Withtheassignmentoperation,aquerycanbewrittenasasequentialprogramcon-
sisting of a series of assignments followed by an expression whose value is displayed
as the result of the query. For relational-algebra queries, assignment must always be
madetoatemporaryrelationvariable.Assignmentstopermanentrelationsconstitute
adatabasemodification.Notethattheassignmentoperationdoesnotprovideanyaddi-
tionalpowertothealgebra.Itis,however,aconvenientwaytoexpresscomplexqueries.
2.6.8 The Rename Operation
Unlike relations in the database, the results of relational-algebra expressions do not
have a name that we can use to refer to them. It is useful in some cases to give them
names;therenameoperator,denotedbythelowercaseGreekletterrho(ρ),letsusdo
this.Givenarelational-algebraexpressionE,theexpression
ρ (E)
x
returnstheresultofexpressionE underthenamex.
A relation r by itself is considered a (trivial) relational-algebra expression. Thus,
wecanalsoapplytherenameoperationtoarelationrtogetthesamerelationundera
newname. Somequeriesrequirethe samerelationtobe used morethanonceinthe
query; in such cases, the rename operation can be used to give unique names to the
differentoccurrencesofthesamerelation.
A second form of the rename operation is as follows: Assume that a relational-
algebraexpressionE hasarityn.Then,theexpression
ρ (E)
x(A ,A ,…,A )
1 2 n
returns the result of expression E underthe namex, and with the attributes renamed
to A ,A ,…,A . This form of the rename operation can be used to give names to
1 2 n
attributes in the results of relational algebra operations that involve expressions on
attributes.
Toillustraterenamingarelation,weconsiderthequery“FindtheIDandnameof
those instructors who earn more than the instructor whose ID is 12121.” (That’s the
instructorWuintheexampletableinFigure2.1.)
Thereare several strategies forwritingthisquery, but to illustrate therename op-
eration,ourstrategy istocomparethesalaryofeachinstructor withthesalaryofthe

--- Page 86 ---

2.6 TheRelationalAlgebra 57
Note 2.1 OTHERRELATIONALOPERATIONS
In addition to the relational algebra operations we have seen so far, there are a
numberofotheroperationsthatarecommonlyused.Wesummarizethembelow
anddescribethemindetaillater,alongwithequivalentSQLconstructs.
The aggregation operation allows a function to be computed over the set of
values returned by a query. These functions include average, sum, min, and max,
among others. The operation allows also for these aggregations to be performed
aftersplittingthesetofvaluesintogroups,forexample,bycomputingtheaverage
salary in each department. We study the aggregation operation in more detail in
Section3.7(Note3.2onpage97).
Thenaturaljoinoperationreplacesthepredicateθin⋈ withanimplicitpred-
θ
icate that requires equality over those attributes that appear in the schemas of
boththeleftandrightrelations.Thisisnotationallyconvenientbutposesrisksfor
queriesthatarereusedandthusmightbeusedafterarelation’sschemaischanged.
ItiscoveredinSection4.1.1.
Recall that when we computed the join of instructor and teaches, instructors
who have not taught any course do not appear in the join result. The outer join
operationallowsfortheretentionofsuchtuplesintheresultbyinsertingnullsfor
themissingvalues.ItiscoveredinSection4.1.3(Note4.1onpage136).
instructorwithID12121.Thedifficultyhereisthatweneedtoreferencetheinstructor
relation once to get the salary of each instructor and then a second time to get the
salary of instructor 12121; and we want to do all this in one expression. The rename
operatorallowsustodothisusingdifferentnamesforeachreferencingoftheinstructor
relation.Inthisexample, weshalluse thenamei torefertoourscan oftheinstructor
relationinwhichweareseekingthosethatwillbepartoftheanswer,andwtoreferto
thescanoftheinstructor relationtoobtainthesalaryofinstructor12121:
Π ((σ (ρ(instructor) × σ (ρ (instructor)))))
i.ID,i.name i.salary>w.salary i w.id=12121 w
Therenameoperationisnotstrictlyrequired,sinceitispossibletouseapositional
notationforattributes.Wecannameattributesofarelationimplicitlybyusingaposi-
tional notation, where $1, $2, … refer to the first attribute, the second attribute, and
so on. The positional notation can also be used to refer to attributes of the results of
relational-algebraoperations.However,thepositionalnotationisinconvenientforhu-
mans,sincethepositionoftheattributeisanumber,ratherthananeasy-to-remember
attributename.Hence,wedonotusethepositionalnotationinthistextbook.

--- Page 87 ---

58 Chapter2 IntroductiontotheRelationalModel
2.6.9 Equivalent Queries
Notethatthereisoftenmorethanonewaytowriteaqueryinrelationalalgebra.Con-
siderthefollowingquery,whichfindsinformationaboutcoursestaughtbyinstructors
inthePhysicsdepartment:
σ (instructor ⋈ teaches)
deptname=“Physics” instructor.ID=teaches.ID
Nowconsideranalternativequery:
(σ (instructor)) ⋈ teaches
deptname=“Physics” instructor.ID=teaches.ID
Note the subtle difference between the two queries: in the first query, the selection
thatrestrictsdept nametoPhysicsisappliedafterthejoinofinstructorandteacheshas
beencomputed,whereasinthesecondquery,theselectionthatrestrictsdeptnameto
Physicsisappliedtoinstructor,andthejoinoperationisappliedsubsequently.
Althoughthetwoqueriesarenotidentical,theyareinfactequivalent;thatis,they
givethesameresultonanydatabase.
Query optimizers in database systems typically look at what result an expression
computesandfindanefficientwayofcomputingthatresult,ratherthanfollowingthe
exact sequence of steps specified in the query. The algebraic structure of relational
algebramakesiteasytofindefficientbutequivalentalternativeexpressions,aswewill
seeinChapter16.
2.7 Summary
• The relational data model is based on a collection of tables. The user of the
database system may query these tables, insert new tuples, delete tuples, and up-
date(modify)tuples.Thereareseverallanguagesforexpressingtheseoperations.
• The schema of a relation refers to its logical design, while an instance of the re-
lation refers to its contents at a point in time. The schema of a database and an
instanceofadatabasearesimilarlydefined.Theschemaofarelationincludesits
attributes,andoptionallythetypesoftheattributesandconstraintsontherelation
suchasprimaryandforeign-keyconstraints.
• A superkey of a relation is a set of one or more attributes whose values are guar-
anteed to identify tuples in the relation uniquely. A candidate key is a minimal
superkey,thatis,asetofattributesthatformsasuperkey,butnoneofwhosesub-
setsisasuperkey.Oneofthecandidatekeysofarelationischosenasitsprimary
key.
• Aforeign-keyconstraintfromattribute(s)Aofrelationr totheprimary-keyBof
1
relationr states thatthevalue ofAforeachtupleinr mustalsobethevalueof
2 1
B for some tuple in r . The relation r is calledthe referencingrelation,and r is
2 1 2
calledthereferencedrelation.

--- Page 88 ---

PracticeExercises 59
• Aschemadiagramisapictorialdepictionoftheschemaofadatabasethatshows
therelationsinthedatabase,theirattributes,andprimarykeysandforeignkeys.
• Therelationalquerylanguagesdefineasetofoperationsthatoperateontablesand
outputtablesastheirresults.Theseoperationscanbecombinedtogetexpressions
thatexpressdesiredqueries.
• Therelationalalgebraprovidesasetofoperationsthattakeoneormorerelations
asinputandreturnarelationasanoutput.PracticalquerylanguagessuchasSQL
are based on the relational algebra, but they add a number of useful syntactic
features.
• Therelationalalgebradefinesasetofalgebraicoperationsthatoperateontables,
andoutputtablesastheirresults.Theseoperationscanbecombinedtogetexpres-
sions that express desired queries. The algebra defines the basic operations used
withinrelationalquerylanguageslikeSQL.
Review Terms
• Table • Referentialintegrityconstraint
• Relation • Schemadiagram
• Tuple • Querylanguagetypes
• Attribute ° Imperative
• Relationinstance
° Functional
• Domain
° Declarative
• Atomicdomain
• Nullvalue • Relationalalgebra
• Databaseschema • Relational-algebraexpression
• Databaseinstance • Relational-algebraoperations
• Relationschema ° Selectσ
• Keys ° ProjectΠ
° Superkey ° Cartesianproduct×
° Candidatekey ° Join⋈
° Primarykey ° Union∪
° Primarykeyconstraints ° Setdifference−
• Foreign-keyconstraint ° Setintersection∩
° Referencingrelation ° Assignment←
° Referencedrelation ° Renameρ

--- Page 89 ---

60 Chapter2 IntroductiontotheRelationalModel
employee(person name,street,city)
works(person name,company name,salary)
company(company name,city)
Figure 2.17 Employeedatabase.
Practice Exercises
2.1 Consider the employee database of Figure 2.17. What are the appropriate pri-
marykeys?
2.2 Considertheforeign-keyconstraintfromthedept nameattributeofinstructorto
thedepartmentrelation.Giveexamplesofinsertsanddeletestotheserelations
thatcancauseaviolationoftheforeign-keyconstraint.
2.3 Considerthetime slotrelation.Giventhataparticulartimeslotcanmeetmore
thanonceinaweek,explainwhydayandstart timearepartoftheprimarykey
ofthisrelation,whileend timeisnot.
2.4 In the instance of instructor shown in Figure 2.1, no two instructors have the
same name. From this, can we conclude that name can be used as a superkey
(orprimarykey)ofinstructor?
2.5 WhatistheresultoffirstperformingtheCartesianproductofstudentandadvi-
sor,andthenperformingaselectionoperationontheresultwiththepredicate
s id=ID?(Usingthesymbolicnotationofrelationalalgebra,thisquerycanbe
writtenasσ (student×advisor).)
sid=ID
2.6 ConsidertheemployeedatabaseofFigure2.17.Giveanexpressionintherela-
tionalalgebratoexpresseachofthefollowingqueries:
a. Findthenameofeachemployeewholivesincity“Miami”.
b. Findthenameofeachemployeewhosesalaryisgreaterthan$100000.
c. Findthenameofeachemployeewholivesin“Miami”andwhosesalary
isgreaterthan$100000.
2.7 ConsiderthebankdatabaseofFigure2.18.Giveanexpressionintherelational
algebraforeachofthefollowingqueries:
a. Findthenameofeachbranchlocatedin“Chicago”.
b. FindtheIDofeachborrowerwhohasaloaninbranch“Downtown”.

--- Page 90 ---

PracticeExercises 61
branch(branch name,branch city,assets)
customer (ID,customer name,customer street,customer city)
loan(loan number,branch name,amount)
borrower (ID,loan number)
account(account number,branch name,balance)
depositor (ID,account number)
Figure 2.18 Bankdatabase.
2.8 ConsidertheemployeedatabaseofFigure2.17.Giveanexpressionintherela-
tionalalgebratoexpresseachofthefollowingqueries:
a. FindtheIDandnameofeachemployeewhodoesnotworkfor“BigBank”.
b. Find the ID and name of each employee who earns at least as much as
everyemployeeinthedatabase.
2.9 The division operator of relational algebra, “÷”, is defined as follows. Let r(R)
and s(S) be relations, and let S ⊆ R; that is, every attribute of schema S is
also in schema R. Given a tuple t, let t[S] denote the projection of tuple t on
theattributes inS.Thenr ÷ sisarelationonschemaR − S (thatis,onthe
schemacontainingallattributesofschemaRthatarenotinschemaS).Atuple
tisinr ÷ sifandonlyifbothoftwoconditionshold:
• tisinΠ (r)
R−S
• Foreverytuplet ins,thereisatuplet inrsatisfyingbothofthefollowing:
s r
a.t [S] = t [S]
r s
b.t [R − S] = t
r
Giventheabovedefinition:
a. Write a relational algebra expression using the division operator to find
the IDs of all students who have taken all Comp. Sci. courses. (Hint:
project takes to just ID and course id, and generate the set of all Comp.
Sci.course idsusingaselectexpression,beforedoingthedivision.)
b. Show how to write the above query in relational algebra, without using
division.(Bydoingso,youwouldhaveshownhowtodefinethedivision
operationusingtheotherrelationalalgebraoperations.)

--- Page 91 ---

62 Chapter2 IntroductiontotheRelationalModel
Exercises
2.10 Describe the differences in meaning between the terms relation and relation
schema.
2.11 Considertheadvisor relationshownintheschemadiagraminFigure2.9,with
s id as the primary key of advisor. Suppose a student can have more than one
advisor. Then, would s id still be a primary key of the advisor relation? If not,
whatshouldtheprimarykeyofadvisor be?
2.12 ConsiderthebankdatabaseofFigure2.18.Assumethatbranchnamesandcus-
tomernamesuniquelyidentifybranchesandcustomers,butloansandaccounts
canbeassociatedwithmorethanonecustomer.
a. Whataretheappropriateprimarykeys?
b. Givenyourchoiceofprimarykeys,identifyappropriateforeignkeys.
2.13 ConstructaschemadiagramforthebankdatabaseofFigure2.18.
2.14 ConsidertheemployeedatabaseofFigure2.17.Giveanexpressionintherela-
tionalalgebratoexpresseachofthefollowingqueries:
a. FindtheIDandnameofeachemployeewhoworksfor“BigBank”.
b. FindtheID,name,andcityofresidenceofeachemployeewhoworksfor
“BigBank”.
c. FindtheID,name,streetaddress,andcityofresidenceofeachemployee
whoworksfor“BigBank”andearnsmorethan$10000.
d. FindtheIDandnameofeachemployeeinthisdatabasewholivesinthe
samecityasthecompanyforwhichsheorheworks.
2.15 ConsiderthebankdatabaseofFigure2.18.Giveanexpressionintherelational
algebraforeachofthefollowingqueries:
a. Findeachloannumberwithaloanamountgreaterthan$10000.
b. FindtheIDofeachdepositorwhohasanaccountwithabalancegreater
than$6000.
c. FindtheIDofeachdepositorwhohasanaccountwithabalancegreater
than$6000atthe“Uptown”branch.
2.16 Listtworeasonswhynullvaluesmightbeintroducedintoadatabase.
2.17 Discusstherelativemeritsofimperative,functional,anddeclarativelanguages.
2.18 Writethefollowingqueriesinrelationalalgebra,usingtheuniversityschema.
a. FindtheIDandnameofeachinstructorinthePhysicsdepartment.

--- Page 92 ---

FurtherReading 63
b. FindtheID and nameof eachinstructor in adepartmentlocated inthe
building“Watson”.
c. FindtheIDandnameofeachstudentwhohastakenatleastonecourse
inthe“Comp.Sci.”department.
d. FindtheIDandnameofeachstudentwhohastakenatleastonecourse
sectionintheyear2018.
e. Find the ID and name of each student who has not taken any course
sectionintheyear2018.
Further Reading
E. F. Codd of the IBM San Jose Research Laboratory proposed the relational model
in the late 1960s ([Codd (1970)]). In that paper, Codd also introduced the original
definitionofrelationalalgebra.ThisworkledtotheprestigiousACMTuringAwardto
Coddin1981([Codd(1982)]).
AfterE.F.Coddintroducedtherelationalmodel,anexpansive theorydeveloped
around therelationalmodelpertainingtoschemadesignandtheexpressive powerof
various relational languages. Several classic texts cover relational database theory, in-
cluding[Maier(1983)](whichisavailablefree,online),and[Abitebouletal.(1995)].
Codd’s original paper inspired several research projects that were formed in the
mid to late 1970s with the goal of constructing practical relational database systems,
includingSystemRattheIBMSanJoseResearchLaboratory,IngresattheUniversity
of California at Berkeley, and Query-by-Example at the IBM T. J. Watson Research
Center.TheOracledatabasewasdevelopedcommerciallyatthesametime.
Manyrelationaldatabaseproductsarenowcommerciallyavailable.Theseinclude
IBM’sDB2and Informix,Oracle,MicrosoftSQL Server, and Sybase and HANAfrom
SAP.Popularopen-sourcerelationaldatabasesystemsincludeMySQLandPostgreSQL.
Hive and Spark are widely used systems that support parallel execution of queries
acrosslargenumbersofcomputers.
Bibliography
[Abitebouletal.(1995)] S.Abiteboul,R.Hull,andV.Vianu,FoundationsofDatabases,Ad-
disonWesley(1995).
[Codd(1970)] E.F.Codd,“ARelationalModelforLargeSharedDataBanks”,Communi-
cationsoftheACM,Volume13,Number6(1970),pages377–387.
[Codd(1982)] E.F.Codd,“The1981ACMTuringAwardLecture:RelationalDatabase:A
PracticalFoundationforProductivity”,CommunicationsoftheACM,Volume25,Number2
(1982),pages109–117.

--- Page 93 ---

64 Chapter2 IntroductiontotheRelationalModel
[Maier(1983)] D. Maier, The Theory of Relational Databases, Computer Science Press
(1983).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 94 ---

3
CHAPTER
Introduction to SQL
Inthischapter,aswellasinChapter4andChapter5,westudythemostwidelyused
databasequerylanguage,SQL.
AlthoughwerefertotheSQLlanguageasa“querylanguage,”itcandomuchmore
than just query a database. It can define the structure of the data, modify data in the
database,andspecifysecurityconstraints.
Itisnotourintentiontoprovideacompleteusers’guideforSQL.Rather,wepresent
SQL’sfundamentalconstructsandconcepts.IndividualimplementationsofSQLmay
differindetailsormaysupportonlyasubsetofthefulllanguage.
WestronglyencourageyoutotryouttheSQLqueriesthatwedescribehereonanactual
database.SeetheToolssectionattheendofthischapterfortipsonwhatdatabasesys-
temsyoucoulduse,andhowtocreatetheschema,populatesampledata,andexecute
yourqueries.
3.1 Overview of the SQL Query Language
IBM developed the original version of SQL, originally called Sequel, as part of the
SystemRprojectintheearly1970s.TheSequellanguagehasevolvedsincethen,andits
namehaschangedtoSQL(StructuredQueryLanguage).Manyproductsnowsupport
theSQLlanguage.SQLhasclearlyestablisheditselfasthestandardrelationaldatabase
language.
In1986,theAmericanNationalStandardsInstitute(ANSI)andtheInternational
Organization for Standardization (ISO) published an SQL standard, called SQL-86.
ANSIpublishedanextendedstandardforSQL,SQL-89,in1989.Thenextversionofthe
standardwasSQL-92standard,followedbySQL:1999,SQL:2003,SQL:2006,SQL:2008,
SQL:2011,andmostrecentlySQL:2016.
TheSQLlanguagehasseveralparts:
• Data-definition language (DDL). The SQL DDL provides commands for defining
relationschemas,deletingrelations,andmodifyingrelationschemas.
65

--- Page 95 ---

66 Chapter3 IntroductiontoSQL
• Data-manipulation language (DML). The SQL DML provides the ability to query
information from the database and to insert tuples into, delete tuples from, and
modifytuplesinthedatabase.
• Integrity. The SQL DDL includes commands for specifying integrity constraints
that the data stored in the database must satisfy. Updates that violate integrity
constraintsaredisallowed.
• Viewdefinition.TheSQLDDLincludescommandsfordefiningviews.
• Transactioncontrol.SQLincludescommandsforspecifyingthebeginningandend
pointsoftransactions.
• Embedded SQL and dynamic SQL. Embedded and dynamic SQL define how SQL
statementscanbeembeddedwithingeneral-purposeprogramminglanguages,such
asC,C++,andJava.
• Authorization. The SQL DDL includes commands for specifying access rights to
relationsandviews.
In this chapter, we present a survey of basic DML and the DDL features of SQL.
FeaturesdescribedherehavebeenpartoftheSQLstandardsinceSQL-92.
In Chapter 4, we provide a more detailed coverage of the SQL query language,
including (a) various join expressions, (b) views, (c) transactions, (d) integrity con-
straints,(e)typesystem,and(f)authorization.
InChapter5,wecovermoreadvancedfeaturesoftheSQLlanguage,including(a)
mechanismstoallowaccessingSQLfromaprogramminglanguage,(b)SQLfunctions
andprocedures,(c)triggers,(d)recursivequeries,(e)advancedaggregationfeatures,
and(f)severalfeaturesdesignedfordataanalysis.
Although most SQL implementations support the standard features we describe
here, there are differences between implementations. Most implementations support
somenonstandardfeatureswhileomittingsupportforsomeofthemoreadvancedand
morerecentfeatures.Incaseyoufindthatsomelanguagefeaturesdescribedheredonot
workonthedatabasesystemthatyouuse,consulttheusermanualsforyourdatabase
systemtofindexactlywhatfeaturesitsupports.
3.2 SQL Data Definition
Thesetofrelationsinadatabasearespecifiedusingadata-definitionlanguage(DDL).
The SQLDDL allowsspecification ofnotonlyasetofrelations,but alsoinformation
abouteachrelation,including:
• Theschemaforeachrelation.
• Thetypesofvaluesassociatedwitheachattribute.

--- Page 96 ---

3.2 SQLDataDefinition 67
• Theintegrityconstraints.
• Thesetofindicestobemaintainedforeachrelation.
• Thesecurityandauthorizationinformationforeachrelation.
• Thephysicalstoragestructureofeachrelationondisk.
We discuss here basic schema definition and basic types; we defer discussion of the
otherSQLDDLfeaturestoChapter4andChapter5.
3.2.1 Basic Types
TheSQLstandardsupportsavarietyofbuilt-intypes,including:
• char(n):Afixed-lengthcharacterstringwithuser-specifiedlengthn.Thefullform,
character,canbeusedinstead.
• varchar(n):Avariable-lengthcharacterstringwithuser-specifiedmaximumlength
n.Thefullform,charactervarying,isequivalent.
• int:Aninteger(afinitesubsetoftheintegersthatismachinedependent).Thefull
form,integer,isequivalent.
• smallint:Asmallinteger(amachine-dependentsubsetoftheintegertype).
• numeric(p,d): A fixed-point number with user-specified precision. The number
consistsofpdigits(plusasign),anddofthepdigitsaretotherightofthedecimal
point. Thus, numeric(3,1) allows 44.5 to be stored exactly, but neither 444.5 nor
0.32canbestoredexactlyinafieldofthistype.
• real,doubleprecision:Floating-pointanddouble-precisionfloating-pointnumbers
withmachine-dependentprecision.
• float(n):Afloating-pointnumberwithprecisionofatleastndigits.
AdditionaltypesarecoveredinSection4.5.
Eachtypemayincludeaspecialvaluecalledthenullvalue.Anullvalueindicates
an absent value thatmayexist but be unknown or thatmaynotexist at all.Incertain
cases,wemaywishtoprohibitnullvaluesfrombeingentered,asweshallseeshortly.
The char data type stores fixed-lengthstrings. Consider, forexample, an attribute
A of type char(10). If we stored a string “Avi” in this attribute, seven spaces are ap-
pended to the string to make it 10 characters long. In contrast, if attribute B were of
typevarchar(10),andwestored“Avi”inattributeB,nospaceswouldbeadded.When
comparingtwovaluesoftypechar,iftheyareofdifferentlengths,extraspacesareau-
tomaticallyattachedtotheshorteronetomakethemthesamesizebeforecomparison.
Whencomparingachar type withavarchartype, onemayexpectextraspaces to
be added to the varchar type to make the lengths equal, before comparison; however,
this may or may not be done, depending on the database system. As a result, even if

--- Page 97 ---

68 Chapter3 IntroductiontoSQL
thesamevalue“Avi”isstoredintheattributesAandBabove,acomparisonA=Bmay
return false. We recommend you always use the varchar type instead of the char type
toavoidtheseproblems.
SQL also provides the nvarchar type to store multilingual data using the Unicode
representation.However,manydatabasesallowUnicode(intheUTF-8representation)
tobestoredeveninvarchartypes.
3.2.2 Basic Schema Definition
WedefineanSQLrelationbyusingthecreatetablecommand.Thefollowingcommand
createsarelationdepartmentinthedatabase:
createtabledepartment
(dept name varchar(20),
building varchar(15),
budget numeric(12,2),
primarykey(dept name));
Therelationcreatedabovehasthreeattributes,dept name,whichisacharacterstring
of maximum length 20, building, which is a character string of maximum length 15,
and budget, whichis anumber with 12 digitsin total, two of whichare after the deci-
malpoint.Thecreatetablecommandalsospecifiesthatthedept nameattributeisthe
primarykeyofthedepartmentrelation.
Thegeneralformofthecreatetablecommandis:
createtabler
(A D ,
1 1
A D ,
2 2
...,
A D ,
n n
⟨integrity-constraint ⟩,
1
…,
⟨integrity-constraint ⟩);
k
whereristhenameoftherelation,eachA isthenameofanattributeintheschemaof
i
relationr,andD isthedomainofattributeA;thatis,D specifiesthetypeofattribute
i i i
A alongwithoptionalconstraintsthatrestrictthesetofallowedvaluesforA.
i i
Thesemicolonshownattheendofthecreatetablestatements,aswellasattheend
ofotherSQLstatementslaterinthischapter,isoptionalinmanySQLimplementations.
SQLsupportsanumberofdifferentintegrityconstraints.Inthissection,wediscuss
onlyafewofthem:
• primary key (A ,A ,…,A ): The primary-key specification says that attributes
j j j
A ,A ,…,A f 1 orm 2 the pri m mary key for the relation. The primary-key attributes
j j j
1 2 m

--- Page 98 ---

3.2 SQLDataDefinition 69
are required to be nonnull and unique; that is, no tuple can have a null value for
a primary-key attribute, and no two tuples in the relation can be equal on all the
primary-keyattributes.Althoughtheprimary-keyspecificationisoptional,itisgen-
erallyagoodideatospecifyaprimarykeyforeachrelation.
• foreign key (A ,A ,…,A ) references s: The foreign key specification says that
k k k
thevaluesofat 1 tribu 2 tes (A n ,A ,…,A )foranytupleintherelationmustcorre-
k k k
1 2 n
spondtovaluesoftheprimarykeyattributesofsometupleinrelations.
Figure3.1presentsapartialSQLDDLdefinitionoftheuniversitydatabasewe
use in the text. The definition of the course table has a declaration “foreign key
(dept name)referencesdepartment”.Thisforeign-keydeclarationspecifiesthatfor
eachcoursetuple,thedepartmentnamespecifiedinthetuplemustexistinthepri-
marykeyattribute(dept name)ofthedepartmentrelation.Withoutthisconstraint,
it is possible for a course to specify a nonexistent department name. Figure 3.1
also shows foreign-key constraints on tables section, instructor and teaches. Some
database systems, including MySQL, require an alternative syntax, “foreign key
(dept name) references department(dept name)”, where the referenced attributes
inthereferencedtablearelistedexplicitly.
• notnull:Thenotnullconstraintonanattributespecifiesthatthenullvalueisnot
allowed for that attribute; in other words, the constraint excludes the null value
from the domain of that attribute. For example, in Figure 3.1, the not null con-
straintonthenameattributeoftheinstructorrelationensuresthatthenameofan
instructorcannotbenull.
Moredetailsontheforeign-keyconstraint,aswellasonotherintegrityconstraintsthat
thecreatetablecommandmayinclude,areprovidedlater,inSection4.4.
SQLpreventsanyupdatetothedatabasethatviolatesanintegrityconstraint.For
example, if a newly inserted or modified tuple in a relation has null values for any
primary-keyattribute, orifthetuplehasthesamevalueontheprimary-keyattributes
asdoesanothertupleintherelation,SQLflagsanerrorandpreventstheupdate.Sim-
ilarly, an insertion of a course tuple with a dept name value that does not appear in
the department relation would violate the foreign-key constraint on course, and SQL
preventssuchaninsertionfromtakingplace.
Anewlycreatedrelationisemptyinitially.Insertingtuplesintoarelation,updating
them,anddeletingthemaredonebydatamanipulationstatementsinsert,update,and
delete,whicharecoveredinSection3.9.
To remove a relation from an SQL database, we use the drop table command.
The droptable commanddeletesallinformation about the dropped relationfrom the
database.Thecommand
droptabler;
isamoredrasticactionthan

--- Page 99 ---

70 Chapter3 IntroductiontoSQL
createtabledepartment
(dept name varchar(20),
building varchar(15),
budget numeric(12,2),
primarykey(dept name));
createtablecourse
(course id varchar(7),
title varchar(50),
dept name varchar(20),
credits numeric(2,0),
primarykey(course id),
foreignkey(dept name)referencesdepartment);
createtableinstructor
(ID varchar(5),
name varchar(20)notnull,
dept name varchar(20),
salary numeric(8,2),
primarykey(ID),
foreignkey(dept name)referencesdepartment);
createtablesection
(course id varchar(8),
sec id varchar(8),
semester varchar(6),
year numeric(4,0),
building varchar(15),
room number varchar(7),
time slot id varchar(4),
primarykey(course id,sec id,semester,year),
foreignkey(course id)referencescourse);
createtableteaches
(ID varchar(5),
course id varchar(8),
sec id varchar(8),
semester varchar(6),
year numeric(4,0),
primarykey(ID,course id,sec id,semester,year),
foreignkey(course id,sec id,semester,year)referencessection,
foreignkey(ID)referencesinstructor);
Figure 3.1 SQLdatadefinitionforpartoftheuniversitydatabase.

--- Page 100 ---

3.3 BasicStructureofSQLQueries 71
deletefromr;
Thelatterretainsrelationr,butdeletesalltuplesinr.Theformerdeletesnotonlyall
tuplesofr,butalsotheschemaforr.Afterrisdropped,notuplescanbeinsertedinto
r unlessitisre-createdwiththecreatetablecommand.
Weusethealtertablecommandtoaddattributestoanexistingrelation.Alltuples
intherelationareassignednullasthevalueforthenewattribute.Theformofthealter
tablecommandis
altertabler addAD;
wherer isthenameofanexistingrelation,Aisthenameoftheattributetobeadded,
andDisthetypeoftheaddedattribute.Wecandropattributesfromarelationbythe
command
altertabler dropA;
where r is the name of an existing relation, and A is the name of an attribute of the
relation.Manydatabasesystemsdonotsupportdroppingofattributes,althoughthey
willallowanentiretabletobedropped.
3.3 Basic Structure of SQL Queries
ThebasicstructureofanSQLqueryconsistsofthreeclauses:select,from,andwhere.
A query takes as its input the relations listed in the from clause, operates on them as
specifiedinthewhereandselectclauses,andthenproducesarelationastheresult.We
introducetheSQL syntax throughexamples, and wedescribethegeneral structure of
SQLquerieslater.
3.3.1 Queries on a Single Relation
Letusconsiderasimplequeryusingouruniversityexample,“Findthenamesofallin-
structors.”Instructornamesarefoundintheinstructorrelation,soweputthatrelation
inthefromclause.Theinstructor’snameappearsinthenameattribute,soweputthat
intheselectclause.
selectname
frominstructor;
The result is a relation consisting of a single attribute with the heading name. If the
instructor relation is as shown in Figure 2.1, then the relation that results from the
precedingqueryisshowninFigure3.2.

--- Page 101 ---

72 Chapter3 IntroductiontoSQL
name
Srinivasan
Wu
Mozart
Einstein
ElSaid
Gold
Katz
Califieri
Singh
Crick
Brandt
Kim
Figure 3.2 Resultof“selectnamefrominstructor”.
Now consider another query, “Find the department names of all instructors,”
whichcanbewrittenas:
selectdept name
frominstructor;
Sincemorethanoneinstructorcanbelongtoadepartment,adepartmentnamecould
appear more than once in the instructor relation. The result of the above query is a
relationcontainingthedepartmentnames,showninFigure3.3.
In the formal, mathematical definition of the relational model, a relation is a set.
Thus,duplicatetupleswouldneverappearinrelations.Inpractice,duplicateelimina-
tionistime-consuming.Therefore,SQLallowsduplicatesindatabaserelationsaswell
asintheresultsofSQLexpressions.1 Thus,theprecedingSQLquerylistseachdepart-
mentnameonceforeverytupleinwhichitappearsintheinstructor relation.
Inthosecaseswherewewanttoforcetheeliminationofduplicates,weinsertthe
keyworddistinctafterselect.Wecanrewritetheprecedingqueryas:
selectdistinctdept name
frominstructor;
if we want duplicates removed. The result of the above query would contain each de-
partmentnameatmostonce.
1Anydatabaserelationwhoseschemaincludesaprimary-keydeclarationcannotcontainduplicatetuples,sincethey
wouldviolatetheprimary-keyconstraint.

--- Page 102 ---

3.3 BasicStructureofSQLQueries 73
dept name
Comp.Sci.
Finance
Music
Physics
History
Physics
Comp.Sci.
History
Finance
Biology
Comp.Sci.
Elec.Eng.
Figure 3.3 Resultof“selectdeptnamefrominstructor”.
SQL allows us to use the keyword all to specify explicitly that duplicates are not
removed:
selectalldept name
frominstructor;
Sinceduplicateretentionisthedefault,weshallnotuseallinourexamples.Toensure
theeliminationofduplicatesintheresultsofourexamplequeries,weshallusedistinct
wheneveritisnecessary.
Theselectclausemayalsocontainarithmeticexpressionsinvolvingtheoperators
+,−,∗,and/operatingonconstantsorattributesoftuples.Forexample,thequery:
selectID,name,dept name,salary*1.1
frominstructor;
returns a relation that is the same as the instructor relation, except that the attribute
salaryismultipliedby1.1.Thisshowswhatwouldresultifwegavea10%raisetoeach
instructor;note,however,thatitdoesnotresultinanychangetotheinstructorrelation.
SQL also provides special data types, such as various forms of the date type, and
allows several arithmetic functions to operate on these types. We discuss this further
inSection4.5.1.
Thewhereclauseallowsustoselectonlythoserowsintheresultrelationofthefrom
clausethatsatisfyaspecifiedpredicate.Considerthequery“Findthenamesofallin-
structorsintheComputerSciencedepartmentwhohavesalarygreaterthan$70,000.”
ThisquerycanbewritteninSQLas:

--- Page 103 ---

74 Chapter3 IntroductiontoSQL
name
Katz
Brandt
Figure 3.4 Resultof“FindthenamesofallinstructorsintheComputerScience
departmentwhohavesalarygreaterthan$70,000.”
selectname
frominstructor
wheredept name='Comp.Sci.'andsalary>70000;
If the instructor relation is as shown in Figure 2.1, then the relation that results from
theprecedingqueryisshowninFigure3.4.
SQLallowstheuseofthelogicalconnectivesand,or,andnotinthewhereclause.
Theoperandsofthelogicalconnectivescanbe expressionsinvolvingthecomparison
operators <, <=, >, >=, =, and <>. SQL allows us to use the comparison operators
to compare strings and arithmetic expressions, as well as special types, such as date
types.
Weshallexploreotherfeaturesofwhereclausepredicateslaterinthischapter.
3.3.2 Queries on Multiple Relations
So far our example queries were on a single relation. Queries often need to access
informationfrommultiplerelations.Wenowstudyhowtowritesuchqueries.
As an example, suppose we want to answer the query “Retrieve the names of all
instructors,alongwiththeirdepartmentnamesanddepartmentbuildingname.”
Looking at the schema of the relation instructor, we realize that we can get the
department name from the attribute dept name, but the department building name is
presentintheattributebuilding oftherelationdepartment.Toanswerthequery,each
tupleintheinstructorrelationmustbematchedwiththetupleinthedepartmentrelation
whosedept namevaluematchesthedept namevalueoftheinstructor tuple.
In SQL, to answer the above query, we list the relations that need to be accessed
inthefromclauseandspecifythematchingconditioninthewhereclause.Theabove
querycanbewritteninSQLas
selectname,instructor.dept name,building
frominstructor,department
whereinstructor.dept name=department.dept name;
If the instructor and department relations are as shown in Figure 2.1 and Figure 2.5
respectively,thentheresultofthisqueryisshowninFigure3.5.
Note that the attribute dept name occurs in both the relations instructor and de-
partment, and the relation name is used as a prefix (in instructor.dept name, and de-

--- Page 104 ---

3.3 BasicStructureofSQLQueries 75
name dept name building
Srinivasan Comp.Sci. Taylor
Wu Finance Painter
Mozart Music Packard
Einstein Physics Watson
ElSaid History Painter
Gold Physics Watson
Katz Comp.Sci. Taylor
Califieri History Painter
Singh Finance Painter
Crick Biology Watson
Brandt Comp.Sci. Taylor
Kim Elec.Eng. Taylor
Figure 3.5 Theresultof“Retrievethenamesofallinstructors,alongwiththeir
departmentnamesanddepartmentbuildingname.”
partment.dept name)tomakecleartowhichattributewearereferring.Incontrast,the
attributes nameand building appear in onlyone of the relationsand thereforedo not
needtobeprefixedbytherelationname.
This naming convention requires that the relations that are present in the from
clause have distinctnames. Thisrequirementcauses problemsin some cases, suchas
wheninformationfromtwodifferenttuplesinthesamerelationneedstobecombined.
InSection3.4.1,weseehowtoavoidtheseproblemsbyusingtherenameoperation.
WenowconsiderthegeneralcaseofSQLqueriesinvolvingmultiplerelations.As
wehaveseenearlier,anSQLquerycancontainthreetypesofclauses,theselectclause,
thefromclause,andthewhereclause.Theroleofeachclauseisasfollows:
• Theselectclauseisusedtolisttheattributesdesiredintheresultofaquery.
• The from clause is a list of the relations to be accessed in the evaluation of the
query.
• The where clause is a predicate involving attributes of the relation in the from
clause.
AtypicalSQLqueryhastheform:
selectA , A ,…,A
1 2 n
fromr , r ,…,r
1 2 m
whereP;

--- Page 105 ---

76 Chapter3 IntroductiontoSQL
Each A represents an attribute, and each r a relation. P is a predicate. If the where
i i
clauseisomitted,thepredicateP istrue.
Although the clauses must be written in the order select, from, where, the easiest
way to understand the operations specified by the query is to consider the clauses in
operationalorder:firstfrom,thenwhere,andthenselect.2
ThefromclausebyitselfdefinesaCartesian productof therelationslistedinthe
clause.Itisdefinedformallyintermsofrelationalalgebra,butitcanalsobeunderstood
asaniterativeprocessthatgeneratestuplesfortheresultrelationofthefromclause.
foreachtuplet inrelationr
1 1
foreachtuplet inrelationr
2 2
…
foreachtuplet inrelationr
m m
Concatenatet , t ,…,t intoasingletuplet
1 2 m
Addtintotheresultrelation
Theresultrelationhasallattributesfromalltherelationsinthefromclause.Sincethe
sameattributenamemayappearinbothr andr,aswesawearlier,weprefixthename
i j
oftherelationfromwhichtheattributeoriginallycame,beforetheattributename.
Forexample,therelationschemafortheCartesianproductofrelationsinstructor
andteachesis:
(instructor.ID,instructor.name,instructor.dept name,instructor.salary,
teaches.ID,teaches.course id,teaches.sec id,teaches.semester,teaches.year)
Withthisschema,wecandistinguishinstructor.IDfromteaches.ID.Forthoseattributes
that appear in only one of the two schemas, we shall usually drop the relation-name
prefix.Thissimplificationdoesnotleadtoanyambiguity.Wecanthenwritetherelation
schemaas:
(instructor.ID,name,dept name,salary,teaches.ID,course id,sec id,semester,year)
Toillustrate,considertheinstructor relationinFigure2.1andtheteachesrelation
in Figure 2.7. Their Cartesian product is shown in Figure 3.6, which includes only a
portionofthetuplesthatmakeuptheCartesianproductresult.
The Cartesian product by itself combines tuples from instructor and teaches that
are unrelated to each other. Each tuple in instructor is combined with every tuple in
teaches, even those that refer to a different instructor. The result can be an extremely
largerelation,anditrarelymakessensetocreatesuchaCartesianproduct.
2Inpractice,SQLmayconverttheexpressionintoanequivalentformthatcanbeprocessedmoreefficiently.However,
weshalldeferconcernsaboutefficiencytoChapter15andChapter16.

--- Page 106 ---

3.3 BasicStructureofSQLQueries 77
instructor.ID name deptname salary teaches.ID courseid secid semester year
10101 Srinivasan Comp.Sci. 65000 10101 CS-101 1 Fall 2017
10101 Srinivasan Comp.Sci. 65000 10101 CS-315 1 Spring 2018
10101 Srinivasan Comp.Sci. 65000 10101 CS-347 1 Fall 2017
10101 Srinivasan Comp.Sci. 65000 12121 FIN-201 1 Spring 2018
10101 Srinivasan Comp.Sci. 65000 15151 MU-199 1 Spring 2018
10101 Srinivasan Comp.Sci. 65000 22222 PHY-101 1 Fall 2017
... ... ... ... ... ... ... ... ...
... ... ... ... ... ... ... ... ...
12121 Wu Finance 90000 10101 CS-101 1 Fall 2017
12121 Wu Finance 90000 10101 CS-315 1 Spring 2018
12121 Wu Finance 90000 10101 CS-347 1 Fall 2017
12121 Wu Finance 90000 12121 FIN-201 1 Spring 2018
12121 Wu Finance 90000 15151 MU-199 1 Spring 2018
12121 Wu Finance 90000 22222 PHY-101 1 Fall 2017
... ... ... ... ... ... ... ... ...
... ... ... ... ... ... ... ... ...
15151 Mozart Music 40000 10101 CS-101 1 Fall 2017
15151 Mozart Music 40000 10101 CS-315 1 Spring 2018
15151 Mozart Music 40000 10101 CS-347 1 Fall 2017
15151 Mozart Music 40000 12121 FIN-201 1 Spring 2018
15151 Mozart Music 40000 15151 MU-199 1 Spring 2018
15151 Mozart Music 40000 22222 PHY-101 1 Fall 2017
... ... ... ... ... ... ... ... ...
... ... ... ... ... ... ... ... ...
22222 Einstein Physics 95000 10101 CS-101 1 Fall 2017
22222 Einstein Physics 95000 10101 CS-315 1 Spring 2018
22222 Einstein Physics 95000 10101 CS-347 1 Fall 2017
22222 Einstein Physics 95000 12121 FIN-201 1 Spring 2018
22222 Einstein Physics 95000 15151 MU-199 1 Spring 2018
22222 Einstein Physics 95000 22222 PHY-101 1 Fall 2017
... ... ... ... ... ... ... ... ...
... ... ... ... ... ... ... ... ...
Figure 3.6 TheCartesianproductoftheinstructor relationwiththeteachesrelation.
Instead,thepredicateinthewhereclauseisusedtorestrictthecombinationscre-
atedbytheCartesianproducttothosethataremeaningfulforthedesiredanswer.We
would likely want a query involving instructor and teaches to combine a particular tu-
plet ininstructor withonlythosetuplesinteachesthatrefertothesameinstructorto
whichtrefers.Thatis,wewishonlytomatchteachestupleswithinstructor tuplesthat
have the same ID value. The following SQL query ensures this condition and outputs
theinstructornameandcourseidentifiersfromsuchmatchingtuples.
selectname,course id
frominstructor,teaches
whereinstructor.ID=teaches.ID;

--- Page 107 ---

78 Chapter3 IntroductiontoSQL
name course id
Srinivasan CS-101
Srinivasan CS-315
Srinivasan CS-347
Wu FIN-201
Mozart MU-199
Einstein PHY-101
ElSaid HIS-351
Katz CS-101
Katz CS-319
Crick BIO-101
Crick BIO-301
Brandt CS-190
Brandt CS-190
Brandt CS-319
Kim EE-181
Figure 3.7 Resultof“Forallinstructorsintheuniversitywhohavetaughtsome
course,findtheirnamesandthecourseIDofallcoursestheytaught.”
Notethattheprecedingqueryoutputsonlyinstructorswhohavetaughtsomecourse.
Instructors whohave not taught any course are not output; if we wish to output such
tuples, we could use an operation called the outer join, which is described in Section
4.1.3.
If the instructor relation is as shown in Figure 2.1 and the teaches relation is as
shown inFigure2.7, then the relationthatresultsfrom the precedingquery isshown
inFigure3.7.ObservethatinstructorsGold,Califieri,andSingh,whohavenottaught
anycourse,donotappearinFigure3.7.
If we wished to find only instructor names and course identifiers for instructors
in the Computer Science department, we could add an extra predicate to the where
clause,asshownbelow.
selectname,course id
frominstructor,teaches
whereinstructor.ID=teaches.IDandinstructor.dept name='Comp.Sci.';
Notethatsincethedept nameattributeoccursonlyintheinstructorrelation,wecould
haveusedjustdept name,insteadofinstructor.dept nameintheabovequery.
Ingeneral,themeaningofanSQLquerycanbeunderstoodasfollows:
1. GenerateaCartesianproductoftherelationslistedinthefromclause.
2. ApplythepredicatesspecifiedinthewhereclauseontheresultofStep1.

--- Page 108 ---

3.4 AdditionalBasicOperations 79
3. ForeachtupleintheresultofStep2,outputtheattributes(orresultsofexpres-
sions)specifiedintheselectclause.
ThissequenceofstepshelpsmakeclearwhattheresultofanSQLqueryshouldbe,not
howitshouldbeexecuted.ArealimplementationofSQLwouldnotexecutethequery
inthisfashion;itwouldinstead optimizeevaluation bygenerating(asfaraspossible)
only elements of the Cartesian product that satisfy the where clause predicates. We
studysuchimplementationtechniquesinChapter15andChapter16.
When writing queries, you should be careful to include appropriate where clause
conditions.IfyouomitthewhereclauseconditionintheprecedingSQLquery,itwill
outputtheCartesianproduct,whichcouldbeahugerelation.Fortheexampleinstruc-
torrelationinFigure2.1andtheexampleteachesrelationinFigure2.7,theirCartesian
producthas12 ∗ 13 = 156tuples—morethanwecanshow inthetext!Tomakemat-
ters worse, suppose we have a more realistic number of instructors than we show in
our sample relations in the figures, say 200 instructors. Let’s assume each instructor
teachesthreecourses,sowehave600tuplesintheteachesrelation.Thenthepreceding
iterativeprocessgenerates200 ∗ 600 = 120,000tuplesintheresult.
3.4 Additional Basic Operations
AnumberofadditionalbasicoperationsaresupportedinSQL.
3.4.1 The Rename Operation
Consideragainthequerythatweusedearlier:
selectname,course id
frominstructor,teaches
whereinstructor.ID=teaches.ID;
Theresultofthisqueryisarelationwiththefollowingattributes:
name,course id
Thenamesoftheattributes in theresultarederivedfrom thenamesoftheattributes
intherelationsinthefromclause.
Wecannot,however,alwaysderivenamesinthisway,forseveralreasons:First,two
relationsinthefromclausemayhaveattributeswiththesamename,inwhichcasean
attributenameisduplicatedintheresult.Second,ifweuseanarithmeticexpressionin
theselectclause,theresultantattributedoesnothaveaname.Third,evenifanattribute
namecanbederivedfromthebaserelationsasintheprecedingexample,wemaywant
tochangetheattributenameintheresult.Hence,SQLprovidesawayofrenamingthe
attributesofaresultrelation.Itusestheasclause,takingtheform:

--- Page 109 ---

80 Chapter3 IntroductiontoSQL
Note 3.1 SQLANDMULTISETRELATIONALALGEBRA-PART1
There is a close connection between relational algebra operations and SQL op-
erations. One key difference is that, unlike the relational algebra, SQL allows du-
plicates. The SQL standard defines how many copies of each tuple are there in
the output of a query, which depends, in turn, on how many copies of tuples are
presentintheinputrelations.
TomodelthisbehaviorofSQL,aversionofrelationalalgebra,calledthemul-
tisetrelationalalgebra,isdefinedtoworkonmultisets:setsthatmaycontaindupli-
cates.Thebasicoperationsinthemultisetrelationalalgebraaredefinedasfollows:
1. If there are c copies of tuple t in r , and t satisfies selection σ , then
1 1 1 1 θ
therearec copiesoft inσ (r ).
1 1 θ 1
2. Foreachcopyof tuple t in r , thereisa copyof tupleΠ (t ) in Π (r ),
1 1 A 1 A 1
whereΠ (t )denotestheprojectionofthesingletuplet .
A 1 1
3. Iftherearec copiesoftuplet inr andc copiesoftuplet inr ,there
1 1 1 2 2 2
arec ∗ c copiesofthetuplet .t inr ×r .
1 2 1 2 1 2
Forexample,supposethatrelationsr withschema(A,B)andr withschema
1 2
(C)arethefollowingmultisets:r = {(1,a),(2,a)}andr = {(2),(3),(3)}.Then
1 2
Π (r )wouldbe{(a),(a)},whereasΠ (r )×r wouldbe:
B 1 B 1 2
{(a,2),(a,2),(a,3),(a,3),(a,3),(a,3)}
NowconsiderabasicSQLqueryoftheform:
selectA , A ,…,A
1 2 n
fromr , r ,…,r
1 2 m
whereP
EachA representsanattribute,andeachr arelation.Pisapredicate.Ifthewhere
i i
clause is omitted, the predicate P is true. The query is equivalent to the multiset
relational-algebraexpression:
Π (σ (r × r × ⋯ × r ))
A ,A ,…,A P 1 2 m
1 2 n
The relational algebra select operation corresponds to the SQL where clause,
nottotheSQLselectclause;thedifferenceinmeaningisanunfortunatehistorical
fact. We discuss the representation of more complex SQL queries in Note 3.2 on
page97.
The relational-algebrarepresentation of SQL querieshelps toformallydefine
the meaning of the SQL program. Further, database systems typically translate
SQLqueriesintoalower-levelrepresentationbasedonrelationalalgebra,andthey
performqueryoptimizationandqueryevaluationusingthisrepresentation.

--- Page 110 ---

3.4 AdditionalBasicOperations 81
old-nameasnew-name
Theasclausecanappearinboththeselectandfromclauses.3
For example, if we want the attribute name name to be replaced with the name
instructor name,wecanrewritetheprecedingqueryas:
selectnameasinstructor name,course id
frominstructor,teaches
whereinstructor.ID=teaches.ID;
The as clause is particularly useful in renaming relations. One reason to rename
a relation is to replace a long relation name with a shortened version that is more
convenient to use elsewhere in the query. To illustrate, we rewrite the query “For all
instructors in the university who have taught some course, find their names and the
courseIDofallcoursestheytaught.”
selectT.name,S.course id
frominstructor asT,teachesasS
whereT.ID=S.ID;
Another reason to rename a relation is a case where we wish to compare tuples
in the same relation. We then need to take the Cartesian product of a relation with
itselfand, withoutrenaming,itbecomes impossible to distinguish one tuple from the
other.Supposethatwewanttowritethequery“Findthenamesofallinstructorswhose
salaryisgreaterthanatleastoneinstructorintheBiologydepartment.”Wecanwrite
theSQLexpression:
selectdistinctT.name
frominstructor asT,instructor asS
whereT.salary>S.salaryandS.dept name='Biology';
Observethatwecouldnotusethenotationinstructor.salary,sinceitwouldnotbeclear
whichreferencetoinstructor isintended.
Intheabovequery,T andS canbethoughtofascopiesoftherelationinstructor,
but more precisely, they are declared as aliases, that is, as alternative names, for the
relation instructor. An identifier, such as T and S, that is used to rename a relation is
referredtoasacorrelationnameintheSQLstandard,butitisalsocommonlyreferred
toasatablealias,oracorrelationvariable,oratuplevariable.
3EarlyversionsofSQLdidnotincludethekeywordas.Asaresult,someimplementationsofSQL,notablyOracle,
donotpermitthekeywordasinthefromclause.InOracle,“old-nameasnew-name”iswritteninsteadas“old-name
new-name”inthefromclause.Thekeywordasispermittedforrenamingattributesintheselectclause,butitisoptional
andmaybeomittedinOracle.

--- Page 111 ---

82 Chapter3 IntroductiontoSQL
NotethatabetterwaytophrasethepreviousqueryinEnglishwouldbe“Findthe
namesofallinstructorswhoearnmorethanthelowestpaidinstructorintheBiology
department.” Our original wording fits more closely with the SQL that we wrote, but
thelatterwordingismoreintuitive,anditcan infactbe expressed directlyinSQL as
weshallseeinSection3.8.2.
3.4.2 String Operations
SQL specifies strings by enclosing them in single quotes, for example, 'Computer'. A
singlequotecharacterthatispartofastringcanbespecifiedbyusingtwosinglequote
characters;forexample,thestring“It’sright”canbespecifiedby'It''sright'.
TheSQLstandardspecifiesthattheequalityoperationonstringsiscasesensitive;
as a result, the expression “'comp. sci.' = 'Comp. Sci.'” evaluates to false. However,
somedatabasesystems,suchasMySQLandSQLServer,donotdistinguishuppercase
fromlowercasewhenmatchingstrings;asaresult,“'comp.sci.'='Comp.Sci.'”would
evaluate to true on these systems. This default behavior can, however, be changed,
eitheratthedatabaseleveloratthelevelofspecificattributes.
SQLalsopermitsavarietyoffunctionsoncharacterstrings,suchasconcatenating
(using “∥”), extracting substrings, finding the length of strings, converting strings to
uppercase (using the function upper(s) where s is a string) and lowercase (using the
function lower(s)), removing spaces at the end of the string (using trim(s)), and so
on. There are variations on the exact set of string functions supported by different
databasesystems.Seeyourdatabasesystem’smanualformoredetailsonexactlywhat
stringfunctionsitsupports.
Patternmatchingcanbeperformedonstringsusingtheoperatorlike.Wedescribe
patternsbyusingtwospecialcharacters:
• Percent(%):The%charactermatchesanysubstring.
• Underscore( ):The charactermatchesanycharacter.
Patternsarecasesensitive;4thatis,uppercasecharactersdonotmatchlowercasechar-
acters,orviceversa.Toillustratepatternmatching,weconsiderthefollowingexamples:
• 'Intro%'matchesanystringbeginningwith“Intro”.
• '%Comp%' matches any string containing “Comp” as a substring, for example,
'Intro.toComputerScience',and'ComputationalBiology'.
• ' 'matchesanystringofexactlythreecharacters.
• ' %'matchesanystringofatleastthreecharacters.
4ExceptforMySQL,orwiththeilikeoperatorinPostgreSQL,wherepatternsarecaseinsensitive.

--- Page 112 ---

3.4 AdditionalBasicOperations 83
SQL expresses patterns by using the like comparison operator. Consider the query
“Findthenamesofalldepartmentswhosebuildingnameincludesthesubstring'Wat-
son'.”Thisquerycanbewrittenas:
selectdept name
fromdepartment
wherebuildinglike'%Watson%';
Forpatternstoincludethespecialpatterncharacters(thatis,%and ),SQLallowsthe
specificationofanescapecharacter.Theescapecharacterisusedimmediatelybefore
aspecialpatterncharactertoindicatethatthespecialpatterncharacteristobetreated
likeanormalcharacter.Wedefinetheescapecharacterforalikecomparisonusingthe
escape keyword. To illustrate, consider the following patterns, which use a backslash
(∖)astheescapecharacter:
• like'ab∖%cd%'escape'∖'matchesallstringsbeginningwith“ab%cd”.
• like'ab∖∖cd%'escape'∖'matchesallstringsbeginningwith“ab∖cd”.
SQLallowsustosearchformismatchesinsteadofmatchesbyusingthenotlikecom-
parisonoperator.Someimplementationsprovidevariantsofthelikeoperationthatdo
notdistinguishlower-anduppercase.
SomeSQLimplementations,notablyPostgreSQL,offerasimilartooperationthat
providesmorepowerfulpatternmatchingthanthelikeoperation;thesyntaxforspeci-
fyingpatternsissimilartothatusedinUnixregularexpressions.
3.4.3 Attribute Specification in the Select Clause
The asterisk symbol “ * ” can be used in the select clause to denote “all attributes.”
Thus,theuseofinstructor.*intheselectclauseofthequery:
selectinstructor.*
frominstructor,teaches
whereinstructor.ID=teaches.ID;
indicatesthatallattributesofinstructor aretobeselected.Aselectclauseoftheform
select*indicatesthatallattributesoftheresultrelationofthefromclauseareselected.
3.4.4 Ordering the Display of Tuples
SQL offers the user some control over the order in which tuples in a relation are dis-
played.Theorderbyclausecausesthetuplesintheresultofaquerytoappearinsorted
order.TolistinalphabeticorderallinstructorsinthePhysicsdepartment,wewrite:

--- Page 113 ---

84 Chapter3 IntroductiontoSQL
selectname
frominstructor
wheredept name='Physics'
orderbyname;
Bydefault,theorderbyclauselistsitemsinascendingorder.Tospecifythesortorder,
we may specify desc for descending order or asc for ascending order. Furthermore,
ordering can be performed on multiple attributes. Suppose that we wish to list the
entire instructor relation in descending order of salary. If several instructors have the
samesalary,weordertheminascendingorderbyname.WeexpressthisqueryinSQL
asfollows:
select*
frominstructor
orderbysalarydesc,nameasc;
3.4.5 Where-Clause Predicates
SQL includes a between comparison operator to simplify where clauses that specify
thatavaluebelessthanorequaltosomevalueandgreaterthanorequaltosomeother
value.Ifwewishtofindthenamesofinstructorswithsalaryamountsbetween$90,000
and$100,000,wecanusethebetweencomparisontowrite:
selectname
frominstructor
wheresalarybetween90000and100000;
insteadof:
selectname
frominstructor
wheresalary<=100000andsalary>=90000;
Similarly,wecanusethenotbetweencomparisonoperator.
SQLpermitsustousethenotation(v ,v ,…,v )todenoteatupleofarityncon-
1 2 n
taining values v ,v ,…,v ; the notation is called a row constructor. The comparison
1 2 n
operatorscanbeusedontuples,andtheorderingisdefinedlexicographically.Forex-
ample,(a ,a ) <= (b ,b )istrue ifa <= b anda <= b ;similarly,thetwotuples
1 2 1 2 1 1 2 2
areequalifalltheirattributesareequal.Thus,theSQLquery:
selectname,course id
frominstructor,teaches
whereinstructor.ID=teaches.IDanddept name='Biology';

--- Page 114 ---

3.5 SetOperations 85
course id
CS-101
CS-347
PHY-101
Figure 3.8 Thec1relation,listingcoursestaughtinFall2017.
canberewrittenasfollows:5
selectname,course id
frominstructor,teaches
where(instructor.ID,dept name)=(teaches.ID,'Biology');
3.5 Set Operations
TheSQLoperationsunion,intersect,andexceptoperateonrelationsandcorrespondto
themathematicalsetoperations∪,∩,and−.Weshallnowconstructqueriesinvolving
theunion,intersect,andexceptoperationsovertwosets.
• ThesetofallcoursestaughtintheFall2017semester:
selectcourse id
fromsection
wheresemester ='Fall'andyear=2017;
• ThesetofallcoursestaughtintheSpring2018semester:
selectcourse id
fromsection
wheresemester ='Spring'andyear=2018;
Inourdiscussionthatfollows,weshallrefertotherelationsobtainedastheresultofthe
preceding queries as c1 and c2, respectively, and show the results when these queries
arerunonthesectionrelationofFigure2.6inFigure3.8andFigure3.9.Observethat
c2 contains two tuples corresponding to course id CS-319, since two sections of the
coursewereofferedinSpring2018.
5AlthoughitispartoftheSQL-92standard,someSQLimplementations,notablyOracle,donotsupportthissyntax.

--- Page 115 ---

86 Chapter3 IntroductiontoSQL
course id
CS-101
CS-315
CS-319
CS-319
FIN-201
HIS-351
MU-199
Figure 3.9 Thec2relation,listingcoursestaughtinSpring2018.
3.5.1 The Union Operation
Tofind the setofallcourses taught eitherinFall2017 orin Spring2018, orboth, we
write the following query. Note that the parentheses we include around each select-
from-wherestatementbelowareoptionalbutusefulforeaseofreading;somedatabases
donotallowtheuseoftheparentheses,inwhichcasetheymaybedropped.
(selectcourse id
fromsection
wheresemester ='Fall'andyear=2017)
union
(selectcourse id
fromsection
wheresemester ='Spring'andyear=2018);
Theunionoperationautomaticallyeliminatesduplicates,unliketheselectclause.Thus,
using the section relation of Figure 2.6, where two sections of CS-319 are offered in
Spring2018,andasectionofCS-101isofferedintheFall2017aswellasintheSpring
2018 semesters, CS-101 and CS-319 appear only once in the result, shown in Figure
3.10.
Ifwewanttoretainallduplicates,wemustwriteunionallinplaceofunion:
(selectcourse id
fromsection
wheresemester ='Fall'andyear=2017)
unionall
(selectcourse id
fromsection
wheresemester ='Spring'andyear=2018);
Thenumberofduplicatetuplesintheresultisequaltothetotalnumberofduplicates
thatappearinbothc1andc2.So,intheabovequery,eachofCS-319andCS-101would

--- Page 116 ---

3.5 SetOperations 87
course id
CS-101
CS-315
CS-319
CS-347
FIN-201
HIS-351
MU-199
PHY-101
Figure 3.10 Theresultrelationforc1unionc2.
belistedtwice.Asafurtherexample,ifitwerethecasethatfoursectionsofECE-101
weretaughtintheFall2017semesterandtwosectionsofECE-101 weretaughtinthe
Spring2018semester,thentherewouldbesixtupleswithECE-101intheresult.
3.5.2 The Intersect Operation
TofindthesetofallcoursestaughtinboththeFall2017andSpring2018,wewrite:
(selectcourse id
fromsection
wheresemester ='Fall'andyear=2017)
intersect
(selectcourse id
fromsection
wheresemester ='Spring'andyear=2018);
Theresultrelation,showninFigure3.11,containsonlyonetuplewithCS-101.Thein-
tersectoperationautomaticallyeliminatesduplicates.6Forexample,ifitwerethecase
thatfoursectionsofECE-101weretaughtintheFall2017semesterandtwosectionsof
ECE-101 weretaughtintheSpring2018semester,thentherewouldbeonlyonetuple
withECE-101intheresult.
course id
CS-101
Figure 3.11 Theresultrelationforc1intersectc2.
6MySQLdoesnotimplementtheintersectoperation;awork-aroundistousesubqueriesasdiscussedinSection3.8.1.

--- Page 117 ---

88 Chapter3 IntroductiontoSQL
course id
CS-347
PHY-101
Figure 3.12 Theresultrelationforc1exceptc2.
Ifwewanttoretainallduplicates,wemustwriteintersectallinplaceofintersect:
(selectcourse id
fromsection
wheresemester ='Fall'andyear=2017)
intersectall
(selectcourse id
fromsection
wheresemester ='Spring'andyear=2018);
Thenumberofduplicatetuplesthatappearintheresultisequaltotheminimumnum-
berofduplicatesinbothc1andc2.Forexample,iffoursectionsofECE-101weretaught
intheFall2017semesterandtwosectionsofECE-101weretaughtintheSpring2018
semester,thentherewouldbetwotupleswithECE-101intheresult.
3.5.3 The Except Operation
TofindallcoursestaughtintheFall2017semesterbutnotintheSpring2018semester,
wewrite:
(selectcourse id
fromsection
wheresemester ='Fall'andyear=2017)
except
(selectcourse id
fromsection
wheresemester ='Spring'andyear=2018);
The result of this query is shown in Figure 3.12. Note that this is exactly relation c1
ofFigure3.8exceptthatthetupleforCS-101doesnotappear.Theexceptoperation7
outputs all tuples from its first input that do not occur in the second input; that is, it
7SomeSQLimplementations,notablyOracle,usethekeywordminusinplaceofexcept,whileOracle12cusesthe
keywordsmultisetexceptinplaceofexceptall.MySQLdoesnotimplementitatall;awork-aroundistousesubqueries
asdiscussedinSection3.8.1.

--- Page 118 ---

3.6 NullValues 89
performssetdifference.Theoperationautomaticallyeliminatesduplicatesintheinputs
beforeperformingsetdifference.Forexample,iffoursectionsofECE-101weretaught
intheFall2017semesterandtwosectionsofECE-101weretaughtintheSpring2018
semester,theresultoftheexceptoperationwouldnothaveanycopyofECE-101.
Ifwewanttoretainduplicates,wemustwriteexceptallinplaceofexcept:
(selectcourse id
fromsection
wheresemester ='Fall'andyear=2017)
exceptall
(selectcourse id
fromsection
wheresemester ='Spring'andyear=2018);
Thenumberofduplicatecopiesofatupleintheresultisequaltothenumberofdupli-
catecopiesinc1minusthenumberofduplicatecopiesinc2,providedthatthediffer-
enceispositive.Thus,iffoursectionsofECE-101weretaughtintheFall2017semester
andtwosectionsofECE-101weretaughtinSpring2018,thentherearetwotupleswith
ECE-101 in theresult.If,however,thereweretwoorfewersectionsof ECE-101 inthe
Fall 2017 semester and two sections of ECE-101 in the Spring 2018 semester, there is
notuplewithECE-101intheresult.
3.6 Null Values
Nullvaluespresentspecialproblemsinrelationaloperations,includingarithmeticop-
erations,comparisonoperations,andsetoperations.
Theresultofanarithmeticexpression(involving,forexample,+,−,∗,or∕)isnull
ifanyoftheinputvaluesisnull.Forexample,ifaqueryhasanexpressionr.A+5,and
r.A is null for a particular tuple, then the expression result must also be null for that
tuple.
Comparisons involving nulls are more of a problem. For example, consider the
comparison “1 < null”. It would be wrong to say this is true since we do not know
whatthenullvaluerepresents.Butitwouldlikewisebewrongtoclaimthisexpression
isfalse;ifwedid,“not(1 <null)”wouldevaluatetotrue,whichdoesnotmakesense.
SQL therefore treats as unknown the result of any comparison involving a null value
(otherthanpredicatesisnullandisnotnull,whicharedescribedlaterinthissection).
Thiscreatesathirdlogicalvalueinadditiontotrueandfalse.
SincethepredicateinawhereclausecaninvolveBooleanoperationssuchasand,
or,andnotontheresultsofcomparisons,thedefinitionsoftheBooleanoperationsare
extendedtodealwiththevalueunknown.

--- Page 119 ---

90 Chapter3 IntroductiontoSQL
• and:Theresultoftrueandunknownisunknown,falseandunknownisfalse,while
unknownandunknownisunknown.
• or: The result of true or unknown is true, false or unknown is unknown, while un-
knownorunknownisunknown.
• not:Theresultofnotunknownisunknown.
Youcanverifythatifr.Aisnull,then“1< r.A”aswellas“not(1 < r.A)”evaluate
tounknown.
Ifthe whereclausepredicateevaluatestoeitherfalse orunknown foratuple,that
tupleisnotaddedtotheresult.
SQL uses the special keyword null in a predicate to test for a null value. Thus, to
findallinstructorswhoappearintheinstructor relationwithnullvaluesforsalary,we
write:
selectname
frominstructor
wheresalaryisnull;
Thepredicateisnotnullsucceedsifthevalueonwhichitisappliedisnotnull.
SQLallowsustotestwhethertheresultofacomparisonisunknown,ratherthan
trueorfalse,byusingtheclausesisunknownandisnotunknown.8 Forexample,
selectname
frominstructor
wheresalary>10000isunknown;
Whenaqueryusestheselectdistinctclause,duplicatetuplesmustbe eliminated.
Forthispurpose,whencomparingvaluesofcorrespondingattributesfromtwotuples,
thevaluesaretreatedasidenticalifeitherbotharenon-nullandequalinvalue,orboth
arenull.Thus,twocopiesofatuple,suchas{('A',null),('A',null)},aretreatedasbeing
identical,evenifsomeoftheattributeshaveanullvalue.Usingthedistinctclausethen
retainsonlyonecopyofsuchidenticaltuples.Notethatthetreatmentofnullaboveis
differentfromthewaynullsaretreatedinpredicates,whereacomparison“null=null”
wouldreturnunknown,ratherthantrue.
The approach of treating tuples as identical if they have the same values for all
attributes,evenifsomeofthevaluesarenull,isalsousedforthesetoperationsunion,
intersection,andexcept.
8Theisunknownandisnotunknownconstructsarenotsupportedbyseveraldatabases.

--- Page 120 ---

3.7 AggregateFunctions 91
3.7 Aggregate Functions
Aggregatefunctionsarefunctionsthattakeacollection(asetormultiset)ofvaluesas
inputandreturnasinglevalue.SQLoffersfivestandardbuilt-inaggregatefunctions:9
• Average:avg
• Minimum:min
• Maximum:max
• Total:sum
• Count:count
Theinputtosumandavgmustbeacollectionofnumbers,buttheotheroperatorscan
operateoncollectionsofnonnumericdatatypes,suchasstrings,aswell.
3.7.1 Basic Aggregation
Consider the query “Find the average salary of instructors in the Computer Science
department.”Wewritethisqueryasfollows:
selectavg(salary)
frominstructor
wheredept name='Comp.Sci.';
Theresultofthisqueryisarelationwithasingleattributecontainingasingletuplewith
anumericalvaluecorrespondingtotheaveragesalaryofinstructorsintheComputer
Science department. The database system may give an awkward name to the result
relationattributethatisgeneratedbyaggregation,consistingofthetextoftheexpres-
sion;however,wecangiveameaningfulnametotheattributebyusingtheasclauseas
follows:
selectavg(salary)asavg salary
frominstructor
wheredept name='Comp.Sci.';
In the instructor relation of Figure 2.1, the salaries in the Computer Science de-
partment are $75,000, $65,000, and $92,000. The average salary is $232,000∕3 =
$77,333.33.
Retainingduplicatesisimportantincomputinganaverage.SupposetheComputer
Sciencedepartmentaddsafourthinstructorwhosesalaryhappenstobe$75,000.Ifdu-
9MostimplementationsofSQLofferanumberofadditionalaggregatefunctions.

--- Page 121 ---

92 Chapter3 IntroductiontoSQL
plicateswereeliminated,wewouldobtainthewronganswer($232,000∕4=$58,000)
ratherthanthecorrectanswerof$76,750.
There are cases where we must eliminate duplicates before computing an aggre-
gatefunction.Ifwedowanttoeliminateduplicates,weusethekeyworddistinctinthe
aggregateexpression.Anexamplearisesinthequery“Findthetotalnumberofinstruc-
torswhoteachacourseintheSpring2018semester.”Inthiscase,aninstructorcounts
onlyonce,regardlessofthenumberofcoursesectionsthattheinstructorteaches.The
required information is contained in the relation teaches, and we write this query as
follows:
selectcount(distinctID)
fromteaches
wheresemester ='Spring'andyear =2018;
Becauseofthekeyword distinctprecedingID,evenifaninstructorteachesmorethan
onecourse,sheiscountedonlyonceintheresult.
Weusetheaggregatefunctioncountfrequentlytocountthenumberoftuplesina
relation. The notation for this function in SQL is count (*). Thus, to find the number
oftuplesinthecourserelation,wewrite
selectcount(*)
fromcourse;
SQLdoesnotallowtheuseofdistinctwithcount(*).Itislegaltousedistinctwith
max and min, even though the result does not change. We can use the keyword all in
place of distinct to specify duplicate retention, but since all is the default, there is no
needtodoso.
3.7.2 Aggregation with Grouping
Therearecircumstanceswherewewouldliketoapplytheaggregatefunctionnotonly
to a single set of tuples, but also to a group of sets of tuples; we specify this in SQL
using the group by clause. The attribute or attributes given in the group by clause are
usedtoformgroups.Tupleswiththesamevalueonallattributesinthegroupbyclause
areplacedinonegroup.
Asanillustration,considerthequery“Findtheaveragesalaryineachdepartment.”
Wewritethisqueryasfollows:
selectdept name,avg(salary)asavg salary
frominstructor
groupbydept name;

--- Page 122 ---

3.7 AggregateFunctions 93
ID name dept name salary
76766 Crick Biology 72000
45565 Katz Comp.Sci. 75000
10101 Srinivasan Comp.Sci. 65000
83821 Brandt Comp.Sci. 92000
98345 Kim Elec.Eng. 80000
12121 Wu Finance 90000
76543 Singh Finance 80000
32343 ElSaid History 60000
58583 Califieri History 62000
15151 Mozart Music 40000
33456 Gold Physics 87000
22222 Einstein Physics 95000
Figure 3.13 Tuplesofthe instructor relation,groupedbythedeptnameattribute.
Figure 3.13 shows the tuples in the instructor relation grouped by the dept name
attribute,whichisthefirststepincomputingthequeryresult.Thespecifiedaggregate
iscomputedforeachgroup,andtheresultofthequeryisshowninFigure3.14.
In contrast, consider the query “Find the average salary of all instructors.” We
writethisqueryasfollows:
selectavg(salary)
frominstructor;
Inthiscasethegroupbyclausehasbeenomitted,sotheentirerelationistreatedasa
singlegroup.
dept name avg salary
Biology 72000
Comp.Sci. 77333
Elec.Eng. 80000
Finance 85000
History 61000
Music 40000
Physics 91000
Figure 3.14 Theresultrelationforthe query“Findtheaveragesalaryineach
department”.

--- Page 123 ---

94 Chapter3 IntroductiontoSQL
Asanotherexample ofaggregationongroupsoftuples,considerthequery“Find
the number of instructors in each department whoteach a course in the Spring 2018
semester.”Informationaboutwhichinstructorsteachwhichcoursesectionsinwhich
semesterisavailableintheteachesrelation.However,thisinformationhastobejoined
with information from the instructor relation to get the department name of each in-
structor.Thus,wewritethisqueryasfollows:
selectdept name,count(distinctID)asinstr count
frominstructor,teaches
whereinstructor.ID=teaches.IDand
semester ='Spring'andyear =2018
groupbydept name;
TheresultisshowninFigure3.15.
WhenanSQLqueryusesgrouping,itisimportanttoensurethattheonlyattributes
thatappearintheselectstatementwithoutbeingaggregatedarethosethatarepresent
inthegroupbyclause.Inotherwords,anyattributethatisnotpresentinthegroupby
clause may appear in the select clause only as an argument to an aggregate function,
otherwise the query is treated as erroneous. Forexample, the followingquery is erro-
neoussinceIDdoesnotappearinthegroupbyclause,andyetitappearsintheselect
clausewithoutbeingaggregated:
/*erroneousquery*/
selectdept name,ID,avg(salary)
frominstructor
groupbydept name;
In the preceding query, each instructor in a particular group (defined by dept name)
can have adifferentID, and since onlyone tuple isoutput for eachgroup, thereisno
uniquewayofchoosingwhichIDvaluetooutput.Asaresult,suchcasesaredisallowed
bySQL.
The preceding query also illustrates a comment written in SQL by enclosing text
in“/**/”;thesamecommentcouldhavealsobeenwrittenas“––erroneousquery”.
dept name instr count
Comp.Sci. 3
Finance 1
History 1
Music 1
Figure 3.15 Theresultrelationforthequery“Findthenumberofinstructorsineach
departmentwhoteachacourseinthe Spring2018semester.”

--- Page 124 ---

3.7 AggregateFunctions 95
dept name avg salary
Physics 91000
Elec.Eng. 80000
Finance 85000
Comp.Sci. 77333
Biology 72000
History 61000
Figure 3.16 Theresultrelationforthequery“Findtheaveragesalaryofinstructors
inthosedepartments wheretheaveragesalaryismorethan$42,000.”
3.7.3 The Having Clause
Attimes,itisusefultostateaconditionthatappliestogroupsratherthantotuples.For
example,wemightbeinterestedinonlythosedepartmentswheretheaveragesalaryof
theinstructorsismorethan $42,000. Thisconditiondoesnotapplytoasingletuple;
rather, it applies to each group constructed by the group by clause. To express such
aquery, weuse the having clause of SQL.SQL applies predicatesin the having clause
aftergroupshavebeenformed,soaggregatefunctionsmaybeusedinthehavingclause.
WeexpressthisqueryinSQLasfollows:
selectdept name,avg(salary)asavg salary
frominstructor
groupbydept name
havingavg(salary)>42000;
TheresultisshowninFigure3.16.
As was the case for the select clause, any attribute that is present in the having
clause without being aggregated must appear in the group by clause, otherwise the
queryiserroneous.
Themeaningofaquerycontainingaggregation,groupby,orhavingclausesisde-
finedbythefollowingsequenceofoperations:
1. Aswasthecaseforquerieswithoutaggregation,thefromclauseisfirstevaluated
togetarelation.
2. If a where clause is present, the predicate in the where clause is applied on the
resultrelationofthefromclause.
3. Tuples satisfying the where predicate are then placed into groups by the group
by clause if itispresent. If the group by clause isabsent, the entire setof tuples
satisfyingthewherepredicateistreatedasbeinginonegroup.

--- Page 125 ---

96 Chapter3 IntroductiontoSQL
4. Thehavingclause,ifitispresent,isappliedtoeachgroup;thegroupsthatdonot
satisfythehavingclausepredicateareremoved.
5. Theselectclauseusestheremaininggroupstogeneratetuplesoftheresultofthe
query,applyingtheaggregatefunctionstogetasingleresulttupleforeachgroup.
Toillustratetheuseofbothahavingclauseandawhereclauseinthesamequery,
weconsiderthequery“Foreachcoursesectionofferedin2017,findtheaveragetotal
credits (tot cred) of all students enrolled in the section, if the section has at least 2
students.”
selectcourse id,semester,year,sec id,avg(tot cred)
fromstudent,takes
wherestudent.ID=takes.IDandyear =2017
groupbycourse id,semester,year,sec id
havingcount(ID)>=2;
Note that all the required information for the preceding query is available from the
relations takes and student, and that although the query pertains to sections, a join
withsectionisnotneeded.
3.7.4 Aggregation with Null and Boolean Values
Null values, when they exist, complicate the processing of aggregate operators. For
example,assumethatsometuplesintheinstructorrelationhaveanullvalueforsalary.
Considerthefollowingquerytototalallsalaryamounts:
selectsum(salary)
frominstructor;
Thevaluestobesummedintheprecedingqueryincludenullvalues,sinceweassumed
that some tuples have a null value for salary. Rather than say that the overall sum is
itselfnull,theSQLstandardsaysthatthesumoperatorshouldignorenullvaluesinits
input.
Ingeneral,aggregatefunctionstreatnullsaccordingtothefollowingrule:Allaggre-
gate functionsexceptcount(*)ignorenullvaluesintheirinputcollection.Asaresult
of null values being ignored, the collection of values may be empty. The count of an
empty collection is defined to be 0, and all other aggregate operations return a value
ofnullwhenappliedonanemptycollection.Theeffectofnullvaluesonsomeofthe
morecomplicatedSQLconstructscanbesubtle.
ABooleandatatypethatcantakevaluestrue,false,andunknownwasintroduced
inSQL:1999.Theaggregatefunctionssomeandeverycanbeappliedonacollectionof
Booleanvalues,andcomputethedisjunction(or)andconjunction(and),respectively,
ofthevalues.

--- Page 126 ---

3.7 AggregateFunctions 97
Note 3.2 SQLANDMULTISETRELATIONALALGEBRA-PART2
AswesawearlierinNote3.1onpage80,theSQLselect,from,andwhereclauses
canberepresentedinthemultisetrelationalalgebra,usingthemultisetversionsof
theselect,project,andCartesianproductoperations.
The relational algebra union, intersection, and set difference (∪,∩, and −)
operationscanalsobeextendedtothemultisetrelationalalgebrainasimilarway,
followingthecorrespondingdefinitionsof unionall,intersectall,andexceptallin
SQL,whichwesawinSection3.5;theSQLunion,intersect,andexceptcorrespond
tothesetversionof∪,∩,and−.
Theextendedrelationalalgebraaggregateoperationγpermitstheuseofaggre-
gate functions on relation attributes. (The symbol  is also used to representthe
aggregate operation and was used in earliereditions of the book.) The operation
γ (instructor) groups the instructor relation on the dept name at-
deptname average(salary)
tributeandcomputestheaveragesalaryforeachgroup,aswesawearlierinSection
3.7.2. The subscript on the left side may be omitted, resulting in the entire input
relationbeinginasinglegroup.Thus,γ (instructor)computestheaver-
average(salary)
agesalaryofallinstructors.Theaggregatedvaluesdonothaveanattributename;
theycanbegivenanameeitherbyusingtherenameoperatorρorforconvenience
usingthefollowingsyntax:
γ (instructor)
deptname average(salary)asavgsalary
More complex SQL queries can also be rewritten in relational algebra. For
example,thequery:
selectA , A ,sum(A )
1 2 3
fromr , r ,…,r
1 2 m
whereP
groupbyA , A havingcount(A )> 2
1 2 4
isequivalentto:
t1 ← σ (r × r × ⋯ × r )
P 1 2 m
Π (σ ( γ (t1))
A ,A ,SumA3 countA4>2 A ,A sum(A )asSumA3,count(A )ascountA4
1 2 1 2 3 4
Joinexpressionsinthefromclausecanbewrittenusingequivalentjoinexpres-
sionsinrelationalalgebra;weleavethedetailsasanexerciseforthereader.How-
ever, subqueries in the where or select clause cannot be rewritten into relational
algebrainsuchastraightforwardmanner,sincethereisnorelationalalgebraoper-
ation equivalent to the subquery construct. Extensions of relational algebra have
beenproposedforthistask,buttheyarebeyondthescopeofthisbook.

--- Page 127 ---

98 Chapter3 IntroductiontoSQL
3.8 Nested Subqueries
SQL provides a mechanism for nesting subqueries. A subquery is a select-from-where
expressionthatisnestedwithinanotherquery.Acommonuseofsubqueriesistoper-
form tests for set membership, make set comparisons, and determine set cardinality
by nesting subqueries in the where clause. We study such uses of nested subqueries
in the where clause in Section 3.8.1 through Section 3.8.4. In Section 3.8.5, we study
nesting of subqueries in the from clause. In Section 3.8.7, we see how a class of sub-
queries called scalar subqueries can appear wherever an expression returning a value
canoccur.
3.8.1 Set Membership
SQLallowstestingtuplesformembershipinarelation.Theinconnectivetestsforset
membership, where the set is a collection of values produced by a select clause. The
notinconnectivetestsfortheabsenceofsetmembership.
Asanillustration,reconsiderthequery“Findallthecoursestaughtintheboththe
Fall 2017 and Spring 2018 semesters.” Earlier, we wrote such a query by intersecting
twosets:thesetofcoursestaughtinFall2017andthesetofcoursestaughtinSpring
2018. We can take the alternative approach of finding all courses that were taught in
Fall2017 and thatarealsomembersofthesetofcoursestaught inSpring2018. This
formulationgeneratesthesameresultsasthepreviousonedid,butitleadsustowrite
our query using the in connective of SQL. We begin by finding all courses taught in
Spring2018,andwewritethesubquery:
(selectcourse id
fromsection
wheresemester ='Spring'andyear=2018)
We then need to find those coursesthat weretaught in the Fall2017 and thatappear
inthesetofcoursesobtainedinthesubquery.Wedosobynestingthesubqueryinthe
whereclauseofanouterquery.Theresultingqueryis:
selectdistinctcourse id
fromsection
wheresemester ='Fall'andyear=2017and
course id in(selectcourse id
fromsection
wheresemester ='Spring'andyear=2018);
Note that we need to use distinct here because the intersect operation removes dupli-
catesbydefault.
ThisexampleshowsthatitispossibletowritethesamequeryseveralwaysinSQL.
This flexibility is beneficial, since it allows a user to think about the query in the way

--- Page 128 ---

3.8 NestedSubqueries 99
thatseemsmostnatural.Weshallseethatthereisasubstantialamountofredundancy
inSQL.
Weusethenotinconstructinawaysimilartotheinconstruct.Forexample,tofind
all the courses taught in the Fall 2017 semester but not in the Spring 2018 semester,
whichweexpressedearlierusingtheexceptoperation,wecanwrite:
selectdistinctcourse id
fromsection
wheresemester ='Fall'andyear=2017and
course id notin(selectcourse id
fromsection
wheresemester ='Spring'andyear=2018);
The in and not in operators can also be used on enumerated sets. The following
query selects the names of instructors whose names are neither “Mozart” nor “Ein-
stein”.
selectdistinctname
frominstructor
wherenamenotin('Mozart','Einstein');
Intheprecedingexamples, wetested membershipinaone-attribute relation.Itis
also possible to test for membership in an arbitrary relation inSQL. For example, we
canwritethequery“findthetotalnumberof(distinct)studentswhohavetakencourse
sectionstaughtbytheinstructorwithID110011”asfollows:
selectcount(distinctID)
fromtakes
where(course id,sec id,semester,year)in(selectcourse id,sec id,semester,year
fromteaches
whereteaches.ID='10101');
Note,however,thatsomeSQLimplementationsdonotsupporttherowconstruc-
tionsyntax“(course id,sec id,semester,year)”usedabove.Wewillseealternativeways
ofwritingthisqueryinSection3.8.3.
3.8.2 Set Comparison
Asanexampleoftheabilityofanestedsubquerytocomparesets,considerthequery
“Findthe names of allinstructors whose salary isgreater than at leastone instructor
intheBiologydepartment.”InSection3.4.1,wewrotethisqueryasfollows:

--- Page 129 ---

100 Chapter3 IntroductiontoSQL
selectdistinctT.name
frominstructor asT,instructor asS
whereT.salary>S.salaryandS.dept name='Biology';
SQLdoes,however,offeranalternativestyleforwritingtheprecedingquery.Thephrase
“greaterthan at least one” is represented in SQL by > some. Thisconstruct allowsus
to rewrite the query in a form that resembles closely our formulation of the query in
English.
selectname
frominstructor
wheresalary>some(selectsalary
frominstructor
wheredept name='Biology');
Thesubquery:
(selectsalary
frominstructor
wheredept name='Biology')
generatesthesetofallsalaryvaluesofallinstructorsintheBiologydepartment.The>
somecomparisoninthewhereclauseoftheouterselectistrueifthesalaryvalueofthe
tuple isgreaterthanatleast one memberof thesetofallsalary valuesforinstructors
inBiology.
SQLalsoallows<some,<=some,>=some,=some,and<>somecomparisons.
Asanexercise,verifythat=someisidenticaltoin,whereas<>someisnot thesame
asnotin.10
Now we modify our query slightly. Let us find the names of all instructors that
haveasalaryvaluegreaterthanthatofeachinstructorintheBiologydepartment.The
construct > all correspondsto the phrase “greaterthan all.”Usingthisconstruct, we
writethequeryasfollows:
selectname
frominstructor
wheresalary>all(selectsalary
frominstructor
wheredept name='Biology');
Asitdoesforsome,SQLalsoallows<all,<=all,>=all,=all,and<>allcomparisons.
Asanexercise,verifythat<>allisidenticaltonotin,whereas=allisnotthesameas
in.
10ThekeywordanyissynonymoustosomeinSQL.EarlyversionsofSQLallowedonlyany.Laterversionsaddedthe
alternativesometoavoidthelinguisticambiguityofthewordanyinEnglish.

--- Page 130 ---

3.8 NestedSubqueries 101
Asanotherexampleofsetcomparisons,considerthequery“Findthedepartments
that have the highest average salary.” We begin by writing a query to find all average
salaries,andthennestitasasubquery ofalargerquerythatfindsthosedepartments
forwhichtheaveragesalaryisgreaterthanorequaltoallaveragesalaries:
selectdept name
frominstructor
groupbydept name
havingavg(salary)>=all(selectavg(salary)
frominstructor
groupbydept name);
3.8.3 Test for Empty Relations
SQLincludesafeaturefortestingwhetherasubqueryhasanytuplesinitsresult.The
existsconstructreturnsthevaluetrueiftheargumentsubqueryisnonempty.Usingthe
existsconstruct,wecanwritethequery“FindallcoursestaughtinboththeFall2017
semesterandintheSpring2018semester”instillanotherway:
selectcourse id
fromsectionasS
wheresemester ='Fall'andyear=2017and
exists(select*
fromsectionasT
wheresemester ='Spring'andyear=2018and
S.course id=T.courseid);
The above query also illustrates a feature of SQL where a correlation name from
anouterquery(S intheabovequery), canbeusedinasubquery inthewhereclause.
A subquery that uses a correlation name from an outer query is called a correlated
subquery.
In queries that contain subqueries, a scoping rule applies for correlation names.
In a subquery, according to the rule, it is legal to use only correlation names defined
inthesubqueryitselforinanyquerythatcontainsthesubquery.Ifacorrelationname
isdefinedboth locallyinasubquery andgloballyinacontainingquery,thelocaldef-
inition applies. This rule is analogous to the usual scoping rules used for variables in
programminglanguages.
We can test for the nonexistence of tuples in a subquery by using the not exists
construct. We can use the not exists construct to simulate the set containment (that
is,superset)operation:Wecanwrite“relationAcontainsrelationB”as“notexists(B
except A).” (Although it is not part of the current SQL standards, the contains opera-
torwaspresentinsomeearlyrelationalsystems.) Toillustratethenotexistsoperator,

--- Page 131 ---

102 Chapter3 IntroductiontoSQL
considerthequery“FindallstudentswhohavetakenallcoursesofferedintheBiology
department.”Usingtheexceptconstruct,wecanwritethequeryasfollows:
selectS.ID,S.name
fromstudentasS
wherenotexists((selectcourse id
fromcourse
wheredept name='Biology')
except
(selectT.courseid
fromtakesasT
whereS.ID=T.ID));
Here,thesubquery:
(selectcourse id
fromcourse
wheredept name='Biology')
findsthesetofallcoursesofferedintheBiologydepartment.Thesubquery:
(selectT.courseid
fromtakesasT
whereS.ID=T.ID)
findsallthecoursesthatstudentS.IDhastaken.Thus,theouterselecttakeseachstu-
dentandtestswhetherthesetofallcoursesthatthestudenthastakencontainstheset
ofallcoursesofferedintheBiologydepartment.
WesawinSection3.8.1,anSQLqueryto“findthetotalnumberof(distinct)stu-
dents who have taken course sections taught by the instructor with ID 110011”. That
query used a tuple constructor syntax that is not supported by some databases. An
alternativewaytowritethequery,usingtheexistsconstruct,isasfollows:
selectcount(distinctID)
fromtakes
whereexists(selectcourse id,sec id,semester,year
fromteaches
whereteaches.ID='10101'
andtakes.courseid =teaches.course id
andtakes.secid =teaches.sec id
andtakes.semester =teaches.semester
andtakes.year =teaches.year
);

--- Page 132 ---

3.8 NestedSubqueries 103
3.8.4 Test for the Absence of Duplicate Tuples
SQL includes a Boolean function for testing whether a subquery has duplicate tuples
in its result. The unique construct11 returns the value true if the argument subquery
containsnoduplicatetuples.Usingtheuniqueconstruct,wecanwritethequery“Find
allcoursesthatwereofferedatmostoncein2017”asfollows:
selectT.course id
fromcourseasT
whereunique(selectR.course id
fromsectionasR
whereT.courseid=R.course id and
R.year =2017);
Note that if a course were not offered in 2017, the subquery would return an empty
result,andtheuniquepredicatewouldevaluatetotrueontheemptyset.
Anequivalentversionofthisquerynotusingtheuniqueconstructis:
selectT.courseid
fromcourseasT
where1>=(selectcount(R.course id)
fromsectionasR
whereT.course id=R.course id and
R.year =2017);
We can test for the existence of duplicate tuples in a subquery by using the not
uniqueconstruct.Toillustratethisconstruct,considerthequery“Findallcoursesthat
wereofferedatleasttwicein2017”asfollows:
selectT.courseid
fromcourseasT
wherenotunique(selectR.course id
fromsectionasR
whereT.course id=R.course id and
R.year =2017);
Formally,the unique test on a relation is defined to fail if and only if the relation
contains two distinct tuples t and t such that t = t . Since the test t = t fails if
1 2 1 2 1 2
anyofthefieldsoft ort arenull,itispossibleforuniquetobetrueevenifthereare
1 2
multiplecopiesofatuple,aslongasatleastoneoftheattributesofthetupleisnull.
11Thisconstructisnotyetwidelyimplemented.

--- Page 133 ---

104 Chapter3 IntroductiontoSQL
3.8.5 Subqueries in the From Clause
SQL allows a subquery expression to be used in the from clause. The key concept ap-
plied here is that any select-from-where expression returns a relation as a result and,
therefore,canbeinserted intoanotherselect-from-whereanywherethatarelationcan
appear.
Consider the query “Find the average instructors’ salaries of those departments
wheretheaverage salaryisgreaterthan$42,000.” WewrotethisqueryinSection3.7
by using the having clause. We can now rewrite this query, without using the having
clause,byusingasubqueryinthefromclause,asfollows:
selectdeptname,avg salary
from(selectdept name,avg(salary)asavg salary
frominstructor
groupbydept name)
whereavg salary>42000;
Thesubquerygeneratesarelationconsistingofthenamesofalldepartmentsandtheir
corresponding average instructors’ salaries. The attributes of the subquery result can
beusedintheouterquery,ascanbeseenintheaboveexample.
Notethatwedonotneedtousethehavingclause,sincethesubqueryinthefrom
clause computes the average salary, and the predicate that was in the having clause
earlierisnowinthewhereclauseoftheouterquery.
Wecangivethesubqueryresultrelationaname,andrenametheattributes,using
theasclause,asillustratedbelow.
selectdept name,avg salary
from(selectdept name,avg(salary)
frominstructor
groupbydept name)
asdept avg(dept name,avg salary)
whereavg salary>42000;
The subquery resultrelationisnameddept avg,withthe attributes dept nameand avg
salary.
NestedsubqueriesinthefromclausearesupportedbymostbutnotallSQLimple-
mentations. Note that some SQL implementations, notably MySQL and PostgreSQL,
requirethateachsubqueryrelationinthefromclausemustbegivenaname,evenifthe
nameisneverreferenced;Oracleallowsasubquery resultrelationtobegivenaname
(withthekeywordasomitted)butdoesnotallowrenamingofattributesoftherelation.
Aneasyworkaroundforthatistodotheattributerenamingintheselectclauseofthe
subquery;intheabovequery,theselectclauseofthesubquerywouldbereplacedby
selectdept name,avg(salary)asavg salary

--- Page 134 ---

3.8 NestedSubqueries 105
and
“asdept avg(dept name,avg salary)”
wouldbereplacedby
“asdept avg”.
Asanotherexample,supposewewishtofindthemaximumacrossalldepartments
ofthetotalofallinstructors’salariesineachdepartment.Thehavingclausedoesnot
helpusinthistask,butwecanwritethisqueryeasilybyusingasubqueryinthefrom
clause,asfollows:
selectmax(tot salary)
from(selectdept name,sum(salary)
frominstructor
groupbydept name)asdept total (dept name,tot salary);
Wenotethatnestedsubqueriesinthefromclausecannotusecorrelationvariables
fromotherrelationsinthesamefromclause.However,theSQLstandard,startingwith
SQL:2003,allowsasubqueryinthefromclausethatisprefixedbythelateral keyword
to access attributes of preceding tables or subqueries in the same from clause. For
example, ifwewishtoprintthenamesofeachinstructor, alongwiththeirsalaryand
theaveragesalaryintheirdepartment,wecouldwritethequeryasfollows:
selectname,salary,avg salary
frominstructor I1,lateral(selectavg(salary)asavg salary
frominstructor I2
whereI2.deptname=I1.deptname);
Withoutthelateralclause,thesubquerycannotaccessthecorrelationvariableI1from
the outer query. Only the more recent implementations of SQL support the lateral
clause.
3.8.6 The With Clause
The with clause provides a way of defining a temporary relation whose definition is
available only to the query in which the with clause occurs. Consider the following
query,whichfindsthosedepartmentswiththemaximumbudget.
withmax budget(value)as
(selectmax(budget)
fromdepartment)
selectbudget
fromdepartment,max budget
wheredepartment.budget=max budget.value;

--- Page 135 ---

106 Chapter3 IntroductiontoSQL
Thewithclauseinthequerydefinesthetemporaryrelationmax budgetcontainingthe
resultsofthesubquerydefiningtherelation.Therelationisavailableforuseonlywithin
laterpartsofthesamequery.12 Thewithclause,introducedinSQL:1999,issupported
bymany,butnotall,databasesystems.
Wecouldhavewrittentheprecedingquerybyusinganestedsubqueryineitherthe
from clause or the where clause. However, using nested subqueries would have made
thequeryhardertoreadandunderstand.Thewithclausemakesthequerylogicclearer;
italsopermitsthistemporaryrelationtobeusedinmultipleplaceswithinaquery.
For example, suppose we want to find all departments where the total salary is
greaterthantheaverageofthetotalsalaryatalldepartments.Wecanwritethequery
usingthewithclauseasfollows.
withdept total (dept name,value)as
(selectdept name,sum(salary)
frominstructor
groupbydept name),
dept total avg(value)as
(selectavg(value)
fromdept total)
selectdept name
fromdept total,dept totalavg
wheredept total.value>dept total avg.value;
Wecancreateanequivalentquerywithoutthewithclause,butitwouldbemorecom-
plicatedandhardertounderstand.Youcanwritetheequivalentqueryasanexercise.
3.8.7 Scalar Subqueries
SQLallowssubqueriestooccurwhereveranexpressionreturningavalueispermitted,
provided the subquery returns only one tuple containing a single attribute; such sub-
queriesarecalledscalarsubqueries.Forexample,asubquerycanbeusedintheselect
clauseasillustrated inthefollowingexample thatlistsalldepartmentsalongwiththe
numberofinstructorsineachdepartment:
selectdept name,
(selectcount(*)
frominstructor
wheredepartment.dept name=instructor.dept name)
asnum instructors
fromdepartment;
12TheSQLevaluationenginemaynotphysicallycreatetherelationandisfreetocomputetheoverallqueryresultin
alternativeways,aslongastheresultofthequeryisthesameasiftherelationhadbeencreated.

--- Page 136 ---

3.8 NestedSubqueries 107
The subquery in this example is guaranteed to return only a single value since it has
acount(*)aggregatewithoutagroupby.Theexamplealsoillustratestheusageofcor-
relationvariables,thatis,attributes of relationsinthe fromclauseof theouter query,
suchasdepartment.dept nameintheaboveexample.
Scalarsubqueriescanoccurinselect,where,andhavingclauses.Scalarsubqueries
mayalsobedefinedwithoutaggregates.Itisnotalwayspossibletofigureoutatcompile
time if a subquery can return more than one tuple in its result; if the result has more
thanonetuplewhenthesubqueryisexecuted,arun-timeerroroccurs.
Notethattechnicallythetypeofascalarsubquery resultisstillarelation,evenif
it contains a single tuple. However, when a scalar subquery is used in an expression
whereavalueisexpected,SQLimplicitlyextractsthevaluefromthesingleattributeof
thesingletupleintherelationandreturnsthatvalue.
3.8.8 Scalar Without a From Clause
Certainqueriesrequireacalculationbutnoreferencetoanyrelation.Similarly,certain
queries may have subqueries that contain a from clause without the top-level query
needingafromclause.
Asanexample,supposewewishtofindtheaveragenumberofsectionstaught(re-
gardlessofyearorsemester)perinstructor,withsectionstaughtbymultipleinstructors
countedonceperinstructor.Weneedtocountthenumberoftuplesinteachestofind
thetotalnumberofsectionstaughtandcountthenumberoftuplesininstructortofind
thenumberofinstructors.Thenasimpledivisiongivesusthedesiredresult.Onemight
writethisas:
(selectcount(*)fromteaches)/(selectcount(*)frominstructor);
Whilethisislegalinsomesystems,otherswillreportanerrorduetothelackofa
fromclause.13Inthelattercase,aspecialdummyrelationcalled,forexample,dualcan
becreated,containingasingletuple.Thisallowstheprecedingquerytobewrittenas:
select(selectcount(*)fromteaches)/(selectcount(*)frominstructor)
fromdual;
Oracle provides a predefined relation called dual, containing a single tuple, for uses
such as the above (the relation has a single attribute, which is not relevant for our
purposes);youcancreateanequivalentrelationifyouuseanyotherdatabase.
Since the above queries divide one integer by another, the result would, on most
databases,beaninteger,whichwouldresultinlossofprecision.Ifyouwishtogetthe
resultasafloatingpointnumber,youcouldmultiplyoneofthetwosubqueryresultsby
1.0toconvertittoafloatingpointnumber,beforethedivisionoperationisperformed.
13Thisconstructislegal,forexample,inSQLServer,butnotlegal,forexample,inOracle.

--- Page 137 ---

108 Chapter3 IntroductiontoSQL
Note 3.3 SQLANDMULTISETRELATIONALALGEBRA-PART3
UnliketheSQLsetandaggregationoperationsthatwestudiedearlierinthischap-
ter,SQLsubqueriesdonothavedirectlyequivalentoperationsintherelationalal-
gebra.MostSQLqueriesinvolvingsubqueriescanberewritteninawaythatdoes
notrequiretheuseofsubqueries,andthustheyhaveequivalentrelationalalgebra
expressions.
Rewriting to relational algebra can benefit from two extended relational al-
gebra operations called semijoin, denoted ⋉, and antijoin, denoted ⋉, which are
supported internally by many database implementations (the symbol ⊳ is some-
timesusedinplaceof⋉todenoteantijoin).Forexample,givenrelationsr ands,
r⋉ soutputsalltuplesinrthathaveatleastonetupleinswhoses.Battribute
r.A=s.B
valuematchesthattuplesr.Aattributevalue.Conversely,r⋉ soutputsalltu-
r.A=s.B
plesinr thathavedonothaveanysuchmatchingtupleins.Theseoperatorscan
beusedtorewritemanysubqueriesthatusetheexistsandnotexistsconnectives.
Semijoin and antijoin can be expressed using other relational algebra opera-
tions, so they do not add any expressive power, but they are nevertheless quite
usefulinpracticesincetheycanbeimplementedveryefficiently.
However, the process of rewriting SQL queries that contain subqueries is in
general not straightforward. Database system implementations therefore extend
therelationalalgebrabyallowingσandΠoperatorstoinvokesubqueriesintheir
predicatesandprojectionlists.
3.9 Modification of the Database
We have restricted our attention until now to the extraction of information from the
database.Now,weshowhowtoadd,remove,orchangeinformationwithSQL.
3.9.1 Deletion
A delete request is expressed in much the same way as a query. We can delete only
whole tuples; we cannot delete values on only particular attributes. SQL expresses a
deletionby:
deletefromr
whereP;
where P represents a predicate and r represents a relation. The delete statement first
finds all tuples t in r for which P(t) is true, and then deletes them from r. The where
clausecanbeomitted,inwhichcasealltuplesinr aredeleted.

--- Page 138 ---

3.9 ModificationoftheDatabase 109
Note that a delete command operates on only one relation. If we want to delete
tuplesfromseveralrelations,wemustuse onedeletecommandforeachrelation.The
predicateinthewhereclausemaybeascomplexasaselectcommand’swhereclause.
Attheotherextreme,thewhereclausemaybeempty.Therequest:
deletefrominstructor;
deletes all tuples from the instructor relation. The instructor relation itself still exists,
butitisempty.
HereareexamplesofSQLdeleterequests:
• Deletealltuplesintheinstructor relationpertainingtoinstructorsintheFinance
department.
deletefrominstructor
wheredept name='Finance';
• Deleteallinstructorswithasalarybetween$13,000and$15,000.
deletefrominstructor
wheresalarybetween13000and15000;
• Delete all tuples in the instructor relation for those instructors associated with a
departmentlocatedintheWatsonbuilding.
deletefrominstructor
wheredept namein(selectdept name
fromdepartment
wherebuilding='Watson');
Thisdelete requestfirstfindsalldepartmentslocatedinWatson andthendeletes
allinstructor tuplespertainingtothosedepartments.
Notethat,althoughwemaydeletetuplesfromonlyonerelationatatime,wemay
referenceanynumberofrelationsinaselect-from-wherenestedinthewhereclauseofa
delete.Thedeleterequestcancontainanestedselectthatreferencestherelationfrom
whichtuplesaretobedeleted.Forexample,supposethatwewanttodeletetherecords
ofallinstructorswithsalarybelowtheaverageattheuniversity.Wecouldwrite:
deletefrominstructor
wheresalary<(selectavg(salary)
frominstructor);

--- Page 139 ---

110 Chapter3 IntroductiontoSQL
The delete statement first tests each tuple in the relation instructor to check whether
thesalaryislessthantheaveragesalaryofinstructorsintheuniversity.Then,alltuples
thatpassthetest—thatis,representaninstructorwithalower-than-averagesalary—are
deleted.Performingallthetestsbeforeperforminganydeletionisimportant—ifsome
tuplesaredeletedbeforeothertupleshavebeentested,theaveragesalarymaychange,
and the final result of the delete would depend on the order in which the tuples were
processed!
3.9.2 Insertion
Toinsertdataintoarelation,weeitherspecifyatuple tobe insertedorwriteaquery
whose result is a set of tuples to be inserted. The attribute values for inserted tuples
must be members of the corresponding attribute’s domain. Similarly, tuples inserted
musthavethecorrectnumberofattributes.
Thesimplestinsertstatementisarequesttoinsertonetuple.Supposethatwewish
to insert the fact that there is a course CS-437 in the Computer Science department
withtitle“DatabaseSystems”andfourcredithours.Wewrite:
insertintocourse
values('CS-437','DatabaseSystems','Comp.Sci.',4);
In this example, the values are specified in the order in which the corresponding at-
tributes are listed in the relation schema. For the benefit of users who may not re-
membertheorderoftheattributes,SQLallowstheattributestobespecifiedaspartof
theinsertstatement.Forexample,thefollowingSQLinsertstatementsareidenticalin
functiontotheprecedingone:
insertintocourse(course id,title,dept name,credits)
values('CS-437','DatabaseSystems','Comp.Sci.',4);
insertintocourse(title,course id,credits,dept name)
values('DatabaseSystems','CS-437',4,'Comp.Sci.');
Moregenerally,wemightwanttoinserttuplesonthebasisoftheresultofaquery.
SupposethatwewanttomakeeachstudentintheMusicdepartmentwhohasearned
more than 144 credit hours an instructor in the Music department with a salary of
$18,000.Wewrite:
insertintoinstructor
selectID,name,dept name,18000
fromstudent
wheredept name='Music'andtot cred >144;

--- Page 140 ---

3.9 ModificationoftheDatabase 111
Insteadofspecifyingatupleaswedidearlierinthissection,weuseaselecttospecifya
setoftuples.SQLevaluatestheselectstatementfirst,givingasetoftuplesthatisthen
insertedintotheinstructorrelation.EachtuplehasanID,aname,adept name(Music),
andasalaryof$18,000.
Itisimportantthatthesystemevaluatetheselectstatementfullybeforeitperforms
any insertions. If it were to carry out some insertions while the select statement was
beingevaluated,arequestsuchas:
insertintostudent
select*
fromstudent;
mightinsertaninfinitenumberoftuples,iftheprimarykeyconstraintonstudentwere
absent.Withouttheprimarykeyconstraint,therequestwouldinsertthefirsttuplein
student again, creating a second copy of the tuple. Since this second copy is part of
student now,the select statement may find it, and a third copywould be inserted into
student.Theselectstatementmaythenfindthisthirdcopyandinsertafourthcopy,and
soon,forever.Evaluatingtheselectstatementcompletelybeforeperforminginsertions
avoids such problems. Thus, the above insert statement would simply duplicate every
tupleinthestudentrelationiftherelationdidnothaveaprimarykeyconstraint.
Ourdiscussionoftheinsertstatementconsideredonlyexamplesinwhichavalue
isgivenforeveryattributeininsertedtuples.Itispossibleforinsertedtuplestobegiven
valuesononlysomeattributesoftheschema.Theremainingattributesareassigneda
nullvaluedenotedbynull.Considertherequest:
insertintostudent
values('3003','Green','Finance',null);
The tuple inserted by this request specified that a student with ID “3003” is in the
Financedepartment,butthetot cred valueforthisstudentisnotknown.
Most relational database products have special “bulk loader” utilities to insert a
large set of tuples into a relation. These utilities allow data to be read from format-
ted text files, and they can execute much faster than an equivalent sequence of insert
statements.
3.9.3 Updates
In certain situations, we may wish to change a value in a tuple without changing all
values in the tuple. For this purpose, the update statement can be used. As we could
forinsertanddelete,wecanchoosethetuplestobeupdatedbyusingaquery.
Supposethatannualsalaryincreasesarebeingmade,andsalariesofallinstructors
aretobeincreasedby5percent.Wewrite:

--- Page 141 ---

112 Chapter3 IntroductiontoSQL
updateinstructor
setsalary=salary*1.05;
Theprecedingupdate statementisappliedoncetoeachofthetuplesintheinstructor
relation.
If a salary increase is to be paid only to instructors with a salary of less than
$70,000,wecanwrite:
updateinstructor
setsalary=salary*1.05
wheresalary<70000;
In general, the where clause of the update statement may contain any construct legal
in the where clause of the select statement (including nested selects). As with insert
and delete, a nested select within an update statement may reference the relation that
is being updated. As before, SQL first tests all tuples in the relation to see whether
theyshouldbeupdated,anditcarriesouttheupdatesafterward.Forexample,wecan
writetherequest“Givea5percentsalaryraisetoinstructorswhosesalaryislessthan
average”asfollows:
updateinstructor
setsalary=salary*1.05
wheresalary<(selectavg(salary)
frominstructor);
Letusnowsuppose thatallinstructorswithsalaryover$100,000 receivea3per-
cent raise, whereas all others receive a 5 percent raise. We could write two update
statements:
updateinstructor
setsalary=salary*1.03
wheresalary>100000;
updateinstructor
setsalary=salary*1.05
wheresalary<=100000;
Notethattheorderofthetwoupdatestatementsisimportant.Ifwechangedtheorder
ofthetwostatements,aninstructorwithasalaryjustunder$100,000wouldreceivea
raiseofover8percent.
SQL provides a case construct that we can use to perform both updates with a
singleupdatestatement,avoidingtheproblemwiththeorderofupdates.

--- Page 142 ---

3.9 ModificationoftheDatabase 113
updateinstructor
setsalary=case
whensalary<=100000thensalary*1.05
elsesalary*1.03
end
Thegeneralformofthecasestatementisasfollows:
case
whenpred thenresult
1 1
whenpred thenresult
2 2
…
whenpred thenresult
n n
elseresult
0
end
Theoperationreturnsresult,whereiisthefirstofpred ,pred ,...,pred thatissatis-
i 1 2 n
fied;ifnoneofthepredicatesissatisfied,theoperationreturnsresult .Casestatements
0
canbeusedinanyplacewhereavalueisexpected.
ScalarsubqueriesareusefulinSQLupdatestatements,wheretheycanbeusedin
thesetclause.Weillustratethisusingthestudentandtakesrelationsthatweintroduced
in Chapter 2. Consider an update where we set the tot cred attribute of each student
tuple to the sum of the credits of courses successfully completed by the student. We
assumethatacourseissuccessfullycompletedifthestudenthasagradethatisneither
'F' nor null. To specify this update, we need to use a subquery in the set clause, as
shownbelow:
updatestudent
settot cred =(
selectsum(credits)
fromtakes,course
wherestudent.ID=takes.IDand
takes.courseid =course.course id and
takes.grade<>'F'and
takes.gradeisnotnull);
Incaseastudenthasnotsuccessfully completedanycourse,theprecedingstatement
would set the tot cred attribute value to null. To set the value to 0 instead, we could
use another update statement to replace null values with 0; a better alternative is to
replace the clause “select sum(credits)” in the preceding subquery with the following
selectclauseusingacaseexpression:
selectcase
whensum(credits)isnotnullthensum(credits)
else0
end

--- Page 143 ---

114 Chapter3 IntroductiontoSQL
Manysystemssupportacoalescefunction,whichwedescribeinmoredetaillater,
in Section 4.5.2, which provides a concise way of replacing nulls by other values. In
the above example, we could have used coalesce(sum(credits), 0) instead of the case
expression; this expression would return the aggregate result sum(credits) if it is not
null,and0otherwise.
3.10 Summary
• SQListhemostinfluentialcommerciallymarketedrelationalquerylanguage.The
SQLlanguagehasseveralparts:
° Data-definition language (DDL), which provides commands for defining rela-
tionschemas,deletingrelations,andmodifyingrelationschemas.
° Data-manipulationlanguage(DML),whichincludesaquerylanguageandcom-
mands to insert tuples into, delete tuples from, and modify tuples in the
database.
• The SQL data-definition language is used to create relations with specified
schemas. In addition to specifying the names and types of relation attributes,
SQLalsoallowsthespecificationofintegrityconstraintssuchasprimary-keycon-
straintsandforeign-keyconstraints.
• SQL includesa varietyof language constructs forqueries on the database. These
includetheselect,from,andwhereclauses.
• SQL also provides mechanisms to rename both attributes and relations, and to
orderqueryresultsbysortingonspecifiedattributes.
• SQLsupportsbasicsetoperationsonrelations,includingunion,intersect,andex-
cept,whichcorrespondtothemathematicalsetoperations∪,∩,and−.
• SQLhandlesqueriesonrelationscontainingnullvaluesbyaddingthetruthvalue
“unknown”totheusualtruthvaluesoftrueandfalse.
• SQL supports aggregation, including the ability to divide a relation into groups,
applyingaggregation separately on each group. SQL alsosupports setoperations
ongroups.
• SQLsupports nested subqueriesinthewhereandfromclausesofanouterquery.
Italsosupportsscalarsubquerieswhereveranexpressionreturningavalueisper-
mitted.
• SQLprovidesconstructsforupdating,inserting,anddeletinginformation.

--- Page 144 ---

PracticeExercises 115
Review Terms
• Data-definitionlanguage • Setoperations
• Data-manipulationlanguage
° union
• Databaseschema
° intersect
• Databaseinstance
° except
• Relationschema
• Relationinstance • Aggregatefunctions
• Primarykey ° avg,min,max,sum,count
• Foreignkey ° groupby
° Referencingrelation ° having
° Referencedrelation • Nestedsubqueries
• Nullvalue • Setcomparisons
• Querylanguage ° {<,<=,>,>=}{some,all}
• SQLquerystructure
° exists
° selectclause
° unique
° fromclause
• lateralclause
° whereclause • withclause
• Multisetrelationalalgebra • Scalarsubquery
• asclause • Databasemodification
• orderbyclause
° Delete
• Tablealias
° Insert
• Correlation name (correlation vari-
able,tuplevariable) ° Update
Practice Exercises
3.1 Write the following queries in SQL, using the university schema. (We suggest
you actually run these queries on a database, using the sample data that we
provide on the website of the book, db-book.com. Instructions for settingup
adatabase,andloadingsampledata,areprovidedontheabovewebsite.)
a. FindthetitlesofcoursesintheComp.Sci.departmentthathave3credits.
b. FindtheIDsofallstudentswhoweretaughtbyaninstructornamedEin-
stein;makesuretherearenoduplicatesintheresult.

--- Page 145 ---

116 Chapter3 IntroductiontoSQL
c. Findthehighestsalaryofanyinstructor.
d. Find all instructors earning the highest salary (there may be more than
onewiththesamesalary).
e. FindtheenrollmentofeachsectionthatwasofferedinFall2017.
f. Findthemaximumenrollment,acrossallsections,inFall2017.
g. FindthesectionsthathadthemaximumenrollmentinFall2017.
3.2 Supposeyouaregivenarelationgrade points(grade,points)thatprovidesacon-
versionfromlettergradesinthetakesrelationtonumericscores;forexample,
an“A”gradecouldbespecifiedtocorrespondto4points,an“A−”to3.7points,
a“B+”to3.3points,a“B”to3points,andsoon.Thegradepointsearnedbya
studentforacourseoffering(section)isdefinedasthenumberofcreditsforthe
coursemultipliedbythenumericpointsforthegradethatthestudentreceived.
Given the precedingrelation,and our university schema, write each of the
followingqueriesinSQL.Youmayassumeforsimplicitythatnotakestuplehas
thenull valueforgrade.
a. FindthetotalgradepointsearnedbythestudentwithID'12345',across
allcoursestakenbythestudent.
b. Findthegradepointaverage(GPA)fortheabovestudent,thatis,thetotal
gradepointsdividedbythetotalcreditsfortheassociatedcourses.
c. FindtheIDandthegrade-pointaverageofeachstudent.
d. Now reconsider your answers to the earlier parts of this exercise under
the assumption that some grades might be null. Explain whether your
solutionsstillworkand,ifnot,provideversionsthathandlenullsproperly.
3.3 Write the following inserts, deletes, or updates in SQL, using the university
schema.
a. Increase the salary of each instructor in the Comp. Sci. department by
10%.
b. Delete all courses that have never been offered (i.e., do not occur in the
sectionrelation).
c. Inserteverystudentwhosetot cred attribute isgreaterthan100asanin-
structorinthesamedepartment,withasalaryof$10,000.
3.4 Consider the insurance database of Figure 3.17, where the primary keys are
underlined.ConstructthefollowingSQLqueriesforthisrelationaldatabase.
a. Find the total number of people who owned cars that were involved in
accidentsin2017.

--- Page 146 ---

PracticeExercises 117
person(driver id,name,address)
car (license plate,model,year)
accident(report number,year,location)
owns(driver id,license plate)
participated (report number,license plate,driver id,damage amount)
Figure 3.17 Insurancedatabase
b. Deleteallyear-2010carsbelongingtothepersonwhoseIDis'12345'.
3.5 Suppose thatwehavearelationmarks(ID,score)andwewishtoassigngrades
to students based on the score as follows: grade F if score < 40, grade C if 40
≤score < 60, grade B if60 ≤ score <80, and gradeA if 80 ≤score. Write SQL
queriestodothefollowing:
a. Displaythegradeforeachstudent,basedonthemarksrelation.
b. Findthenumberofstudentswitheachgrade.
3.6 TheSQLlikeoperatoriscasesensitive(inmostsystems),butthelower()func-
tiononstringscanbeusedtoperformcase-insensitivematching.Toshowhow,
writeaquerythatfindsdepartmentswhosenamescontainthestring“sci”asa
substring,regardlessofthecase.
3.7 ConsidertheSQLquery
selectp.a1
fromp,r1,r2
wherep.a1=r1.a1orp.a1=r2.a1
Underwhatconditionsdoes theprecedingquery selectvalues of p.a1thatare
eitherinr1orinr2?Examinecarefullythecaseswhereeitherr1orr2maybe
empty.
3.8 Consider the bank database of Figure 3.18, where the primary keys are under-
lined.ConstructthefollowingSQLqueriesforthisrelationaldatabase.
a. FindtheIDofeachcustomer ofthebank whohasan accountbut nota
loan.
b. FindtheIDofeachcustomerwholivesonthesamestreetandinthesame
cityascustomer'12345'.
c. Findthenameofeachbranchthathasatleastonecustomerwhohasan
accountinthebankandwholivesin“Harrison”.

--- Page 147 ---

118 Chapter3 IntroductiontoSQL
branch(branch name,branch city,assets)
customer (ID,customer name,customer street,customer city)
loan(loan number,branch name,amount)
borrower (ID,loan number)
account (account number,branch name,balance)
depositor (ID,account number)
Figure 3.18 Bankingdatabase.
3.9 Consider the relational database of Figure 3.19, where the primary keys are
underlined.GiveanexpressioninSQLforeachofthefollowingqueries.
a. FindtheID,name,andcityofresidenceofeachemployeewhoworksfor
“FirstBankCorporation”.
b. FindtheID,name,andcityofresidenceofeachemployeewhoworksfor
“FirstBankCorporation”andearnsmorethan$10000.
c. FindtheIDofeachemployeewhodoesnotworkfor“FirstBankCorpo-
ration”.
d. Find the ID of each employee who earns more than every employee of
“SmallBankCorporation”.
e. Assume that companies may be located in several cities. Find the name
ofeachcompanythatislocatedineverycityinwhich“SmallBankCor-
poration”islocated.
f. Find the name of the company that has the most employees (or compa-
nies,inthecasewherethereisatieforthemost).
g. Find the name of each company whose employees earn a higher salary,
onaverage,thantheaveragesalaryat“FirstBankCorporation”.
employee(ID,person name,street,city)
works(ID,company name,salary)
company(company name,city)
manages(ID,manager id)
Figure 3.19 Employeedatabase.

--- Page 148 ---

Exercises 119
3.10 ConsidertherelationaldatabaseofFigure3.19.GiveanexpressioninSQLfor
eachofthefollowing:
a. Modifythe database sothattheemployee whose ID is'12345' now lives
in“Newtown”.
b. Giveeachmanagerof“FirstBankCorporation”a10percentraiseunless
the salary becomes greater than $100000; in such cases, give only a 3
percentraise.
Exercises
3.11 WritethefollowingqueriesinSQL,usingtheuniversityschema.
a. FindtheIDandnameofeachstudentwhohastakenatleastoneComp.
Sci.course;makesuretherearenoduplicatenamesintheresult.
b. Find the ID and name of each student who has not taken any course
offeredbefore2017.
c. Foreachdepartment,findthemaximumsalaryofinstructorsinthatde-
partment.Youmayassumethateverydepartmenthasatleastoneinstruc-
tor.
d. Findthelowest,acrossalldepartments,oftheper-departmentmaximum
salarycomputedbytheprecedingquery.
3.12 WritetheSQLstatementsusingtheuniversityschematoperformthefollowing
operations:
a. Createanewcourse“CS-001”,titled“WeeklySeminar”,with0credits.
b. CreateasectionofthiscourseinFall2017,withsec id of1,andwiththe
locationofthissectionnotyetspecified.
c. EnrolleverystudentintheComp.Sci.departmentintheabovesection.
d. Deleteenrollmentsintheabovesectionwherethestudent’sIDis12345.
e. Delete the course CS-001. What will happen if you run this delete state-
mentwithoutfirstdeletingofferings(sections)ofthiscourse?
f. Delete all takes tuples corresponding to any section of any course with
theword“advanced”asapartofthetitle;ignorecasewhenmatchingthe
wordwiththetitle.
3.13 WriteSQLDDLcorrespondingtotheschemainFigure3.17.Makeanyreason-
ableassumptionsaboutdatatypes,andbesuretodeclareprimaryandforeign
keys.

--- Page 149 ---

120 Chapter3 IntroductiontoSQL
3.14 Consider the insurance database of Figure 3.17, where the primary keys are
underlined.ConstructthefollowingSQLqueriesforthisrelationaldatabase.
a. Findthenumberofaccidentsinvolvingacarbelongingtoapersonnamed
“JohnSmith”.
b. Update the damage amount for the car with license plate “AABB2000”
intheaccidentwithreportnumber“AR2197”to$3000.
3.15 Consider the bank database of Figure 3.18, where the primary keys are under-
lined.ConstructthefollowingSQLqueriesforthisrelationaldatabase.
a. Findeachcustomerwhohasanaccountateverybranchlocatedin“Brook-
lyn”.
b. Findthetotalsumofallloanamountsinthebank.
c. Find the names of all branches that have assets greater than those of at
leastonebranchlocatedin“Brooklyn”.
3.16 Consider the employee database of Figure 3.19, where the primary keys are
underlined.GiveanexpressioninSQLforeachofthefollowingqueries.
a. Find ID and name of each employee who lives in the same city as the
locationofthecompanyforwhichtheemployeeworks.
b. FindIDandnameofeachemployeewholivesinthesamecityandonthe
samestreetasdoesherorhismanager.
c. Find ID and name of each employee who earns more than the average
salaryofallemployeesofherorhiscompany.
d. Findthecompanythathasthesmallestpayroll.
3.17 ConsidertheemployeedatabaseofFigure3.19.GiveanexpressioninSQLfor
eachofthefollowingqueries.
a. Giveallemployeesof“FirstBankCorporation”a10percentraise.
b. Giveallmanagersof“FirstBankCorporation”a10percentraise.
c. Deletealltuplesintheworksrelationforemployeesof“SmallBankCor-
poration”.
3.18 Give an SQL schema definition for the employee database of Figure 3.19.
Choose an appropriate domain for each attribute and an appropriate primary
keyforeachrelationschema.Includeanyforeign-keyconstraintsthatmightbe
appropriate.
3.19 Listtworeasonswhynullvaluesmightbeintroducedintothedatabase.
3.20 Showthat,inSQL,<>allisidenticaltonotin.

--- Page 150 ---

Exercises 121
member(memb no,name)
book(isbn,title,authors,publisher)
borrowed(memb no,isbn,date)
Figure 3.20 Librarydatabase.
3.21 ConsiderthelibrarydatabaseofFigure3.20.WritethefollowingqueriesinSQL.
a. Findthemembernumberandnameofeachmemberwhohasborrowed
atleastonebookpublishedby“McGraw-Hill”.
b. Findthemembernumberandnameofeachmemberwhohasborrowed
everybookpublishedby“McGraw-Hill”.
c. Foreachpublisher,findthemembernumberandnameofeachmember
whohasborrowedmorethanfivebooksofthatpublisher.
d. Find the average number of books borrowed per member. Take into ac-
countthatifamemberdoesnotborrowanybooks,thenthatmemberdoes
notappearintheborrowedrelationatall,butthatmemberstillcountsin
theaverage.
3.22 Rewritethewhereclause
whereunique(selecttitlefromcourse)
withoutusingtheuniqueconstruct.
3.23 Considerthequery:
withdept total (dept name,value)as
(selectdept name,sum(salary)
frominstructor
groupbydept name),
dept total avg(value)as
(selectavg(value)
fromdept total)
selectdept name
fromdept total,dept totalavg
wheredept total.value>=dept totalavg.value;
Rewritethisquerywithoutusingthewithconstruct.
3.24 Using the university schema, write an SQL query to find the name and ID of
thoseAccountingstudentsadvisedbyaninstructorinthePhysicsdepartment.

--- Page 151 ---

122 Chapter3 IntroductiontoSQL
3.25 Using the university schema, write an SQL query to find the names of those
departments whose budget is higher than that of Philosophy. List them in al-
phabeticorder.
3.26 Usingtheuniversityschema,useSQLtodothefollowing:Foreachstudentwho
hasretakenacourseatleasttwice(i.e.,thestudenthastakenthecourseatleast
threetimes),showthecourseIDandthestudent’sID.
Please display your results in order of course ID and do not display duplicate
rows.
3.27 Using the university schema, write an SQL query to find the IDs of those stu-
dents who have retaken at least three distinct courses at least once (i.e, the
studenthastakenthecourseatleasttwotimes).
3.28 Usingtheuniversityschema,writeanSQLquerytofindthenamesandIDsof
thoseinstructorswhoteacheverycoursetaughtinhisorherdepartment(i.e.,
everycoursethatappearsinthecourserelationwiththeinstructor’sdepartment
name).Orderresultbyname.
3.29 Using the university schema, write an SQL query to find the name and ID of
each History student whose name begins with the letter ‘D’ and who has not
takenatleastfiveMusiccourses.
3.30 ConsiderthefollowingSQLqueryontheuniversityschema:
selectavg(salary)-(sum(salary)/count(*))
frominstructor
We might expect that the result of this query is zero since the average of a set
of numbers isdefined to be the sum of the numbers dividedby the number of
numbers. Indeed this is true for the example instructor relation in Figure 2.1.
However,thereareotherpossibleinstancesofthatrelationforwhichtheresult
would not be zero. Give one such instance, and explain why the result would
notbezero.
3.31 Usingtheuniversityschema,writeanSQLquerytofindtheIDandnameofeach
instructorwhohasnevergivenan Agrade inanycourse sheorhe hastaught.
(Instructorswhohavenevertaughtacoursetriviallysatisfythiscondition.)
3.32 Rewrite the precedingquery, but also ensure that you include onlyinstructors
whohavegivenatleastoneothernon-nullgradeinsomecourse.
3.33 Usingtheuniversityschema,writeanSQLquerytofindtheIDandtitleofeach
courseinComp.Sci.thathashadatleastonesectionwithafternoonhours(i.e.,
endsatorafter12:00).(Youshouldeliminateduplicatesifany.)
3.34 Usingtheuniversityschema,writeanSQLquerytofindthenumberofstudents
ineachsection.Theresultcolumnsshouldappearintheorder“courseid,secid,
year,semester,num”.Youdonotneedtooutputsectionswith0students.

--- Page 152 ---

Tools 123
3.35 Using the university schema, write an SQL query to find section(s) with max-
imum enrollment. The result columns should appear in the order “courseid,
secid,year,semester,num”.(Itmaybeconvenienttousethewithconstruct.)
Tools
A number of relational database systems are available commercially, including IBM
DB2, IBM Informix, Oracle, SAP Adaptive Server Enterprise (formerly Sybase), and
MicrosoftSQLServer.Inadditionseveralopen-sourcedatabasesystemscanbedown-
loadedandusedfreeofcharge,includingPostgreSQLandMySQL(freeexceptforcer-
tain kinds of commercial use). Some commercial vendors offer free versions of their
systems withcertainuselimitations.TheseincludeOracleExpressedition,Microsoft
SQLServerExpress,andIBMDB2Express-C.
Thesql.jsdatabaseisversionoftheembeddedSQLdatabaseSQLitewhichcanbe
run directlyin aweb browser, allowingSQL commandsto be executed directlyin the
browser. All data are temporary and vanishes when you close the browser, but it can
beusefulforlearningSQL;bewarnedthatthesubsetofSQLthatissupportedbysql.js
andSQLiteisconsiderablysmallerthanwhatissupportedbyotherdatabases.AnSQL
tutorialusingsql.jsastheexecutionengineishostedatwww.w3schools.com/sql.
Thewebsiteofourbook,db-book.com,providesasignificantamountofsupport-
ingmaterialforthebook.ByfollowingthelinkonthesitetitledLaboratoryMaterial,
youcangetaccesstothefollowing:
• Instructionsonhowtosetupandaccesssomepopulardatabasesystems,including
sql.js(whichyoucanruninyourbrowser),MySQL,andPostgreSQL.
• SQLschemadefinitionsfortheUniversityschema.
• SQLscriptsforloadingsampledatasets.
• TipsonhowtousetheXDatasystem,developedatIITBombay,totestqueriesfor
correctnessbyexecutingthemonmultipledatasetsgeneratedbythesystem;and,
forinstructors,tipsonhowtouseXDatatoautomateSQLquerygrading.
• GettipsonSQLvariationsacrossdifferentdatabases.
Support for different SQL features varies by databases, and most databases also
supportsomenon-standardextensionstoSQL.Readthesystemmanualstounderstand
theexactSQLfeaturesthatadatabasesupports.
MostdatabasesystemsprovideacommandlineinterfaceforsubmittingSQLcom-
mands. In addition, most databases also provide graphical user interfaces (GUIs),
whichsimplifythetaskofbrowsingthedatabase,creatingandsubmittingqueries,and
administering the database. For PostgreSQL, the pgAdmin tool provides GUI func-
tionality,whileforMySQL,phpMyAdminprovidesGUIfunctionality.Oracleprovides

--- Page 153 ---

124 Chapter3 IntroductiontoSQL
OracleSQL Developer, whileMicrosoftSQLServer comeswith the SQLServer Man-
agementStudio.
TheNetBeansIDEsSQLEditorprovidesaGUIfrontendwhichworkswithanum-
ber of different database systems, but with limited functionality, while the Eclipse
IDE supports similarfunctionalitythrough theData ToolsPlatform(DTP). Commer-
cialIDEsthatsupportSQLaccessacrossmultipledatabaseplatformsincludeEmbar-
cadero’sRADStudioandAquaDataStudio.
Further Reading
The original Sequel language that became SQL is described in [Chamberlin et al.
(1976)].
The most important SQL reference is likely to be the online documentation pro-
videdbythevendorortheparticulardatabasesystemyouareusing.Thatdocumenta-
tionwillidentifyanyfeaturesthatdeviatefromtheSQLstandardfeaturespresentedin
thischapter.HerearelinkstotheSQLreferencemanualsforthecurrent(asof2018)
versionsofsomeofthepopulardatabases.
• MySQL8.0:dev.mysql.com/doc/refman/8.0/en/
• Oracle12c:docs.oracle.com/database/121/SQLRF/
• PostgreSQL:www.postgresql.org/docs/current/static/sql.html
• SQLite:www.sqlite.org/lang.html
• SQLServer:docs.microsoft.com/en-us/sql/t-sql
Bibliography
[Chamberlinetal.(1976)] D.D.Chamberlin,M.M.Astrahan,K.P.Eswaran,P.P.Griffiths,
R.A.Lorie,J.W.Mehl,P.Reisner,andB.W.Wade,“SEQUEL2:AUnifiedApproachto
Data Definition, Manipulation, and Control”, IBM Journal of Research and Development,
Volume20,Number6(1976),pages560–575.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 154 ---

4
CHAPTER
Intermediate SQL
In this chapter, we continue our study of SQL. We consider more complex forms of
SQLqueries,viewdefinition,transactions,integrityconstraints,moredetailsregarding
SQLdatadefinition,andauthorization.
4.1 Join Expressions
In all of the example queries we used in Chapter 3 (except when we used set opera-
tions),wecombinedinformationfrommultiplerelationsusingtheCartesian product
operator. In this section, we introduce a number of “join” operations that allow the
programmertowritesomequeriesinamorenaturalwayandtoexpresssomequeries
thataredifficulttodowithonlytheCartesianproduct.
ID name dept name tot cred
00128 Zhang Comp.Sci. 102
12345 Shankar Comp.Sci. 32
19991 Brandt History 80
23121 Chavez Finance 110
44553 Peltier Physics 56
45678 Levy Physics 46
54321 Williams Comp.Sci. 54
55739 Sanchez Music 38
70557 Snow Physics 0
76543 Brown Comp.Sci. 58
76653 Aoi Elec.Eng. 60
98765 Bourikas Elec.Eng. 98
98988 Tanaka Biology 120
Figure 4.1 Thestudent relation.
125

--- Page 155 ---

126 Chapter4 IntermediateSQL
ID course id sec id semester year grade
00128 CS-101 1 Fall 2017 A
00128 CS-347 1 Fall 2017 A-
12345 CS-101 1 Fall 2017 C
12345 CS-190 2 Spring 2017 A
12345 CS-315 1 Spring 2018 A
12345 CS-347 1 Fall 2017 A
19991 HIS-351 1 Spring 2018 B
23121 FIN-201 1 Spring 2018 C+
44553 PHY-101 1 Fall 2017 B-
45678 CS-101 1 Fall 2017 F
45678 CS-101 1 Spring 2018 B+
45678 CS-319 1 Spring 2018 B
54321 CS-101 1 Fall 2017 A-
54321 CS-190 2 Spring 2017 B+
55739 MU-199 1 Spring 2018 A-
76543 CS-101 1 Fall 2017 A
76543 CS-319 2 Spring 2018 A
76653 EE-181 1 Spring 2017 C
98765 CS-101 1 Fall 2017 C-
98765 CS-315 1 Spring 2018 B
98988 BIO-101 1 Summer 2017 A
98988 BIO-301 1 Summer 2018 null
Figure 4.2 Thetakesrelation.
All the examples used in this section involve the two relations student and takes,
shown in Figure4.1 and Figure4.2, respectively.Observe that the attribute grade has
avalue nullforthe studentwithID98988, forthecourse BIO-301, section1, taken in
Summer2018.Thenullvalueindicatesthatthegradehasnotbeenawardedyet.
4.1.1 The Natural Join
ConsiderthefollowingSQLquery,whichcomputesforeachstudentthesetofcourses
astudenthastaken:
selectname,course id
fromstudent,takes
wherestudent.ID=takes.ID;
Notethatthisqueryoutputsonlystudentswhohavetakensomecourse.Studentswho
havenottakenanycoursearenotoutput.

--- Page 156 ---

4.1 JoinExpressions 127
Notethatinthestudentandtakestable,thematchingconditionrequiredstudent.ID
tobeequaltotakes.ID.Thesearetheonlyattributesinthetworelationsthathavethe
samename.Infact,thisisacommoncase;thatis,thematchingconditioninthefrom
clausemostoftenrequiresallattributeswithmatchingnamestobeequated.
TomakethelifeofanSQLprogrammereasierforthiscommoncase,SQLsupports
anoperationcalledthenaturaljoin,whichwedescribebelow.Infact,SQLsupportssev-
eralotherwaysinwhichinformationfromtwoormorerelationscanbejoinedtogether.
WehavealreadyseenhowaCartesianproductalongwithawhereclausepredicatecan
beusedtojoininformationfrommultiplerelations.Otherwaysofjoininginformation
frommultiplerelationsarediscussedinSection4.1.2throughSection4.1.4.
Thenaturaljoinoperationoperatesontworelationsandproducesarelationasthe
result.UnliketheCartesianproductoftworelations,whichconcatenateseachtupleof
thefirstrelationwitheverytupleofthesecond,naturaljoinconsidersonlythosepairs
of tuples with the same value on those attributes that appear in the schemas of both
relations.So,goingbacktotheexampleoftherelationsstudentandtakes,computing:
studentnaturaljointakes
considers only those pairs of tuples where both the tuple from student and the tuple
fromtakeshavethesamevalueonthecommonattribute,ID.
Theresultingrelation,shown inFigure4.3,hasonly22tuples, theonesthatgive
information about a student and a course that the student has actually taken. Notice
that we do not repeat those attributes that appear in the schemas of both relations;
rather they appear only once. Notice also the order in whichthe attributes are listed:
first the attributes common to the schemas of both relations, second those attributes
unique to the schema of the first relation, and finally, those attributes unique to the
schemaofthesecondrelation.
Earlierwewrotethequery“Forallstudentsintheuniversitywhohavetakensome
course,findtheirnamesandthecourseIDofallcoursestheytook”as:
selectname,course id
fromstudent,takes
wherestudent.ID=takes.ID;
Thisquerycanbewrittenmoreconciselyusingthenatural-joinoperationinSQLas:
selectname,course id
fromstudentnaturaljointakes;
Bothoftheabovequeriesgeneratethesameresult.1
1Fornotationalsymmetry,SQLallowstheCartesianproduct,whichwehavedenotedwithacomma,tobedenotedby
thekeywordscrossjoin.Thus,“fromstudent,takes”couldbeexpressedequivalentlyas“fromstudentcrossjointakes”.

--- Page 157 ---

128 Chapter4 IntermediateSQL
ID name dept name tot cred course id sec id semester year grade
00128 Zhang Comp.Sci. 102 CS-101 1 Fall 2017 A
00128 Zhang Comp.Sci. 102 CS-347 1 Fall 2017 A-
12345 Shankar Comp.Sci. 32 CS-101 1 Fall 2017 C
12345 Shankar Comp.Sci. 32 CS-190 2 Spring 2017 A
12345 Shankar Comp.Sci. 32 CS-315 1 Spring 2018 A
12345 Shankar Comp.Sci. 32 CS-347 1 Fall 2017 A
19991 Brandt History 80 HIS-351 1 Spring 2018 B
23121 Chavez Finance 110 FIN-201 1 Spring 2018 C+
44553 Peltier Physics 56 PHY-101 1 Fall 2017 B-
45678 Levy Physics 46 CS-101 1 Fall 2017 F
45678 Levy Physics 46 CS-101 1 Spring 2018 B+
45678 Levy Physics 46 CS-319 1 Spring 2018 B
54321 Williams Comp.Sci. 54 CS-101 1 Fall 2017 A-
54321 Williams Comp.Sci. 54 CS-190 2 Spring 2017 B+
55739 Sanchez Music 38 MU-199 1 Spring 2018 A-
76543 Brown Comp.Sci. 58 CS-101 1 Fall 2017 A
76543 Brown Comp.Sci. 58 CS-319 2 Spring 2018 A
76653 Aoi Elec.Eng. 60 EE-181 1 Spring 2017 C
98765 Bourikas Elec.Eng. 98 CS-101 1 Fall 2017 C-
98765 Bourikas Elec.Eng. 98 CS-315 1 Spring 2018 B
98988 Tanaka Biology 120 BIO-101 1 Summer 2017 A
98988 Tanaka Biology 120 BIO-301 1 Summer 2018 null
Figure 4.3 Thenatural joinofthestudent relationwiththetakesrelation.
Theresultofthenaturaljoinoperationisarelation.Conceptually,expression“stu-
dentnaturaljointakes”inthefromclauseisreplacedbytherelationobtainedbyevalu-
atingthenaturaljoin.2Thewhereandselectclausesarethenevaluatedonthisrelation,
aswesawinSection3.3.2.
AfromclauseinanSQLquerycanhavemultiplerelationscombinedusingnatural
join,asshownhere:
selectA , A ,…,A
1 2 n
fromr naturaljoinr naturaljoin... naturaljoinr
1 2 m
whereP;
Moregenerally,afromclausecanbeoftheform
2Asaconsequence,itmaynotbepossibleinsomesystemstouseattributenamescontainingtheoriginalrelation
names,forinstance,student.IDortakes.ID,torefertoattributesinthenaturaljoinresult.Whilesomesystemsallow
it,othersdon’t,andsomeallowitforallattributesexceptthejoinattributes(i.e.,thosethatappearinbothrelation
schemas).Wecan,however,useattributenamessuchasnameandcourseidwithouttherelationnames.

--- Page 158 ---

4.1 JoinExpressions 129
fromE ,E ,...,E
1 2 n
where each E can be a single relation or an expression involving natural joins. For
i
example,supposewewishtoanswerthequery“Listthenamesofstudentsalongwith
thetitlesofcoursesthattheyhavetaken.”ThequerycanbewritteninSQLasfollows:
selectname,title
fromstudentnaturaljointakes,course
wheretakes.courseid =course.course id;
Thenaturaljoinofstudentandtakesisfirstcomputed,aswesawearlier,andaCartesian
product of this result with course is computed, from which the where clause extracts
only those tuples where the course identifier from the join result matches the course
identifierfrom thecourserelation.Note thattakes.course id inthewhereclause refers
to the course id field of the natural join result, since thisfield,in turn, came from the
takesrelation.
Incontrast,thefollowingSQLquerydoesnotcomputethesameresult:
selectname,title
fromstudentnaturaljointakesnaturaljoincourse;
Toseewhy,notethatthenaturaljoinofstudent andtakescontainstheattributes(ID,
name, dept name, tot cred, course id, sec id), while the course relation contains the at-
tributes(course id,title,dept name,credits).Asaresult,thenaturaljoinwouldrequire
that the dept name attribute values from the two relations be the same in addition to
requiring that the course id values be the same. This query would then omit all (stu-
dentname,coursetitle)pairswherethestudenttakesacourseinadepartmentother
than the student’s own department. The previous query, on the other hand, correctly
outputssuchpairs.
To provide the benefit of natural join while avoiding the danger of equating at-
tributeserroneously,SQLprovidesaformofthenaturaljoinconstructthatallowsyou
to specify exactly which columns should be equated. This feature is illustrated by the
followingquery:
selectname,title
from(studentnaturaljointakes)joincourseusing(course id);
The operation join … using requires a list of attribute names to be specified. Both
relationsbeingjoinedmusthaveattributeswiththespecifiednames.Considertheop-
erationr joinr using(A ,A ).Theoperationissimilartor naturaljoinr ,exceptthat
1 2 1 2 1 2
apairoftuplest fromr andt fromr matchift .A = t .A andt .A = t .A ;even
1 1 2 2 1 1 2 1 1 2 2 2
ifr andr bothhaveanattributenamedA ,itisnotrequiredthatt .A = t .A .
1 2 3 1 3 2 3

--- Page 159 ---

130 Chapter4 IntermediateSQL
Thus,intheprecedingSQLquery,thejoinconstructpermitsstudent.dept nameand
course.dept nametodiffer,andtheSQLquerygivesthecorrectanswer.
4.1.2 Join Conditions
In Section 4.1.1, we saw how to express natural joins, and we saw the join … using
clause,whichisaformofnatural jointhatrequiresvaluestomatchonlyonspecified
attributes.SQLsupportsanotherformofjoin,inwhichanarbitraryjoinconditioncan
bespecified.
The on condition allows a general predicate over the relations being joined. This
predicateiswrittenlikeawhereclausepredicateexceptfortheuse ofthekeyword on
ratherthanwhere.Liketheusingcondition,theonconditionappearsattheendofthe
joinexpression.
Considerthe followingquery, whichhas ajoin expression containingthe on con-
dition:
select*
fromstudentjointakesonstudent.ID=takes.ID;
Theonconditionabovespecifiesthatatuplefromstudent matchesatuplefromtakes
if theirID values are equal. The join expression in thiscase isalmost the same as the
joinexpressionstudentnaturaljointakes,sincethenaturaljoinoperationalsorequires
thatforastudenttupleandatakestupletomatch.Theonedifferenceisthattheresult
hastheIDattributelistedtwice,inthejoinresult,onceforstudentandoncefortakes,
eventhoughtheirIDvaluesmustbethesame.
Infact,theprecedingqueryisequivalenttothefollowingquery:
select*
fromstudent,takes
wherestudent.ID=takes.ID;
Aswehaveseenearlier,therelationnameisusedtodisambiguatetheattributenameID,
andthusthetwooccurrencescanbereferredtoasstudent.IDandtakes.ID,respectively.
AversionofthisquerythatdisplaystheIDvalueonlyonceisasfollows:
selectstudent.IDasID,name,dept name,tot cred,
course id,sec id,semester,year,grade
fromstudentjointakesonstudent.ID=takes.ID;
The result of this query is exactly the same as the result of the natural join of student
andtakes,whichweshowedinFigure4.3.
The on conditioncan express any SQLpredicate,and thusjoin expressions using
theonconditioncanexpressaricherclassofjoinconditionsthannaturaljoin.However,

--- Page 160 ---

4.1 JoinExpressions 131
as illustrated by our preceding example, a query using a join expression with an on
conditioncanbereplacedbyanequivalentexpression withoutthe oncondition,with
thepredicateintheonclausemovedtothewhereclause.Thus,itmayappearthatthe
onconditionisaredundantfeatureofSQL.
However, there are two good reasons for introducing the on condition. First, we
shall see shortly that for a kind of join called an outer join, on conditions do behave
in a manner different from where conditions. Second, an SQL query is often more
readable by humans if the join condition is specified in the on clause and the rest of
theconditionsappearinthewhereclause.
4.1.3 Outer Joins
Suppose we wish to display a list of all students, displaying their ID, and name, dept
name, and tot cred, along with the courses that they have taken. The following SQL
querymayappeartoretrievetherequiredinformation:
select*
fromstudentnaturaljointakes;
Unfortunately, the above query does not work quite as intended. Suppose that there
is some student who takes no courses. Then the tuple in the student relation for that
particularstudentwouldnotsatisfytheconditionofanaturaljoinwithanytupleinthe
takes relation, and that student’s data would not appear in the result. We would thus
notseeanyinformationaboutstudentswhohavenottakenanycourses.Forexample,
inthestudentandtakesrelationsofFigure4.1andFigure4.2,notethatstudentSnow,
with ID 70557, has not taken any courses. Snow appears in student, but Snow’s ID
numberdoesnotappearintheIDcolumnoftakes.Thus,Snowdoesnotappearinthe
resultofthenaturaljoin.
More generally, some tuples in either or both of the relations being joined may
be “lost” in this way. The outer-join operation works in a manner similar to the join
operationswehavealreadystudied,butitpreservesthosetuplesthatwouldbelostin
ajoinbycreatingtuplesintheresultcontainingnullvalues.
Forexample,toensurethatthestudentnamedSnowfromourearlierexampleap-
pearsintheresult,atuplecouldbeaddedtothejoinresultwithallattributesfromthe
studentrelationsettothecorrespondingvaluesforthestudentSnow,andalltheremain-
ing attributes which come from the takes relation, namely, course id, sec id, semester,
andyear,settonull.Thus,thetupleforthestudentSnowispreservedintheresultof
theouterjoin.
Therearethreeformsofouterjoin:
• The left outer join preserves tuples only in the relation named before (to the left
of)theleftouterjoinoperation.

--- Page 161 ---

132 Chapter4 IntermediateSQL
• Therightouterjoinpreservestuplesonlyintherelationnamedafter(totheright
of)therightouterjoinoperation.
• Thefullouterjoinpreservestuplesinbothrelations.
Incontrast,thejoinoperationswestudiedearlierthatdonotpreservenonmatchedtu-
plesarecalledinner-joinoperations,todistinguishthemfromtheouter-joinoperations.
We now explain exactly how each form of outer join operates. We can compute
the left outer-join operation as follows: First, compute the result of the inner join as
before. Then, for every tuple t in the left-hand-side relation that does not match any
tupleintheright-hand-siderelationintheinnerjoin,addatupler totheresultofthe
joinconstructedasfollows:
• Theattributesoftupler thatarederivedfromtheleft-hand-siderelationarefilled
inwiththevaluesfromtuplet.
• Theremainingattributesofr arefilledwithnullvalues.
Figure4.4showstheresultof:
select*
fromstudentnaturalleftouterjointakes;
That result includes student Snow (ID 70557), unlike the result of an inner join, but
the tuple for Snow includesnulls for the attributes that appear only in the schemaof
thetakesrelation.3
Asanotherexampleoftheuseoftheouter-joinoperation,wecanwritethequery
“Findallstudentswhohavenottakenacourse”as:
selectID
fromstudentnaturalleftouterjointakes
wherecourse id isnull;
Therightouterjoinissymmetrictotheleftouterjoin.Tuplesfromtheright-hand-
siderelationthatdonotmatchanytupleintheleft-hand-siderelationarepaddedwith
nullsandareaddedtotheresultoftherightouterjoin.Thus,ifwerewritethepreceding
queryusingarightouterjoinandswappingtheorderinwhichwelisttherelationsas
follows:
select*
fromtakesnaturalrightouterjoinstudent;
wegetthesameresultexceptfortheorderinwhichtheattributesappearintheresult
(seeFigure4.5).
3Weshownullvaluesintablesusingnull,butmostsystemsdisplaynullvaluesasablankfield.

--- Page 162 ---

4.1 JoinExpressions 133
ID name dept name tot cred course id sec id semester year grade
00128 Zhang Comp.Sci. 102 CS-101 1 Fall 2017 A
00128 Zhang Comp.Sci. 102 CS-347 1 Fall 2017 A-
12345 Shankar Comp.Sci. 32 CS-101 1 Fall 2017 C
12345 Shankar Comp.Sci. 32 CS-190 2 Spring 2017 A
12345 Shankar Comp.Sci. 32 CS-315 1 Spring 2018 A
12345 Shankar Comp.Sci. 32 CS-347 1 Fall 2017 A
19991 Brandt History 80 HIS-351 1 Spring 2018 B
23121 Chavez Finance 110 FIN-201 1 Spring 2018 C+
44553 Peltier Physics 56 PHY-101 1 Fall 2017 B-
45678 Levy Physics 46 CS-101 1 Fall 2017 F
45678 Levy Physics 46 CS-101 1 Spring 2018 B+
45678 Levy Physics 46 CS-319 1 Spring 2018 B
54321 Williams Comp.Sci. 54 CS-101 1 Fall 2017 A-
54321 Williams Comp.Sci. 54 CS-190 2 Spring 2017 B+
55739 Sanchez Music 38 MU-199 1 Spring 2018 A-
70557 Snow Physics 0 null null null null null
76543 Brown Comp.Sci. 58 CS-101 1 Fall 2017 A
76543 Brown Comp.Sci. 58 CS-319 2 Spring 2018 A
76653 Aoi Elec.Eng. 60 EE-181 1 Spring 2017 C
98765 Bourikas Elec.Eng. 98 CS-101 1 Fall 2017 C-
98765 Bourikas Elec.Eng. 98 CS-315 1 Spring 2018 B
98988 Tanaka Biology 120 BIO-101 1 Summer 2017 A
98988 Tanaka Biology 120 BIO-301 1 Summer 2018 null
Figure 4.4 Resultofstudent naturalleftouterjointakes.
Thefullouterjoinisacombinationoftheleftandrightouter-jointypes.Afterthe
operationcomputestheresultoftheinnerjoin,itextendswithnullsthosetuplesfrom
theleft-hand-siderelationthatdidnotmatchwithanyfromtheright-hand-siderelation
andaddsthemtotheresult.Similarly,itextendswithnullsthosetuplesfromtheright-
hand-side relation that did not match with any tuples from the left-hand-side relation
andaddsthemtotheresult.Saiddifferently,fullouterjoinistheunionofaleftouter
joinandthecorrespondingrightouterjoin.4
Asanexampleoftheuseoffullouterjoin,considerthefollowingquery:“Display
a list of all students in the Comp. Sci. department, along with the course sections, if
any, that they have taken in Spring 2017; all course sections from Spring 2017 must
4Inthosesystems,notablyMySQL,thatimplementonlyleftandrightouterjoin,thisisexactlyhowonehastowritea
fullouterjoin.

--- Page 163 ---

134 Chapter4 IntermediateSQL
ID course id sec id semester year grade name dept name tot cred
00128 CS-101 1 Fall 2017 A Zhang Comp.Sci. 102
00128 CS-347 1 Fall 2017 A- Zhang Comp.Sci. 102
12345 CS-101 1 Fall 2017 C Shankar Comp.Sci. 32
12345 CS-190 2 Spring 2017 A Shankar Comp.Sci. 32
12345 CS-315 1 Spring 2018 A Shankar Comp.Sci. 32
12345 CS-347 1 Fall 2017 A Shankar Comp.Sci. 32
19991 HIS-351 1 Spring 2018 B Brandt History 80
23121 FIN-201 1 Spring 2018 C+ Chavez Finance 110
44553 PHY-101 1 Fall 2017 B- Peltier Physics 56
45678 CS-101 1 Fall 2017 F Levy Physics 46
45678 CS-101 1 Spring 2018 B+ Levy Physics 46
45678 CS-319 1 Spring 2018 B Levy Physics 46
54321 CS-101 1 Fall 2017 A- Williams Comp.Sci. 54
54321 CS-190 2 Spring 2017 B+ Williams Comp.Sci. 54
55739 MU-199 1 Spring 2018 A- Sanchez Music 38
70557 null null null null null Snow Physics 0
76543 CS-101 1 Fall 2017 A Brown Comp.Sci. 58
76543 CS-319 2 Spring 2018 A Brown Comp.Sci. 58
76653 EE-181 1 Spring 2017 C Aoi Elec.Eng. 60
98765 CS-101 1 Fall 2017 C- Bourikas Elec.Eng. 98
98765 CS-315 1 Spring 2018 B Bourikas Elec.Eng. 98
98988 BIO-101 1 Summer 2017 A Tanaka Biology 120
98988 BIO-301 1 Summer 2018 null Tanaka Biology 120
Figure 4.5 Theresultoftakesnaturalrightouterjoinstudent.
bedisplayed,evenifnostudentfromtheComp.Sci.departmenthastakenthecourse
section.”Thisquerycanbewrittenas:
select*
from(select*
fromstudent
wheredept name='Comp.Sci.')
naturalfullouterjoin
(select*
fromtakes
wheresemester ='Spring'andyear =2017);
TheresultappearsinFigure4.6.

--- Page 164 ---

4.1 JoinExpressions 135
ID name dept name tot cred course id sec id semester year grade
00128 Zhang Comp.Sci. 102 null null null null null
12345 Shankar Comp.Sci. 32 CS-190 2 Spring 2017 A
54321 Williams Comp.Sci. 54 CS-190 2 Spring 2017 B+
76543 Brown Comp.Sci. 58 null null null null null
76653 null null null ECE-181 1 Spring 2017 C
Figure 4.6 Resultoffullouterjoinexample(seetext).
Theonclausecanbeusedwithouterjoins.Thefollowingqueryisidenticaltothe
firstquerywesawusing“studentnaturalleftouterjointakes,”exceptthattheattribute
IDappearstwiceintheresult.
select*
fromstudentleftouterjointakesonstudent.ID=takes.ID;
As we noted earlier, on and where behave differently for outer join. The reason
for this is that outer join adds null-padded tuples only for those tuples that do not
contributetotheresultofthecorresponding“inner”join.Theonconditionispartof
the outer join specification,but a where clause is not. In our example, the case of the
studenttupleforstudent“Snow”withID70557,illustratesthisdistinction.Supposewe
modifytheprecedingquerybymovingtheonclausepredicatetothewhereclauseand
insteadusinganonconditionoftrue.5
select*
fromstudentleftouterjointakesontrue
wherestudent.ID=takes.ID;
The earlier query, using the left outer join with the on condition, includes a tuple
(70557, Snow, Physics, 0, null, null, null, null, null, null ) because there is no tuple
in takes with ID = 70557. In the latter query, however, every tuple satisfies the join
conditiontrue,sononull-paddedtuplesaregeneratedbytheouterjoin.Theouterjoin
actually generates the Cartesian product of the two relations. Since there is no tuple
in takes with ID = 70557, every time a tuple appears in the outer join with name =
“Snow”,thevaluesforstudent.IDandtakes.IDmustbedifferent,andsuchtupleswould
beeliminatedbythewhereclausepredicate.Thus,studentSnowneverappearsinthe
resultofthelatterquery.
5SomesystemsdonotallowtheuseoftheBooleanconstanttrue.Totestthisonthosesystems,useatautology(i.e.,a
predicatethatalwaysevaluatestotrue),like“1=1”.

--- Page 165 ---

136 Chapter4 IntermediateSQL
Note 4.1 SQLANDMULTISETRELATIONALALGEBRA-PART4
The relational algebra supports the left outer-join operation, denoted by ⟕ , the
θ
right outer-join operation, denoted by ⟖ , and the full outer-join operation, de-
θ
notedby⟗ .Italsosupportsthenaturaljoinoperation,denotedby⋈,aswellas
θ
the natural join versions of the left, right and full outer-join operations, denoted
by⟕,⟖,and⟗.Thedefinitionsofalltheseoperationsareidenticaltothedef-
initions of the corresponding operations in SQL, which we have seen in Section
4.1.
4.1.4 Join Types and Conditions
Todistinguishnormaljoinsfromouterjoins,normaljoinsarecalledinnerjoinsinSQL.
A joinclause canthus specify inner join instead ofouter join tospecify thatanormal
joinistobeused.Thekeywordinneris,however,optional.Thedefaultjointype,when
thejoinclauseisusedwithouttheouterprefix,istheinnerjoin.Thus,
select*
fromstudentjointakesusing(ID);
isequivalentto:
select*
fromstudentinnerjointakesusing(ID);
Similarly,naturaljoinisequivalenttonaturalinnerjoin.
Figure4.7showsafulllistofthevarioustypesofjointhatwehavediscussed.As
canbeseenfromthefigure,anyformofjoin(inner,leftouter,rightouter,orfullouter)
canbecombinedwithanyjoincondition(natural,using,oron).
Jointypes Joinconditions
inner join natural
leftouterjoin on <predicate>
rightouterjoin using (A , A , . . .,A )
1 2 n
fullouter join
Figure 4.7 Jointypesandjoinconditions.

--- Page 166 ---

4.2 Views 137
4.2 Views
Itisnotalwaysdesirableforalluserstoseetheentiresetofrelationsinthedatabase.
In Section 4.7, we shall see how to use the SQL authorization mechanism to restrict
accesstorelations,butsecurityconsiderationsmayrequirethatonlycertaindataina
relationbehiddenfromauser.Consideraclerkwhoneedstoknowaninstructor’sID,
name, and department name, but does not have authorization to see the instructor’s
salaryamount.ThispersonshouldseearelationdescribedinSQLby:
selectID,name,dept name
frominstructor;
Asidefromsecurityconcerns,wemaywishtocreateapersonalizedcollectionof“vir-
tual”relationsthatisbettermatchedtoacertainuser’sintuitionofthestructureofthe
enterprise.Inouruniversityexample,wemaywanttohavealistofallcoursesections
offered by the Physics department in the Fall 2017 semester, with the building and
room number ofeach section.The relationthatwe wouldcreate for obtainingsuch a
listis:
selectcourse.course id,sec id,building,room number
fromcourse,section
wherecourse.course id =section.course id
andcourse.dept name='Physics'
andsection.semester ='Fall'
andsection.year =2017;
Itispossibletocomputeandstoretheresultsofthesequeriesandthenmakethe
storedrelationsavailabletousers.However,ifwedidso,andtheunderlyingdatainthe
relationsinstructor,course,orsection changed,thestoredqueryresultswouldthenno
longermatchtheresultofreexecutingthequeryontherelations.Ingeneral,itisabad
ideatocomputeandstorequeryresultssuchasthoseintheaboveexamples(although
therearesomeexceptionsthatwestudylater).
Instead, SQL allowsa“virtual relation”tobe definedby aquery, and the relation
conceptuallycontainstheresultofthequery.Thevirtualrelationisnotprecomputed
andstoredbutinsteadiscomputedbyexecutingthequerywheneverthevirtualrelation
isused.WesawafeatureforthisinSection3.8.6,wherewedescribedthewithclause.
Thewithclauseallowsustotoassignanametoasubqueryforuseasoftenasdesired,
butinoneparticularqueryonly.Here,wepresentawaytoextendthisconceptbeyond
a single query by defininga view. It ispossible to support a large number of views on
topofanygivensetofactualrelations.

--- Page 167 ---

138 Chapter4 IntermediateSQL
4.2.1 View Definition
WedefineaviewinSQLbyusingthecreateviewcommand.Todefineaview,wemust
givetheviewanameandmuststatethequerythatcomputestheview.Theformofthe
createviewcommandis:
createviewvas<queryexpression>;
where<queryexpression>isanylegalqueryexpression.Theviewnameisrepresented
byv.
Consider again the clerk who needs to access all data in the instructor relation,
exceptsalary.Theclerkshouldnotbeauthorizedtoaccesstheinstructor relation(we
seeinSection4.7,howauthorizationscanbespecified).Instead,aviewrelationfaculty
canbemadeavailabletotheclerk,withtheviewdefinedasfollows:
createviewfacultyas
selectID,name,dept name
frominstructor;
Asexplainedearlier,theviewrelationconceptuallycontainsthetuplesinthequery
result, but it is not precomputed and stored. Instead, the database system stores the
query expression associated with the view relation. Whenever the view relation is ac-
cessed,itstuplesarecreatedbycomputingthequeryresult.Thus,theviewrelationis
createdwheneverneeded,ondemand.
TocreateaviewthatlistsallcoursesectionsofferedbythePhysicsdepartmentin
theFall2017semesterwiththebuildingandroomnumberofeachsection,wewrite:
createviewphysics fall 2017 as
selectcourse.course id,sec id,building,room number
fromcourse,section
wherecourse.course id =section.course id
andcourse.dept name='Physics'
andsection.semester ='Fall'
andsection.year =2017;
Later,whenwestudytheSQLauthorizationmechanisminSection4.7,weshallsee
thatuserscanbegivenaccesstoviewsinplaceof,orinadditionto,accesstorelations.
Viewsdifferfromthewithstatementinthatviews,oncecreated,remainavailable
until explicitly dropped. The named subquery defined by with is local to the query in
whichitisdefined.
4.2.2 Using Views in SQL Queries
Oncewehavedefinedaview,wecanusetheviewnametorefertothevirtualrelation
thattheviewgenerates.Usingtheviewphysics fall 2017,wecanfindallPhysicscourses
offeredintheFall2017semesterintheWatsonbuildingbywriting:

--- Page 168 ---

4.2 Views 139
selectcourse id
fromphysics fall 2017
wherebuilding='Watson';
Viewnamesmayappearinaqueryanyplacewherearelationnamemayappear,
Theattributenamesofaviewcanbespecifiedexplicitlyasfollows:
createviewdepartments totalsalary(dept name,totalsalary)as
selectdept name,sum(salary)
frominstructor
groupbydept name;
Theprecedingviewgivesforeachdepartmentthesumofthesalariesofalltheinstruc-
tors at that department. Since the expression sum(salary) does not have a name, the
attributenameisspecifiedexplicitlyintheviewdefinition.
Intuitively, at any given time, the set of tuples in the view relation is the result
of evaluation of the query expression that defines the view. Thus, if a view relation is
computed and stored, it may become out of date if the relations used to define it are
modified. To avoid this, views are usually implemented as follows: When we define a
view,thedatabasesystemstoresthedefinitionoftheviewitself,ratherthantheresult
of evaluation of the query expression that defines the view. Wherever a view relation
appears in a query, it is replaced by the stored query expression. Thus, whenever we
evaluatethequery,theviewrelationisrecomputed.
One view may be used in the expression defining another view. For example, we
candefineaviewphysics fall 2017watsonthatliststhecourseIDandroomnumberof
allPhysicscoursesofferedintheFall2017semesterintheWatsonbuildingasfollows:
createviewphysics fall 2017watsonas
selectcourse id,room number
fromphysics fall 2017
wherebuilding='Watson';
wherephysics fall 2017 watsonisitselfaviewrelation.Thisisequivalentto:
createviewphysics fall 2017watsonas
selectcourse id,room number
from(selectcourse.course id,building,room number
fromcourse,section
wherecourse.course id =section.course id
andcourse.dept name='Physics'
andsection.semester ='Fall'
andsection.year =2017)
wherebuilding='Watson';

--- Page 169 ---

140 Chapter4 IntermediateSQL
4.2.3 Materialized Views
Certaindatabasesystemsallowviewrelationstobestored,buttheymakesurethat,if
theactualrelationsusedintheviewdefinitionchange,theviewiskeptup-to-date.Such
viewsarecalledmaterializedviews.
For example, consider the view departmentstotal salary. If that view is material-
ized,its results would be stored in the database, allowingqueries that use the view to
potentiallyrunmuchfasterbyusingtheprecomputedviewresult,insteadofrecomput-
ingit.
However, if an instructor tuple is added to or deleted from the instructor relation,
theresultofthequerydefiningtheviewwouldchange,andasaresultthematerialized
view’s contents must be updated. Similarly, if an instructor’s salary is updated, the
tuple in departments total salary corresponding to that instructor’s department must
beupdated.
Theprocessofkeepingthematerializedviewup-to-dateiscalledmaterializedview
maintenance (or often, just view maintenance) and is covered in Section 16.5. View
maintenancecanbedoneimmediatelywhenanyoftherelationsonwhichtheviewis
definedisupdated.Somedatabasesystems,however,performviewmaintenancelazily,
whentheviewisaccessed.Somesystemsupdatematerializedviewsonlyperiodically;
inthiscase,thecontentsofthematerializedviewmaybestale,thatis,notup-to-date,
when it is used, and it should not be used if the application needs up-to-date data.
Andsomedatabasesystemspermitthedatabaseadministratortocontrolwhichofthe
precedingmethodsisusedforeachmaterializedview.
Applications that use a view frequently may benefit if the view is materialized.
Applicationsthatdemandfastresponsetocertainqueriesthatcomputeaggregatesover
largerelationscanalsobenefitgreatlybycreatingmaterializedviewscorrespondingto
the queries. In this case, the aggregated result is likely to be much smaller than the
large relations on which the view is defined; as a result the materialized view can be
usedtoanswerthequeryveryquickly,avoidingreadingthelargeunderlyingrelations.
Thebenefitstoqueriesfromthematerializationofaviewmustbeweighedagainstthe
storagecostsandtheaddedoverheadforupdates.
SQL does not define a standard way of specifying that a view is materialized,
but many database systems provide their own SQL extensions for this task. Some
database systems always keep materialized views up-to-date when the underlying re-
lations change, while others permit them to become out of date and periodically re-
computethem.
4.2.4 Update of a View
Althoughviewsareausefultoolforqueries,theypresentseriousproblemsifweexpress
updates,insertions,ordeletionswiththem.Thedifficultyisthatamodificationtothe
databaseexpressedintermsofaviewmustbetranslatedtoamodificationtotheactual
relationsinthelogicalmodelofthedatabase.

--- Page 170 ---

4.2 Views 141
Supposetheviewfaculty,whichwesawearlier,ismadeavailabletoaclerk.Since
we allow a view name to appear wherever a relation name is allowed, the clerk can
write:
insertintofaculty
values('30765','Green','Music');
This insertion must be represented by an insertion into the relation instructor, since
instructor is the actual relation from which the database system constructs the view
faculty.However,toinsertatupleintoinstructor,wemusthavesomevalue forsalary.
Therearetworeasonableapproachestodealingwiththisinsertion:
• Rejecttheinsertion,andreturnanerrormessagetotheuser.
• Insertatuple('30765','Green','Music',null)intotheinstructor relation.
Another problem with modification of the database through views occurs with a
viewsuchas:
createviewinstructor infoas
selectID,name,building
frominstructor,department
whereinstructor.dept name=department.dept name;
This view lists the ID, name, and building-name of each instructor in the university.
Considerthefollowinginsertionthroughthisview:
insertintoinstructor info
values('69987','White','Taylor');
Suppose there is no instructor with ID 69987, and no department in the Taylor
building.Thentheonlypossiblemethodofinsertingtuplesintotheinstructor andde-
partment relations is to insert ('69987', 'White', null, null) into instructor and (null,
'Taylor',null)intodepartment.ThenweobtaintherelationsshowninFigure4.8.How-
ever,thisupdatedoesnothavethedesiredeffect,sincetheviewrelationinstructor info
stilldoesnotincludethetuple('69987','White','Taylor').Thus,thereisnowaytoup-
datetherelationsinstructoranddepartmentbyusingnullstogetthedesiredupdateon
instructor info.
Because of problems such as these, modifications are generally not permitted on
viewrelations,exceptinlimitedcases.Differentdatabasesystemsspecifydifferentcon-
ditions under which they permit updates on view relations; see the database system
manualsfordetails.
Ingeneral,anSQLviewissaidtobeupdatable(i.e.,inserts,updates,ordeletescan
beappliedontheview)ifthefollowingconditionsareallsatisfiedbythequerydefining
theview:
• Thefromclausehasonlyonedatabaserelation.

--- Page 171 ---

142 Chapter4 IntermediateSQL
ID name dept name salary
10101 Srinivasan Comp.Sci. 65000
12121 Wu Finance 90000
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 ElSaid History 60000
33456 Gold Physics 87000
45565 Katz Comp.Sci. 75000
58583 Califieri History 62000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp.Sci. 92000
98345 Kim Elec.Eng. 80000
69987 White null null
instructor
dept name building budget
Biology Watson 90000
Comp.Sci. Taylor 100000
ElectricalEng. Taylor 85000
Finance Painter 120000
History Painter 50000
Music Packard 80000
Physics Watson 70000
null Taylor null
department
Figure 4.8 Relationsinstructor anddepartment afterinsertionoftuples.
• Theselectclausecontainsonlyattributenamesoftherelationanddoesnothave
anyexpressions,aggregates,ordistinctspecification.
• Any attribute not listed in the select clause can be set to null; that is, it does not
haveanotnullconstraintandisnotpartofaprimarykey.
• Thequerydoesnothaveagroupbyorhavingclause.
Undertheseconstraints,theupdate,insert,anddeleteoperationswouldbeallowedon
thefollowingview:

--- Page 172 ---

4.3 Transactions 143
createviewhistory instructorsas
select*
frominstructor
wheredept name='History';
Evenwiththeconditionsonupdatability,thefollowingproblemstillremains.Sup-
pose thatausertriestoinsertthetuple('25566', 'Brown','Biology',100000) intothe
history instructors view. This tuple can be inserted into the instructor relation, but it
would not appear in the history instructors view since it does not satisfy the selection
imposedbytheview.
Bydefault,SQLwouldallowtheabove update toproceed.However,viewscanbe
definedwithawithcheckoptionclauseattheendoftheviewdefinition;then,ifatuple
insertedintotheviewdoesnotsatisfytheview’swhereclausecondition,theinsertion
isrejectedbythedatabasesystem.Updatesaresimilarlyrejectedifthenewvaluedoes
notsatisfythewhereclauseconditions.
SQL:1999hasamorecomplexsetofrulesaboutwheninserts,updates,anddeletes
canbeexecutedonaviewthatallowsupdatesthroughalargerclassofviews;however,
therulesaretoocomplextobediscussedhere.
Analternative,andoftenpreferable,approachtomodifyingthedatabasethrougha
viewistousethetriggermechanismdiscussedinSection5.3.Theinsteadoffeaturein
declaringtriggersallowsonetoreplacethedefaultinsert,update,anddeleteoperations
onaviewwithactionsdesignedespeciallyforeachparticularcase.
4.3 Transactions
Atransactionconsistsofasequenceofqueryand/orupdatestatements.TheSQLstan-
dardspecifiesthatatransactionbeginsimplicitlywhenanSQLstatementisexecuted.
OneofthefollowingSQLstatementsmustendthetransaction:
• Commit work commits the current transaction; that is, it makes the updates per-
formed by the transaction become permanent in the database. After the transac-
tioniscommitted,anewtransactionisautomaticallystarted.
• Rollback work causes the current transaction to be rolled back; that is, it undoes
all the updates performed by the SQL statements in the transaction. Thus, the
databasestateisrestoredtowhatitwasbeforethefirststatementofthetransaction
wasexecuted.
Thekeywordworkisoptionalinboththestatements.
Transactionrollbackisusefulifsomeerrorconditionisdetectedduringexecution
of a transaction. Commit is similar, in a sense, to saving changes to a document that
is being edited, while rollback is similar to quitting the edit session without saving

--- Page 173 ---

144 Chapter4 IntermediateSQL
changes. Once a transaction has executed commit work, its effects can no longer be
undone by rollback work. The database system guarantees that in the event of some
failure, such as an error in one of the SQL statements, a power outage, or a system
crash,atransaction’seffectswillberolledbackifithasnotyetexecutedcommitwork.
Inthecaseofpoweroutageorothersystemcrash,therollbackoccurswhenthesystem
restarts.
For instance, consider a banking application where we need to transfer money
from one bank account to another in the same bank. To do so, we need to update
two account balances, subtracting the amount transferred from one, and adding it to
the other. If the system crashes after subtracting the amount from the first account
but before adding it to the second account, the bank balances will be inconsistent. A
similarproblemoccursifthesecondaccountiscreditedbeforesubtractingtheamount
fromthefirstaccountandthesystemcrashesjustaftercreditingtheamount.
Asanotherexample,considerourrunningexampleofauniversityapplication.We
assume that the attribute tot cred of each tuple in the student relation is kept up-to-
date by modifying it whenever the student successfully completes a course. To do so,
wheneverthetakesrelationisupdatedtorecordsuccessfulcompletionofacoursebya
student(byassigninganappropriategrade),thecorrespondingstudenttuplemustalso
be updated. Iftheapplicationperformingthese twoupdates crashesafterone update
isperformed,butbeforethesecondoneisperformed,thedatainthedatabasewillbe
inconsistent.
Byeithercommittingtheactionsofatransactionafterallitsstepsarecompleted,
orrollingbackallitsactionsincasethetransactioncouldnotcompleteallitsactions
successfully,thedatabaseprovidesanabstractionofatransactionasbeingatomic,that
is, indivisible. Either all the effects of the transaction are reflected in the database or
noneare(afterrollback).
Applying the notion of transactions to the above applications, the update state-
mentsshouldbeexecutedasasingletransaction.Anerrorwhileatransactionexecutes
oneofitsstatementswouldresultinundoingtheeffectsoftheearlierstatementsofthe
transactionsothatthedatabaseisnotleftinapartiallyupdatedstate.
Ifaprogramterminateswithoutexecutingeitherofthesecommands,theupdates
are either committed or rolled back. The standard does not specify which of the two
happens,andthechoiceisimplementationdependent.
InmanySQLimplementations,includingMySQLandPostgreSQL,bydefaulteach
SQL statement is taken to be a transaction on its own, and itgets committed as soon
asitisexecuted.Suchautomaticcommit ofindividualSQLstatementsmustbeturned
off if a transaction consisting of multiple SQL statements needs to be executed. How
to turn off automatic commitdepends on the specific SQL implementation, although
manydatabasessupportthecommandsetautocommitoff.6
6ThereisastandardwayofturningautocommitonoroffwhenusingapplicationprograminterfacessuchasJDBCor
ODBC,whichwestudyinSection5.1.1andSection5.1.3,respectively.

--- Page 174 ---

4.4 IntegrityConstraints 145
Abetteralternative,whichispartoftheSQL:1999standardistoallowmultipleSQL
statementstobeenclosedbetweenthekeywordsbeginatomic…end.Allthestatements
betweenthekeywordsthenformasingletransaction,whichiscommittedbydefaultif
executionreachestheendstatement.Onlysomedatabases,suchasSQLServer,support
the above syntax. However, several other databases, such as MySQL and PostgreSQL,
support a begin statement which starts a transaction containing all subsequent SQL
statements, but do not support the end statement; instead, the transaction must be
endedbyeitheracommitworkorarollbackworkcommand.
IfyouuseadatabasesuchasOracle,wheretheautomaticcommitisnotthedefault
for DML statements, be sure to issue a commit command after adding or modifying
data,orelsewhenyoudisconnect,allyourdatabasemodificationswillberolledback!7
YoushouldbeawarethatalthoughOraclehasautomaticcommitturnedoffbydefault,
thatdefaultmaybeoverriddenbylocalconfigurationsettings.
WestudyfurtherpropertiesoftransactionsinChapter17;issuesinimplementing
transactionsareaddressedinChapter18andChapter19.
4.4 Integrity Constraints
Integrity constraints ensure that changes made to the database by authorized users
do not result in a loss of data consistency. Thus, integrity constraints guard against
accidental damage to the database. This is in contrast to security constraints, which
guardagainstaccesstothedatabasebyunauthorizedusers.
Examplesofintegrityconstraintsare:
• Aninstructornamecannotbenull.
• NotwoinstructorscanhavethesameinstructorID.
• Every department name in the course relation must have a matchingdepartment
nameinthedepartmentrelation.
• Thebudgetofadepartmentmustbegreaterthan$0.00.
In general, an integrity constraint can be an arbitrary predicate pertaining to the
database. However, arbitrary predicates may be costly to test. Thus, most database
systems allow one to specify only those integrity constraints that can be tested with
minimaloverhead.
WehavealreadyseensomeformsofintegrityconstraintsinSection3.2.2.Westudy
somemoreformsofintegrityconstraintsinthissection.InChapter7,westudyanother
formofintegrityconstraint,calledfunctionaldependencies,thatisusedprimarilyinthe
processofschemadesign.
7OracledoesautomaticallycommitDDLstatements.

--- Page 175 ---

146 Chapter4 IntermediateSQL
Integrity constraints are usually identified as part of the database schema design
process and declared as part of the create table command used to create relations.
However, integrity constraints can also be added to an existing relation by using the
commandaltertabletable-nameaddconstraint,whereconstraintcanbeanyconstraint
ontherelation.Whensuchacommandisexecuted,thesystemfirstensuresthatthere-
lationsatisfiesthespecifiedconstraint.Ifitdoes,theconstraintisaddedtotherelation;
ifnot,thecommandisrejected.
4.4.1 Constraints on a Single Relation
WedescribedinSection3.2howtodefinetablesusingthecreatetablecommand.The
createtablecommandmayalsoincludeintegrity-constraintstatements.Inadditionto
the primary-key constraint, there are a number of other ones that can be included in
thecreatetablecommand.Theallowedintegrityconstraintsinclude
• notnull
• unique
• check(<predicate>)
Wecovereachofthesetypesofconstraintsinthefollowingsections.
4.4.2 Not Null Constraint
AswediscussedinChapter3,thenullvalueisamemberofalldomains,andasaresult
itisalegalvalueforeveryattributeinSQLbydefault.Forcertainattributes,however,
nullvaluesmaybeinappropriate.Consideratupleinthestudentrelationwherename
isnull.Suchatuplegivesstudentinformationforanunknownstudent;thus,itdoesnot
containusefulinformation.Similarly,wewouldnotwantthedepartmentbudgettobe
null.Incasessuchasthis,wewishtoforbidnullvalues,andwecandosobyrestricting
thedomainoftheattributesnameandbudgettoexcludenullvalues,bydeclaringitas
follows:
name varchar(20)notnull
budgetnumeric(12,2)notnull
The not null constraint prohibits the insertion of a null value for the attribute, and is
anexampleofadomainconstraint.Anydatabasemodificationthatwouldcauseanull
tobeinsertedinanattributedeclaredtobenotnullgeneratesanerrordiagnostic.
There are many situations where we want to avoid null values. In particular, SQL
prohibits null values in the primary key of a relation schema. Thus, in our university
example,inthedepartmentrelation,iftheattributedept nameisdeclaredastheprimary
key for department, it cannot take a null value. As a result it would not need to be
declaredexplicitlytobenotnull.

--- Page 176 ---

4.4 IntegrityConstraints 147
4.4.3 Unique Constraint
SQLalsosupportsanintegrityconstraint:
unique(A ,A ,…,A )
j j j
1 2 m
TheuniquespecificationsaysthatattributesA ,A ,…,A formasuperkey;thatis,no
j j j
1 2 m
twotuplesintherelationcanbe equalonallthelistedattributes. However,attributes
declaredasuniquearepermittedtobenullunlesstheyhaveexplicitlybeendeclaredto
be notnull. Recallthatanullvalue doesnotequal anyothervalue. (Thetreatmentof
nullshereisthesameasthatoftheuniqueconstructdefinedinSection3.8.4.)
4.4.4 The Check Clause
Whenappliedtoarelationdeclaration,theclausecheck(P)specifiesapredicatePthat
mustbesatisfiedbyeverytupleinarelation.
A common use of the check clause is to ensure that attribute values satisfy speci-
fiedconditions,ineffectcreatingapowerfultypesystem.Forinstance,aclausecheck
(budget>0)inthecreatetablecommandforrelationdepartmentwouldensurethatthe
valueofbudgetisnonnegative.
Asanotherexample,considerthefollowing:
createtablesection
(course id varchar(8),
sec id varchar(8),
semester varchar(6),
year numeric(4,0),
building varchar(15),
room number varchar(7),
time slot id varchar(4),
primarykey(course id,sec id,semester,year),
check(semester in('Fall','Winter','Spring','Summer')));
Here, we use the check clause to simulate an enumerated type by specifying that
semester must be one of 'Fall', 'Winter', 'Spring', or 'Summer'. Thus, the check clause
permits attribute domains to be restricted in powerful ways that most programming-
languagetypesystemsdonotpermit.
Nullvaluespresentaninterestingspecialcaseintheevaluationofacheckclause.
Acheckclauseissatisfiedifitisnotfalse,soclausesthatevaluatetounknownarenot
violations. If null values are not desired, a separate not null constraint (see Section
4.4.2)mustbespecified.
Acheckclausemayappearonitsown,asshownabove,oraspartofthedeclaration
of an attribute. In Figure 4.9, we show the check constraint for the semester attribute

--- Page 177 ---

148 Chapter4 IntermediateSQL
createtableclassroom
(building varchar(15),
room number varchar(7),
capacity numeric(4,0),
primarykey(building,room number));
createtabledepartment
(dept name varchar(20),
building varchar(15),
budget numeric(12,2)check(budget>0),
primarykey(dept name));
createtablecourse
(course id varchar(8),
title varchar(50),
dept name varchar(20),
credits numeric(2,0)check(credits>0),
primarykey(course id),
foreignkey(dept name)referencesdepartment);
createtableinstructor
(ID varchar(5),
name varchar(20)notnull,
dept name varchar(20),
salary numeric(8,2)check(salary>29000),
primarykey(ID),
foreignkey(dept name)referencesdepartment);
createtablesection
(course id varchar(8),
sec id varchar(8),
semester varchar(6)check(semester in
(’Fall’,’Winter’,’Spring’,’Summer’)),
year numeric(4,0)check(year >1759andyear <2100),
building varchar(15),
room number varchar(7),
time slot id varchar(4),
primarykey(course id,sec id,semester,year),
foreignkey(course id)referencescourse,
foreignkey(building,room number)referencesclassroom);
Figure 4.9 SQLdatadefinitionforpartoftheuniversitydatabase.

--- Page 178 ---

4.4 IntegrityConstraints 149
as part of the declaration of semester. The placement of a check clause is a matter of
codingstyle.Typically,constraintsonthevalueofasingleattributearelistedwiththat
attribute,whilemorecomplexcheckclausesarelistedseparatelyattheendofacreate
tablestatement.
The predicate in the check clause can, according to the SQL standard, be an ar-
bitrary predicate that can include a subquery. However, currently none of the widely
useddatabaseproductsallowsthepredicatetocontainasubquery.
4.4.5 Referential Integrity
Often,wewishtoensurethatavaluethatappearsinonerelation(thereferencingrela-
tion)foragivensetofattributesalsoappearsforacertainsetofattributesinanother
relation (the referenced relation). As we saw earlier, in Section 2.3, such conditions
arecalledreferentialintegrityconstraints,andforeignkeysareaformofareferentialin-
tegrityconstraintwherethereferencedattributesformaprimarykeyofthereferenced
relation.
ForeignkeyscanbespecifiedaspartoftheSQLcreatetablestatementbyusingthe
foreignkeyclause,aswesawinSection3.2.2.Weillustrateforeign-keydeclarationsby
usingtheSQLDDLdefinitionofpartofouruniversitydatabase,showninFigure4.9.
Thedefinitionofthecoursetablehasadeclaration
“foreignkey(dept name)referencesdepartment”.
Thisforeign-keydeclarationspecifiesthatforeachcoursetuple,thedepartmentname
specifiedinthetuplemustexistinthedepartment relation.Withoutthisconstraint,it
ispossibleforacoursetospecifyanonexistentdepartmentname.
By default, in SQL a foreign key references the primary-key attributes of the ref-
erenced table. SQL also supports a version of the references clause where a list of at-
tributesofthereferencedrelationcanbespecifiedexplicitly.8Forexample,theforeign
keydeclarationforthecourserelationcanbespecifiedas:
foreignkey(dept name)referencesdepartment(dept name)
The specified list of attributes must, however, be declared as a superkey of the
referenced relation, using either a primary key constraint or a unique constraint. A
more general form of a referential-integrityconstraint, where the referenced columns
need not be a candidate key, cannot be directly specified in SQL. The SQL standard
specifies other constructs that can be used to implement such constraints, which are
describedinSection4.4.8;however,thesealternativeconstructsarenotsupportedby
anyofthewidelyuseddatabasesystems.
Notethattheforeignkeymustreferenceacompatiblesetofattributes,thatis,the
numberofattributesmustbethesameandthedatatypesofcorrespondingattributes
mustbecompatible.
8Somesystems,notablyMySQL,donotsupportthedefaultandrequirethattheattributesofthereferencedrelations
bespecified.

--- Page 179 ---

150 Chapter4 IntermediateSQL
We can use the following as part of a table definition to declare that an attribute
formsaforeignkey:
dept namevarchar(20)referencesdepartment
Whenareferential-integrityconstraintisviolated,thenormalprocedureistoreject
theactionthatcausedtheviolation(i.e.,thetransactionperformingtheupdateaction
isrolledback).However,aforeignkeyclausecanspecifythatifadeleteorupdateaction
onthereferencedrelationviolatestheconstraint,then,insteadofrejectingtheaction,
thesystemmusttakestepstochangethetupleinthereferencingrelationtorestorethe
constraint.Considerthisdefinitionofanintegrityconstraintontherelationcourse:
createtablecourse
(…
foreignkey(dept name)referencesdepartment
ondeletecascade
onupdatecascade,
…);
Becauseoftheclauseondeletecascadeassociatedwiththeforeign-keydeclaration,ifa
deleteofatupleindepartment resultsinthisreferential-integrityconstraintbeingvio-
lated,thesystemdoesnotrejectthedelete.Instead,thedelete“cascades”tothecourse
relation,deletingthetuplethatreferstothedepartmentthatwasdeleted.Similarly,the
systemdoesnotrejectanupdatetoafieldreferencedbytheconstraintifitviolatesthe
constraint;instead,thesystemupdatesthefielddept nameinthereferencingtuplesin
coursetothenewvalueaswell.SQLalsoallowstheforeignkeyclausetospecifyactions
otherthancascade,iftheconstraintisviolated:Thereferencingfield(here,dept name)
canbesettonull(byusingsetnullinplaceofcascade),ortothedefaultvalueforthe
domain(byusingsetdefault).
Ifthereisachainofforeign-keydependenciesacrossmultiplerelations,adeletion
orupdateatoneendofthechaincanpropagateacrosstheentirechain.Aninteresting
casewheretheforeignkeyconstraintonarelationreferencesthesamerelationappears
inExercise4.9.Ifacascadingupdateordeletecausesaconstraintviolationthatcannot
be handled by a further cascading operation, the system aborts the transaction. As a
result,allthechangescausedbythetransactionanditscascadingactionsareundone.
Null values complicate the semantics of referential-integrity constraints in SQL.
Attributesofforeignkeysareallowedtobenull,providedthattheyhavenototherwise
beendeclaredtobe notnull.Ifallthecolumnsofaforeignkeyarenonnullinagiven
tuple,theusualdefinitionofforeign-keyconstraintsisusedforthattuple.Ifanyofthe
foreign-keycolumnsisnull,thetupleisdefinedautomaticallytosatisfytheconstraint.
Thisdefinitionmaynotalwaysbetherightchoice,soSQLalsoprovidesconstructsthat
allowyoutochangethebehaviorwithnullvalues;wedonotdiscusstheconstructshere.

--- Page 180 ---

4.4 IntegrityConstraints 151
4.4.6 Assigning Names to Constraints
Itispossibleforustoassignanametointegrityconstraints.Suchnamesareusefulif
wewanttodropaconstraintthatwasdefinedpreviously.
Tonameaconstraint, weprecedetheconstraint withthekeyword constraintand
thenamewewishtoassignit.So,forexample,ifwewishtoassignthenameminsalary
tothecheckconstraintonthesalaryattributeofinstructor(seeFigure4.9),wewould
modifythedeclarationforsalaryto:
salarynumeric(8,2),constraintminsalarycheck(salary>29000),
Later,ifwedecidewenolongerwantthisconstraint,wecanwrite:
altertableinstructordropconstraintminsalary;
Lacking a name, we would need first to use system-specific features to identify the
system-assignednamefortheconstraint.Notallsystemssupportthis,but,forexample,
inOracle,thesystemtableuser constraintscontainsthisinformation.
4.4.7 Integrity Constraint Violation During a Transaction
Transactions may consist of several steps, and integrity constraints may be violated
temporarily after one step, but a later step may remove the violation. For instance,
supposewehavearelationpersonwithprimarykeyname,andanattributespouse,and
supposethatspouseisaforeignkeyonperson.Thatis,theconstraintsaysthatthespouse
attribute must contain aname thatispresentinthe person table. Suppose wewish to
note the fact that John and Mary are married to each other by inserting two tuples,
one for John and one for Mary, in the preceding relation, with the spouse attributes
set to Mary and John, respectively. The insertion of the first tuple would violate the
foreign-keyconstraint,regardlessofwhichofthetwotuplesisinsertedfirst.Afterthe
secondtupleisinserted,theforeign-keyconstraintwouldholdagain.
To handle such situations, the SQL standard allows a clause initially deferred to
be added to a constraint specification; the constraint would then be checked at the
end of a transaction and not at intermediate steps. A constraint can alternatively be
specified as deferrable, which means it is checked immediately by default but can be
deferred when desired. For constraints declared as deferrable, executing a statement
set constraints constraint-list deferred as part of a transaction causes the checking of
thespecifiedconstraintstobedeferredtotheendofthattransaction.Constraintsthat
are to appear in a constraint list must have names assigned. The default behavior is
tocheckconstraintsimmediately,andmanydatabaseimplementationsdonotsupport
deferredconstraintchecking.
Wecanworkaroundtheproblemintheprecedingexampleinanotherway,ifthe
spouseattributecanbesettonull:Wesetthespouseattributestonullwheninsertingthe

--- Page 181 ---

152 Chapter4 IntermediateSQL
tuplesforJohnandMary,andweupdatethemlater.However,thistechniquerequires
moreprogrammingeffort,anditdoesnotworkiftheattributescannotbesettonull.
4.4.8 Complex Check Conditions and Assertions
ThereareadditionalconstructsintheSQLstandardforspecifyingintegrityconstraints
that are not currently supported by most systems. We discuss some of these in this
section.
As defined by the SQL standard, the predicate in the check clause can be an ar-
bitrary predicate that can include a subquery. If a database implementation supports
subqueriesinthecheckclause,wecouldspecifythefollowingreferential-integritycon-
straintontherelationsection:
check(time slot id in(selecttime slot id fromtime slot))
Thecheckconditionverifiesthatthetime slot id ineachtupleinthesectionrelationis
actuallytheidentifierofatimeslotinthetime slotrelation.Thus,theconditionhasto
becheckednotonlywhenatupleisinsertedormodifiedinsection,butalsowhenthe
relationtime slot changes(inthiscase,whenatupleisdeletedormodifiedinrelation
time slot).
Anothernaturalconstraintonouruniversityschemawouldbetorequirethatevery
section has at least one instructor teachingthe section. In an attempt to enforce this,
wemaytrytodeclarethattheattributes(course id,sec id,semester,year)ofthesection
relationformaforeignkeyreferencingthecorrespondingattributesoftheteachesrela-
tion.Unfortunately,theseattributesdonotformacandidatekeyoftherelationteaches.
Acheckconstraintsimilartothatforthetime slotattributecanbeusedtoenforcethis
constraint,ifcheckconstraintswithsubqueriesweresupportedbyadatabasesystem.
Complex check conditionscan be useful when we want to ensure the integrity of
data,but theymaybecostlytotest. Inourexample,the predicateinthe checkclause
wouldnotonlyhavetobeevaluatedwhenamodificationismadetothesectionrelation,
butitmayhavetobecheckedifamodificationismadetothetime slotrelationbecause
thatrelationisreferencedinthesubquery.
Anassertionisapredicateexpressingaconditionthatwewishthedatabasealways
tosatisfy.Considerthefollowingconstraints,whichcanbeexpressedusingassertions.
• Foreachtupleinthestudentrelation,thevalueoftheattributetot credmustequal
thesumofcreditsofcoursesthatthestudenthascompletedsuccessfully.
• Aninstructorcannotteachintwodifferentclassroomsinasemesterinthesame
timeslot.9
9Weassumethatlecturesarenotdisplayedremotelyinasecondclassroom!Analternativeconstraintthatspecifies
that“aninstructorcannotteachtwocoursesinagivensemesterinthesametimeslot”maynotholdsincecoursesare
sometimescross-listed;thatis,thesamecourseisgiventwoidentifiersandtitles.

--- Page 182 ---

4.5 SQLDataTypesandSchemas 153
createassertioncredits earned constraintcheck
(notexists(selectID
fromstudent
wheretot cred <>(selectcoalesce(sum(credits),0)
fromtakesnaturaljoincourse
wherestudent.ID=takes.ID
andgradeisnotnullandgrade<>’F’)))
Figure 4.10 Anassertionexample.
AnassertioninSQLtakestheform:
createassertion<assertion-name>check<predicate>;
InFigure4.10,weshowhowthefirstexampleofconstraintscanbewritteninSQL.
SinceSQLdoesnotprovidea“forallX,P(X)”construct(whereP isapredicate),we
are forcedtoimplementthe constraint byan equivalentconstruct, “notexists X such
thatnotP(X)”,thatcanbeexpressedinSQL.
Weleavethespecificationofthesecondconstraintasanexercise.Althoughthese
two constraints can be expressed using check predicates, using an assertion may be
morenatural,especiallyforthesecondconstraint.
Whenanassertioniscreated,thesystemtestsitforvalidity.Iftheassertionisvalid,
then any future modification to the database is allowed only if it does not cause that
assertion to be violated. This testing may introduce a significant amount of overhead
if complex assertions have been made. Hence, assertions should be used with great
care. The high overhead of testing and maintaining assertions has led some system
developers to omit support for general assertions, or to provide specialized forms of
assertionthatareeasiertotest.
Currently,noneofthewidelyuseddatabasesystemssupportseithersubqueriesin
thecheckclausepredicateorthecreateassertionconstruct.However,equivalentfunc-
tionalitycanbeimplementedusingtriggers,whicharedescribedinSection5.3,ifthey
are supported by the database system. Section 5.3 also describes how the referential
integrityconstraintontime slot id canbeimplementedusingtriggers.
4.5 SQL Data Types and Schemas
In Chapter 3, we covered a number of built-in data types supported in SQL, such as
integer types, real types, and character types. There are additional built-in data types
supported by SQL, which we describe below. We also describe how to create basic
user-definedtypesinSQL.

--- Page 183 ---

154 Chapter4 IntermediateSQL
4.5.1 Date and Time Types in SQL
In addition to the basic data types we introduced in Section 3.2, the SQL standard
supportsseveraldatatypesrelatingtodatesandtimes:
• date:Acalendardatecontaininga(four-digit)year,month,anddayofthemonth.
• time: The timeof day, in hours, minutes, and seconds. Avariant, time(p), can be
used to specify the number of fractional digits for seconds (the default being 0).
Itisalsopossibletostoretime-zoneinformationalongwiththetimebyspecifying
timewithtimezone.
• timestamp:Acombinationofdateandtime.Avariant,timestamp(p),canbeused
to specify the number of fractional digits for seconds (the default here being 6).
Time-zoneinformationisalsostoredifwithtimezoneisspecified.
Dateandtimevaluescanbespecifiedlikethis:
date'2018-04-25'
time'09:30:00'
timestamp'2018-04-2510:29:01.45'
Dates must be specified in the format year followed by month followed by day, as
shown.10 The seconds field of time or timestamp can have a fractional part, as in the
timestampabove.
Toextractindividualfieldsofadateortimevalued,wecanuseextract(field from
d), where field can be one of year, month, day, hour, minute, or second. Time-zone
informationcanbeextractedusingtimezone hourandtimezone minute.
SQL defines several functions to get the current date and time. For example, cur-
rent date returns the current date, current time returns the current time (with time
zone), and localtime returns the current local time (without time zone). Timestamps
(date plus time) are returned by current timestamp (with time zone) and localtimes-
tamp(localdateandtimewithouttimezone).
Somesystems,includingMySQL offerthedatetimedatatypethatrepresentsatime
that is not adjustable for time zone. In practice, specification of time has numerous
special cases, includingthe use of standard time versus “daylight” or “summer” time.
Systemsvaryintherangeoftimesrepresentable.
SQLallowscomparisonoperations onallthetypeslisted here,anditallowsboth
arithmeticandcomparisonoperationsonthevariousnumerictypes.SQLalsoprovides
a data type called interval, and it allows computations based on dates and times and
on intervals. For example, if x and y are of type date, then x−y is an interval whose
value is the number of days from date x to date y. Similarly,addingor subtracting an
intervalfromadateortimegivesbackadateortime,respectively.
10Manydatabasesystemsoffergreaterflexibilityindefaultconversionsofstringstodatesandtimestamps.

--- Page 184 ---

4.5 SQLDataTypesandSchemas 155
4.5.2 Type Conversion and Formatting Functions
Although systems perform some data type conversions automatically, others need to
be requested explicitly. We can use an expression of the form cast (e as t) to convert
anexpressionetothetypet.Data-typeconversionsmaybeneededtoperformcertain
operationsortoenforcecertainsortorders.Forexample,considertheIDattributeof
instructor, which we have specified as being a string (varchar(5)). If we were to order
outputbythisattribute,theID11111comesbeforetheID9,becausethefirstcharacter,
'1',comesbefore'9'.However,ifweweretowrite:
selectcast(IDasnumeric(5))asinst id
frominstructor
orderbyinst id
theresultwouldbethesortedorderwedesire.
Adifferenttypeofconversionmayberequiredfordatatobedisplayedastheresult
of a query. For example, we may wish numbers to be shown with a specific number
of digits, or data to be displayed in a particular format (such as month-day-year or
day-month-year).Thesechangesindisplayformatarenotconversionofdatatypebut
ratherconversionofformat.Databasesystemsofferavarietyofformattingfunctions,
and details vary among the leading systems. MySQL offers a format function. Oracle
and PostgreSQL offer a set of functions, to char, to number, and to date. SQL Server
offersaconvertfunction.
Anotherissueindisplayingresultsisthehandlingofnullvalues.Inthistext,weuse
nullforclarityofreading,butthedefaultinmostsystemsisjusttoleavethefieldblank.
Wecanchoosehownullvaluesareoutputinaqueryresultusingthecoalescefunction.
Ittakesanarbitrarynumberofarguments,allofwhichmustbeofthesametype,and
returnsthefirstnon-nullargument.Forexample,ifwewishedtodisplayinstructorIDs
andsalariesbuttoshownullsalariesas0,wewouldwrite:
selectID,coalesce(salary,0)assalary
frominstructor
Alimitationofcoalesceistherequirementthatalltheargumentsmustbeofthesame
type. Ifwehadwanted null salariestoappear as'N/A'toindicate“notavailable”,we
would not be able to use coalesce. System-specific functions, such as Oracle’sdecode,
doallowsuchconversions.Thegeneralformofdecodeis:
decode(value,match-1,replacement-1,match-2,replacement-2,…,
match-N,replacement-N,default-replacement);
It compares value against the match values and if a match is found, it replaces the at-
tribute value with the corresponding replacement value. If no match succeeds, then
theattributevalueisreplacedwiththedefaultreplacementvalue.Therearenorequire-

--- Page 185 ---

156 Chapter4 IntermediateSQL
mentsthatdatatypesmatch.Conveniently,thevaluenullmayappearasamatchvalue
and,unliketheusualcase,nullistreatedasbeingequaltonull.Thus,wecouldreplace
nullsalarieswith'N/A'asfollows:
selectID,decode(salary,null,'N/A',salary)assalary
frominstructor
4.5.3 Default Values
SQLallowsadefaultvaluetobespecifiedforanattributeasillustratedbythefollowing
createtablestatement:
createtablestudent
(ID varchar(5),
name varchar(20)notnull,
dept name varchar(20),
tot cred numeric(3,0)default0,
primarykey(ID));
Thedefaultvalueofthetot cred attributeisdeclaredtobe0.Asaresult,whenatuple
isinsertedintothestudentrelation,ifnovalueisprovidedforthetot cred attribute,its
value is set to 0. The following insert statement illustrates how an insertion can omit
thevalueforthetot cred attribute.
insertintostudent(ID,name,dept name)
values('12789','Newman','Comp.Sci.');
4.5.4 Large-Object Types
Many database applications need to store attributes whose domain consists of large
dataitemssuchasaphoto,ahigh-resolutionmedicalimage,oravideo.SQL,therefore,
provides large-object data types for character data (clob) and binary data (blob). The
letters“lob”inthesedatatypesstandfor“LargeOBject.”Forexample,wemaydeclare
attributes
book reviewclob(10KB)
imageblob(10MB)
movieblob(2GB)
For result tuples containing large objects (multiple megabytes to gigabytes), it is
inefficient or impractical to retrieve an entire large object into memory. Instead, an
application would usually use an SQL query to retrieve a “locator” for a large object
and then use the locator to manipulate the object from the host language in which
theapplicationitselfiswritten.Forinstance,theJDBCapplicationprograminterface
(describedin Section5.1.1)permitsalocatortobe fetchedinstead oftheentirelarge

--- Page 186 ---

4.5 SQLDataTypesandSchemas 157
Note 4.2 TEMPORALVALIDITY
Insomesituations,thereisaneedtoincludehistoricaldata,as,forexample,ifwe
wish to store not only the current salary of each instructor but also entire salary
histories. It is easy enough to do this by adding two attributes to the instructor
relation schema indicating the starting date for a given salary value and another
indicatingthe end date. Then, an instructor may have several salary values, each
correspondingtoaspecificpairofstartandenddates.Thosestartandenddates
arecalledthevalidtimevaluesforthecorrespondingsalaryvalue.
Observethattheremaynowbemorethanonetupleintheinstructor relation
with the same value of ID. Issues in specifying primary key and foreign key con-
straintsinthecontextofsuchtemporaldataarediscussedinSection7.10.
For a database system to support such temporal constructs, a first step is to
providesyntaxtospecifythatcertainattributesdefineavalidtimeinterval.Weuse
Oracle12’ssyntaxasanexample.TheSQLDDLforinstructorisaugmentedusing
a period declaration as follows, to indicate that start date and end date attributes
specifyavalid-timeinterval.
createtableinstructor
(…
start date date,
end date date,
periodforvalid time(start date,end date),
…);
Oracle 12c also provides several DML extensions to ease querying with temporal
data.Theasofperiodforconstructcanthenbeused inquerytofetchonlythose
tuples whose valid time period includes a specific time. To find instructors and
theirsalariesasofsometimeinthepast,sayJanuary20,2014,wewrite:
selectname,salary,start date,end date
frominstructor asofperiodforvalid time'20-JAN-2014';
If we wish to find tuples whose period of validity includes all or part of a period
oftime,say,January20,2014toJanuary30,2014,wewrite:
selectname,salary,start date,end date
frominstructor versionsperiodforvalid timebetween'20-JAN-2014'and'30-JAN-2014';
Oracle12calsoimplementsafeaturethatallowsstoreddatabaseprocedures(cov-
eredinChapter5)toberunasofaspecifiedtimeperiod.
Theaboveconstructseasethespecificationofthequeries,althoughthequeries
canbewrittenwithoutusingtheconstructs.

--- Page 187 ---

158 Chapter4 IntermediateSQL
object;thelocatorcanthenbeusedtofetchthelargeobjectinsmallpieces,ratherthan
allatonce,muchlikereadingdatafromanoperatingsystemfileusingareadfunction
call.
4.5.5 User-Defined Types
SQLsupportstwoformsofuser-defineddatatypes.Thefirstform,whichwecoverhere,
iscalleddistincttypes.Theotherform,calledstructureddatatypes,allowsthecreation
ofcomplexdatatypeswithnestedrecordstructures,arrays, andmultisets.Wedonot
coverstructureddatatypesinthischapter,butwedescribetheminSection8.2.
It is possible for several attributes to have the same data type. For example, the
name attributes for student name and instructor name might have the same domain:
the set of all person names. However, the domains of budget and dept name certainly
oughttobedistinct.Itisperhapslessclearwhethernameanddept nameshouldhave
thesamedomain.Attheimplementationlevel,bothinstructornamesanddepartment
namesarecharacterstrings.However,wewouldnormallynotconsiderthequery“Find
all instructors who have the same name as a department” to be a meaningful query.
Thus, if we view the database at the conceptual, rather than the physical, level, name
anddept nameshouldhavedistinctdomains.
More importantly,at apractical level,assigningan instructor’s name toadepart-
ment name is probably a programming error; similarly, comparing a monetary value
expressedindollarsdirectlywithamonetaryvalueexpressedinpoundsisalsoalmost
surelyaprogrammingerror.Agoodtypesystem shouldbeabletodetectsuchassign-
ments or comparisons. To support such checks, SQL provides the notion of distinct
types.
Thecreatetypeclausecanbeusedtodefinenewtypes.Forexample,thestatements:
createtypeDollarsasnumeric(12,2)final;
createtypePoundsasnumeric(12,2)final;
definetheuser-definedtypesDollarsandPoundstobedecimalnumberswithatotalof
12 digits, two of which are placed after the decimal point.11 The newly created types
canthenbeused,forexample,astypesofattributesofrelations.Forexample,wecan
declarethedepartmenttableas:
createtabledepartment
(dept name varchar(20),
building varchar(15),
budget Dollars);
An attempt to assign a value of type Dollars to a variable of type Pounds results in a
compile-timeerror, although both are of the same numeric type. Such an assignment
is likely to be due to a programmer error, where the programmer forgot about the
11Thekeywordfinalisn’treallymeaningfulinthiscontextbutisrequiredbytheSQL:1999standardforreasonswewon’t
getintohere;someimplementationsallowthefinalkeywordtobeomitted.

--- Page 188 ---

4.5 SQLDataTypesandSchemas 159
differences in currency. Declaring different types for different currencies helps catch
sucherrors.
Asaresultofstrongtypechecking,theexpression(department.budget+20)would
not be accepted since the attribute and the integer constant 20 have different types.
AswesawinSection4.5.2,valuesofonetypecanbeconvertedtoanotherdomain,as
illustratedbelow:
cast(department.budgettonumeric(12,2))
We could doadditionon the numerictype, but tosave theresultbackto an attribute
oftypeDollarswewouldhavetouseanothercastexpressiontoconvertthetypeback
toDollars.
SQL provides drop type and alter type clauses to drop or modify types that have
beencreatedearlier.
Evenbeforeuser-definedtypeswereaddedtoSQL(inSQL:1999),SQLhadasimilar
butsubtlydifferentnotionofdomain(introducedinSQL-92),whichcanaddintegrity
constraintstoanunderlyingtype.Forexample,wecoulddefineadomainDDollarsas
follows.
createdomainDDollarsasnumeric(12,2)notnull;
ThedomainDDollarscanbeusedasanattributetype,justasweusedthetypeDollars.
However,therearetwosignificantdifferencesbetweentypesanddomains:
1. Domainscanhaveconstraints,suchasnotnull,specifiedonthem,andcanhave
defaultvaluesdefinedforvariablesofthedomaintype,whereasuser-definedtypes
cannot have constraints or default values specified on them. User-defined types
aredesignedtobeusednotjustforspecifyingattribute types,butalsoinproce-
duralextensionstoSQLwhereitmaynotbepossibletoenforceconstraints.
2. Domains are not strongly typed. As a result, values of one domain type can be
assigned to values of another domain type as long as the underlying types are
compatible.
Whenappliedtoadomain,thecheckclausepermitstheschemadesignertospecify
apredicatethatmustbesatisfiedbyanyattributedeclaredtobefromthisdomain.For
instance,acheckclausecanensurethataninstructor’ssalarydomainallowsonlyvalues
greaterthanaspecifiedvalue:
createdomainYearlySalarynumeric(8,2)
constraintsalary value test check(value>=29000.00);
ThedomainYearlySalaryhasaconstraintthatensuresthattheYearlySalaryisgreater
than or equal to $29,000.00. The clause constraint salary value test is optional and is

--- Page 189 ---

160 Chapter4 IntermediateSQL
Note 4.3 SUPPORTFORTYPESANDDOMAINS
Although the create type and create domain constructs described in this section
are part of the SQL standard, the forms of these constructs described here are
not fully supported by most database implementations. PostgreSQL supports the
create domain construct, but its create type construct has a different syntax and
interpretation.
IBMDB2supports aversionofthecreatetypethatusesthesyntaxcreatedis-
tincttype,butitdoesnotsupportcreatedomain.MicrosoftSQLServerimplements
aversionofcreatetypeconstructthatsupportsdomainconstraints,similartothe
SQLcreatedomainconstruct.
Oracledoesnotsupporteitherconstructasdescribedhere.Oracle,IBMDB2,
PostgreSQL,andSQLServerallsupportobject-orientedtypesystemsusingdiffer-
entformsofthecreatetypeconstruct.
However,SQLalsodefinesamorecomplexobject-orientedtypesystem,which
westudyinSection8.2.Typesmayhavestructurewithinthem,like,forexample,
a Name type consisting of firstname and lastname. Subtyping is allowed as well;
forexample,aPersontypemayhavesubtypesStudent,Instructor,etc.Inheritance
rulesaresimilartothoseinobject-orientedprogramminglanguages.Itispossible
to use references to tuples that behave much like references to objects in object-
oriented programming languages. SQL allows array and multiset datatypes along
withwaystomanipulatethosetypes.
Wedonotcoverthedetailsofthesefeatureshere.Databasesystemsdifferin
howtheyimplementthem,iftheyareimplementedatall.
usedtogivethenamesalary value testtotheconstraint.Thenameisusedbythesystem
toindicatetheconstraintthatanupdateviolated.
Asanotherexample,adomaincanberestrictedtocontainonlyaspecifiedsetof
valuesbyusingtheinclause:
createdomaindegree level varchar(10)
constraintdegree level test
check(valuein('Bachelors','Masters','Doctorate'));
4.5.6 Generating Unique Key Values
Inouruniversityexample,wehaveseenprimary-keyattributeswithdifferentdatatypes.
Some, like dept name, hold actual real-world information. Others, like ID, hold val-
ues created by the enterprise solely for identification purposes. Those latter types of
primary-key domains generate the practical problem of new-value creation. Suppose

--- Page 190 ---

4.5 SQLDataTypesandSchemas 161
the university hires a new instructor. What ID should be assigned? How do we deter-
mine that the new ID is unique? Although it is possible to write an SQL statement to
do this, such a statement would need to checkall preexisting IDs, which would harm
systemperformance.Alternatively,onecouldsetupaspecialtableholdingthelargest
IDvalueissuedsofar.Then,whenanewIDisneeded,thatvaluecanbeincremented
tothenextoneinsequenceandstoredasthenewlargestvalue.
Databasesystemsofferautomaticmanagementofuniquekey-valuegeneration.The
syntax differs among the most popular systems and, sometimes, between versions of
systems. The syntax we show here is close to that of Oracle and DB2. Suppose that
instead of declaringinstructor IDs in the instructor relation as “IDvarchar(5)”, we in-
stead choose to let the system select a unique instructor ID value. Since this feature
worksonlyfornumerickey-valuedatatypes,wechangethetypeofIDtonumber,and
write:
IDnumber(5)generatedalwaysasidentity
Whenthealwaysoptionisused,anyinsertstatementmustavoidspecifyingavalue
for the automatically generated key. To do this, use the syntax for insert in which the
attributeorderisspecified(seeSection3.9.2).Forourexampleofinstructor,weneed
specify onlythevalues forname, dept name,and salary, asshown in the followingex-
ample:
insertintoinstructor (name,dept name,salary)
values('Newprof','Comp.Sci.',100000);
The generated ID value can be found via a normal select query. If we replace always
withbydefault,wehavetheoptionofspecifyingourownchoiceofIDorrelyingonthe
systemtogenerateone.
InPostgreSQL,wecandefinethetypeofIDasserial,whichtellsPostgreSQLtoau-
tomaticallygenerateidentifiers;inMySQL weuseauto incrementinplaceofgenerated
alwaysasidentity,whileinSQLServerwecanusejustidentity.
Additionaloptionscan be specified,withtheidentityspecification,dependingon
the database, includingsetting minimum and maximum values, choosing the starting
value,choosingtheincrementfromonevaluetothenext,andsoon.
Further, many databases support a create sequence construct, whichcreates a se-
quence counter object separate from any relation, and allow SQL queries to get the
nextvaluefromthesequence.Eachcalltogetthenextvalueincrementsthesequence
counter. See the system manuals of the database to find the exact syntax for creating
sequences, and for retrieving the next value. Using sequences, we can generate iden-
tifiers that are unique across multiple relations, for example, across student.ID, and
instructor.ID.

--- Page 191 ---

162 Chapter4 IntermediateSQL
4.5.7 Create Table Extensions
Applicationsoften require the creationof tables thathave the same schemaas an ex-
istingtable.SQLprovidesacreatetablelikeextensiontosupportthistask:12
createtabletemp instructor likeinstructor;
The above statement creates a new table temp instructor that has the same schema as
instructor.
When writing a complex query, it is often useful to store the result of a query as
anewtable;thetableisusuallytemporary.Twostatementsarerequired,onetocreate
thetable(withappropriatecolumns)andthesecondtoinsertthequeryresultintothe
table.SQL:2003providesasimplertechniquetocreateatablecontainingtheresultsof
aquery.Forexample,thefollowingstatementcreatesatablet1containingtheresults
ofaquery.
createtablet1as
(select*
frominstructor
wheredept name='Music')
withdata;
Bydefault,thenamesanddatatypesofthecolumnsareinferredfromthequeryresult.
Names can be explicitly given to the columns by listing the column names after the
relationname.
As defined by the SQL:2003 standard, if the with data clause is omitted, the table
iscreatedbutnotpopulatedwithdata.However,manyimplementationspopulatethe
table with data by default even if the with data clause is omitted. Note that several
implementationssupportthefunctionalityofcreatetable…likeandcreatetable…as
usingdifferentsyntax;seetherespectivesystemmanualsforfurtherdetails.
Theabovecreatetable…asstatement,closelyresemblesthecreateviewstatement
andbotharedefinedbyusingqueries.Themaindifferenceisthatthecontentsofthe
tablearesetwhenthetableiscreated,whereasthecontentsofaviewalwaysreflectthe
currentqueryresult.
4.5.8 Schemas, Catalogs, and Environments
Tounderstandthemotivationforschemasandcatalogs,considerhowfilesarenamed
in a file system. Early file systems were flat; that is, all files were stored in a single
directory. Current file systems have a directory (or, synonymously, folder) structure,
withfilesstoredwithinsubdirectories.Tonameafileuniquely,wemustspecifythefull
pathnameofthefile,forexample,/users/avi/db-book/chapter3.tex.
12Thissyntaxisnotsupportedinallsystems.

--- Page 192 ---

4.5 SQLDataTypesandSchemas 163
Likeearlyfilesystems,earlydatabasesystemsalsohadasinglenamespaceforall
relations.Usershadtocoordinatetomakesuretheydidnottrytousethesamename
fordifferentrelations.Contemporarydatabasesystemsprovideathree-levelhierarchy
fornamingrelations.Thetoplevelofthehierarchyconsistsofcatalogs,eachofwhich
can contain schemas. SQL objects such as relations and views are contained within a
schema. (Some database implementationsuse the term database in place of the term
catalog.)
In order to perform any actions on a database, a user (or a program) must first
connecttothedatabase.Theusermustprovidetheusernameandusually,apassword
forverifyingtheidentityoftheuser.Eachuserhasadefaultcatalogandschema,and
the combination is unique to the user. When a user connects to a database system,
the defaultcatalog and schemaare set up for the connection;thiscorresponds tothe
current directory being set to the user’s home directory when the user logs into an
operatingsystem.
Toidentifyarelationuniquely,athree-partnamemaybeused,forexample,
catalog5.univ schema.course
We may omit the catalog component, in which case the catalog part of the name is
consideredtobethedefaultcatalogfortheconnection.Thus,ifcatalog5isthedefault
catalog,wecanuseuniv schema.coursetoidentifythesamerelationuniquely.
Ifauserwishestoaccessarelationthatexistsinadifferentschemathanthedefault
schemaforthatuser,thenameoftheschemamustbespecified.However,ifarelationis
inthedefaultschemaforaparticularuser,theneventheschemanamemaybeomitted.
Thus,wecanusejustcourseifthedefaultcatalogiscatalog5andthedefaultschemais
univ schema.
Withmultiplecatalogsandschemasavailable,differentapplicationsanddifferent
userscanworkindependentlywithoutworryingaboutnameclashes.Moreover,multi-
pleversionsofanapplication—oneaproductionversion,othertestversions—canrun
onthesamedatabasesystem.
The default catalog and schemaare part of an SQL environment thatis set up for
each connection. The environment additionally contains the user identifier (also re-
ferred to as the authorization identifier). All the usual SQL statements, including the
DDLandDMLstatements,operateinthecontextofaschema.
Wecancreateanddropschemasbymeansofcreateschemaanddropschemastate-
ments.Inmostdatabasesystems,schemasarealsocreatedautomaticallywhenuserac-
countsarecreated,withtheschemanamesettotheuseraccountname.Theschemais
createdineitheradefaultcatalogoracatalogspecifiedwhencreatingtheuseraccount.
Thenewlycreatedschemabecomesthedefaultschemafortheuseraccount.
Creation and dropping of catalogs is implementation dependent and not part of
theSQLstandard.

--- Page 193 ---

164 Chapter4 IntermediateSQL
4.6 Index Definition in SQL
Manyqueriesreferenceonlyasmallproportionoftherecordsinafile.Forexample,a
querylike“FindallinstructorsinthePhysicsdepartment”or“Findthesalaryvalueof
theinstructorwithID22201”referencesonlyafractionoftheinstructorrecords.Itis
inefficientforthesystemtoreadeveryrecordandtocheckIDfieldfortheID“32556,”
orthebuildingfieldforthevalue“Physics”.
An index on an attribute of a relation is a data structure that allows the database
systemtofindthosetuplesintherelationthathaveaspecifiedvalueforthatattribute
efficiently, without scanning through all the tuples of the relation. For example, if we
create an index on attribute dept name of relation instructor, the database system can
find the record with any specified dept name value, such as “Physics”, or “Music”, di-
rectly, without reading all the tuples of the instructor relation. An index can also be
createdonalistofattributes,forexample,onattributesnameanddept nameofinstruc-
tor.
Indicesarenotrequiredforcorrectness,sincetheyareredundantdatastructures.
Indices form part of the physical schema of the database, as opposed to its logical
schema.
However, indicesare important for efficient processing of transactions, including
bothupdatetransactionsandqueries.Indicesarealsoimportantforefficientenforce-
mentofintegrityconstraintssuchasprimary-keyandforeign-keyconstraints.Inprin-
ciple,adatabasesystemcandecideautomaticallywhatindicestocreate.However,be-
causeofthespacecostofindices,aswellastheeffectofindicesonupdateprocessing,
itisnoteasytoautomaticallymaketherightchoicesaboutwhatindicestomaintain.
Therefore,mostSQLimplementationsprovidetheprogrammerwithcontrolover
the creation and removal of indices via data-definition-language commands. We illus-
trate thesyntax ofthesecommandsnext.Althoughthesyntaxthatweshowiswidely
usedandsupportedbymanydatabasesystems,itisnotpartoftheSQLstandard.The
SQL standard does not support control of the physical database schema; it restricts
itselftothelogicaldatabaseschema.
Wecreateanindexwiththecreateindexcommand,whichtakestheform:
createindex<index-name>on<relation-name>(<attribute-list>);
Theattribute-lististhelistofattributesoftherelationsthatformthesearchkeyforthe
index.
To define an index named dept index on the instructor relation with dept name as
thesearchkey,wewrite:
createindexdept indexoninstructor (dept name);
WhenausersubmitsanSQLquerythatcanbenefitfromusinganindex,theSQL
query processor automatically uses the index. For example, given an SQL query that

--- Page 194 ---

4.7 Authorization 165
selectstheinstructortuplewithdept name“Music”,theSQLqueryprocessorwoulduse
theindexdept indexdefinedabovetofindtherequiredtuplewithoutreadingthewhole
relation.
If we wish to declare that the search key is a candidate key, we add the attribute
uniquetotheindexdefinition.Thus,thecommand:
createuniqueindexdept indexoninstructor (dept name);
declares dept name to be a candidate key for instructor (which is probably not what
weactuallywouldwantforouruniversitydatabase).If,atthetimeweenterthecreate
unique index command, dept name is not a candidate key, the system will display an
errormessage,andtheattempttocreatetheindexwillfail.Iftheindex-creationattempt
succeeds,anysubsequentattempttoinsertatuplethatviolatesthekeydeclarationwill
fail.Notethattheuniquefeatureisredundantifthedatabasesystemsupportstheunique
declarationoftheSQLstandard.
The index name we specified for an index is required to drop an index. The drop
indexcommandtakestheform:
dropindex<index-name>;
Manydatabasesystemsalsoprovideawaytospecifythetypeofindextobeused,
suchasB+-treeorhashindices,whichwestudyinChapter14.Somedatabasesystems
alsopermitoneoftheindicesonarelationtobedeclaredtobeclustered;thesystem
then stores the relation sorted by the search key of the clustered index. We study in
Chapter14howindicesareactuallyimplemented,aswellaswhatindicesareautomat-
icallycreatedbydatabases,andhowtodecideonwhatadditionalindicestocreate.
4.7 Authorization
Wemayassignauserseveralformsofauthorizationsonpartsofthedatabase.Autho-
rizationsondatainclude:
• Authorizationtoreaddata.
• Authorizationtoinsertnewdata.
• Authorizationtoupdatedata.
• Authorizationtodeletedata.
Each of these types of authorizations iscalled a privilege. We may authorize the user
all,none,oracombinationofthesetypesofprivilegesonspecifiedpartsofadatabase,
suchasarelationoraview.

--- Page 195 ---

166 Chapter4 IntermediateSQL
Whenausersubmitsaqueryoranupdate,theSQLimplementationfirstchecksif
thequeryorupdate isauthorized,based ontheauthorizationsthattheuserhasbeen
granted.Ifthequeryorupdateisnotauthorized,itisrejected.
Inadditiontoauthorizationsondata,usersmayalsobegrantedauthorizationson
thedatabaseschema,allowingthem,forexample,tocreate,modify,ordroprelations.
A user who has some form of authorization may be allowed to pass on (grant) this
authorizationtootherusers,ortowithdraw(revoke)anauthorizationthatwasgranted
earlier.Inthissection,weseehoweachoftheseauthorizationscanbespecifiedinSQL.
The ultimate form of authority is that given to the database administrator. The
database administratormayauthorizenewusers,restructurethedatabase,andsoon.
Thisformofauthorizationisanalogoustothatofasuperuser,administrator,oroper-
atorforanoperatingsystem.
4.7.1 Granting and Revoking of Privileges
TheSQLstandardincludestheprivilegesselect,insert,update,anddelete.Theprivilege
all privileges can be used as a short form for all the allowable privileges. A user who
createsanewrelationisgivenallprivilegesonthatrelationautomatically.
The SQL data-definition language includes commands to grant and revoke privi-
leges.Thegrantstatementisusedtoconferauthorization.Thebasicformofthisstate-
mentis:
grant<privilegelist>
on<relationnameorviewname>
to<user/rolelist>;
Theprivilegelistallowsthegrantingofseveralprivilegesinonecommand.Thenotion
ofrolesiscoveredinSection4.7.2.
Theselectauthorizationonarelationisrequiredtoreadtuplesintherelation.The
followinggrantstatementgrantsdatabaseusersAmitandSatoshiselectauthorization
onthedepartmentrelation:
grantselectondepartmenttoAmit,Satoshi;
Thisallowsthoseuserstorunqueriesonthedepartmentrelation.
The update authorization on a relation allows a user to update any tuple in the
relation.Theupdateauthorizationmaybegiveneitheronallattributesoftherelation
or on only some. If update authorization is included in a grant statement, the list of
attributesonwhichupdateauthorizationistobegrantedoptionallyappearsinparen-
theses immediately after the update keyword. If the list of attributes is omitted, the
updateprivilegewillbegrantedonallattributesoftherelation.
This grant statement gives users Amit and Satoshi update authorization on the
budgetattributeofthedepartmentrelation:

--- Page 196 ---

4.7 Authorization 167
grantupdate(budget)ondepartmenttoAmit,Satoshi;
The insert authorization on a relation allows a user to insert tuples into the relation.
The insert privilege may also specify a list of attributes; any inserts to the relation
must specify only these attributes, and the system either gives each of the remaining
attributesdefaultvalues(ifadefaultisdefinedfortheattribute)orsetsthemtonull.
Thedeleteauthorizationonarelationallowsausertodeletetuplesfromarelation.
The user name public refers to all current and future users of the system. Thus,
privilegesgrantedtopublicareimplicitlygrantedtoallcurrentandfutureusers.
By default, a user/role that is granted a privilege is not authorized to grant that
privilegetoanotheruser/role.SQLallowsaprivilegegranttospecifythattherecipient
mayfurthergranttheprivilegetoanotheruser.Wedescribethisfeatureinmoredetail
inSection4.7.5.
It is worth noting that the SQL authorization mechanism grants privileges on an
entire relation, or on specified attributes of a relation. However, it does not permit
authorizationsonspecifictuplesofarelation.
To revoke an authorization, we use the revoke statement. It takes a form almost
identicaltothatofgrant:
revoke<privilegelist>
on<relationnameorviewname>
from<user/rolelist>;
Thus,torevoketheprivilegesthatwegrantedpreviously,wewrite
revokeselectondepartmentfromAmit,Satoshi;
revokeupdate(budget)ondepartmentfromAmit,Satoshi;
Revocation of privileges is more complex if the user from whom the privilege is
revoked has granted the privilege to another user. We return to this issue in Section
4.7.5.
4.7.2 Roles
Consider the real-world roles of various people in a university. Each instructor must
have the same types of authorizations on the same set of relations. Whenever a new
instructorisappointed,shewillhavetobegivenalltheseauthorizationsindividually.
A better approach would be to specify the authorizations that every instructor is
to be given, and to identify separately which database users are instructors. The sys-
tem can use these two pieces of information to determine the authorizations of each
instructor. When anewinstructor ishired,a useridentifiermust be allocated tohim,
andhemustbeidentifiedasaninstructor.Individualpermissionsgiventoinstructors
neednotbespecifiedagain.

--- Page 197 ---

168 Chapter4 IntermediateSQL
Thenotionofrolescapturesthisconcept.Asetofrolesiscreatedinthedatabase.
Authorizationscanbegrantedtoroles,inexactlythesamefashionastheyaregranted
toindividualusers.Eachdatabaseuserisgrantedasetofroles(whichmaybeempty)
thatsheisauthorizedtoperform.
In our university database, examples of roles could include instructor, teaching
assistant,student,dean,anddepartment chair.
Alesspreferablealternativewouldbetocreateaninstructoruseridandpermiteach
instructortoconnecttothedatabaseusingtheinstructoruserid.Theproblemwiththis
approach is that it would not be possible to identify exactly which instructor carried
outadatabaseupdate,andthiscouldcreatesecurityrisks.Furthermore,ifaninstruc-
tor leavesthe university oris moved to anon instructional role, then anew instructor
password must be created and distributed in a secure manner to all instructors. The
useofroleshasthebenefitofrequiringuserstoconnecttothedatabasewiththeirown
userid.
Anyauthorizationthatcanbegrantedtoausercanbegrantedtoarole.Rolesare
grantedtousersjustasauthorizationsare.
RolescanbecreatedinSQLasfollows:
createroleinstructor;
Roles can then be granted privileges just as the users can, as illustrated in this state-
ment:
grantselectontakes
toinstructor;
Rolescanbegrantedtousers,aswellastootherroles,asthesestatementsshow:
createroledean;
grantinstructortodean;
grantdeantoSatoshi;
Thus,theprivilegesofauseroraroleconsistof:
• Allprivilegesdirectlygrantedtotheuser/role.
• Allprivilegesgrantedtorolesthathavebeengrantedtotheuser/role.
Notethattherecanbeachainofroles;forexample,theroleteaching assistantmay
begrantedtoallinstructors.Inturn,theroleinstructorisgrantedtoalldeans.Thus,the
deanroleinheritsallprivilegesgrantedtotherolesinstructor andtoteaching assistant
inadditiontoprivilegesgranteddirectlytodean.
Whenauserlogsintothedatabasesystem,theactionsexecutedbytheuserduring
thatsessionhavealltheprivilegesgranteddirectlytotheuser,aswellasallprivileges

--- Page 198 ---

4.7 Authorization 169
granted to roles that are granted (directly or indirectly via other roles) to that user.
Thus, if a user Amit has been granted the role dean, user Amit holds all privileges
granted directlytoAmit,aswellasprivilegesgranted to dean, plusprivilegesgranted
to instructor and teaching assistant if, as above, those roles were granted (directly or
indirectly)totheroledean.
It is worth noting that the concept of role-based authorization is not specific to
SQL,androle-basedauthorizationisusedforaccesscontrolinawidevarietyofshared
applications.
4.7.3 Authorization on Views
Inouruniversityexample,considerastaffmemberwhoneedstoknowthesalariesof
allfacultyinaparticulardepartment,saytheGeologydepartment.Thisstaffmember
isnotauthorizedtoseeinformationregardingfacultyinotherdepartments.Thus,the
staffmembermustbedenieddirectaccesstotheinstructorrelation.Butifheistohave
accesstotheinformationfortheGeologydepartment,hemightbegrantedaccesstoa
viewthatweshallcallgeo instructor,consistingofonlythoseinstructortuplespertaining
totheGeologydepartment.ThisviewcanbedefinedinSQLasfollows:
createviewgeo instructoras
(select*
frominstructor
wheredept name='Geology');
SupposethatthestaffmemberissuesthefollowingSQLquery:
select*
fromgeo instructor;
Thestaffmemberisauthorizedtoseetheresultofthisquery.However,whenthequery
processor translates itintoaquery on the actual relationsin the database, itreplaces
usesofaviewbythedefinitionoftheview,producingaqueryoninstructor.Thus,the
systemmustcheckauthorizationontheclerk’squerybeforeitreplacesviewsbytheir
definitions.
Auserwhocreatesaviewdoesnotnecessarilyreceiveallprivilegesonthatview.
She receives only those privileges that provide no additional authorization beyond
thosethatshealreadyhad.Forexample,auserwhocreatesaviewcannotbegivenup-
dateauthorizationonaviewwithouthavingupdateauthorizationontherelationsused
todefine the view.Ifauser createsaviewon whichnoauthorization canbe granted,
thesystemwilldenytheviewcreationrequest.Inourgeo instructorviewexample,the
creatoroftheviewmusthaveselectauthorizationontheinstructorrelation.
As we will see in Section 5.2, SQL supports the creation of functions and proce-
dures, which may, in turn, contain queries and updates. The execute privilege can be
granted on a function or procedure,enabling a user to execute the function or proce-

--- Page 199 ---

170 Chapter4 IntermediateSQL
dure. By default, just like views, functions and procedures have all the privileges that
thecreatorofthefunctionorprocedurehad.Ineffect,thefunctionorprocedureruns
asifitwereinvokedbytheuserwhocreatedthefunction.
Althoughthisbehaviorisappropriateinmanysituations,itisnotalwaysappropri-
ate. Starting with SQL:2003, if the function definition has an extra clause sql security
invoker, then it is executed under the privileges of the user who invokes the function,
rather than the privileges of the definer of the function. This allows the creation of
librariesoffunctionsthatcanrununderthesameauthorizationastheinvoker.
4.7.4 Authorizations on Schema
The SQL standard specifies a primitive authorization mechanism for the database
schema:Onlytheowneroftheschemacancarryoutanymodificationtotheschema,
such as creating or deleting relations, adding or dropping attributes of relations, and
addingordroppingindices.
However,SQLincludesareferencesprivilegethatpermitsausertodeclareforeign
keys when creating relations. The SQL references privilege is granted on specific at-
tributes in a manner like that for the update privilege. The following grant statement
allowsuserMarianotocreaterelationsthatreferencethekeydept nameofthedepart-
mentrelationasaforeignkey:
grantreferences(dept name)ondepartmenttoMariano;
Initially,itmayappearthatthereisnoreason evertopreventusersfromcreating
foreign keys referencing another relation. However, recall that foreign-key constraints
restrict deletion and update operations on the referenced relation. Suppose Mariano
createsaforeignkeyinarelationrreferencingthedept nameattributeofthedepartment
relationandtheninsertsatupleintor pertainingtotheGeologydepartment.Itisno
longerpossibletodeletetheGeologydepartmentfromthedepartmentrelationwithout
also modifying relation r. Thus, the definition of a foreign key by Mariano restricts
futureactivitybyotherusers;therefore,thereisaneedforthereferencesprivilege.
Continuingtousetheexampleofthedepartmentrelation,thereferencesprivilege
on department is also required to create a check constraint on a relation r if the con-
strainthasasubqueryreferencingdepartment.Thisisreasonableforthesamereasonas
theonewegaveforforeign-keyconstraints;acheckconstraintthatreferencesarelation
limitspotentialupdatestothatrelation.
4.7.5 Transfer of Privileges
A user who has been granted some form of authorization may be allowed to pass on
thisauthorizationtootherusers.Bydefault,auser/rolethatisgrantedaprivilegeisnot
authorized to grant that privilege to another user/role. If we wish to grant a privilege
and to allow the recipientto pass the privilege on to other users, we append the with
grantoptionclausetotheappropriategrantcommand.Forexample,ifwewishtoallow

--- Page 200 ---

4.7 Authorization 171
AmittheselectprivilegeondepartmentandallowAmittograntthisprivilegetoothers,
wewrite:
grantselectondepartmenttoAmitwithgrantoption;
Thecreatorofanobject(relation/view/role)holdsallprivilegesontheobject,including
theprivilegetograntprivilegestoothers.
Consider,asanexample,thegrantingofupdateauthorizationontheteachesrela-
tionoftheuniversitydatabase.Assumethat,initially,thedatabaseadministratorgrants
updateauthorizationonteachestousersU ,U ,andU ,whomay,inturn,passonthis
1 2 3
authorization tootherusers. Thepassingofaspecificauthorization fromone userto
anothercanberepresentedbyanauthorizationgraph.Thenodesofthisgrapharethe
users.
Consider the graph for update authorization on teaches. The graph includes an
edge U → U if user U grants update authorization on teaches to U. The root of the
i j i j
graph is the database administrator. In the sample graph in Figure 4.11, observe that
user U is granted authorization by both U and U ; U is granted authorization by
5 1 2 4
onlyU .
1
A user has an authorization if and only if there is a path from the root of the
authorization graph (the node representing the database administrator) down to the
noderepresentingtheuser.
4.7.6 Revoking of Privileges
Suppose that the database administrator decides to revoke the authorization of user
U .SinceU hasauthorizationfromU ,thatauthorizationshouldberevokedaswell.
1 4 1
However, U was granted authorization by both U and U . Since the database ad-
5 1 2
ministratordidnotrevokeupdateauthorizationonteachesfromU ,U retainsupdate
2 5
U 1 U 4
DBA U U
2 5
U
3
Figure 4.11 Authorization-grant graph(U 1 ,U 2 ,…,U 5 areusersandDBAreferstothe
databaseadministrator).

--- Page 201 ---

172 Chapter4 IntermediateSQL
authorizationonteaches.IfU eventuallyrevokesauthorizationfromU ,thenU loses
2 5 5
theauthorization.
A pair of devious users mightattempt to defeat the rules for revocation of autho-
rizationbygrantingauthorizationtoeachother.Forexample,U isinitiallygrantedan
2
authorization by the database administrator, and U further grants it to U . Suppose
2 3
U now grants the privilege back to U . If the database administrator revokes autho-
3 2
rization from U ,itmightappearthat U retainsauthorization through U .However,
2 2 3
notethatoncetheadministratorrevokesauthorizationfromU ,thereisnopathinthe
2
authorization graph from the root either to U or to U . Thus, SQL ensures that the
2 3
authorizationisrevokedfromboththeusers.
As we just saw, revocation of a privilege from a user/role may cause other
users/roles also to lose that privilege. This behavior is called cascading revocation. In
most database systems, cascading is the default behavior. However, the revoke state-
mentmayspecifyrestrictinordertopreventcascadingrevocation:
revokeselectondepartmentfromAmit,Satoshirestrict;
Inthiscase,thesystemreturnsanerrorifthereareanycascadingrevocationsanddoes
notcarryouttherevokeaction.
The keyword cascade can be used instead of restrict to indicate that revocation
shouldcascade;however,itcanbeomitted,aswehavedoneintheprecedingexamples,
sinceitisthedefaultbehavior.
Thefollowingrevokestatementrevokesonlythegrantoption,ratherthantheactual
selectprivilege:
revokegrantoptionforselectondepartmentfromAmit;
Note that some database implementations do not support the above syntax; instead,
theprivilegeitselfcanberevokedandthengrantedagainwithoutthegrantoption.
Cascadingrevocationisinappropriateinmanysituations.SupposeSatoshihasthe
roleofdean,grantsinstructortoAmit,andlatertheroledeanisrevokedfromSatoshi
(perhapsbecauseSatoshileavestheuniversity);Amitcontinuestobeemployedonthe
facultyandshouldretaintheinstructorrole.
Todeal with thissituation, SQL permitsa privilege to be granted by a role rather
thanbyauser.SQLhasanotionofthecurrentroleassociatedwithasession.Bydefault,
the current role associated with a session is null (except in some special cases). The
current role associated with a session can be set by executing set role role name. The
specifiedrolemusthavebeengrantedtotheuser,otherwisethesetrolestatementfails.
Tograntaprivilegewiththegrantorsettothecurrentroleassociatedwithasession,
wecanaddtheclause:
grantedbycurrent role
tothegrantstatement,providedthecurrentroleisnotnull.

--- Page 202 ---

4.8 Summary 173
Suppose the granting of the role instructor (or other privileges) to Amit is done
using the granted by current role clause, with the current role set to dean, instead of
the grantor being the user Satoshi. Then, revoking of roles/privileges (including the
roledean)fromSatoshiwillnotresultinrevokingofprivilegesthathadthegrantorset
totheroledean,evenifSatoshiwastheuserwhoexecutedthegrant;thus,Amitwould
retaintheinstructorroleevenafterSatoshi’sprivilegesarerevoked.
4.7.7 Row-Level Authorization
Thetypesofauthorizationprivilegeswehavestudiedapplyatthelevelofrelationsor
views. Some database systems provide mechanisms for fine-grained authorization at
thelevelofspecifictupleswithinarelation.
Suppose, for example, that we wish to allow a student to see her or his own data
in the takes relation but not those data of other users. We can enforce such a restric-
tion using row-level authorization, if the database supports it. We describe row-level
authorization in Oracle below; PostgreSQL and SQL Server too support row-level au-
thorizationusingaconceptuallysimilarmechanism,butusingadifferentsyntax.
The Oracle Virtual Private Database (VPD) feature supports row-level authoriza-
tionasfollows.Itallowsasystemadministratortoassociateafunctionwitharelation;
the function returns a predicate that gets added automatically to any query that uses
the relation.The predicatecan use the function sys context, whichreturnsthe identi-
fieroftheuseronwhosebehalfaqueryisbeingexecuted.Forourexampleofstudents
accessing their data in the takes relation, we would specify the following predicate to
beassociatedwiththetakesrelation:
ID=sys context('USERENV','SESSION USER')
Thispredicateisaddedbythesystemtothewhereclauseofeveryquerythatusesthe
takesrelation.Asaresult,eachstudentcanseeonlythosetakestupleswhoseIDvalue
matchesherID.
VPD provides authorization at the level of specific tuples, or rows, of a relation,
andisthereforesaidtobearow-levelauthorizationmechanism.Apotentialpitfallwith
adding a predicate as described above is that it may change the meaning of a query
significantly. For example, if a user wrote a query to find the average grade over all
courses, she would end up getting the average of her grades, not all grades. Although
thesystemwouldgivethe“right”answerfortherewrittenquery,thatanswerwouldnot
correspondtothequerytheusermayhavethoughtshewassubmitting.
4.8 Summary
• SQL supports several types of joins including natural join, inner and outer joins,
andseveraltypesofjoinconditions.

--- Page 203 ---

174 Chapter4 IntermediateSQL
° Natural join provides a simple way to write queries over multiple relations
in which a where predicate would otherwise equate attributes with matching
namesfromeachrelation.Thisconveniencecomesattheriskofqueryseman-
ticschangingifanewattributeisaddedtotheschema.
° The join-using construct provides a simple way to write queries over multiple
relationsinwhichequalityisdesiredforsomebutnotnecessarilyallattributes
withmatchingnames.
° The join-on construct provides a way to include a join predicate in the from
clause.
° Outer join provides a means to retain tuples that, due to a join predicate
(whether a natural join, a join-using, or a join-on), would otherwise not ap-
pearanywhereintheresultrelation.Theretainedtuplesarepaddedwithnull
valuessoastoconformtotheresultschema.
• Viewrelationscanbe definedas relationscontainingthe resultofqueries. Views
areusefulforhidingunneededinformationandforgatheringtogetherinformation
frommorethanonerelationintoasingleview.
• Transactionsaresequencesofqueriesandupdatesthattogethercarryoutatask.
Transactionscanbecommitted,orrolledback;whenatransactionisrolledback,
theeffectsofallupdatesperformedbythetransactionareundone.
• Integrityconstraintsensurethatchangesmadetothedatabasebyauthorizedusers
donotresultinalossofdataconsistency.
• Referential-integrity constraints ensure that a value that appears in one relation
for a given set of attributes also appears for a certain set of attributes in another
relation.
• Domainconstraintsspecifythesetofpossiblevaluesthatmaybeassociatedwith
anattribute.Suchconstraintsmayalsoprohibittheuseofnullvaluesforparticular
attributes.
• Assertionsaredeclarativeexpressionsthatstatepredicatesthatwerequirealways
tobetrue.
• The SQL data-definition language provides support for defining built-in domain
typessuchasdateandtimeaswellasuser-defineddomaintypes.
• Indices are important for efficient processing of queries, as well as for efficient
enforcementofintegrityconstraints.AlthoughnotpartoftheSQLstandard,SQL
commandsforcreationofindicesaresupportedbymostdatabasesystems.
• SQLauthorization mechanismsallowone todifferentiateamongtheusersofthe
database on the type of access they are permitted on various data values in the
database.

--- Page 204 ---

PracticeExercises 175
• Rolesenableustoassignasetofprivilegestoauseraccordingtotherolethatthe
userplaysintheorganization.
Review Terms
• Jointypes ° Defaultvalues
° Naturaljoin ° Largeobjects
⋄clob
° Innerjoinwithusingandon
⋄blob
° Left,rightandfullouterjoin
° User-definedtypes
° Outerjoinwithusingandon
° distincttypes
• Viewdefinition
° Domains
° Materializedviews
° Typeconversions
° Viewmaintenance
• Catalogs
° Viewupdate
• Schemas
• Transactions • Indices
° Commitwork • Privileges
° Rollbackwork ° Typesofprivileges
° Atomictransaction
⋄select
⋄insert
• Constraints
⋄update
° Integrityconstraints
° Grantingofprivileges
° Domainconstraints
° Revokingofprivileges
° Uniqueconstraint
° Privilegetograntprivileges
° Checkclause
° Grantoption
° Referentialintegrity
• Roles
⋄ Cascadingdeletes
• Authorizationonviews
⋄ Cascadingupdates
• Executeauthorization
° Assertions
• Invokerprivileges
• Datatypes • Row-levelauthorization
° Dateandtimetypes • Virtualprivatedatabase(VPD)

--- Page 205 ---

176 Chapter4 IntermediateSQL
Practice Exercises
4.1 ConsiderthefollowingSQLquerythatseekstofindalistoftitlesofallcourses
taughtinSpring2017alongwiththenameoftheinstructor.
selectname,title
frominstructor naturaljointeachesnaturaljoinsectionnaturaljoincourse
wheresemester ='Spring'andyear=2017
Whatiswrongwiththisquery?
4.2 WritethefollowingqueriesinSQL:
a. Displayalistofallinstructors,showingeachinstructor’sIDandthenum-
berofsectionstaught.Makesuretoshowthenumberofsectionsas0for
instructors who have not taught any section. Your query should use an
outerjoin,andshouldnotusesubqueries.
b. Write the same query as in part a, but using a scalar subquery and not
usingouterjoin.
c. Display the list of all course sections offered in Spring 2018, along with
theIDandnameofeachinstructorteachingthesection.Ifasectionhas
more than one instructor, that section should appear as many times in
the result as it has instructors. If a section does not have any instructor,
itshouldstillappearintheresultwiththeinstructornamesetto“—”.
d. Display the list of all departments, with the total number of instructors
ineachdepartment,withoutusingsubqueries.Makesuretoshowdepart-
mentsthathavenoinstructors,andlistthosedepartmentswithaninstruc-
torcountofzero.
4.3 Outer join expressions can be computed in SQL without using the SQL outer
joinoperation.Toillustratethisfact,showhowtorewriteeachofthefollowing
SQLquerieswithoutusingtheouterjoinexpression.
a. select*fromstudentnaturalleftouterjointakes
b. select*fromstudentnaturalfullouterjointakes
4.4 Supposewehavethreerelationsr(A,B),s(B,C),andt(B,D),withallattributes
declaredasnotnull.
a. Giveinstancesofrelationsr,s,andtsuchthatintheresultof
(r naturalleftouterjoins)naturalleftouterjoint
attributeC hasanullvaluebutattributeDhasanon-nullvalue.
b. Arethereinstancesofr,s,andtsuchthattheresultof
r naturalleftouterjoin(snaturalleftouterjoint)

--- Page 206 ---

Exercises 177
employee(ID,person name,street,city)
works(ID,company name,salary)
company(company name,city)
manages(ID,manager id)
Figure 4.12 Employeedatabase.
hasanullvalueforC butanon-nullvalueforD?Explainwhyorwhynot.
4.5 Testing SQL queries: To test if a query specified in English has been correctly
writteninSQL,theSQLqueryistypicallyexecutedonmultipletestdatabases,
andahumanchecksiftheSQLqueryresultoneachtestdatabasematchesthe
intentionofthespecificationinEnglish.
a. InSection4.1.1wesawanexampleofanerroneousSQLquerywhichwas
intended to find which courses had been taught by each instructor; the
querycomputedthenaturaljoinofinstructor,teaches,andcourse,andas
aresultitunintentionallyequatedthedept nameattributeofinstructorand
course.Giveanexampleofadatasetthatwouldhelpcatchthisparticular
error.
b. Whencreatingtestdatabases,itisimportanttocreatetuplesinreferenced
relationsthatdonothaveanymatchingtuple inthereferencingrelation
foreachforeignkey.Explainwhy,usinganexamplequeryontheuniver-
sitydatabase.
c. When creating test databases, it is important to create tuples with null
values for foreign-key attributes, provided the attribute is nullable (SQL
allowsforeign-keyattributestotakeonnullvalues,aslongastheyarenot
partoftheprimarykeyandhavenotbeendeclaredasnotnull). Explain
why,usinganexamplequeryontheuniversitydatabase.
Hint:UsethequeriesfromExercise4.2.
4.6 Show how to define the view student grades (ID, GPA) giving the grade-point
averageofeachstudent,basedonthequeryinExercise3.2;recallthatweused
arelationgrade points(grade,points) to getthe numericpointsassociated with
alettergrade.Makesureyourviewdefinitioncorrectlyhandlesthecaseofnull
valuesforthegradeattributeofthetakesrelation.
4.7 Consider the employee database of Figure 4.12. Give an SQL DDL definition
ofthisdatabase.Identifyreferential-integrityconstraintsthatshouldhold,and
includethemintheDDLdefinition.

--- Page 207 ---

178 Chapter4 IntermediateSQL
4.8 As discussed in Section 4.4.8, we expect the constraint “an instructor cannot
teachsectionsintwodifferentclassroomsinasemesterinthesametimeslot”
tohold.
a. WriteanSQLquerythatreturnsall(instructor,section)combinationsthat
violatethisconstraint.
b. Write an SQL assertion to enforce this constraint (as discussed in Sec-
tion 4.4.8, current generation database systems do not support such as-
sertions,althoughtheyarepartoftheSQLstandard).
4.9 SQL allows a foreign-key dependency to refer to the same relation, as in the
followingexample:
createtablemanager
(employee ID char(20),
manager ID char(20),
primarykeyemployee ID,
foreignkey(manager ID)referencesmanager(employee ID)
ondeletecascade)
Here, employee ID is a key to the table manager, meaning that each employee
has at most one manager. The foreign-key clause requires that every manager
alsobeanemployee.Explainexactlywhathappenswhenatupleintherelation
manager isdeleted.
4.10 Given the relations a(name, address, title) and b(name, address, salary), show
howtoexpressanaturalfullouterjoinbusingthefullouter-joinoperationwith
anonconditionratherthanusingthenaturaljoinsyntax.Thiscanbedoneusing
thecoalesceoperation.Makesurethattheresultrelationdoesnotcontaintwo
copiesoftheattributes nameandaddressandthatthesolution iscorrecteven
ifsometuplesinaandbhavenullvaluesforattributesnameoraddress.
4.11 Operatingsystemsusuallyofferonlytwotypesofauthorizationcontrolfordata
files:readaccessandwriteaccess.Whydodatabasesystemsoffersomanykinds
ofauthorization?
4.12 Supposeauserwantstograntselectaccessonarelationtoanotheruser.Why
shouldtheuserinclude(ornotinclude)theclausegrantedbycurrentroleinthe
grantstatement?
4.13 Consideraviewvwhosedefinitionreferencesonlyrelationr.
• If a user is granted select authorization on v, does that user need to have
selectauthorizationonr aswell?Whyorwhynot?
• Ifauserisgrantedupdate authorization on v, doesthatuserneed tohave
updateauthorizationonr aswell?Whyorwhynot?

--- Page 208 ---

Exercises 179
• Givean example ofaninsertoperation onaviewvtoaddatuplet thatis
notvisibleintheresultofselect*fromv.Explainyouranswer.
Exercises
4.14 Considerthequery
selectcourse id,semester,year,sec id,avg(tot cred)
fromtakesnaturaljoinstudent
whereyear =2017
groupbycourse id,semester,year,sec id
havingcount(ID)>=2;
Explainwhyappendingnaturaljoinsectioninthefromclausewouldnotchange
theresult.
4.15 Rewritethequery
select*
fromsectionnaturaljoinclassroom
withoutusinganaturaljoinbutinsteadusinganinnerjoinwithausingcondi-
tion.
4.16 WriteanSQLqueryusingtheuniversityschematofindtheIDofeachstudent
whohasnevertakenacourseattheuniversity.Dothisusingnosubqueriesand
nosetoperations(useanouterjoin).
4.17 ExpressthefollowingqueryinSQLusingnosubqueriesandnosetoperations.
selectID
fromstudent
except
selects id
fromadvisor
wherei IDisnotnull
4.18 Forthedatabase ofFigure4.12, writeaquerytofindthe IDofeachemployee
withnomanager.Notethatanemployeemaysimplyhavenomanagerlistedor
may have a null manager. Write your query using an outer join and then write
itagainusingnoouterjoinatall.
4.19 Underwhatcircumstanceswouldthequery

--- Page 209 ---

180 Chapter4 IntermediateSQL
select*
fromstudentnaturalfullouterjointakes
naturalfullouterjoincourse
includetupleswithnullvaluesforthetitleattribute?
4.20 Showhowtodefineaviewtot credits(year,num credits),givingthetotalnumber
ofcreditstakenineachyear.
4.21 FortheviewofExercise4.18,explainwhythedatabasesystemwouldnotallow
atupletobeinsertedintothedatabasethroughthisview.
4.22 Showhowtoexpressthecoalescefunctionusingthecaseconstruct.
4.23 Explain why, when a manager, say Satoshi, grants an authorization, the grant
shouldbedonebythemanagerrole,ratherthanbytheuserSatoshi.
4.24 SupposeuserA,whohasallauthorizationprivilegesonarelationr,grantsselect
onrelationrtopublicwithgrantoption.SupposeuserBthengrantsselectonr
toA.Doesthiscauseacycleintheauthorizationgraph?Explainwhy.
4.25 Supposeausercreatesanewrelationr1withaforeignkeyreferencinganother
relationr2.Whatauthorizationprivilegedoestheuserneedonr2?Whyshould
thisnotsimplybeallowedwithoutanysuchauthorization?
4.26 Explain the difference between integrity constraints and authorization con-
straints.
Further Reading
General SQL references were provided in Chapter 3. As noted earlier, many systems
implementfeaturesinanon-standardmanner,and,forthatreason,areferencespecific
to the database system you are using is an essential guide. Most vendorsalso provide
extensivesupportontheweb.
The rules used by SQL to determine the updatability of a view, and how updates
arereflectedonthe underlyingdatabase relationsappeared inSQL:1999and aresum-
marizedin[MeltonandSimon(2001)].
The original SQL proposals for assertions date back to [Astrahan et al. (1976)],
[Chamberlinetal.(1976)],and[Chamberlinetal.(1981)].
Bibliography
[Astrahanetal.(1976)] M.M.Astrahan,M.W.Blasgen,D.D.Chamberlin,K.P.Eswaran,
J.N.Gray,P.P.Griffiths,W.F.King,R.A.Lorie,P.R.McJones,J.W.Mehl,G.R.Putzolu,
I.L.Traiger,B.W.Wade,andV.Watson,“SystemR,ARelationalApproachtoDataBase

--- Page 210 ---

FurtherReading 181
Management”,ACMTransactionsonDatabaseSystems,Volume1,Number2(1976),pages
97–137.
[Chamberlinetal.(1976)] D.D.Chamberlin,M.M.Astrahan,K.P.Eswaran,P.P.Griffiths,
R.A.Lorie,J.W.Mehl,P.Reisner,andB.W.Wade,“SEQUEL2:AUnifiedApproachto
Data Definition, Manipulation, and Control”, IBM Journal of Research and Development,
Volume20,Number6(1976),pages560–575.
[Chamberlinetal.(1981)] D.D.Chamberlin,M.M.Astrahan,M.W.Blasgen,J.N.Gray,
W.F.King,B.G.Lindsay,R.A.Lorie,J.W.Mehl,T.G.Price,P.G.Selinger,M.Schkolnick,
D.R.Slutz,I.L.Traiger,B.W.Wade,andR.A.Yost,“AHistoryandEvaluationofSystem
R”,CommunicationsoftheACM,Volume24,Number10(1981),pages632–646.
[MeltonandSimon(2001)] J.MeltonandA.R.Simon,SQL:1999,UnderstandingRelational
LanguageComponents,MorganKaufmann(2001).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 212 ---

5
CHAPTER
Advanced SQL
Chapter3andChapter4provideddetailedcoverageofthebasicstructure ofSQL.In
this chapter, we first address the issue of how to access SQL from a general-purpose
programming language, which is very important for building applications that use a
databasetomanagedata.WethencoversomeofthemoreadvancedfeaturesofSQL,
startingwithhowproceduralcodecanbeexecutedwithinthedatabaseeitherbyextend-
ingtheSQLlanguagetosupportproceduralactionsorbyallowingfunctionsdefinedin
procedurallanguagestobeexecutedwithinthedatabase.Wedescribetriggers,which
canbeusedtospecifyactionsthataretobecarriedoutautomaticallyoncertainevents
suchasinsertion,deletion,orupdateoftuplesinaspecifiedrelation.Finally,wediscuss
recursivequeriesandadvancedaggregationfeaturessupportedbySQL.
5.1 Accessing SQL from a Programming Language
SQLprovidesapowerfuldeclarativequerylanguage.WritingqueriesinSQLisusually
mucheasierthancodingthesamequeriesinageneral-purposeprogramminglanguage.
However,adatabaseprogrammermusthaveaccesstoageneral-purposeprogramming
languageforatleasttworeasons:
1. NotallqueriescanbeexpressedinSQL,sinceSQLdoesnotprovidethefullex-
pressivepowerofageneral-purposelanguage.Thatis,thereexistqueriesthatcan
beexpressedinalanguagesuchasC,Java,orPythonthatcannotbeexpressedin
SQL.Towritesuchqueries,wecanembedSQLwithinamorepowerfullanguage.
2. Nondeclarative actions—such as printing a report, interacting with a user, or
sendingtheresultsofaquerytoagraphicaluserinterface—cannotbedonefrom
withinSQL.Applicationsusuallyhaveseveral components,andqueryingorup-
dating data are only one component; other components are written in general-
purposeprogramminglanguages.Foranintegratedapplication,theremustbea
meanstocombineSQLwithageneral-purposeprogramminglanguage.
TherearetwoapproachestoaccessingSQLfromageneral-purposeprogramming
language:
183

--- Page 213 ---

184 Chapter5 AdvancedSQL
1. DynamicSQL:Ageneral-purposeprogramcanconnecttoandcommunicatewith
a database server using a collection of functions (for procedural languages) or
methods (for object-oriented languages). Dynamic SQL allows the program to
construct an SQL query as a character string at runtime, submit the query, and
then retrieve the result into program variables a tuple at a time. The dynamic
SQLcomponentofSQLallowsprogramstoconstructandsubmitSQLqueriesat
runtime.
Inthischapter,welookattwostandardsforconnectingtoanSQLdatabase
andperformingqueriesandupdates.One,JDBC(Section5.1.1),isanapplication
program interface for the Java language. The other, ODBC (Section 5.1.3), is
an application program interface originally developed for the C language, and
subsequentlyextendedtootherlanguagessuchasC++,C#,Ruby,Go,PHP,and
VisualBasic.WealsoillustratehowprogramswritteninPythoncanconnectto
adatabaseusingthePythonDatabaseAPI(Section5.1.2).
The ADO.NET API, designed for the Visual Basic .NET and C# languages,
provides functions to access data, which at a high level are similar to the JDBC
functions,althoughdetailsdiffer.TheADO.NETAPIcanalsobeusedwithsome
kinds of non-relational data sources. Details of ADO.NET may be found in the
manualsavailableonlineandarenotcoveredfurtherinthischapter.
2. Embedded SQL: Like dynamic SQL, embedded SQL provides a means by which
a program can interact with a database server. However, under embedded SQL,
the SQL statements are identified at compile time using a preprocessor, which
translates requests expressed in embedded SQL into function calls. At runtime,
thesefunctioncallsconnecttothedatabaseusinganAPIthatprovidesdynamic
SQLfacilitiesbutmaybespecifictothedatabasethatisbeingused.Section5.1.4
brieflycoversembeddedSQL.
AmajorchallengeinmixingSQLwithageneral-purposelanguageisthemismatch
in the ways these languages manipulate data. In SQL, the primary type of data are
relations. SQL statements operate on relations and return relations as a result. Pro-
gramminglanguagesnormallyoperateonavariableatatime,andthosevariablescor-
respond roughly to the value of an attribute in a tuple in a relation. Thus, integrating
thesetwotypesoflanguagesintoasingleapplicationrequiresprovidingamechanism
toreturntheresultofaqueryinamannerthattheprogramcanhandle.
Ourexamplesinthissectionassume thatweareaccessingadatabase onaserver
that runs a database system. An alternative approach using an embedded database is
discussedinNote5.1onpage198.
5.1.1 JDBC
TheJDBCstandarddefinesanapplicationprograminterface(API)thatJavaprograms
canusetoconnecttodatabaseservers.(ThewordJDBCwasoriginallyanabbreviation
forJavaDatabaseConnectivity,butthefullformisnolongerused.)

--- Page 214 ---

5.1 AccessingSQLfromaProgrammingLanguage 185
Figure5.1showsexampleJavacodethatusestheJDBCinterface.TheJavaprogram
must import java.sql.*, which contains the interface definitions for the functionality
providedbyJDBC.
5.1.1.1 ConnectingtotheDatabase
ThefirststepinaccessingadatabasefromaJavaprogramistoopenaconnectionto
thedatabase.Thisstepisrequiredtoselectwhichdatabasetouse,suchasaninstance
of Oracle running on your machine, or a PostgreSQL database running on another
machine.OnlyafteropeningaconnectioncanaJavaprogramexecuteSQLstatements.
public static void JDBCexample(String userid, String passwd)
{
try (
Connection conn = DriverManager.getConnection(
"jdbc:oracle:thin:@db.yale.edu:1521:univdb",
userid, passwd);
Statement stmt = conn.createStatement();
) {
try {
stmt.executeUpdate(
"insert into instructor values(’77987’,’Kim’,’Physics’,98000)");
}
catch (SQLException sqle) {
System.out.println("Could not insert tuple. " + sqle);
}
ResultSet rset = stmt.executeQuery(
"select deptname, avg (salary) "+
" from instructor "+
" group by deptname");
while (rset.next()){
System.out.println(rset.getString("deptname") + " " +
rset.getFloat(2));
}
}
catch (Exceptionsqle)
{
System.out.println("Exception: " + sqle);
}
}
Figure 5.1 AnexampleofJDBCcode.

--- Page 215 ---

186 Chapter5 AdvancedSQL
AconnectionisopenedusingthegetConnection()methodoftheDriverManager
class(withinjava.sql).Thismethodtakesthreeparameters.1
1. ThefirstparametertothegetConnection()callisastringthatspecifiestheURL,
or machine name, where the server runs (in our example, db.yale.edu), along
withpossiblysomeotherinformationsuchastheprotocoltobeusedtocommu-
nicatewiththedatabase(inourexample,jdbc:oracle:thin:;weshallshortlysee
whythisisrequired),theportnumberthedatabasesystemusesforcommunica-
tion (in our example, 2000), and the specific database on the server to be used
(inourexample,univdb).NotethatJDBCspecifiesonlytheAPI,notthecommu-
nication protocol.A JDBCdriver may support multiple protocols, and we must
specifyonesupported byboththedatabaseandthedriver.Theprotocoldetails
arevendorspecific.
2. ThesecondparametertogetConnection()isadatabaseuseridentifier,whichis
astring.
3. Thethirdparameterisapassword,whichisalsoastring.(Notethattheneedto
specifyapassword withintheJDBCcodepresentsasecurityriskifanunautho-
rizedpersonaccessesyourJavacode.)
In our example in the figure, we have created a Connection object whose handle is
conn.
Each database product that supports JDBC (all the major database vendors do)
providesaJDBCdriverthatmustbedynamicallyloadedinordertoaccessthedatabase
from Java. In fact, loading the driver must be done first, before connecting to the
database. If the appropriate driver has been downloaded from the vendor’s web site
andisintheclasspath,thegetConnection()methodwilllocatetheneededdriver.2The
driverprovidesforthetranslationofproduct-independentJDBCcallsintotheproduct-
specificcallsneededbythespecificdatabasemanagementsystembeingused.Theac-
tual protocol used to exchange information with the database depends on the driver
that is used, and it is not defined by the JDBC standard. Some drivers support more
thanoneprotocol,andasuitableprotocolmustbechosendependingonwhatprotocol
theparticulardatabaseproductsupports.Inourexample,whenopeningaconnection
withthedatabase,thestringjdbc:oracle:thin:specifiesaparticularprotocolsupported
byOracle.TheMySQLequivalentisjdbc:mysql:
5.1.1.2 ShippingSQLStatementstotheDatabaseSystem
Onceadatabaseconnectionisopen,theprogramcanuseittosendSQLstatementsto
thedatabasesystemforexecution.ThisisdoneviaaninstanceoftheclassStatement.
1TherearemultipleversionsofthegetConnection()method,whichdifferintheparametersthattheyaccept.Wepresent
themostcommonlyusedversion.
2Priortoversion4,locatingthedriverwasdonemanuallybyinvokingClass.forNamewithoneargumentspecifyinga
concreteclassimplementingthejava.sql.Driverinterface,inalineofcodepriortothegetConnectioncall.

--- Page 216 ---

5.1 AccessingSQLfromaProgrammingLanguage 187
AStatementobjectisnottheSQLstatementitself,butratheranobjectthatallowsthe
JavaprogramtoinvokemethodsthatshipanSQLstatementgivenasanargumentfor
executionbythedatabasesystem.OurexamplecreatesaStatementhandle(stmt)on
theconnectionconn.
Toexecuteastatement,weinvokeeithertheexecuteQuery()methodortheexe-
cuteUpdate()method,dependingonwhethertheSQLstatementisaquery(and,thus,
returns aresult set) or nonquery statement such as update, insert, delete, or create ta-
ble. Inour example, stmt.executeUpdate()executesan update statement thatinserts
into the instructor relation. It returns an integer giving the number of tuples inserted,
updated,ordeleted.ForDDLstatements,thereturnvalueiszero.
5.1.1.3 ExceptionsandResourceManagement
Executing any SQL method might result in an exception being thrown. The try { … }
catch{…} constructpermitsustocatchanyexceptions(errorconditions)thatarise
whenJDBCcallsaremadeandtakeappropriateaction.InJDBCprogramming,itmay
beusefultodistinguishbetweenanSQLexception,whichisanSQL-specificexception,
and the general case of an Exception, which could be any Java exception such as a
null-pointerexception,orarray-index-out-of-boundsexception.WeshowbothinFigure
5.1. In practice, one would write more complete exception handlers than we do (for
thesakeofconciseness)inourexamplecode.
Opening a connection, a statement, and other JDBC objects are all actions that
consumesystemresources.Programmersmusttakecaretoensurethatprogramsclose
all such resources. Failure to do so may cause the database system’s resource pools
tobecomeexhausted,renderingthesysteminaccessibleorinoperativeuntilatime-out
period expires. One way to do this is to code explicit calls to close connections and
statements. This approach fails if the code exits due to an exception and, in so do-
ing,avoidstheJavastatementwiththecloseinvocation.Forthisreason,thepreferred
approach is to use the try-with-resources construct in Java. In the example of Figure
5.1, the opening of the connection and statement objects is done within parentheses
ratherthaninthemainbodyofthetryincurlybraces.Resourcesopenedinthecode
withinparenthesesareclosedautomaticallyattheendofthetryblock.Thisprotectsus
fromleavingconnectionsorstatementsunclosed.Sinceclosingastatementimplicitly
closes objects opened for that statement (i.e., the ResultSet objects we shall discuss
inthenextsection,thiscodingpracticeprotectsusfromleavingresourcesunclosed.3
In the example of Figure5.1, we could have closed the connectionexplicitlywiththe
statement conn.close() and closed the statement explicitly with stmt.close(), though
doingsowasnotnecessaryinourexample.
5.1.1.4 RetrievingtheResultofaQuery
The example code of Figure 5.1 executes a query by using stmt.executeQuery(). It
retrievesthesetoftuplesintheresultintoaResultSetobjectrsetandfetchesthemone
3ThisJavafeature,calledtry-with-resources,wasintroducedinJava7.

--- Page 217 ---

188 Chapter5 AdvancedSQL
tupleatatime.Thenext()methodontheresultsettestswhetherornotthereremains
at least one unfetched tuple in the result set and if so, fetches it. The return value of
the next()methodisaBoolean indicatingwhetheritfetchedatuple.Attributes from
the fetched tuple are retrieved using various methods whose names begin with get.
The method getString()can retrieveany of the basic SQL data types (converting the
valuetoaJavaStringobject),butmorerestrictivemethodssuchasgetFloat()canbe
usedaswell.Theargumenttothevariousgetmethodscaneitherbeanattributename
specifiedasastring,oranintegerindicatingthepositionofthedesiredattributewithin
the tuple. Figure 5.1 shows two ways of retrieving the values of attributes in a tuple:
usingthenameoftheattribute(dept name)andusingthepositionoftheattribute(2,
todenotethesecondattribute).
5.1.1.5 PreparedStatements
Wecancreateapreparedstatementinwhichsomevaluesarereplacedby“?”,thereby
specifyingthatactualvalues willbe providedlater.The database system compilesthe
querywhenitisprepared.Eachtimethequeryisexecuted(withnewvaluestoreplace
the “?”s), the database system can reuse the previously compiled form of the query
and apply the new values as parameters. The code fragment in Figure 5.2 shows how
preparedstatementscanbeused.
TheprepareStatement()methodoftheConnectionclassdefinesaquerythatmay
contain parameter values; some JDBC drivers may submit the query to the database
forcompilationaspartofthemethod,butotherdriversdonotcontactthedatabaseat
thispoint.ThemethodreturnsanobjectofclassPreparedStatement.Atthispoint,no
SQLstatementhasbeenexecuted.TheexecuteQuery()andexecuteUpdate()methods
of PreparedStatement class do that. But before they can be invoked, we must use
methods of class PreparedStatement that assign values for the “?” parameters. The
setString() method and other similar methods such as setInt() for other basic SQL
typesallowustospecifythevaluesfortheparameters.Thefirstargumentspecifiesthe
“?”parameterforwhichweareassigningavalue(thefirstparameteris1,unlikemost
otherJavaconstructs,whichstartwith0).Thesecondargumentspecifiesthevalueto
beassigned.
In the example in Figure 5.2, we prepare an insert statement, set the “?” parame-
ters, and theninvoke executeUpdate().The finaltwolinesof ourexample show that
parameterassignmentsremainunchangeduntilwespecificallyreassignthem.Thus,the
final statement, whichinvokes executeUpdate(),inserts the tuple (“88878”, “Perry”,
“Finance”,125000).
Prepared statements allow for more efficient execution in cases where the same
querycanbecompiledonceandthenrunmultipletimeswithdifferentparameterval-
ues.However,thereisanevenmoresignificantadvantagetopreparedstatementsthat
makes them the preferred method of executing SQL queries whenever a user-entered
valueisused,evenifthequeryistoberunonlyonce.Supposethatwereadinauser-
entered value and then use Java string manipulation to construct the SQL statement.

--- Page 218 ---

5.1 AccessingSQLfromaProgrammingLanguage 189
PreparedStatementpStmt = conn.prepareStatement(
"insert into instructor values(?,?,?,?)");
pStmt.setString(1,"88877");
pStmt.setString(2,"Perry");
pStmt.setString(3,"Finance");
pStmt.setInt(4,125000);
pStmt.executeUpdate();
pStmt.setString(1,"88878");
pStmt.executeUpdate();
Figure 5.2 PreparedstatementsinJDBCcode.
If the user enters certain special characters, such as a single quote, the resulting SQL
statementmaybesyntacticallyincorrectunlesswetakeextraordinarycareinchecking
theinput.ThesetString()methoddoesthisforusautomaticallyandinsertstheneeded
escapecharacterstoensuresyntacticcorrectness.
In our example, suppose that the values for the variables ID, name, dept name,
andsalaryhavebeenenteredbyauser,andacorrespondingrowistobeinsertedinto
theinstructor relation.Supposethat,insteadofusingapreparedstatement,aqueryis
constructedbyconcatenatingthestringsusingthefollowingJavaexpression:
"insert into instructor values(’ " + ID + " ’, ’ " + name + " ’, " +
" ’" + dept name + " ’, " + salary + ")"
and the query is executed directlyusing the executeQuery() method of a Statement
object.Observetheuseofsinglequotesinthestring,whichwouldsurroundthevalues
ofID,nameanddept nameinthegeneratedSQLquery.
Now,iftheusertypedasinglequoteintheIDornamefields,thequerystringwould
have asyntax error. It isquite possible thatan instructor name may have aquotation
markinitsname(forexample,“O’Henry”).
Whiletheaboveexamplemightbeconsideredanannoyance,thesituationcanbe
muchworse.AtechniquecalledSQLinjectioncanbeusedbymalicioushackerstosteal
dataordamagethedatabase.
SupposeaJavaprograminputsastringnameandconstructsthequery:
"select * from instructor where name = ’" + name + "’"
Iftheuser,insteadofenteringaname,enters:
X’ or ’Y’ = ’Y
thentheresultingstatementbecomes:

--- Page 219 ---

190 Chapter5 AdvancedSQL
"select * from instructor where name = ’" + "X’ or ’Y’ = ’Y" + "’"
whichis:
select * from instructor where name = ’X’ or ’Y’ = ’Y’
Intheresultingquery,thewhereclauseisalwaystrueandtheentireinstructorrelation
isreturned.
More clever malicious users could arrange to output even more data, including
credentialssuch as passwords that allow the user to connectto the database and per-
formanyactionstheywant.SQLinjectionattacksonupdatestatementscanbeusedto
changethevaluesthatarebeingstoredinupdatedcolumns.Infacttherehavebeena
numberofattacksintherealworldusingSQLinjections;attacksonmultiplefinancial
siteshaveresultedintheftoflargeamountsofmoneybyusingSQLinjectionattacks.
Use ofapreparedstatement wouldpreventthisproblembecause the inputstring
wouldhaveescapecharactersinserted,sotheresultingquerybecomes:
"select * from instructor where name = ’X∖’ or ∖’Y∖’ = ∖’Y’
whichisharmlessandreturnstheemptyrelation.
Programmersmustpassuser-inputstringstothedatabaseonlythroughparametersof
preparedstatements;creatingSQLqueriesbyconcatenatingstringswithuser-inputvalues
isanextremelyserioussecurityriskandshouldneverbedoneinanyprogram.
Some database systems allow multiple SQL statements to be executed in a single
JDBC execute method, with statements separated by a semicolon. This feature has
been turned off by default on some JDBC drivers because it allows malicious hackers
to insert whole SQL statements using SQL injection. For instance, in our earlier SQL
injectionexampleamalicioususercouldenter:
X’; drop table instructor; – –
whichwillresultinaquerystringwithtwostatementsseparatedbyasemicolonbeing
submitted to the database. Because these statements run with the privileges of the
database userid used by the JDBC connection, devastating SQL statements such as
drop table, or updates to any table of the user’s choice, could be executed. However,
some databases still allow execution of multiple statements as above; it is thus very
importanttocorrectlyusepreparedstatementstoavoidtheriskofSQLinjection.
5.1.1.6 CallableStatements
JDBCalsoprovidesaCallableStatementinterfacethatallowsinvocationofSQLstored
proceduresandfunctions(describedinSection5.2).Theseplaythesameroleforfunc-
tionsandproceduresasprepareStatementdoesforqueries.

--- Page 220 ---

5.1 AccessingSQLfromaProgrammingLanguage 191
CallableStatementcStmt1=conn.prepareCall("{?=callsome function(?)}");
CallableStatementcStmt2=conn.prepareCall("{callsome procedure(?,?)}");
The data types of function return values and out parameters of procedures must be
registered using the method registerOutParameter(), and can be retrieved using get
methodssimilartothoseforresultsets.SeeaJDBCmanualformoredetails.
5.1.1.7 MetadataFeatures
Aswenotedearlier,aJavaapplicationprogramdoesnotincludedeclarationsfordata
storedinthedatabase.ThosedeclarationsarepartoftheSQLDDLstatements.There-
fore,aJavaprogramthatusesJDBCmusteitherhaveassumptionsaboutthedatabase
schemahard-codedintotheprogram or determinethatinformationdirectlyfrom the
database system at runtime. The latter approach is usually preferable, since it makes
theapplicationprogrammorerobusttochangesinthedatabaseschema.
RecallthatwhenwesubmitaqueryusingtheexecuteQuery()method,theresultof
thequeryiscontainedinaResultSetobject.TheinterfaceResultSethasamethod,get-
MetaData(),that returns a ResultSetMetaDataobject that contains metadata about
theresultset.ResultSetMetaData,inturn,hasmethodstofindmetadatainformation,
such as the number of columns in the result, the name of a specified column, or the
typeofaspecifiedcolumn.Inthisway,wecanwritecodetoexecuteaqueryevenifwe
havenopriorknowledgeoftheschemaoftheresult.
ThefollowingJavacodesegmentusesJDBCtoprintoutthenamesandtypesofall
columnsofaresultset. Thevariable rsin thecode isassumed torefer toaResultSet
instanceobtainedbyexecutingaquery.
ResultSetMetaData rsmd = rs.getMetaData();
for(int i = 1; i <= rsmd.getColumnCount(); i++) {
System.out.println(rsmd.getColumnName(i));
System.out.println(rsmd.getColumnTypeName(i));
}
The getColumnCount() method returns the arity (number of attributes) of the
result relation. That allows us to iterate through each attribute (note that we start at
1, asis conventional inJDBC). Foreach attribute, we retrieveitsname and datatype
usingthemethodsgetColumnName()andgetColumnTypeName(),respectively.
TheDatabaseMetaDatainterfaceprovidesawaytofindmetadataaboutthedata-
base.TheinterfaceConnectionhasamethodgetMetaData()thatreturnsaDatabase-
MetaDataobject.TheDatabaseMetaDatainterfaceinturnhasaverylargenumber
ofmethodstogetmetadataabout thedatabase andthedatabase system towhichthe
applicationisconnected.
Forexample,therearemethodsthatreturntheproductnameandversionnumber
of the database system. Other methods allow the application to query the database
systemaboutitssupportedfeatures.

--- Page 221 ---

192 Chapter5 AdvancedSQL
DatabaseMetaDatadbmd = conn.getMetaData();
ResultSet rs = dbmd.getColumns(null, "univdb", "department","%");
// Arguments to getColumns: Catalog, Schema-pattern,Table-pattern,
// and Column-Pattern
// Returns: One row for each column; row has a number of attributes
// such as COLUMN NAME, TYPE NAME
while( rs.next()){
System.out.println(rs.getString("COLUMN NAME"),
rs.getString("TYPE NAME");
}
Figure 5.3 FindingcolumninformationinJDBCusingDatabaseMetaData.
Stillothermethodsreturninformationaboutthedatabaseitself.ThecodeinFig-
ure5.3illustrateshowtofindinformationaboutcolumns(attributes)ofrelationsina
database.Thevariableconnisassumedtobeahandleforanalreadyopeneddatabase
connection. The method getColumns() takes four arguments: a catalog name (null
signifiesthatthecatalognameistobeignored),aschemanamepattern,atablename
pattern,andacolumnnamepattern.Theschemaname,tablename,andcolumnname
patterns can be used to specify a name or a pattern. Patterns can use the SQL string
matching special characters “%” and “ ”; for instance, the pattern “%” matches all
names. Only columns of tables of schemas satisfying the specified name or pattern
are retrieved.Each row in the result setcontains informationabout one column.The
rows have a number of columns such as the name of the catalog, schema, table and
column,thetypeofthecolumn,andsoon.
The getTables() method allows you toget a listof all tables in the database. The
first three parameters to getTables() are the same as for getColumns(). The fourth
parametercanbe used torestrictthetypesoftablesreturned;ifsettonull,alltables,
includingsystem internal tables are returned, but the parameter can be set to restrict
thetablesreturnedtoonlyuser-createdtables.
ExamplesofothermethodsprovidedbyDatabaseMetaDatathatprovideinforma-
tionaboutthedatabaseincludethoseforprimarykeys(getPrimaryKeys()),foreign-key
references (getCrossReference()), authorizations, database limits such as maximum
numberofconnections,andsoon.
Themetadatainterfacescanbe used foravarietyoftasks. Forexample, theycan
beusedtowriteadatabasebrowserthatallowsausertofindthetablesinadatabase,
examine their schema, examine rows in a table, apply selections to see desired rows,
and so on. The metadata information can be used to make code used for these tasks
generic;forexample,codetodisplaytherowsinarelationcanbewritteninsuchaway
that it would work on all possible relations regardless of their schema. Similarly, it is

--- Page 222 ---

5.1 AccessingSQLfromaProgrammingLanguage 193
possibletowritecodethattakesaquerystring,executesthequery,andprintsoutthe
resultsasaformattedtable;thecodecanworkregardlessoftheactualquerysubmitted.
5.1.1.8 OtherFeatures
JDBCprovides anumber of otherfeatures, such as updatable result sets. It can create
an updatable resultsetfrom aquerythatperformsaselectionand/oraprojectionon
adatabase relation.Anupdate to atuple in the resultsetthenresults inan update to
thecorrespondingtupleofthedatabaserelation.
RecallfromSection4.3thatatransactionallowsmultipleactionstobetreatedasa
singleatomicunitwhichcanbecommittedorrolledback.Bydefault,eachSQLstate-
mentistreatedasaseparatetransactionthatiscommittedautomatically.Themethod
setAutoCommit()intheJDBCConnectioninterfaceallowsthisbehaviortobeturned
onoroff.Thus,ifconnisanopen connection,conn.setAutoCommit(false) turnsoff
automaticcommit.Transactionsmustthenbecommittedorrolledbackexplicitlyusing
either conn.commit() or conn.rollback(). conn.setAutoCommit(true) turns on auto-
maticcommit.
JDBCprovidesinterfacestodealwithlargeobjectswithoutrequiringanentirelarge
objecttobecreatedinmemory.Tofetchlargeobjects,theResultSetinterfaceprovides
methodsgetBlob()andgetClob()thataresimilartothegetString()method,butreturn
objectsoftypeBlobandClob,respectively.Theseobjectsdonotstoretheentirelarge
object,butinsteadstore“locators”forthelargeobjects,thatis,logicalpointerstothe
actuallargeobjectinthedatabase.Fetchingdatafromtheseobjectsisverymuchlike
fetching data from a file or an input stream, and it can be performed using methods
suchasgetBytes()andgetSubString().
Conversely, to store large objects in the database, the PreparedStatement class
permits a database column whose type is blob to be linked to an input stream (such
asafilethathasbeenopened)usingthemethodsetBlob(intparameterIndex,Input-
Stream inputStream). When the prepared statement is executed, data are read from
theinputstreamandwrittentotheblobinthedatabase.Similarly,aclobcolumncan
besetusingthesetClob()method,whichtakesasargumentsaparameterindexanda
characterstream.
JDBCincludesarowsetfeaturethatallowsresultsetstobecollectedandshipped
tootherapplications.Rowsetscanbescannedbothbackwardandforwardandcanbe
modified.
5.1.2 Database Access from Python
DatabaseaccesscanbedonefromPythonasillustratedbythemethodshowninFigure
5.4.ThestatementcontainingtheinsertqueryshowshowtousethePythonequivalent
of JDBC prepared statements, with parameters identified in the SQL query by “%s”,
and parameter values provided as a list. Updates are not committed to the database
automatically;thecommit()methodneedstobecalledtocommitanupdate.

--- Page 223 ---

194 Chapter5 AdvancedSQL
import psycopg2
def PythonDatabaseExample(userid,passwd)
try:
conn = psycopg2.connect( host="db.yale.edu", port=5432,
dbname="univdb", user=userid, password=passwd)
cur = conn.cursor()
try:
cur.execute("insert into instructor values(%s, %s, %s, %s)",
("77987","Kim","Physics",98000))
conn.commit();
except Exceptionas sqle:
print("Could not insert tuple. ", sqle)
conn.rollback()
cur.execute( ("select deptname, avg (salary)"
" from instructor group by deptname"))
for dept in cur:
print dept[0], dept[1]
except Exceptionas sqle:
print("Exception: ", sqle)
Figure 5.4 DatabaseaccessfromPython
Thetry:,except…:blockshowshowtocatchexceptionsandtoprintinformation
about the exception. The for loop illustrates how to loop over the result of a query
execution,andtoaccessindividualattributesofaparticularrow.
The preceding program uses the psycopg2 driver, which allows connection to
PostgreSQLdatabasesandisimportedinthefirstlineoftheprogram.Driversareusu-
allydatabasespecific,withtheMySQLdbdrivertoconnecttoMySQL,andcx Oracleto
connecttoOracle;butthepyodbcdrivercanconnecttomostdatabasesthatsupport
ODBC. The Python Database API used in the program is implemented by drivers for
many databases, but unlike with JDBC, there are minor differences in the API across
differentdrivers,inparticularintheparameterstotheconnect()function.
5.1.3 ODBC
The Open Database Connectivity (ODBC) standard defines an API that applications
canusetoopenaconnectionwithadatabase,sendqueriesandupdates,andgetback
results.Applicationssuchasgraphicaluserinterfaces,statisticspackages,andspread-
sheets can make use of the same ODBC API to connect to any database server that
supportsODBC.
Each database system supporting ODBC provides a library that must be linked
withtheclientprogram.WhentheclientprogrammakesanODBCAPIcall,thecode

--- Page 224 ---

5.1 AccessingSQLfromaProgrammingLanguage 195
void ODBCexample()
{
RETCODE error;
HENV env; /* environment */
HDBC conn; /* database connection */
SQLAllocEnv(&env);
SQLAllocConnect(env, &conn);
SQLConnect(conn, "db.yale.edu", SQL NTS, "avi", SQL NTS,
"avipasswd", SQL NTS);
{
char deptname[80];
float salary;
int lenOut1, lenOut2;
HSTMT stmt;
char * sqlquery = "select dept name, sum (salary)
from instructor
group by dept name";
SQLAllocStmt(conn, &stmt);
error = SQLExecDirect(stmt, sqlquery, SQL NTS);
if (error == SQL SUCCESS) {
SQLBindCol(stmt, 1, SQL C CHAR, deptname , 80, &lenOut1);
SQLBindCol(stmt, 2, SQL C FLOAT, &salary, 0 , &lenOut2);
while (SQLFetch(stmt) == SQL SUCCESS) {
printf (" %s %g∖n", deptname,salary);
}
}
SQLFreeStmt(stmt, SQL DROP);
}
SQLDisconnect(conn);
SQLFreeConnect(conn);
SQLFreeEnv(env);
}
Figure 5.5 ODBCcodeexample.
inthelibrarycommunicateswiththeservertocarryouttherequestedactionandfetch
results.
Figure5.5showsanexampleofCcodeusingtheODBCAPI.Thefirststepinusing
ODBCtocommunicatewithaserveristosetupaconnectionwiththeserver.Todoso,
the program first allocates an SQL environment, then a database connection handle.
ODBC defines the types HENV, HDBC, and RETCODE. The program then opens the

--- Page 225 ---

196 Chapter5 AdvancedSQL
databaseconnectionbyusingSQLConnect.Thiscalltakesseveralparameters,includ-
ingtheconnectionhandle,theservertowhichtoconnect,theuseridentifier,andthe
passwordforthedatabase.TheconstantSQL NTSdenotesthatthepreviousargument
isanull-terminatedstring.
Once the connection is set up, the program can send SQL commands to the
databasebyusingSQLExecDirect.Clanguagevariablescanbeboundtoattributesof
thequeryresult,sothatwhenaresulttupleisfetchedusingSQLFetch,itsattributeval-
uesarestoredincorrespondingCvariables.TheSQLBindColfunctiondoesthistask;
thesecondargumentidentifiesthepositionoftheattributeinthequeryresult,andthe
third argument indicatesthe type conversion required from SQL to C. The next argu-
mentgivestheaddressofthevariable. Forvariable-lengthtypes likecharacterarrays,
thelasttwoargumentsgivethemaximumlengthofthevariableandalocationwhere
theactuallengthistobestoredwhenatupleisfetched.Anegativevaluereturnedfor
the length field indicates that the value is null. For fixed-length types such as integer
or float, the maximum length field is ignored, while a negative value returned for the
lengthfieldindicatesanullvalue.
TheSQLFetchstatementisinawhileloopthatisexecuteduntilSQLFetchreturns
a value other than SQL SUCCESS. On each fetch, the program stores the values in C
variablesasspecifiedbythecallsonSQLBindColandprintsoutthesevalues.
At the end of the session, the program frees the statement handle, disconnects
fromthedatabase, andfreesuptheconnectionandSQLenvironmenthandles.Good
programming style requires that the result of every function call must be checked to
makesuretherearenoerrors;wehaveomittedmostofthesechecksforbrevity.
ItispossibletocreateanSQLstatementwithparameters;forexample,considerthe
statementinsertintodepartmentvalues(?,?,?).Thequestionmarksareplaceholders
forvalueswhichwillbesuppliedlater.Theabovestatementcanbe“prepared,”thatis,
compiled at the database, and repeatedly executed by providing actual values for the
placeholders—inthiscase, by providinga department name, building,and budget for
therelationdepartment.
ODBC defines functions for a variety of tasks, such as finding all the relations in
thedatabaseandfindingthenamesandtypesofcolumnsofaqueryresultorarelation
inthedatabase.
Bydefault,eachSQLstatementistreatedasaseparatetransactionthatiscommit-
ted automatically. The SQLSetConnectOption(conn, SQL AUTOCOMMIT, 0) turns
offautomaticcommitonconnectionconn,andtransactionsmustthenbecommitted
explicitlybySQLTransact(conn,SQL COMMIT)orrolledbackbySQLTransact(conn,
SQL ROLLBACK).
TheODBCstandarddefinesconformancelevels,whichspecifysubsetsofthefunc-
tionality defined by the standard. An ODBC implementation may provide only core
level features, or it may provide more advanced (level 1 or level 2) features. Level 1
requiressupportforfetchinginformationaboutthecatalog,suchasinformationabout
whatrelationsarepresentandthetypesoftheirattributes.Level2requiresfurtherfea-

--- Page 226 ---

5.1 AccessingSQLfromaProgrammingLanguage 197
tures,suchastheabilitytosendandretrievearraysofparametervaluesandtoretrieve
moredetailedcataloginformation.
The SQL standard defines a call level interface (CLI) that is similar to the ODBC
interface.
5.1.4 Embedded SQL
TheSQLstandarddefinesembeddingsofSQLinavarietyofprogramminglanguages,
such as C, C++, Cobol, Pascal, Java, PL/I, and Fortran. A language in which SQL
queries are embedded is referred to as a host language, and the SQL structures per-
mittedinthehostlanguageconstituteembeddedSQL.
ProgramswritteninthehostlanguagecanusetheembeddedSQLsyntaxtoaccess
andupdatedatastoredinadatabase. AnembeddedSQLprogrammustbeprocessed
by a special preprocessor prior to compilation. The preprocessor replaces embedded
SQL requests with host-language declarations and procedure calls that allow runtime
executionofthedatabaseaccesses.Thentheresultingprogramiscompiledbythehost-
language compiler.ThisisthemaindistinctionbetweenembeddedSQLandJDBCor
ODBC.
To identify embedded SQL requests to the preprocessor, we use the EXEC SQL
statement;ithastheform:
EXECSQL<embeddedSQLstatement>;
BeforeexecutinganySQLstatements,theprogrammustfirstconnecttothedatabase.
VariablesofthehostlanguagecanbeusedwithinembeddedSQLstatements,butthey
mustbeprecededbyacolon(:)todistinguishthemfromSQLvariables.
To iterate over the results of an embedded SQL query, we must declare a cursor
variable, which can then be opened, and fetch commands issued in a host language
loop to fetch consecutive rows of the query result. Attributes of a row can be fetched
into host language variables. Database updates can also be performed using a cursor
onarelationtoiteratethroughtherowsoftherelation,optionallyusingawhereclause
toiteratethroughonlyselectedrows.EmbeddedSQLcommandscanbeusedtoupdate
thecurrentrowwherethecursorispointing.
The exact syntax for embedded SQL requests depends on the language in which
SQL is embedded. You may refer to the manuals of the specific language embedding
thatyouuseforfurtherdetails.
InJDBC,SQLstatementsareinterpretedatruntime(eveniftheyarecreatedusing
thepreparedstatementfeature).WhenembeddedSQLisused,thereisapotentialfor
catching some SQL-related errors (including data-type errors) at the time of prepro-
cessing.SQL queriesinembeddedSQL programsare alsoeasiertocomprehendthan
inprogramsusingdynamicSQL.However,therearealsosomedisadvantageswithem-
beddedSQL.Thepreprocessorcreatesnewhostlanguagecode,whichmaycomplicate
debugging of the program. The constructs used by the preprocessor to identify SQL

--- Page 227 ---

198 Chapter5 AdvancedSQL
Note 5.1 EMBEDDEDDATABASES
Both JDBC and ODBC assume that a server is running on the database system
hostingthedatabase.Someapplicationsuseadatabasethatexistsentirelywithin
theapplication.Suchapplicationsmaintainthedatabaseonlyforinternaluseand
offernoaccessibilitytothedatabaseexceptthroughtheapplicationitself.Insuch
cases, one may use an embedded database and use one of several packages that
implementanSQLdatabaseaccessiblefromwithinaprogramminglanguage.Pop-
ularchoicesincludeJavaDB,SQLite,HSQLBD,and˝2.Thereisalsoanembedded
versionofMySQL.
Embedded database systems lack many of the features of full server-based
databasesystems,buttheyofferadvantagesforapplicationsthatcanbenefitfrom
thedatabaseabstractionsbutdonotneedtosupportverylargedatabasesorlarge-
scaletransactionprocessing.
DonotconfuseembeddeddatabaseswithembeddedSQL;thelatterisameans
ofconnectingtoadatabaserunningonaserver.
statementsmayclashsyntacticallywithhostlanguagesyntaxintroducedinsubsequent
versionsofthehostlanguage.
As a result, most current systems use dynamic SQL, rather than embedded SQL.
OneexceptionistheMicrosoftLanguage Integrated Query(LINQ)facility,whichex-
tendsthehostlanguagetoincludesupportforqueriesinsteadofusingapreprocessor
totranslateembeddedSQLqueriesintothehostlanguage.
5.2 Functions and Procedures
We have already seen several functions that are built into the SQL language. In this
section,weshowhowdeveloperscanwritetheirownfunctionsandprocedures,store
theminthedatabase, andtheninvokethemfromSQLstatements.Functionsarepar-
ticularlyuseful withspecializeddatatypessuch asimagesand geometricobjects. For
instance,aline-segmentdatatypeusedinamapdatabasemayhaveanassociatedfunc-
tionthatcheckswhethertwolinesegmentsoverlap,andanimagedatatypemayhave
associatedfunctionstocomparetwoimagesforsimilarity.
Proceduresandfunctionsallow“businesslogic”tobestoredinthedatabaseandex-
ecutedfromSQLstatements.Forexample,universitiesusuallyhavemanyrulesabout
how many courses a student can take in a given semester, the minimum number of
courses a full-time instructor must teach in a year, the maximum number of majors a
student can be enrolled in, and so on. While such business logic can be encoded as
programming-languageproceduresstoredentirelyoutsidethedatabase,definingthem
as stored procedures in the database has several advantages. For example, it allows

--- Page 228 ---

5.2 FunctionsandProcedures 199
createfunctiondept count(dept namevarchar(20))
returnsinteger
begin
declared countinteger;
selectcount(*)intod count
frominstructor
whereinstructor.dept name=dept name
returnd count;
end
Figure 5.6 FunctiondefinedinSQL.
multipleapplicationstoaccesstheprocedures,anditallowsasinglepointofchangein
casethebusinessruleschange,withoutchangingotherpartsoftheapplication.Appli-
cation code can then call the stored proceduresinstead of directlyupdating database
relations.
SQL allows the definition of functions, procedures, and methods. These can be
defined either by the procedural component of SQL or by an external programming
languagesuchasJava,C,orC++.WelookatdefinitionsinSQLfirstandthenseehow
tousedefinitionsinexternallanguagesinSection5.2.3.
Although the syntax we present here is defined by the SQL standard, most
databasesimplementnonstandardversionsofthissyntax.Forexample,theprocedural
languages supported by Oracle (PL/SQL), Microsoft SQL Server (TransactSQL), and
PostgreSQL(PL/pgSQL)alldifferfromthestandardsyntaxwepresenthere.Weillus-
trate some of the differencesfor the case of Oracle in Note 5.2 on page 204. See the
respectivesystemmanualsforfurtherdetails.Althoughpartsofthesyntaxwepresent
here may not be supported on such systems, the concepts we describe are applicable
acrossimplementations,althoughwithadifferentsyntax.
5.2.1 Declaring and Invoking SQL Functions and Procedures
Suppose that we want a function that, given the name of a department, returns the
countofthenumberofinstructorsinthatdepartment.Wecandefinethefunctionas
shown in Figure 5.6.4 This function can be used in a query that returns names and
budgetsofalldepartmentswithmorethan12instructors:
selectdept name,budget
fromdepartment
wheredept count(dept name)>12;
4Ifyouareenteringyourownfunctionsorprocedures,youshouldwrite“createorreplace”ratherthancreatesothatit
iseasytomodifyyourcode(byreplacingthefunction)duringdebugging.

--- Page 229 ---

200 Chapter5 AdvancedSQL
createfunctioninstructor of (dept namevarchar(20))
returnstable(
IDvarchar(5),
namevarchar(20),
dept namevarchar(20),
salarynumeric(8,2))
returntable
(selectID,name,dept name,salary
frominstructor
whereinstructor.dept name=instructor of.dept name);
Figure 5.7 TablefunctioninSQL.
Performance problems have been observed on many database systems when in-
vokingcomplexuser-definedfunctionswithinaquery,ifthefunctionsareinvokedon
alargenumberoftuples.Programmersshouldthereforetakeperformanceintoconsid-
erationwhendecidingwhethertouseuser-definedfunctionsinaquery.
The SQLstandard supports functionsthatcan returntablesas results;such func-
tionsarecalledtablefunctions.ConsiderthefunctiondefinedinFigure5.7.Thefunc-
tionreturnsatablecontainingalltheinstructorsofaparticulardepartment.Notethat
the function’s parameter is referenced by prefixing it with the name of the function
(instructor of.dept name).
Thefunctioncanbeusedinaqueryasfollows:
select*
fromtable(instructor of('Finance'));
This query returns all instructors of the 'Finance' department. In this simple case it
isstraightforward towritethisquerywithoutusingtable-valuedfunctions.Ingeneral,
however,table-valuedfunctionscanbethoughtofasparameterizedviewsthatgeneralize
theregularnotionofviewsbyallowingparameters.
SQLalsosupportsprocedures.Thedept countfunctioncouldinsteadbewrittenas
aprocedure:
createproceduredept count proc(indept namevarchar(20),
outd countinteger)
begin
selectcount(*)intod count
frominstructor
whereinstructor.dept name=dept count proc.dept name
end

--- Page 230 ---

5.2 FunctionsandProcedures 201
The keywords in and out indicate, respectively, parameters that are expected to
havevaluesassignedtothemandparameterswhosevaluesaresetintheprocedurein
ordertoreturnresults.
ProcedurescanbeinvokedeitherfromanSQLprocedureorfromembeddedSQL
bythecallstatement:
declared countinteger;
calldept count proc('Physics',d count);
ProceduresandfunctionscanbeinvokedfromdynamicSQL,asillustratedbytheJDBC
syntaxinSection5.1.1.5.
SQLpermitsmorethanoneprocedureofthesamename,solongasthenumberof
argumentsoftheprocedureswiththesamenameisdifferent.Thename,alongwiththe
number of arguments, is used to identify the procedure. SQL also permits more than
onefunctionwiththesamename,solongasthedifferentfunctionswiththesamename
eitherhavedifferentnumbersofarguments,orforfunctionswiththesamenumberof
arguments,theydifferinthetypeofatleastoneargument.
5.2.2 Language Constructs for Procedures and Functions
SQLsupportsconstructsthatgiveitalmostallthepowerofageneral-purposeprogram-
minglanguage.ThepartoftheSQLstandardthatdealswiththeseconstructsiscalled
thePersistentStorageModule(PSM).
VariablesaredeclaredusingadeclarestatementandcanhaveanyvalidSQLdata
type.Assignmentsareperformedusingasetstatement.
A compound statement is of the form begin … end, and it may contain multiple
SQLstatementsbetweenthebeginandtheend.Localvariablescanbedeclaredwithin
a compound statement, as we have seen in Section 5.2.1. A compound statement of
the form begin atomic … end ensures that all the statements contained within it are
executedasasingletransaction.
Thesyntaxforwhilestatementsandrepeatstatementsis:
whilebooleanexpressiondo
sequenceofstatements;
endwhile
repeat
sequenceofstatements;
untilbooleanexpression
endrepeat
Thereisalsoaforloopthatpermitsiterationoveralltheresultsofaquery:

--- Page 231 ---

202 Chapter5 AdvancedSQL
declarenintegerdefault0;
forr as
selectbudgetfromdepartment
wheredept name=‘Music‘
do
setn =n−r.budget
endfor
Theprogramfetchesthequeryresultsonerowatatimeintotheforloopvariable(r,in
theaboveexample).Thestatementleavecanbeusedtoexittheloop,whileiteratestarts
onthenexttuple,fromthebeginningoftheloop,skippingtheremainingstatements.
The conditional statements supported by SQL include if-then-else statements by
usingthissyntax:
ifbooleanexpression
thenstatementorcompoundstatement
elseifbooleanexpression
thenstatementorcompoundstatement
elsestatementorcompoundstatement
endif
SQLalsosupportsacasestatementsimilartotheC/C++languagecasestatement
(inadditiontocaseexpressions,whichwesawinChapter3).
Figure 5.8 provides a larger example of the use of procedural constructs in SQL.
ThefunctionregisterStudentdefinedinthefigureregistersastudentinacoursesection
afterverifyingthatthenumberofstudentsinthesectiondoesnotexceedthecapacityof
theroomallocatedtothesection.Thefunctionreturnsanerrorcode—avaluegreater
thanorequalto0signifiessuccess,andanegativevaluesignifiesanerrorcondition—
andamessageindicatingthereasonforthefailureisreturnedasanoutparameter.
The SQL procedural language also supports the signaling of exception conditions
anddeclaringofhandlersthatcanhandletheexception,asinthiscode:
declareout of classroom seatscondition
declareexithandlerforout of classroom seats
begin
sequenceofstatements
end
Thestatementsbetweenthebeginandtheendcanraiseanexceptionbyexecutingsig-
nal out of classroom seats. The handler says that if the condition arises, the action to
betakenistoexittheenclosingbeginendstatement.Alternativeactionswouldbecon-
tinue,whichcontinuesexecutionfromthenextstatementfollowingtheonethatraised
the exception. In addition to explicitly defined conditions, there are also predefined
conditionssuchassqlexception,sqlwarning,andnotfound.

--- Page 232 ---

5.2 FunctionsandProcedures 203
––Registersastudentafterensuringclassroomcapacityisnotexceeded
––Returns0onsuccess,and-1ifcapacityisexceeded.
createfunctionregisterStudent(
ins id varchar(5),
ins courseid varchar(8),
ins secid varchar(8),
ins semester varchar(6),
ins year numeric(4,0),
outerrorMsgvarchar(100)
returnsinteger
begin
declarecurrEnrol int;
selectcount(*)intocurrEnrol
fromtakes
wherecourse id =s courseid andsec id =s secid
andsemester =s semester andyear =s year;
declarelimit int;
selectcapacityintolimit
fromclassroomnaturaljoinsection
wherecourse id =s courseid andsec id =s secid
andsemester =s semester andyear =s year;
if(currEnrol <limit)
begin
insertintotakesvalues
(s id,s courseid,s secid,s semester,s year,null);
return(0);
end
––Otherwise,sectioncapacitylimitalreadyreached
seterrorMsg =’Enrollmentlimitreachedforcourse’||s courseid
||’section’||s secid;
return(-1);
end;
Figure 5.8 Proceduretoregisterastudentforacoursesection.
5.2.3 External Language Routines
AlthoughtheproceduralextensionstoSQLcanbeveryuseful,theyareunfortunately
not supported in a standard way across databases. Even the most basic features have
differentsyntaxorsemanticsindifferentdatabaseproducts.Asaresult,programmers
havetolearnanewlanguageforeachdatabaseproduct.Analternativethatisgaining

--- Page 233 ---

204 Chapter5 AdvancedSQL
Note 5.2 NONSTANDARDSYNTAXFORPROCEDURESANDFUNCTIONS
AlthoughtheSQLstandarddefinesthesyntaxforproceduresandfunctions,most
databasesdonotfollowthestandardstrictly,andthereisconsiderablevariationin
thesyntaxsupported.Oneofthereasonsforthissituationisthatthesedatabases
typically introduced support for procedures and functions before the syntax was
standardized, and they continue to support their original syntax. It is not possi-
ble to list the syntax supported by each database here, but we illustrate a few of
the differencesin thecase of Oracle’s PL/SQLbyshowing below aversion of the
functionfromFigure5.6asitwouldbedefinedinPL/SQL.
createfunctiondept count(dnameininstructor.dept name%type)returninteger
as
d countinteger;
begin
selectcount(*)intod count
frominstructor
whereinstructor.dept name=dname;
returnd count;
end;
While the two versions are similar in concept, there are a number of minor syn-
tacticdifferences,someofwhichareevidentwhencomparingthetwoversionsof
thefunction.Althoughnotshownhere,thesyntaxforcontrolflowinPL/SQLalso
hasseveraldifferencesfromthesyntaxpresentedhere.
ObservethatPL/SQLallowsatypetobespecifiedasthetypeofanattributeof
arelation,byaddingthesuffix%type.Ontheotherhand,PL/SQLdoesnotdirectly
supporttheabilitytoreturnatable,althoughthereisanindirectwayofimplement-
ingthisfunctionalitybycreatingatabletype.Theprocedurallanguagessupported
byotherdatabasesalsohaveanumberofsyntacticandsemanticdifferences.See
therespectivelanguage referencesformoreinformation.Theuse ofnonstandard
syntax forstored proceduresand functionsisan impedimenttoporting an appli-
cationtoadifferentdatabase.
supportistodefineproceduresinanimperativeprogramminglanguage,butallowthem
tobeinvokedfromSQLqueriesandtriggerdefinitions.
SQLallowsustodefinefunctionsinaprogramminglanguagesuchasJava,C#,C,
orC++.Functionsdefinedinthisfashioncanbemoreefficientthanfunctionsdefined
inSQL,andcomputationsthatcannotbecarriedoutinSQLcanbeexecutedbythese
functions.

--- Page 234 ---

5.2 FunctionsandProcedures 205
Externalproceduresandfunctionscanbespecifiedinthisway(notethattheexact
syntaxdependsonthespecificdatabasesystemyouuse):
createproceduredeptcount proc(indept namevarchar(20),
outcountinteger)
languageC
externalname'/usr/avi/bin/dept count proc'
createfunctiondeptcount(dept namevarchar(20))
returnsinteger
languageC
externalname'/usr/avi/bin/dept count'
Ingeneral,theexternallanguageproceduresneedtodealwithnullvaluesinparameters
(both in and out) and return values. They also need to communicate failure/success
status and to deal with exceptions. This information can be communicated by extra
parameters:ansqlstatevaluetoindicatefailure/successstatus,aparametertostorethe
returnvalueofthefunction,andindicatorvariablesforeachparameter/functionresult
to indicate if the value is null. Other mechanisms are possible to handle null values,
for example, by passing pointers instead of values. The exact mechanisms depend on
the database. However, ifa function does not deal with these situations, an extra line
parameter style general can be added to the declaration to indicate that the external
procedures/functionstakeonlytheargumentsshownanddonothandlenullvaluesor
exceptions.
Functionsdefinedinaprogramminglanguageandcompiledoutsidethedatabase
system may be loaded and executed with the database-system code. However, doing
so carries the risk that a bug in the program can corrupt the internal structures of
the database and can bypass the access-control functionality of the database system.
Databasesystemsthatareconcernedmoreaboutefficientperformancethanaboutse-
curitymayexecuteproceduresinsuchafashion.Databasesystemsthatareconcerned
aboutsecuritymayexecutesuchcodeaspartofaseparateprocess,communicatethe
parameter values to it, and fetch results back via interprocess communication. How-
ever, the time overhead of interprocess communication is quite high; on typical CPU
architectures, tens to hundreds of thousands of instructions can execute in the time
takenforoneinterprocesscommunication.
If the code is written in a “safe” language such as Java or C#, there is another
possibility:executingthecodeinasandboxwithinthedatabasequeryexecutionprocess
itself. The sandbox allows the Java or C# code to access its own memory area, but it
preventsthecodefromreadingorupdatingthememoryofthequeryexecutionprocess,
oraccessingfilesinthefilesystem.(Creatingasandboxisnotpossibleforalanguage
such as C, which allows unrestricted access to memory through pointers.) Avoiding
interprocesscommunicationreducesfunctioncalloverheadgreatly.

--- Page 235 ---

206 Chapter5 AdvancedSQL
Several database systems today support external language routines running in a
sandboxwithinthequeryexecutionprocess.Forexample,OracleandIBMDB2allow
Java functions to run as part of the database process. Microsoft SQL Server allows
procedures compiled into the Common Language Runtime (CLR) to execute within
thedatabaseprocess;suchprocedurescouldhavebeenwritten,forexample,inC#or
Visual Basic. PostgreSQL allows functions defined in several languages, such as Perl,
Python,andTcl.
5.3 Triggers
A trigger is a statement that the system executes automatically as a side effect of a
modificationtothedatabase.Todefineatrigger,wemust:
• Specifywhenatriggeristobeexecuted.Thisisbrokenupintoaneventthatcauses
thetriggertobecheckedandaconditionthatmustbesatisfiedfortriggerexecution
toproceed.
• Specifytheactionstobetakenwhenthetriggerexecutes.
Onceweenteratriggerintothedatabase,thedatabasesystemtakesontheresponsibil-
ityofexecutingitwheneverthespecifiedeventoccursandthecorrespondingcondition
issatisfied.
5.3.1 Need for Triggers
Triggers can be used to implement certain integrity constraints that cannot be speci-
fied using the constraint mechanism of SQL. Triggers are also useful mechanisms for
alertinghumansorforstartingcertaintasksautomaticallywhencertainconditionsare
met.Asanillustration,wecoulddesignatriggerthat,wheneveratupleisinsertedinto
the takes relation, updates the tuple in the student relation for the student taking the
coursebyaddingthenumberofcreditsforthecoursetothestudent’stotalcredits.As
another example, suppose a warehouse wishes to maintain a minimum inventory of
eachitem;whentheinventorylevelofanitemfallsbelowtheminimumlevel,anorder
canbeplacedautomatically.Onanupdateoftheinventorylevelofanitem,thetrigger
compares the current inventory level with the minimum inventory level for the item,
andifthelevelisatorbelowtheminimum,aneworderiscreated.
Notethattriggerscannotusuallyperformupdatesoutsidethedatabase,andhence,
intheinventoryreplenishmentexample,wecannotuseatriggertoplaceanorderinthe
externalworld.Instead,weaddanordertoarelationholdingreorders.Wemustcreate
a separate permanently running system process that periodically scans that relation
and places orders. Some database systems provide built-in support for sending email
fromSQLqueriesandtriggersusingthisapproach.

--- Page 236 ---

5.3 Triggers 207
createtriggertimeslot check1afterinsertonsection
referencingnewrowasnrow
foreachrow
when(nrow.time slot id notin(
selecttime slot id
fromtime slot))/*time slot id notpresentintime slot*/
begin
rollback
end;
createtriggertimeslot check2afterdeleteontimeslot
referencingoldrowasorow
foreachrow
when(orow.time slot id notin(
selecttime slot id
fromtime slot)/*lasttuplefortime slot id deletedfromtime slot*/
andorow.time slot id in(
selecttime slot id
fromsection))/*andtime slot id stillreferencedfromsection*/
begin
rollback
end;
Figure 5.9 Usingtriggerstomaintainreferentialintegrity.
5.3.2 Triggers in SQL
WenowconsiderhowtoimplementtriggersinSQL.Thesyntaxwepresenthereisde-
finedbytheSQLstandard,butmostdatabasesimplementnonstandardversionsofthis
syntax. Although the syntax we present here may not be supported on such systems,
theconceptswedescribeareapplicableacrossimplementations.Wediscussnonstan-
dard trigger implementations in Note 5.3 on page 212. In each system, trigger syntax
isbaseduponthatsystem’ssyntaxforcodingfunctionsandprocedures.
Figure5.9showshowtriggerscanbeusedtoensurereferentialintegrityonthetime
slot idattributeofthesectionrelation.Thefirsttriggerdefinitioninthefigurespecifies
thatthetriggerisinitiatedafteranyinsertontherelationsection anditensuresthatthe
time slot id valuebeinginsertedisvalid.SQLbfinsertstatementcouldinsertmultiple
tuplesoftherelation,andtheforeachrowclauseinthetriggercodewouldthenexplic-
itlyiterateovereachinsertedrow.Thereferencingnewrowasclausecreatesavariable
nrow(calledatransitionvariable)thatstoresthevalueoftherowbeinginserted.

--- Page 237 ---

208 Chapter5 AdvancedSQL
Thewhenstatementspecifiesacondition.Thesystemexecutestherestofthetrig-
gerbodyonlyfortuplesthatsatisfythecondition.Thebeginatomic…endclausecan
servetocollectmultipleSQLstatementsintoasinglecompoundstatement.Inourex-
ample,though,thereisonlyonestatement,whichrollsbackthetransactionthatcaused
thetriggertogetexecuted.Thus,anytransactionthatviolatesthereferentialintegrity
constraintgetsrolledback,ensuringthedatainthedatabasesatisfiestheconstraint.
It is not sufficient to check referential integrity on inserts alone; we also need to
considerupdatesofsection,aswellasdeletesandupdatestothereferencedtabletime
slot. The second trigger definition in Figure 5.9 considers the case of deletes to time
slot. This trigger checks that the time slot id of the tuple being deleted is either still
presentintime slot,orthatnotupleinsectioncontainsthatparticulartime slot idvalue;
otherwise,referentialintegritywouldbeviolated.
Toensurereferentialintegrity,wewouldalsohavetocreatetriggerstohandleup-
datestosectionandtime slot;wedescribenexthowtriggerscanbeexecutedonupdates,
butweleavethedefinitionofthesetriggersasanexercisetothereader.
For updates, the trigger can specify attributes whose update causes the trigger to
execute;updatestootherattributeswouldnotcauseittobeexecuted.Forexample,to
specifythatatriggerexecutesafteranupdatetothegradeattributeofthetakesrelation,
wewrite:
afterupdateoftakesongrade
The referencing old row as clause can be used to create a variable storing the old
valueofanupdatedordeletedrow.Thereferencingnewrowasclausecanbeusedwith
updatesinadditiontoinserts.
Figure5.10showshowatriggercanbeusedtokeepthetot cred attributevalueof
student tuples up-to-date when the grade attribute is updated for a tuple in the takes
relation.Thetriggerisexecutedonlywhenthegradeattributeisupdatedfromavalue
thatiseithernullor’F’toagradethatindicatesthecourseissuccessfullycompleted.
TheupdatestatementisnormalSQLsyntaxexceptfortheuseofthevariablenrow.
A more realistic implementation of this example trigger would also handle grade
corrections that change a successful completion grade to a failing grade and handle
insertionsintothetakesrelationwherethegradeindicatessuccessfulcompletion.We
leavetheseasanexerciseforthereader.
As anotherexample of the use of a trigger, the action on delete of a student tuple
couldbetocheckifthestudenthasanyentriesinthetakesrelation,andifso,todelete
them.
Manydatabasesystemssupportavarietyofothertriggeringevents,suchaswhen
a user (application) logs on to the database (that is, opens a connection), the system
shutsdown,orchangesaremadetosystemsettings.
Triggerscanbeactivatedbeforetheevent(insert,delete,orupdate)insteadofafter
theevent.Triggersthatexecutebeforeaneventcanserveasextraconstraintsthatcan
preventinvalidupdates,inserts,ordeletes.Insteadoflettingtheinvalidactionproceed

--- Page 238 ---

5.3 Triggers 209
createtriggercredits earned afterupdateoftakesongrade
referencingnewrowasnrow
referencingoldrowasorow
foreachrow
whennrow.grade<>’F’andnrow.gradeisnotnull
and(orow.grade=’F’ororow.gradeisnull)
beginatomic
updatestudent
settot cred=tot cred+
(selectcredits
fromcourse
wherecourse.course id=nrow.courseid)
wherestudent.id=nrow.id;
end;
Figure 5.10 Usingatriggertomaintaincreditsearned values.
and cause an error, the trigger might take action to correct the problem so that the
update,insert,ordeletebecomesvalid.Forexample,ifweattempttoinsertaninstructor
intoadepartmentwhosenamedoesnotappearinthedepartmentrelation,thetrigger
could insertatuple intothedepartmentrelation forthatdepartmentname before the
insertiongeneratesaforeign-keyviolation.Asanotherexample,supposethevalueofan
insertedgradeisblank,presumablytoindicatetheabsenceofagrade.Wecandefine
a trigger that replaces the value with the null value. The set statement can be used to
carryoutsuchmodifications.AnexampleofsuchatriggerappearsinFigure5.11.
Instead of carryingout an action for each affected row,we can carryout a single
action for the entire SQL statement that caused the insert, delete, or update. To do
so,weusetheforeachstatementclauseinsteadoftheforeachrowclause.Theclauses
createtriggersetnull beforeupdateoftakes
referencingnewrowasnrow
foreachrow
when(nrow.grade=’’)
beginatomic
setnrow.grade=null;
end;
Figure 5.11 Exampleofusingsettochange aninsertedvalue.

--- Page 239 ---

210 Chapter5 AdvancedSQL
referencingoldtableasorreferencingnewtableascanthenbeusedtorefertotemporary
tables(calledtransitiontables)containingalltheaffectedrows.Transitiontablescannot
be used with before triggers, but they can be used with after triggers, regardless of
whether they are statement triggers or row triggers. A single SQL statement can then
beusedtocarryoutmultipleactionsonthebasisofthetransitiontables.
Triggers can be disabled or enabled; by default they are enabled when they are
created, but they can be disabled by using alter trigger trigger name disable (some
databases use alternative syntax such as disable trigger trigger name). A trigger that
has been disabled can be enabled again. A trigger can instead be dropped, which re-
movesitpermanently,byusingthecommanddroptriggertrigger name.
Returningtoourinventory-replenishmentexamplefromSection5.3.1,supposewe
havethefollowingrelations:
• inventory (item, level), which notes the current amount of the item in the ware-
house.
• minlevel (item, level), which notes the minimum amount of the item to be main-
tained.
• reorder(item,amount),whichnotestheamountoftheitemtobeorderedwhenits
levelfallsbelowtheminimum.
• orders(item,amount),whichnotestheamountoftheitemtobeordered.
To place a reorder when inventory falls below a specified minimum, we can use the
trigger shown in Figure 5.12. Note that we have been careful to place an order only
when the amount fallsfrom above the minimumlevelto below the minimumlevel.If
wecheckonlythatthenewvalueafteranupdateisbelowtheminimumlevel,wemay
placeanordererroneouslywhentheitemhasalreadybeenreordered.
SQL-based database systems use triggers widely, although before SQL:1999 they
were not part of the SQL standard. Unfortunately, as a result, each database system
implemented its own syntax for triggers, leading to incompatibilities. The SQL:1999
syntax for triggers that we use here is similar, but not identical, to the syntax in the
IBMDB2andOracledatabasesystems.SeeNote5.3onpage212.
5.3.3 When Not to Use Triggers
Therearemanygoodusesfortriggers,suchasthosewehavejustseeninSection5.3.2,
butsomeusesarebesthandledbyalternativetechniques.Forexample,wecouldimple-
menttheondeletecascadefeatureofaforeign-keyconstraintbyusingatriggerinstead
of using the cascade feature. Not only would this be more work to implement, but
also itwould be much harderfor adatabase user tounderstand the set of constraints
implementedinthedatabase.

--- Page 240 ---

5.3 Triggers 211
createtriggerreorder afterupdateoflevel oninventory
referencingoldrowasorow,newrowasnrow
foreachrow
whennrow.level <=(selectlevel
fromminlevel
whereminlevel.item=orow.item)
andorow.level >(selectlevel
fromminlevel
whereminlevel.item=orow.item)
beginatomic
insertintoorders
(selectitem,amount
fromreorder
wherereorder.item = orow.item);
end;
Figure 5.12 Exampleoftriggerforreorderinganitem.
As another example, triggers can be used to maintain materialized views. For in-
stance, if we wished to support very fast access to the total number of students regis-
teredforeachcoursesection,wecoulddothisbycreatingarelation
section registration(course id,sec id,semester,year,totalstudents)
definedbythequery
selectcourse id,sec id,semester,year,count(ID)astotal students
fromtakes
groupbycourse id,sec id,semester,year;
The value of total students for each course must be maintained up-to-date by triggers
oninsert,delete,orupdateofthetakesrelation.Suchmaintenancemayrequireinser-
tion,updateordeletionoftuplesfromsection registration,andtriggersmustbewritten
accordingly.
However,manydatabasesystemsnowsupportmaterializedviews,whichareauto-
matically maintained by the database system (see Section 4.2.3). As a result, there is
noneedtowritetriggercodeformaintainingsuchmaterializedviews.
Triggershavebeenusedformaintainingcopies,orreplicas,ofdatabases.Acollec-
tion of triggers on insert, delete, or update can be created on each relation to record
thechangesinrelationscalledchangeordeltarelations.Aseparateprocesscopiesover
thechangestothereplicaofthedatabase.Moderndatabasesystems,however,provide

--- Page 241 ---

212 Chapter5 AdvancedSQL
Note 5.3 NONSTANDARDTRIGGERSYNTAX
Although the trigger syntax we describe here is part of the SQL standard, and
is supported by IBM DB2, most other database systems have nonstandard syntax
for specifying triggers and may not implement all features in the SQL standard.
We outline a few of the differences below; see the respective system manuals for
furtherdetails.
Forexample,intheOraclesyntax,unliketheSQLstandardsyntax,thekeyword
row does not appear in the referencing statement. The keyword atomic does not
appear after begin. The reference to nrow in the select statement nested in the
updatestatementmustbeginwithacolon(:)toinformthesystemthatthevariable
nrow is defined externally from the SQL statement. Further, subqueries are not
allowed in the when and if clauses. It is possible to work around this problem by
movingcomplexpredicatesfromthewhenclauseintoaseparatequerythatsaves
theresultintoalocalvariable,andthenreferencethatvariableinanifclause,and
thebodyofthetriggerthenmovesintothecorrespondingthenclause.Further,in
Oracle,triggersarenotallowedtoexecuteatransactionrollbackdirectly;however,
they can instead use a function called raise application error to not only roll
backthetransactionbutalsoreturnanerrormessagetotheuser/applicationthat
performedtheupdate.
Asanotherexample, inMicrosoftSQLServerthekeyword on isused instead
ofafter.Thereferencingclauseisomitted,andoldandnewrowsarereferencedby
thetuplevariablesdeletedandinserted.Further,theforeachrowclauseisomitted,
andwhenisreplacedbyif.Thebeforespecificationisnotsupported,butaninstead
ofspecificationissupported.
InPostgreSQL,triggersdonothaveabody,butinsteadinvokeaprocedurefor
eachrow,whichcanaccessvariablesnewandoldcontainingtheoldandnewvalues
oftherow.Insteadofperformingarollback,thetriggercanraiseanexceptionwith
anassociatederrormessage.
built-in facilities for database replication, making triggers unnecessary for replication
inmostcases.ReplicateddatabasesarediscussedindetailinChapter23.
Anotherproblemwithtriggersliesinunintendedexecutionofthetriggeredaction
when data are loaded from a backup copy,5 or when database updates at a site are
replicated on a backup site. In such cases, the triggered action has already been exe-
cuted,andtypicallyitshouldnotbeexecutedagain.Whenloadingdata,triggerscanbe
disabledexplicitly.Forbackupreplicasystemsthatmayhavetotakeoverfromthepri-
marysystem,triggerswouldhavetobedisabledinitiallyandenabledwhenthebackup
5WediscussdatabasebackupandrecoveryfromfailuresindetailinChapter19.

--- Page 242 ---

5.4 RecursiveQueries 213
course id prereq id
BIO-301 BIO-101
BIO-399 BIO-101
CS-190 CS-101
CS-315 CS-190
CS-319 CS-101
CS-319 CS-315
CS-347 CS-319
Figure 5.13 Aninstanceoftheprereq relation.
site takes over processing from the primary system. As an alternative, some database
systemsallowtriggerstobespecifiedasnotforreplication,whichensuresthattheyare
not executed on the backup site during database replication. Other database systems
provideasystemvariablethatdenotesthatthedatabaseisareplicaonwhichdatabase
actions are being replayed; the trigger body should checkthisvariable and exit if itis
true.Bothsolutionsremovetheneedforexplicitdisablingandenablingoftriggers.
Triggersshouldbewrittenwithgreatcare,sinceatriggererrordetectedatruntime
causes the failure of the action statement that set off the trigger. Furthermore, the
actionofonetriggercansetoffanothertrigger.Intheworstcase,thiscouldevenlead
toan infinitechainof triggering. Forexample, suppose an insert triggeron arelation
hasanactionthatcausesanother(new)insertonthesamerelation.Theinsertaction
thentriggersyetanotherinsertaction,andsoonadinfinitum.Somedatabasesystems
limitthelengthofsuchchainsoftriggers(forexample,to16or32)andconsiderlonger
chains of triggering an error. Other systems flag as an error any trigger that attempts
to reference the relation whose modification caused the trigger to execute in the first
place.
Triggers can serve a very useful purpose, but they are best avoided when alterna-
tives exist. Many trigger applications can be substituted by appropriate use of stored
procedures,whichwediscussedinSection5.2.
5.4 Recursive Queries
ConsidertheinstanceoftherelationprereqshowninFigure5.13containinginforma-
tion about the various courses offered at the university and the prerequisite for each
course.6
Supposenowthatwewanttofindoutwhichcoursesareaprerequisitewhetherdi-
rectlyorindirectly,foraspecificcourse—say,CS-347.Thatis,wewishtofindacourse
6Thisinstanceofprereqdiffersfromthatusedearlierforreasonsthatwillbecomeapparentasweuseittoexplain
recursivequeries.

--- Page 243 ---

214 Chapter5 AdvancedSQL
thatisadirectprerequisiteforCS-347,orisaprerequisiteforacoursethatisaprereq-
uisiteforCS-347,andsoon.
Thus, since CS-319 is a prerequisite for CS-347 and CS-315 and CS-101 are pre-
requisitesforCS-319,CS-315andCS-101arealsoprerequisites(indirectly)forCS-347.
Then,sinceCS-190isaprerequisiteforCS-315,CS-190isanotherindirectprerequisite
forCS-347. Continuing,weseethatCS-101isaprerequisiteforCS-190,butnotethat
CS-101 was already added to the list of prerequisites for CS-347. In a real university,
rather than our example, we would not expect such a complex prerequisite structure,
butthisexampleservestoshowsomeofthesituationsthatmightpossiblyarise.
Thetransitiveclosureoftherelationprereqisarelationthatcontainsallpairs(cid,
pre) such that pre is a direct or indirect prerequisite of cid. There are numerous ap-
plications that require computation of similar transitive closures on hierarchies. For
instance, organizations typically consist of several levels of organizational units. Ma-
chines consist of parts that in turn have subparts, and so on; for example, a bicycle
may have subparts such as wheels and pedals, which in turn have subparts such as
tires,rims,and spokes. Transitiveclosurecan be usedon such hierarchiestofind,for
example,allpartsinabicycle.
5.4.1 Transitive Closure Using Iteration
One wayto writethe precedingqueryisto use iteration: Firstfindthose coursesthat
areadirectprerequisiteofCS-347,thenthosecoursesthatareaprerequisiteofallthe
coursesunderthefirstset,andsoon.Thisiterativeprocesscontinuesuntilwereachan
iterationwherenocoursesareadded.Figure5.14showsafunctionfindAllPrereqs(cid)
tocarryoutthistask;thefunctiontakesthecourse idofthecourseasaparameter(cid),
computesthesetofalldirectandindirectprerequisitesofthatcourse,andreturnsthe
set.
Theprocedureusesthreetemporarytables:
• c prereq:storesthesetoftuplestobereturned.
• new c prereq:storesthecoursesfoundinthepreviousiteration.
• temp:usedastemporarystoragewhilesetsofcoursesaremanipulated.
NotethatSQLallowsthecreationoftemporarytablesusingthecommandcreatetem-
porarytable; such tablesareavailableonlywithinthetransaction executingthequery
and are dropped when the transaction finishes. Moreover, if two instances of findAll-
Prereqsrunconcurrently,eachgetsitsowncopyofthetemporarytables;iftheyshared
acopy,theirresultcouldbeincorrect.
Theprocedureinsertsalldirectprerequisitesofcoursecidintonew c prereqbefore
therepeatloop.Therepeatloopfirstaddsallcoursesinnew c prereqtoc prereq.Next,
it computes prerequisites of all those courses in new c prereq, except those that have
already been found to be prerequisites of cid, and stores them in the temporary table

--- Page 244 ---

5.4 RecursiveQueries 215
createfunctionfindAllPrereqs(cid varchar(8))
––Findsallcoursesthatareprerequisite(directlyorindirectly)forcid
returnstable(course id varchar(8))
––Therelationprereq(course id,prereq id)specifieswhichcourseis
––directlyaprerequisiteforanothercourse.
begin
createtemporarytablec prereq(course id varchar(8));
––tablec prereqstoresthesetofcoursestobereturned
createtemporarytablenew c prereq(course id varchar(8));
––tablenew c prereqcontainscoursesfoundinthepreviousiteration
createtemporarytabletemp(course id varchar(8));
––tabletempisusedtostoreintermediateresults
insertintonew c prereq
selectprereq id
fromprereq
wherecourse id =cid;
repeat
insertintoc prereq
selectcourse id
fromnew c prereq;
insertintotemp
(selectprereq.prereq id
fromnew c prereq,prereq
wherenew c prereq.course id =prereq.course id
)
except(
selectcourse id
fromc prereq
);
deletefromnew c prereq;
insertintonew c prereq
select*
fromtemp;
deletefromtemp;
untilnotexists(select*fromnew c prereq)
endrepeat;
returntablec prereq;
end
Figure 5.14 Findingallprerequisitesofacourse.

--- Page 245 ---

216 Chapter5 AdvancedSQL
IterationNumber Tuplesinc1
0
1 (CS-319)
2 (CS-319),(CS-315),(CS-101)
3 (CS-319),(CS-315),(CS-101),(CS-190)
4 (CS-319),(CS-315),(CS-101),(CS-190)
5 done
Figure 5.15 PrerequisitesofCS-347initerationsoffunctionfindAllPrereqs.
temp. Finally, it replaces the contents of new c prereq with the contents of temp. The
repeatloopterminateswhenitfindsnonew(indirect)prerequisites.
Figure5.15showstheprerequisitesthatarefoundineachiterationwhentheproce-
dureiscalledforCS-347.Whilec prereqcouldhavebeenupdatedinoneSQLstatement,
weneed firstto construct new c prereq so wecan tellwhen nothingisbeingaddedin
the(final)iteration.
The use of the exceptclause inthe function ensures thatthe function works even
in the (abnormal) case where there is a cycle of prerequisites. For example, if a is a
prerequisiteforb,bisaprerequisiteforc,andcisaprerequisitefora,thereisacycle.
Whilecyclesmaybeunrealisticincourseprerequisites,cyclesarepossibleinother
applications.Forinstance,supposewehavearelationflights(to,from)thatsayswhich
cities can be reached from which other cities by a direct flight. We can write code
similar to that in the findAllPrereqs function, to find all cities that are reachable by a
sequenceofoneormoreflightsfromagivencity.Allwehavetodoistoreplaceprereq
withflightandreplaceattributenamescorrespondingly.Inthissituation,therecanbe
cycles of reachability, but the function would work correctly since it would eliminate
citiesthathavealreadybeenseen.
5.4.2 Recursion in SQL
Itisratherinconvenienttospecifytransitive closureusing iteration.Thereisan alter-
nativeapproach,usingrecursiveviewdefinitions,thatiseasiertouse.
We can use recursion to define the set of courses that are prerequisites of a par-
ticular course, say CS-347, as follows. The courses that are prerequisites (directly or
indirectly)ofCS-347are:
• CoursesthatareprerequisitesforCS-347.
• Coursesthatareprerequisitesforthosecoursesthatareprerequisites(directlyor
indirectly)forCS-347.
Notethatcase2isrecursive,sinceitdefinesthesetofcoursesthatareprerequisitesof
CS-347intermsofthesetofcoursesthatareprerequisitesofCS-347.Otherexamples

--- Page 246 ---

5.4 RecursiveQueries 217
withrecursiverec prereq(course id,prereq id)as(
selectcourse id,prereq id
fromprereq
union
selectrec prereq.course id,prereq.prereq id
fromrec prereq,prereq
whererec prereq.prereq id =prereq.course id
)
select∗
fromrec prereq;
Figure 5.16 RecursivequeryinSQL.
oftransitiveclosure,suchasfindingallsubparts(directorindirect)ofagivenpartcan
alsobedefinedinasimilarmanner,recursively.
The SQL standard supports a limited form of recursion, using the with recursive
clause, where a view (or temporary view) is expressed in terms of itself. Recursive
queries can be used, for example, to express transitive closure concisely. Recall that
the with clause is used to define a temporary view whose definition is available only
tothequeryinwhichitisdefined.Theadditionalkeywordrecursivespecifiesthatthe
viewisrecursive.7
Forexample,wecanfindeverypair(cid,pre)suchthatpreisdirectlyorindirectly
aprerequisiteforcoursecid,usingtherecursiveSQLviewshowninFigure5.16.
Anyrecursiveviewmustbedefinedastheunion8 oftwosubqueries:abasequery
thatisnonrecursiveandarecursivequery thatusestherecursiveview.Intheexample
inFigure5.16,thebasequeryistheselectonprereqwhiletherecursivequerycomputes
thejoinofprereqandrec prereq.
The meaningof a recursive view is best understood as follows: Firstcompute the
base query and add all the resultant tuples to the recursively defined view relation
rec prereq(whichisinitiallyempty).Nextcomputetherecursivequeryusingthecurrent
contentsoftheviewrelation,andaddalltheresultingtuplesbacktotheviewrelation.
Keeprepeatingtheabovestepuntilnonewtuplesareaddedtotheviewrelation.The
resultant view relation instance is calleda fixed point of the recursive view definition.
(Theterm“fixed”referstothefactthatthereisnofurtherchange.)Theviewrelation
isthusdefinedtocontainexactlythetuplesinthefixed-pointinstance.
Applying this logic to our example, we first find all direct prerequisites of each
coursebyexecutingthebasequery.Therecursivequeryaddsonemorelevelofcourses
7Somesystemstreattherecursivekeywordasoptional;othersdisallowit.
8Somesystems,notablyOracle,requireuseofunionall.

--- Page 247 ---

218 Chapter5 AdvancedSQL
ineachiteration,untilthemaximumdepthofthecourse-prereqrelationshipisreached.
Atthispointnonewtuplesareaddedtotheview,andafixedpointisreached.
To find the prerequisites of a specific course, such as CS-347, we can modify the
outerlevelquerybyaddingawhereclause“whererec prereq.course id=‘CS-347‘”.One
waytoevaluatethequerywiththeselectionistocomputethefullcontentsofrec prereq
usingtheiterative technique,andthenselectfrom thisresultonlythosetupleswhose
course id is CS-347. However, this would result in computing (course, prerequisite)
pairsforallcourses,allofwhichareirrelevantexceptforthoseforthecourseCS-347.
In fact the database system is not required to use this iterative technique to compute
the full result of the recursive query and then perform the selection. It may get the
sameresultusingothertechniquesthatmaybemoreefficient,suchasthatusedinthe
functionfindAllPrereqswhichwesawearlier.Seethebibliographicnotesforreferences
tomoreinformationonthistopic.
Therearesomerestrictionsontherecursivequeryinarecursiveview;specifically,
thequerymustbemonotonic,thatis,itsresultonaviewrelationinstanceV mustbea
1
supersetofitsresultonaviewrelationinstanceV ifV isasupersetofV .Intuitively,
2 1 2
if more tuples are added to the view relation, the recursive query must return at least
thesamesetoftuplesasbefore,andpossiblyreturnadditionaltuples.
Inparticular,recursivequeriesmaynotuseanyofthefollowingconstructs, since
theywouldmakethequerynonmonotonic:
• Aggregationontherecursiveview.
• notexistsonasubquerythatusestherecursiveview.
• Setdifference(except)whoseright-handsideusestherecursiveview.
Forinstance,iftherecursivequerywasoftheformr−v,wherevistherecursiveview,
ifweaddatupletov,theresultofthequerycanbecomesmaller;thequeryistherefore
notmonotonic.
Themeaningofrecursiveviewscanbedefinedbytheiterativeprocedureaslongas
therecursivequeryismonotonic;iftherecursivequeryisnonmonotonic,themeaning
oftheviewishardtodefine.SQLthereforerequiresthequeriestobemonotonic.Recur-
sivequeriesarediscussedinmoredetailinthecontextoftheDatalogquerylanguage,
inSection27.4.6.
SQLalsoallowscreationofrecursivelydefinedpermanentviewsbyusingcreatere-
cursiveviewinplaceofwithrecursive.Someimplementationssupportrecursivequeries
using a different syntax. This includes the Oracle start with / connect by prior syntax
for what it calls hierarchical queries. 9 See the respective system manuals for further
details.
9StaringwithOracle12.c,thestandardsyntaxisacceptedinadditiontothelegacyhierarchicalsyntax,withtherecursive
keywordomittedandwiththerequirementinourexamplethatunionallbeusedinsteadofunion.

--- Page 248 ---

5.5 AdvancedAggregationFeatures 219
5.5 Advanced Aggregation Features
The aggregation support in SQL is quite powerful and handles most common tasks
with ease. However, there are some tasks that are hard to implement efficiently with
thebasicaggregationfeatures.Inthissection,westudyfeaturesinSQLtohandlesome
suchtasks.
5.5.1 Ranking
Findingthe position of a value within a set is a common operation. For instance, we
maywishtoassignstudentsarankinclassbasedontheirgrade-pointaverage(GPA),
with the rank 1 going to the student with the highest GPA, the rank 2 to the student
withthenexthighestGPA,andsoon.Arelatedtypeofqueryistofindthepercentile
in which a value in a (multi)set belongs, for example, the bottom third, middle third,
or top third. While such queries can be expressed using the SQL constructs we have
seen so far, they are difficult to express and inefficient to evaluate. Programmersmay
resort to writing the query partly in SQL and partly in a programming language. We
studySQLsupportfordirectexpressionofthesetypesofquerieshere.
Inouruniversityexample,thetakesrelationshowsthegradeeachstudentearned
ineachcoursetaken.Toillustrateranking,letusassumewehaveaviewstudentgrades
(ID,GPA)givingthegrade-pointaverageofeachstudent.10
Rankingisdonewithanorderbyspecification.Thefollowingquerygivestherank
ofeachstudent:
selectID,rank()over(orderby(GPA)desc)ass rank
fromstudent grades;
Notethattheorderoftuplesintheoutputisnotdefined,sotheymaynotbesortedby
rank.Anextraorderbyclauseisneededtogettheminsortedorder,asfollows:
selectID,rank()over(orderby(GPA)desc)ass rank
fromstudent grades
orderbys rank;
Abasicissuewithrankingishowtodealwiththecaseofmultipletuplesthatare
thesameontheorderingattribute(s).Inourexample,thismeansdecidingwhattodo
iftherearetwostudentswiththesameGPA.Therankfunctiongivesthesamerankto
all tuples that are equal on the order by attributes. For instance, if the highest GPAis
sharedbytwostudents,bothwouldgetrank1.Thenextrankgivenwouldbe3,not2,
so if three students get the next highest GPA, they would all get rank 3, and the next
10TheSQLstatementtocreatetheviewstudentgradesissomewhatcomplexsincewemustconvertthelettergrades
inthetakesrelationtonumbersandweightthegradesforeachcoursebythenumberofcreditsforthatcourse.The
definitionofthisviewisthegoalofExercise4.6.

--- Page 249 ---

220 Chapter5 AdvancedSQL
student(s) wouldget rank 6, and so on. Thereisalsoa dense rankfunction thatdoes
not create gaps in the ordering. In the precedingexample, the tuples withthe second
highestvalue allgetrank 2, and tupleswiththe thirdhighestvalue getrank 3, andso
on.
If there are null values among the values being ranked, they are treated as the
highestvalues.Thatmakessenseinsomesituations,althoughforourexample,itwould
result in students with no courses being shown as having the highest GPAs. Thus, we
see that care needs to be taken in writing ranking queries in cases where null values
may appear. SQL permits the user to specify where they should occur by using nulls
firstornullslast,forinstance:
selectID,rank()over(orderbyGPAdescnullslast)ass rank
fromstudent grades;
Itispossible toexpresstheprecedingquerywiththebasicSQLaggregationfunc-
tions,usingthefollowingquery:
selectID,(1+(selectcount(*)
fromstudent gradesB
whereB.GPA>A.GPA))ass rank
fromstudent gradesA
orderbys rank;
Itshouldbeclearthattherankofastudentismerely1plusthenumberofstudents
with a higher GPA, which is exactly what the query specifies.11 However, this compu-
tationofeachstudent’sranktakestimelinearinthesizeoftherelation,leadingtoan
overall time quadratic in the size of the relation. On large relations, the above query
couldtakeaverylongtimetoexecute.Incontrast,thesystem’simplementationofthe
rankclausecansorttherelationandcomputetherankinmuchlesstime.
Rankingcanbedonewithinpartitionsofthedata.Forinstance,supposewewish
torankstudentsbydepartmentratherthanacrosstheentireuniversity.Assumethata
viewisdefinedlikestudent gradesbutincludingthedepartmentname:dept grades(ID,
dept name,GPA).Thefollowingquerythengivestherankofstudentswithineachsec-
tion:
selectID,dept name,
rank()over(partitionbydept nameorderbyGPAdesc)asdept rank
fromdept grades
orderbydept name,dept rank;
11ThereisaslighttechnicaldifferenceifastudenthasnottakenanycoursesandthereforehasanullGPA.Duetohow
comparisonsofnullvaluesworkinSQL,astudentwithanullGPAdoesnotcontributetootherstudents’countvalues.

--- Page 250 ---

5.5 AdvancedAggregationFeatures 221
Theouterorderbyclauseorderstheresulttuplesbydepartmentname,andwithineach
departmentbytherank.
Multiple rank expressions can be used within a single select statement; thus, we
can obtain the overall rank and the rank within the department by using two rank
expressionsinthesameselectclause.Whenranking(possiblywithpartitioning)occurs
alongwithagroupbyclause,thegroupbyclauseisappliedfirst,andpartitioningand
ranking are done on the results of the group by. Thus, aggregate values can then be
usedforranking.
It is often the case, especially for large results, that we may be interested only in
thetop-rankingtuplesoftheresultratherthantheentirelist.Forrankqueries,thiscan
be done by nesting the ranking query within a containing query whose where clause
choosesonlythosetupleswhoserankislowerthansomespecifiedvalue.Forexample,
tofindthetop5rankingstudentsbasedonGPA wecouldextendourearlierexample
bywriting:
select*
from(selectID,rank()over(orderby(GPA)desc)ass rank
fromstudent grades)
wheres rank<=5;
Thisquerydoesnotnecessarilygive5students,sincetherecouldbeties.Forexample,
if 2 students tie for fifth, the result would contain a total of 6 tuples. Note that the
bottomnissimplythesameasthetopnwithareversesortingorder.
Severaldatabasesystems providenonstandardSQLsyntaxtospecifydirectlythat
only the top n results are required. In our example, this would allow us to find the
top 5 students without the need to use the rank function. However, those constructs
resultinexactlythenumberoftuplesspecified(5inourexample),andsotiesforthe
final position are broken arbitrarily. The exact syntax for these “top n” queries varies
widely among systems; see Note 5.4 on page 222. Note that the top n constructs do
not support partitioning; so we cannot get the top n within each partition without
performingranking.
Severalotherfunctionscanbeusedinplaceofrank.Forinstance,percent rankof
atuple givestherankofthetupleasafraction.Iftherearentuplesinthepartition12
andtherankofthetupleisr,thenitspercentrankisdefinedas(r−1)∕(n−1)(and
as null if there is only one tuple in the partition). The function cume dist, short for
cumulative distribution, for a tuple is defined as p∕n where p is the number of tuples
in the partition with ordering values preceding or equal to the ordering value of the
tuple and n is the number of tuples in the partition. The function row number sorts
therowsandgiveseachrowauniquenumbercorrespondingtoitspositioninthesort
order;differentrowswiththesameorderingvaluewouldgetdifferentrownumbers,in
anondeterministicfashion.
12Theentiresetistreatedasasinglepartitionifnoexplicitpartitionisused.

--- Page 251 ---

222 Chapter5 AdvancedSQL
Note 5.4 TOP-NQUERIES
Often, only the first few tuples of a query result are required. This may occur in
arankingquerywhereonlytop-rankedresultsareofinterest.Anothercasewhere
this may occur is in a query with an order by from which only the top values are
ofinterest.Restrictingresultstothetop-rankedresultscanbedoneusingtherank
functionaswesawearlier,butthatsyntaxisrathercumbersome.Manydatabases
support asimplersyntax forsuch restriction,but the syntax varieswidelyamong
theleadingdatabasesystems.Weprovideafewexampleshere.
Somesystems(includingMySQLandPostgreSQL)allowaclauselimitntobe
addedattheendofanSQLquerytospecifythatonlythefirstntuplesshouldbe
output.Thisclausecanbeusedinconjunctionwithanorderbyclausetofetchthe
topntuples,asillustratedbythefollowingquery,whichretrievestheIDandGPA
ofthetop10studentsinorderofGPA:
selectID,GPA
fromstudentgrades
orderbyGPAdesc
limit10;
In IBM DB2 and the most recent versions of Oracle, the equivalent of the limit
clause is fetch first 10 rows only. Microsoft SQL Server places its version of this
feature in the select clause rather than adding a separate limit clause. The select
clauseiswrittenas:selecttop10ID,GPA.
Oracle(bothcurrentandolderversions)offerstheconceptofarownumberto
providethisfeature.Aspecial,hiddenattributerownumnumberstuplesofaresult
relation in order of retrieval. This attribute can then be used in a where clause
withinacontainingquery.However,theuseofthisfeatureisabittricky,sincethe
rownumisdecidedbeforerowsaresortedbyanorderbyclause.Touseitproperly,
anestedqueryshouldbeusedasfollows:
select*
from(selectID,GPA
fromstudentgrades
orderbyGPAdesc)
whererownum<=10;
The nested query ensures that the predicate on rownum is applied only after the
orderbyisapplied.
Some database systems have features allowing tuple limits to be exceeded in
caseofties.Seeyoursystem’sdocumentationfordetails.

--- Page 252 ---

5.5 AdvancedAggregationFeatures 223
Finally,foragivenconstantn,therankingfunctionntile(n)takesthetuplesineach
partitioninthespecifiedorderanddividesthemintonbucketswithequalnumbersof
tuples.13 For each tuple, ntile(n) then gives the number of the bucket in which it is
placed, with bucket numbers starting with 1. This function is particularly useful for
constructing histograms based on percentiles. We can show the quartile into which
eachstudentfallsbasedonGPAbythefollowingquery:
selectID,ntile(4)over(orderby(GPAdesc))asquartile
fromstudent grades;
5.5.2 Windowing
Window queries compute an aggregate function over ranges of tuples. This is useful,
forexample,tocomputeanaggregateofafixedrangeoftime;thetimerangeiscalleda
window.Windowsmayoverlap,inwhichcaseatuplemaycontributetomorethanone
window.Thisisunlikethepartitionswesawearlier,whereatuplecouldcontributeto
onlyonepartition.
An example of the use of windowing is trend analysis. Consider our earlier sales
example.Salesmayfluctuatewidelyfromdaytodaybasedonfactorslikeweather(e.g.,
asnowstorm,flood,hurricane,orearthquakemightreducesalesforaperiodoftime).
However,overasufficientlylongperiodoftime,fluctuationsmightbeless(continuing
theexample,salesmay“makeup”forweather-relateddownturns).Stock-markettrend
analysis is another example of the use of the windowing concept. Various “moving
averages”arefoundonbusinessandinvestmentwebsites.
It is relatively easy to write an SQL query using those features we have already
studied to compute an aggregate over one window, for example, sales over a fixed 3-
day period. However, if we want to do this for every 3-day period, the query becomes
cumbersome.
SQLprovidesawindowingfeaturetosupportsuchqueries.Supposewearegivena
viewtot credits(year,num credits)givingthetotalnumberofcreditstakenbystudents
in each year.14 Note that this relation can contain at most one tuple for each year.
Considerthefollowingquery:
selectyear,avg(num credits)
over(orderbyyearrows3preceding)
asavg totalcredits
fromtot credits;
13Ifthetotalnumberoftuplesinapartitionisnotdivisiblebyn,thenthenumberoftuplesineachbucketcandifferbyat
most1.Tupleswiththesamevaluefortheorderingattributemaybeassignedtodifferentbuckets,nondeterministically,
inordertomakethenumberoftuplesineachbucketequal.
14Weleavethedefinitionofthisviewintermsofouruniversityexampleasanexercise.

--- Page 253 ---

224 Chapter5 AdvancedSQL
Thisquerycomputesaveragesoverthethreeprecedingtuplesinthespecifiedsortorder.
Thus,for2019, iftuplesforyears2018and2017arepresentintherelationtot credits,
sinceeachyearisrepresentedbyonlyonetuple,theresultofthewindowdefinitionis
theaverageofthevaluesforyears2017,2018,and2019.Theaverageseachyearwould
be computed in a similar manner. For the earliest year in the relation tot credits, the
average would be over only that year itself, while for the next year, the average would
be over 2 years. Note that this example makes sense only because each year appears
only once in tot weight. Were this not the case, then there would be several possible
orderings of tuples since tuples for the same year could be in any order. We shall see
shortly awindowingquerythatuses arange of valuesinstead of aspecificnumberof
tuples.
Supposethatinsteadofgoingbackafixednumberoftuples,wewantthewindow
to consist of all prior years. That means the number of prior years considered is not
fixed.Togettheaveragetotalcreditsoverallprioryears,wewrite:
selectyear,avg(num credits)
over(orderbyyearrowsunboundedpreceding)
asavg total credits
fromtot credits;
It is possible to use the keyword following in place of preceding. If we did this in
our example, the year value specifiesthe beginningof the windowinstead of the end.
Similarly,wecanspecifyawindowbeginningbeforethecurrenttupleandendingafter
it:
selectyear,avg(num credits)
over(orderbyyearrowsbetween3precedingand2following)
asavg total credits
fromtot credits;
Inourexample,alltuplespertaintotheentireuniversity.Supposeinsteadwehave
creditdataforeachdepartmentinaviewtot credits dept(dept name,year,num credits)
givingthetotalnumberofcreditsstudentstookwiththeparticulardepartmentinthe
specified year. (Again, we leave writing this view definition as an exercise.) We can
writewindowingqueriesthattreateachdepartmentseparatelybypartitioningbydept
name:
selectdept name,year,avg(num credits)
over(partitionbydept name
orderbyyearrowsbetween3precedingandcurrentrow)
asavg totalcredits
fromtot credits dept;

--- Page 254 ---

5.5 AdvancedAggregationFeatures 225
item name color clothes size quantity
dress dark small 2
dress dark medium 6
dress dark large 12
dress pastel small 4
dress pastel medium 3
dress pastel large 3
dress white small 2
dress white medium 3
dress white large 0
pants dark small 14
pants dark medium 6
pants dark large 0
pants pastel small 1
pants pastel medium 0
pants pastel large 1
pants white small 3
pants white medium 0
pants white large 2
shirt dark small 2
shirt dark medium 6
shirt dark large 6
shirt pastel small 4
shirt pastel medium 1
shirt pastel large 2
shirt white small 17
shirt white medium 1
shirt white large 10
skirt dark small 2
skirt dark medium 5
skirt dark large 1
skirt pastel small 11
skirt pastel medium 9
skirt pastel large 15
skirt white small 2
skirt white medium 5
skirt white large 3
Figure 5.17 Anexampleofsalesrelation.

--- Page 255 ---

226 Chapter5 AdvancedSQL
item name clothes size dark pastel white
dress small 2 4 2
dress medium 6 3 3
dress large 12 3 0
pants small 14 1 3
pants medium 6 0 0
pants large 0 1 2
shirt small 2 4 17
shirt medium 6 1 1
shirt large 6 2 10
skirt small 2 11 2
skirt medium 5 9 5
skirt large 1 15 3
Figure 5.18 ResultofSQLpivotoperationonthesalesrelationofFigure5.17.
Theuseofthekeywordrangeinplaceofrowallowsthewindowingquerytocover
alltupleswithaparticularvalueratherthancoveringaspecificnumberoftuples.Thus
forexample,rowscurrentrowreferstoexactlyonetuple,whilerangecurrentrowrefers
toalltupleswhosevalue forthesort attributeisthesameasthatofthecurrenttuple.
Therangekeywordisnotimplementedfullyineverysystem.15
5.5.3 Pivoting
Consideranapplicationwhereashopwantstofindoutwhatkindsofclothesarepop-
ular.Letussupposethatclothesarecharacterizedbytheiritem name,color,andsize,
andthatwehavearelationsaleswiththeschema.
sales(item name,color,clothes size,quantity)
Suppose that item name can take on the values (skirt, dress, shirt, pants), color can
takeonthevalues(dark,pastel,white),clothes sizecantakeonvalues(small,medium,
large),andquantityisanintegervaluerepresentingthetotalnumberofitemssoldofa
given (item name, color, clothes size) combination.An instance of the sales relationis
showninFigure5.17.
Figure5.18showsanalternativewaytoviewthedatathatispresentinFigure5.17;
thevalues“dark”,“pastel”,and“white”ofattributecolorhavebecomeattributenames
inFigure5.18.ThetableinFigure5.18isanexampleofacross-tabulation(orcross-tab,
forshort),alsoreferredtoasapivot-table.
Thevaluesofthenewattributesdark,pastelandwhiteinourexamplearedefinedas
follows.Foraparticularcombinationofitem name,clothes size(e.g.,(“dress”,“dark”))
15Somesystems,suchasPostgreSQL,allowrangeonlywithunbounded.

--- Page 256 ---

5.5 AdvancedAggregationFeatures 227
ifthereisasingletuplewithcolor value“dark”,thequantityvalueofthatattributeap-
pears as the value for the attribute dark. If there are multiple such tuples, the values
areaggregatedusingthesumaggregateinourexample;ingeneralotheraggregatefunc-
tions could be used instead. Values for the other two attributes, pastel and white, are
similarlydefined.
Ingeneral,across-tabisatablederivedfromarelation(say, R),wherevaluesfor
someattributeofrelationR(say,A)becomeattributenamesintheresult;theattribute
Aisthepivotattribute.Cross-tabsarewidelyusedfordataanalysis,andarediscussed
inmoredetailinSection11.3.
SeveralSQLimplementations,suchasMicrosoftSQLServer,andOracle,support
a pivot clause that allows creation of cross-tabs. Given the sales relation from Figure
5.17,thequery:
select*
fromsales
pivot(
sum(quantity)
forcolor in(’dark’,’pastel’,’white’)
)
returnstheresultshowninFigure5.18.
Notethattheforclausewithinthepivotclausespecifies(i)apivotattribute(color,
in the above query), (ii) the values of that attribute that should appear as attribute
names in the pivot result (dark, pastel and white, in the above query), and (iii) the
aggregatefunctionthatshouldbeusedtocomputethevalueofthenewattributes(ag-
gregatefunctionsum,ontheattributequantity,intheabovequery).
Theattributecolorandquantitydonotappearintheresult,butallotherattributes
areretained.Incasemorethanonetuplecontributesvaluestoagivencell,theaggregate
operationwithinthepivotclausespecifieshowthevaluesshouldbecombined.Inthe
aboveexample,thequantityvaluesareaggregatedusingthesumfunction.
A query using pivot can be written using basic SQL constructs, without using the
pivotconstruct,buttheconstructsimplifiesthetaskofwritingsuchqueries.
5.5.4 Rollup and Cube
SQL supports generalizations of the group by construct using the rollup and cube op-
erations, which allow multiple group by queries to be run in a single query, with the
resultreturnedasasinglerelation.
Consideragainourretailshopexampleandtherelation:
sales(item name,color,clothes size,quantity)
Wecanfindthenumberofitemssoldineachitemnamebywritingasimplegroupby
query:

--- Page 257 ---

228 Chapter5 AdvancedSQL
selectitem name,sum(quantity)asquantity
fromsales
groupbyitem name;
Similarly, we can find the number of items sold in each color, and each size. We
canfurtherfindabreakdownofsalesbyitem-nameandcolorbywriting:
selectitem name,color,sum(quantity)asquantity
fromsales
groupbyitem name,color;
Similarly,aquerywithgroupbyitem name,color,clothes sizewouldallowustoseethe
salesbreakdownby(item name,color,clothes size)combinations.
Data analysts often need to view data aggregated in multiple ways as illustrated
above.TheSQLrollupandcubeconstructsprovideaconcisewaytogetmultiplesuch
aggregatesusingasinglequery,insteadofwritingmultiplequeries.
Therollupconstructisillustratedusingthefollowingquery:
selectitem name,color,sum(quantity)
fromsales
groupbyrollup(item name,color);
The result of the query is shown in Figure 5.19. The above query is equivalent to the
followingqueryusingtheunionoperation.
(selectitem name,color,sum(quantity)asquantity
fromsales
groupbyitem name,color)
union
(selectitem name,null ascolor,sum(quantity)asquantity
fromsales
groupbyitem name)
union
(selectnull asitem name,null ascolor,sum(quantity)asquantity
fromsales)
Theconstructgroupbyrollup(item name,color)generates3groupings:
{(item name,color),(item name),()}
where () denotes an empty group by list. Observe that a grouping is present for each
prefixoftheattributeslistedintherollupclause,includingtheemptyprefix.Thequery
result contains the union of the results by these groupings. The different groupings
generatedifferentschemas;tobringtheresultsofthedifferentgroupingstoacommon

--- Page 258 ---

5.5 AdvancedAggregationFeatures 229
item name color quantity
skirt dark 8
skirt pastel 35
skirt white 10
dress dark 20
dress pastel 10
dress white 5
shirt dark 14
shirt pastel 7
shirt white 28
pants dark 20
pants pastel 2
pants white 5
skirt null 53
dress null 35
shirt null 49
pants null 27
null null 164
Figure 5.19 Queryresult:groupbyrollup(itemname,color).
schema,tuplesintheresultcontainnullasthevalueofthoseattributesnotpresentin
aparticulargrouping.16
Thecubeconstructgeneratesanevenlargernumberofgroupings,consistingofall
subsetsoftheattributeslistedinthecubeconstruct.Forexample,thequery:
selectitem name,color,clothes size,sum(quantity)
fromsales
groupbycube(item name,color,clothes size);
generatesthefollowinggroupings:
{(item name,color,clothes size),(item name,color),(item name,clothes size),
(color,clothes size),(item name),(color),(clothes size),()}
Tobringtheresultsofthedifferentgroupingstoacommonschema,aswithrollup,tu-
plesintheresultcontainnullasthevalueofthoseattributesnotpresentinaparticular
grouping.
16TheSQLouterunionoperationcanbeusedtoperformaunionofrelationsthatmaynothaveacommonschema.
Theresultantschemahastheunionofalltheattributesacrosstheinputs;eachinputtupleismappedtoanoutput
tuplebyaddingalltheattributesmissinginthattuple,withthevaluesettonull.Ourunionquerycanbewrittenusing
outerunion,andinthatcasewedonotneedtoexplicitlygeneratenull-valueattributesusingnullasattribute-name
constructs,aswehavedoneintheabovequery.

--- Page 259 ---

230 Chapter5 AdvancedSQL
Multiple rollups and cubes can be used in a single group by clause. For instance,
thefollowingquery:
selectitem name,color,clothes size,sum(quantity)
fromsales
groupbyrollup(item name),rollup(color,clothes size);
generatesthegroupings:
{(item name,color,clothes size),(item name,color),(item name),
(color,clothes size),(color),()}
To understand why, observe that rollup(item name) generates a set of two group-
ings, {(item name), ()}, while rollup(color, clothes size) generates a set of three group-
ings, {(color, clothes size), (color), () }. The Cartesian product of the two sets gives us
thesixgroupingsshown.
Neither the rollup nor the cube clause gives complete control on the groupings
that are generated. For instance, we cannot use them to specify that we want only
groupings{(color,clothes size),(clothes size,item name)}.Suchrestrictedgroupingscan
begeneratedbyusingthegroupingsetsconstruct,inwhichonecanspecifythespecific
listofgroupingstobeused.Toobtainonlygroupings{(color,clothes size),(clothes size,
item name)},wewouldwrite:
selectitem name,color,clothes size,sum(quantity)
fromsales
groupbygroupingsets((color,clothes size),(clothes size,item name));
Analysts may want to distinguish those nulls generated by rollup and cube opera-
tionsfrom“normal”nullsactuallystoredinthedatabaseorarisingfromanouterjoin.
The grouping()function returns1 ifitsargumentisanull value generated by arollup
orcubeand0otherwise(notethatthegroupingfunctionisdifferentfromthegrouping
setsconstruct). IfwewishtodisplaytherollupqueryresultshowninFigure5.19,but
usingthevalue“all”inplaceofnullsgeneratedbyrollup,wecanusethequery:
select(casewhengrouping(item name)=1then’all’
elseitem nameend)asitem name,
(casewhengrouping(color)=1then’all’
elsecolor end)ascolor,
sum(quantity)asquantity
fromsales
groupbyrollup(item name,color);
One might consider using the following query using coalesce, but it would incor-
rectlyconvertnullitemnamesandcolorstoall:

--- Page 260 ---

ReviewTerms 231
selectcoalesce(item name,’all’)asitem name,
coalesce(color,’all’)ascolor,
sum(quantity)asquantity
fromsales
groupbyrollup(item name,color);
5.6 Summary
• SQLqueriescanbeinvokedfromhostlanguagesviaembeddedanddynamicSQL.
The ODBC and JDBC standards define application program interfaces to access
SQLdatabasesfromCandJavalanguageprograms.
• Functions and procedures can be defined using SQL procedural extensions that
allowiterationandconditional(if-then-else)statements.
• Triggersdefineactionstobeexecutedautomaticallywhencertaineventsoccurand
correspondingconditionsaresatisfied.Triggershavemanyuses,suchasbusiness
rule implementation and audit logging. They may carry out actions outside the
databasesystembymeansofexternallanguageroutines.
• Some queries, such as transitive closure, can be expressed either by using itera-
tion or by using recursive SQL queries. Recursion can be expressed using either
recursiveviewsorrecursivewithclausedefinitions.
• SQL supports several advanced aggregation features, including ranking and win-
dowing queries, as well as pivot, and rollup/cube operations. These simplify the
expressionofsomeaggregatesandallowmoreefficientevaluation.
Review Terms
• JDBC • Tablefunctions.
• Preparedstatements • Parameterizedviews
• SQLinjection • PersistentStorageModule(PSM).
• Metadata • Exceptionconditions
• Updatableresultsets • Handlers
• Open Database Connectivity • Externallanguageroutines
(ODBC) • Sandbox
• EmbeddedSQL • Trigger
• Embeddeddatabase • Transitiveclosure
• Storedproceduresandfunctions • Hierarchies

--- Page 261 ---

232 Chapter5 AdvancedSQL
• Createtemporarytable • Rankingfunctions
• Basequery • Cross-tabulation
• Recursivequery • Cross-tab
• Fixedpoint • Pivot-table
• Monotonic • Pivot
• Windowing • SQLgroupbycube,groupbyrollup
Practice Exercises
5.1 Considerthefollowingrelationsforacompanydatabase:
• emp(ename,dname,salary)
• mgr(ename,mname)
and the Java code in Figure 5.20, which uses the JDBC API. Assume that the
userid,password,machinename,etc.areallokay.DescribeinconciseEnglish
whattheJavaprogramdoes.(Thatis,produceanEnglishsentencelike“Itfinds
themanagerofthetoydepartment,”notaline-by-linedescriptionofwhateach
Javastatementdoes.)
5.2 Write a Java method using JDBC metadata features that takes a ResultSet as
an input parameter and prints out the result in tabular form, with appropriate
namesascolumnheadings.
5.3 Suppose thatwewishtofindallcoursesthatmustbetaken beforesomegiven
course.Thatmeansfindingnotonlytheprerequisitesofthatcourse,butprereq-
uisitesofprerequisites,andsoon.WriteacompleteJavaprogramusingJDBC
that:
• Takesacourse id valuefromthekeyboard.
• FindsprerequisitesofthatcourseusinganSQLquerysubmittedviaJDBC.
• Foreachcoursereturned,findsitsprerequisitesandcontinuesthisprocess
iterativelyuntilnonewprerequisitecoursesarefound.
• Printsouttheresult.
Forthisexercise,donotusearecursiveSQLquery,butratherusetheiterative
approach describedpreviously.Awell-developedsolution willbe robust tothe
error case where a university has accidentally created a cycle of prerequisites
(that is, for example, course A is a prerequisite for course B, course B is apre-
requisiteforcourseC,andcourseC isaprerequisiteforcourseA).

--- Page 262 ---

PracticeExercises 233
import java.sql.*;
public class Mystery {
public static void main(String[] args) {
try (
Connection con=DriverManager.getConnection(
"jdbc:oracle:thin:star/X@//edgar.cse.lehigh.edu:1521/XE");
q = "select mname from mgr where ename = ?";
PreparedStatementstmt=con.prepareStatement();
)
{
String q;
String empName = "dog";
boolean more;
ResultSet result;
do {
stmt.setString(1,empName);
result = stmt.executeQuery(q);
more = result.next();
if (more) {
empName = result.getString("mname");
System.out.println (empName);
}
} while (more);
s.close();
con.close();
}
catch(Exceptione){
e.printStackTrace();
}
}
}
Figure 5.20 JavacodeforExercise5.1(usingOracleJDBC).
5.4 Describethecircumstancesinwhichyou wouldchoosetouse embeddedSQL
ratherthanSQLaloneoronlyageneral-purposeprogramminglanguage.
5.5 Show how to enforce the constraint “an instructor cannot teach two different
sectionsinasemesterinthesametimeslot.”usingatrigger(rememberthatthe
constraint can be violated by changes to the teaches relation as well as to the
sectionrelation).

--- Page 263 ---

234 Chapter5 AdvancedSQL
branch(branch name,branch city,assets)
customer (customer name,customer street,customer city)
loan(loan number,branch name,amount)
borrower (customer name,loan number)
account (account number,branch name,balance)
depositor (customer name,account number)
Figure 5.21 BankingdatabaseforExercise5.6.
5.6 ConsiderthebankdatabaseofFigure5.21.Letusdefineaviewbranch custas
follows:
createviewbranch custas
selectbranch name,customer name
fromdepositor,account
wheredepositor.account number=account.account number
Supposethattheviewismaterialized;thatis,theviewiscomputedandstored.
Write triggers to maintain the view, that is, to keep it up-to-date on insertions
todepositororaccount.Itisnotnecessarytohandledeletionsorupdates.Note
that,forsimplicity,wehavenotrequiredtheeliminationofduplicates.
5.7 Consider the bank database of Figure 5.21. Write an SQL trigger to carry out
the following action: On delete of an account, for each customer-owner of the
account, check if the owner has any remaining accounts, and if she does not,
deleteherfromthedepositor relation.
5.8 GivenarelationS(student,subject,marks),writeaquerytofindthetop10stu-
dentsbytotalmarks,byusingSQLranking.Includeallstudentstiedforthefinal
spotintheranking,evenifthatresultsinmorethan10totalstudents.
5.9 Given a relation nyse(year, month, day, shares traded, dollar volume) with trad-
ing data from the New York Stock Exchange, list each trading day in order of
numberofsharestraded,andshoweachday’srank.
5.10 Using the relation from Exercise 5.9, write an SQL query to generate a report
showingthenumberofsharestraded,numberoftrades,andtotaldollarvolume
brokendownbyyear,eachmonthofeachyear,andeachtradingday.
5.11 Show how toexpress group by cube(a,b,c,d) using rollup; your answer should
haveonlyonegroupbyclause.

--- Page 264 ---

Exercises 235
Exercises
5.12 WriteaJavaprogramthatallowsuniversityadministratorstoprinttheteaching
recordofaninstructor.
a. Start by having the user input the login ID and password; then open the
properconnection.
b. Theuserisaskednextforasearchsubstringandthesystem returns(ID,
name)pairsofinstructorswhosenamesmatchthesubstring.Usethelike
('%substring%') construct in SQL to do this. If the search comes back
empty,allowcontinuedsearchesuntilthereisanonemptyresult.
c. ThentheuserisaskedtoenteranIDnumber,whichisanumberbetween
0and99999.Onceavalidnumberisentered,checkifaninstructorwith
thatIDexists.IfthereisnoinstructorwiththegivenID,printareasonable
messageandquit.
d. Iftheinstructorhastaughtnocourses,printamessagesayingthat.Other-
wiseprinttheteachingrecordfortheinstructor,showingthedepartment
name,course identifier,course title,section number, semester, year, and
totalenrollment(andsortthosebydept name,course id,year,semester).
Testcarefullyforbadinput.MakesureyourSQLquerieswon’tthrowanexcep-
tion.Atlogin,exceptionsmayoccursincetheusermighttypeabadpassword,
butcatchthoseexceptionsandallowtheusertotryagain.
5.13 Suppose you were asked to define a class MetaDisplay in Java, containing a
methodstaticvoidprintTable(Stringr);themethodtakesarelationnameras
input, executes the query “select * from r”, and prints the result out in tabular
format,withtheattributenamesdisplayedintheheaderofthetable.
a. Whatdoyou needtoknow about relationr tobe able toprinttheresult
inthespecifiedtabularformat?
b. WhatJDBCmethods(s)cangetyoutherequiredinformation?
c. WritethemethodprintTable(String r)usingtheJDBCAPI.
5.14 RepeatExercise5.13usingODBC,definingvoidprintTable(char*r)asafunc-
tioninsteadofamethod.
5.15 Consideranemployeedatabasewithtworelations
employee(employee name,street,city)
works(employee name,company name,salary)

--- Page 265 ---

236 Chapter5 AdvancedSQL
wheretheprimarykeysareunderlined.Writeafunctionavg salarythattakesa
companynameasanargumentandfindstheaveragesalaryofemployeesatthat
company.Then,writeanSQLstatement,usingthatfunction,tofindcompanies
whose employees earn a higher salary, on average, than the average salary at
“FirstBank”.
5.16 Considertherelationalschema
part(part id,name,cost)
subpart(part id,subpart id,count)
wheretheprimary-keyattributesareunderlined.Atuple(p ,p ,3)inthesubpart
1 2
relation denotes that the part with part id p is a direct subpart of the part
2
with part id p , and p has 3 copies of p . Note that p may itself have further
1 1 2 2
subparts.WritearecursiveSQLquerythatoutputsthenamesofallsubpartsof
thepartwithpart-id'P-100'.
5.17 ConsidertherelationalschemafromExercise5.16.WriteaJDBCfunctionusing
nonrecursiveSQLtofindthetotalcostofpart“P-100”,includingthecostsofall
itssubparts.Besuretotakeintoaccountthefactthatapartmayhavemultiple
occurrencesofasubpart.YoumayuserecursioninJavaifyouwish.
5.18 RedoExercise5.12usingthelanguageofyourdatabasesystemforcodingstored
proceduresandfunctions.Notethatyouarelikelytohavetoconsulttheonline
documentation for your system as a reference, since most systems use syntax
differingfromtheSQLstandardversionfollowedinthetext.Specifically,write
a prodedure that takes an instructor ID as an argument and produces printed
output in the format specified in Exercise 5.12, or an appropriate message if
the instructor does not exist or has taught no courses. (For a simpler version
of this exercise, rather than providing printed output, assume a relation with
the appropriate schema and insert your answer there without worrying about
testingforerroneousargumentvalues.)
5.19 Supposetherearetworelationsrands,suchthattheforeignkeyBofrreferences
the primary key A of s. Describe how the trigger mechanism can be used to
implementtheondeletecascadeoptionwhenatupleisdeletedfroms.
5.20 The execution of a trigger can cause another action to be triggered. Most
database systems place a limit on how deep the nesting can be. Explain why
theymightplacesuchalimit.
5.21 ModifytherecursivequeryinFigure5.16todefinearelation
prereq depth(course id,prereq id,depth)

--- Page 266 ---

Tools 237
building room number time slot id course id sec id
Garfield 359 A BIO-101 1
Garfield 359 B BIO-101 2
Saucon 651 A CS-101 2
Saucon 550 C CS-319 1
Painter 705 D MU-199 1
Painter 403 D FIN-201 1
Figure 5.22 Therelationr forExercise5.24.
where the attribute depth indicates how many levels of intermediate prerequi-
sitestherearebetweenthecourseandtheprerequisite.Directprerequisiteshave
adepthof0.Notethataprerequisitecoursemayhavemultipledepthsandthus
mayappearmorethanonce.
5.22 Givenrelations(a,b,c),writeanSQLstatementtogenerateahistogramshow-
ing the sum of c values versus a, dividinga into 20 equal-sized partitions (i.e.,
whereeachpartitioncontains5percentofthetuplesins,sortedbya).
5.23 ConsiderthenyserelationofExercise5.9.Foreachmonthofeachyear,show
thetotalmonthlydollarvolumeandtheaveragemonthlydollarvolumeforthat
month and the two prior months. (Hint: First write a query to find the total
dollar volume for each month of each year. Once that is right, put that in the
from clause of the outer query that solves the full problem. That outer query
willneedwindowing.Thesubquerydoesnot.)
5.24 Considertherelation,r,showninFigure5.22.Givetheresultofthefollowing
query:
selectbuilding,room number,time slot id,count(*)
fromr
groupbyrollup(building,room number,time slot id)
Tools
WeprovidesampleJDBCcodeonourbookwebsitedb-book.com.
Mostdatabasevendors,includingIBM,Microsoft,andOracle,provideOLAPtools
as part of their database systems, or as add-on applications. Tools may be integrated
withalarger“businessintelligence”productsuchasIBMCognos.Manycompaniesalso
provideanalysistoolsforspecificapplications,suchascustomerrelationshipmanage-
ment(e.g.,OracleSiebelCRM).

--- Page 267 ---

238 Chapter5 AdvancedSQL
Further Reading
MoredetailsaboutJDBCmaybefoundatdocs.oracle.com/javase/tutorial/jdbc.
Inordertowritestoredprocedures,storedfunctions,andtriggersthatcanbeexe-
cutedonagivensystem,youneedtorefertothesystemdocumentation.
Although our discussion of recursive queries focused on SQL syntax, there are
otherapproachestorecursionin relationaldatabases. Datalogisa database language
basedonthePrologprogramminglanguageandisdescribedinmoredetailinSection
27.4(availableonline).
OLAP features in SQL, including rollup, and cubes were introduced in SQL:1999,
and window functions with ranking and partitioning were added in SQL:2003. OLAP
features,includingwindowfunctions,aresupportedbymostdatabasestoday.Although
most follow the SQL standard syntax that we have presented, there are some differ-
ences;refertothesystemmanualsofthesystemthatyouareusingforfurtherdetails.
Microsoft’s Multidimensional Expressions (MDX) is an SQL-like query language de-
signedforqueryingOLAPcubes.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 268 ---

2
PART
DATABASE DESIGN
The task of creating a database application is a complex one, involving design of the
databaseschema,designoftheprogramsthataccessandupdatethedata,anddesign
of a security scheme to control access to data. The needs of the users play a central
roleinthedesignprocess.Inthispart,wefocusprimarilyonthedesignofthedatabase
schema.Wealsooutlinesomeoftheotherdesigntasks.
The entity-relationship (E-R) model described in Chapter 6 is a high-level data
model.Insteadofrepresentingalldataintables,itdistinguishesbetweenbasicobjects,
called entities, and relationships among these objects. It is often used as a first step in
database-schemadesign.
Relationaldatabasedesign—thedesignoftherelationalschema— wascoveredin-
formallyin earlierchapters. There are, however, principlesthat can be used to distin-
guishgooddatabasedesignsfrombadones.Theseareformalizedbymeansofseveral
“normalforms”thatofferdifferenttrade-offsbetweenthepossibilityofinconsistencies
andtheefficiencyofcertainqueries.Chapter7describestheformaldesignofrelational
schemas.
239

--- Page 270 ---

6
CHAPTER
Database Design Using the E-R
Model
Uptothispointinthetext,wehaveassumedagivendatabaseschemaandstudiedhow
queriesandupdatesareexpressed.Wenowconsiderhowtodesignadatabaseschema
in the first place. In this chapter, we focus on the entity-relationship data model (E-
R), which provides a means of identifying entities to be represented in the database
andhowthoseentitiesarerelated.Ultimately,thedatabasedesignwillbeexpressedin
termsofarelationaldatabasedesignandanassociatedsetofconstraints.Weshowin
thischapterhowanE-Rdesigncanbetransformedintoasetofrelationschemasand
how some of the constraints can be captured in that design. Then, in Chapter 7, we
consider in detail whethera set of relation schemas is a good or bad database design
andstudytheprocessofcreatinggooddesignsusingabroadersetofconstraints.These
twochapterscoverthefundamentalconceptsofdatabasedesign.
6.1 Overview of the Design Process
The task of creating a database application is a complex one, involving design of the
databaseschema,designoftheprogramsthataccessandupdatethedata,anddesign
ofasecurityschemetocontrolaccesstodata.Theneedsoftheusersplayacentralrole
inthedesignprocess.Inthischapter,wefocusonthedesignofthedatabaseschema,
althoughwebrieflyoutlinesomeoftheotherdesigntaskslaterinthechapter.
6.1.1 Design Phases
For small applications, it may be feasible for a database designer who understands
the application requirements to decide directly on the relations to be created, their
attributes, and constraints on the relations. However, such a direct design process is
difficultforreal-worldapplications,sincetheyareoftenhighlycomplex.Oftennoone
personunderstandsthecompletedataneedsofanapplication.Thedatabasedesigner
must interact with users of the application to understand the needs of the applica-
tion, represent them in a high-level fashion that can be understood by the users, and
241

--- Page 271 ---

242 Chapter6 DatabaseDesignUsingtheE-RModel
thentranslatetherequirementsintolowerlevelsofthedesign.Ahigh-leveldatamodel
servesthedatabasedesignerbyprovidingaconceptualframeworkinwhichtospecify,
in a systematic fashion, the data requirements of the database users, and a database
structurethatfulfillstheserequirements.
• The initial phase of database design isto characterize fully the data needs of the
prospective database users. The database designer needs to interact extensively
withdomainexpertsanduserstocarryoutthistask.Theoutcomeofthisphaseis
aspecificationofuserrequirements.Whiletherearetechniquesfordiagrammati-
callyrepresentinguserrequirements,inthischapterwerestrictourselvestotextual
descriptionsofuserrequirements.
• Next,thedesignerchoosesadatamodeland,byapplyingtheconceptsofthecho-
sen data model, translates these requirements into a conceptual schema of the
database. The schema developed at this conceptual-design phase provides a de-
tailedoverviewoftheenterprise.Theentity-relationshipmodel,whichwestudyin
therestofthischapter,istypicallyusedtorepresenttheconceptualdesign.Stated
intermsoftheentity-relationshipmodel,theconceptualschemaspecifiestheenti-
tiesthatarerepresentedinthedatabase,theattributesoftheentities,therelation-
ships among the entities, and constraints on the entities and relationships. Typi-
cally,theconceptual-designphase resultsinthecreationofanentity-relationship
diagramthatprovidesagraphicrepresentationoftheschema.
The designer reviews the schema to confirm that all data requirements are
indeedsatisfiedandarenotinconflictwithoneanother.Shecanalsoexaminethe
designtoremoveanyredundantfeatures.Herfocusatthispointisondescribing
thedataandtheirrelationships,ratherthanonspecifyingphysicalstoragedetails.
• A fully developed conceptual schema also indicates the functional requirements
of the enterprise. In a specification of functional requirements, users describe the
kindsofoperations(ortransactions)thatwillbeperformedonthedata.Example
operations include modifying or updating data, searching for and retrieving spe-
cific data, and deletingdata. At thisstage of conceptual design, the designercan
reviewtheschematoensurethatitmeetsfunctionalrequirements.
• Theprocessofmovingfromanabstractdatamodeltotheimplementationofthe
databaseproceedsintwofinaldesignphases.
° Inthelogical-designphase,thedesignermapsthehigh-levelconceptualschema
ontotheimplementationdatamodelofthedatabasesystemthatwillbeused.
Theimplementationdatamodelistypicallytherelationaldatamodel,andthis
step typically consists of mapping the conceptual schema defined using the
entity-relationshipmodelintoarelationschema.
° Finally,thedesignerusestheresultingsystem-specificdatabaseschemainthe
subsequentphysical-designphase,inwhichthephysicalfeaturesofthedatabase

--- Page 272 ---

6.1 OverviewoftheDesignProcess 243
are specified. These features include the form of file organization and choice
ofindexstructures,discussedinChapter13andChapter14.
Thephysicalschemaofadatabasecanbechangedrelativelyeasilyafteranapplica-
tionhasbeenbuilt.However,changestothelogicalschemaareusuallyhardertocarry
out,sincetheymayaffectanumberofqueriesandupdatesscatteredacrossapplication
code.Itisthereforeimportanttocarryoutthedatabasedesignphasewithcare,before
buildingtherestofthedatabaseapplication.
6.1.2 Design Alternatives
Amajorpartofthedatabasedesignprocessisdecidinghowtorepresentinthedesign
thevarioustypesof“things”suchaspeople,places,products,andthelike.Weusethe
term entity to refer to any such distinctly identifiable item. In a university database,
examples of entities would include instructors, students, departments, courses, and
courseofferings.Weassumethatacoursemayhaveruninmultiplesemesters,aswell
asmultipletimesinasemester;werefertoeachsuchofferingofacourseasasection.
Thevariousentitiesarerelatedtoeachotherinavarietyofways,allofwhichneedtobe
capturedinthedatabasedesign.Forexample,astudenttakesacourseoffering,while
aninstructorteachesacourseoffering;teachesandtakesareexamplesofrelationships
betweenentities.
Indesigningadatabaseschema,wemustensurethatweavoidtwomajorpitfalls:
1. Redundancy:Abaddesignmayrepeatinformation.Forexample,ifwestorethe
courseidentifierandtitleofacoursewitheachcourseoffering,thetitlewouldbe
storedredundantly(i.e.,multipletimes,unnecessarily)witheachcourseoffering.
Itwouldsufficetostoreonlythecourseidentifierwitheachcourseoffering,and
toassociatethetitlewiththecourseidentifieronlyonce,inacourseentity.
Redundancycanalsooccurinarelationalschema.Intheuniversityexample
we have used so far, we have a relationwith section information and aseparate
relationwithcourseinformation.Supposethatinsteadwehaveasinglerelation
wherewerepeatallofthecourseinformation(course id,title,dept name,credits)
onceforeachsection(offering)ofthecourse.Informationaboutcourseswould
thenbestoredredundantly.
Thebiggestproblemwithsuchredundantrepresentationofinformationisthat
thecopiesofapieceofinformationcanbecomeinconsistentiftheinformation
is updated without taking precautions to update all copies of the information.
Forexample,differentofferingsofacoursemayhavethesamecourseidentifier,
butmayhavedifferenttitles.Itwouldthenbecomeunclearwhatthecorrecttitle
ofthecourseis.Ideally,informationshouldappearinexactlyoneplace.
2. Incompleteness: A bad design may make certain aspects of the enterprise diffi-
cult or impossible to model. For example, suppose that, as in case (1) above,
we only had entities corresponding to course offering, without having an entity

--- Page 273 ---

244 Chapter6 DatabaseDesignUsingtheE-RModel
corresponding to courses. Equivalently, in terms of relations, suppose we have
a single relation where we repeat all of the course information once for each
sectionthatthecourseisoffered.Itwouldthenbeimpossibletorepresentinfor-
mationabout anewcourse,unlessthatcourse isoffered.Wemighttrytomake
dowiththeproblematicdesignbystoringnullvaluesforthesectioninformation.
Suchawork-aroundisnotonlyunattractivebutmaybepreventedbyprimary-key
constraints.
Avoidingbaddesignsisnotenough.Theremaybealargenumberofgooddesigns
from which we must choose. As a simple example, consider a customer who buys a
product.Isthesaleofthisproductarelationshipbetweenthecustomerandtheprod-
uct?Alternatively,isthesaleitselfanentitythatisrelatedbothtothecustomerandto
the product? This choice, though simple, may make an important difference in what
aspectsoftheenterprise canbe modeledwell.Consideringtheneedtomakechoices
suchasthisforthelargenumberofentitiesandrelationshipsinareal-worldenterprise,
itisnothardtoseethatdatabasedesigncanbeachallengingproblem.Indeedweshall
seethatitrequiresacombinationofbothscienceand“goodtaste.”
6.2 The Entity-Relationship Model
Theentity-relationship(E-R)datamodelwasdevelopedtofacilitatedatabasedesignby
allowingspecificationofanenterpriseschemathatrepresentstheoveralllogicalstruc-
tureofadatabase.
The E-R model is very useful in mapping the meanings and interactions of real-
worldenterprisesontoaconceptualschema.Becauseofthisusefulness,manydatabase-
designtoolsdrawonconceptsfromtheE-Rmodel.TheE-Rdatamodelemploysthree
basicconcepts:entitysets,relationshipsets,andattributes.TheE-Rmodelalsohasan
associateddiagrammaticrepresentation,theE-Rdiagram.AswesawbrieflyinSection
1.3.1,anE-Rdiagramcanexpresstheoveralllogicalstructureofadatabasegraphically.
E-Rdiagramsaresimpleandclear—qualitiesthatmaywellaccountinlargepartforthe
widespreaduseoftheE-Rmodel.
The Tools section at the end of the chapter provides information about several
diagrameditorsthatyoucanusetocreateE-Rdiagrams.
6.2.1 Entity Sets
Anentityisa“thing”or“object”intherealworldthatisdistinguishablefromallother
objects.Forexample,eachpersoninauniversityisanentity.Anentityhasasetofprop-
erties, and the values for some set of properties must uniquely identify an entity. For
instance,aperson mayhave a person id property whose value uniquelyidentifiesthat
person.Thus,thevalue677-89-9011forperson id woulduniquelyidentifyoneparticu-
larpersonintheuniversity.Similarly,coursescanbethoughtofasentities,andcourse
iduniquelyidentifiesacourseentityintheuniversity.Anentitymaybeconcrete,such

--- Page 274 ---

6.2 TheEntity-RelationshipModel 245
as a person or a book, or it may be abstract, such as a course, a course offering, or a
flightreservation.
An entity set is a set of entities of the same type that share the same properties,
orattributes. Thesetof allpeople whoareinstructorsatagiven university,forexam-
ple, can be defined as the entity set instructor. Similarly, the entity set student might
representthesetofallstudentsintheuniversity.
Intheprocessofmodeling,weoftenusethetermentitysetintheabstract,without
referringtoaparticularsetofindividualentities.Weusethetermextensionoftheentity
settorefertotheactualcollectionofentitiesbelongingtotheentityset.Thus,theset
of actual instructors in the university forms the extension of the entity set instructor.
Thisdistinctionissimilartothedifferencebetweenarelationandarelationinstance,
whichwesawinChapter2.
Entitysetsdonotneedtobedisjoint.Forexample,itispossibletodefinetheentity
setpersonconsistingofallpeopleinauniversity.Aperson entitymaybeaninstructor
entity,astudententity,both,orneither.
Anentityisrepresentedbyasetofattributes.Attributesaredescriptiveproperties
possessed byeach memberofan entityset.The designation of an attribute foran en-
tity set expresses that the database stores similar information concerning each entity
in the entity set; however, each entity may have its own value for each attribute. Pos-
sible attributes of theinstructor entity setare ID, name, dept name, and salary. In real
life,therewouldbefurtherattributes,suchasstreetnumber,apartmentnumber,state,
postal code, and country, but we generally omit them to keep our examples simple.
Possibleattributesofthecourseentitysetarecourse id,title,dept name,andcredits.
Inthissectionweconsideronlyattributesthataresimple— thosenotdividedinto
subparts. In Section 6.3, we discuss more complex situations where attributes can be
compositeandmultivalued.
Eachentityhasavalueforeachofitsattributes.Forinstance,aparticularinstructor
entity may have the value 12121 for ID, the value Wu for name, the value Finance for
dept name,andthevalue90000forsalary.
The ID attribute is used to identify instructors uniquely, since there may be more
than one instructor with the same name. Historically, many enterprises found it con-
venient to use a government-issued identificationnumber as an attribute whose value
uniquelyidentifiestheperson.However,thatisconsideredbadpracticeforreasonsof
securityandprivacy.Ingeneral,theenterprisewouldhavetocreateandassignitsown
uniqueidentifierforeachinstructor.
A database thus includes a collection of entity sets, each of which contains any
numberofentitiesofthesametype.Adatabaseforauniversitymayincludeanumber
of other entity sets. For example, in addition to keeping track of instructors and stu-
dents,theuniversityalsohasinformationaboutcourses,whicharerepresentedbythe
entitysetcoursewithattributescourse id,title,dept nameandcredits.Inarealsetting,
auniversitydatabasemaykeepdozensofentitysets.
An entity set is represented in an E-R diagram by a rectangle, which is divided
into two parts. The first part, which in this text is shaded blue, contains the name of

--- Page 275 ---

246 Chapter6 DatabaseDesignUsingtheE-RModel
instructor student
ID ID
name name
salary tot_cred
Figure 6.1 E-Rdiagramshowingentitysetsinstructor andstudent.
the entity set. The second part contains the names of all the attributes of the entity
set. The E-R diagram in Figure 6.1 shows two entity sets instructor and student. The
attributesassociatedwithinstructorareID,name,andsalary.Theattributesassociated
withstudentareID,name,andtot cred.Attributesthatarepartoftheprimarykeyare
underlined(seeSection6.5).
6.2.2 Relationship Sets
A relationship is an association among several entities. For example, we can define a
relationshipadvisorthatassociatesinstructorKatzwithstudentShankar.Thisrelation-
ship specifiesthat Katz isan advisorto student Shankar. A relationship set isa setof
relationshipsofthesametype.
Consider two entity sets instructor and student. We define the relationshipset ad-
visor todenotetheassociationsbetweenstudentsandtheinstructorswhoactastheir
advisors. Figure 6.2 depicts this association. To keep the figure simple, only some of
theattributesofthetwoentitysetsareshown.
A relationship instance in an E-R schema represents an association between the
named entities in the real-world enterprise that is being modeled. As an illustration,
theindividualinstructor entityKatz,whohasinstructorID45565,andthestudenten-
tityShankar,whohasstudentID12345, participate inarelationshipinstanceofadvi-
76766 Crick 98988 Tanaka
45565 Katz 12345 Shankar
10101 Srinivasan 00128 Zhang
98345 Kim 76543 Brown
76543 Singh 76653 Aoi
22222 Einstein 23121 Chavez
44553 Peltier
instructor
student
Figure 6.2 Relationshipsetadvisor (onlysomeattributesofinstructor andstudent are
shown).

--- Page 276 ---

6.2 TheEntity-RelationshipModel 247
instructor student
ID advisor ID
name name
salary tot_cred
Figure 6.3 E-R diagramshowingrelationshipsetadvisor.
sor. This relationshipinstance representsthat in the university, the instructor Katz is
advisingstudentShankar.
Arelationshipsetisrepresentedinan E-Rdiagrambya diamond,whichislinked
vialinestoanumberofdifferententitysets(rectangles).TheE-RdiagraminFigure6.3
shows the two entity sets instructor and student, related through a binary relationship
setadvisor.
Asanotherexample,considerthetwoentitysetsstudentandsection,wheresection
denotesanofferingofacourse.Wecandefinetherelationshipsettakestodenotethe
associationbetweenastudentandasectioninwhichthatstudentisenrolled.
Although in the preceding examples each relationship set was an association be-
tweentwoentitysets,ingeneralarelationshipsetmaydenotetheassociationofmore
thantwoentitysets.
Formally,arelationship set isamathematicalrelationonn ≥ 2(possibly nondis-
tinct)entity sets. If E , E ,…,E are entity sets, then a relationshipset Ris a subset
1 2 n
of
{(e ,e ,…,e )|e ∈ E ,e ∈ E ,…,e ∈ E }
1 2 n 1 1 2 2 n n
where(e ,e ,…,e )isarelationshipinstance.
1 2 n
The association between entity sets is referred to as participation; i.e., the entity
setsE , E ,…,E participateinrelationshipsetR.
1 2 n
Thefunctionthatanentityplaysinarelationshipiscalledthatentity’srole.Since
entitysetsparticipatinginarelationshipsetaregenerallydistinct,rolesareimplicitand
arenotusuallyspecified.However,theyareusefulwhenthemeaningofarelationship
needs clarification. Such is the case when the entity sets of a relationship set are not
distinct; that is, the same entity set participates in a relationship set more than once,
indifferentroles.Inthistypeofrelationshipset,sometimescalledarecursiverelation-
ship set, explicit role names are necessary to specify how an entity participates in a
relationshipinstance.Forexample,considertheentitysetcoursethatrecordsinforma-
tion about all the courses offered in the university. To depict the situation where one
course (C2) is a prerequisite for another course (C1) we have relationship set prereq
thatismodeledbyorderedpairsofcourseentities.Thefirstcourseofapairtakesthe
roleofcourseC1,whereasthesecondtakestheroleofprerequisitecourseC2.Inthis
way,allrelationshipsofprereqarecharacterizedby(C1,C2)pairs;(C2,C1)pairsare
excluded.WeindicaterolesinE-Rdiagramsbylabelingthelinesthatconnectdiamonds

--- Page 277 ---

248 Chapter6 DatabaseDesignUsingtheE-RModel
course
course_id
course_id
title prereq
prereq_id
credits
Figure 6.4 E-R diagramwithroleindicators.
torectangles.Figure6.4showstheroleindicatorscourse id andprereq id betweenthe
courseentitysetandtheprereqrelationshipset.
Arelationshipmayalsohaveattributescalleddescriptiveattributes.Asanexample
ofdescriptiveattributesforrelationships,considertherelationshipsettakeswhichre-
latesentitysetsstudentandsection.Wemaywishtostoreadescriptiveattributegrade
withtherelationshiptorecordthegradethatastudentreceivedinacourseoffering.
AnattributeofarelationshipsetisrepresentedinanE-Rdiagrambyanundivided
rectangle. We link the rectangle with a dashed line to the diamond representing that
relationshipset.Forexample,Figure6.5showstherelationshipsettakesbetweenthe
entitysetssection andstudent.Wehavethedescriptiveattribute gradeattachedtothe
relationship set takes. A relationship set may have multiple descriptive attributes; for
example,wemayalsostoreadescriptiveattributefor creditwiththetakesrelationship
settorecordwhetherastudenthastakenthesectionforcredit,orisauditing(orsitting
inon)thecourse.
Observe that the attributes of the two entitysets have been omitted from the E-R
diagraminFigure6.5,withtheunderstandingthattheyarespecifiedelsewhereinthe
completeE-Rdiagramfortheuniversity;wehavealreadyseentheattributesforstudent,
andwewillseetheattributesofsectionlaterinthischapter.ComplexE-Rdesignsmay
need to be split into multiple diagrams that may be located in different pages. Rela-
tionshipsetsshouldbeshowninonlyonelocation,butentitysetsmayberepeatedin
morethanonelocation.Theattributesofanentitysetshouldbeshowninthefirstoc-
currence.Subsequentoccurrencesoftheentitysetshouldbeshownwithoutattributes,
toavoidrepetitionofinformationandtheresultantpossibilityofinconsistencyinthe
attributesshownindifferentoccurrences.
grade
student takes section
Figure 6.5 E-R diagramwithanattribute attachedtoarelationshipset.

--- Page 278 ---

6.3 ComplexAttributes 249
Itispossibletohavemorethanonerelationshipsetinvolvingthesameentitysets.
Forexample,supposethatstudentsmaybeteachingassistantsforacourse.Then,the
entity sets section and student may participate in a relationship set teaching assistant,
inadditiontoparticipatinginthetakesrelationshipset.
The formal definition of a relationship set, which we saw earlier, defines a rela-
tionshipsetasasetofrelationshipinstances.Considerthetakesrelationshipbetween
student andsection.Sinceasetcannothaveduplicates,itfollowsthataparticularstu-
dentcanhaveonlyoneassociationwithaparticularsectioninthetakesrelationship.
Thus,astudentcanhaveonlyonegradeassociatedwithasection,whichmakessense
in this case. However, if we wish to allow a student to have more than one grade for
thesamesection,weneedtohaveanattributegradeswhichstoresasetofgrades;such
attributesarecalledmultivaluedattributes,andweshallseethemlaterinSection6.3.
The relationship sets advisor and takes provide examples of a binary relationship
set—thatis,onethatinvolvestwoentitysets.Mostoftherelationshipsetsinadatabase
systemarebinary.Occasionally,however,relationshipsetsinvolvemorethantwoentity
sets.Thenumberofentitysetsthatparticipateinarelationshipsetisthedegreeofthe
relationshipset.Abinaryrelationshipsetisofdegree2;aternaryrelationshipsetisof
degree3.
Asanexample,supposethatwehaveanentitysetprojectthatrepresentsallthere-
searchprojectscarriedoutintheuniversity.Considertheentitysetsinstructor,student,
andproject.Eachprojectcanhavemultipleassociatedstudentsandmultipleassociated
instructors. Furthermore, each student workingon a projectmust have an associated
instructor who guides the student on the project. For now, we ignore the first two re-
lationships,betweenprojectandinstructor,andbetweenprojectandstudent.Instead,
wefocusontheinformationaboutwhichinstructorisguidingwhichstudentonapar-
ticularproject.
Torepresentthisinformation,werelatethethreeentitysetsthroughaternaryre-
lationship set proj guide, which relates entity sets instructor, student, and project. An
instance of proj guide indicates that a particular student is guided by a particular in-
structoronaparticularproject.Notethatastudentcouldhavedifferentinstructorsas
guidesfordifferentprojects,whichcannotbecapturedbyabinaryrelationshipbetween
studentsandinstructors.
Nonbinary relationship sets can be specified easily in an E-R diagram. Figure 6.6
showstheE-Rdiagramrepresentationoftheternaryrelationshipsetproj guide.
6.3 Complex Attributes
Foreachattribute,thereisasetofpermittedvalues,calledthedomain,orvalueset,of
that attribute. The domain of attribute course id might be the set of all text strings of
acertainlength.Similarly,thedomainofattributesemester mightbestringsfromthe
set{Fall,Winter,Spring,Summer}.

--- Page 279 ---

250 Chapter6 DatabaseDesignUsingtheE-RModel
project
. . .
instructor student
ID proj_guide ID
name name
salary tot_cred
Figure 6.6 E-Rdiagramwithaternaryrelationshipprojguide.
composite name address
attributes
first_name middle_initial last_name street city state postal_code
component
attributes
street_number street_name apartment_number
Figure 6.7 Compositeattributesinstructorname andaddress.
An attribute, as used in the E-R model, can be characterized by the following at-
tributetypes.
• Simpleandcompositeattributes.Inourexamplesthusfar,theattributeshavebeen
simple;thatis,theyhavenotbeendividedintosubparts.Compositeattributes,on
the other hand, can be divided into subparts (i.e., other attributes). For exam-
ple, an attribute name could be structured as a composite attribute consisting of
first name, middle initial, and last name. Using composite attributes in a design
schemaisagoodchoiceifauserwillwishtorefertoanentireattributeonsome
occasions,andtoonlyacomponentoftheattributeonotheroccasions.Suppose
we were to add an address to the student entity-set. The address can be defined
as the composite attribute address with the attributes street, city, state, and postal
code.1 Composite attributes help us to group together related attributes, making
themodelingcleaner.
Notealsothatacompositeattributemayappearasahierarchy.Inthecompos-
iteattributeaddress,itscomponentattributestreetcanbefurtherdividedintostreet
number,street name,andapartment number.Figure6.7depictstheseexamplesof
compositeattributesfortheinstructor entityset.
1WeassumetheaddressformatusedintheUnitedStates,whichincludesanumericpostalcodecalledazipcode.

--- Page 280 ---

6.3 ComplexAttributes 251
• Single-valued and multivalued attributes. The attributes in our examples all have
a single value for a particular entity. For instance, the student ID attribute for a
specificstudententityreferstoonlyonestudentID.Suchattributesaresaidtobe
single valued. There may be instances where an attribute has a set of values for
a specific entity. Suppose we add to the instructor entity set a phone number at-
tribute.Aninstructormayhavezero,one,orseveralphonenumbers,anddifferent
instructorsmayhavedifferentnumbersofphones.Thistypeofattributeissaidto
be multivalued. As another example, we could add to the instructor entity set an
attributedependent namelistingallthedependents.Thisattributewouldbemulti-
valued,sinceanyparticularinstructormayhavezero,one,ormoredependents.
• Derivedattributes.Thevalueforthistypeofattributecanbederivedfromtheval-
uesofotherrelatedattributesorentities.Forinstance,letussaythattheinstructor
entity set has an attribute studentsadvised, which represents how many students
an instructor advises. We can derive the value for this attribute by counting the
numberofstudententitiesassociatedwiththatinstructor.
Asanotherexample,supposethattheinstructor entitysethasanattributeage
thatindicatestheinstructor’s age. Iftheinstructor entitysetalsohasan attribute
date of birth, we can calculate age from date of birth and the current date. Thus,
age is a derived attribute. In this case, date of birth may be referred to as a base
attribute,orastored attribute.Thevalueofaderivedattributeisnotstoredbutis
computedwhenrequired.
Figure 6.8 shows how composite attributes can be represented in the E-R notation.
Here,acompositeattributenamewithcomponentattributesfirst name,middle initial,
and last name replaces the simple attribute name of instructor. As another example,
suppose weweretoaddanaddresstotheinstructor entityset.Theaddresscanbede-
finedasthecompositeattributeaddresswiththeattributesstreet,city,state,andpostal
code. The attribute street is itself a composite attribute whose component attributes
arestreet number,street name,andapartment number.Thefigurealsoillustratesamul-
tivaluedattributephone number,denotedby“{phone number}”,andaderivedattribute
age,depictedby“age()”.
Anattributetakesanullvaluewhenanentitydoesnothaveavalueforit.Thenull
valuemayindicate“notapplicable”—thatis,thevaluedoesnotexistfortheentity.For
example, a person who has no middle name may have the middle initial attribute set
tonull.Null canalsodesignatethatanattributevalueisunknown.Anunknownvalue
may be either missing (the value does exist, but we do not have that information) or
notknown(wedonotknowwhetherornotthevalueactuallyexists).
For instance, if the name value for a particular instructor is null, we assume that
the value is missing, since every instructor must have a name. A null value for the
apartment numberattributecouldmeanthattheaddressdoesnotincludeanapartment
number (not applicable), that an apartment number exists but we do not know what

--- Page 281 ---

252 Chapter6 DatabaseDesignUsingtheE-RModel
instructor
ID
name
first_name
middle_initial
last_name
address
street
street_number
street_name
apt_number
city
state
zip
{ phone_number }
date_of_birth
age ( )
Figure 6.8 E-Rdiagramwithcomposite,multivalued,andderivedattributes.
itis(missing),orthatwedonotknowwhetherornotanapartmentnumberispartof
theinstructor’saddress(unknown).
6.4 Mapping Cardinalities
Mapping cardinalities, or cardinality ratios, express the number of entities to which
anotherentitycanbeassociatedviaarelationshipset.Mappingcardinalitiesaremost
useful in describing binary relationship sets, although they can contribute to the de-
scriptionofrelationshipsetsthatinvolvemorethantwoentitysets.
ForabinaryrelationshipsetRbetweenentitysetsAandB,themappingcardinality
mustbeoneofthefollowing:
• One-to-one.AnentityinAisassociatedwithatmostoneentityinB,andanentity
inBisassociatedwithatmostoneentityinA.(SeeFigure6.9a.)
• One-to-many.AnentityinAisassociatedwithanynumber(zeroormore)ofenti-
tiesinB.AnentityinB, however,canbe associated withat most one entityinA.
(SeeFigure6.9b.)
• Many-to-one. An entity in A is associated with at most one entity in B. An entity
inB,however,canbeassociatedwithanynumber(zeroormore)ofentitiesinA.
(SeeFigure6.10a.)

--- Page 282 ---

6.4 MappingCardinalities 253
A B A B
b
a 1
1
b a b
a 1 1 2
2
b a b
a 2 2 3
3
b a b
a 3 3 4
4
b
5
(a) (b)
Figure 6.9 Mappingcardinalities.(a)One-to-one.(b)One-to-many.
• Many-to-many. An entity in A is associated with any number (zero or more) of
entities in B, and an entity in B is associated with any number (zero or more) of
entitiesinA.(SeeFigure6.10b.)
Theappropriatemappingcardinalityforaparticularrelationshipsetobviouslydepends
onthereal-worldsituationthattherelationshipsetismodeling.
Asanillustration,considertheadvisorrelationshipset.Ifastudentcanbeadvised
byseveralinstructors(asinthecaseofstudentsadvisedjointly),therelationshipsetis
many-to-many.Incontrast,ifaparticularuniversityimposesaconstraintthatastudent
can be advised by only one instructor, and an instructor can advise several students,
thentherelationshipsetfrominstructortostudentmustbeone-to-many.Thus,mapping
A B A B
a
1 a b
1 1
a
aa
22
b
1 a b
2 2
a b
3 2
a b
3 3
a b
4 3
a b
a 4 4
5
(a) (b)
Figure 6.10 Mappingcardinalities.(a)Many-to-one. (b)Many-to-many.

--- Page 283 ---

254 Chapter6 DatabaseDesignUsingtheE-RModel
cardinalitiescanbeusedtospecifyconstraintsonwhatrelationshipsarepermittedin
therealworld.
IntheE-Rdiagramnotation,weindicatecardinalityconstraintsonarelationship
bydrawingeitheradirectedline(→)oranundirectedline(—)betweentherelationship
setandtheentitysetinquestion.Specifically,fortheuniversityexample:
• One-to-one. We draw a directed line from the relationship set to both entity sets.
For example, in Figure 6.11a, the directed lines to instructor and student indicate
thataninstructormayadviseatmostonestudent,andastudentmayhaveatmost
oneadvisor.
instructor student
advisor
ID ID
name name
salary tot_cred
(a) One-to-one
instructor student
advisor
ID ID
name name
salary tot_cred
(b) One-to-many
instructor student
advisor
ID ID
name name
salary tot_cred
(c) Many-to-one
instructor student
advisor
ID ID
name name
salary tot_cred
(d) Many-to-many
Figure 6.11 Relationshipcardinalities.

--- Page 284 ---

6.4 MappingCardinalities 255
• One-to-many.Wedrawadirectedlinefromtherelationshipsettothe“one”sideof
therelationship.Thus,inFigure6.11b,thereisadirectedlinefromrelationshipset
advisor totheentitysetinstructor,andanundirectedlinetotheentitysetstudent.
Thisindicatesthataninstructormayadvisemanystudents,butastudentmayhave
atmostoneadvisor.
• Many-to-one. We draw a directed line from the relationship set to the “one” side
of the relationship. Thus, in Figure 6.11c, there is an undirected line from the
relationshipsetadvisor totheentitysetinstructor andadirectedlinetotheentity
setstudent. Thisindicatesthat an instructor may advise at most one student, but
astudentmayhavemanyadvisors.
• Many-to-many.Wedrawanundirectedlinefromtherelationshipsettobothentity
sets. Thus, in Figure 6.11d, there are undirected lines from the relationship set
advisor tobothentitysetsinstructor andstudent.Thisindicatesthataninstructor
mayadvisemanystudents,andastudentmayhavemanyadvisors.
TheparticipationofanentitysetEinarelationshipsetRissaidtobetotalifevery
entityinE mustparticipateinatleastonerelationshipinR.Ifitispossiblethatsome
entitiesinE donotparticipateinrelationshipsinR,theparticipationofentitysetE in
relationshipRissaidtobepartial.
For example, a university may require every student to have at least one advisor;
in the E-R model, this corresponds to requiring each entity to be related to at least
oneinstructorthroughtheadvisorrelationship.Therefore,theparticipationofstudent
in the relationship set advisor is total. In contrast, an instructor need not advise any
students.Hence,itispossiblethatonlysomeoftheinstructorentitiesarerelatedtothe
studententitysetthroughtheadvisorrelationship,andtheparticipationofinstructorin
theadvisor relationshipsetisthereforepartial.
Weindicatetotalparticipationofanentityinarelationshipsetusingdoublelines.
Figure 6.12 shows an example of the advisor relationship set where the double line
indicatesthatastudentmusthaveanadvisor.
E-Rdiagramsalsoprovideawaytoindicatemorecomplexconstraintsonthenum-
ber of times each entity participates in relationships in a relationship set. A line may
haveanassociatedminimumandmaximumcardinality,shownintheforml..h,wherel
instructor student
ID advisor ID
name name
salary tot_cred
Figure 6.12 E-Rdiagramshowingtotalparticipation.

--- Page 285 ---

256 Chapter6 DatabaseDesignUsingtheE-RModel
instructor student
ID 0..* advisor 1..1 ID
name name
salary tot_cred
Figure 6.13 Cardinalitylimitsonrelationshipsets.
istheminimumandhthemaximumcardinality.Aminimumvalueof1indicatestotal
participation of the entity set in the relationship set; that is, each entity in the entity
set occurs in at least one relationship in that relationship set. A maximum value of
1 indicates that the entity participates in at most one relationship, while a maximum
value∗indicatesnolimit.
Forexample,considerFigure6.13.Thelinebetweenadvisorandstudenthasacar-
dinality constraint of 1..1, meaning the minimum and the maximum cardinality are
both 1. That is, each student must have exactly one advisor. The limit 0.. ∗ on the
linebetweenadvisor andinstructor indicatesthatan instructorcanhavezeroormore
students. Thus, the relationship advisor is one-to-many from instructor to student, and
furthertheparticipationofstudentinadvisoristotal,implyingthatastudentmusthave
anadvisor.
Itiseasytomisinterpretthe0.. ∗ontheleftedgeandthinkthattherelationshipad-
visorismany-to-onefrominstructortostudent—thisisexactlythereverseofthecorrect
interpretation.
Ifbothedgeshaveamaximumvalueof1,therelationshipisone-to-one.Ifwehad
specified a cardinality limit of 1.. ∗ on the left edge, we would be saying that each
instructormustadviseatleastonestudent.
TheE-RdiagraminFigure6.13couldalternativelyhavebeendrawnwithadouble
linefromstudenttoadvisor,andanarrowonthelinefromadvisortoinstructor,inplace
ofthecardinalityconstraintsshown.Thisalternativediagramwouldenforceexactlythe
sameconstraintsastheconstraintsshowninthefigure.
In thecase of nonbinaryrelationshipsets, wecan specify some types ofmany-to-
one relationships. Suppose a student can have at most one instructor as a guide on a
project.Thisconstraintcanbespecifiedbyanarrowpointingtoinstructorontheedge
fromproj guide.
We permit at most one arrow out of a nonbinary relationship set, since an E-R
diagramwithtwoormorearrowsoutofanonbinaryrelationshipsetcanbeinterpreted
intwoways.WeelaborateonthisissueinSection6.5.2.
6.5 Primary Key
Wemusthaveawaytospecifyhowentitieswithinagivenentitysetandrelationships
withinagivenrelationshipsetaredistinguished.

--- Page 286 ---

6.5 PrimaryKey 257
6.5.1 Entity Sets
Conceptually,individualentitiesaredistinct;fromadatabaseperspective,however,the
differencesamongthemmustbeexpressedintermsoftheirattributes.
Therefore,thevaluesoftheattributevaluesofanentitymustbesuchthattheycan
uniquelyidentifytheentity.Inotherwords,notwoentitiesinanentitysetareallowed
tohaveexactlythesamevalueforallattributes.
Thenotionofakeyforarelationschema,asdefinedinSection2.3,appliesdirectly
toentitysets.Thatis,akeyforanentityisasetofattributesthatsufficetodistinguish
entitiesfromeachother.Theconceptsofsuperkey,candidatekey,andprimarykeyare
applicabletoentitysetsjustastheyareapplicabletorelationschemas.
Keysalsohelptoidentifyrelationshipsuniquely,andthusdistinguishrelationships
fromeachother.Next,wedefinethecorrespondingnotionsofkeysforrelationshipsets.
6.5.2 Relationship Sets
Weneedamechanismtodistinguishamongthevariousrelationshipsofarelationship
set.
LetRbearelationshipsetinvolvingentitysetsE , E ,…,E .Letprimary-key(E)
1 2 n i
denote the set of attributes that forms the primary key for entity set E. Assume for
i
now that the attribute names of all primary keys are unique. The composition of the
primarykeyforarelationshipsetdependsonthesetofattributesassociatedwiththe
relationshipsetR.
IftherelationshipsetRhasnoattributesassociatedwithit,thenthesetofattributes
primary-key(E )∪primary-key(E )∪⋯∪primary-key(E )
1 2 n
describesanindividualrelationshipinsetR.
IftherelationshipsetRhasattributesa ,a ,…,a associatedwithit,thentheset
1 2 m
ofattributes
primary-key(E )∪primary-key(E )∪⋯∪primary-key(E ) ∪{a ,a ,…,a }
1 2 n 1 2 m
describesanindividualrelationshipinsetR.
If the attribute names of primary keys are not unique across entity sets, the at-
tributes are renamed to distinguish them; the name of the entity set combined with
thenameoftheattributewouldformauniquename.Ifanentitysetparticipatesmore
thanonceinarelationshipset(asintheprereqrelationshipinSection6.2.2),therole
nameisusedinsteadofthenameoftheentityset,toformauniqueattributename.
Recallthatarelationshipsetisasetofrelationshipinstances,andeachinstanceis
uniquelyidentifiedbytheentitiesthatparticipateinit.Thus,inbothofthepreceding
cases,thesetofattributes
primary-key(E )∪primary-key(E )∪⋯∪primary-key(E )
1 2 n
formsasuperkeyfortherelationshipset.

--- Page 287 ---

258 Chapter6 DatabaseDesignUsingtheE-RModel
The choice of the primary key for a binary relationship set depends on the map-
pingcardinalityoftherelationshipset.Formany-to-manyrelationships,thepreceding
union of the primary keys is a minimal superkey and is chosen as the primary key.
As an illustration, considerthe entity sets instructor and student,and the relationship
set advisor, in Section 6.2.2. Suppose that the relationship set is many-to-many. Then
the primary key of advisor consists of the union of the primary keys of instructor and
student.
Forone-to-manyandmany-to-onerelationships,theprimarykeyofthe“many”side
isaminimalsuperkeyandisusedastheprimarykey.Forexample,iftherelationship
is many-to-one from student to instructor—that is, each student can have at most one
advisor—thentheprimarykeyofadvisorissimplytheprimarykeyofstudent.However,
ifaninstructorcanadviseonlyonestudent—thatis,iftheadvisorrelationshipismany-
to-onefrominstructortostudent—thentheprimarykeyofadvisorissimplytheprimary
keyofinstructor.
For one-to-one relationships, the primary key of either one of the participating
entity sets forms a minimal superkey, and either one can be chosen as the primary
keyoftherelationshipset.However,ifaninstructorcanadviseonlyonestudent,and
eachstudentcanbeadvisedbyonlyoneinstructor—thatis,iftheadvisor relationship
isone-to-one—thentheprimarykeyofeitherstudentorinstructorcanbechosenasthe
primarykeyforadvisor.
Fornonbinaryrelationships,ifnocardinalityconstraintsarepresent,thenthesu-
perkey formed as described earlier in this section is the only candidate key, and it is
chosenastheprimarykey.Thechoiceoftheprimarykeyismorecomplicatedifcardi-
nalityconstraintsarepresent.AswenotedinSection6.4,wepermitatmostonearrow
outofarelationshipset.WedosobecauseanE-Rdiagramwithtwoormorearrowsout
ofanonbinaryrelationshipsetcanbeinterpretedinthetwowayswedescribebelow.
SupposethereisarelationshipsetRbetweenentitysetsE ,E ,E ,E ,andtheonly
1 2 3 4
arrowsareontheedgestoentitysetsE andE .Then,thetwopossibleinterpretations
3 4
are:
1. Aparticularcombinationofentitiesfrom E ,E canbeassociated withatmost
1 2
one combination of entitiesfrom E ,E . Thus, the primarykey for the relation-
3 4
shipRcanbeconstructedbytheunionoftheprimarykeysofE andE .
1 2
2. A particular combination of entities from E ,E ,E can be associated with at
1 2 3
mostonecombinationofentitiesfromE ,andfurtheraparticularcombination
4
of entities from E ,E ,E can be associated with at most one combination of
1 2 4
entities from E , Then the union of the primary keys of E ,E , and E forms a
3 1 2 3
candidatekey,asdoestheunionoftheprimarykeysofE ,E ,andE .
1 2 4
Eachoftheseinterpretationshasbeenusedinpracticeandbotharecorrectforparticu-
larenterprisesbeingmodeled.Thus,toavoidconfusion,wepermitonlyonearrowout
ofanonbinaryrelationshipset,inwhichcasethetwointerpretationsareequivalent.

--- Page 288 ---

6.5 PrimaryKey 259
Inordertorepresentasituationwhereoneofthemultiple-arrowsituationsholds,
the E-R design can be modified by replacing the non-binary relationship set with an
entityset.Thatis,wetreateachinstanceofthenon-binaryrelationshipsetasanentity.
Then we can relate each of those entities to corresponding instances of E ,E ,E via
1 2 4
separaterelationshipsets.Asimplerapproachistousefunctionaldependencies,which
we study in Chapter 7 (Section 7.4). Functional dependencies which allow either of
theseinterpretationstobespecifiedsimplyinanunambiguousmanner.
TheprimarykeyfortherelationshipsetRisthentheunionoftheprimarykeysof
thoseparticipatingentitysetsE thatdonothaveanincomingarrowfromtherelation-
i
shipsetR.
6.5.3 Weak Entity Sets
Considerasection entity,whichisuniquelyidentifiedbyacourseidentifier,semester,
year, and sectionidentifier.Sectionentitiesare relatedtocourse entities.Suppose we
createarelationshipsetsec coursebetweenentitysetssectionandcourse.
Now,observethattheinformationinsec courseisredundant,sincesectionalready
hasanattributecourse id,whichidentifiesthecoursewithwhichthesectionisrelated.
One option to deal with this redundancy is to get rid of the relationship sec course;
however, by doing so the relationship between section and course becomes implicitin
anattribute,whichisnotdesirable.
Analternativewaytodealwiththisredundancyistonotstoretheattributecourse
id in the section entity and to only store the remaining attributes sec id, year, and
semester.2 However,theentitysetsectionthendoesnothaveenoughattributestoiden-
tifyaparticularsectionentityuniquely;althougheachsectionentityisdistinct,sections
for different courses may share the same sec id, year, and semester. To deal with this
problem,wetreattherelationshipsec courseasaspecialrelationshipthatprovidesextra
information,inthiscasethecourse id,requiredtoidentifysectionentitiesuniquely.
The notion of weak entity set formalizes the above intuition. A weak entity set is
onewhoseexistenceisdependentonanotherentityset,calleditsidentifyingentityset;
insteadofassociatingaprimarykeywithaweakentity,weusetheprimarykeyofthe
identifyingentity,alongwithextraattributes,calleddiscriminatorattributestouniquely
identifyaweakentity.Anentitysetthatisnotaweakentitysetistermedastrongentity
set.
Every weak entity must be associated with an identifyingentity; that is, the weak
entitysetissaidtobeexistencedependentontheidentifyingentityset.Theidentifying
entitysetissaidtoowntheweakentitysetthatitidentifies.Therelationshipassociating
theweakentitysetwiththeidentifyingentitysetiscalledtheidentifyingrelationship.
Theidentifyingrelationshipismany-to-onefromthe weakentitysettotheidenti-
fyingentityset,andtheparticipationoftheweakentitysetintherelationshipistotal.
2Notethattherelationalschemaweeventuallycreatefromtheentitysetsectiondoeshavetheattributecourseid,for
reasonsthatwillbecomeclearlater,eventhoughwehavedroppedtheattributecourseidfromtheentitysetsection.

--- Page 289 ---

260 Chapter6 DatabaseDesignUsingtheE-RModel
The identifying relationship set should not have any descriptive attributes, since any
suchattributescaninsteadbeassociatedwiththeweakentityset.
Inourexample,theidentifyingentitysetforsectioniscourse,andtherelationship
sec course,whichassociatessectionentitieswiththeircorrespondingcourseentities,is
the identifying relationship. The primary key of section is formed by the primary key
of the identifyingentityset(that is, course), plus the discriminatorofthe weakentity
set(thatis,section).Thus,theprimarykeyis{course id,sec id,year,semester}.
Note thatwecould have chosentomake sec id globallyunique acrossallcourses
offeredintheuniversity,inwhichcasethesectionentitysetwouldhavehadaprimary
key. However, conceptually, a section is still dependent on a course for its existence,
whichismadeexplicitbymakingitaweakentityset.
InE-Rdiagrams,a weakentitysetisdepicted viaadouble rectangle withthe dis-
criminator being underlined with a dashed line. The relationship set connecting the
weakentitysettotheidentifyingstrongentitysetisdepictedbyadoublediamond.In
Figure6.14,the weakentitysetsection dependsonthe strongentityset courseviathe
relationshipsetsec course.
Thefigurealsoillustratestheuseofdoublelinestoindicatethattheparticipation
ofthe(weak)entitysetsectionintherelationshipsec courseistotal,meaningthatevery
sectionmustberelatedviasec coursetosomecourse.Finally,thearrowfromsec course
tocourseindicatesthateachsectionisrelatedtoasinglecourse.
Ingeneral,aweakentitysetmusthaveatotalparticipationinitsidentifyingrela-
tionshipset,andtherelationshipismany-to-onetowardtheidentifyingentityset.
A weak entity set can participate in relationships other than the identifying rela-
tionship. For instance, the section entity could participate in a relationship with the
time slot entityset,identifyingthetimewhenaparticularclasssectionmeets.Aweak
entitysetmayparticipateasownerinanidentifyingrelationshipwithanotherweaken-
tityset.Itisalsopossibletohaveaweakentitysetwithmorethanoneidentifyingentity
set.Aparticularweakentitywouldthenbeidentifiedbyacombinationofentities,one
fromeachidentifyingentityset.Theprimarykeyoftheweakentitysetwouldconsist
of the union of the primary keys of the identifying entity sets, plus the discriminator
oftheweakentityset.
course
section
course_id
sec_course sec_id
title
semester
credits
year
Figure 6.14 E-Rdiagramwithaweakentityset.

--- Page 290 ---

6.6 RemovingRedundantAttributesinEntitySets 261
6.6 Removing Redundant Attributes in Entity Sets
WhenwedesignadatabaseusingtheE-Rmodel,weusuallystartbyidentifyingthose
entity sets that should be included. For example, in the university organization we
have discussed thus far, we decided to include such entity sets as student and instruc-
tor.Oncetheentitysetsaredecidedupon,wemustchoosetheappropriateattributes.
Theseattributesaresupposedtorepresentthevariousvalueswewanttocaptureinthe
database.Intheuniversityorganization,wedecidedthatfortheinstructorentityset,we
will include the attributes ID, name, dept name, and salary. We could have added the
attributesphone number,office number,home page,andothers.Thechoiceofwhatat-
tributestoincludeisuptothedesigner,whohasagoodunderstandingofthestructure
oftheenterprise.
Once the entities and their corresponding attributes are chosen, the relationship
setsamongthevariousentitiesareformed.Theserelationshipsetsmayresultinasitu-
ationwhereattributesinthevariousentitysetsareredundantandneedtoberemoved
fromtheoriginalentitysets.Toillustrate,considertheentitysetsinstructoranddepart-
ment:
• The entity set instructor includes the attributes ID, name, dept name, and salary,
withIDformingtheprimarykey.
• Theentitysetdepartment includestheattributes dept name,building,andbudget,
withdept nameformingtheprimarykey.
Wemodelthefactthateachinstructorhasanassociateddepartmentusingarelation-
shipsetinst deptrelatinginstructor anddepartment.
Theattributedept nameappearsinbothentitysets.Sinceitistheprimarykeyfor
the entity set department, it is redundant in the entity set instructor and needs to be
removed.
Removingtheattributedept namefromtheinstructor entitysetmayappearrather
unintuitive, since the relation instructor that we used in the earlier chapters had an
attributedept name.Asweshallseelater,whenwecreatearelationalschemafromthe
E-R diagram, the attribute dept name in fact gets added to the relation instructor, but
onlyifeachinstructorhasatmostoneassociateddepartment.Ifaninstructorhasmore
thanoneassociateddepartment,therelationshipbetweeninstructorsanddepartments
isrecordedinaseparaterelationinst dept.
Treatingtheconnectionbetweeninstructorsanddepartmentsuniformlyasarela-
tionship,ratherthanasanattributeofinstructor,makesthelogicalrelationshipexplicit,
andithelpsavoidaprematureassumptionthateachinstructorisassociatedwithonly
onedepartment.
Similarly,the student entity set is related to the department entity set through the
relationshipsetstudentdept andthusthereisnoneedforadept nameattributeinstu-
dent.

--- Page 291 ---

262 Chapter6 DatabaseDesignUsingtheE-RModel
Asanotherexample,considercourseofferings(sections)alongwiththetimeslots
of the offerings. Each time slot is identified by a time slot id, and has associated with
it a set of weekly meetings, each identified by a day of the week, start time, and end
time.Wedecidetomodelthesetofweeklymeetingtimesasamultivaluedcomposite
attribute.Supposewemodelentitysetssectionandtime slotasfollows:
• Theentitysetsectionincludestheattributescourse id,sec id,semester,year,build-
ing,room number,andtime slot id,with(course id,sec id,year,semester)forming
theprimarykey.
• The entity set time slot includes the attributes time slot id, which is the primary
key,3 andamultivaluedcompositeattribute{(day,start time,end time)}.4
Theseentitiesarerelatedthroughtherelationshipsetsec time slot.
Theattributetime slot idappearsinbothentitysets.Sinceitistheprimarykeyfor
theentitysettime slot,itisredundantintheentitysetsectionandneedstoberemoved.
Asafinalexample,supposewehaveanentitysetclassroom,withattributesbuilding,
room number, and capacity, with building and room number forming the primary key.
Suppose alsothatwehavearelationshipsetsec classthatrelatessectiontoclassroom.
Thentheattributes{building,room number}areredundantintheentitysetsection.
A good entity-relationship design does not contain redundant attributes. For our
universityexample,welisttheentitysetsandtheirattributesbelow,withprimarykeys
underlined:
• classroom:withattributes(building,room number,capacity).
• department:withattributes(dept name,building,budget).
• course:withattributes(course id,title,credits).
• instructor:withattributes(ID,name,salary).
• section:withattributes(course id,sec id,semester,year).
• student:withattributes(ID,name,tot cred).
• time slot:withattributes(time slot id,{(day,start time,end time)}).
Therelationshipsetsinourdesignarelistedbelow:
• inst dept:relatinginstructorswithdepartments.
• stud dept:relatingstudentswithdepartments.
3Weshallseelateronthattheprimarykeyfortherelationcreatedfromtheentitysettimeslotincludesdayandstart
time;however,dayandstarttimedonotformpartoftheprimarykeyoftheentitysettimeslot.
4Wecouldoptionallygiveaname,suchasmeeting,forthecompositeattributecontainingday,starttime,andendtime.

--- Page 292 ---

6.6 RemovingRedundantAttributesinEntitySets 263
• teaches:relatinginstructorswithsections.
• takes:relatingstudentswithsections,withadescriptiveattributegrade.
• course dept:relatingcourseswithdepartments.
• sec course:relatingsectionswithcourses.
• sec class:relatingsectionswithclassrooms.
• sec time slot:relatingsectionswithtimeslots.
• advisor:relatingstudentswithinstructors.
• prereq:relatingcourseswithprerequisitecourses.
Youcanverifythatnoneoftheentitysetshasanyattributethatismaderedundant
byoneoftherelationshipsets.Further,youcanverifythatalltheinformation(other
than constraints) in the relational schema for our university database, which we saw
earlierinFigure2.9,hasbeencapturedbytheabovedesign,butwithseveralattributes
intherelationaldesignreplacedbyrelationshipsintheE-Rdesign.
Wearefinallyinapositiontoshow(Figure6.15)theE-Rdiagramthatcorresponds
totheuniversityenterprisethatwehavebeenusingthusfarinthetext.ThisE-Rdiagram
is equivalent to the textual description of the university E-R model, but with several
additionalconstraints.
In our university database, we have a constraint that each instructor must have
exactly one associated department. As a result, there is a double line in Figure 6.15
betweeninstructor andinst dept,indicatingtotalparticipationofinstructor ininst dept;
that is, each instructor must be associated with a department. Further, there is an ar-
rowfrominst depttodepartment,indicatingthateachinstructorcanhaveatmostone
associateddepartment.
Similarly,entitysetcoursehasadoublelinetorelationshipsetcourse dept,indicat-
ingthateverycoursemustbeinsomedepartment,andentitysetstudenthasadouble
linetorelationshipsetstud dept,indicatingthateverystudentmustbemajoringinsome
department. Ineach case,an arrow points tothe entitysetdepartment toshow thata
course(and,respectively,astudent)canberelatedtoonlyonedepartment,notseveral.
Similarly,entitysetcoursehasadoublelinetorelationshipsetcourse dept,indicat-
ingthateverycoursemustbeinsomedepartment,andentitysetstudenthasadouble
linetorelationshipsetstud dept,indicatingthateverystudentmustbemajoringinsome
department. Ineach case,an arrow points tothe entitysetdepartment toshow thata
course(and,respectively,astudent)canberelatedtoonlyonedepartment,notseveral.
Further,Figure6.15showsthattherelationshipsettakeshasadescriptiveattribute
grade,andthateachstudenthasatmostoneadvisor.Thefigurealsoshowsthatsection
isaweakentityset,withattributessec id,semester,andyearformingthediscriminator;
sec courseistheidentifyingrelationshipsetrelatingweakentitysetsectiontothestrong
entitysetcourse.

--- Page 293 ---

264 Chapter6 DatabaseDesignUsingtheE-RModel
department
course_dept dept_name
building
budget
inst_dept stud_dept
instructor student
ID advisor ID
name name
salary tot_cred
teaches takes grade
section
course time_slot
sec_id
course_id sec_course semester sec_time_slot time_slot_id
title year { day
credits start_time
end_time
}
prereq
course_id prereq_id sec_class
classroom
building
room_number
capacity
Figure 6.15 E-Rdiagramforauniversityenterprise.
In Section 6.7, we show how this E-R diagram can be used to derive the various
relationschemasweuse.
6.7 Reducing E-R Diagrams to Relational Schemas
BoththeE-Rmodelandtherelationaldatabasemodelareabstract,logicalrepresenta-
tions of real-world enterprises. Because the two models employ similar design princi-
ples,wecanconvertanE-Rdesignintoarelationaldesign.Foreachentitysetandfor
eachrelationshipsetinthedatabasedesign,thereisauniquerelationschematowhich
weassignthenameofthecorrespondingentitysetorrelationshipset.

--- Page 294 ---

6.7 ReducingE-RDiagramstoRelationalSchemas 265
In this section, we describe how an E-R schema can be represented by relation
schemasandhowconstraintsarisingfromtheE-Rdesigncanbemappedtoconstraints
onrelationschemas.
6.7.1 Representation of Strong Entity Sets
Let E be a strong entity set with only simple descriptive attributes a , a ,…,a . We
1 2 n
representthisentitywithaschemacalledE withndistinctattributes.Eachtupleina
relationonthisschemacorrespondstooneentityoftheentitysetE.
Forschemasderivedfromstrongentitysets,theprimarykeyoftheentitysetserves
astheprimarykeyoftheresultingschema.Thisfollowsdirectlyfromthefactthateach
tuplecorrespondstoaspecificentityintheentityset.
Asanillustration,considertheentitysetstudentoftheE-RdiagraminFigure6.15.
Thisentitysethasthreeattributes:ID,name,tot cred.Werepresentthisentitysetbya
schemacalledstudent withthreeattributes:
student(ID,name,tot cred)
NotethatsincestudentIDistheprimarykeyoftheentityset,itisalsotheprimarykey
oftherelationschema.
Continuing with our example, for the E-R diagram in Figure 6.15, all the strong
entity sets, except time slot, have only simple attributes. The schemas derived from
thesestrongentitysetsaredepictedinFigure6.16.Notethattheinstructor,student,and
course schemasare differentfrom the schemaswe have used in the previous chapters
(theydonotcontaintheattributedept name).Weshallrevisitthisissueshortly.
6.7.2 Representation of Strong Entity Sets with Complex Attributes
Whenastrongentitysethasnonsimpleattributes, thingsareabitmorecomplex.We
handlecompositeattributesbycreatingaseparateattributeforeachofthecomponent
attributes; we do not create a separate attribute for the composite attribute itself. To
illustrate,considertheversionoftheinstructorentitysetdepictedinFigure6.8.Forthe
composite attribute name, the schemagenerated for instructor contains the attributes
classroom(building,room number,capacity)
department(dept name,building,budget)
course(course id,title,credits)
instructor(ID,name,salary)
student(ID,name,tot cred)
Figure 6.16 SchemasderivedfromtheentitysetsintheE-RdiagraminFigure6.15.

--- Page 295 ---

266 Chapter6 DatabaseDesignUsingtheE-RModel
first name, middle initial, and last name; there is no separate attribute or schema for
name. Similarly, for the composite attribute address, the schema generated contains
theattributesstreet,city,state,andpostal code.Sincestreetisacompositeattributeitis
replacedbystreet number,street name,andapt number.
Multivalued attributes are treated differently from other attributes. We have seen
thatattributesinanE-Rdiagramgenerallymapdirectlyintoattributesfortheappropri-
ate relation schemas. Multivalued attributes, however, are an exception; new relation
schemasarecreatedfortheseattributes,asweshallseeshortly.
Derivedattributesarenotexplicitlyrepresentedintherelationaldatamodel.How-
ever,theycanberepresentedasstoredprocedures,functions,ormethodsinotherdata
models.
Therelationalschemaderivedfromtheversionofentitysetinstructorwithcomplex
attributes,withoutincludingthemultivaluedattribute,isthus:
instructor (ID,first name,middle initial,last name,
street number,street name,apt number,
city,state,postal code,dateof birth)
For a multivalued attribute M, we create a relation schema R with an attribute A
that corresponds to M and attributes corresponding to the primary key of the entity
setorrelationshipsetofwhichM isanattribute.
Asanillustration,considertheE-RdiagraminFigure6.8thatdepictstheentityset
instructor,whichincludesthemultivaluedattributephone number.Theprimarykeyof
instructor isID.Forthismultivaluedattribute,wecreatearelationschema
instructor phone(ID,phone number)
Eachphonenumberofaninstructorisrepresentedasauniquetupleintherelationon
thisschema.Thus,ifwehadaninstructorwithID22222,andphonenumbers555-1234
and 555-4321, the relation instructor phone would have two tuples (22222, 555-1234)
and(22222,555-4321).
We create a primary key of the relation schema consisting of all attributes of the
schema.Intheaboveexample,theprimarykeyconsistsofbothattributesoftherelation
schemainstructor phone.
Inaddition,wecreateaforeign-keyconstraintontherelationschemacreatedfrom
the multivalued attribute. In that newly created schema, the attribute generated from
theprimarykeyoftheentitysetmustreferencetherelationgeneratedfromtheentity
set. In the above example, the foreign-key constraint on the instructor phone relation
wouldbethatattributeIDreferencestheinstructor relation.
Inthecasethatanentitysetconsistsofonlytwoattributes—asingleprimary-key
attribute B and a single multivalued attribute M— the relation schema for the entity
setwouldcontainonlyoneattribute,namely,theprimary-keyattributeB.Wecandrop

--- Page 296 ---

6.7 ReducingE-RDiagramstoRelationalSchemas 267
this relation, while retaining the relation schema with the attribute B and attribute A
thatcorrespondstoM.
To illustrate, consider the entity set time slot depicted in Figure 6.15. Here, time
slot id is the primary key of the time slot entity set, and there is a single multivalued
attribute thathappens alsotobe composite. Theentitysetcanbe representedby just
thefollowingschemacreatedfromthemultivaluedcompositeattribute:
time slot(time slot id,day,start time,end time)
AlthoughnotrepresentedasaconstraintontheE-Rdiagram,weknowthattherecan-
notbetwomeetingsofaclassthatstartatthesametimeofthesamedayoftheweek
butendatdifferenttimes;basedonthisconstraint,end timehasbeenomittedfromthe
primarykeyofthetime slotschema.
The relation created from the entity set would have only a single attribute time
slot id; the optimization of dropping this relation has the benefit of simplifying the
resultant database schema, although it has a drawback related to foreign keys, which
webrieflydiscussinSection6.7.4.
6.7.3 Representation of Weak Entity Sets
Let A be aweak entityset withattributes a ,a ,…,a . Let B be the strong entity set
1 2 m
on whichA depends.Letthe primarykey of B consistof attributes b , b ,…,b . We
1 2 n
represent the entity set A by a relation schema called A with one attribute for each
memberoftheset:
{a ,a ,…,a }∪{b ,b ,…,b }
1 2 m 1 2 n
Forschemasderivedfromaweakentityset,thecombinationoftheprimarykeyof
thestrongentitysetandthediscriminatoroftheweakentitysetservesastheprimary
key of the schema. In addition to creatinga primary key, we also create a foreign-key
constraint on the relation A, specifying that the attributes b , b ,…,b reference the
1 2 n
primarykeyoftherelationB.Theforeign-keyconstraintensuresthatforeachtuplerep-
resentingaweakentity,thereisacorrespondingtuplerepresentingthecorresponding
strongentity.
Asanillustration,considertheweakentitysetsectionintheE-RdiagramofFigure
6.15. This entity set has the attributes: sec id, semester, and year. The primary key of
thecourseentityset,onwhichsectiondepends,iscourse id.Thus,werepresentsection
byaschemawiththefollowingattributes:
section(course id,sec id,semester,year)
The primary key consists of the primary key of the entity set course, along with the
discriminatorofsection,whichissec id,semester,andyear.Wealsocreateaforeign-key

--- Page 297 ---

268 Chapter6 DatabaseDesignUsingtheE-RModel
constraint on the section schema, with the attribute course id referencingthe primary
keyofthecourseschema.5
6.7.4 Representation of Relationship Sets
LetRbearelationshipset,leta ,a ,…,a bethesetofattributesformedbytheunion
1 2 m
oftheprimarykeysofeachoftheentitysetsparticipatinginR,andletthedescriptive
attributes(ifany)ofRbeb ,b ,…,b .Werepresentthisrelationshipsetbyarelation
1 2 n
schemacalledRwithoneattributeforeachmemberoftheset:
{a ,a ,…,a }∪{b ,b ,…,b }
1 2 m 1 2 n
WedescribedinSection6.5,howtochooseaprimarykeyforabinaryrelationship
set.Theprimarykeyattributesoftherelationshipsetarealsousedastheprimarykey
attributesoftherelationalschemaR.
Asanillustration,considertherelationshipsetadvisorintheE-RdiagramofFigure
6.15.Thisrelationshipsetinvolvesthefollowingentitysets:
• instructor,withtheprimarykeyID.
• student,withtheprimarykeyID.
Sincetherelationshipsethasnoattributes,theadvisor schemahastwoattributes,the
primarykeysofinstructorandstudent.Sincebothattributeshavethesamename,were-
namethemi IDands ID.Sincetheadvisorrelationshipsetismany-to-onefromstudent
toinstructor theprimarykeyfortheadvisor relationschemaiss ID.
Wealsocreateforeign-keyconstraintsontherelationschemaRasfollows:Foreach
entitysetE relatedbyrelationshipsetR,wecreateaforeign-keyconstraintfromrela-
i
tion schema R, with the attributes of R that werederived from primary-key attributes
ofE referencingtheprimarykeyoftherelationschemarepresentingE.
i i
Returning to our earlier example, we thus create two foreign-key constraints on
the advisor relation, with attribute i ID referencing the primary key of instructor and
attributes IDreferencingtheprimarykeyofstudent.
ApplyingtheprecedingtechniquestotheotherrelationshipsetsintheE-Rdiagram
inFigure6.15,wegettherelationalschemasdepictedinFigure6.17.
Observe that for the case of the relationship set prereq, the role indicators asso-
ciated with the relationship are used as attribute names, since both roles refer to the
samerelationcourse.
Similartothecaseofadvisor,theprimarykeyforeachoftherelationssec course,
sec time slot, sec class, inst dept, stud dept, and course dept consists of the primary key
5Optionally,theforeign-keyconstraintcouldhavean“ondeletecascade”specification,sothatdeletionofacourse
entityautomaticallydeletesanysectionentitiesthatreferencethecourseentity.Withoutthatspecification,eachsection
ofacoursewouldhavetobedeletedbeforethecorrespondingcoursecanbedeleted.

--- Page 298 ---

6.7 ReducingE-RDiagramstoRelationalSchemas 269
teaches(ID,course id,sec id,semester,year)
takes(ID,course id,sec id,semester,year,grade)
prereq(course id,prereq id)
advisor (s ID,i ID)
sec course(course id,sec id,semester,year)
sec time slot(course id,sec id,semester,year,time slot id)
sec class(course id,sec id,semester,year,building,room number)
inst dept(ID,dept name)
stud dept(ID,dept name)
course dept(course id,dept name)
Figure 6.17 SchemasderivedfromrelationshipsetsintheE-RdiagraminFigure6.15.
ofonlyoneofthetworelatedentitysets,sinceeachofthecorrespondingrelationships
ismany-to-one.
Foreign keys are not shown in Figure 6.17, but for each of the relations in the
figuretherearetwoforeign-keyconstraints,referencingthetworelationscreatedfrom
the two related entity sets. Thus, for example, sec course has foreign keys referencing
section and classroom, teaches has foreign keys referencing instructor and section, and
takeshasforeignkeysreferencingstudentandsection.
Theoptimizationthatallowedustocreateonlyasinglerelationschemafromthe
entitysettime slot,whichhadamultivaluedattribute,preventsthecreationofaforeign
key from the relation schema sec time slot to the relation created from entity set time
slot,sincewedroppedtherelationcreatedfromtheentitysettime slot.Weretainedthe
relationcreatedfromthemultivaluedattributeandnamedittime slot,butthisrelation
maypotentiallyhavenotuplescorrespondingtoatime slot id,oritmayhavemultiple
tuplescorrespondingtoatime slot id;thus,time slot idinsec time slotcannotreference
thisrelation.
The astute reader may wonder why we have not seen the schemas sec course, sec
time slot, sec class, inst dept, stud dept, and course dept in the previous chapters. The
reason is that the algorithm we have presented thus far results in some schemas that
canbeeithereliminatedorcombinedwithotherschemas.Weexplorethisissuenext.
6.7.5 Redundancy of Schemas
A relationship set linking a weak entity set to the corresponding strong entity set is
treatedspecially.AswenotedinSection6.5.3,theserelationshipsaremany-to-oneand
have no descriptive attributes. Furthermore, the of a weak entity set includes the pri-
marykeyofthestrongentityset.IntheE-RdiagramofFigure6.14,theweakentityset
section is dependent on the strong entity set course via the relationship set sec course.

--- Page 299 ---

270 Chapter6 DatabaseDesignUsingtheE-RModel
Theprimarykeyofsectionis{course id,sec id,semester,year},andtheprimarykeyof
courseiscourse id.Sincesec coursehasnodescriptiveattributes,thesec courseschema
has attributes course id, sec id, semester, and year. The schema for the entity set sec-
tionincludestheattributes course id,sec id,semester,andyear (amongothers).Every
(course id, sec id, semester, year) combination in a sec course relation would also be
presentintherelationonschemasection,andviceversa.Thus,thesec courseschema
isredundant.
Ingeneral,theschemafortherelationshipsetlinkingaweakentitysettoitscorre-
spondingstrongentitysetisredundantanddoesnotneedtobepresentinarelational
databasedesignbaseduponanE-Rdiagram.
6.7.6 Combination of Schemas
Consideramany-to-onerelationshipsetABfromentitysetAtoentitysetB.Usingour
relational-schemaconstructionalgorithmoutlinedpreviously,wegetthreeschemas:A,
B,andAB.SupposefurtherthattheparticipationofAintherelationshipistotal;that
is, every entity a in the entity set A must participate in the relationship AB. Then we
cancombinetheschemasAandABtoformasingleschemaconsistingoftheunionof
attributes of both schemas. The primary key of the combined schema is the primary
keyoftheentitysetintowhoseschematherelationshipsetschemawasmerged.
Toillustrate, let’sexamine thevariousrelationsintheE-RdiagramofFigure6.15
thatsatisfytheprecedingcriteria:
• inst dept. The schemas instructor and department correspond to the entity sets A
andB,respectively.Thus,theschemainst deptcanbecombinedwiththeinstructor
schema.Theresultinginstructor schemaconsistsoftheattributes {ID,name,dept
name,salary}.
• stud dept. The schemas student and department correspond to the entity sets A
andB,respectively.Thus,theschemastud deptcanbecombinedwiththestudent
schema. The resulting student schema consists of the attributes {ID, name, dept
name,tot cred}.
• course dept. The schemas course and department correspond to the entity sets A
andB,respectively.Thus,theschemacourse deptcanbecombinedwiththecourse
schema.Theresultingcourseschemaconsistsoftheattributes{course id,title,dept
name,credits}.
• sec class.TheschemassectionandclassroomcorrespondtotheentitysetsAandB,
respectively.Thus,theschemasec classcanbecombinedwiththesectionschema.
Theresultingsectionschemaconsistsoftheattributes{course id,sec id,semester,
year,building,room number}.
• sec time slot.Theschemassectionandtime slotcorrespondtotheentitysetsAand
B respectively, Thus, the schema sec time slot can be combined with the section

--- Page 300 ---

6.8 ExtendedE-RFeatures 271
schemaobtainedinthepreviousstep.Theresultingsectionschemaconsistsofthe
attributes{course id,sec id,semester,year,building,room number,time slot id}.
Inthecaseofone-to-onerelationships,therelationschemafortherelationshipset
canbecombinedwiththeschemasforeitheroftheentitysets.
We can combine schemas even if the participation is partial by using null values.
Intheprecedingexample,ifinst dept werepartial,thenwewouldstorenullvaluesfor
thedept nameattributeforthoseinstructorswhohavenoassociateddepartment.
Finally, we consider the foreign-key constraints that would have appeared in the
schema representing the relationship set. There would have been foreign-key con-
straintsreferencingeachoftheentitysetsparticipatingintherelationshipset.Wedrop
theconstraintreferencingtheentitysetintowhoseschematherelationshipsetschema
ismerged,andaddtheotherforeign-keyconstraintstothecombinedschema.Forex-
ample,inst depthasaforeignkeyconstraintoftheattributedept namereferencingthe
department relation. This foreign constraint is enforced implicitlyby the instructor re-
lationwhentheschemaforinst deptismergedintoinstructor.
6.8 Extended E-R Features
Although the basic E-R concepts can model most database features, some aspects of
adatabasemaybemoreaptlyexpressedbycertainextensionstothebasicE-Rmodel.
In thissection, we discuss the extended E-R features of specialization,generalization,
higher-andlower-levelentitysets,attributeinheritance,andaggregation.
To help with the discussions, we shall use a slightly more elaborate database
schema for the university. In particular, we shall model the various people within a
universitybydefininganentitysetperson,withattributesID,name,street,andcity.
6.8.1 Specialization
Anentitysetmayincludesubgroupings ofentitiesthataredistinctinsome wayfrom
otherentitiesintheset.Forinstance,asubsetofentitieswithinanentitysetmayhave
attributesthatarenotsharedbyalltheentitiesintheentityset.TheE-Rmodelprovides
ameansforrepresentingthesedistinctiveentitygroupings.
Asanexample,theentitysetpersonmaybefurtherclassifiedasoneofthefollow-
ing:
• employee.
• student.
Each of these person types is described by a set of attributes that includes all the at-
tributes ofentityset person pluspossiblyadditionalattributes. Forexample, employee
entitiesmaybe describedfurtherbytheattribute salary, whereasstudent entitiesmay

--- Page 301 ---

272 Chapter6 DatabaseDesignUsingtheE-RModel
bedescribedfurtherbytheattributetot cred.Theprocessofdesignatingsubgroupings
within an entity set is called specialization. The specialization of person allows us to
distinguishamongpersonentitiesaccordingtowhethertheycorrespondtoemployees
orstudents:ingeneral,apersoncouldbeanemployee,astudent,both,orneither.
As another example, suppose the university divides students into two categories:
graduate and undergraduate. Graduate students have an office assigned to them. Un-
dergraduatestudentsareassignedtoaresidentialcollege.Eachofthesestudenttypes
isdescribedbyasetofattributesthatincludesalltheattributesoftheentitysetstudent
plusadditionalattributes.
We can apply specialization repeatedly to refine a design. The university could
create two specializations of student, namely graduate and undergraduate. As we saw
earlier, student entities are described by the attributes ID, name, street, city, and tot
cred.Theentitysetgraduatewouldhavealltheattributesofstudentandanadditional
attribute office number. The entity set undergraduate would have all the attributes of
student, and an additional attribute residential college. As another example, university
employeesmaybefurtherclassifiedasoneofinstructor orsecretary.
Eachoftheseemployeetypesisdescribedbyasetofattributesthatincludesallthe
attributesofentitysetemployeeplusadditionalattributes.Forexample,instructorenti-
tiesmaybedescribedfurtherbytheattributerankwhilesecretaryentitiesaredescribed
bytheattributehours per week.Further,secretaryentitiesmayparticipateinarelation-
ship secretary for between the secretary and employee entity sets, which identifies the
employeeswhoareassistedbyasecretary.
An entity set may be specialized by more than one distinguishing feature. In our
example, the distinguishing feature among employee entities is the job the employee
performs.Another,coexistent,specializationcouldbebasedonwhetherthepersonis
atemporary(limitedterm)employeeorapermanentemployee,resultingintheentity
setstemporary employeeandpermanent employee.Whenmorethanonespecialization
is formed on an entity set, a particular entity may belong to multiple specializations.
Forinstance,agivenemployeemaybeatemporaryemployeewhoisasecretary.
IntermsofanE-Rdiagram,specializationisdepictedbyahollowarrow-headpoint-
ingfromthespecializedentitytotheotherentity(seeFigure6.18).Werefertothisre-
lationshipastheISArelationship,whichstandsfor“isa”andrepresents,forexample,
thataninstructor“isa”employee.
The way we depict specialization in an E-R diagram depends on whether an en-
tity may belong to multiple specialized entity sets or if it must belong to at most one
specialized entity set. The former case (multiple sets permitted) is called overlapping
specialization, while the latter case (at most one permitted) is called disjoint special-
ization. For an overlapping specialization (as is the case for student and employee as
specializations of person), two separate arrows are used. For a disjoint specialization
(asisthecaseforinstructorandsecretaryasspecializationsofemployee),asinglearrow
isused.Thespecializationrelationshipmayalsobereferredtoasasuperclass-subclass
relationship.Higher-andlower-levelentitysetsaredepictedasregularentitysets—that
is,asrectanglescontainingthenameoftheentityset.

--- Page 302 ---

6.8 ExtendedE-RFeatures 273
person
ID
name
street
city
employee student
salary tot_credits
instructor secretary
rank hours_ per_week
Figure 6.18 Specializationandgeneralization.
6.8.2 Generalization
The refinement from an initial entity set into successive levels of entity subgroupings
representsatop-downdesignprocessinwhichdistinctionsaremadeexplicit.Thedesign
process may also proceed in a bottom-up manner, in which multiple entity sets are
synthesizedintoahigher-levelentitysetonthebasisofcommonfeatures.Thedatabase
designermayhavefirstidentified:
• instructor entitysetwithattributes instructor id,instructor name,instructor salary,
andrank.
• secretaryentitysetwithattributessecretary id,secretary name,secretary salary,and
hours per week.
Therearesimilaritiesbetweentheinstructorentitysetandthesecretaryentitysetin
thesensethattheyhaveseveralattributesthatareconceptuallythesameacrossthetwo
entitysets:namely,theidentifier,name,andsalaryattributes.Thiscommonalitycanbe
expressedbygeneralization,whichisacontainmentrelationshipthatexistsbetweena
higher-levelentitysetandoneormorelower-levelentitysets.Inourexample,employeeis
thehigher-levelentitysetandinstructor andsecretaryarelower-levelentitysets.Inthis
case, attributes that are conceptually the same had different names in the two lower-
levelentitysets.Tocreateageneralization,theattributesmustbegivenacommonname
andrepresentedwiththehigher-levelentityperson.WecanusetheattributenamesID,
name,street,andcity,aswesawintheexampleinSection6.8.1.

--- Page 303 ---

274 Chapter6 DatabaseDesignUsingtheE-RModel
Higher-andlower-levelentitysetsalsomaybe designatedbythetermssuperclass
and subclass, respectively. The person entity set is the superclass of the employee and
studentsubclasses.
For all practical purposes, generalization is a simple inversion of specialization.
We apply both processes, in combination, in the course of designing the E-R schema
for an enterprise. In terms of the E-R diagram itself, we do not distinguish between
specializationandgeneralization.Newlevelsofentityrepresentationaredistinguished
(specialization)orsynthesized(generalization)asthedesignschemacomestoexpress
fully the database application and the user requirements of the database. Differences
inthetwoapproachesmaybecharacterizedbytheirstartingpointandoverallgoal.
Specializationstemsfromasingleentityset;itemphasizesdifferencesamongen-
titieswithinthe setbycreatingdistinctlower-levelentitysets.These lower-levelentity
sets may have attributes, or may participate in relationships, that do not apply to all
theentitiesinthehigher-levelentityset.Indeed,thereasonadesignerappliesspecial-
izationistorepresentsuchdistinctivefeatures.Ifstudentandemployeehaveexactlythe
sameattributes aspersonentities,and participateinexactlythesamerelationshipsas
personentities,therewouldbenoneedtospecializethepersonentityset.
Generalization proceeds from the recognition that a number of entity sets share
somecommonfeatures(namely,theyaredescribedbythesameattributesandpartici-
pateinthesamerelationshipsets).Onthebasisoftheircommonalities,generalization
synthesizestheseentitysetsintoasingle,higher-levelentityset.Generalizationisused
toemphasizethesimilaritiesamonglower-levelentitysetsandtohidethedifferences;
italsopermitsaneconomyofrepresentationinthatsharedattributesarenotrepeated.
6.8.3 Attribute Inheritance
Acrucialpropertyofthehigher-andlower-levelentitiescreatedbyspecializationand
generalizationisattribute inheritance. Theattributes ofthehigher-levelentitysetsare
saidtobeinheritedbythelower-levelentitysets.Forexample,studentandemployeein-
herittheattributesofperson.Thus,studentisdescribedbyitsID,name,street,andcity
attributes, and additionally a tot cred attribute; employee is described by its ID, name,
street,and city attributes, andadditionallya salary attribute. Attribute inheritanceap-
pliesthroughalltiersoflower-levelentitysets;thus,instructorandsecretary,whichare
subclasses of employee, inherit the attributes ID, name, street, and city from person, in
additiontoinheritingsalaryfromemployee.
Alower-levelentityset(orsubclass)alsoinheritsparticipationintherelationship
sets in which its higher-level entity (or superclass) participates. Like attribute inheri-
tance,participation inheritanceappliesthrough alltiersoflower-levelentitysets. For
example, suppose the person entity set participates in a relationship person dept with
department.Then,thestudent,employee,instructor andsecretaryentitysets,whichare
subclassesofthepersonentityset,alsoimplicitlyparticipateintheperson deptrelation-
ship with department. These entity sets can participate in any relationships in which
thepersonentitysetparticipates.

--- Page 304 ---

6.8 ExtendedE-RFeatures 275
Whethera given portion of an E-R model was arrived at by specialization or gen-
eralization,theoutcomeisbasicallythesame:
• A higher-level entity set with attributes and relationships that apply to all of its
lower-levelentitysets.
• Lower-levelentitysetswithdistinctivefeaturesthatapplyonlywithinaparticular
lower-levelentityset.
Inwhatfollows,althoughweoftenrefertoonlygeneralization,thepropertiesthat
wediscussbelongfullytobothprocesses.
Figure6.18depictsahierarchyofentitysets.Inthefigure,employeeisalower-level
entitysetofpersonandahigher-levelentitysetoftheinstructorandsecretaryentitysets.
Inahierarchy,agivenentitysetmaybeinvolvedasalower-levelentitysetinonlyone
ISA relationship; that is, entity sets in this diagram have only single inheritance. If an
entity set is a lower-levelentity set in more than one ISA relationship, then the entity
sethasmultipleinheritance,andtheresultingstructureissaidtobealattice.
6.8.4 Constraints on Specializations
To model an enterprise more accurately, the database designer may choose to place
certainconstraintsonaparticulargeneralization/specialization.
One type of constraint on specialization which we saw earlier specifies whether
a specialization is disjoint or overlapping. Another type of constraint on a specializa-
tion/generalizationisacompletenessconstraint,whichspecifieswhetherornotanen-
tityinthehigher-levelentitysetmustbelongtoatleastoneofthelower-levelentitysets
withinthegeneralization/specialization.Thisconstraintmaybeoneofthefollowing:
• Total specialization or generalization. Each higher-level entity must belong to a
lower-levelentityset.
• Partialspecializationorgeneralization.Somehigher-levelentitiesmaynotbelong
toanylower-levelentityset.
Partial specialization is the default. We can specify total specialization in an E-R dia-
grambyaddingthekeyword“total”inthediagramanddrawingadashedlinefromthe
keyword to the corresponding hollow arrowhead to which it applies (for a total spe-
cialization),ortothesetofhollowarrowheadstowhichitapplies(foranoverlapping
specialization).
Thespecializationofpersontostudentoremployeeistotaliftheuniversitydoesnot
needtorepresentanypersonwhoisneitherastudentnoranemployee.However,ifthe
universityneedstorepresentsuchpersons,thenthespecializationwouldbepartial.
Thecompletenessanddisjointnessconstraints,donotdependoneachother.Thus,
specializationsmaybepartial-overlapping,partial-disjoint,total-overlapping,andtotal-
disjoint.

--- Page 305 ---

276 Chapter6 DatabaseDesignUsingtheE-RModel
We can see thatcertain insertion and deletionrequirementsfollow from the con-
straintsthatapplytoagivengeneralizationorspecialization.Forinstance,whenatotal
completenessconstraintisinplace,anentityinsertedintoahigher-levelentitysetmust
alsobeinsertedintoatleastoneofthelower-levelentitysets.Anentitythatisdeleted
from a higher-level entity set must also be deleted from all the associated lower-level
entitysetstowhichitbelongs.
6.8.5 Aggregation
OnelimitationoftheE-Rmodelisthatitcannotexpressrelationshipsamongrelation-
ships.Toillustratetheneedforsuchaconstruct,considertheternaryrelationshipproj
guide,whichwesawearlier,betweenaninstructor,studentandproject(seeFigure6.6).
Nowsupposethateachinstructorguidingastudentonaprojectisrequiredtofile
a monthly evaluation report. We model the evaluation report as an entity evaluation,
with a primary key evaluation id. One alternative for recording the (student, project,
instructor) combination to which an evaluation corresponds is to create a quaternary
(4-way)relationshipseteval for betweeninstructor,student,project,andevaluation.(A
quaternaryrelationshipisrequired—abinaryrelationshipbetweenstudentandevalua-
tion,forexample,wouldnotpermitustorepresentthe(project,instructor)combination
towhichanevaluationcorresponds.)UsingthebasicE-Rmodelingconstructs,weob-
taintheE-RdiagramofFigure6.19.(Wehaveomittedtheattributesoftheentitysets,
forsimplicity.)
It appears that the relationship sets proj guide and eval for can be combined into
one single relationship set. Nevertheless, we should not combine them into a single
project
instructor student
proj_guide
eval_ for
evaluation
Figure 6.19 E-Rdiagramwithredundantrelationships.

--- Page 306 ---

6.8 ExtendedE-RFeatures 277
project
instructor student
proj_guide
eval_ for
evaluation
Figure 6.20 E-Rdiagramwithaggregation.
relationship, since some instructor, student, project combinations may not have an as-
sociatedevaluation.
Thereisredundantinformationintheresultantfigure,however,sinceeveryinstruc-
tor,student,projectcombinationineval formustalsobeinproj guide.Ifevaluationwas
modeled as a value rather than an entity, we could instead make evaluation a multi-
valuedcompositeattribute oftherelationshipsetproj guide.However,thisalternative
maynotbeanoptionifanevaluationmayalsoberelatedtootherentities;forexample,
eachevaluationreportmaybeassociatedwithasecretarywhoisresponsibleforfurther
processingoftheevaluationreporttomakescholarshippayments.
Thebestwaytomodelasituationsuchastheonejustdescribedistouseaggrega-
tion. Aggregation is an abstraction through which relationships are treated as higher-
levelentities.Thus,forourexample,weregardtherelationshipsetproj guide(relating
the entity sets instructor, student, and project) as a higher-level entity set called proj
guide. Such an entityset istreated in the same manneras isany otherentityset. We
canthencreateabinaryrelationshipeval for betweenproj guideandevaluationtorep-
resentwhich(student,project,instructor)combinationanevaluationisfor.Figure6.20
showsanotationforaggregationcommonlyusedtorepresentthissituation.
6.8.6 Reduction to Relation Schemas
WeareinapositionnowtodescribehowtheextendedE-Rfeaturescanbetranslated
intorelationschemas.

--- Page 307 ---

278 Chapter6 DatabaseDesignUsingtheE-RModel
6.8.6.1 RepresentationofGeneralization
TherearetwodifferentmethodsofdesigningrelationschemasforanE-Rdiagramthat
includesgeneralization. Although we refer to the generalization in Figure 6.18 in this
discussion,wesimplifyitbyincludingonlythefirsttieroflower-levelentitysets—that
is,employeeandstudent.WeassumethatIDistheprimarykeyofperson.
1. Create a schema for the higher-level entity set. For each lower-level entity set,
createaschemathatincludesanattributeforeachoftheattributesofthatentity
set plus one for each attribute of the primary key of the higher-level entity set.
Thus, for the E-R diagram of Figure 6.18 (ignoring the instructor and secretary
entitysets)wehavethreeschemas:
person(ID,name,street,city)
employee(ID,salary)
student(ID,tot cred)
The primary-key attributes of the higher-level entity set become primary-key at-
tributes of the higher-level entity set as well as all lower-level entity sets. These
canbeseenunderlinedintheprecedingexample.
In addition, we create foreign-key constraints on the lower-level entity sets,
withtheirprimary-keyattributesreferencingtheprimarykeyoftherelationcre-
ated from the higher-level entity set. In the preceding example, the ID attribute
ofemployeewouldreferencetheprimarykeyofperson,andsimilarlyforstudent.
2. Analternativerepresentationispossible,ifthegeneralizationisdisjointandcom-
plete—thatis,ifnoentityisamemberoftwolower-levelentitysetsdirectlybelow
a higher-levelentityset, and ifevery entityin the higher-levelentitysetisalso a
member of one of the lower-level entity sets. Here, we do not create a schema
forthehigher-levelentityset.Instead,foreachlower-levelentityset,wecreatea
schemathatincludesanattributeforeachoftheattributesofthatentitysetplus
oneforeachattributeofthehigher-levelentityset.Then,fortheE-Rdiagramof
Figure6.18,wehavetwoschemas:
employee(ID,name,street,city,salary)
student(ID,name,street,city,tot cred)
BoththeseschemashaveID,whichistheprimary-keyattributeofthehigher-level
entitysetperson,astheirprimarykey.
One drawback of the second method lies in defining foreign-key constraints. To
illustratetheproblem,supposewehavearelationshipsetRinvolvingentitysetperson.
With the first method, when we create a relation schemaR from the relationshipset,
we also define a foreign-key constraint on R, referencing the schema person. Unfortu-
nately,withthesecondmethod,wedonothaveasinglerelationtowhichaforeign-key

--- Page 308 ---

6.9 Entity-RelationshipDesignIssues 279
constrainton Rcanrefer.Toavoid thisproblem,weneedtocreate arelationschema
personcontainingatleasttheprimary-keyattributesofthepersonentity.
If the second method were used for an overlapping generalization, some values
would be stored multiple times, unnecessarily. For instance, if a person is both an
employeeandastudent,valuesforstreetandcitywouldbestoredtwice.
Ifthegeneralizationweredisjointbutnotcomplete—thatis,ifsomepersonisnei-
theranemployeenorastudent—thenanextraschema
person(ID,name,street,city)
would be required to represent such people. However, the problem with foreign-key
constraintsmentionedabovewouldremain.Asanattempttoworkaroundtheproblem,
suppose employees and students are additionally represented in the person relation.
Unfortunately, name, street, and city information would then be stored redundantly
inthepersonrelationandthestudent relationforstudents, andsimilarlyintheperson
relation and the employee relation for employees. That suggests storing name, street,
and city information only in the person relation and removing that information from
studentandemployee.Ifwedothat,theresultisexactlythefirstmethodwepresented.
6.8.6.2 RepresentationofAggregation
DesigningschemasforanE-Rdiagramcontainingaggregationisstraightforward.Con-
siderFigure6.20.Theschemafortherelationshipseteval forbetweentheaggregation
of proj guide and the entity set evaluation includes an attribute for each attribute in
theprimarykeysoftheentitysetevaluationandtherelationshipsetproj guide.Italso
includesanattributeforanydescriptiveattributes,iftheyexist,oftherelationshipset
eval for.Wethentransformtherelationshipsetsandentitysetswithintheaggregated
entitysetfollowingtheruleswehavealreadydefined.
The rules we saw earlier for creating primary-key and foreign-key constraints on
relationshipsetscanbeappliedtorelationshipsetsinvolvingaggregationsaswell,with
the aggregation treated like any other entity set. The primary key of the aggregation
is the primary key of its defining relationship set. No separate relation is required to
represent the aggregation; the relation created from the defining relationship is used
instead.
6.9 Entity-Relationship Design Issues
The notions of an entity set and a relationship set are not precise, and it is possible
to define a set of entities and the relationships among them in a number of different
ways.Inthissection,weexaminebasicissuesinthedesignofanE-Rdatabaseschema.
Section6.11coversthedesignprocessinfurtherdetail.

--- Page 309 ---

280 Chapter6 DatabaseDesignUsingtheE-RModel
student department
ID stud—dept
dept_name
name
building
tot_cred
budget
dept_name
(a) Incorrect use of attribute
assignment
marks
student stud_section section
(b) Erroneous use of relationship attributes
Figure 6.21 ExampleoferroneousE-Rdiagrams
6.9.1 Common Mistakes in E-R Diagrams
AcommonmistakewhencreatingE-Rmodelsistheuseoftheprimarykeyofanentity
setasanattributeofanotherentityset,insteadofusingarelationship.Forexample,in
ouruniversityE-Rmodel,itisincorrecttohavedept nameasanattributeofstudent,as
depictedinFigure6.21a,eventhoughitispresentasanattributeintherelationschema
forstudent.Therelationshipstud dept isthecorrectwaytorepresentthisinformation
in the E-R model, since it makes the relationship between student and department ex-
plicit,ratherthan implicitviaan attribute. Having an attribute dept nameas wellas a
relationshipstud deptwouldresultinduplicationofinformation.
Anotherrelatedmistakethatpeoplesometimesmakeistodesignatetheprimary-
keyattributesoftherelatedentitysetsasattributesoftherelationshipset.Forexample,
ID(theprimary-keyattributesofstudent)andID(theprimarykeyofinstructor)should
notappearasattributesoftherelationshipadvisor.Thisshouldnotbedonesincethe
primary-keyattributesarealreadyimplicitintherelationshipset.6
A third common mistake is to use a relationship with a single-valued attribute in
a situation that requires a multivalued attribute. For example, suppose we decided to
represent the marks that a student gets in different assignments of a course offering
(section). A wrong way of doing this would be to add two attributes assignment and
marks to the relationship takes, as depicted in Figure 6.21b. The problem with this
designisthatwecanonlyrepresentasingleassignmentforagivenstudent-sectionpair,
6WhenwecreatearelationschemafromtheE-Rschema,theattributesmayappearinaschemacreatedfromtheadvisor
relationshipset,asweshallseelater;however,theyshouldnotappearintheadvisorrelationshipset.

--- Page 310 ---

6.9 Entity-RelationshipDesignIssues 281
marks
student marks_in assignment sec_assign section
(c) Correct alternative to erroneous E-R diagram (b)
{assignment_marks
assignment
marks
}
student stud_section section
(d) Correct alternative to erroneous E-R diagram (b)
Figure 6.22 CorrectversionsoftheE-RdiagramofFigure6.21.
since relationship instances must be uniquely identified by the participating entities,
studentandsection.
OnesolutiontotheproblemdepictedinFigure6.21c,showninFigure6.22a,isto
modelassignmentasaweakentityidentifiedbysection,andtoaddarelationshipmarks
inbetweenassignmentandstudent;therelationshipwouldhaveanattributemarks.An
alternativesolution,showninFigure6.22d,istouseamultivaluedcompositeattribute
{assignment marks}totakes,whereassignment markshascomponentattributesassign-
ment and marks. Modeling an assignment as a weak entity is preferable in this case,
since it allows recording other information about the assignment, such as maximum
marksordeadlines.
When an E-R diagram becomes too big to draw in a single piece, it makes sense
to break it up into pieces, each showing part of the E-R model. When doing so, you
mayneedtodepictanentitysetinmorethanonepage.AsdiscussedinSection6.2.2,
attributes of the entity set should be shown only once, in its first occurrence. Subse-
quent occurrences of the entity set should be shown without any attributes, to avoid
repeatingthesameinformationatmultipleplaces,whichmayleadtoinconsistency.
6.9.2 Use of Entity Sets versus Attributes
Consider the entity set instructor with the additional attribute phone number (Figure
6.23a.)Itcanbearguedthataphoneisanentityinitsownrightwithattributesphone

--- Page 311 ---

282 Chapter6 DatabaseDesignUsingtheE-RModel
instructor
instructor phone
ID inst_phone phone_number
name ID
location
salary name
phone_number salary
(a) (b)
Figure 6.23 Alternativesforaddingphonetotheinstructor entityset.
number and location; the location may be the office or home where the phone is lo-
cated,withmobile(cell)phonesperhapsrepresentedbythevalue“mobile.”Ifwetake
thispointofview,wedonotaddtheattributephone number totheinstructor.Rather,
wecreate:
• Aphoneentitysetwithattributesphone number andlocation.
• Arelationshipsetinst phone,denotingtheassociationbetweeninstructorsandthe
phonesthattheyhave.
ThisalternativeisshowninFigure6.23b.
What,then,isthemaindifferencebetweenthesetwodefinitionsofaninstructor?
Treatingaphone asan attribute phone number impliesthatinstructorshave precisely
one phone number each. Treating a phone as an entity phone permits instructors to
haveseveralphonenumbers(includingzero)associatedwiththem.However,wecould
insteadeasilydefinephone numberasamultivaluedattributetoallowmultiplephones
perinstructor.
The main difference then is that treating a phone as an entity better models a
situation where one may want to keep extra information about a phone, such as its
location,oritstype(mobile,IPphone,orplainoldphone),orallwhosharethephone.
Thus,treatingphoneasanentityismoregeneralthantreatingitasanattributeandis
appropriatewhenthegeneralitymaybeuseful.
Incontrast,itwouldnotbeappropriatetotreattheattributename(ofaninstruc-
tor)asanentity;itisdifficulttoarguethatnameisanentityinitsownright(incontrast
tothephone).Thus,itisappropriatetohavenameasanattributeoftheinstructorentity
set.
Two natural questions thus arise: What constitutes an attribute, and what consti-
tutesanentityset?Unfortunately,therearenosimpleanswers.Thedistinctionsmainly
dependonthestructureofthereal-worldenterprisebeingmodeledandontheseman-
ticsassociatedwiththeattributeinquestion.
6.9.3 Use of Entity Sets versus Relationship Sets
Itisnotalwaysclearwhetheranobjectisbestexpressedbyanentitysetorarelationship
set. In Figure 6.15, we used the takes relationship set to model the situation where a

--- Page 312 ---

6.9 Entity-RelationshipDesignIssues 283
registration
section_reg ... student_reg
...
...
section student
sec_id ID
semester name
year tot_cred
Figure 6.24 Replacementoftakesbyregistration andtworelationshipsets.
studenttakesa(sectionofa)course.Analternativeistoimaginethatthereisacourse-
registration record for each course that each student takes. Then, we have an entity
set to represent the course-registration record. Let us call that entity set registration.
Eachregistrationentityisrelatedtoexactlyonestudentandtoexactlyonesection,so
wehavetworelationshipsets,onetorelatecourse-registrationrecordstostudentsand
onetorelatecourse-registrationrecordstosections.InFigure6.24,weshowtheentity
setssectionandstudentfromFigure6.15withthetakesrelationshipsetreplacedbyone
entitysetandtworelationshipsets:
• registration,theentitysetrepresentingcourse-registrationrecords.
• section reg,therelationshipsetrelatingregistrationandcourse.
• student reg,therelationshipsetrelatingregistrationandstudent.
Notethatweusedoublelinestoindicatetotalparticipationbyregistrationentities.
BoththeapproachofFigure6.15andthatofFigure6.24accuratelyrepresentthe
university’sinformation,buttheuseoftakesismorecompactandprobablypreferable.
However,iftheregistrar’sofficeassociatesotherinformationwithacourse-registration
record,itmightbebesttomakeitanentityinitsownright.
Onepossibleguidelineindeterminingwhethertouseanentitysetorarelationship
setistodesignatearelationshipsettodescribeanactionthatoccursbetweenentities.
This approach can also be useful in decidingwhethercertain attributes may be more
appropriatelyexpressedasrelationships.
6.9.4 Binary versus n-ary Relationship Sets
Relationshipsindatabasesareoftenbinary.Somerelationshipsthatappeartobenonbi-
narycouldactuallybebetterrepresentedbyseveralbinaryrelationships.Forinstance,
one could create a ternary relationship parent, relating a child to his/her mother and
father.However,sucharelationshipcouldalsoberepresentedbytwobinaryrelation-
ships,motherandfather,relatingachildtohis/hermotherandfatherseparately.Using

--- Page 313 ---

284 Chapter6 DatabaseDesignUsingtheE-RModel
the tworelationshipsmother and father providesuswitharecordofachild’smother,
even if we are not aware of the father’s identity; a null value would be required if the
ternary relationship parent were used. Using binary relationship sets is preferable in
thiscase.
Infact,itisalwayspossibletoreplaceanonbinary(n-ary,forn > 2)relationshipset
by a number of distinct binary relationship sets. For simplicity, consider the abstract
ternary (n = 3) relationship set R, relating entity sets A, B, and C. We replace the
relationshipsetRwithanentitysetE,andwecreatethreerelationshipsetsasshown
inFigure6.25:
• R ,amany-to-onerelationshipsetfromE toA.
A
• R ,amany-to-onerelationshipsetfromE toB.
B
• R ,amany-to-onerelationshipsetfromE toC.
C
E isrequiredtohave total participation ineachof R ,R ,and R . Ifthe relationship
A B C
setRhadanyattributes,theseareassignedtoentitysetE;further,aspecialidentifying
attribute is created for E (since it must be possible to distinguish different entities in
an entity set on the basis of their attribute values). For each relationship (a,b,c) in
i i i
therelationshipsetR,wecreateanewentitye intheentitysetE.Then,ineachofthe
i
threenewrelationshipsets,weinsertarelationshipasfollows:
• (e,a)inR .
i i A
• (e,b)inR .
i i B
• (e,c)inR .
i i C
We can generalize this process in a straightforward manner to n-ary relationship
sets.Thus,conceptually,wecanrestricttheE-Rmodeltoincludeonlybinaryrelation-
shipsets.However,thisrestrictionisnotalwaysdesirable.
A
A R
A
B R C B R E R C
B C
(a) (b)
Figure 6.25 Ternaryrelationshipversusthreebinaryrelationships.

--- Page 314 ---

6.10 AlternativeNotationsforModelingData 285
• An identifying attribute may have to be created for the entity set created to rep-
resent the relationship set. This attribute, along with the extra relationship sets
required, increases the complexity of the design and (as we shall see in Section
6.7)overallstoragerequirements.
• An n-ary relationship set shows more clearly that several entities participate in a
singlerelationship.
• There may not be a way to translate constraints on the ternary relationship into
constraints on the binary relationships. For example, consider a constraint that
saysthatRismany-to-onefromA,BtoC;thatis,eachpairofentitiesfromAand
BisassociatedwithatmostoneC entity.Thisconstraintcannotbeexpressedby
usingcardinalityconstraintsontherelationshipsetsR ,R ,andR .
A B C
Consider the relationship set proj guide in Section 6.2.2, relating instructor, stu-
dent,andproject.Wecannotdirectlysplitproj guideintobinaryrelationshipsbetween
instructorandprojectandbetweeninstructorandstudent.Ifwedidso,wewouldbeable
to record that instructor Katz works on projects A and B with students Shankar and
Zhang; however, we would not be able to record that Katz works on project A with
student Shankar and works on project B with student Zhang, but does not work on
projectAwithZhangoronprojectBwithShankar.
The relationshipset proj guidecan be split intobinary relationshipsby creatinga
newentitysetasdescribedabove.However,doingsowouldnotbeverynatural.
6.10 Alternative Notations for Modeling Data
Adiagrammaticrepresentationofthedatamodelofanapplicationisaveryimportant
partofdesigningadatabaseschema.Creationofadatabaseschemarequiresnotonly
data modeling experts, but also domain experts who know the requirements of the
application but may not be familiar with data modeling. An intuitive diagrammatic
representation is particularly important since it eases communication of information
betweenthesegroupsofexperts.
Anumberofalternativenotationsformodelingdatahavebeenproposed,ofwhich
E-RdiagramsandUMLclassdiagramsarethemostwidelyused.Thereisnouniversal
standard forE-Rdiagramnotation,anddifferentbooks andE-Rdiagramsoftwareuse
differentnotations.
Intherestofthissection,westudysomeofthealternativeE-Rdiagramnotations,
aswellastheUMLclassdiagramnotation.Toaidincomparisonofournotationwith
thesealternatives,Figure6.26summarizesthesetofsymbolswehaveusedinourE-R
diagramnotation.
6.10.1 Alternative E-R Notations
Figure 6.27 indicates some of the alternative E-R notations that are widelyused. One
alternative representation of attributes of entities is to show them in ovals connected

--- Page 315 ---

286 Chapter6 DatabaseDesignUsingtheE-RModel
E
E entity set
A1
attributes:
A2
simple (A1),
A2.1 composite (A2) and
R relationship set A2.2 multivalued (A3)
derived (A4)
{A3}
A4()
identifying
R relationship set E
for weak entity set primary key
A1
total participation E discriminating
R E of entity set in attribute of
A1
relationship weak entity set
many-to-many many-to-one
R R
relationship relationship
R one-to-one R l..h E cardinality
relationship limits
E1
role-
name
R E role indicator ISA: generalization
or specialization
E2 E3
E1 E1
total (disjoint) disjoint
total generalization generalization
E2 E3 E2 E3
Figure 6.26 SymbolsusedintheE-R notation.
totheboxrepresentingtheentity;primarykeyattributesareindicatedbyunderlining
them. The above notation is shown at the top of the figure. Relationship attributes
canbesimilarlyrepresented,byconnectingtheovalstothediamondrepresentingthe
relationship.
Cardinalityconstraintsonrelationshipscanbeindicatedinseveraldifferentways,
asshowninFigure6.27.Inonealternative,shownontheleftsideofthefigure,labels
∗and1ontheedgesoutoftherelationshipareusedfordepictingmany-to-many,one-

--- Page 316 ---

6.10 AlternativeNotationsforModelingData 287
entity set E with A2.1 A2.2
simple attribute A1,
composite attribute A2, A2
multivalued attribute A3, A1 A3
derived attribute A4,
A4
and primary key A1 E
many-to-many E1 * R * E2 E1 R E2
relationship
one-to-one 1 1 R
E1 R E2 E1 E2
relationship
many-to-one E1 * R 1 E2 E1 R E2
relationship
participation
R
in R: total (E1) E1 R E2 E1 E2
and partial (E2)
total
weak entity set generalization ISA generalization ISA
Figure 6.27 AlternativeE-Rnotations.
to-one,andmany-to-onerelationships.Thecaseofone-to-manyissymmetrictomany-
to-oneandisnotshown.
InanotheralternativenotationshownontherightsideofFigure6.27,relationship
sets are represented by lines between entity sets, without diamonds; only binary rela-
tionshipscanbemodeledthus.Cardinalityconstraintsinsuchanotationareshownby
“crow’s-foot”notation,asinthefigure.InarelationshipRbetweenE1andE2,crow’s
feet on both sides indicate a many-to-many relationship, while crow’s feet on just the
E1sideindicateamany-to-onerelationshipfromE1toE2.Totalparticipationisspec-
ifiedinthisnotationbyaverticalbar.Note however,thatinarelationshipRbetween
entitiesE1andE2,iftheparticipationofE1inRistotal,theverticalbarisplacedon
theoppositeside,adjacenttoentityE2.Similarly,partialparticipationisindicatedby
usingacircle,againontheoppositeside.
ThebottompartofFigure6.27showsanalternativerepresentationofgeneraliza-
tion,usingtrianglesinsteadofhollowarrowheads.

--- Page 317 ---

288 Chapter6 DatabaseDesignUsingtheE-RModel
In prior editions of this text up to the fifth edition, we used ovals to represent
attributes,withtrianglesrepresentinggeneralization,asshowninFigure6.27.Theno-
tationusingovalsforattributesanddiamondsforrelationshipsisclosetotheoriginal
form of E-R diagrams used by Chen in his paper that introduced the notion of E-R
modeling.ThatnotationisnowreferredtoasChen’snotation.
TheU.S.NationalInstituteforStandardsandTechnologydefinedastandardcalled
IDEF1X in1993. IDEF1X uses thecrow’s-footnotation,withverticalbarson therela-
tionshipedgetodenotetotalparticipationandhollowcirclestodenotepartialpartici-
pation,anditincludesothernotationsthatwehavenotshown.
WiththegrowthintheuseofUnifiedMarkupLanguage(UML),describedinSec-
tion6.10.2,wehavechosentoupdateourE-Rnotationtomakeitclosertotheformof
UMLclassdiagrams;theconnectionswillbecomeclearinSection6.10.2.Incompari-
sonwithourpreviousnotation,ournewnotationprovidesamorecompactrepresenta-
tionofattributes,anditisalsoclosertothenotationsupportedbymanyE-Rmodeling
tools,inadditiontobeingclosertotheUMLclassdiagramnotation.
There are a variety of tools for constructing E-R diagrams, each of which has its
ownnotationalvariants.SomeofthetoolsevenprovideachoicebetweenseveralE-R
notationvariants.Seethetoolssectionattheendofthechapterforreferences.
OnekeydifferencebetweenentitysetsinanE-Rdiagramandtherelationschemas
createdfromsuchentitiesisthatattributesintherelationalschemacorrespondingto
E-R relationships, such as the dept name attribute of instructor, are not shown in the
entity set in the E-R diagram. Some data modeling tools allow designers to choose
betweentwoviewsofthesameentity,oneanentityviewwithoutsuchattributes, and
otherarelationalviewwithsuchattributes.
6.10.2 The Unified Modeling Language UML
Entity-relationshipdiagramshelpmodelthedatarepresentationcomponentofasoft-
ware system. Data representation, however, forms only one part of an overall system
design. Other components include models of user interactions with the system, spec-
ification of functional modules of the system and their interaction, etc. The Unified
Modeling Language (UML) is a standard developed under the auspices of the Object
ManagementGroup(OMG)forcreatingspecificationsofvariouscomponentsofasoft-
waresystem.SomeofthepartsofUMLare:
• Classdiagram.AclassdiagramissimilartoanE-Rdiagram.Laterinthissection
weillustrateafewfeaturesofclassdiagramsandhowtheyrelatetoE-Rdiagrams.
• Usecasediagram.Usecasediagramsshowtheinteractionbetweenusersandthe
system, in particular the steps of tasks that users perform (such as withdrawing
moneyorregisteringforacourse).
• Activitydiagram.Activitydiagramsdepicttheflowoftasksbetweenvariouscom-
ponentsofasystem.

--- Page 318 ---

6.10 AlternativeNotationsforModelingData 289
• Implementationdiagram.Implementationdiagramsshowthesystemcomponents
andtheirinterconnections,bothatthesoftwarecomponentlevelandthehardware
componentlevel.
WedonotattempttoprovidedetailedcoverageofthedifferentpartsofUMLhere.
Instead we illustrate some features of that part of UML that relates to data modeling
throughexamples.SeetheFurtherReadingsectionattheendofthechapterforrefer-
encesonUML.
Figure6.28showsseveralE-RdiagramconstructsandtheirequivalentUMLclass
diagramconstructs.Wedescribetheseconstructsbelow.UMLactuallymodelsobjects,
whereasE-Rmodelsentities.Objectsarelikeentities,andhaveattributes,butaddition-
allyprovideasetoffunctions(calledmethods)thatcanbeinvokedtocomputevalues
on the basis of attributes of the objects, orto update the objectitself.Class diagrams
candepictmethodsinadditiontoattributes.WecoverobjectsinSection8.2.UMLdoes
notsupportcompositeormultivaluedattributes,andderivedattributesareequivalent
tomethodsthattakenoparameters.Sinceclassessupportencapsulation,UMLallows
attributesandmethodstobeprefixedwitha“+”,“-”,or“#”,whichdenoterespectively
public,private,andprotectedaccess.Privateattributescanonlybeusedinmethodsof
the class, while protected attributes can be used only in methods of the class and its
subclasses;theseshouldbefamiliartoanyonewhoknowsJava,C++,orC#.
InUMLterminology,relationshipsetsarereferredtoasassociations;weshallrefer
tothemasrelationshipsetsforconsistencywithE-Rterminology.Werepresentbinary
relationshipsetsinUMLbyjustdrawingalineconnectingtheentitysets.Wewritethe
relationship set name adjacent to the line. We may also specify the role played by an
entitysetinarelationshipsetbywritingtherolenameontheline,adjacenttotheentity
set.Alternatively,wemaywritetherelationshipsetnameinabox,alongwithattributes
of the relationship set, and connect the box by a dotted line to the line depicting the
relationship set. This box can then be treated as an entity set, in the same way as an
aggregationinE-Rdiagrams,andcanparticipateinrelationshipswithotherentitysets.
SinceUMLversion1.3,UMLsupportsnonbinaryrelationships,usingthesamedi-
amond notation used in E-R diagrams. Nonbinary relationships could not be directly
represented in earlier versions of UML—they had to be converted to binary relation-
shipsbythetechniquewehaveseenearlierinSection6.9.4.UMLallowsthediamond
notationtobeusedevenforbinaryrelationships,butmostdesignersusethelinenota-
tion.
Cardinalityconstraints are specifiedinUMLin thesame wayasinE-Rdiagrams,
intheforml..h,whereldenotestheminimumandhthemaximumnumberofrelation-
ships an entity can participate in. However, you should be aware that the positioning
of the constraints is exactly the reverse of the positioning of constraints in E-R dia-
grams, as shown in Figure 6.28. The constraint 0.. ∗ on the E2 side and 0..1 on the
E1sidemeansthateachE2entitycanparticipateinatmostonerelationship,whereas
eachE1 entitycan participate in manyrelationships; inotherwords, the relationship
ismany-to-onefromE2toE1.

--- Page 319 ---

290 Chapter6 DatabaseDesignUsingtheE-RModel
ER Diagram Notation Equivalent in UML
E entity with E class with simple attributes
attributes (simple, and methods (attribute
A1 –A1
composite, prefixes: + = public,
M10 multivalued, derived) +M10 – = private, # = protected)
role1 role2 binary role1 R role2
E1 R E2 E1 E2
relationship
A1 R
A1
role1 role2 relationship role1 role2
E1 R E2 attributes E1 E2
0..* 0..1 cardinality 0_1 R 0_*
E1 R E2 E1 E2
constraints
E2 E2
n-ary
E1 R relationships E1 R
E3 E3
E1 E1
overlapping
overlapping
generalization
E2 E3 E2 E3
E1 E1
disjoint disjoint
generalization
E2 E3 E2 E3
weak-entity
E1 R E2 E1 E2
composition
Figure 6.28 SymbolsusedintheUMLclassdiagramnotation.
Singlevaluessuchas1or∗maybewrittenonedges;thesinglevalue1onanedgeis
treatedasequivalentto1..1,while∗isequivalentto0.. ∗.UMLsupportsgeneralization;
thenotationisbasicallythesameasinourE-Rnotation,includingtherepresentation
ofdisjointandoverlappinggeneralizations.
UMLclassdiagramsincludeseveralothernotationsthatapproximatelycorrespond
totheE-Rnotationswehaveseen.Alinebetweentwoentitysetswithasmallshaded
diamond at one end in UML specifies “composition” in UML. The composition rela-
tionship between E2 and E1 in Figure 6.28 indicates that E2 is existence dependent
on E1; this is roughly equivalent to denotingE2 as a weak entity set that is existence

--- Page 320 ---

6.11 OtherAspectsofDatabaseDesign 291
dependent on the identifying entity set E1. (The term aggregation in UML denotes a
variantofcompositionwhereE2iscontainedinE1butmayexistindependently,and
itisdenotedusingasmallhollowdiamond.)
UML class diagrams also provide notations to represent object-oriented language
features such as interfaces. See the Further Readingsection for more information on
UMLclassdiagrams.
6.11 Other Aspects of Database Design
Ourextensivediscussionofschemadesigninthischaptermaycreatethefalseimpres-
sionthatschemadesignistheonlycomponentofadatabasedesign.Thereareindeed
several other considerations that we address more fully in subsequent chapters, and
surveybrieflyhere.
6.11.1 Functional Requirements
All enterprises have rules on what kinds of functionality are to be supported by an
enterprise application. These could includetransactions that update the data, as well
asqueriestoviewdatainadesiredfashion. Inadditiontoplanningthe functionality,
designershavetoplantheinterfacestobebuilttosupportthefunctionality.
Not all users are authorized to view all data, or to perform all transactions. An
authorizationmechanismisveryimportantforanyenterpriseapplication.Suchautho-
rization could be at the level of the database, using database authorization features.
But it could also be at the level of higher-level functionality or interfaces, specifying
whocanusewhichfunctions/interfaces.
6.11.2 Data Flow, Workflow
Database applications are often part of a larger enterprise application that interacts
not only with the database system but also with various specialized applications. As
an example, consider a travel-expense report. It is created by an employee returning
from a business trip (possibly by means of a special software package) and is subse-
quently routed to the employee’s manager, perhaps other higher-level managers, and
eventuallytotheaccountingdepartmentforpayment(atwhichpointitinteractswith
theenterprise’saccountinginformationsystems).
Thetermworkflowreferstothecombinationofdataandtasksinvolvedinprocesses
like those of the precedingexamples. Workflows interact with the database system as
theymoveamongusersandusersperformtheirtasksontheworkflow.Inadditiontothe
dataonwhichworkflowsoperate,thedatabasemaystoredataabouttheworkflowitself,
includingthetasksmakingupaworkflowandhowtheyaretoberoutedamongusers.
Workflowsthusspecifyaseriesofqueriesandupdatestothedatabasethatmaybetaken
intoaccountas part of the database-design process. Putin otherterms, modelingthe

--- Page 321 ---

292 Chapter6 DatabaseDesignUsingtheE-RModel
enterprise requires us not only to understand the semantics of the data but also the
businessprocessesthatusethosedata.
6.11.3 Schema Evolution
Databasedesignisusuallynotaone-timeactivity.Theneedsofanorganizationevolve
continually, and the data that it needs to store also evolve correspondingly. During
the initial database-design phases, or during the development of an application, the
database designer may realize that changes are required at the conceptual, logical, or
physical schema levels. Changes in the schema can affect all aspects of the database
application. A good database design anticipates future needs of an organization and
ensuresthattheschemarequiresminimalchangesastheneedsevolve.
It is important to distinguish between fundamental constraints that are expected
tobepermanentandconstraintsthatareanticipatedtochange.Forexample,thecon-
straint that an instructor-id identify a unique instructor is fundamental. On the other
hand,auniversitymayhaveapolicythataninstructorcanhaveonlyonedepartment,
whichmaychangeatalaterdateifjointappointmentsareallowed.Adatabasedesign
that only allows one department per instructor might require major changes if joint
appointments are allowed. Such joint appointments can be represented by adding an
extrarelationshipwithoutmodifyingtheinstructor relation,aslongaseachinstructor
hasonlyoneprimarydepartmentaffiliation;apolicychangethatallowsmorethanone
primaryaffiliation may requirealargerchange in the database design.A good design
should account not only for current policies, but should also avoid or minimize the
needformodificationsduetochangesthatareanticipatedorhaveareasonablechance
ofhappening.
Finally,itisworthnotingthatdatabasedesignisahuman-orientedactivityintwo
senses:theendusersofthesystemarepeople(evenifanapplicationsitsbetweenthe
database and the end users); and the database designer needs to interact extensively
with experts in the application domain to understand the data requirements of the
application. All of the people involved with the data have needs and preferences that
shouldbetakenintoaccountinorderforadatabasedesignanddeploymenttosucceed
withintheenterprise.
6.12 Summary
• Database design mainly involves the design of the database schema. The entity-
relationship (E-R) data model is a widely used data model for database design.
Itprovidesaconvenientgraphicalrepresentationtoviewdata,relationships,and
constraints.
• The E-R model is intended primarily for the database-design process. It was de-
velopedtofacilitatedatabasedesignbyallowingthespecificationofanenterprise
schema. Such a schema represents the overall logical structure of the database.
ThisoverallstructurecanbeexpressedgraphicallybyanE-Rdiagram.

--- Page 322 ---

ReviewTerms 293
• Anentityisanobjectthatexistsintherealworldandisdistinguishablefromother
objects.Weexpressthedistinctionbyassociatingwitheachentityasetofattributes
thatdescribestheobject.
• Arelationshipisanassociationamongseveralentities.Arelationshipsetisacol-
lectionofrelationshipsofthesametype,andanentitysetisacollectionofentities
ofthesametype.
• The terms superkey, candidate key, and primary key apply to entity and relation-
shipsetsastheydoforrelationschemas.Identifyingtheprimarykeyofarelation-
shipsetrequiressomecare,sinceitiscomposedofattributesfromoneormoreof
therelatedentitysets.
• Mappingcardinalitiesexpressthenumberofentitiestowhichanotherentitycan
beassociatedviaarelationshipset.
• Anentitysetthatdoesnothavesufficientattributestoformaprimarykeyistermed
aweakentityset.Anentitysetthathasaprimarykeyistermedastrongentityset.
• The various features of the E-R model offer the database designer numerous
choicesinhowtobestrepresenttheenterprisebeingmodeled.Conceptsandob-
jectsmay,incertaincases,berepresentedbyentities,relationships,orattributes.
Aspects of the overall structure of the enterprise may be best described by using
weakentitysets,generalization,specialization,oraggregation.Often,thedesigner
mustweighthemeritsofasimple,compactmodelversusthoseofamoreprecise,
butmorecomplexone.
• AdatabasedesignspecifiedbyanE-Rdiagramcanberepresentedbyacollectionof
relationschemas.Foreachentitysetandforeachrelationshipsetinthedatabase,
thereisaunique relationschemathatisassigned thenameofthecorresponding
entitysetorrelationshipset.Thisformsthebasisforderivingarelationaldatabase
designfromanE-Rdiagram.
• Specialization and generalization define a containment relationship between a
higher-level entity set and one or more lower-level entity sets. Specialization is
theresultoftakingasubsetofahigher-levelentitysettoformalower-levelentity
set.Generalizationistheresultoftakingtheunionoftwoormoredisjoint(lower-
level)entitysetstoproduceahigher-levelentityset.Theattributesofhigher-level
entitysetsareinheritedbylower-levelentitysets.
• Aggregation is an abstraction in which relationship sets (along with their asso-
ciated entity sets) are treated as higher-level entity sets, and can participate in
relationships.
• Care must be taken in E-R design. There are a number of common mistakes to
avoid.Also, thereare choicesamongthe use of entitysets, relationshipsets, and

--- Page 323 ---

294 Chapter6 DatabaseDesignUsingtheE-RModel
attributesinrepresentingaspectsoftheenterprisewhosecorrectnessmaydepend
onsubtledetailsspecifictotheenterprise.
• UML is a popular modeling language. UML class diagrams are widely used for
modelingclasses,aswellasforgeneral-purposedatamodeling.
Review Terms
• DesignProcess ° Superkey, candidate key, and pri-
marykey
° Conceptual-design
° Role
° Logical-design
° Recursiverelationshipset
° Physical-design
• Entity-relationship(E-R)datamodel • E-Rdiagram
• Entityandentityset • Mappingcardinality:
° Simpleandcompositeattributes ° One-to-onerelationship
° Single-valued and multivalued at- ° One-to-manyrelationship
tributes
° Many-to-onerelationship
° Derivedattribute
° Many-to-manyrelationship
• Key
• Totalandpartialparticipation
° Superkey • Weakentitysetsandstrongentitysets
° Candidatekey
° Discriminatorattributes
° Primarykey
° Identifyingrelationship
• Relationshipandrelationshipset
• Specializationandgeneralization
° Binaryrelationshipset
• Aggregation
° Degreeofrelationshipset • Designchoices
° Descriptiveattributes • UnitedModelingLanguage(UML)
Practice Exercises
6.1 Construct an E-R diagram for a carinsurance company whose customers own
one or more cars each. Each car has associated with it zero to any number of
recordedaccidents.Eachinsurancepolicycoversoneormorecarsandhasone
ormorepremiumpaymentsassociatedwithit.Eachpaymentisforaparticular
periodoftime,andhasanassociatedduedate,andthedatewhenthepayment
wasreceived.

--- Page 324 ---

PracticeExercise 295
6.2 Consider a database that includes the entity sets student, course, and section
fromtheuniversityschemaandthatadditionallyrecordsthemarksthatstudents
receiveindifferentexamsofdifferentsections.
a. ConstructanE-Rdiagramthatmodelsexamsasentitiesandusesaternary
relationshipaspartofthedesign.
b. ConstructanalternativeE-Rdiagramthatusesonlyabinaryrelationship
between student and section. Make sure that only one relationship exists
between a particular student and section pair, yet you can represent the
marksthatastudentgetsindifferentexams.
6.3 DesignanE-Rdiagramforkeepingtrackofthescoringstatisticsofyourfavorite
sportsteam.Youshouldstorethematchesplayed,thescoresineachmatch,the
players in each match, and individual player scoring statistics for each match.
Summarystatisticsshouldbemodeledasderivedattributeswithanexplanation
astohowtheyarecomputed.
6.4 Consider an E-R diagram in which the same entity set appears several times,
withitsattributes repeated inmorethan oneoccurrence.Whyisallowingthis
redundancyabadpracticethatoneshouldavoid?
6.5 AnE-Rdiagramcanbeviewedasagraph.Whatdothefollowingmeaninterms
ofthestructureofanenterpriseschema?
a. Thegraphisdisconnected.
b. Thegraphhasacycle.
6.6 Consider the representation of the ternary relationship of Figure 6.29a using
thebinaryrelationshipsillustratedinFigure6.29b(attributesnotshown).
a. Show a simple instance of E,A,B,C, R ,R , and R that cannot corre-
A B C
spondtoanyinstanceofA,B,C,andR.
b. ModifytheE-RdiagramofFigure6.29btointroduceconstraintsthatwill
guaranteethatanyinstanceofE,A,B,C,R ,R ,andR thatsatisfiesthe
A B C
constraintswillcorrespondtoaninstanceofA,B,C,andR.
c. Modifytheprecedingtranslationtohandletotalparticipationconstraints
ontheternaryrelationship.
6.7 A weak entity set can always be made into a strong entity set by adding to its
attributes the primary-key attributes of its identifying entity set. Outline what
sortofredundancywillresultifwedoso.
6.8 Consider a relation such as sec course, generated from a many-to-one relation-
ship set sec course. Do the primary and foreign key constraints created on the
relationenforcethemany-to-onecardinalityconstraint?Explainwhy.

--- Page 325 ---

296 Chapter6 DatabaseDesignUsingtheE-RModel
A
A R
A
B R C B R E R C
B C
(a) (b)
R AB A R AC
B R BC C
(c)
Figure 6.29 Representationofaternaryrelationshipusingbinaryrelationships.
6.9 Suppose the advisor relationship set were one-to-one. What extra constraints
are required on the relation advisor to ensure that the one-to-one cardinality
constraintisenforced?
6.10 Consider a many-to-one relationship R between entity sets A and B. Suppose
the relation created from R is combined with the relation created from A. In
SQL, attributes participating in a foreign key constraint can be null. Explain
howaconstraintontotalparticipationofAinRcanbeenforcedusingnotnull
constraintsinSQL.
6.11 InSQL,foreignkeyconstraintscanreferenceonlytheprimarykeyattributesof
the referenced relation or other attributes declared to be a superkey using the
uniqueconstraint.Asaresult,totalparticipationconstraintsonamany-to-many
relationshipset(oronthe“one”sideofaone-to-manyrelationshipset)cannot
be enforced on the relations created from the relationship set, using primary
key,foreignkey,andnotnullconstraintsontherelations.
a. Explainwhy.
b. Explain how to enforce total participation constraints using complex
checkconstraintsorassertions(seeSection4.4.8).(Unfortunately,these
featuresarenotsupportedonanywidelyuseddatabasecurrently.)
6.12 Considerthefollowinglatticestructureofgeneralizationandspecialization(at-
tributesnotshown).

--- Page 326 ---

Exercises 297
X Y
A B C
ForentitysetsA,B,andC,explainhowattributesareinheritedfromthehigher-
levelentitysetsX andY.DiscusshowtohandleacasewhereanattributeofX
hasthesamenameassomeattributeofY.
6.13 An E-R diagram usually models the state of an enterprise at a point in time.
Suppose we wish to track temporal changes, that is, changes to data over time.
For example, Zhang may have been a student between September 2015 and
May2019,whileShankarmayhavehadinstructorEinsteinasadvisorfromMay
2018toDecember2018,andagainfromJune2019toJanuary2020.Similarly,
attribute values of an entity or relationship, such as title and credits of course,
salary,orevennameofinstructor,andtot credofstudent,canchangeovertime.
Onewaytomodeltemporalchangesisasfollows:Wedefineanewdatatype
called valid time, which is a time interval, or a set of time intervals. We then
associateavalid timeattributewitheachentityandrelationship,recordingthe
timeperiodsduringwhichtheentityorrelationshipisvalid.Theendtimeofan
intervalcanbeinfinity;forexample,ifShankarbecameastudentinSeptember
2018, and is still a student, we can represent the end time of the valid time in-
tervalasinfinityfortheShankarentity.Similarly,wemodelattributesthatcan
changeovertimeasasetofvalues,eachwithitsownvalid time.
a. DrawanE-Rdiagramwiththestudentandinstructor entities,andthead-
visor relationship,withtheaboveextensionstotracktemporalchanges.
b. ConverttheE-Rdiagramdiscussedaboveintoasetofrelations.
Itshouldbeclearthatthesetofrelationsgeneratedisrathercomplex,leading
todifficultiesintaskssuchaswritingqueriesinSQL.Analternativeapproach,
which is used more widely, is to ignore temporal changes when designing the
E-Rmodel(in particular, temporal changestoattribute values), and tomodify
therelationsgeneratedfromtheE-Rmodeltotracktemporalchanges.
Exercises
6.14 Explain the distinctions among the terms primary key, candidate key, and su-
perkey.

--- Page 327 ---

298 Chapter6 DatabaseDesignUsingtheE-RModel
6.15 ConstructanE-Rdiagramforahospitalwithasetofpatientsandasetofmed-
icaldoctors.Associatewitheachpatientalogofthevarioustestsandexamina-
tionsconducted.
6.16 Extend the E-R diagram of Exercise 6.3 to track the same information for all
teamsinaleague.
6.17 Explainthedifferencebetweenaweakandastrongentityset.
6.18 ConsidertwoentitysetsAandBthatbothhavetheattributeX (amongothers
whosenamesarenotrelevanttothisquestion).
a. If the two Xs are completely unrelated, how should the design be im-
proved?
b. IfthetwoXsrepresentthesamepropertyanditisonethatappliesbothto
AandtoB,howshouldthedesignbeimproved?Considerthreesubcases:
• X istheprimarykeyforAbutnotB
• X istheprimarykeyforbothAandB
• X isnottheprimarykeyforAnorforB
6.19 We can convert any weak entity set to a strong entity set by simply adding ap-
propriateattributes.Why,then,dowehaveweakentitysets?
6.20 ConstructappropriaterelationschemasforeachoftheE-Rdiagramsin:
a. Exercise6.1.
b. Exercise6.2.
c. Exercise6.3.
d. Exercise6.15.
6.21 ConsidertheE-RdiagraminFigure6.30,whichmodelsanonlinebookstore.
a. Suppose the bookstore addsBlu-raydiscsanddownloadablevideotoits
collection.Thesameitemmaybepresentinoneorbothformats,withdif-
feringprices.DrawthepartoftheE-Rdiagramthatmodelsthisaddition,
showingjustthepartsrelatedtovideo.
b. NowextendthefullE-Rdiagramtomodelthecasewhereashoppingbas-
ketmaycontainanycombinationofbooks,Blu-raydiscs,ordownloadable
video.
6.22 Designadatabaseforanautomobilecompanytoprovidetoitsdealerstoassist
theminmaintainingcustomerrecordsanddealerinventoryandtoassist sales
staffinorderingcars.

--- Page 328 ---

Exercises 299
author publisher
name name
address address
URL phone
URL
customer
email
written_by
published_by name
address
phone
book
number
ISBN
title shopping_basket basket_of
year contains basket_id
price
number
warehouse
code
stocks
address
phone
Figure 6.30 E-Rdiagramformodelinganonlinebookstore.
Eachvehicleisidentifiedbyavehicleidentificationnumber(VIN).Eachindi-
vidualvehicleisaparticularmodelofaparticularbrandofferedbythecompany
(e.g., the XF is a model of the car brand Jaguar of Tata Motors). Each model
can be offered with a variety of options, but an individual car may have only
some (or none) of the available options. The database needs to store informa-
tionaboutmodels,brands,andoptions,aswellasinformationaboutindividual
dealers,customers,andcars.
YourdesignshouldincludeanE-Rdiagram,asetofrelationalschemas,and
alistofconstraints,includingprimary-keyandforeign-keyconstraints.
6.23 Design a database for a worldwide package delivery company (e.g., DHL or
FedEx).Thedatabasemustbeabletokeeptrackofcustomerswhoshipitems
andcustomerswhoreceiveitems;somecustomersmaydoboth.Eachpackage
must be identifiable and trackable, so the database must be able to store the
location of the package and its history of locations. Locations include trucks,
planes,airports,andwarehouses.
YourdesignshouldincludeanE-Rdiagram,asetofrelationalschemas,and
alistofconstraints,includingprimary-keyandforeign-keyconstraints.
6.24 Design a database for an airline. The database must keep track of customers
and their reservations, flights and their status, seat assignments on individual
flights,andthescheduleandroutingoffutureflights.
YourdesignshouldincludeanE-Rdiagram,asetofrelationalschemas,and
alistofconstraints,includingprimary-keyandforeign-keyconstraints.

--- Page 329 ---

300 Chapter6 DatabaseDesignUsingtheE-RModel
6.25 In Section 6.9.4, we represented a ternary relationship (repeated in Figure
6.29a)usingbinaryrelationships,asshowninFigure6.29b.Considerthealter-
nativeshowninFigure6.29c.Discusstherelativemeritsofthesetwoalternative
representationsofaternaryrelationshipbybinaryrelationships.
6.26 Designageneralization–specializationhierarchyforamotorvehiclesalescom-
pany. The company sells motorcycles, passenger cars, vans, and buses. Justify
your placement of attributes at each level of the hierarchy. Explain why they
shouldnotbeplacedatahigherorlowerlevel.
6.27 Explainthedistinctionbetweendisjointandoverlappingconstraints.
6.28 Explainthedistinctionbetweentotalandpartialconstraints.
Tools
Many database systems provide tools for database design that support E-R diagrams.
ThesetoolshelpadesignercreateE-Rdiagrams,andtheycanautomaticallycreatecor-
respondingtablesinadatabase.SeebibliographicalnotesofChapter1forreferences
todatabase-systemvendors’websites.
Therearealsoseveraldatabase-independentdatamodelingtoolsthatsupportE-R
diagramsandUMLclassdiagrams.
Dia,whichisafreediagrameditorthatrunsonmultipleplatformssuchasLinux
and Windows, supports E-R diagrams and UML class diagrams. To represent entities
with attributes, you can use either classes from the UML library or tables from the
Database library provided by Dia, since the default E-R notation in Dia represents
attributesasovals.ThefreeonlinediagrameditorLucidChartallowsyoutocreateE-R
diagramswithentitiesrepresentedinthesamewaysaswedo.Tocreaterelationships,
wesuggestyouusediamondsfromtheFlowchartshapecollection.Draw.ioisanother
onlinediagrameditorthatsupportsE-Rdiagrams.
Commercial tools include IBM Rational Rose Modeler, Microsoft Visio, ERwin
DataModeler,PoseidonforUML,andSmartDraw.
Further Reading
The E-R data model was introduced by [Chen (1976)]. The Integration Definition
forInformationModeling(IDEF1X) standard [NIST(1993)] releasedbythe United
States National Institute of Standards and Technology (NIST) defined standards for
E-Rdiagrams.However,avarietyofE-Rnotationsareinusetoday.
[Thalheim(2000)] providesadetailedtextbook coverageofresearchinE-Rmod-
eling.
Asof2018,thecurrentUMLversionwas2.5,whichwasreleasedinJune2015.See
www.uml.orgformoreinformationonUMLstandardsandtools.

--- Page 330 ---

FurtherReading 301
Bibliography
[Chen(1976)] P.P.Chen,“TheEntity-RelationshipModel:TowardaUnifiedViewofData”,
ACMTransactionsonDatabaseSystems,Volume1,Number1(1976),pages9–36.
[NIST(1993)] NIST, “Integration Definition for Information Modeling (IDEF1X)”, Tech-
nicalReportFederalInformationProcessingStandardsPublication184,NationalInstitute
ofStandardsandTechnology(NIST)(1993).
[Thalheim(2000)] B.Thalheim,Entity-RelationshipModeling:FoundationsofDatabaseTech-
nology,SpringerVerlag(2000).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 332 ---

7
CHAPTER
Relational Database Design
Inthischapter,weconsidertheproblemofdesigningaschemaforarelationaldatabase.
ManyoftheissuesindoingsoaresimilartodesignissuesweconsideredinChapter6
usingtheE-Rmodel.
In general, the goal of relational database design is to generate a set of relation
schemasthatallowsustostoreinformationwithoutunnecessaryredundancy,yetalso
allowsustoretrieveinformationeasily.Thisisaccomplishedbydesigningschemasthat
areinanappropriatenormalform.Todeterminewhetherarelationschemaisinoneof
the desirable normal forms, we need informationabout the real-worldenterprise that
wearemodelingwiththedatabase.Someofthisinformationexistsinawell-designed
E-Rdiagram,butadditionalinformationabouttheenterprisemaybeneededaswell.
Inthischapter,weintroduceaformalapproachtorelationaldatabasedesignbased
on the notion of functional dependencies. We then define normal forms in terms of
functionaldependenciesandothertypesofdatadependencies.First,however,weview
the problem of relational design from the standpoint of the schemas derived from a
givenentity-relationshipdesign.
7.1 Features of Good Relational Designs
Ourstudyofentity-relationshipdesigninChapter6providesanexcellentstartingpoint
forcreatingarelationaldatabasedesign.WesawinSection6.7thatitispossibletogen-
erateasetofrelationschemasdirectlyfromtheE-Rdesign.Thegoodness(orbadness)
of the resulting set of schemas depends on how good the E-R design was in the first
place.Laterinthischapter,weshallstudyprecisewaysofassessingthedesirabilityof
acollectionofrelationschemas.However,wecangoalongwaytowardagooddesign
usingconceptswehave alreadystudied.Foreaseofreference,werepeattheschemas
fortheuniversitydatabaseinFigure7.1.
Supposethatwehadstartedoutwhendesigningtheuniversityenterprisewiththe
schemain dep.
in dep(ID,name,salary,dept name,building,budget)
303

--- Page 333 ---

304 Chapter7 RelationalDatabaseDesign
classroom(building,room number,capacity)
department(dept name,building,budget)
course(course id,title,dept name,credits)
instructor(ID,name,dept name,salary)
section(course id,sec id,semester,year,building,room number,time slot id)
teaches(ID,course id,sec id,semester,year)
student(ID,name,dept name,tot cred)
takes(ID,course id,sec id,semester,year,grade)
advisor(s ID,i ID)
time slot(time slot id,day,start time,end time)
prereq(course id,prereq id)
Figure 7.1 Databaseschemafortheuniversityexample.
Thisrepresentstheresultofanaturaljoinontherelationscorrespondingtoinstructor
and department. This seems like a good idea because some queries can be expressed
usingfewerjoins,untilwethinkcarefullyaboutthefactsabouttheuniversitythatled
toourE-Rdesign.
Let us consider the instance of the in dep relation shown in Figure 7.2. Notice
thatwehavetorepeatthedepartmentinformation(“building”and“budget”)oncefor
eachinstructorinthedepartment.Forexample,theinformationabouttheComp.Sci.
department(Taylor,100000)isincludedinthetuplesofinstructorsKatz,Srinivasan,
andBrandt.
Itisimportantthatallthesetuplesagreeastothebudgetamountsinceotherwise
ourdatabasewouldbeinconsistent.Inouroriginaldesignusinginstructor anddepart-
ment, we stored the amount of each budget exactly once. This suggests that using in
depisabadideasinceitstoresthebudgetamountsredundantlyandrunstheriskthat
some user might update the budget amount in one tuple but not all, and thus create
inconsistency.
Evenifwedecidedtolivewiththeredundancyproblem,thereisstillanotherprob-
lem with the in dep schema. Suppose we are creating a new department in the uni-
versity. In the alternative design above, we cannot represent directly the information
concerninga department (dept name, building, budget) unless that department has at
leastoneinstructorattheuniversity.Thisisbecause tuplesinthein deptablerequire
values for ID, name, and salary. Thismeansthat wecannotrecord information about
thenewlycreateddepartmentuntilthefirstinstructorishiredforthenewdepartment.
Intheolddesign,theschemadepartmentcanhandlethis,butunderthereviseddesign,
wewouldhavetocreateatuplewithanullvalueforbuildingandbudget.Insomecases
nullvaluesaretroublesome,aswesawinourstudyofSQL.However,ifwedecidethat

--- Page 334 ---

7.1 FeaturesofGoodRelationalDesigns 305
ID name salary dept name building budget
22222 Einstein 95000 Physics Watson 70000
12121 Wu 90000 Finance Painter 120000
32343 ElSaid 60000 History Painter 50000
45565 Katz 75000 Comp.Sci. Taylor 100000
98345 Kim 80000 Elec.Eng. Taylor 85000
76766 Crick 72000 Biology Watson 90000
10101 Srinivasan 65000 Comp.Sci. Taylor 100000
58583 Califieri 62000 History Painter 50000
83821 Brandt 92000 Comp.Sci. Taylor 100000
15151 Mozart 40000 Music Packard 80000
33456 Gold 87000 Physics Watson 70000
76543 Singh 80000 Finance Painter 120000
Figure 7.2 Theindeprelation.
thisisnotaproblemtousinthiscase,thenwecanproceedtousethereviseddesign,
though,aswenoted,wewouldstillhavetheredundancyproblem.
7.1.1 Decomposition
Theonlywaytoavoidtherepetition-of-informationprobleminthein depschemaisto
decompose itintotwoschemas(inthiscase,theinstructor anddepartment schemas).
Later on in this chapter we shall present algorithms to decide which schemas are ap-
propriate and which ones are not. In general, a schema that exhibits repetition of in-
formationmayhavetobedecomposedintoseveralsmallerschemas.
Notalldecompositionsofschemasarehelpful.Consideranextremecaseinwhich
all schemas consist of one attribute. No interesting relationships of any kind could
be expressed. Now consider a less extreme case where we choose to decompose the
employeeschema(Section6.8):
employee(ID,name,street,city,salary)
intothefollowingtwoschemas:
employee1(ID,name)
employee2(name,street,city,salary)
The flaw in thisdecomposition arisesfrom the possibility thatthe enterprise has two
employeeswiththesamename.Thisisnotunlikelyinpractice,asmanycultureshave
certain highly popular names. Each person would have a unique employee-id, which
is why ID can serve as the primary key. As an example, letus assume two employees,

--- Page 335 ---

306 Chapter7 RelationalDatabaseDesign
both named Kim, work at the university and have the following tuples in the relation
onschemaemployeeintheoriginaldesign:
(57766,Kim,Main,Perryridge,75000)
(98776,Kim,North,Hampton,67000)
Figure 7.3 shows these tuples, the resulting tuples using the schemas resulting from
thedecomposition,andtheresultifweattemptedtoregeneratetheoriginaltuplesus-
ing a natural join. As we see in the figure, the twooriginal tuples appear in the result
along with two new tuples that incorrectly mix data values pertaining to the two em-
ployeesnamedKim.Althoughwehavemoretuples,weactuallyhavelessinformation
in the following sense. We can indicate that a certain street, city, and salary pertain
to someone named Kim, but we are unable to distinguish which of the Kims. Thus,
ourdecompositionisunable torepresentcertainimportantfactsabouttheuniversity
ID name street city salary
.
.
.
57766 Kim Main Perryridge 75000
98776 Kim North Hampton 67000
.
.
.
employee
ID name name street city salary
. . . . . .
57766 Kim Kim Main Perryridge 75000
98776 Kim Kim North Hampton 67000
. . . . . .
natural join
ID name street city salary
.
.
.
57766 Kim Main Perryridge 75000
57766 Kim North Hampton 67000
98776 Kim Main Perryridge 75000
98776 Kim North Hampton 67000
.
.
.
Figure 7.3 Lossofinformationviaabaddecomposition.

--- Page 336 ---

7.1 FeaturesofGoodRelationalDesigns 307
employees.Wewouldliketoavoidsuchdecompositions.Weshallrefertosuchdecom-
positionsasbeinglossydecompositions,and,conversely,tothosethatarenotaslossless
decompositions.
For the remainder of the text we shall insist that all decompositions should be
losslessdecompositions.
7.1.2 Lossless Decomposition
LetRbearelationschemaandletR andR formadecompositionofR—thatis,view-
1 2
ingR,R ,andR assetsofattributes,R = R ∪R .Wesaythatthedecompositionisa
1 2 1 2
losslessdecompositionifthereisnolossofinformationbyreplacingRwithtworelation
schemasR andR .Lossofinformationoccursifitispossibletohaveaninstanceof
1 2
a relation r(R) that includes information that cannot be represented if instead of the
instance of r(R) we must use instances of r (R ) and r (R ). More precisely, we say
1 1 2 2
thedecompositionislosslessif,foralllegal(weshallformallydefine“legal”inSection
7.2.2.)databaseinstances,relationrcontainsthesamesetoftuplesastheresultofthe
followingSQLquery:1
select*
from(selectR fromr)
1
naturaljoin
(selectR fromr)
2
Thisisstatedmoresuccinctlyintherelationalalgebraas:
Π (r) ⋈ Π (r) = r
R R
1 2
In other words, if we project r onto R and R , and compute the natural join of the
1 2
projectionresults,wegetbackexactlyr.
Conversely, a decomposition is lossy if when we compute the natural join of the
projectionresults,wegetapropersupersetoftheoriginalrelation.Thisisstatedmore
succinctlyintherelationalalgebraas:
r ⊂Π (r) ⋈ Π (r)
R R
1 2
Let us return to our decomposition of the employee schema into employee1 and
employee2(Figure7.3)andacasewheretwoormoreemployeeshavethesamename.
The result of employee1 natural join employee2 is a superset of the original relation
employee,butthedecompositionislossysincethejoinresulthaslostinformationabout
whichemployeeidentifierscorrespondtowhichaddressesandsalaries.
1Thedefinitionoflosslessisstatedassumingthatnoattributethatappearsontheleftsideofafunctionaldependency
canhaveanullvalue.ThisisexploredfurtherinExercise7.10.

--- Page 337 ---

308 Chapter7 RelationalDatabaseDesign
It may seem counterintuitive that we have more tuples but less information, but
thatisindeedthecase.Thedecomposedversionisunabletorepresenttheabsenceof
a connection between a name and an address or salary, and absence of a connection
isindeedinformation.
7.1.3 Normalization Theory
We are now in a position to define a general methodology for deriving a set of
schemas each of which isin “good form”; that is, does not suffer from the repetition-
of-informationproblem.
The method for designing a relational database is to use a process commonly
known as normalization. The goal is to generate a set of relation schemas that allows
ustostoreinformationwithoutunnecessaryredundancy,yetalsoallowsustoretrieve
informationeasily.Theapproachis:
• Decideifagivenrelationschemaisin“goodform.”Thereareanumberofdifferent
forms(callednormalforms),whichwecoverinSection7.3.
• If a given relation schema is not in “good form,” then we decompose it into a
number of smaller relation schemas, each of which is in an appropriate normal
form.Thedecompositionmustbealosslessdecomposition.
Todeterminewhetherarelationschemaisinoneofthedesirablenormalforms,we
needadditionalinformationaboutthereal-worldenterprisethatwearemodelingwith
thedatabase.Themostcommonapproachistousefunctionaldependencies,whichwe
coverinSection7.2.
7.2 Decomposition Using Functional Dependencies
Adatabasemodelsasetofentitiesandrelationshipsintherealworld.Thereareusually
avarietyofconstraints(rules)onthedataintherealworld.Forexample,someofthe
constraintsthatareexpectedtoholdinauniversitydatabaseare:
1. StudentsandinstructorsareuniquelyidentifiedbytheirID.
2. Eachstudentandinstructorhasonlyonename.
3. Eachinstructorandstudentis(primarily)associatedwithonlyonedepartment.2
4. Eachdepartmenthasonlyonevalueforitsbudget,andonlyoneassociatedbuild-
ing.
2Aninstructor,inmostrealuniversities,canbeassociatedwithmorethanonedepartment,forexample,viaajoint
appointmentorinthecaseofadjunctfaculty.Similarly,astudentmayhavetwo(ormore)majorsoraminor.Our
simplifieduniversityschemamodelsonlytheprimarydepartmentassociatedwitheachinstructororstudent.

--- Page 338 ---

7.2 DecompositionUsingFunctionalDependencies 309
An instance of a relation that satisfies all such real-world constraints is called a
legalinstanceoftherelation;alegalinstanceofadatabaseisonewherealltherelation
instancesarelegalinstances.
7.2.1 Notational Conventions
In discussing algorithms for relational database design, we shall need to talk about
arbitraryrelationsandtheirschema,ratherthantalkingonlyaboutexamples.Recalling
ourintroductiontotherelationalmodelinChapter2,wesummarizeournotationhere.
• Ingeneral,weuseGreeklettersforsetsofattributes(e.g.,α).Weuseanuppercase
Romanlettertorefertoarelationschema.Weusethenotationr(R)toshowthat
theschemaRisforrelationr.
Arelationschemaisasetofattributes,butnotallsetsofattributesareschemas.
When we use a lowercase Greek letter, we are referring to a set of attributes that
may or may not be a schema. A Roman letter is used when we wish to indicate
thatthesetofattributesisdefinitelyaschema.
• Whenasetofattributesisasuperkey,wemaydenoteitbyK.Asuperkeypertains
toaspecificrelationschema,soweusetheterminology“K isasuperkeyforR.”
• Weusealowercasenameforrelations.Inourexamples,thesenamesareintended
to be realistic (e.g., instructor), while in our definitions and algorithms, we use
singleletters,liker.
• Thenotationr(R)thusreferstotherelationrwithschemaR.Whenwewriter(R),
wethusreferbothtotherelationanditsschema.
• Arelation,hasaparticularvalueatanygiventime;werefertothatasaninstance
and use the term “instance of r.” When it is clear that we are talking about an
instance,wemayusesimplytherelationname(e.g.,r).
For simplicity, we assume that attribute names have only one meaning within the
databaseschema.
7.2.2 Keys and Functional Dependencies
Some of the most commonly used types of real-world constraints can be represented
formallyaskeys(superkeys,candidatekeys,andprimarykeys),orasfunctionaldepen-
dencies,whichwedefinebelow.
InSection2.3,wedefinedthenotionofasuperkeyasasetofoneormoreattributes
that,takencollectively,allowsustoidentifyuniquelyatupleintherelation.Werestate
that definitionhere as follows: Given r(R), a subset K of R isa superkey of r(R) if, in
anylegalinstanceofr(R),forallpairst andt oftuplesintheinstanceofrift ≠ t ,
1 2 1 2
thent [K] ≠ t [K].Thatis,notwotuplesinanylegalinstanceofrelationr(R)may
1 2

--- Page 339 ---

310 Chapter7 RelationalDatabaseDesign
have the same value on attribute set K.3 If no two tuples in r have the same value on
K,thenaK-valueuniquelyidentifiesatupleinr.
Whereasasuperkeyisasetofattributesthatuniquelyidentifiesanentiretuple,a
functionaldependencyallowsustoexpressconstraintsthatuniquelyidentifythevalues
ofcertainattributes.Considerarelationschemar(R),andletα⊆Randβ⊆R.
• Given an instance of r(R), we say that the instance satisfies the functional de-
pendency α → β if for all pairs of tuples t and t in the instance such that
1 2
t [α] = t [α],itisalsothecasethatt [β] = t [β].
1 2 1 2
• Wesaythatthefunctionaldependencyα→βholdsonschemar(R)if,everylegal
instanceofr(R)satisfiesthefunctionaldependency.
Using the functional-dependency notation, we say that K is a superkey for r(R) if
the functional dependency K → R holds on r(R). In other words, K is a superkey if,
for every legal instance of r(R), for every pair of tuples t and t from the instance,
1 2
whenevert [K] = t [K],itisalsothecasethatt [R] = t [R](i.e.,t = t ).4
1 2 1 2 1 2
Functional dependencies allow us to express constraints that we cannot express
withsuperkeys.InSection7.1,weconsideredtheschema:
in dep(ID,name,salary,dept name,building,budget)
in which the functional dependency dept name → budget holds because for each de-
partment(identifiedbydept name)thereisauniquebudgetamount.
Wedenotethefactthatthepairofattributes(ID,dept name)formsasuperkeyfor
in depbywriting:
ID,dept name→name,salary,building,budget
Weshallusefunctionaldependenciesintwoways:
1. TotestinstancesofrelationstoseewhethertheysatisfyagivensetF offunctional
dependencies.
2. To specify constraints on the set of legal relations. We shall thus concern our-
selveswithonlythoserelationinstancesthatsatisfyagivensetoffunctionalde-
pendencies. If we wish to constrain ourselves to relations on schema r(R) that
satisfyasetF offunctionaldependencies,wesaythatF holdsonr(R).
3Inourdiscussionoffunctionaldependencies,weuseequality(=)inthenormalmathematicalsense,notthethree-
valued-logicsenseofSQL.Saiddifferently,indiscussingfunctionaldependencies,weassumenonullvalues.
4Notethatweassumeherethatrelationsaresets.SQLdealswithmultisets,andaprimarykeydeclarationinSQLfora
setofattributesKrequiresnotonlythatt
1
= t
2
ift
1
[K] = t
2
[K],butalsothattherebenoduplicatetuples.SQLalso
requiresthatattributesinthesetKcannotbeassignedanullvalue.

--- Page 340 ---

7.2 DecompositionUsingFunctionalDependencies 311
A B C D
a b c d
1 1 1 1
a b c d
1 2 1 2
a b c d
2 2 2 2
a b c d
2 3 2 3
a b c d
3 3 2 4
Figure 7.4 Sampleinstanceofrelationr.
Let us consider the instance of relation r of Figure 7.4, to see which functional
dependenciesare satisfied. Observe that A → C is satisfied. There are two tuples that
have an A value of a . These tuples have the same C value—namely, c . Similarly,the
1 1
two tuples with an A value of a have the same C value, c . There are no other pairs
2 2
ofdistincttuplesthathavethesameAvalue.ThefunctionaldependencyC →Aisnot
satisfied,however.Toseethatitisnot,considerthetuplest =(a ,b ,c ,d )andt =
1 2 3 2 3 2
(a ,b ,c ,d ). These two tuples have the same C values, c , but they have different A
3 3 2 4 2
values,a anda ,respectively.Thus,wehavefoundapairoftuplest andt suchthat
2 3 1 2
t [C] = t [C],butt [A] ≠ t [A].
1 2 1 2
Somefunctionaldependenciesaresaidtobetrivialbecausetheyaresatisfiedbyall
relations.Forexample,A→AissatisfiedbyallrelationsinvolvingattributeA.Reading
thedefinitionoffunctionaldependencyliterally,weseethat,foralltuplest andt such
1 2
thatt [A] = t [A], itisthe case thatt [A] = t [A]. Similarly,AB → A issatisfied
1 2 1 2
by all relations involving attribute A. In general, a functional dependencyof the form
α→βistrivialifβ⊆α.
Itisimportanttorealizethataninstanceofarelationmaysatisfysomefunctional
dependenciesthatarenotrequiredtoholdontherelation’sschema.Intheinstanceof
the classroom relation of Figure 7.5, we see that room number → capacity is satisfied.
However, we believe that, in the real world, two classrooms in differentbuildings can
have the same room number but with different room capacity. Thus, it is possible, at
some time, to have an instance of the classroom relation in which room number →
capacityisnotsatisfied.So,wewouldnotincluderoom number→capacityinthesetof
building room number capacity
Packard 101 500
Painter 514 10
Taylor 3128 70
Watson 100 30
Watson 120 50
Figure 7.5 Aninstanceoftheclassroom relation.

--- Page 341 ---

312 Chapter7 RelationalDatabaseDesign
functionaldependenciesthatholdontheschemafortheclassroomrelation.However,
wewouldexpectthefunctionaldependencybuilding,room number→capacitytohold
ontheclassroomschema.
Because we assume that attribute names have only one meaning in the database
schema, if we state that a functional dependency α → β holds as a constraint on the
database,thenforanyschemaRsuchthatα ⊆ Randβ ⊆R,α → βmusthold.
Given that a set of functional dependencies F holds on a relation r(R), it may
be possible to infer that certain other functional dependenciesmust also hold on the
relation.Forexample,givenaschemar(A,B,C),iffunctionaldependenciesA → Band
B → C holdonr,wecaninferthefunctionaldependencyA → C mustalsoholdonr.
Thisisbecause,givenanyvalueofA,therecanbeonlyonecorrespondingvalueforB,
andforthatvalueofB,therecanonlybeonecorrespondingvalueforC.Westudyin
Section7.4.1,howtomakesuchinferences.
We shall use the notation F+ todenote the closureof thesetF,thatis, thesetof
allfunctionaldependenciesthatcanbeinferredgiventhesetF.F+ containsallofthe
functionaldependenciesinF.
7.2.3 Lossless Decomposition and Functional Dependencies
Wecanusefunctionaldependenciestoshowwhencertaindecompositionsarelossless.
Let R, R , R , and F be as above. R and R form a lossless decomposition of R if at
1 2 1 2
leastoneofthefollowingfunctionaldependenciesisinF+:
• R ∩R → R
1 2 1
• R ∩R → R
1 2 2
Inotherwords,ifR ∩R formsasuperkeyforeitherR orR ,thedecompositionofRis
1 2 1 2
alosslessdecomposition.Wecanuseattributeclosuretotestefficientlyforsuperkeys,
aswehaveseenearlier.
Toillustratethis,considertheschema
in dep(ID,name,salary,dept name,building,budget)
thatwedecomposedinSection7.1intotheinstructor anddepartmentschemas:
instructor (ID,name,dept name,salary)
department(dept name,building,budget)
Consider the intersection of these two schemas, which is dept name. We see that be-
cause dept name→ dept name, building, budget, the lossless-decomposition rule is sat-
isfied.

--- Page 342 ---

7.3 NormalForms 313
Forthegeneralcaseofdecompositionofaschemaintomultipleschemasatonce,
thetestforlosslessdecompositionismorecomplicated.SeetheFurtherReadingsec-
tionattheendofthischapterforreferencesonthistopic.
Whilethetestforbinarydecompositionisclearlyasufficientconditionforlossless
decomposition,itisanecessaryconditiononlyifallconstraintsarefunctionaldepen-
dencies.Weshallseeothertypesofconstraintslater(inparticular,atypeofconstraint
calledmultivalueddependenciesdiscussedinSection7.6.1)thatcanensurethatade-
compositionislosslessevenifnofunctionaldependenciesarepresent.
Supposewedecomposearelationschemar(R)intor (R )andr (R ),whereR ∩
1 1 2 2 1
R → R .5 Then the following SQL constraints must be imposed on the decomposed
2 1
schematoensuretheircontentsareconsistentwiththeoriginalschema.
• R ∩R istheprimarykeyofr .
1 2 1
Thisconstraintenforcesthefunctionaldependency.
• R ∩R isaforeignkeyfromr referencingr .
1 2 2 1
This constraint ensures that each tuple in r has a matching tuple in r , without
2 1
whichitwouldnotappearinthenaturaljoinofr andr .
1 2
Ifr orr isdecomposedfurther,aslongasthedecompositionensuresthatallattributes
1 2
inR ∩R areinonerelation,theprimaryorforeign-keyconstraintonr orr would
1 2 1 2
beinheritedbythatrelation.
7.3 Normal Forms
Asstated inSection7.1.3,thereareanumberofdifferentnormalformsthatareused
in designing relational databases. In this section, we cover two of the most common
ones.
7.3.1 Boyce–Codd Normal Form
OneofthemoredesirablenormalformsthatwecanobtainisBoyce–Coddnormalform
(BCNF).Iteliminatesallredundancythatcanbediscoveredbasedonfunctionaldepen-
dencies,though,asweshallseeinSection7.6,theremaybeothertypesofredundancy
remaining.
7.3.1.1 Definition
ArelationschemaRisinBCNFwithrespecttoasetFoffunctionaldependenciesif,
for all functional dependencies in F+ of the form α → β, where α ⊆ R and β ⊆ R, at
leastoneofthefollowingholds:
5ThecaseforR ∩R →R issymmetrical,andignored.
1 2 2

--- Page 343 ---

314 Chapter7 RelationalDatabaseDesign
• α → βisatrivialfunctionaldependency(i.e.,β ⊆ α).
• αisasuperkeyforschemaR.
AdatabasedesignisinBCNFifeachmemberofthesetofrelationschemasthatcon-
stitutesthedesignisinBCNF.
WehavealreadyseeninSection7.1anexampleofarelationalschemathatisnot
inBCNF:
in dep(ID,name,salary,dept name,building,budget)
Thefunctionaldependencydept name→budgetholdsonin dep,butdept nameisnota
superkey(becauseadepartmentmayhaveanumberofdifferentinstructors).InSection
7.1 we saw that the decomposition of in dep into instructor and department is a better
design.TheinstructorschemaisinBCNF.Allofthenontrivialfunctionaldependencies
thathold,suchas:
ID→name,dept name,salary
includeIDontheleftsideofthearrow,andIDisasuperkey(actually,inthiscase,the
primary key) for instructor. (In other words, there is no nontrivial functional depen-
dency with any combination of name, dept name, and salary, without ID, on the left
side.)Thus,instructor isinBCNF.
Similarly,thedepartmentschemaisinBCNFbecauseallofthenontrivialfunctional
dependenciesthathold,suchas:
dept name→building,budget
include dept name on the leftside of the arrow, and dept nameis a superkey (and the
primarykey)fordepartment.Thus,departmentisinBCNF.
We now state a general rule for decomposing schemas that are not in BCNF. Let
R be a schema that is not in BCNF. Then there is at least one nontrivial functional
dependencyα → βsuchthatαisnotasuperkeyforR.WereplaceRinourdesignwith
twoschemas:
• (α∪β)
• (R−(β−α))
Inthecaseofin depabove,α=dept name,β={building,budget},andin depisreplaced
by
• (α∪β)=(dept name,building,budget)
• (R−(β−α))=(ID,name,dept name,salary)

--- Page 344 ---

7.3 NormalForms 315
department
dept_name
building
budget
instructor student
ID dept_advisor ID
name name
salary tot_cred
Figure 7.6 Thedeptadvisor relationshipset.
Inthisexample,itturnsoutthatβ−α = β.Weneedtostate theruleaswedidsoas
todealcorrectlywithfunctionaldependenciesthathaveattributesthatappearonboth
sidesofthearrow.ThetechnicalreasonsforthisarecoveredlaterinSection7.5.1.
When we decompose a schema that is not in BCNF, it may be that one or more
of the resulting schemas are not in BCNF. In such cases, further decomposition is
required,theeventualresultofwhichisasetofBCNFschemas.
7.3.1.2 BCNFandDependencyPreservation
We have seen several ways in which to express database consistency constraints:
primary-key constraints, functional dependencies, check constraints, assertions, and
triggers.Testingtheseconstraintseachtimethedatabaseisupdatedcanbecostlyand,
therefore,itisusefultodesignthedatabaseinawaythatconstraintscanbetestedeffi-
ciently.Inparticular,iftestingafunctionaldependencycanbedonebyconsideringjust
one relation,then thecostof testing thisconstraintislow.We shallsee that,in some
cases,decompositionintoBCNFcanpreventefficienttestingofcertainfunctionalde-
pendencies.
Toillustratethis,supposethatwemakeasmallchangetoouruniversityorganiza-
tion. In the design of Figure 6.15, a student may have only one advisor. This follows
fromtherelationshipsetadvisorbeingmany-to-onefromstudenttoadvisor.The“small”
changeweshallmakeisthataninstructorcanbeassociatedwithonlyasingledepart-
ment, and a student may have more than one advisor, but no more than one from a
givendepartment.6
One way to implement this change using the E-R design is by replacing the advi-
sor relationship set with a ternary relationship set, dept advisor, involving entity sets
instructor, student, and department that is many-to-one from the pair {student, instruc-
tor}todepartmentasshowninFigure7.6.TheE-Rdiagramspecifiestheconstraintthat
6Suchanarrangementmakessenseforstudentswithadoublemajor.

--- Page 345 ---

316 Chapter7 RelationalDatabaseDesign
“astudentmayhavemorethanoneadvisor,butatmostonecorrespondingtoagiven
department.”
WiththisnewE-Rdiagram,theschemasfortheinstructor,department,andstudent
relations are unchanged. However, the schema derived from the dept advisor relation-
shipsetisnow:
dept advisor (s ID,i ID,dept name)
Although not specified in the E-R diagram, suppose we have the additional con-
straintthat“aninstructorcanactasadvisorforonlyasingledepartment.”
Then,thefollowingfunctionaldependenciesholdondept advisor:
i ID→dept name
s ID,dept name→i ID
Thefirstfunctionaldependencyfollowsfromourrequirementthat“aninstructorcan
act as an advisor for only one department.” The second functional dependency fol-
lows from our requirement that “a student may have at most one advisor for a given
department.”
Notice that with this design, we are forced to repeat the department name once
foreachtimeaninstructorparticipatesinadept advisor relationship.Weseethatdept
advisor is not in BCNF because i ID is not a superkey. Following our rule for BCNF
decomposition,weget:
(s ID,i ID)
(i ID,dept name)
BoththeaboveschemasareBCNF.(Infact,youcanverifythatanyschemawithonly
twoattributesisinBCNFbydefinition.)
Note, however, that in our BCNF design, there is no schema that includes all the
attributes appearing in the functional dependency s ID, dept name → i ID. The only
dependencythatcanbeenforcedontheindividualdecomposedrelationsisID→dept
name. The functional dependency s ID, dept name → i ID can only be checked by
computingthejoinofthedecomposedrelations.7
Becauseourdesigndoesnotpermittheenforcementofthisfunctionaldependency
withoutajoin,wesaythatourdesignisnotdependencypreserving(weprovideaformal
definition of dependency preservation in Section 7.4.4). Because dependency preser-
vationisusuallyconsidereddesirable,weconsideranothernormalform,weakerthan
BCNF,thatwillallowustopreservedependencies.Thatnormalformiscalledthethird
normalform.8
7Technically,itispossiblethatadependencywhoseattributesdonotallappearinanyoneschemaisstillimplicitly
enforced,becauseofthepresenceofotherdependenciesthatimplyitlogically.WeaddressthatcaseinSection7.4.4.
8Youmayhavenotedthatweskippedsecondnormalform.Itisofhistoricalsignificanceonlyand,inpractice,oneof
thirdnormalformorBCNFisalwaysabetterchoice.WeexploresecondnormalforminExercise7.19.Firstnormal
formpertainstoattributedomains,notdecomposition.WediscussitinSection7.8.

--- Page 346 ---

7.3 NormalForms 317
7.3.2 Third Normal Form
BCNF requires that all nontrivial dependencies be of the form α → β, where α is a
superkey.Thirdnormalform(3NF)relaxesthisconstraintslightlybyallowingcertain
nontrivialfunctionaldependencieswhoseleftsideisnotasuperkey.Beforewedefine
3NF,werecallthatacandidatekeyisaminimalsuperkey—thatis,asuperkeynoproper
subsetofwhichisalsoasuperkey.
A relation schema R is in third normal form with respect to a set F of functional
dependenciesif,forallfunctionaldependenciesinF+oftheformα → β,whereα ⊆ R
andβ ⊆ R,atleastoneofthefollowingholds:
• α → βisatrivialfunctionaldependency.
• αisasuperkeyforR.
• EachattributeAinβ−αiscontainedinacandidatekeyforR.
Notethatthethirdconditionabovedoesnotsaythatasinglecandidatekeymustcon-
tainalltheattributesinβ−α;eachattributeAinβ−αmaybecontainedinadifferent
candidatekey.
The first two alternatives are the same as the two alternatives in the definition of
BCNF.Thethirdalternativeinthe3NFdefinitionseemsratherunintuitive,anditisnot
obviouswhyitisuseful.Itrepresents,insomesense,aminimalrelaxationoftheBCNF
conditionsthathelpsensurethateveryschemahasadependency-preservingdecompo-
sitioninto3NF.Itspurposewillbecomemoreclearlater,whenwestudydecomposition
into3NF.
Observe that any schema that satisfies BCNF also satisfies 3NF, since each of its
functionaldependencieswouldsatisfyoneofthefirsttwoalternatives.BCNFisthere-
foreamorerestrictivenormalformthanis3NF.
Thedefinitionof3NFallowscertainfunctionaldependenciesthatarenotallowed
in BCNF. A dependency α → β that satisfies only the third alternative of the 3NF
definitionisnotallowedinBCNFbutisallowedin3NF.9
Now,letusagainconsidertheschemaforthedept advisor relation,whichhasthe
followingfunctionaldependencies:
i ID→dept name
s ID,dept name→i ID
In Section 7.3.1.2, we argued that the functional dependency “i ID → dept name”
caused the dept advisor schemanot to be in BCNF. Note that here α = i ID, β = dept
name, and β − α = dept name. Since the functional dependency s ID, dept name →
9Thesedependenciesareexamplesoftransitivedependencies(seePracticeExercise7.18).Theoriginaldefinitionof
3NFwasintermsoftransitivedependencies.Thedefinitionweuseisequivalentbuteasiertounderstand.

--- Page 347 ---

318 Chapter7 RelationalDatabaseDesign
i IDholdsondept advisor,theattributedept nameiscontainedinacandidatekeyand,
therefore,dept advisor isin3NF.
Wehaveseenthetrade-offthatmustbemadebetweenBCNFand3NFwhenthereis
nodependency-preservingBCNFdesign.Thesetrade-offsaredescribedinmoredetail
inSection7.3.3.
7.3.3 Comparison of BCNF and 3NF
Of the two normal forms for relational database schemas, 3NF and BCNF there are
advantages to 3NF in that we know that it is always possible to obtain a 3NF design
without sacrificing losslessness or dependency preservation. Nevertheless, there are
disadvantagesto3NF:Wemayhavetousenullvaluestorepresentsomeofthepossible
meaningful relationships among data items, and there is the problem of repetition of
information.
Ourgoalsofdatabasedesignwithfunctionaldependenciesare:
1. BCNF.
2. Losslessness.
3. Dependencypreservation.
Sinceitisnotalwayspossibletosatisfyallthree,wemaybeforcedtochoosebetween
BCNFanddependencypreservationwith3NF.
ItisworthnotingthatSQLdoesnotprovideawayofspecifyingfunctionaldepen-
dencies,exceptforthespecialcaseofdeclaringsuperkeysbyusingtheprimarykeyor
uniqueconstraints.Itispossible,althoughalittlecomplicated,towriteassertionsthat
enforce a functional dependency (see Practice Exercise 7.9); unfortunately, currently
no database system supports the complex assertions that are required to enforce ar-
bitrary functional dependencies, and the assertions would be expensive to test. Thus
evenifwehadadependency-preservingdecomposition,ifweusestandardSQLwecan
testefficientlyonlythosefunctionaldependencieswhoseleft-handsideisakey.
Althoughtestingfunctionaldependenciesmayinvolveajoinifthedecomposition
is not dependencypreserving, if the database system supports materializedviews, we
couldinprinciplereducethecostbystoringthejoinresultasmaterializedview;how-
ever, this approach is feasible only if the database system supports primary key con-
straints or unique constraints on materialized views. On the negative side, there is a
space and time overhead due to the materialized view, but on the positive side, the
application programmer need not worry about writing code to keep redundant data
consistent on updates; it is the job of the database system to maintain the material-
izedview,thatis,keepituptodatewhenthedatabaseisupdated.(InSection16.5,we
outlinehowadatabasesystemcanperformmaterializedviewmaintenanceefficiently.)
Unfortunately, most current database systems limit constraints on materialized
views or do not support them at all. Even if such constraints are allowed, there is an
additional requirement: the database must update the view and check the constraint

--- Page 348 ---

7.3 NormalForms 319
immediately(aspartofthesametransaction)whenanunderlyingrelationisupdated.
Otherwise,aconstraintviolationmaygetdetectedwellaftertheupdatehasbeenper-
formedandthetransactionthatcausedtheviolationhascommitted.
Insummary,evenifwearenotabletogetadependency-preservingBCNFdecom-
position,itisstillpreferabletooptforBCNF,sincecheckingfunctionaldependencies
otherthanprimarykeyconstraintsisdifficultinSQL.
7.3.4 Higher Normal Forms
Using functional dependenciesto decompose schemas may not be sufficient to avoid
unnecessaryrepetitionofinformationincertaincases.Consideraslightvariationinthe
instructorentity-setdefinitioninwhichwerecordwitheachinstructorasetofchildren’s
names and a set of landline phone numbers that may be shared by multiple people.
Thus, phone number and child name would be multivalued attributes and, following
ourrulesforgeneratingschemasfromanE-Rdesign,wewouldhavetwoschemas,one
foreachofthemultivaluedattributes,phone number andchild name:
(ID,child name)
(ID,phone number)
Ifweweretocombinetheseschemastoget
(ID,child name,phone number)
wewouldfindtheresulttobeinBCNFbecausenonontrivialfunctionaldependencies
hold.Asaresultwemightthinkthatsuchacombinationisagoodidea.However,such
a combination is a bad idea, as we can see by considering the example of an instruc-
tor with two children and two phone numbers. For example, let the instructor with
ID 99999 have two children named “David” and “William” and two phone numbers,
512-555-1234 and 512-555-4321. In the combined schema, we must repeat the phone
numbersonceforeachdependent:
(99999,David,512-555-1234)
(99999,David,512-555-4321)
(99999,William,512-555-1234)
(99999,William,512-555-4321)
If we did not repeat the phone numbers, and we stored only the first and last tu-
ples, we would have recorded the dependent names and the phone numbers, but the
resultanttupleswouldimplythatDavidcorrespondedto512-555-1234,whileWilliam
correspondedto512-555-4321.Thiswouldbeincorrect.
Becausenormalformsbasedonfunctionaldependenciesarenotsufficienttodeal
withsituationslikethis,otherdependenciesandnormalformshavebeendefined.We
covertheseinSection7.6andSection7.7.

--- Page 349 ---

320 Chapter7 RelationalDatabaseDesign
7.4 Functional-Dependency Theory
Wehaveseeninourexamplesthatitisusefultobeabletoreasonsystematicallyabout
functionaldependenciesaspartofaprocessoftestingschemasforBCNFor3NF.
7.4.1 Closure of a Set of Functional Dependencies
Weshallseethat,givenasetF offunctionaldependenciesonaschema,wecanprove
thatcertainotherfunctionaldependenciesalsoholdontheschema.Wesaythatsuch
functionaldependenciesare“logicallyimplied”byF.Whentestingfornormalforms,
itisnotsufficienttoconsiderthegivensetoffunctionaldependencies;rather,weneed
toconsiderall functionaldependenciesthatholdontheschema.
Moreformally,givenarelationschemar(R),afunctionaldependencyf onRislog-
icallyimpliedbyasetoffunctionaldependenciesF onRifeveryinstanceofarelation
r(R)thatsatisfiesF alsosatisfiesf.
Supposewearegivenarelationschemar(A,B,C,G,H,I)andthesetoffunctional
dependencies:
A→B
A→C
CG →H
CG →I
B→H
Thefunctionaldependency:
A→H
is logically implied. That is, we can show that, whenever a relation instance satisfies
ourgivensetoffunctionaldependencies,A→H mustalsobesatisfiedbythatrelation
instance.Supposethatt andt aretuplessuchthat:
1 2
t [A] = t [A]
1 2
SincewearegiventhatA→B,itfollowsfromthedefinitionoffunctionaldependency
that:
t [B] = t [B]
1 2
Then, since we are given that B → H, it follows from the definition of functional de-
pendencythat:
t [H] = t [H]
1 2

--- Page 350 ---

7.4 Functional-DependencyTheory 321
Therefore,wehaveshownthat,whenevert andt aretuplessuchthatt [A] = t [A],
1 2 1 2
itmustbethatt [H] = t [H].ButthatisexactlythedefinitionofA → H.
1 2
LetF beasetoffunctionaldependencies.TheclosureofF,denotedbyF+,isthe
setofallfunctionaldependencieslogicallyimpliedbyF.GivenF,wecancomputeF+
directlyfromtheformaldefinitionoffunctionaldependency.IfF werelarge,thispro-
cesswouldbelengthyanddifficult.SuchacomputationofF+requiresargumentsofthe
typejustusedtoshowthatA→H isintheclosureofourexamplesetofdependencies.
Axioms,orrulesofinference,provideasimplertechniqueforreasoningaboutfunc-
tionaldependencies.Intherulesthatfollow,weuseGreekletters(α,β,γ,…)forsets
ofattributesanduppercaseRomanlettersfromthebeginningofthealphabetforindi-
vidualattributes.Weuseαβtodenoteα ∪ β.
Wecanusethefollowingthreerulestofindlogicallyimpliedfunctionaldependen-
cies.Byapplyingtheserulesrepeatedly,wecanfindallofF+,givenF.Thiscollection
ofrulesiscalledArmstrong’saxiomsinhonorofthepersonwhofirstproposedit.
• Reflexivityrule.Ifαisasetofattributesandβ ⊆ α,thenα→βholds.
• Augmentation rule. If α → β holds and γ is a set of attributes, then γα → γβ
holds.
• Transitivityrule.Ifα→βholdsandβ→γholds,thenα→γholds.
Armstrong’s axioms are sound, because they do not generate any incorrect func-
tional dependencies. They are complete, because, for a given set F of functional de-
pendencies, they allow us to generate all F+. The Further Reading section provides
referencesforproofsofsoundnessandcompleteness.
Although Armstrong’s axioms are complete, it is tiresome to use them directly
for the computation of F+. To simplify matters further, we list additional rules. It is
possible to use Armstrong’s axioms to prove that these rules are sound (see Practice
Exercise7.4,PracticeExercise7.5,andExercise7.27).
• Unionrule.Ifα→βholdsandα→γholds,thenα→βγholds.
• Decompositionrule.Ifα→βγholds,thenα→βholdsandα→γholds.
• Pseudotransitivityrule.Ifα→βholdsandγβ→δholds,thenαγ→δholds.
LetusapplyourrulestotheexampleofschemaR= (A,B,C,G,H,I)andtheset
F of functional dependencies {A → B, A → C, CG → H, CG → I, B → H}. We list
severalmembersofF+ here:
• A → H.SinceA → BandB → H hold,weapplythetransitivityrule.Observethat
itwas much easier to use Armstrong’s axioms to show thatA → H holds than it
wastoarguedirectlyfromthedefinitions,aswedidearlierinthissection.
• CG → HI.SinceCG → H andCG → I,theunionruleimpliesthatCG → HI.

--- Page 351 ---

322 Chapter7 RelationalDatabaseDesign
F+ =F
applythereflexivityrule/*Generatesalltrivialdependencies*/
repeat
foreachfunctionaldependencyf inF+
applytheaugmentationruleonf
addtheresultingfunctionaldependenciestoF+
foreachpairoffunctionaldependenciesf andf inF+
1 2
iff andf canbecombinedusingtransitivity
1 2
addtheresultingfunctionaldependencytoF+
untilF+ doesnotchangeanyfurther
Figure 7.7 Aproceduretocompute F+.
• AG → I. Since A → C and CG → I, the pseudotransitivity rule implies that
AG → I holds.
Another way of finding that AG → I holds is as follows: We use the augmen-
tation rule on A → C to infer AG → CG. Applying the transitivity rule to this
dependencyandCG → I,weinferAG → I.
Figure7.7showsaprocedurethatdemonstratesformallyhowtouseArmstrong’s
axioms to compute F+. In this procedure, when a functional dependency is added to
F+,itmaybealreadypresent,andinthatcasethereisnochangetoF+.Weshallsee
analternativewayofcomputingF+ inSection7.4.2.
The left-hand and right-hand sides of a functional dependency are both subsets
of R. Since a set of size n has 2n subsets, there are a total of 2n × 2n = 22n possible
functional dependencies, where n is the number of attributes in R. Each iteration of
therepeatloopoftheprocedure,exceptthelastiteration,addsatleastonefunctional
dependency to F+. Thus, the procedure is guaranteed to terminate, though it may be
verylengthy.
7.4.2 Closure of Attribute Sets
We say that an attribute B is functionally determined by α if α → B. To test whether
a set α is a superkey, we must devise an algorithm for computing the set of attributes
functionally determined by α. One way of doing this is to compute F+, take all func-
tionaldependencieswithαastheleft-handside,andtaketheunionoftheright-hand
sides of all such dependencies. However, doing so can be expensive, since F+ can be
large.
Anefficientalgorithmforcomputingthesetofattributesfunctionallydetermined
by α is useful not only for testing whether α is a superkey, but also for several other
tasks,asweshallseelaterinthissection.

--- Page 352 ---

7.4 Functional-DependencyTheory 323
Letαbeasetofattributes.Wecallthesetofallattributesfunctionallydetermined
byαunderasetF offunctionaldependenciestheclosureofαunderF;wedenoteitby
α+. Figure 7.8 shows an algorithm, written in pseudocode, to compute α+. The input
is a set F of functional dependenciesand the set α of attributes. The output is stored
inthevariableresult.
To illustrate how the algorithm works, we shall use it to compute (AG)+ with the
functionaldependenciesdefinedinSection7.4.1.Westartwithresult = AG.Thefirst
timethatweexecutetherepeatlooptotesteachfunctionaldependency,wefindthat:
• A → BcausesustoincludeBinresult.Toseethisfact,weobservethatA → Bis
inF,A ⊆result(whichisAG),soresult:=result∪B.
• A→C causesresulttobecomeABCG.
• CG→H causesresulttobecomeABCGH.
• CG→I causesresulttobecomeABCGHI.
Thesecondtimethatweexecutetherepeatloop,nonewattributesareaddedtoresult,
andthealgorithmterminates.
Let us see why the algorithm of Figure 7.8 is correct. The first step is correct be-
cause α → α always holds (by the reflexivity rule). We claim that, for any subset β of
result,α→β.Sincewestarttherepeatloopwithα→resultbeingtrue,wecanaddγto
resultonlyifβ⊆resultandβ→γ.Butthenresult→βbythereflexivityrule,soα→β
bytransitivity.Anotherapplicationoftransitivityshowsthatα→γ(usingα→βand
β → γ). The union rule impliesthat α → result ∪ γ, so α functionallydeterminesany
newresultgeneratedintherepeatloop.Thus,anyattributereturnedbythealgorithm
isinα+.
Itiseasytoseethatthealgorithmfindsallofα+.ConsideranattributeAinα+that
isnotyetinresultatanypointduringtheexecution.Theremustbeawaytoprovethat
result → A using the axioms. Either result → A is in F itself (making the proof trivial
andensuringAisaddedtoresult)ortheremustaproofstepusingtransitivitytoshow
result:= α;
repeat
foreachfunctionaldependencyβ→γinF do
begin
ifβ ⊆ resultthenresult:=result∪γ;
end
until(resultdoesnotchange)
Figure 7.8 Analgorithmtocompute α+,theclosureofαunderF.

--- Page 353 ---

324 Chapter7 RelationalDatabaseDesign
forsomeattributeBthatresult→B.IfithappensthatA = B,thenwehaveshownthat
Aisaddedtoresult.Ifnot,B ≠ Aisadded.Thenrepeatingthisargument,weseethat
Amusteventuallybeaddedtoresult.
It turns out that, in the worst case, this algorithm may take an amount of time
quadraticinthesizeofF.Thereisafaster(althoughslightlymorecomplex)algorithm
thatrunsintimelinearinthesizeofF;thatalgorithmispresentedaspartofPractice
Exercise7.8.
Thereareseveralusesoftheattributeclosurealgorithm:
• Totestifαisasuperkey,wecomputeα+ andcheckifα+ containsallattributesin
R.
• We can check if a functional dependency α → β holds (or, in other words, is in
F+),bycheckingifβ ⊆ α+.Thatis,wecomputeα+byusingattributeclosure,and
then checkifitcontainsβ.Thistest is particularlyuseful, as weshall see laterin
thischapter.
• ItgivesusanalternativewaytocomputeF+:Foreachγ ⊆ R,wefindtheclosure
γ+,andforeachS ⊆γ+,weoutputafunctionaldependencyγ → S.
7.4.3 Canonical Cover
SupposethatwehaveasetoffunctionaldependenciesF onarelationschema.When-
everauser performs an update on the relation,the database system must ensure that
theupdatedoesnotviolateanyfunctionaldependencies,thatis,allthefunctionalde-
pendenciesinF aresatisfiedinthenewdatabasestate.
Thesystemmustrollbacktheupdateifitviolatesanyfunctionaldependenciesin
thesetF.
Wecanreducetheeffortspentincheckingforviolationsbytestingasimplifiedset
of functional dependencies that has the same closure as the given set. Any database
thatsatisfiesthesimplifiedsetoffunctionaldependenciesalsosatisfiestheoriginalset,
and vice versa, since the two sets have the same closure. However, the simplified set
is easier to test. We shall see how the simplified set can be constructed in a moment.
First,weneedsomedefinitions.
Anattributeofafunctionaldependencyissaidtobeextraneousifwecanremove
itwithoutchangingtheclosureofthesetoffunctionaldependencies.
• Removing an attribute from the leftside of a functional dependencycould make
it a stronger constraint. For example, if we have AB → C and remove B, we get
the possibly stronger result A → C. It may be stronger because A → C logically
implies AB → C, but AB → C does not, on its own, logically imply A → C.
But, depending on what our set F of functional dependencies happens to be, we
may be able to removeB from AB → C safely. Forexample, suppose that the set

--- Page 354 ---

7.4 Functional-DependencyTheory 325
F = {AB → C,A → D,D → C}. Then we can show that F logically implies
A → C,makingBextraneousinAB → C.
• Removinganattributefromtherightsideofafunctionaldependencycouldmake
it a weaker constraint. For example, if we have AB → CD and remove C, we get
thepossiblyweakerresultAB → D.ItmaybeweakerbecauseusingjustAB → D,
we can no longer infer AB → C. But, depending on what our set F of functional
dependencieshappens tobe, wemaybe able toremoveC from AB → CDsafely.
For example, suppose that F = {AB → CD,A → C}. Then we can show that
even after replacing AB → CD by AB → D, we can still infer AB → C and thus
AB → CD.
The formal definition of extraneous attributes is as follows: Consider a set F of
functionaldependenciesandthefunctionaldependencyα→βinF.
• Removalfromtheleftside:AttributeAisextraneousinαifA ∈ αandF logically
implies(F −{α → β}) ∪ {(α−A) → β}.
• Removalfromtherightside:AttributeAisextraneousinβifA ∈ βandthesetof
functionaldependencies(F −{α→β})∪{α → (β − A)}logicallyimpliesF.
Bewareofthedirectionoftheimplicationswhenusingthedefinitionofextraneous
attributes:Ifyoureversethestatement,theimplicationwillalwayshold.Thatis,(F −
{α → β}) ∪ {(α−A) → β} always logically implies F, and also F always logically
implies(F −{α→β})∪{α → (β − A)}.
Hereishowwecantestefficientlyifanattributeisextraneous.LetRbetherelation
schema,andletF bethegivensetoffunctionaldependenciesthatholdonR.Consider
anattributeAinadependencyα → β.
• IfA ∈ β,tocheckifAisextraneous,considertheset
F′ =(F −{α→β})∪{α → (β − A)}
andcheckifα → AcanbeinferredfromF′.Todoso,computeα+ (theclosureof
α)underF′;ifα+ includesA,thenAisextraneousinβ.
• IfA ∈ α,tocheckifAisextraneous, letγ = α−{A},andcheckifγ → βcanbe
inferred from F. To do so, compute γ+ (the closure of γ) under F; if γ+ includes
allattributesinβ,thenAisextraneousinα.
Forexample,supposeF containsAB → CD,A → E,andE → C.TocheckifC is
extraneousinAB → CD,wecomputetheattributeclosureofABunderF′ = {AB → D,
A → E, E → C}. The closure is ABCDE, which includes CD, so we infer that C is
extraneous.

--- Page 355 ---

326 Chapter7 RelationalDatabaseDesign
F = F
c
repeat
UsetheunionruletoreplaceanydependenciesinF oftheform
c
α → β andα → β withα → β β .
1 1 1 2 1 1 2
Findafunctionaldependencyα → βinF withanextraneous
c
attributeeitherinαorinβ.
/*Note:thetestforextraneousattributesisdoneusingF ,notF */
c
Ifanextraneousattributeisfound,deleteitfromα →βinF .
c
until(F doesnotchange)
c
Figure 7.9 Computingcanonical cover.
Having defined the concept of extraneous attributes, we can explain how we can
constructasimplifiedsetoffunctionaldependenciesequivalenttoagivensetoffunc-
tionaldependencies.
A canonical cover F for F is a set of dependencies such that F logically implies
c
alldependenciesinF ,andF logicallyimpliesalldependenciesinF.Furthermore,F
c c c
musthavethefollowingproperties:
• NofunctionaldependencyinF containsanextraneousattribute.
c
• EachleftsideofafunctionaldependencyinF isunique.Thatis,therearenotwo
c
dependenciesα → β andα → β inF suchthatα = α .
1 1 2 2 c 1 2
A canonicalcoverfor asetoffunctional dependenciesF can be computed as de-
scribedinFigure7.9.Itisimportanttonotethatwhencheckingifanattributeisextra-
neous,thecheckusesthedependenciesinthecurrentvalue ofF ,andnotthedepen-
c
dencies in F. If a functional dependency contains only one attribute in its right-hand
side,forexampleA → C,andthatattribute isfoundtobeextraneous, wewouldgeta
functional dependency with an empty right-hand side. Such functional dependencies
shouldbedeleted.
Sincethealgorithmpermitsachoiceofanyextraneousattribute,itispossiblethat
there may be several possible canonical covers for a given F. Any such F is equally
c
acceptable. Any canonical cover of F, F , can be shown to have the same closure as
c
F; hence, testing whetherF is satisfied is equivalent to testing whetherF is satisfied.
c
However, F is minimal in a certain sense—it does not contain extraneous attributes,
c
and it combines functional dependencieswith the same left side. It is cheaper to test
F thanitistotestF itself.
c
Wenowconsideranexample.AssumewearegiventhefollowingsetF offunctional
dependenciesonschema(A,B,C):

--- Page 356 ---

7.4 Functional-DependencyTheory 327
A→BC
B→C
A→B
AB→C
LetuscomputeacanonicalcoverforF.
• Therearetwofunctionaldependencieswiththesamesetofattributes ontheleft
sideofthearrow:
A→BC
A→B
WecombinethesefunctionaldependenciesintoA→BC.
• AisextraneousinAB → C becauseF logicallyimplies(F −{AB → C}) ∪ {B →
C}.ThisassertionistruebecauseB→C isalreadyinoursetoffunctionaldepen-
dencies.
• C isextraneousinA→BC,sinceA→BC islogicallyimpliedbyA→BandB→
C.
Thus,ourcanonicalcoveris:
A→B
B→C
Given a set F of functional dependencies, it may be that an entire functional de-
pendency in the set is extraneous, in the sense that dropping it does not change the
closureofF.WecanshowthatacanonicalcoverF ofF containsnosuchextraneous
c
functional dependency. Suppose that, to the contrary, there were such an extraneous
functional dependency in F . The right-side attributes of the dependency would then
c
beextraneous,whichisnotpossiblebythedefinitionofcanonicalcovers.
Aswenotedearlier,acanonicalcovermightnotbeunique.Forinstance,consider
thesetoffunctionaldependenciesF = {A → BC,B → AC,andC → AB}.Ifweapply
thetestforextraneousattributestoA → BC,wefindthatbothBandC areextraneous
underF.However,itisincorrecttodeleteboth!Thealgorithmforfindingthecanonical
coverpicksoneofthetwoanddeletesit.Then,
1. IfCisdeleted,wegetthesetF′ = {A → B,B → AC,andC →AB}.Now,Bisnot
extraneous on the right side of A → B under F′. Continuing the algorithm, we
findAandBareextraneousintherightsideofC → AB,leadingtotwochoices
ofcanonicalcover:

--- Page 357 ---

328 Chapter7 RelationalDatabaseDesign
computeF+;
foreachschemaR inDdo
i
begin
F :=therestrictionofF+ toR;
i i
end
F′ :=∅
foreachrestrictionF do
i
begin
F′ = F′∪F
i
end
computeF′+;
if(F′+ =F+)thenreturn(true)
elsereturn(false);
Figure 7.10 Testingfordependencypreservation.
F = {A → B,B → C,C → A}
c
F = {A → B,B → AC,C → B}.
c
2. If B is deleted, we get the set {A → C, B → AC, and C → AB}. This case
is symmetrical to the previous case, leading to two more choices of canonical
cover:
F ={A →C,C → B,andB → A}
c
F ={A →C,B → C,andC → AB}.
c
Asanexercise,canyoufindonemorecanonicalcoverforF?
7.4.4 Dependency Preservation
Using the theory of functional dependencies, there is a way to describe dependency
preservationthatissimplerthantheadhocapproachweusedinSection7.3.1.2.
LetF beasetoffunctionaldependenciesonaschemaR,andletR ,R ,…,R bea
1 2 n
decompositionofR.TherestrictionofFtoR isthesetF ofallfunctionaldependencies
i i
inF+thatincludeonlyattributesofR.Sinceallfunctionaldependenciesinarestriction
i
involveattributesofonlyonerelationschema,itispossibletotestsuchadependency
forsatisfactionbycheckingonlyonerelation.
Note that the definition of restriction uses all dependencies in F+, not just those
inF.Forinstance,supposeF = {A → B,B → C},andwehaveadecompositioninto
AC and AB. The restriction of F to AC includes A → C, since A → C is in F+, even
thoughitisnotinF.

--- Page 358 ---

7.4 Functional-DependencyTheory 329
ThesetofrestrictionsF , F ,…,F isthesetofdependenciesthatcanbechecked
1 2 n
efficiently.Wenowmustaskwhethertestingonlytherestrictionsissufficient.LetF′ =
F ∪ F ∪ ⋯ ∪ F .F′isasetoffunctionaldependenciesonschemaR,but,ingeneral,
1 2 n
F′ ≠ F. However, even if F′ ≠ F, it may be that F′+ = F+. If the latter is true, then
every dependency in F is logically implied by F′, and, if we verify that F′ is satisfied,
we have verified that F is satisfied. We say that a decomposition having the property
F′+ = F+ isadependency-preservingdecomposition.
Figure7.10shows an algorithmfortesting dependencypreservation. The inputis
a setD = {R , R ,…,R } of decomposed relation schemas,and a set F of functional
1 2 n
dependencies.ThisalgorithmisexpensivesinceitrequirescomputationofF+.Instead
ofapplyingthealgorithmofFigure7.10,weconsidertwoalternatives.
First, note that if each member of F can be tested on one of the relations of the
decomposition,thenthedecompositionisdependencypreserving.Thisisaneasyway
to show dependency preservation; however, it does not always work. There are cases
where,eventhoughthedecompositionisdependencypreserving,thereisadependency
in F that cannot be tested in any one relation in the decomposition. Thus, this alter-
nativetestcanbeusedonlyasasufficientconditionthatiseasytocheck;ifitfailswe
cannotconcludethatthedecompositionisnotdependencypreserving;insteadwewill
havetoapplythegeneraltest.
We now give a second alternative test for dependency preservation that avoids
computing F+. We explain the intuition behind the test after presenting the test. The
testappliesthefollowingproceduretoeachα → βinF.
result=α
repeat
foreachR inthedecomposition
i
t=(result∩R)+∩R
i i
result=result∪t
until(result doesnotchange)
TheattributeclosurehereisunderthesetoffunctionaldependenciesF.Ifresult con-
tains all attributes in β, then the functional dependency α → β is preserved. The de-
composition is dependency preserving if and only if the procedure shows that all the
dependenciesinF arepreserved.
Thetwokeyideasbehindtheprecedingtestareasfollows:
• The first idea is to test each functional dependency α → β in F to see if it is
preserved in F′ (where F′ is as defined in Figure 7.10). To do so, we compute
the closure of α under F′; the dependency is preserved exactly when the closure
includes β. The decomposition is dependency preserving if (and only if) all the
dependenciesinF arefoundtobepreserved.

--- Page 359 ---

330 Chapter7 RelationalDatabaseDesign
• The second idea is to use a modified form of the attribute-closure algorithm to
compute closure under F′, without actuallyfirst computing F′. We wish to avoid
computing F′ since computing it is quite expensive. Note that F′ is the union of
allF,whereF istherestrictionofF onR.Thealgorithmcomputestheattribute
i i i
closureof(result∩R)withrespecttoF,intersectstheclosurewithR,andaddsthe
i i
resultantsetofattributestoresult;thissequenceofstepsisequivalenttocomputing
theclosureofresult underF.Repeatingthisstepforeachi insidethewhileloop
i
givestheclosureofresultunderF′.
Tounderstandwhythismodifiedattribute-closureapproachworkscorrectly,we
notethatforanyγ ⊆ R,γ → γ+isafunctionaldependencyinF+,andγ → γ+∩R
i i
isafunctionaldependencythatisinF,therestrictionofF+ toR.Conversely,if
i i
γ → δwereinF,thenδwouldbeasubsetofγ+∩R.
i i
This test takes polynomial time, instead of the exponential time required to com-
puteF+.
7.5 Algorithms for Decomposition Using Functional Dependencies
Real-world database schemas are much larger than the examples that fit in the pages
ofabook.Forthisreason,weneedalgorithmsforthegenerationofdesignsthatarein
appropriatenormalform.Inthissection,wepresentalgorithmsforBCNFand3NF.
7.5.1 BCNF Decomposition
ThedefinitionofBCNFcanbeuseddirectlytotestifarelationisinBCNF.However,
computationofF+canbeatedioustask.Wefirstdescribesimplifiedtestsforverifying
if a relation is in BCNF. If a relation is not in BCNF, it can be decomposed to create
relationsthatareinBCNF.Laterinthissection,wedescribeanalgorithmtocreatea
losslessdecompositionofarelation,suchthatthedecompositionisinBCNF.
7.5.1.1 TestingforBCNF
Testing of a relation schema R to see if it satisfies BCNF can be simplified in some
cases:
• Tocheckifanontrivialdependencyα → βcausesaviolationofBCNF,compute
α+ (the attribute closure of α), and verify that it includesall attributes of R; that
is,itisasuperkeyforR.
• TocheckifarelationschemaRisinBCNF,itsufficestocheckonlythedependen-
ciesin the given set F for violation of BCNF, rather than checkall dependencies
inF+.
WecanshowthatifnoneofthedependenciesinF causesaviolationofBCNF,
thennoneofthedependenciesinF+ willcauseaviolationofBCNF,either.

--- Page 360 ---

7.5 AlgorithmsforDecompositionUsingFunctionalDependencies 331
result:={R};
done:=false;
while(notdone)do
if(thereisaschemaR inresultthatisnotinBCNF)
i
thenbegin
letα → βbeanontrivialfunctionaldependencythatholds
onR suchthatα+ doesnotcontainR andα∩β = ∅;
i i
result:=(result−R)∪(R −β)∪(α,β);
i i
end
elsedone:=true;
Figure 7.11 BCNFdecompositionalgorithm.
Unfortunately, the latter procedure does not work when a relation schema is decom-
posed. That is, it does not suffice to use F when we test a relation schema R, in a
i
decomposition of R, for violation of BCNF. For example, consider relation schema
(A,B,C,D,E), with functional dependenciesF containing A → B and BC → D. Sup-
pose this were decomposed into (A,B) and (A,C,D,E). Now, neither of the depen-
dencies in F contains only attributes from (A,C,D,E), so we might be misled into
thinkingthatitisinBCNF.Infact,thereisadependencyAC → DinF+(whichcanbe
inferredusingthepseudotransitivityrulefromthetwodependenciesinF)thatshows
that(A,C,D,E)isnotinBCNF.Thus,wemayneedadependencythatisinF+,butis
notinF,toshowthatadecomposedrelationisnotinBCNF.
An alternative BCNF test is sometimes easier than computing every dependency
inF+.TocheckifarelationschemaR inadecompositionofRisinBCNF,weapply
i
thistest:
• For every subset α of attributes in R, check that α+ (the attribute closure
i
ofαunderF)eitherincludesnoattributeofR −α,orincludesallattributesofR.
i i
If the condition is violated by some set of attributes α in R, consider the following
i
functionaldependency,whichcanbeshowntobepresentinF+:
α → (α+−α)∩R.
i
ThisdependencyshowsthatR violatesBCNF.
i
7.5.1.2 BCNFDecompositionAlgorithm
We are now able to state a general method to decompose a relation schema so as to
satisfy BCNF. Figure 7.11 shows an algorithm for this task. If R is not in BCNF, we
candecomposeRintoacollectionofBCNFschemasR ,R ,…,R bythealgorithm.
1 2 n

--- Page 361 ---

332 Chapter7 RelationalDatabaseDesign
Thealgorithmusesdependenciesthatdemonstrate violationof BCNFtoperformthe
decomposition.
The decomposition that the algorithm generates is not only in BCNF, but is also
a lossless decomposition. To see why our algorithm generates only lossless decom-
positions, we note that, when we replace a schema R with (R − β) and (α,β), the
i i
dependencyα → βholds,and(R −β)∩(α,β)=α.
i
Ifwedidnotrequireα∩β = ∅,thenthoseattributesinα∩βwouldnotappearin
theschema(R −β),andthedependencyα → βwouldnolongerhold.
i
It is easy to see that our decomposition of in dep in Section 7.3.1 would result
fromapplyingthealgorithm.Thefunctionaldependencydept name→building,budget
satisfies the α ∩ β = ∅ condition and would therefore be chosen to decompose the
schema.
TheBCNFdecompositionalgorithmtakestimeexponentialtothesizeoftheinitial
schema,sincethealgorithmforcheckingwhetherarelationinthedecompositionsat-
isfiesBCNFcantakeexponentialtime.ThereisanalgorithmthatcancomputeaBCNF
decompositioninpolynomialtime;however,thealgorithmmay“overnormalize,”that
is,decomposearelationunnecessarily.
AsalongerexampleoftheuseoftheBCNFdecompositionalgorithm,supposewe
haveadatabasedesignusingtheclassrelation,whoseschemaisasshownbelow:
class(course id,title,dept name,credits,sec id,semester,year,building,
room number,capacity,time slot id)
Thesetoffunctionaldependenciesthatweneedtoholdonthisschemaare:
course id → title,deptname,credits
building,room number →capacity
course id,sec id,semester,year→building,room number,time slot id
Acandidatekeyforthisschemais{course id,sec id,semester,year}.
WecanapplythealgorithmofFigure7.11totheclassexampleasfollows:
• Thefunctionaldependency:
course id → title,deptname,credits
holds,butcourse id isnotasuperkey.Thus,classisnotinBCNF.Wereplaceclass
withtworelationswiththefollowingschemas:
course(course id,title,dept name,credits)
class-1(course id,sec id,semester,year,building,room number
capacity,time slot id)

--- Page 362 ---

7.5 AlgorithmsforDecompositionUsingFunctionalDependencies 333
Theonlynontrivialfunctionaldependenciesthatholdoncourseincludecourse id
on the left side of the arrow. Since course id is a superkey for course, course is in
BCNF.
• Acandidatekeyforclass-1is{course id,sec id,semester,year}.Thefunctionalde-
pendency:
building,room number →capacity
holds on class-1, but {building, room number} is not a superkey for class-1. We re-
placeclass-1tworelationswiththefollowingschemas:
classroom(building,room number,capacity)
section(course id,sec id,semester,year,
building,room number,time slot id)
ThesetwoschemasareinBCNF.
Thus,thedecompositionofclassresultsinthethreerelationschemascourse,classroom,
andsection,eachofwhichisinBCNF.Thesecorrespondtotheschemasthatwehave
used in this and previous chapters. You can verify that the decomposition is lossless
anddependencypreserving.
7.5.2 3NF Decomposition
Figure7.12showsanalgorithmforfindingadependency-preserving,losslessdecompo-
sitioninto3NF.ThesetofdependenciesF usedinthealgorithmisacanonicalcover
c
forF.NotethatthealgorithmconsidersthesetofschemasR, j = 1,2,…,i; initially
j
i = 0,andinthiscasethesetisempty.
Letusapplythisalgorithmtoourexampleofdept advisorfromSection7.3.2,where
weshowedthat:
dept advisor (s ID,i ID,dept name)
is in 3NF even though it is not in BCNF. The algorithm uses the following functional
dependenciesinF:
f :i ID→dept name
1
f :s ID,dept name→i ID
2
Therearenoextraneous attributes inanyofthefunctionaldependenciesinF,so
F containsf andf .ThealgorithmthengeneratesasR theschema,(i ID dept name),
c 1 2 1
andasR theschema(s ID,dept name,i ID).ThealgorithmthenfindsthatR contains
2 2
acandidatekey,sonofurtherrelationschemaiscreated.

--- Page 363 ---

334 Chapter7 RelationalDatabaseDesign
letF beacanonicalcoverforF;
c
i:=0;
foreachfunctionaldependencyα→ βinF
c
i:=i+1;
R :=αβ;
i
ifnoneoftheschemasR,j = 1,2,…,icontainsacandidatekeyforR
j
then
i := i+1;
R :=anycandidatekeyforR;
i
/*Optionally,removeredundantrelations*/
repeat
ifanyschemaR iscontainedinanotherschemaR
j k
then
/*DeleteR */
j
R :=R;
j i
i:=i-1;
untilnomoreRscanbedeleted
j
return(R ,R ,…,R)
1 2 i
Figure 7.12 Dependency-preserving, losslessdecompositioninto3NF.
Theresultantsetofschemascancontainredundantschemas,withoneschemaR
k
containingalltheattributesofanotherschemaR.Forexample,R abovecontainsall
j 2
the attributes from R . The algorithm deletes all such schemas that are contained in
1
another schema. Any dependencies that could be tested on an R that is deleted can
j
alsobetestedonthecorrespondingrelationR ,andthedecompositionislosslesseven
k
ifR isdeleted.
j
Now let us consider again the schema of the class relation of Section 7.5.1.2 and
apply the 3NF decomposition algorithm. The set of functional dependencies we listed
therehappentobeacanonicalcover.Asaresult,thealgorithmgivesusthesamethree
schemascourse,classroom,andsection.
The preceding example illustrates an interesting property of the 3NF algorithm.
Sometimes, the result is not only in 3NF, but also in BCNF. This suggests an alterna-
tive methodof generating a BCNF design. Firstuse the 3NF algorithm. Then, forany
schemainthe3NFdesignthatisnotinBCNF,decomposeusingtheBCNFalgorithm.
Iftheresultisnotdependency-preserving,reverttothe3NFdesign.
7.5.3 Correctness of the 3NF Algorithm
The 3NF algorithm ensures the preservation of dependencies by explicitly building a
schemaforeachdependencyinacanonicalcover.Itensuresthatthedecompositionisa

--- Page 364 ---

7.5 AlgorithmsforDecompositionUsingFunctionalDependencies 335
losslessdecompositionbyguaranteeingthatatleastoneschemacontainsacandidate
key for the schema being decomposed. Practice Exercise 7.16 provides some insight
intotheproofthatthissufficestoguaranteealosslessdecomposition.
Thisalgorithmisalsocalledthe3NFsynthesisalgorithm,sinceittakesasetofde-
pendenciesandaddsoneschemaatatime,insteadofdecomposingtheinitialschema
repeatedly. The result is not uniquely defined, since a set of functional dependencies
canhavemorethanonecanonicalcover.Thealgorithmmaydecomposearelationeven
ifitisalreadyin3NF;however,thedecompositionisstillguaranteedtobein3NF.
To see that the algorithm produces a 3NF design, consider a schema R in the
i
decomposition. Recall that when we test for 3NF it suffices to consider functional
dependencieswhoseright-handsideconsistsofasingleattribute.Therefore,toseethat
R is in 3NF you must convince yourself that any functional dependency γ → B that
i
holdsonR satisfiesthedefinitionof3NF.Assumethatthedependencythatgenerated
i
R inthesynthesisalgorithmisα → β.Bmustbeinαorβ,sinceBisinR andα → β
i i
generatedR.Letusconsiderthethreepossiblecases:
i
• Bisinbothαandβ.Inthiscase,thedependencyα → βwouldnothavebeenin
F sinceBwouldbeextraneousinβ.Thus,thiscasecannothold.
c
• Bisinβbutnotα.Considertwocases:
° γisasuperkey.Thesecondconditionof3NFissatisfied.
° γisnotasuperkey.Thenαmustcontainsomeattributenotinγ.Now,sinceγ →
BisinF+,itmustbederivablefromF byusingtheattributeclosurealgorithm
c
on γ.The derivation couldnothave used α → β,because ifithad been used,
α must be contained in the attribute closure of γ,whichisnotpossible, since
we assumed γ is not a superkey. Now, using α → (β − {B}) and γ → B, we
can derive α → B (since γ ⊆ αβ, and γ cannot contain B because γ → B
is nontrivial). This would imply that B is extraneous in the right-hand side of
α → β,whichisnotpossiblesinceα → βisinthecanonicalcoverF .Thus,if
c
Bisinβ,thenγmustbeasuperkey,andthesecondconditionof3NFmustbe
satisfied.
• Bisinαbutnotβ.
Sinceαisacandidatekey,thethirdalternativeinthedefinitionof3NFissatisfied.
Interestingly, the algorithm we described for decomposition into 3NF can be im-
plementedinpolynomialtime,eventhoughtestingagivenschematoseeifitsatisfies
3NFisNP-hard(whichmeansthatitisveryunlikelythatapolynomial-timealgorithm
willeverbeinventedforthistask).

--- Page 365 ---

336 Chapter7 RelationalDatabaseDesign
7.6 Decomposition Using Multivalued Dependencies
Somerelationschemas,eventhoughtheyareinBCNF,donotseemtobesufficiently
normalized, in the sense that they still suffer from the problem of repetition of infor-
mation.Consideravariationoftheuniversityorganizationwhereaninstructormaybe
associatedwithmultipledepartments,andwehavearelation:
inst(ID,dept name,name,street,city)
The astute reader will recognize this schema as a non-BCNF schema because of the
functionaldependency
ID → name,street,city
andbecauseIDisnotakeyforinst.
Furtherassumethataninstructormayhaveseveraladdresses(say,awinterhome
andasummerhome).Then,wenolongerwishtoenforcethefunctionaldependency
“ID→street,city”,though,westillwanttoenforce“ID → name”(i.e.,theuniversityis
notdealingwithinstructorswhooperateundermultiplealiases!).FollowingtheBCNF
decompositionalgorithm,weobtaintwoschemas:
r (ID,name)
1
r (ID,dept name,street,city)
2
Both of these are in BCNF (recall that an instructor can be associated with multiple
departmentsandadepartmentmayhaveseveralinstructors,andtherefore,neither“ID
→dept name”nor“dept name→ID”hold).
Despiter beinginBCNF,thereisredundancy.Werepeattheaddressinformation
2
ofeachresidenceofaninstructoronceforeachdepartmentwithwhichtheinstructor
isassociated.Wecouldsolvethisproblembydecomposingr furtherinto:
2
r (dept name,ID)
21
r (ID,street,city)
22
butthereisnoconstraintthatleadsustodothis.
Todealwiththisproblem,wemustdefineanewformofconstraint,calledamul-
tivalued dependency. As we did for functional dependencies, we shall use multivalued
dependenciestodefineanormalformforrelationschemas.Thisnormalform,called
fourthnormalform(4NF),ismorerestrictivethanBCNF.Weshallseethatevery4NF
schemaisalsoinBCNFbutthereareBCNFschemasthatarenotin4NF.

--- Page 366 ---

7.6 DecompositionUsingMultivaluedDependencies 337
α β R―α―β
t a ...a a ...a a ...a
1 1 i i + 1 j j + 1 n
t a ...a b ...b b ...b
2 1 i i + 1 j j + 1 n
t a ...a a ...a b ...b
3 1 i i + 1 j j + 1 n
t a ...a b ...b a ...a
4 1 i i + 1 j j + 1 n
Figure 7.13 Tabularrepresentationofα→→β.
7.6.1 Multivalued Dependencies
Functional dependencies rule out certain tuples from being in a relation. If A → B,
thenwecannothavetwotupleswiththesameAvaluebutdifferentBvalues.Multival-
ued dependencies, on the other hand, do not rule out the existence of certain tuples.
Instead,theyrequirethatothertuplesofacertainformbepresentintherelation.For
this reason, functional dependencies sometimes are referred to as equality-generating
dependencies,and multivalued dependenciesarereferredto astuple-generating depen-
dencies.
Letr(R)bearelationschemaandletα ⊆ Randβ⊆R.Themultivalueddependency
α→→ β
holdsonRif,inanylegalinstanceofrelationr(R),forallpairsoftuplest andt inr
1 2
suchthatt [α] = t [α],thereexisttuplest andt inrsuchthat
1 2 3 4
t [α] = t [α] = t [α] = t [α]
1 2 3 4
t [β] = t [β]
3 1
t [R−β] = t [R−β]
3 2
t [β] = t [β]
4 2
t [R−β] = t [R−β]
4 1
This definition is less complicated than it appears to be. Figure 7.13 gives a tabular
pictureoft ,t ,t ,andt .Intuitively,themultivalueddependencyα →→ βsaysthatthe
1 2 3 4
relationshipbetweenαandβisindependentoftherelationshipbetweenαandR−β.
If the multivalued dependency α →→ β is satisfied by all relations on schema R, then
α →→ β is a trivial multivalued dependency on schema R. Thus, α →→ β is trivial if
β ⊆ αorβ∪α = R.ThiscanbeseenbylookingatFigure7.13andconsideringthetwo
specialcasesβ ⊆αandβ∪α =R.Ineachcase,thetablereducestojusttwocolumns
andweseethatt andt areabletoserveintherolesoft andt .
1 2 3 4
To illustrate the differencebetween functional and multivalued dependencies, we
considertheschemar again,andanexamplerelationonthatschemaisshowninFig-
2
ure7.14.Wemustrepeatthedepartmentnameonceforeachaddressthataninstructor
has, and we must repeat the address for each department with which an instructor is
associated.Thisrepetitionisunnecessary,sincetherelationshipbetweenaninstructor

--- Page 367 ---

338 Chapter7 RelationalDatabaseDesign
ID dept name street city
22222 Physics North Rye
22222 Physics Main Manchester
12121 Finance Lake Horseneck
Figure 7.14 Anexample ofredundancyinarelationonaBCNFschema.
and his address is independent of the relationship between that instructor and a de-
partment.IfaninstructorwithID22222isassociatedwiththePhysicsdepartment,we
wantthatdepartmenttobeassociatedwithallofthatinstructor’saddresses.Thus,the
relationofFigure7.15isillegal.Tomakethisrelationlegal,weneedtoaddthetuples
(Physics,22222,Main,Manchester)and(Math,22222,North,Rye)totherelationof
Figure7.15.
Comparingtheprecedingexamplewithourdefinitionofmultivalueddependency,
weseethatwewantthemultivalueddependency:
ID →→ street,city
to hold. (The multivalued dependency ID →→ dept name will do as well. We shall
soonseethattheyareequivalent.)
As with functional dependencies, we shall use multivalued dependencies in two
ways:
1. To test relations to determine whether they are legal under a given set of func-
tionalandmultivalueddependencies.
2. Tospecifyconstraintsonthesetoflegalrelations;weshallthusconcernourselves
with only those relations that satisfy a given set of functional and multivalued
dependencies.
Note that, if a relation r fails to satisfy a given multivalued dependency, we can con-
structarelationr′ thatdoessatisfythemultivalueddependencybyaddingtuplestor.
Let D denote a set of functional and multivalued dependencies. The closure D+
of D is the set of all functional and multivalued dependencies logically implied by D.
Aswedidforfunctional dependencies,wecancompute D+ from D,usingtheformal
definitionsoffunctionaldependenciesandmultivalueddependencies.Wecanmanage
ID dept name street city
22222 Physics North Rye
22222 Math Main Manchester
Figure 7.15 Anillegalr 2 relation.

--- Page 368 ---

7.6 DecompositionUsingMultivaluedDependencies 339
with such reasoning for very simple multivalued dependencies. Luckily, multivalued
dependenciesthatoccurinpracticeappeartobequitesimple.Forcomplexdependen-
cies, it is better to reason about sets of dependencies by using a system of inference
rules.
Fromthedefinitionofmultivalueddependency,wecanderivethefollowingrules
forα,β ⊆ R:
• If α → β, then α →→ β. In other words, every functional dependency is also a
multivalueddependency.
• Ifα →→ β,thenα →→ R−α−β
Section28.1.1outlinesasystemofinferencerulesformultivalueddependencies.
7.6.2 Fourth Normal Form
ConsideragainourexampleoftheBCNFschema:
r (ID,dept name,street,city)
2
inwhichthemultivalueddependencyID →→ street,cityholds.Wesawintheopening
paragraphsofSection7.6that,althoughthisschemaisinBCNF,thedesignisnotideal,
sincewemustrepeataninstructor’saddressinformationforeachdepartment.Weshall
seethatwecanusethegivenmultivalueddependencytoimprovethedatabasedesign
bydecomposingthisschemaintoafourthnormalformdecomposition.
A relation schema R is in fourth normal form (4NF) with respect to a set D of
functionalandmultivalueddependenciesif,forallmultivalueddependenciesinD+ of
theformα→→β,whereα⊆Randβ⊆R,atleastoneofthefollowingholds:
• α→→βisatrivialmultivalueddependency.
• αisasuperkeyforR.
Adatabasedesignisin4NFifeachmemberofthesetofrelationschemasthatconsti-
tutesthedesignisin4NF.
Notethatthedefinitionof4NFdiffersfromthedefinitionofBCNFinonlytheuse
ofmultivalueddependencies.Every4NFschemaisinBCNF.Toseethisfact,wenote
that, if a schema R is not in BCNF, then there is a nontrivial functional dependency
α → βholdingonR,whereαisnotasuperkey.Sinceα→βimpliesα→→β,Rcannot
bein4NF.
Let R be a relation schema, and let R ,R ,…,R be a decomposition of R. To
1 2 n
checkifeachrelationschemaR inthedecompositionisin4NF,weneedtofindwhat
i
multivalueddependenciesholdoneachR.Recallthat,forasetFoffunctionaldepen-
i
dencies, the restriction F of F to R is all functional dependenciesin F+ that include
i i
only attributesof R.Now considerasetDofbothfunctional andmultivalueddepen-
i
dencies.TherestrictionofDtoR isthesetD consistingof:
i i

--- Page 369 ---

340 Chapter7 RelationalDatabaseDesign
1. AllfunctionaldependenciesinD+ thatincludeonlyattributesofR.
i
2. Allmultivalueddependenciesoftheform:
α →→ β∩R
i
whereα ⊆ R andα →→ βisinD+.
i
7.6.3 4NF Decomposition
The analogy between 4NF and BCNF applies to the algorithm for decomposing a
schemainto 4NF. Figure7.16 shows the 4NF decomposition algorithm.It isidentical
to the BCNF decomposition algorithm of Figure 7.11, except that it uses multivalued
dependenciesandusestherestrictionofD+ toR.
i
IfweapplythealgorithmofFigure7.16to(ID,dept name,street,city),wefindthat
ID→→ dept name is a nontrivial multivalued dependency, and ID is not a superkey for
theschema.Followingthealgorithm,wereplaceitwithtwoschemas:
(ID,dept name)
(ID,street,city)
Thispairofschemas,whichisin4NF,eliminatestheredundancyweencounteredear-
lier.
Aswasthecasewhenweweredealingsolelywithfunctionaldependencies,weare
interestedindecompositionsthatarelosslessandthatpreservedependencies.Thefol-
lowingfactaboutmultivalueddependenciesandlosslessnessshowsthatthealgorithm
ofFigure7.16generatesonlylosslessdecompositions:
result:={R};
done:=false;
computeD+;GivenschemaR,letD denotetherestrictionofD+ toR
i i i
while(notdone)do
if(thereisaschemaR inresultthatisnotin4NFw.r.t.D)
i i
thenbegin
letα→→βbeanontrivialmultivalueddependencythatholds
onR suchthatα → R isnotinD,andα ∩ β = ∅;
i i i
result:=(result−R) ∪ (R − β) ∪ (α, β);
i i
end
elsedone:=true;
Figure 7.16 4NFdecompositionalgorithm.

--- Page 370 ---

7.7 MoreNormalForms 341
• Let r(R) be a relation schema, and let D be a set of functional and multivalued
dependencies on R. Let r (R ) and r (R ) form a decomposition of R. This de-
1 1 2 2
compositionofRislosslessifandonlyifatleastoneofthefollowingmultivalued
dependenciesisinD+:
R ∩R →→ R
1 2 1
R ∩R →→ R
1 2 2
Recall that we stated in Section 7.2.3 that, if R ∩R → R or R ∩R → R , then
1 2 1 1 2 2
r (R ) and r (R ) forms a lossless decomposition of r(R). The preceding fact about
1 1 2 2
multivalueddependenciesisamoregeneralstatementaboutlosslessness.Itsaysthat,
for every lossless decomposition of r(R) into two schemas r (R ) and r (R ), one of
1 1 2 2
the two dependencies R ∩R →→ R or R ∩R →→ R must hold. To see that this
1 2 1 1 2 2
is true, we need to show first that if at least one of these dependencies holds, then
Π (r) ⋈ Π (r) = r andnextweneedtoshowthatifΠ (r) ⋈ Π (r) = r thenr(R)
R R R R
1 2 1 2
must satisfy at least one of these dependencies. See the Further Reading section for
referencestoafullproof.
Theissue ofdependencypreservation when wedecompose arelationschemabe-
comesmorecomplicatedinthepresenceofmultivalueddependencies.Section28.1.2
pursuesthistopic.
A further complication arises from the fact that it is possible for a multivalued
dependencytoholdonlyonapropersubsetofthegivenschema,withnowaytoexpress
that multivalued dependency on that given schema. Such a multivalued dependency
mayappearastheresultofadecomposition.Fortunately,suchcases,calledembedded
multivalueddependencies,arerare.SeetheFurtherReadingsectionfordetails.
7.7 More Normal Forms
Thefourthnormalformisbynomeansthe“ultimate”normalform.Aswesawearlier,
multivalueddependencieshelpusunderstandandeliminatesomeformsofrepetition
ofinformationthatcannotbeunderstoodintermsoffunctionaldependencies.There
aretypesofconstraintscalledjoindependenciesthatgeneralizemultivalueddependen-
cies and lead to another normal form called project-join normal form (PJNF). PJNF is
calledfifthnormalforminsomebooks.Thereisaclassofevenmoregeneralconstraints
thatleadstoanormalformcalleddomain-keynormalform(DKNF).
A practical problem with the use of these generalized constraints is that they are
notonlyhardtoreasonwith,butthereisalsonosetofsoundandcompleteinference
rulesforreasoningabouttheconstraints.HencePJNFandDKNFareusedquiterarely.
Chapter28providesmoredetailsaboutthesenormalforms.
Conspicuousbyitsabsencefromourdiscussionofnormalformsissecondnormal
form(2NF).Wehavenotdiscusseditbecauseitisofhistoricalinterestonly.Wesimply

--- Page 371 ---

342 Chapter7 RelationalDatabaseDesign
define it and let you experiment with it in Practice Exercise 7.19. First normal form
dealswithadifferentissue than the normalforms wehave seen so far.Itisdiscussed
inthenextsection.
7.8 Atomic Domains and First Normal Form
The E-R model allows entity sets and relationship sets to have attributes that have
somedegreeofsubstructure.Specifically,itallowsmultivaluedattributessuchasphone
numberinFigure6.8andcompositeattributes(suchasanattributeaddresswithcom-
ponent attributes street, city, and state). When we create tables from E-R designs that
contain these types of attributes, we eliminate this substructure. For composite at-
tributes, we let each component be an attribute in its own right. For multivalued at-
tributes,wecreateonetupleforeachiteminamultivaluedset.
Intherelationalmodel,weformalizethisideathatattributesdonothaveanysub-
structure.Adomainisatomicifelementsofthedomainareconsideredtobeindivisible
units. We saythatarelationschemaRisin firstnormalform(1NF) ifthe domainsof
allattributesofRareatomic.
Asetofnamesisanexampleofanon-atomicvalue.Forexample,iftheschemaof
a relation employee included an attribute children whose domain elements are sets of
names,theschemawouldnotbeinfirstnormalform.
Compositeattributes,suchasanattributeaddresswithcomponentattributesstreet
andcityalsohavenon-atomicdomains.
Integers are assumed to be atomic, so the set of integers is an atomic domain;
however, the set of all sets of integers is a non-atomic domain. The distinction is that
wedonotnormallyconsiderintegerstohavesubparts,butweconsidersetsofintegers
to have subparts—namely, the integers making up the set. But the important issue is
notwhatthedomainitselfis,butratherhowweusedomainelementsinourdatabase.
Thedomainofallintegerswouldbenon-atomicifweconsideredeachintegertobean
orderedlistofdigits.
Asa practicalillustration of thispoint, consideran organization that assigns em-
ployees identification numbers of the following form: The first two letters specify the
departmentandtheremainingfourdigitsareauniquenumberwithinthedepartment
fortheemployee.Examples ofsuchnumberswouldbe“CS001” and“EE1127”. Such
identificationnumberscanbedividedintosmallerunitsandarethereforenon-atomic.
Ifarelationschemahadanattributewhosedomainconsistsofidentificationnumbers
encodedasabove,theschemawouldnotbeinfirstnormalform.
Whensuchidentificationnumbersareused,thedepartmentofanemployeecanbe
foundbywritingcodethatbreaksupthestructureofanidentificationnumber.Doingso
requiresextraprogramming,andinformationgetsencodedintheapplicationprogram
ratherthaninthedatabase.Furtherproblemsariseifsuchidentificationnumbersare
usedasprimarykeys:Whenanemployeechangesdepartments,theemployee’sidenti-
fication number must be changed everywhere it occurs, which can be a difficult task,
orthecodethatinterpretsthenumberwouldgiveawrongresult.

--- Page 372 ---

7.9 Database-DesignProcess 343
Fromthisdiscussion,itmayappearthatouruseofcourseidentifierssuchas“CS-
101”,where“CS”indicatestheComputerSciencedepartment,meansthatthedomain
ofcourseidentifiersisnotatomic.Suchadomainisnotatomicasfarashumansusing
the system are concerned. However, the database application still treats the domain
as atomic, as long as it does not attempt to split the identifier and interpret parts of
theidentifierasadepartmentabbreviation.Thecourseschemastoresthedepartment
nameasaseparateattribute,andthedatabaseapplicationcanusethisattributevalue
tofindthedepartmentofacourse,insteadofinterpretingparticularcharactersofthe
course identifier.Thus, our universityschemacan be consideredtobe infirstnormal
form.
Theuseofset-valuedattributescanleadtodesignswithredundantstorageofdata,
whichinturncanresultininconsistencies.Forinstance,insteadofhavingtherelation-
shipbetweeninstructorsandsectionsbeingrepresentedasaseparaterelationteaches,
a database designer may be tempted to store a set of course section identifiers with
eachinstructorandasetofinstructoridentifierswitheachsection.(Theprimarykeys
of section and instructor are used as identifiers.) Whenever data pertaining to which
instructor teaches which section is changed, the update has to be performed at two
places:inthesetofinstructorsforthesection,andinthesetofsectionsfortheinstruc-
tor. Failure to perform both updates can leave the database in an inconsistent state.
Keeping only one of these sets would avoid repeated information; however keeping
onlyoneofthesewouldcomplicatesomequeries,anditisunclearwhichofthetwoit
wouldbebettertoretain.
Some types of non-atomic values can be useful, although they should be used
with care. For example, composite-valued attributes are often useful, and set-valued
attributes are also useful in many cases, which is why both are supported in the E-
R model. In many domains where entities have a complex structure, forcing a first
normalformrepresentationrepresentsanunnecessaryburdenontheapplicationpro-
grammer, who has to write code to convert data into atomic form. There is also the
runtimeoverheadofconvertingdatabackandforthfromtheatomicform.Supportfor
non-atomicvalues can thus be very useful in such domains. Infact, modern database
systems do support many types of non-atomic values, as we shall see in Chapter 29
restrictourselvestorelationsinfirstnormalform,andthusalldomainsareatomic.
7.9 Database-Design Process
Sofarwehavelookedatdetailedissuesaboutnormalformsandnormalization.Inthis
section,westudyhownormalizationfitsintotheoveralldatabase-designprocess.
EarlierinthechapterstartinginSection7.1.1,weassumedthatarelationschema
r(R) is given, and we proceeded to normalize it. There are several ways in which we
couldhavecomeupwiththeschemar(R):
1. r(R)couldhavebeengeneratedinconvertinganE-Rdiagramtoasetofrelation
schemas.

--- Page 373 ---

344 Chapter7 RelationalDatabaseDesign
2. r(R) could have been a single relation schema containing all attributes that are
ofinterest.Thenormalizationprocessthenbreaksupr(R)intosmallerschemas.
3. r(R)couldhavebeentheresultofanadhocdesignofrelationsthatwethentest
toverifythatitsatisfiesadesirednormalform.
In the rest of this section, we examine the implications of these approaches. We also
examine some practical issues in database design, including denormalization for per-
formanceandexamplesofbaddesignthatarenotdetectedbynormalization.
7.9.1 E-R Model and Normalization
WhenwedefineanE-Rdiagramcarefully,identifyingallentitysetscorrectly,therela-
tion schemas generated from the E-R diagram should not need much further normal-
ization.However, therecanbe functional dependenciesamongattributes ofan entity
set. For instance, suppose an instructor entity set had attributes dept name and dept
address, and there is a functional dependency dept name → dept address. We would
thenneedtonormalizetherelationgeneratedfrominstructor.
Most examples of such dependencies arise out of poor E-R diagram design. In
the preceding example, if we had designed the E-R diagram correctly, we would have
createdadepartmententitysetwithattributedept addressandarelationshipsetbetween
instructor and department. Similarly,arelationshipsetinvolvingmore than twoentity
sets may result in a schema that may not be in a desirable normal form. Since most
relationship sets are binary, such cases are relatively rare. (In fact, some E-R-diagram
variantsactuallymakeitdifficultorimpossibletospecifynonbinaryrelationshipsets.)
Functional dependencies can help us detect poor E-R design. If the generated re-
lation schemas are not in desired normal form, the problem can be fixed in the E-R
diagram.Thatis,normalizationcanbedoneformallyaspartofdatamodeling.Alter-
natively,normalizationcanbelefttothedesigner’sintuitionduringE-Rmodeling,and
itcanbedoneformallyontherelationschemasgeneratedfromtheE-Rmodel.
A careful reader will have noted that in order for us to illustrate a need for mul-
tivalued dependencies and fourth normal form, we had to begin with schemas that
were not derived from our E-R design. Indeed, the process of creating an E-R design
tendstogenerate4NFdesigns.Ifamultivalueddependencyholdsandisnotimpliedby
the corresponding functional dependency, it usually arises from one of the following
sources:
• Amany-to-manyrelationshipset.
• Amultivaluedattributeofanentityset.
For a many-to-many relationship set, each related entity set has its own schema, and
there is an additional schema for the relationship set. For a multivalued attribute, a
separateschemaiscreatedconsistingofthatattributeandtheprimarykeyoftheentity
set(asinthecaseofthephone number attributeoftheentitysetinstructor).

--- Page 374 ---

7.9 Database-DesignProcess 345
The universal-relation approach to relational database design starts with an as-
sumption thatthereisone singlerelationschemacontainingallattributes ofinterest.
Thissingleschemadefineshowusersandapplicationsinteractwiththedatabase.
7.9.2 Naming of Attributes and Relationships
A desirable feature of a database design is the unique-role assumption, which means
thateachattributenamehasauniquemeaninginthedatabase.Thispreventsusfrom
usingthesameattributetomeandifferentthingsindifferentschemas.Forexample,we
mightotherwiseconsiderusingtheattributenumberforphonenumberintheinstructor
schemaandforroomnumberintheclassroomschema.Thejoinofarelationonschema
instructorwithoneonclassroomismeaningless.Whileusersandapplicationdevelopers
can work carefully to ensure use of the right number in each circumstance, having a
differentattributenameforphonenumberandforroomnumberservestoreduceuser
errors.
While it is a good idea to keep names for incompatible attributes distinct, if at-
tributesofdifferentrelationshavethesamemeaning,itmaybeagoodideatousethe
sameattributename.Forthisreasonweusedthesameattributename“name”forboth
the instructor and the student entity sets. If this was not the case (i.e., if we used dif-
ferentnamingconventionsfortheinstructorandstudentnames),thenifwewishedto
generalize these entity sets by creating a person entity set, we would have to rename
the attribute. Thus, even if we did not currently have a generalization of student and
instructor,ifweforeseesuchapossibility,itisbesttousethesamenameinbothentity
sets(andrelations).
Althoughtechnically,theorderofattributenamesinaschemadoesnotmatter,it
is a convention to list primary-key attributes first. This makes reading default output
(asfromselect*)easier.
Inlargedatabaseschemas,relationshipsets(andschemasderivedtherefrom)are
often named via a concatenation of the names of related entity sets, perhaps with an
intervening hyphen or underscore. We have used a few such names, for example, inst
sec and student sec. We used the names teaches and takes instead of using the longer
concatenatednames.Thiswasacceptablesinceitisnothardforyoutorememberthe
associatedentitysetsforafewrelationshipsets.Wecannotalwayscreaterelationship-
set names by simple concatenation; for example, a manager or works-for relationship
between employees would not make much sense if it were called employee employee!
Similarly,if there are multiple relationship sets possible between a pair of entity sets,
therelationship-setnamesmustincludeextrapartstoidentifytherelationshipset.
Different organizations have differentconventions for naming entity sets. For ex-
ample,wemaycallanentitysetofstudentsstudentorstudents.Wehavechosentouse
thesingularforminourdatabasedesigns.Usingeithersingularorpluralisacceptable,
aslongastheconventionisusedconsistentlyacrossallentitysets.

--- Page 375 ---

346 Chapter7 RelationalDatabaseDesign
As schemas grow larger, with increasing numbers of relationship sets, using con-
sistent namingof attributes, relationships,and entitiesmakes life much easier forthe
databasedesignerandapplicationprogrammers.
7.9.3 Denormalization for Performance
Occasionallydatabasedesignerschooseaschemathathasredundantinformation;that
is,itisnotnormalized.Theyuse theredundancytoimproveperformanceforspecific
applications.Thepenaltypaidfornotusinganormalizedschemaistheextrawork(in
termsofcodingtimeandexecutiontime)tokeepredundantdataconsistent.
Forinstance,supposeallcourseprerequisiteshavetobedisplayedalongwiththe
course information, every time a course is accessed. In our normalized schema, this
requiresajoinofcoursewithprereq.
Onealternativetocomputingthejoinontheflyistostorearelationcontainingall
theattributesofcourseandprereq.Thismakesdisplayingthe“full”courseinformation
faster.However,theinformationforacourseisrepeatedforeverycourseprerequisite,
and all copies must be updated by the application, whenever a course prerequisite is
added or dropped. The process of taking a normalized schema and making it non-
normalizediscalleddenormalization,anddesignersuse ittotunetheperformanceof
systemstosupporttime-criticaloperations.
Abetteralternative,supportedbymanydatabasesystemstoday,istousethenor-
malized schema and additionallystore the join of course and prereq as a materialized
view. (Recall that a materialized view is a view whose result is stored in the database
and brought up to date when the relationsused in the vieware updated.) Like denor-
malization, using materialized views does have space and time overhead; however, it
has the advantage that keeping the view up to date is the job of the database system,
nottheapplicationprogrammer.
7.9.4 Other Design Issues
Therearesomeaspectsofdatabasedesignthatarenotaddressedbynormalizationand
canthusleadtobaddatabasedesign.Datapertainingtotimeortorangesoftimehave
severalsuchissues.Wegiveexampleshere;obviously,suchdesignsshouldbeavoided.
Considerauniversitydatabase,wherewewanttostorethetotalnumberofinstruc-
tors in each department in different years. A relation totalinst(dept name, year, size)
couldbeusedtostorethedesiredinformation.Theonlyfunctionaldependencyonthis
relationisdept name,year→size,andtherelationisinBCNF.
An alternative design is to use multiple relations, each storing the size informa-
tion for a different year. Let us say the years of interest are 2017, 2018, and 2019; we
wouldthenhaverelationsoftheformtotalinst 2017,totalinst 2018,totalinst 2019,all
ofwhichareontheschema(dept name,size).Theonlyfunctionaldependencyhereon
eachrelationwouldbedept name→size,sotheserelationsarealsoinBCNF.
However, this alternative design is clearly a bad idea—we would have to create a
newrelationeveryyear,andwewouldalsohavetowritenewquerieseveryyear,totake

--- Page 376 ---

7.10 ModelingTemporalData 347
each new relation into account. Queries would also be more complicated since they
mayhavetorefertomanyrelations.
Yet another way of representing the same data is to have a single relation dept
year(dept name, totalinst 2017, totalinst 2018, totalinst 2019). Here the only func-
tionaldependenciesarefromdept nametotheotherattributes,andagaintherelation
isinBCNF.Thisdesignisalsoabadideasinceithasproblemssimilartotheprevious
design—namely, we would have to modify the relation schema and write new queries
every year. Queries would also be more complicated, since they may have to refer to
manyattributes.
Representationssuchasthoseinthedept year relation,withonecolumnforeach
value of an attribute, are called crosstabs; they are widely used in spreadsheets and
reports and in data analysis tools. While such representations are useful for display
to users, for the reasons just given, they are not desirable in a database design. SQL
includes features to convert data from a normal relational representation to a cross-
tab,fordisplay,aswediscussedinSection11.3.1.
7.10 Modeling Temporal Data
Supposeweretaindatainouruniversityorganizationshowingnotonlytheaddressof
eachinstructor,butalsoallformeraddressesofwhichtheuniversityisaware.Wemay
thenaskqueries,suchas“FindallinstructorswholivedinPrincetonin1981.”Inthis
case, we may have multiple addresses for instructors. Each address has an associated
startandenddate,indicatingwhentheinstructorwasresidentatthataddress.Aspecial
valuefortheenddate,forexample,null,oravaluewellintothefuture,suchas9999-
12-31,canbeusedtoindicatethattheinstructorisstillresidentatthataddress.
In general, temporal data are data that have an associated time interval during
whichtheyarevalid.10
Modelingtemporaldataisachallengingproblemforseveralreasons.Forexample,
supposewehaveaninstructorentitysetwithwhichwewishtoassociateatime-varying
address. To add temporal information to an address, we would then have to create a
multivaluedattribute,eachofwhosevaluesisacompositevaluecontaininganaddress
andatimeinterval.Inadditiontotime-varyingattributevalues,entitiesmaythemselves
haveanassociatedvalidtime.Forexample,astudententitymayhaveavalidtimefrom
the date the student entered the university to the date the student graduated (or left
the university). Relationships too may have associated valid times. For example, the
prereqrelationshipmayrecordwhenacoursebecameaprerequisiteforanothercourse.
We would thus have to add valid time intervals to attribute values, entity sets, and
relationshipsets.AddingsuchdetailtoanE-Rdiagrammakesitverydifficulttocreate
and to comprehend. There have been several proposals to extend the E-R notation to
10Thereareothermodelsoftemporaldatathatdistinguishbetweenvalidtimeandtransactiontime,thelatterrecording
whenafactwasrecordedinthedatabase.Weignoresuchdetailsforsimplicity.

--- Page 377 ---

348 Chapter7 RelationalDatabaseDesign
course id title dept name credits start end
BIO-101 Intro.toBiology Biology 4 1985-01-01 9999-12-31
CS-201 Intro.toC Comp.Sci. 4 1985-01-01 1999-01-01
CS-201 Intro.toJava Comp.Sci. 4 1999-01-01 2010-01-01
CS-201 Intro.toPython Comp.Sci. 4 2010-01-01 9999-12-31
Figure 7.17 Atemporalversionofthecourse relation
specify in a simple manner that an attribute value or relationship is time varying, but
therearenoacceptedstandards.
Inpractice,databasedesignersfallbacktosimplerapproachestodesigningtempo-
raldatabases.Onecommonlyusedapproachistodesigntheentiredatabase(including
E-R design and relational design) ignoring temporal changes. After this, the designer
studiesthevariousrelationsanddecideswhichrelationsrequiretemporalvariationto
betracked.
Thenextstepistoaddvalidtimeinformationtoeachsuchrelationbyaddingstart
and end time as attributes. For example, consider the course relation. The title of the
coursemaychangeovertime,whichcanbehandledbyaddingavalidtimerange;the
resultantschemawouldbe:
course(course id,title,dept name,credits,start,end)
An instance of the relation is shown in Figure 7.17. Each tuple has a valid interval
associated with it. Note that as per the SQL:2011 standard, the interval is closed on
theleft-handside,thatis,thetupleisvalidattimestart,but isopenontheright-hand
side,thatis,thetupleisvaliduntiljustbeforetimeend,butisinvalidattimeend.This
allows a tuple to have the same start time as the end time of another tuple, without
overlapping. In general, left and right endpoints that are closed are denoted by [ and
], while left and right endpoints that are open are denoted by ( and ). Intervals in
SQL:2011 are of the form [start, end), that is they are closed on the left and open on
theright,Notethat9999-12-31isthehighestpossibledateaspertheSQLstandard.
ItcanbeseeninFigure7.17thatthetitleofthecourseCS-201haschangedseveral
times.Supposethaton2020-01-01thetitleofthecourseisupdatedagainto,say,“Intro.
toScala”.Then,theendattributevalueofthetuplewithtitle“Intro.toPython”would
be updated to 2020-01-01, and a new tuple (CS-201, Intro. to Scala, Comp. Sci., 4,
2020-01-01,9999-12-31)wouldbeaddedtotherelation.
Whenwetrackdatavaluesacrosstime,functionaldependenciesthatweassumed
tohold,suchas:
course id →title,dept name,credits
may no longer hold. The following constraint (expressed in English) would hold in-
stead: “A course course id has only one title and dept name value at any given time
t.”

--- Page 378 ---

7.10 ModelingTemporalData 349
Functionaldependenciesthatholdataparticularpointintimearecalledtemporal
functional dependencies. We use the term snapshot of data to mean the value of the
data at a particular point in time. Thus, a snapshot of course data gives the values of
allattributes,suchastitleanddepartment,ofallcoursesataparticularpointintime.
τ
Formally, a temporal functional dependency α → β holds on a relation schema r(R)
if, for all legal instances of r(R), all snapshots of r satisfy the functional dependency
α → β.
Theoriginalprimarykeyforatemporalrelationwouldnolongeruniquelyidentify
a tuple. We could try to fix the problem by adding start and end time attributes to
the primary key, ensuring no two tuples have the same primary key value. However,
this solution is not correct, since it is possible to store data with overlapping valid
time intervals, which would not be caught by merely adding the start and end time
attributes to the primary-key constraint. Instead, the temporal version of the primary
key constraint must ensure that if any two tuples have the same primary key values,
their valid time intervals do not overlap. Formally, if r.A is a temporal primary key of
relationr,thenwhenevertwotuplest andt inr aresuchthatt .A = t .A,theirvalid
1 2 1 2
timeintervalsoft andt mustnotoverlap.
1 2
Foreign-key constraints are also more complicated when the referenced relation
is a temporal relation. A temporal foreign key should ensure that not only does each
tupleinthereferencingrelation,sayr,haveamatchingtupleinthereferencedrelation,
say s, but alsotheirtime intervals are accounted for. It isnot requiredthat there be a
matchingtupleinswithexactlythesametimeinterval,noreventhatasingletuplein
s has a time interval containingthe time interval of the r tuple. Instead, we allow the
timeintervalofthertupletobecoveredbyoneormorestuples.Formally,atemporal
foreign-key constraint from r.A to s.B ensures the following:for each tuple t in r, with
valid time interval (l,u), thereis a subset s of one or more tuples in s such that each
t
tuples ∈ s hass.B = t.A,andfurthertheunionofthetemporalintervalsofallthes
i t i i
contains(l,u).
Arecordinastudent’stranscriptshouldrefertothecoursetitleatthetimewhen
the student took the course. Thus, the referencing relation must also record time in-
formation, to identify a particular record from the course relation. In our university
schema, takes.course id is a foreign key referencing course. The year and semester val-
uesofatakestuplecouldbemappedtoarepresentativedate,suchasthestartdateof
thesemester;theresultingdatevaluecouldbeusedtoidentifyatupleinthetemporal
versionofthecourserelationwhosevalidtimeintervalcontainsthespecifieddate.Al-
ternatively,atakestuplemaybeassociatedwithavalidtimeintervalfromthestartdate
of the semester until the end date of the semester, and course tuples with a matching
course id and an overlapping valid time may be retrieved; as long as course tuples are
notupdatedduringasemester,therewouldbeonlyonesuchrecord.
Insteadofaddingtemporalinformationtoeachrelation,somedatabasedesigners
create for each relation a corresponding history relation that stores the history of up-
dates to the tuples. Forexample, a designermay leave the course relationunchanged,

--- Page 379 ---

350 Chapter7 RelationalDatabaseDesign
but create a relation course history containing all the attributes of course, with an ad-
ditional timestamp attribute indicating when a record was added to the course history
table.However,suchaschemehaslimitations,suchasaninabilitytoassociateatakes
recordwiththecorrectcoursetitle.
The SQL:2011 standard added support for temporal data. In particular, it allows
existingattributestobedeclaredtospecifyavalidtimeintervalforatuple.Forexample,
fortheextendedcourserelationwesawabove,wecoulddeclare
periodforvalidtime(start,end)
tospecifythatthetupleisvalidintheintervalspecifiedbythestartandend(whichare
otherwiseordinaryattributes).
TemporalprimarykeyscanbedeclaredinSQL:2011,asillustratedbelow,usingthe
extendedcourseschema:
primarykey(course id,validtimewithoutoverlaps)
SQL:2011 also supports temporal foreign-key constraints that allow a period to be
specified along with the referencing relation attributes, as well as with the referenced
relationattributes.Mostdatabases,withtheexceptionofIBMDB2,Teradata,andpos-
sibly a few others, do not support temporal primary-key constraints. To the best of
ourknowledge,nodatabasesystemcurrentlysupportstemporalforeign-keyconstraints
(Teradataallowsthemtobespecified,butatleastasof2018,doesnotenforcethem).
Somedatabases thatdonotdirectlysupport temporal primary-keyconstraints al-
lowworkaroundstoenforcesuchconstraints.Forexample,althoughPostgreSQLdoes
not support temporal primary-key constraints natively, such constraints can be en-
forced using the exclude constraint feature supported by PostgreSQL. For example,
consider the course relation, whose primary key is course id. In PostgreSQL, we can
addanattributevalidtime,oftypetsrange;thetsrangedatatypeofPostgreSQLstores
atimestamprangewithastartandendtimestamp.PostgreSQLsupportsan&&oper-
atoron apairofranges, whichreturnstrue iftworanges overlapand false otherwise.
Thetemporalprimarykeycanbeenforcedbyaddingthefollowingexcludeconstraint
(atypeofconstraintsupportedbyPostgreSQL)tothecourserelationasfollows:
exclude(course id with=,validtimewith&&)
The above constraint ensures that if two course tuples have the same course id value,
thentheirvalidtimeintervalsdonotoverlap.
Relational algebra operations, such as select, project, or join, can be extended to
taketemporalrelationsasinputsandgeneratetemporalrelationsasoutputs.Selection
and projectionoperations on temporal relationsoutput tuples whose validtime inter-
valsarethesameasthatoftheircorrespondinginputtuples.Atemporaljoinisslightly
different:thevalidtimeofatupleinthejoinresultisdefinedastheintersectionofthe
validtimesofthetuplesfromwhichitisderived.Ifthevalidtimesdonotintersect,the
tupleisdiscardedfromtheresult.Tothebestofourknowledge,nodatabasesupports
temporal joinsnatively,althoughtheycanbeexpressed bySQLqueriesthatexplicitly

--- Page 380 ---

7.11 Summary 351
handlethetemporalconditions.Predicates,suchasoverlaps,contains,before,andafter
andoperationssuchasintersectionanddifferenceonpairsofintervalsaresupportedby
severaldatabasesystems.
7.11 Summary
• We showed pitfalls in database design and how to design a database schema sys-
tematicallyinawaythatavoidsthosepitfalls.Thepitfallsincludedrepeatedinfor-
mationandinabilitytorepresentsomeinformation.
• Chapter 6 showed the development of a relational database design from an E-R
designandwhenschemasmaybecombinedsafely.
• Functional dependencies are consistency constraints that are used to define two
widelyused normal forms, Boyce–Codd normal form (BCNF) and third normal
form(3NF).
• If the decomposition is dependency preserving, all functional dependencies can
be inferred logically by considering only those dependencies that apply to one
relation. This permits the validity of an update to be tested without the need to
computeajoinofrelationsinthedecomposition.
• A canonical cover is a set of functional dependencies equivalent to a given set
of functional dependencies, that is minimized in a specific manner to eliminate
extraneousattributes.
• ThealgorithmfordecomposingrelationsintoBCNFensuresalosslessdecompo-
sition.Therearerelationschemaswithagivensetoffunctionaldependenciesfor
whichthereisnodependency-preservingBCNFdecomposition.
• A canonical cover is used to decompose a relation schema into 3NF, which is
a small relaxation of the BCNF condition. This algorithm produces designs that
are both lossless and dependency-preserving. Relations in 3NF may have some
redundancy,butthatisdeemedanacceptabletrade-offincaseswherethereisno
dependency-preservingdecompositionintoBCNF.
• Multivalueddependenciesspecifycertainconstraintsthatcannotbespecifiedwith
functional dependencies alone. Fourth normal form (4NF) is defined using the
concept of multivalued dependencies. Section 28.1.1 gives details on reasoning
aboutmultivalueddependencies.
• Othernormalformsexist,includingPJNFandDKNF,whicheliminatemoresubtle
forms of redundancy. However, these are hard to work with and are rarely used.
Chapter 28 gives details on these normal forms. Second normal form is of only
historicalinterestsinceitprovidesnobenefitover3NF.
• Relationaldesignstypicallyarebasedonsimpleatomicdomainsforeachattribute.
Thisiscalledfirstnormalform.

--- Page 381 ---

352 Chapter7 RelationalDatabaseDesign
• Time plays an important role in database systems. Databases are models of the
realworld.Whereasmostdatabasesmodelthestateoftherealworldatapointin
time (at the currenttime), temporal databases model the states of the realworld
acrosstime.
• There are possible database designs that are bad despite being lossless,
dependency-preserving,andinanappropriatenormalform.Weshowedexamples
ofsomesuchdesignstoillustratethatfunctional-dependency-basednormalization,
thoughhighlyimportant,isnottheonlyaspectofgoodrelationaldesign.
• Inorderforadatabasetostorenotonlycurrentdatabutalsohistoricaldata,the
database must also store for each such tuple the time period for which the tuple
is or was valid. It then becomes necessary to define temporal functional depen-
dencies to represent the idea that the functional dependency holds at any point
in time but not over the entire relation. Similarly, the join operation needs to be
modifiedsoastoappropriatelyjoinonlytupleswithoverlappingtimeintervals.
• Inreviewingtheissuesinthischapter,notethatthereasonwecoulddefinerigorous
approachestorelationaldatabasedesignisthattherelationaldatamodelrestson
a firm mathematical foundation. That is one of the primary advantages of the
relationalmodelcomparedwiththeotherdatamodelsthatwehavestudied.
Review Terms
• Decomposition • Thirdnormalform
• Transitivedependencies
° Lossydecompositions
• Logicallyimplied
° Losslessdecompositions
• Axioms
• Normalization • Armstrong’saxioms
• Functionaldependencies • Sound
• Legalinstance • Complete
• Superkey • Functionallydetermined
• RsatisfiesF • Extraneousattributes
• Functionaldependency • Canonicalcover
° Holds • RestrictionofFtoR
i
° Trivial • Dependency-preserving decomposi-
tion
° Trivial
• Boyce–Coddnormalform
• Closureofasetoffunctional (BCNF)
dependencies • BCNFdecompositionalgorithm
• Dependencypreserving

--- Page 382 ---

PracticeExercises 353
• Thirdnormalform(3NF) • Domain-keynormalform(DKNF)
• 3NFdecompositionalgorithm • Atomicdomains
• 3NFsynthesisalgorithm • Firstnormalform(1NF)
• Multivalueddependency • Unique-roleassumption
° Equality-generatingdependencies • Denormalization
• Crosstabs
° Tuple-generatingdependencies
• Temporaldata
° Embeddedmultivalueddependen-
• Snapshot
cies
• Temporalfunctionaldependency
• Closure
• Temporalprimarykey
• Fourthnormalform(4NF)
• Temporalforeign-key
• RestrictionofDtoR
i • Temporaljoin
• Fifthnormalform
Practice Exercises
7.1 SupposethatwedecomposetheschemaR = (A,B,C,D,E)into
(A,B,C)
(A,D,E).
ShowthatthisdecompositionisalosslessdecompositionifthefollowingsetF
offunctionaldependenciesholds:
A → BC
CD → E
B → D
E → A
7.2 List all nontrivial functional dependencies satisfied by the relation of Figure
7.18.
A B C
a b c
1 1 1
a b c
1 1 2
a b c
2 1 1
a b c
2 1 3
Figure 7.18 RelationofExercise7.2.

--- Page 383 ---

354 Chapter7 RelationalDatabaseDesign
7.3 Explainhowfunctionaldependenciescanbeusedtoindicatethefollowing:
• Aone-to-onerelationshipsetexistsbetweenentitysetsstudentandinstruc-
tor.
• Amany-to-onerelationshipsetexistsbetweenentitysetsstudentandinstruc-
tor.
7.4 UseArmstrong’saxiomstoprovethesoundnessoftheunionrule.(Hint:Usethe
augmentationruletoshowthat,ifα→β,thenα→αβ.Applytheaugmentation
ruleagain,usingα→γ,andthenapplythetransitivityrule.)
7.5 UseArmstrong’saxiomstoprovethesoundnessofthepseudotransitivityrule.
7.6 ComputetheclosureofthefollowingsetF offunctionaldependenciesforrela-
tionschemaR = (A, B, C, D, E).
A→BC
CD→E
B→D
E →A
ListthecandidatekeysforR.
7.7 Using the functional dependencies of Exercise 7.6, compute the canonical
coverF .
c
7.8 ConsiderthealgorithminFigure7.19tocomputeα+.Showthatthisalgorithm
ismoreefficientthantheonepresentedinFigure7.8(Section7.4.2)andthatit
computesα+ correctly.
7.9 GiventhedatabaseschemaR(A,B,C),andarelationr ontheschemaR,write
an SQL query to test whether the functional dependency B → C holds on re-
lation r. Alsowrite an SQL assertion that enforcesthe functional dependency.
Assume that no null values are present. (Although part of the SQL standard,
suchassertionsarenotsupportedbyanydatabaseimplementationcurrently.)
7.10 Ourdiscussionoflosslessdecompositionimplicitlyassumedthatattributeson
theleft-handsideofafunctionaldependencycannottakeonnullvalues.What
couldgowrongondecomposition,ifthispropertyisviolated?
7.11 In the BCNF decomposition algorithm, suppose you use a functional depen-
dencyα → βtodecomposearelationschemar(α,β,γ)intor (α,β)andr (α,γ).
1 2
a. What primary and foreign-key constraint do you expect to hold on the
decomposedrelations?
b. Give an example of an inconsistency that can arise due to an erroneous
update,iftheforeign-keyconstraintwerenotenforcedonthedecomposed
relationsabove.

--- Page 384 ---

PracticeExercises 355
result := ∅;
/*fdcountisanarraywhoseithelementcontainsthenumber
ofattributesontheleftsideoftheithFDthatare
notyetknowntobeinα+ */
fori := 1to|F|do
begin
letβ → γdenotetheithFD;
fdcount[i] :=|β|;
end
/*appearsisanarraywithoneentryforeachattribute.The
entryforattributeAisalistofintegers.Eachinteger
ionthelistindicatesthatAappearsontheleftside
oftheithFD*/
foreachattributeAdo
begin
appears[A] := NIL;
fori := 1to|F|do
begin
letβ → γdenotetheithFD;
ifA ∈ βthenadditoappears[A];
end
end
addin(α);
return(result);
procedureaddin(α);
foreachattributeAinαdo
begin
ifA ∉ resultthen
begin
result :=result∪{A};
foreachelementiofappears[A]do
begin
fdcount[i] :=fdcount[i] − 1;
iffdcount[i] := 0then
begin
letβ → γdenotetheithFD;
addin(γ);
end
end
end
end
Figure 7.19 Analgorithmtocompute α+.

--- Page 385 ---

356 Chapter7 RelationalDatabaseDesign
c. When arelation schemaisdecomposed into3NFusing the algorithmin
Section 7.5.2, what primary and foreign-key dependencieswould you ex-
pecttoholdonthedecomposedschema?
7.12 LetR , R ,…,R beadecompositionofschemaU.Letu(U)bearelation,and
1 2 n
letr = Π (u).Showthat
i R
I
u ⊆ r ⋈ r ⋈ ⋯ ⋈ r
1 2 n
7.13 Show that the decomposition in Exercise 7.1 is not a dependency-preserving
decomposition.
7.14 Show that there can be more than one canonical cover for a given set of func-
tionaldependencies,usingthefollowingsetofdependencies:
X → YZ,Y →XZ,andZ →XY.
7.15 The algorithm to generate a canonical cover only removes one extraneous at-
tribute at a time. Use the functional dependencies from Exercise 7.14 to show
what can go wrong if two attributes inferred to be extraneous are deleted at
once.
7.16 Showthatitispossibletoensurethatadependency-preservingdecomposition
into 3NF is a lossless decomposition by guaranteeing that at least one schema
contains a candidate key for the schema being decomposed. (Hint: Show that
the join of all the projections onto the schemas of the decomposition cannot
havemoretuplesthantheoriginalrelation.)
7.17 Give an example of a relation schema R′ and set F′ of functional dependen-
ciessuchthatthereareatleastthreedistinctlosslessdecompositionsofR′ into
BCNF.
7.18 Letaprimeattributebeonethatappearsinatleastonecandidatekey.Letαand
βbesetsofattributessuchthatα → βholds,butβ → αdoesnothold.LetAbe
anattributethatisnotinα,isnotinβ,andforwhichβ → Aholds.Wesaythat
Aistransitivelydependentonα.Wecanrestatethedefinitionof3NFasfollows:
ArelationschemaRisin3NFwithrespecttoasetFoffunctionaldependencies
iftherearenononprimeattributesAinRforwhichAistransitivelydependent
onakeyforR.Showthatthisnewdefinitionisequivalenttotheoriginalone.
7.19 A functional dependency α → β is called a partial dependency if there is a
propersubsetγofαsuchthatγ → β;wesaythatβispartiallydependentonα.A
relationschemaRisinsecondnormalform(2NF)ifeachattributeAinRmeets
oneofthefollowingcriteria:
• Itappearsinacandidatekey.

--- Page 386 ---

Exercises 357
• Itisnotpartiallydependentonacandidatekey.
Show that every 3NF schema is in 2NF. (Hint: Show that every partial depen-
dencyisatransitivedependency.)
7.20 GiveanexampleofarelationschemaRandasetofdependenciessuchthatR
isinBCNF butisnotin4NF.
Exercises
7.21 GivealosslessdecompositionintoBCNFofschemaRofExercise7.1.
7.22 Givealossless,dependency-preservingdecompositioninto3NFofschemaRof
Exercise7.1.
7.23 Explain what is meant by repetition of information and inability to represent in-
formation. Explain why each of these properties may indicate a bad relational-
databasedesign.
7.24 Whyarecertainfunctionaldependenciescalledtrivialfunctionaldependencies?
7.25 UsethedefinitionoffunctionaldependencytoarguethateachofArmstrong’s
axioms(reflexivity,augmentation,andtransitivity)issound.
7.26 Considerthefollowingproposedruleforfunctionaldependencies:Ifα → βand
γ →β,thenα → γ.Provethatthisruleisnotsoundbyshowingarelationrthat
satisfiesα → βandγ → β,butdoesnotsatisfyα → γ.
7.27 UseArmstrong’saxiomstoprovethesoundnessofthedecompositionrule.
7.28 UsingthefunctionaldependenciesofExercise7.6,computeB+.
7.29 ShowthatthefollowingdecompositionoftheschemaRofExercise7.1isnota
losslessdecomposition:
(A,B,C)
(C,D,E).
Hint:Giveanexampleofarelationr(R)suchthatΠ (r) ⋈ Π (r) ≠ r
A,B,C C,D,E
7.30 ConsiderthefollowingsetF offunctionaldependenciesontherelationschema
(A, B, C, D,E,G):
A→BCD
BC→DE
B→D
D→A

--- Page 387 ---

358 Chapter7 RelationalDatabaseDesign
a. ComputeB+.
b. Prove(usingArmstrong’saxioms)thatAG isasuperkey.
c. ComputeacanonicalcoverforthissetoffunctionaldependenciesF;give
eachstepofyourderivationwithanexplanation.
d. Give a 3NF decomposition of the given schema based on a canonical
cover.
e. GiveaBCNFdecompositionofthegivenschemausingtheoriginalsetF
offunctionaldependencies.
7.31 Consider the schema R = (A,B,C,D,E,G) and the set F of functional depen-
dencies:
AB → CD
B →D
DE → B
DEG → AB
AC → DE
R is not in BCNF for many reasons, one of which arises from the functional
dependency AB → CD. Explain why AB → CD shows that R is not in BCNF
and then use the BCNF decomposition algorithm starting with AB → CD to
generate a BCNF decomposition of R. Once that is done, determine whether
yourresultisorisnotdependencypreserving,andexplainyourreasoning.
7.32 Consider the schema R = (A,B,C,D,E,G) and the set F of functional depen-
dencies:
A → BC
BD → E
CD → AB
a. Find a nontrivial functional dependency containing no extraneous at-
tributesthatislogicallyimpliedbytheabovethreedependenciesandex-
plainhowyoufoundit.
b. Use the BCNF decomposition algorithm to find a BCNF decomposition
ofR.StartwithA → BC.Explainyoursteps.
c. Foryourdecomposition,statewhetheritislosslessandexplainwhy.
d. For your decomposition, state whether it is dependency preserving and
explainwhy.

--- Page 388 ---

Exercises 359
7.33 Consider the schema R = (A,B,C,D,E,G) and the set F of functional depen-
dencies:
AB → CD
ADE → GDE
B →GC
G → DE
Use the 3NF decomposition algorithm to generate a 3NF decomposition of R,
andshowyourwork.Thismeans:
a. Alistofallcandidatekeys
b. AcanonicalcoverforF,alongwithanexplanationofthestepsyoutook
togenerateit
c. Theremainingstepsofthealgorithm,withexplanation
d. Thefinaldecomposition
7.34 Consider the schema R = (A,B,C,D,E,G,H) and the set F of functional de-
pendencies:
AB → CD
D → C
DE →B
DEH → AB
AC → DC
Use the 3NF decomposition algorithm to generate a 3NF decomposition of R,
andshowyourwork.Thismeans:
a. Alistofallcandidatekeys
b. AcanonicalcoverforF
c. Thestepsofthealgorithm,withexplanation
d. Thefinaldecomposition
7.35 AlthoughtheBCNFalgorithmensuresthattheresultingdecompositionisloss-
less,itispossibletohaveaschemaandadecompositionthatwasnotgenerated
bythealgorithm,thatisinBCNF,andisnotlossless.Giveanexampleofsuch
aschemaanditsdecomposition.
7.36 Show that every schema consisting of exactly two attributes must be in BCNF
regardlessofthegivensetF offunctionaldependencies.

--- Page 389 ---

360 Chapter7 RelationalDatabaseDesign
7.37 List the three design goals for relational databases, and explain why each is
desirable.
7.38 Indesigningarelationaldatabase,whymightwechooseanon-BCNFdesign?
7.39 Giventhethreegoalsofrelationaldatabasedesign,isthereanyreasontodesign
a database schemathatisin2NF, but isin nohigher-ordernormal form? (See
Exercise7.19forthedefinitionof2NF.)
7.40 Givenarelationalschemar(A,B,C,D),doesA →→ BC logicallyimplyA →→ B
andA →→ C?Ifyesproveit,orelsegiveacounterexample.
7.41 Explainwhy4NFisanormalformmoredesirablethanBCNF.
7.42 Normalizethefollowingschema,withgivenconstraints,to4NF.
books(accessionno,isbn,title,author,publisher)
users(userid,name,deptid,deptname)
accessionno→isbn
isbn→title
isbn→publisher
isbn→→author
userid →name
userid →deptid
deptid →deptname
7.43 Although SQL does not support functional dependency constraints, if the
database system supports constraints on materialized views, and materialized
views are maintained immediately, it is possible to enforce functional depen-
dency constraints in SQL. Given a relation r(A,B,C), explain how constraints
onmaterializedviewscanbeusedtoenforcethefunctionaldependencyB → C.
7.44 Giventworelationsr(A,B,validtime)ands(B,C,validtime),wherevalidtimede-
notesthevalidtimeinterval,writeanSQLquerytocomputethetemporalnat-
ural join of the two relations. You can use the && operator to check if two
intervals overlap and the ∗ operator to compute the intersection of two inter-
vals.
Further Reading
Thefirstdiscussionofrelationaldatabasedesigntheoryappearedinanearlypaperby
[Codd(1970)].Inthatpaper,Coddalsointroducedfunctionaldependenciesandfirst,
second,andthirdnormalforms.
Armstrong’saxiomswereintroducedin[Armstrong(1974)].BCNFwasintroduced
in[Codd(1972)].[Maier(1983)]isaclassictextbookthatprovidesdetailedcoverage
ofnormalizationandthetheoryoffunctionalandmultivalueddependencies.

--- Page 390 ---

FurtherReading 361
Bibliography
[Armstrong(1974)] W. W. Armstrong, “Dependency Structures of Data Base Relation-
ships”,InProc.ofthe1974IFIPCongress(1974),pages580–583.
[Codd(1970)] E.F.Codd,“ARelationalModelforLargeSharedDataBanks”,Communi-
cationsoftheACM,Volume13,Number6(1970),pages377–387.
[Codd(1972)] E.F.Codd. “FurtherNormalizationoftheDataBaseRelationalModel”,In
[Rustin(1972)],pages33–64(1972).
[Maier(1983)] D. Maier, The Theory of Relational Databases, Computer Science Press
(1983).
[Rustin(1972)] R.Rustin,DataBaseSystems,PrenticeHall(1972).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 392 ---

3
PART
APPLICATION DESIGN
AND DEVELOPMENT
Oneofthekeyrequirementsoftherelationalmodelisthatdatavaluesbeatomic:mul-
tivalued,composite,andothercomplexdatatypesaredisallowedbythecorerelational
model.However,therearemanyapplicationswheretheconstraintsondatatypesim-
posedbytherelationalmodelcausemoreproblemsthantheysolve.InChapter8,we
discussseveralcomplexdatatypes,includingsemistructureddatatypesthatarewidely
usedinbuildingapplications,object-baseddata,textualdata,andspatialdata.
Practically all use of databases occurs from within application programs. Corre-
spondingly, almost all user interaction with databases is indirect, via application pro-
grams. Database-backed applications are ubiquitous on the web as well as on mobile
platforms. In Chapter 9, we study toolsand technologiesthatare used to build appli-
cations, focusing on interactive applications that use databases to store and retrieve
data.
363

--- Page 394 ---

8
CHAPTER
Complex Data Types
The relational model is very widely used for data representation for a large number
of application domains. One of the key requirements of the relational model is that
data values be atomic: multivalued, composite, and other complex data types are dis-
allowedbythecorerelationalmodel.However,therearemanyapplicationswherethe
constraintsondatatypesimposed bytherelationalmodelcausemoreproblemsthan
theysolve.Inthischapter,wediscussseveralnon-atomicdatatypesthatarewidelyused,
includingsemi-structureddata,object-baseddata,textualdata,andspatialdata.
8.1 Semi-structured Data
Relationaldatabasedesignshavetableswithafixednumberofattributes,eachofwhich
contains an atomic value. Changes to the schema, such as adding an extra attribute,
are rare events, and may require changing of application code. Such a design is well
suitedtomanyorganizationalapplications.
However, there are many application domains that need to store more complex
data, whose schema changes often. Fast evolving web applications are an example of
such a domain. As an example of the data management needs of such applications,
consider the profile of a user which needs to be accessible to a number of different
applications. The profile contains a variety of attributes, and there are frequent addi-
tionstotheattributesstoredintheprofile.Someattributesmaycontaincomplexdata;
forexample,anattributemaystoreasetofintereststhatcanbeusedtoshowtheuser
articles related to the set of interests. While such a set can be stored in a normalized
fashioninaseparaterelation,asetdatatypeallowssignificantlymoreefficientaccess
thandoesanormalizedrepresentation.Westudyanumberofdatamodelsthatsupport
representationofsemi-structureddatainthissection.
Dataexchangeisanotherveryimportantmotivationforsemi-structureddatarep-
resentations;itisperhapsevenmoreimportantthanstorageformanyapplications.A
populararchitectureforbuildinginformationsystems todayistocreateawebservice
thatallowsretrievalofdataandtobuildapplicationcodethatdisplaysthedataandal-
lowsuserinteraction.Suchapplicationcodemaybedevelopedasmobileapplications,
365

--- Page 395 ---

366 Chapter8 ComplexDataTypes
or it may be written in JavaScript and run on the browser. In either case, the ability
to run on the client’s machine allows developers to create very responsive user inter-
faces,unliketheearlygenerationofwebinterfaceswherebackendserverssendHTML
marked-up text to browsers, whichdisplay the HTML.A key to buildingsuch applica-
tionsistheabilitytoefficientlyexchange and processcomplexdatabetweenbackend
servers and clients. We study the JSON and XML data models that have been widely
adoptedforthistask.
8.1.1 Overview of Semi-structured Data Models
Therelationaldatamodelhasbeenextendedinseveralwaystosupportthestorageand
dataexchangeneedsofmodernapplications.
8.1.1.1 FlexibleSchema
Somedatabasesystemsalloweachtupletopotentiallyhaveadifferentsetofattributes;
such a representation is referred to as a wide column data representation. The set of
attributes is not fixed in such a representation; each tuple may have a different set of
attributes,andnewattributesmaybeaddedasneeded.
Amorerestrictedformofthisrepresentationistohaveafixedbutverylargenum-
ber of attributes, with each tuple using only those attributes that it needs, leavingthe
restwithnullvalues;sucharepresentationiscalledasparsecolumnrepresentation.
8.1.1.2 MultivaluedDataTypes
Many data representations allow attributes to contain non-atomic values. Many
databases allow the storage of sets, multisets, or arrays as attribute values. For exam-
ple,anapplicationthatstorestopicsofinteresttoauser,andusesthetopicstotarget
articlesoradvertisementstotheuser,maystorethetopicsasaset.Anexampleofsuch
asetmaybe:
{basketball,LaLiga,cooking,anime,Jazz}
Althoughaset-valuedattributecanbestoredinanormalizedformaswesawearlierin
Section6.7.2,doingsoprovidesnobenefitsinthiscase,sincelookupsarealwaysbased
on the user, and normalization would significantly increase the storage and querying
overhead.
Some representations allow attributes to store key-value maps, which store key-
valuepairs.Akey-valuemap,oftenjustcalledamap,isasetof(key,value)pairs,such
thateachkeyoccursinatmostoneelement.Forexample,e-commercesitesoftenlist
specifications or details for each product that they sell, such as brand, model, size,
color, and numerous other product-specific details. The set of specifications may be
different for each product. Such specifications can be represented as a map, where

--- Page 396 ---

8.1 Semi-structuredData 367
the specifications form the key, and the associated value is stored with the key. The
followingexampleillustratessuchamap:
{(brand,Apple),(ID,MacBookAir),(size,13),(color,silver)}
The put(key, value) method can be used to add a key-value pair, while the get(key)
methodcanbeusedtoretrievethevalueassociatedwithakey.Thedelete(key)method
canbeusedtodeleteakey-valuepairfromthemap.
Arraysareveryimportantforscientificandmonitoringapplications.Forexample,
scientific applications may need to store images, whichare basicallytwo-dimensional
arrays of pixel values. Scientific experiments as well as industrial monitoring applica-
tionsoftenusemultiplesensorsthatprovidereadingsatregularintervals.Suchreadings
canbeviewedasanarray.Infact,treatingastreamofreadingsasanarrayrequiresfar
lessspacethanstoringeachreadingasaseparate tuple,withattributessuchas(time,
reading). Not only do we avoid storing the time attribute explicitly(it can be inferred
fromtheoffset),butwecanalsoreduceper-tupleoverheadinthedatabase,andmost
importantly we can use compression techniques to reduce the space needed to store
anarrayofreadings.
Support for multivalued attribute types was proposed early in the history of
databases,andtheassociateddatamodelwascalledthenonfirst-normal-form,orNFNF,
data model. Several relational databases such as Oracle and PostgreSQL support set
andarraytypes.
An array database is a database that provides specialized support for arrays, in-
cluding efficient compressed storage, and query language extensions to support oper-
ations on arrays. Examples include the Oracle GeoRaster, the PostGIS extension to
PostgreSQL,the SciQLextension of MonetDB,and SciDB,adatabase tailoredfor sci-
entificapplications,withanumberoffeaturestailoredforarraydatatypes.
8.1.1.3 NestedDataTypes
Manydatarepresentationsallowattributestobestructured,directlymodelingcompos-
ite attributes in the E-R model. For example, an attribute name may have component
attributesfirstname,andlastname.Theserepresentationsalsosupportmultivalueddata
types such as sets, arrays, and maps. All of these data types represent a hierarchy of
data types, and that structure leads to the use of the term nested data types. Many
databases support such types as part of their support for object-oriented data, which
wedescribeinSection8.2.
In this section, we outline two widelyused data representations that allow values
to have complex internal structures and that are flexible in that values are not forced
toadheretoafixedschema.ThesearetheJavaScriptObjectNotation (JSON), which
we describe in Section 8.1.2, and the Extensible Markup Language (XML), which we
describeinSection8.1.3.
Likethewide-tableapproach,theJSONandXMLrepresentationsprovideflexibility
in the set of attributes that a record contains, as well as the types of these attributes.

--- Page 397 ---

368 Chapter8 ComplexDataTypes
However,theJSONandXMLrepresentationspermitamoreflexiblestructuringofdata,
whereobjectscouldhavesub-objects;eachobjectthuscorrespondstoatreestructure.
Sincetheyallowmultiplepiecesofinformationaboutabusinessobjecttobepack-
aged into a single structure, the JSON and XML representations have both found sig-
nificantacceptanceinthecontextofdataexchangebetweenapplications.
Today, JSON is widelyused today for exchanging data between the backends and
theuser-facingsidesofapplications,suchasmobileapps,andWebapps.JSONhasalso
found favor for storing complex objects in storage systems that collect different data
relatedtoaparticularuserintoonelargeobject(sometimesreferredtoasadocument),
allowingdatatoberetrievedwithouttheneedforjoins.XMLisanolderrepresentation
andisusedbymanysystems forstoringconfiguration andotherinformation,andfor
dataexchange.
8.1.1.4 KnowledgeRepresentation
Representationofhumanknowledgehaslongbeenagoaloftheartificialintelligence
community. A variety of models were proposed for this task, with varying degrees of
complexity;thesecouldrepresentfactsaswellasrulesaboutfacts.Withthegrowthof
the web, a need arose to represent extremely large knowledge bases, with potentially
billionsoffacts.TheResourceDescriptionFormat(RDF)datarepresentationisonesuch
representation that has found very wide acceptance. The representation actually has
far fewer features than earlier representations, but it was better suited to handle very
largedatavolumesthantheearlierknowledgerepresentations.
LiketheE-Rmodelwhichwestudiedearlier,RDFmodelsdataasobjectsthathave
attributes and have relationships with other objects. RDF data can be viewed as a set
oftriples(3-tuples),orasagraph,withobjectsandattributevaluesmodeledasnodes
andrelationshipsandattributenamesasedges.WestudyRDFinmoredetailinSection
8.1.4.
8.1.2 JSON
The JavaScript Object Notation (JSON), is a textual representation of complex data
types that is widely used to transmit data between applications and to store complex
data.JSONsupportstheprimitivedatatypesinteger,realandstring,aswellasarrays,
and“objects,”whichareacollectionof(attributename,value)pairs.
Figure8.1showsanexampleofdatarepresentedusingJSON.Sinceobjectsdonot
havetoadheretoanyfixedschema,theyarebasicallythesameaskey-valuemaps,with
theattributenamesaskeysandtheattributevaluesastheassociatedvalues.
The example also illustrates arrays, shown in square brackets. In JSON, an array
canbethoughtofasamapfromintegeroffsetstovalues,withthesquare-bracketsyntax
viewedasjustaconvenientwayofcreatingsuchmaps.
JSON is today the primary data representation used for communication between
applications and web services. Many modern applications use web services to store

--- Page 398 ---

8.1 Semi-structuredData 369
{
"ID": "22222",
"name": {
"firstname: "Albert",
"lastname: "Einstein"
},
"deptname": "Physics",
"children": [
{"firstname": "Hans", "lastname": "Einstein" },
{"firstname": "Eduard", "lastname": "Einstein" }
]
}
Figure 8.1 ExampleofJSONdata.
and retrieve data and to perform computations at a backend server; web services are
describedinmoredetailinSection9.5.2.Applicationsinvokewebservicesbysending
parameters either as simple values such as strings or numbers, or by using JSON for
morecomplexparameters.ThewebservicethenreturnsresultsusingJSON.Forexam-
ple,anemailuserinterfacemayinvokewebservicesforeachofthese tasks: authenti-
catingtheuser,fetchingemailheaderinformationtoshowalistofemails,fetchingan
emailbody,sendingemail,andsoon.
Thedataexchangedineachofthesestepsarecomplexandhaveaninternalstruc-
ture.TheabilityofJSONtorepresentcomplexstructures,anditsabilitytoallowflexible
structuring,makeitagoodfitforsuchapplications.
A number of libraries are available that make it easy to transform data between
the JSON representation and the object representation used in languages such as
JavaScript, Java, Python, PHP, and other languages. The ease of interfacing between
JSON and programming language data structures has played a significant role in the
widespreaduseofJSON.
Unlikearelationalrepresentation,JSONisverboseandtakesupmorestoragespace
forthesamedata.Further,parsingthetexttoretrieverequiredfieldscanbeveryCPU
intensive.Compressedrepresentationsthatalsomakeiteasiertoretrievevalueswith-
outparsingarethereforepopularforstorageofdata.Forexample,acompressedbinary
formatcalledBSON(shortforBinaryJSON)isusedinmanysystemsforstoringJSON
data.
TheSQLlanguageitselfhasbeenextendedtosupporttheJSONrepresentationin
severalways:
• JSONdatacanbestoredasaJSONdatatype.
• SQLqueriescangenerateJSONdatafromrelationaldata:

--- Page 399 ---

370 Chapter8 ComplexDataTypes
° ThereareSQLextensionsthatallowconstructionofJSONobjectsineachrow
ofaqueryresult.Forexample,PostgreSQLsupportsajson build object()func-
tion. As an example of its use, json build object('ID', 12345, 'name' 'Ein-
stein')returnsaJSONobject{"ID": 12345, "name", "Einstein"}.
° There are also SQL extensions that allow creation of a JSON object from a
collection of rows by using an aggregate function. For example, the json agg
aggregatefunctioninPostgreSQLallowscreationofasingleJSONobjectfrom
a collection of JSON objects. Oracle supports a similar aggregate function
json objectagg,aswellasanaggregatejson arraytagg,whichcreatesaJSON
arraywithobjectsinaspecifiedorder.SQLServersupportsaFORJSONAUTO
clause that formats the result of an SQL query as a JSON array, with one ele-
mentperrowintheSQLquery.
• SQL queries can extract data from a JSON object using some form of path con-
structs. For example, in PostgreSQL, if a value v is of type JSON and has an at-
tribute “ID”, v−>’ID’ would return the value of the “ID” attribute of v. Oracle
supports a similar feature, using a “.” instead of “−>”, while SQL Server uses a
function JSON VALUE(value, path) to extract values from JSON objects using a
specifiedpath.
Theexactsyntaxandsemanticsoftheseextensions,unfortunately,dependentirelyon
the specific database system. You can find references to more details on these exten-
sionsinthebibliographicnotesforthischapter,availableonline.
8.1.3 XML
The XML data representation adds tags enclosed in angle brackets, <>, to mark up
informationinatextualrepresentation.Tagsareusedinpairs,with<tag>and</tag>
delimitingthebeginningandtheendoftheportionofthetexttowhichthetagrefers.
Forexample,thetitleofadocumentmightbemarkedupasfollows:
<title>Database System Concepts</title>
Such tags can be used to represent relational data specifying relation names and at-
tributenamesastags,asshownbelow:
<course>
<course id> CS-101 </course id>
<title> Intro. to Computer Science </title>
<dept name> Comp. Sci. </dept name>
<credits> 4 </credits>
</course>

--- Page 400 ---

8.1 Semi-structuredData 371
<purchase order>
<identifier> P-101 </identifier>
<purchaser>
<name> Cray Z. Coyote </name>
<address> Route 66, Mesa Flats, Arizona 86047, USA </address>
</purchaser>
<supplier>
<name> Acme Supplies </name>
<address> 1 Broadway, New York, NY, USA </address>
</supplier>
<itemlist>
<item>
<identifier> RS1 </identifier>
<description> Atom powered rocket sled </description>
<quantity> 2 </quantity>
<price> 199.95 </price>
</item>
<item>
<identifier> SG2 </identifier>
<description> Superb glue </description>
<quantity> 1 </quantity>
<unit-of-measure> liter </unit-of-measure>
<price> 29.95 </price>
</item>
</itemlist>
<total cost> 429.85 </total cost>
<payment terms> Cash-on-delivery </payment terms>
<shipping mode> 1-second-delivery </shipping mode>
</purchase order>
Figure 8.2 XMLrepresentationofapurchaseorder.
Unlikewitharelationalschema,newtagscanbeintroducedeasily,andwithsuit-
able namesthe dataare“self-documenting”in thata human canunderstand orguess
whataparticularpieceofdatameansbasedonthename.
Furthermore,tagscanbeusedtocreatehierarchicalstructures,whichisnotpos-
sible with the relational model. Hierarchical structures are particularly important for
representingbusinessobjectsthatmustbeexchangedbetweenorganizations;examples
includebills,purchaseorders,andsoforth.
Figure 8.2, which shows how information about a purchase order can be repre-
sented in XML, illustrates a more realistic use of XML. Purchase orders are typically
generatedbyoneorganizationandsenttoanother.Apurchaseordercontainsavariety
ofinformation;thenestedrepresentationallowsallinformationinapurchaseorderto

--- Page 401 ---

372 Chapter8 ComplexDataTypes
be represented naturally in a single document. (Real purchase orders have consider-
ablymoreinformationthanthatdepictedinthissimplifiedexample.)XMLprovidesa
standardwayoftaggingthedata;thetwoorganizationsmustofcourseagreeonwhat
tagsappearinthepurchaseorderandwhattheymean.
The XQuery language was developed to support querying of XML data. Further
detailsofXMLandXQuerymaybefoundinChapter30.AlthoughXQueryimplemen-
tations are available from several vendors, unlike SQL, adoption of XQuery has been
relativelylimited.
However, the SQL language itself has been extended to support XML in several
ways:
• XMLdatacanbestoredasanXMLdatatype.
• SQLqueriescangenerateXMLdatafromrelationaldata.Suchextensionsarevery
useful for packaging related pieces of data into one XML document, which can
thenbesenttoanotherapplication.
The extensions allow the construction of XML representations from individual
rows, as well as the creation of an XML document from a collection of rows by
usinganXMLAGGaggregatefunction.
• SQLqueriescanextractdatafromanXMLdatatypevalue.Forexample,theXPath
languagesupports“pathexpressions”thatallowtheextractionofdesiredpartsof
datafromanXMLdocument.
YoucanfindmoredetailsontheseextensionsinChapter30.
8.1.4 RDF and Knowledge Graphs
TheResourceDescriptionFramework(RDF)isadatarepresentationstandardbasedon
theentity-relationshipmodel.WeprovideanoverviewofRDFinthissection.
8.1.4.1 TripleRepresentation
TheRDFmodelrepresentsdatabyasetoftriplesthatareinoneofthesetwoforms:
1. (ID,attribute-name,value)
2. (ID1,relationship-name,ID2)
whereID,ID1andID2areidentifiersofentities;entitiesarealsoreferredtoasresources
inRDF.NotethatunliketheE-Rmodel,theRDFmodelonlysupportsbinaryrelation-
ships,anditdoesnotsupportmoregeneraln-aryrelationships;wereturntothisissue
later.
The first attribute of a triple is called its subject, the second attribute is called
its predicate, and the last attribute is called its object. Thus, a triple has the structure
(subject,predicate,object).

--- Page 402 ---

8.1 Semi-structuredData 373
10101 instance-of instructor.
10101 name "Srinivasan".
10101 salary "6500".
00128 instance-of student.
00128 name "Zhang".
00128 tot cred "102".
comp sci instance-of department.
comp sci dept name "Comp.Sci.".
biology instance-of department.
CS-101 instance-of course.
CS-101 title "Intro.toComputerScience".
CS-101 course dept comp sci.
sec1 instance-of section.
sec1 sec course CS-101.
sec1 sec id "1".
sec1 semester "Fall".
sec1 year "2017".
sec1 classroom packard-101.
sec1 time slot id "H".
10101 inst dept comp sci.
00128 stud dept comp sci.
00128 takes sec1.
10101 teaches sec1.
Figure 8.3 RDFrepresentationofpartofthe Universitydatabase.
Figure8.3showsatriplerepresentationofasmallpartoftheUniversitydatabase.
All attribute values are shown in quotes, while identifiers are shown without quotes.
Attribute and relationship names (which form the predicate part of each triple) are
alsoshownwithoutquotes.
Inourexample,weusetheIDvaluestoidentifyinstructorsandstudentsandcourse
id toidentifycourses.Eachoftheirattributesisrepresentedasaseparatetriple.The
type information of objects is provided by the instance-of relationship; for example,
10101isidentifiedasaninstanceofinstructor,while00128isaninstanceofstudent.To
followRDFsyntax,theidentifieroftheComp.Sci.departmentisdenotedascomp sci.
Only one attribute of the department, dept name, is shown. Since the primary key of
section iscomposite, wehave creatednew identifierstoidentifysections; “sec1” iden-
tifiesone suchsection,shown withitssemester,year andsec id attributes, andwitha
relationshipcoursetoCS-101.
Relationshipsshowninthefigureincludethetakesandteachesrelationships,which
appearintheuniversityschema.Thedepartmentsofinstructors,studentsandcourses
are shown as relationships inst dept, stud dept and course dept respectively, following
the E-R model; similarly, the classroom associated with a section is also shown as a
classroomrelationshipwithaclassroomobject(packard-101,inourexample),andthe

--- Page 403 ---

374 Chapter8 ComplexDataTypes
courseassociatedwithasectionisshownasarelationshipsec coursebetweenthesec-
tionandthecourse.
As we saw, entity type information is represented using instance-of relationships
betweenentitiesandobjectsrepresentingtypes;type-subtyperelationshipscanalsobe
representedassubtypeedgesbetweentypeobjects.
IncontrasttotheE-Rmodelandrelationalschemas,RDFallowsnewattributesto
beeasilyaddedtoanobjectandalsotocreatenewtypesofrelationships.
8.1.4.2 GraphRepresentationofRDF
TheRDFrepresentationhasaverynaturalgraphinterpretation.Entitiesandattribute
valuescanbeconsideredasnodes,andattributenamesandrelationshipscanbecon-
sideredasedgesbetweenthenodes.Theattribute/relationshipnamecanbeviewedas
thelabelofthecorrespondingedge.Figure8.4showsagraphrepresentationofthedata
fromFigure8.3.Objectsareshownasovals,attributevaluesinrectangles,andrelation-
shipsasedgeswithassociatedlabelsidentifyingtherelationship.Wehaveomittedthe
instance-of relationshipsforbrevity.
A representation of information using the RDF graph model (or its variants and
extensions)isreferredtoasaknowledgegraph.Knowledgegraphsareusedforavariety
ofpurposes.Onesuchapplicationistostorefactsthatareharvestedfromavarietyof
datasources,suchasWikipedia,Wikidata,andothersourcesontheweb.Anexample
ofafactis“Washington,D.C.isthecapitalofU.S.A.”Suchafactcanberepresented
asanedgelabeledcapital-of connectingtwonodes,onerepresentingtheentityWash-
ington,D.C.,andtheotherrepresentingtheentityU.S.A.
Srinivasan 6500 Comp. Sci. Zhang 102
name salary dept_name name tot_cred
inst_dept stud_dept
10101 comp_sci 00128
teaches course_dept takes
CS-101 sec1
sec_course sec_id
1
title classroom semester year
Intro. to Computer Science packard-101 Fall 2017
Figure 8.4 GraphrepresentationofRDFdata.

--- Page 404 ---

8.1 Semi-structuredData 375
Questions about entities can be answered using a knowledge graph that contains
relevant information. For example, the question “Which city is the capital of the
U.S.A.?” can be answered by looking for an edge labeled capital-of, linking an entity
to the country U.S.A.(If type information isavailable, the query may also verify that
there is an instance-of edge connectingWashington, D.C., to a node representing the
entitytypeCity).
8.1.4.3 SPARQL
SPARQL is a query language designed to query RDF data. The language is based on
triple patterns, which look like RDF triples but may contain variables. For example,
thetriplepattern:
?cid title "Intro.toComputerScience"
would match all triples whose predicate is “title” and object is “Intro. to Computer
Science”.Here,?cidisavariablethatcanmatchanyvalue.
Queriescanhavemultipletriplepatterns,withvariablessharedacrosstriples.Con-
siderthefollowingpairoftriples:
?cid title "Intro.toComputerScience"
?sid course ?cid
Ontheuniversity-tripledatasetshowninFigure8.3,thefirsttriplepatternmatchesthe
triple (CS-101, title, "Intro. to Computer Science"), while the second triple pattern
matches (sec1, course, CS-101). The shared variable ?cid enforces a join condition
betweenthetwotriplepatterns.
WecannowshowacompleteSPARQLquery.Thefollowingqueryretrievesnames
of all students who have taken a section whose course is titled “Intro. to Computer
Science”.
select?name
where{
?cidtitle"Intro.toComputerScience".
?sidcourse?cid.
?idtakes?sid.
?idname?name.
}
Thesharedvariablesbetweenthesetriplesenforceajoinconditionbetweenthetuples
matchingeachofthesetriples.
NotethatunlikeinSQL,thepredicateinatriplepatterncanbeavariable,which
canmatchanyrelationshiporattributename.SPARQLhasmanymorefeatures,such

--- Page 405 ---

376 Chapter8 ComplexDataTypes
as aggregation, optional joins (similar to outerjoins), and subqueries. Formore infor-
mationinSPARQL,seethereferencesinFurtherReading.
8.1.4.4 RepresentingN-aryRelationships
Relationships represented as edges can model only binary relationships. Knowledge
graphs have been extended tostore morecomplex relationships.Forexample, knowl-
edgegraphshavebeenextendedwithtemporal informationtorecordthetimeperiod
duringwhichafactistrue;ifthecapitaloftheU.S.A.changedfromWashington,DC.,
to say, New York, in 2050, thiswould be represented by two facts, one for the period
endingin2050whenWashingtonwasthecapital,andonefortheperiodafter2050.
AswesawinSection6.9.4,ann-aryrelationshipcanberepresentedusingbinary
relationships by creating an artificial entity corresponding to a tuple in an n-ary re-
lationship and linking that artificial entity to each of the entities participating in the
relationship.Intheprecedingexample,wecancreateanartificialentitye torepresent
1
the fact that Barack Obama was president of the U.S.A. from 2008 to 2016. We link
e to the entities representing Obama and U.S.A. by person and country relationship
1
edges respectively, and to the values 2008 and 2016 by attribute edges president-from
and president-till respectively. If we chose to represent years as entities, the edges cre-
atedtothetwoyearsabovewouldrepresentrelationshipsinsteadofattributes.
TheaboveideaissimilartotheE-Rmodelnotionofaggregationwhich,aswesaw
in Section 6.8.5, can treat a relationship as an entity; this idea is called reification in
RDF. Reification is used in many knowledge-graph representations, where the extra
information such as time period of validity are treated as qualifiers of the underlying
edge.
Othermodelsaddafourthattribute,calledthecontext,totriples;thus,insteadof
storing triples, they store quads. The basic relationship is still binary, but the fourth
attributeallowsacontextentitytobeassociatedwitharelationship.Informationsuch
asvalidtimeperiodcanbetreatedasattributesofthecontextentity.
There are several knowledge bases, such as Wikidata, DBPedia, Freebase, and
Yago,thatprovideanRDF/knowledgegraphrepresentationofawidevarietyofknowl-
edge.Inaddition,thereareaverylargenumberofdomain-specificknowledgegraphs.
The linked open data project is aimed at making a variety of such knowledge graphs
opensourceandfurthercreatinglinksbetweentheseindependentlycreatedknowledge
graphs. Such links allow queries to make inferences using information from multiple
knowledgegraphsalongwithlinkstotheknowledgegraphs.Referencestomoreinfor-
mationonthistopicmaybefoundinthebibliographicnotesforthischapter,available
online.
8.2 Object Orientation
Theobject-relationaldatamodelextendstherelationaldatamodelbyprovidingaricher
type system, including complex data types and object orientation. Relational query

--- Page 406 ---

8.2 ObjectOrientation 377
languages, in particular SQL, have been extended correspondingly to deal with the
richer type system. Such extensions attempt to preserve the relational foundations—
inparticular,thedeclarativeaccesstodata—whileextendingthemodelingpower.
Many database applications are written using an object-oriented programming
language, such as Java, Python, or C++, but they need to store and fetch data from
databases. Due to the type difference between the native type system of the object-
orientedprogramminglanguageandtherelationalmodelsupportedbydatabases,data
need to be translated between the two models whenever they are fetched or stored.
Merelyextendingthetype system supported bythedatabase wasnotenough tosolve
this problem completely. Having to express database access using a language (SQL)
thatisdifferentfrom the programminglanguage again makesthe job of the program-
merharder.Itisdesirable,formanyapplications,tohaveprogramminglanguagecon-
structsorextensionsthatpermitdirectaccesstodatainthedatabase,withouthaving
togothroughanintermediatelanguagesuchasSQL.
Three approaches are used in practice for integrating object orientation with
databasesystems:
1. Buildanobject-relationaldatabasesystem,whichaddsobject-orientedfeaturesto
arelationaldatabasesystem.
2. Automatically convert data from the native object-oriented type system of the
programminglanguage to a relationalrepresentation for storage, and vice versa
forretrieval.Dataconversionisspecifiedusinganobject-relationalmapping.
3. Buildanobject-orienteddatabase system,thatis,adatabasesystem thatnatively
supports an object-oriented type system and allows direct access to data from
an object-oriented programming language using the native type system of the
language.
We provide a brief introduction to the first two approaches in this section. While the
thirdapproach,theobject-orienteddatabaseapproach,hassomebenefitsoverthefirst
two approaches in terms of language integration, it has not seen much success for
tworeasons.First,declarativequeryingisveryimportantforefficientlyaccessingdata,
and such querying is not supported by imperative programming languages. Second,
direct access to objects via pointers was found to result in increased risk of database
corruptionduetopointererrors.Wedonotdescribetheobject-orientedapproachany
further.
8.2.1 Object-Relational Database Systems
In this section, we outline how object-oriented features can be added to relational
databasesystems.

--- Page 407 ---

378 Chapter8 ComplexDataTypes
8.2.1.1 User-DefinedTypes
ObjectextensionstoSQLallowcreationofstructureduser-definedtypes,referencesto
suchtypes,andtablescontainingtuplesofsuchtypes.1
createtypePerson
(IDvarchar(20)primarykey,
namevarchar(20),
addressvarchar(20))
reffrom(ID);
createtablepeopleofPerson;
Wecancreateanewpersonasfollows:
insertintopeople(ID,name,address)values
('12345','Srinivasan','23CoyoteRun');
Many database systems support array and table types; attributes of relations and
of user-defined types can be declared to be of such array or table types. The support
forsuchfeaturesaswellasthesyntaxvarieswidelybydatabasesystem.InPostgreSQL,
forexample,integer[]denotesanarrayofintegerswhosesizeisnotprespecified,while
Oraclesupportsthesyntaxvarray(10)ofintegertospecifyanarrayof10integers.SQL
Serverallowstable-valuedtypestobedeclaredasshowninthefollowingexample:
createtypeinterestastable(
topicvarchar(20),
degree of interestint
);
createtableusers(
IDvarchar(20),
namevarchar(20),
interestsinterest
);
User-defined types can also have methods associated with them. Only a few
databasesystems,suchasOracle,supportthisfeature;weomitdetails.
8.2.1.2 TypeInheritance
ConsidertheearlierdefinitionofthetypePersonandthetablepeople.Wemaywantto
storeextrainformationinthedatabaseaboutpeoplewhoarestudentsandaboutpeople
1Structuredtypesaredifferentfromthesimpler“distinct”datatypesthatwecoveredinSection4.5.5.

--- Page 408 ---

8.2 ObjectOrientation 379
whoareteachers.Sincestudentsandteachersarealsopeople,wecanuseinheritance
todefinethestudentandteachertypesinSQL:
createtypeStudentunderPerson
(degreevarchar(20));
createtypeTeacher underPerson
(salaryinteger);
Both Student and Teacher inherit the attributes of Person—namely, ID, name, and ad-
dress.StudentandTeacher aresaidtobesubtypesofPerson,andPersonisasupertype
ofStudent,aswellasofTeacher.
Methods of a structured type are inherited by its subtypes, just as attributes are.
However,asubtypecanredefinetheeffectofamethod.Weomitdetails.
8.2.1.3 TableInheritance
Tableinheritanceallowsatabletobedeclaredasasubtableofanothertableandcor-
responds to the E-R notion of specialization/generalization. Several database systems
supporttableinheritance,butindifferentways.
InPostgreSQL,wecould createatablepeople and thencreate tablesstudentsand
teachersassubtablesofpeopleasfollows:
createtablestudents
(degreevarchar(20))
inheritspeople;
createtableteachers
(salaryinteger)
inheritspeople;
As a result, every attribute present in the table people is also present in the subtables
studentsandteachers.
SQL:1999 supports table inheritance but requires table types to be specified first.
Thus,inOracle,whichsupportsSQL:1999,wecoulduse:
createtablepeopleofPerson;
createtablestudentsofStudent
underpeople;
createtableteachersofTeacher
underpeople;
where the types Student and Teacher have been declared to be subtypes of Person as
describedearlier.

--- Page 409 ---

380 Chapter8 ComplexDataTypes
Ineithercase,wecaninsertatupleintothestudenttableasfollows:
insertintostudentvalues('00128','Zhang','235CoyoteRun','Ph.D.');
where we provide values for the attributes inherited from people as well as the local
attributesofstudent.
When we declarestudentsand teachers as subtables of people, everytuple present
in students or teachers becomes implicitly present in people. Thus, if a query uses the
tablepeople,itwillfindnotonlytuplesdirectlyinsertedintothattablebutalsotuples
insertedintoitssubtables,namely,studentsandteachers.However,onlythoseattributes
thatarepresentinpeoplecanbeaccessedbythatquery.SQLpermitsustofindtuples
thatareinpeoplebutnotinitssubtablesbyusing“onlypeople” inplaceofpeopleina
query.
8.2.1.4 ReferenceTypesinSQL
SomeSQLimplementationssuch asOraclesupport referencetypes. Forexample, we
coulddefinethePersontypeasfollows,withareference-typedeclaration:
createtypePerson
(IDvarchar(20)primarykey,
namevarchar(20),
addressvarchar(20))
reffrom(ID);
createtablepeopleofPerson;
By default, SQL assigns system-defined identifiers for tuples, but an existing primary-
keyvaluecanbeusedtoreferenceatuplebyincludingthereffromclauseinthetype
definitionasshownabove.
WecandefineatypeDepartmentwithafieldnameandafieldhead thatisarefer-
encetothetypePerson.WecanthencreateatabledepartmentsoftypeDepartment,as
follows:
createtypeDepartment(
dept namevarchar(20),
head ref(Person)scopepeople);
createtabledepartmentsofDepartment;
Note that the scope clause above completes the definition of the foreign key from de-
partments.head tothepeoplerelation.
Wheninsertingatuplefordepartments,wecanthenuse:
insertintodepartments
values('CS','12345');

--- Page 410 ---

8.2 ObjectOrientation 381
since the ID attribute is used as a reference to Person. Alternatively, the definition of
Person can specify that the reference must be generated automatically by the system
when a Person object is created. System-generated identifiers can be retrieved using
ref(r) where r is a table name of table alias used in a query. Thus, we could create a
Persontuple,and,usingtheIDornameoftheperson,wecouldretrievethereference
tothetupleinasubquery,whichisusedtocreatethevaluefortheheadattributewhen
insertingatupleintothedepartmentstable.Sincemostdatabasesystemsdonotallow
subqueriesinaninsertintodepartmentsvaluesstatement,thefollowingtwoqueriescan
beusedtocarryoutthetask:
insertintodepartments
values('CS',null);
update departments
sethead =(selectref(p)
frompeopleasp
whereID='12345')
wheredept name='CS';
ReferencesaredereferencedinSQL:1999bythe−>symbol.Considerthedepart-
mentstable defined earlier.We can use thisquery tofind the names and addressesof
theheadsofalldepartments:
selecthead−>name,head−>address
fromdepartments;
Anexpressionsuchas“head−>name”iscalledapathexpression.
Since head is a reference to a tuple in the people table, the attribute name in the
preceding query is the name attribute of the tuple from the people table. References
canbeusedtohidejoinoperations;intheprecedingexample,withoutthereferences,
the head field of department would be declared a foreign key of the table people. To
find the name and address of the head of a department, we would require an explicit
joinoftherelationsdepartmentsandpeople.Theuseofreferencessimplifiesthequery
considerably.
We can use the operation deref to return the tuple pointed to by a reference and
thenaccessitsattributes,asshownbelow:
selectderef(head).name
fromdepartments;
8.2.2 Object-Relational Mapping
Object-relational mapping (ORM) systems allow a programmer to define a mapping
betweentuplesindatabaserelationsandobjectsintheprogramminglanguage.

--- Page 411 ---

382 Chapter8 ComplexDataTypes
An object, or a set of objects, can be retrieved based on a selection condition on
its attributes; relevant data are retrieved from the underlying database based on the
selectionconditions,andoneormoreobjectsarecreatedfromtheretrieveddata,based
ontheprespecifiedmappingbetweenobjectsandrelations.
The program can update retrieved objects, create new objects, or specify that an
object is to be deleted, and then issue a save command; the mapping from objects to
relationsisthenusedtocorrespondinglyupdate,insert,ordeletetuplesinthedatabase.
The primary goal of object-relational mapping systems is to ease the job of pro-
grammers who build applications by providing them an object model while retaining
the benefits of using a robust relational database underneath. As an added benefit,
when operating on objects cached in memory, object-relational systems can provide
significantperformancegainsoverdirectaccesstotheunderlyingdatabase.
Object-relational mapping systems also provide query languages that allow pro-
grammers to write queries directly on the object model; such queries are translated
intoSQLquerieson theunderlyingrelationaldatabase, and resultobjectsare created
fromtheSQLqueryresults.
AfringebenefitofusinganORMisthatanyofanumberofdatabasescanbeused
tostoredata,withexactlythesamehigh-levelcode.ORMshideminorSQLdifferences
between databases from the higher levels. Migration from one database to another is
thusrelativelystraightforwardwhenusinganORM,whereasSQLdifferencescanmake
such migration significantly harder if an application uses SQL to communicate with
thedatabase.
Onthenegativeside,object-relationalmappingsystemscansufferfromsignificant
performance inefficiencies for bulk database updates, as well as for complex queries
thatarewrittendirectlyintheimperativelanguage.Itispossibletoupdatethedatabase
directly,bypassingtheobject-relationalmappingsystem,andtowritecomplexqueries
directlyinSQLincaseswheresuchinefficienciesarediscovered.
The benefits of object-relational models exceed the drawbacks for many applica-
tions,andobject-relationalmappingsystemshaveseenwidespreadadoptioninrecent
years. In particular,Hibernate hasseen wideadoptionwithJava, whileseveral ORMs
includingDjangoandSQLAlchemyarewidelyusedwithPython.Moreinformationon
theHibernateORMsystem,whichprovidesanobject-relationalmappingforJava,and
theDjangoORMsystem,whichprovidesanobject-relationalmappingforPython,can
befoundinSection9.6.2.
8.3 Textual Data
Textual data consists of unstructured text. The term information retrieval generally
refers to the querying of unstructured textual data. In the traditional model used in
thefieldofinformationretrieval,textualinformationisorganizedintodocuments.Ina
database, a text-valued attribute can be considered a document. In the context of the
web,eachwebpagecanbeconsideredtobeadocument.

--- Page 412 ---

8.3 TextualData 383
8.3.1 Keyword Queries
Informationretrievalsystems supporttheabilitytoretrievedocumentswithsomede-
siredinformation.Thedesireddocumentsaretypicallydescribedbyasetofkeywords
—for example, the keywords “database system” may be used to locate documents on
databasesystems, andthekeywords“stock”and“scandal”maybeusedtolocatearti-
cles about stock-market scandals. Documents have associated with them a set of key-
words; typically, all the words in the documents are considered keywords. A keyword
queryretrievesdocumentswhosesetofkeywordscontainsallthekeywordsinthequery.
In its simplest form, an information-retrievalsystem locates and returns all docu-
mentsthatcontainallthekeywordsinthequery.More-sophisticatedsystemsestimate
the relevance of documents to a query so that the documents can be shown in order
of estimated relevance. They use information about keyword occurrences, as well as
hyperlinkinformation,toestimaterelevance.
Keyword search was originally targeted at document repositories within organi-
zations or domain-specific document repositories such as research publications. But
informationretrievalisalsoimportantfordocumentsstoredinadatabase.
Keyword-based information retrieval can be used not only for retrieving textual
data, but also for retrieving other types of data, such as video and audio data, that
havedescriptivekeywordsassociatedwiththem.Forinstance,avideomoviemayhave
associatedwithitkeywordssuchasitstitle,director,actors,andgenre,whileanimage
or video clip may have tags, which are keywords describing the image or video clip,
associatedwithit.
Web search engines are, at core, information retrieval systems. They retrieve and
storewebpagesbycrawlingtheweb.Userssubmitkeywordqueries,andtheinformation
retrievalpartofthewebsearchenginefindsstoredwebpagescontainingtherequired
keyword. Web search engines have today evolved beyond just retrieving web pages.
Today, searchenginesaimto satisfy auser’s informationneedsby judgingwhattopic
a query is about and displaying not only web pages judged as relevant but also other
kinds of information about the topic. For example, given a query term “cricket”, a
searchenginemaydisplayscoresfromongoingorrecentcricketmatches,ratherthan
just top-ranked documents related to cricket. As another example, in response to a
query“NewYork”,asearchenginemayshowamapofNewYorkandimagesofNew
YorkinadditiontowebpagesrelatedtoNewYork.
8.3.2 Relevance Ranking
The set of all documents that contain the keywords in a query may be very large; in
particular, there are billions of documents on the web, and most keyword queries on
a web search engine find hundreds of thousands of documents containing some or
all of the keywords. Not all the documents are equally relevant to a keyword query.
Information-retrieval systems therefore estimate relevance of documents to a query
andreturnonlyhighlyrankeddocumentsasanswers.Relevancerankingisnotanexact
science,buttherearesomewell-acceptedapproaches.

--- Page 413 ---

384 Chapter8 ComplexDataTypes
8.3.2.1 RankingUsingTF-IDF
Thewordtermreferstoakeywordoccurringinadocument,orgivenaspartofaquery.
The first question to address is, given a particular term t, how relevant is a particular
documentdtotheterm.Oneapproachistousethenumberofoccurrencesoftheterm
in the document as a measure of its relevance, on the assumption that more relevant
termsarelikelytobementionedmanytimesinadocument.Justcountingthenumber
of occurrences of a term is usually not a good indicator: first, the number of occur-
rencesdependsonthelengthofthedocument,andsecond,adocumentcontaining10
occurrencesofaterm maynotbe 10timesas relevantasadocumentcontainingone
occurrence.
OnewayofmeasuringTF(d,t),therelevanceofatermttoadocumentd,is:
( )
n(d,t)
TF(d,t) = log 1+
n(d)
where n(d) denotes the number of term occurrences in the document and n(d,t) de-
notesthenumberofoccurrencesoftermtinthedocumentd.Observethatthismetric
takesthelengthofthedocumentintoaccount.Therelevancegrowswithmoreoccur-
rencesofaterminthedocument,althoughitisnotdirectlyproportionaltothenumber
ofoccurrences.
Many systems refine the above metric by using other information. For instance,
if the term occurs in the title, or the author list, or the abstract, the document would
be consideredmorerelevanttotheterm.Similarly,ifthefirstoccurrenceofatermis
late in the document, the document may be considered less relevant than if the first
occurrenceisearlyinthedocument.Theabovenotionscanbeformalizedbyextensions
oftheformulawehaveshownforTF(d,t).Intheinformationretrievalcommunity,the
relevanceof a documenttoa term isreferred toas termfrequency (TF), regardlessof
theexactformulaused.
AqueryQmaycontainmultiplekeywords.Therelevanceofadocumenttoaquery
with two or more keywords is estimated by combining the relevance measures of the
documentforeachkeyword.Asimplewayofcombiningthemeasuresistoaddthemup.
However,notalltermsusedaskeywordsareequal.Supposeaqueryusestwoterms,one
ofwhichoccursfrequently,suchas“database”,andanotherthatislessfrequent,such
as“Silberschatz”.Adocumentcontaining“Silberschatz”butnot“database”shouldbe
rankedhigherthanadocumentcontainingtheterm“database”butnot“Silberschatz”.
To fix this problem, weightsare assigned to terms using the inverse document fre-
quency(IDF),definedas:
1
IDF(t) =
n(t)
wheren(t)denotesthenumberofdocuments(amongthoseindexedbythesystem)that
contain the term t. The relevanceof a document d to a set of terms Q isthen defined
as:

--- Page 414 ---

8.3 TextualData 385
∑
r(d,Q) = TF(d,t)∗ IDF(t)
t∈Q
Thismeasurecanbefurtherrefinediftheuserispermittedtospecifyweightsw(t)for
termsinthequery,inwhichcasetheuser-specifiedweightsarealsotakenintoaccount
bymultiplyingTF(t)byw(t)intheprecedingformula.
The above approach of using term frequency and inverse document frequency as
ameasureoftherelevanceofadocumentiscalledtheTF–IDFapproach.
Almostalltextdocuments(inEnglish)containwordssuchas“and,”“or,”“a,”and
soon,andhencethesewordsareuselessforqueryingpurposessincetheirinversedoc-
umentfrequencyisextremelylow.Information-retrievalsystemsdefineasetofwords,
calledstop words, containing100 or so of the most common words, and ignore these
wordswhenindexingadocument.Suchwordsarenotusedaskeywords,andtheyare
discardedifpresentinthekeywordssuppliedbytheuser.
Another factor taken into account when a query contains multiple terms is the
proximity of the terms in the document. If the terms occur close to each other in the
document,thedocumentwillberankedhigherthaniftheyoccurfarapart.Theformula
forr(d,Q)canbemodifiedtotakeproximityofthetermsintoaccount.
GivenaqueryQ,thejobofaninformation-retrievalsystemistoreturndocuments
in descending order of their relevance to Q. Since there may be a very large number
ofdocumentsthatarerelevant,information-retrievalsystemstypicallyreturnonlythe
firstfewdocumentswiththehighestdegreeofestimatedrelevanceandpermitusersto
interactivelyrequestfurtherdocuments.
8.3.2.2 RankingUsingHyperlinks
Hyperlinks between documents can be used to decide on the overall importance of
a document, independent of the keyword query; for example, documents linked from
manyotherdocumentsareconsideredmoreimportant.
Thewebsearchengine Google introducedPageRank, whichisameasure ofpop-
ularity of a page based on the popularity of pages that link to the page. Using the
PageRank popularity measure torank answersto a query gave resultsso much better
than previously used ranking techniques that Google became the most widely used
searchengineinarathershortperiodoftime.
Note that pages that are pointed to from many web pages are more likely to be
visited, and thus should have a higher PageRank. Similarly, pages pointed to by web
pages with a high PageRank will also have a higher probability of being visited, and
thusshouldhaveahigherPageRank.
ThePageRankofadocumentdisthusdefined(circularly)basedonthePageRank
of other documents that link to document d. PageRank can be defined by a set of
linear equations, as follows: First, web pages are given integer identifiers. The jump
probabilitymatrixT isdefinedwithT[i,j]settotheprobabilitythatarandomwalker
whoisfollowingalinkoutofpageifollowsthelinktopagej.Assumingthateachlink

--- Page 415 ---

386 Chapter8 ComplexDataTypes
fromihasanequalprobabilityofbeingfollowedT[i,j] =1∕N,whereN isthenumber
i i
oflinksoutofpagei.ThenthePageRankP[j]foreachpagej canbedefinedas:
∑N
P[j] = δ∕N +(1−δ) ∗ (T[i,j] ∗ P[i])
i=1
whereδisaconstantbetween0and1,usuallysetto0.15,andN isthenumberofpages.
Thesetofequationsgeneratedasaboveareusuallysolvedbyaniterativetechnique,
starting with each P[i] set to 1∕N. Each step of the iteration computes new values
for each P[i] using the P values from the previous iteration. Iteration stops when the
maximumchangeinanyP[i]valueinaniterationgoesbelowsomecutoffvalue.
NotethatPageRankisastaticmeasure,independentofthekeywordquery;given
akeywordquery,itisusedincombinationwithTF–IDFscoresofadocumenttojudge
itsrelevanceofthedocumenttothekeywordquery.
PageRankisnottheonlymeasureofthepopularityofasite.Informationabouthow
often asite is visited isanother useful measure of popularity. Further, search engines
track what fraction of times users click on a page when it is returned as an answer.
Keywords that occur in the anchor text associated with the hyperlink to a page are
viewedasveryimportantandaregivenahighertermfrequency.Theseandanumber
ofotherfactorsareusedtorankanswerstoakeywordquery.
8.3.3 Measuring Retrieval Effectiveness
Rankingofresultsofakeywordqueryisnotanexactscience.Twometricsareusedto
measure how wellan information-retrievalsystem isable toanswer queries. The first,
precision, measures what percentage of the retrieved documents are actually relevant
tothequery.Thesecond,recall,measureswhatpercentageofthedocumentsrelevant
tothequerywereretrieved.Sincesearchenginesfindaverylargenumberofanswers,
and users typically stop after browsing some number (say, 10 or 20) of the answers,
the precisionand recallnumbersare usuallymeasured “@K”, whereK isthe number
ofanswersviewed.Thus,onecantalkofprecision@10orrecall@20.
8.3.4 Keyword Querying on Structured Data and Knowledge Graphs
Although querying on structured data are typically done using query languages such
asSQL,userswhoarenotfamiliarwiththeschemaorthequerylanguagefinditdiffi-
cult to get information from such data. Based on the success of keyword querying in
thecontextof informationretrievalfrom theweb,techniqueshavebeen developedto
supportkeywordqueriesonstructuredandsemi-structureddata.
One approach is to represent the data using graphs, and then perform keyword
queries on the graphs. For example, tuples can be treated as nodes in the graph, and
foreignkeyandotherconnectionsbetweentuplescanbetreatedasedgesinthegraph.
Keyword search isthen modeled as findingtuples containingthe given keywords and
findingconnectingpathsbetweentheminthecorrespondinggraph.

--- Page 416 ---

8.4 SpatialData 387
For example, a query “Zhang Katz” on a university database may find the name
“Zhang”occurringinastudenttuple,andthename“Katz”inaninstructortuple,apath
through the advisor relation connecting the two tuples. Other paths, such as student
“Zhang”takingacoursetaughtby“Katz”mayalsobefoundinresponsetothisquery.
Suchqueriesmaybeusedforadhocbrowsingandqueryingofdatawhentheuserdoes
notknowtheexactschemaanddoesnotwishtotaketheefforttowriteanSQLquery
definingwhatsheissearchingfor.Indeeditisunreasonabletoexpectlayuserstowrite
queriesinastructuredquerylanguage,whereaskeywordqueryingisquitenatural.
Sincequeriesarenotfullydefined,theymayhavemanydifferenttypesofanswers,
whichmustberanked.Anumberoftechniqueshavebeenproposedtorankanswersin
suchasetting,basedonthelengthsofconnectingpathsandontechniquesforassigning
directions and weights to edges. Techniques have also been proposed for assigning
popularity ranks to tuples based on foreign key links. More information on keyword
searchingofstructured datamaybe found inthe bibliographicnotesforthischapter,
availableonline.
Further, knowledge graphs can be used along with textual information to answer
queries. For example, knowledge graphs can be used to provide unique identifiers to
entities,whichareusedtoannotatementionsoftheentitiesintextualdocuments.Now
aparticularmentionofapersoninadocumentmayhavethephrase“Stonebrakerde-
velopedPostgreSQL”;fromthecontext,thewordStonebrakermaybeinferredtobethe
database researcher“MichaelStonebraker” andannotated bylinkingthewordStone-
brakertotheentity“MichaelStonebraker”.Theknowledgegraphmayalsorecordthe
fact that Stonebraker won the Turing award. A query asking for “turing award post-
gresql”cannowbeansweredbyusinginformationfromthedocumentandtheknowl-
edgegraph.2
Websearchenginestodayuselargeknowledgegraphs,inadditiontocrawleddoc-
uments,toansweruserqueries.
8.4 Spatial Data
Spatialdatasupportindatabasesystems isimportantforefficientlystoring,indexing,
andqueryingofdataonthebasisofspatiallocations.
Twotypesofspatialdataareparticularlyimportant:
• Geographicdatasuchasroadmaps,land-usagemaps,topographicelevationmaps,
politicalmapsshowingboundaries,land-ownershipmaps,andsoon.Geographic
informationsystemsarespecial-purposedatabasesystemstailoredforstoringgeo-
graphicdata.Geographicdataisbasedonaround-earthcoordinatesystem, with
latitude,longitude,andelevation.
2InthiscasetheknowledgegraphmayalreadyrecordthatStonebrakerdevelopedPostgreSQL,buttherearemany
otherpiecesofinformationthatmayexistonlyindocuments,andnotintheknowledgegraphs.

--- Page 417 ---

388 Chapter8 ComplexDataTypes
• Geometric data, which include spatial information about how objects—such as
buildings, cars, or aircraft—are constructed. Geometric data is based on a two-
dimensionalorthree-dimensionalEuclideanspace,withX,Y,andZ coordinates.
Geographic and geometric data types are supported by many database systems, such
as Oracle Spatial and Graph, the PostGIS extension of PostgreSQL, SQL Server, and
theIBMDB2SpatialExtender.
In thissection we describe the modelingand querying of spatial data; implemen-
tation techniques such as indexing and query processing techniques are covered in
Chapter14andinChapter15.
Thesyntaxforrepresentinggeographicandgeometricdatavariesbydatabase,al-
thoughrepresentationsbasedontheOpenGeospatialConsortium(OGC)standardare
now increasingly supported. See the manuals of the database you use to learn more
aboutthespecificsyntaxsupportedbythedatabase.
8.4.1 Representation of Geometric Information
Figure 8.5 illustrates how various geometric constructs can be represented in a data-
base,inanormalizedfashion.Westressherethatgeometricinformationcanberepre-
sentedinseveraldifferentways,onlysomeofwhichwedescribe.
Alinesegmentcanberepresentedbythecoordinatesofitsendpoints.Forexample,
inamapdatabase,thetwocoordinatesofapointwouldbeitslatitudeandlongitude.
Apolyline(alsocalledalinestring)consistsofaconnectedsequenceoflinesegments
andcanberepresentedbyalistcontainingthecoordinatesoftheendpointsoftheseg-
ments,insequence.Wecanapproximatelyrepresentanarbitrarycurvewithpolylines
bypartitioningthecurveintoasequenceofsegments.Thisrepresentationisusefulfor
two-dimensional features such as roads; here, the width of the road is small enough
relativetothesizeofthefullmapthatitcanbeconsideredtobealine.Somesystems
alsosupportcirculararcsasprimitives,allowingcurvestoberepresentedassequences
ofarcs.
We can represent a polygon by listing its vertices in order, as in Figure 8.5.3 The
listofverticesspecifiestheboundaryofapolygonalregion.Inanalternativerepresen-
tation, a polygon can be divided into a set of triangles, as shown in Figure 8.5. This
processiscalledtriangulation,andanypolygoncanbetriangulated.Thecomplexpoly-
goncanbegivenanidentifier,andeachofthetrianglesintowhichitisdividedcarries
theidentifierofthepolygon.Circlesandellipsescanberepresentedbycorresponding
typesorapproximatedbypolygons.
List-basedrepresentationsofpolylinesorpolygonsareoftenconvenientforquery
processing. Such non-first-normal-form representations are used when supported by
the underlying database. So that we can use fixed-size tuples (in first normal form)
for representing polylines, we can give the polyline or curve an identifier,and we can
3Somereferencesusethetermclosedpolygontorefertowhatwecallpolygonsandrefertopolylinesasopenpolygons.

--- Page 418 ---

8.4 SpatialData 389
2
line segment
{(x1,y1), (x2,y2)}
1
3
triangle {(x1,y1), (x2,y2), (x3,y3)}
1 2
2
3
polygon 1 {(x1,y1), (x2,y2), (x3,y3), (x4,y4), (x5,y5)}
4
5
2
3 {(x1,y1), (x2,y2), (x3,y3), ID1}
polygon 1 {(x1,y1), (x3,y3), (x4,y4), ID1}
{(x1,y1), (x4,y4), (x5,y5), ID1}
4
5
object representation
Figure 8.5 Representationofgeometricconstructs.
representeachsegmentasaseparatetuplethatalsocarrieswithittheidentifierofthe
polyline or curve. Similarly, the triangulated representation of polygons allows a first
normalformrelationalrepresentationofpolygons.
Therepresentationofpointsandlinesegmentsinthree-dimensionalspaceissim-
ilar to their representation in two-dimensional space, the only difference being that
pointshaveanextrazcomponent.Similarly,therepresentationofplanarfigures—such
astriangles,rectangles,andotherpolygons—doesnotchangemuchwhenwemoveto
three dimensions. Tetrahedrons and cuboids can be represented in the same way as
triangles and rectangles. We can represent arbitrary polyhedra by dividing them into
tetrahedrons, just as we triangulate polygons. We can also represent them by listing
theirfaces,eachofwhichisitselfapolygon,alongwithanindicationofwhichsideof
thefaceisinsidethepolyhedron.

--- Page 419 ---

390 Chapter8 ComplexDataTypes
Forexample,SQLServerandPostGISsupportthegeometry andgeography types,
each of which has subtypes such as point, linestring, curve, polygon, as well as col-
lections of these types called multipoint, multilinestring, multicurve and multipoly-
gon. Textual representations of these types are defined by the OGC standards, and
canbeconvertedtointernalrepresentationsusingconversionfunctions.Forexample,
LINESTRING(1 1, 2 3, 4 4) defines a line that connects points (1, 1), (2, 3) and (4,
4), while POLYGON((1 1, 2 3, 4 4, 1 1)) defines a triangle defined by these points.
Functions ST GeometryFromText() and ST GeographyFromText() convert the textual
representationstogeometryandgeographyobjectsrespectively.Operationsongeom-
etryandgeographytypesthatreturnobjectsofthesametypeincludetheST Union()
andST Intersection()functionswhichcomputetheunionandintersectionofgeomet-
ricobjectssuchaslinestringsandpolygons.Thefunctionnamesaswellassyntaxdiffer
bysystem;seethesystemmanualsfordetails.
In the context of map data, the various line segments representing the roads are
actuallyinterconnectedtoformagraph.Suchaspatialnetworkorspatialgraphhasspa-
tiallocationsforverticesofthegraph,alongwithinterconnectioninformationbetween
thevertices,whichformtheedgesofthegraph.Theedgeshaveavarietyofassociated
information,suchasdistance,numberoflanes,averagespeedatdifferenttimesofthe
day,andsoon.
8.4.2 Design Databases
Computer-aided-design(CAD)systemstraditionallystoreddatainmemoryduringedit-
ingorotherprocessingandwrotethedatabacktoafileattheendofasessionofediting.
Thedrawbacksofsuchaschemeincludethecost(programmingcomplexity,aswellas
time cost) of transforming data from one form to anotherand the need to read in an
entirefileevenifonlypartsofitarerequired.Forlargedesigns,suchasthedesignof
alarge-scaleintegratedcircuitorthedesignofanentireairplane,itmaybeimpossible
to hold the complete design in memory. Designers of object-oriented databases were
motivatedinlargepartbythedatabaserequirementsofCADsystems.Object-oriented
databasesrepresentcomponentsofthedesignasobjects,andtheconnectionsbetween
theobjectsindicatehowthedesignisstructured.
The objects stored in a design database are generally geometric objects. Simple
two-dimensional geometric objects include points, lines, triangles, rectangles, and, in
general, polygons. Complex two-dimensional objects can be formed from simple ob-
jects by means of union, intersection, and difference operations. Similarly, complex
three-dimensionalobjectsmaybe formedfromsimplerobjectssuchas spheres,cylin-
ders, and cuboids by union, intersection, and difference operations, as in Figure 8.6.
Three-dimensionalsurfacesmayalsoberepresentedbywireframemodels,whichessen-
tiallymodelthesurfaceasasetofsimplerobjects,suchaslinesegments,triangles,and
rectangles.
Designdatabasesalsostorenonspatialinformationaboutobjects,suchasthema-
terialfromwhichtheobjectsareconstructed.Wecanusuallymodelsuchinformation

--- Page 420 ---

8.4 SpatialData 391
(a) Difference of cylinders (b) Union of cylinders
Figure 8.6 Complexthree-dimensionalobjects.
bystandarddata-modelingtechniques.Weconcernourselvesherewithonlythespatial
aspects.
Various spatial operations must be performed on a design. For instance, the de-
signer may want to retrieve that part of the design that corresponds to a particular
regionofinterest.Spatial-indexstructures, discussed inSection14.10.1, areuseful for
suchtasks.Spatial-indexstructuresaremultidimensional,dealingwithtwo-andthree-
dimensional data, rather than dealing with just the simple one-dimensional ordering
providedbytheB+-trees.
Spatial-integrity constraints, such as “two pipes should not be in the same loca-
tion,” are important in design databases to prevent interference errors. Such errors
often occur if the design is performed manually and are detected only when a proto-
type is being constructed. As a result, these errors can be expensive to fix. Database
support for spatial-integrity constraints helps people to avoid design errors, thereby
keeping the design consistent. Implementing such integrity checks again depends on
theavailabilityofefficientmultidimensionalindexstructures.
8.4.3 Geographic Data
Geographicdataarespatialinnaturebutdifferfromdesigndataincertainways.Maps
and satellite images are typical examples of geographic data. Maps may provide not
onlylocationinformation—aboutboundaries,rivers,androads,forexample—butalso
muchmoredetailedinformationassociatedwithlocations,suchaselevation,soiltype,
landusage,andannualrainfall.
8.4.3.1 ApplicationsofGeographicData
Geographicdatabaseshaveavarietyofuses,includingonlinemapandnavigationser-
vices, which are ubiquitous today. Other applications include distribution-network in-
formationforpublic-serviceutilitiessuchastelephone,electric-power,andwater-supply

--- Page 421 ---

392 Chapter8 ComplexDataTypes
systems,andland-usageinformationforecologistsandplanners,landrecordstotrack
landownership,andmanymore.
Geographicdatabasesforpublic-utilityinformationhavebecomeveryimportantas
thenetworkofburiedcablesandpipeshasgrown.Withoutdetailedmaps,workcarried
out by one utility may damage the structure of another utility, resulting in large-scale
disruption of service. Geographic databases, coupled with accurate location-finding
systemsusingGPS helpavoidsuchproblems.
8.4.3.2 RepresentationofGeographicData
Geographicdatacanbecategorizedintotwotypes:
• Raster data. Such data consist of bitmaps or pixel maps, in two or more dimen-
sions. A typical example of a two-dimensionalraster image is a satellite image of
anarea.Inadditiontotheactualimage,thedataincludethelocationoftheimage,
specified, for example, by the latitude and longitude of its corners, and the reso-
lution, specified either by the total number of pixels, or, more commonly in the
contextofgeographicdata,bytheareacoveredbyeachpixel.
Raster data are often represented as tiles, each covering a fixed-size area. A
larger area can be displayed by displaying all the tiles that overlap with the area.
Toallowthedisplayofdataatdifferentzoomlevels,aseparatesetoftilesiscreated
for each zoom level. Once the zoom level is set by the user interface (e.g., a web
browser),tilesatthespecifiedzoomlevelthatoverlaptheareabeingdisplayedare
retrievedanddisplayed.
Raster data can be three-dimensional—forexample, the temperature at differ-
entaltitudesatdifferentregions,againmeasuredwiththehelpofasatellite.Time
could form another dimension—for example, the surface temperature measure-
mentsatdifferentpointsintime.
• Vector data. Vector data are constructed from basic geometric objects, such as
points,linesegments,polylines,triangles,andotherpolygonsintwodimensions,
and cylinders, spheres, cuboids, and other polyhedrons in three dimensions. In
thecontextofgeographicdata,pointsareusuallyrepresentedbylatitudeandlon-
gitude,andwheretheheightisrelevant,additionallybyelevation.
Mapdataareoftenrepresentedinvectorformat.Roadsareoftenrepresentedas
polylines.Geographicfeatures,suchaslargelakes,orevenpoliticalfeaturessuch
asstatesandcountries,arerepresentedascomplexpolygons.Somefeatures,such
as rivers, may be represented either as complex curves or as complex polygons,
dependingonwhethertheirwidthisrelevant.
Geographic information related to regions, such as annual rainfall, can be repre-
sentedasanarray—thatis,inrasterform.Forspaceefficiency,thearraycanbestored
inacompressedform.InSection24.4.1,westudyanalternativerepresentationofsuch
arraysbyadatastructurecalledaquadtree.

--- Page 422 ---

8.4 SpatialData 393
Asanotheralternative,wecanrepresentregioninformationinvectorform,using
polygons,whereeachpolygonisaregionwithinwhichthearrayvalueisthesame.The
vectorrepresentationismorecompactthantherasterrepresentationinsomeapplica-
tions.Itisalsomoreaccurateforsometasks, suchasdepictingroads,wheredividing
theregionintopixels(whichmaybefairlylarge)leadstoalossofprecisioninlocation
information. However, the vector representation is unsuitable for applications where
thedataareintrinsicallyrasterbased,suchassatelliteimages.
Topographicalinformation,thatisinformationabouttheelevation(height)ofeach
pointonasurface,canberepresentedinrasterform.Alternatively,itcanberepresented
invectorformbydividingthesurfaceintopolygonscoveringregionsof(approximately)
equalelevation,withasingleelevationvalueassociatedwitheachpolygon.Asanother
alternative, the surface can be triangulated (i.e., divided into triangles), with each tri-
angle represented by the latitude, longitude, and elevation of each of its corners. The
latterrepresentation,calledthetriangulatedirregularnetwork(TIN)representation,is
acompactrepresentationwhichisparticularlyusefulforgeneratingthree-dimensional
viewsofanarea.
Geographicinformationsystems usuallycontainbothrasterandvectordata,and
they can merge the two kinds of data when displaying results to users. For example,
map applications usually contain both satellite images and vector data about roads,
buildings,andotherlandmarks.Amapdisplayusuallyoverlaysdifferentkindsofinfor-
mation;forexample,roadinformationcanbeoverlaidonabackgroundsatelliteimage
tocreateahybriddisplay.Infact,amaptypicallyconsistsofmultiplelayers,whichare
displayed in bottom-to-top order; data from higher layers appear on top of data from
lowerlayers.
Itisalsointerestingtonotethateveninformationthatisactuallystoredinvector
formmaybeconvertedtorasterformbeforeitissenttoauserinterfacesuchasaweb
browser.OnereasonisthatevenwebbrowsersinwhichJavaScripthasbeendisabled
canthendisplaymapdata;asecondreasonmaybetopreventendusersfromextracting
andusingthevectordata.
MapservicessuchasGoogleMapsandBingMapsprovideAPIsthatallowusersto
createspecializedmapdisplays,containingapplication-specificdataoverlaidontopof
standardmapdata.Forexample,awebsitemayshowamapofanareawithinformation
about restaurants overlaid on the map. The overlays can be constructed dynamically,
displaying only restaurants with a specific cuisine, for example, or allowing users to
changethezoomlevelorpanthedisplay.
8.4.4 Spatial Queries
Thereareanumberoftypesofqueriesthatinvolvespatiallocations.
• Region queriesdealwithspatial regions.Suchaquerycanaskforobjectsthatlie
partiallyorfullyinsideaspecifiedregion.Aquerytofindallretailshopswithinthe
geographicboundariesofagiventownisanexample.PostGISsupportspredicates
betweentwogeometryorgeographyobjectssuchasST Contains(),ST Overlaps(),

--- Page 423 ---

394 Chapter8 ComplexDataTypes
ST Disjoint() and ST Touches(). These can be used to find objects that are con-
tainedin,orintersect,oraredisjointfromaregion.SQLServersupportsequivalent
functionswithslightlydifferentnames.
Suppose we have a shop relation, with an attribute location of type point, and a
geographyobjectoftypepolygon.ThentheST Contains()functioncanbeusedto
retrieveallshopswhoselocationiscontainedinthegivenpolygon.
• Nearnessqueriesrequestobjectsthatlienearaspecifiedlocation.Aquerytofind
all restaurants thatliewithina given distance of a given point isan example of a
nearness query. The nearest-neighbor query requests the object that is nearest to
a specified point. For example, we may want to find the nearest gasoline station.
Note that this query does not have to specify a limit on the distance, and hence
wecanaskitevenifwehavenoideahowfarthenearestgasolinestationlies.
ThePostGISST Distance()functiongivestheminimumdistancebetweentwosuch
objects,andcanbeusedtofindobjectsthatarewithinaspecifieddistancefroma
pointorregion.Nearestneighborscanbefoundbyfindingobjectswithminimum
distance.
• Spatial graph queries request information based on spatial graphs such as road
maps. Forexample, aquery may ask for the shortest path between twolocations
viatheroadnetwork,orviaatrainnetwork,eachofwhichcanberepresentedas
aspatialgraph.Suchqueriesareubiquitousfornavigationsystems.
Queriesthatcomputeintersectionsofregionscanbethoughtofascomputingthe
spatialjoinoftwospatialrelations—forexample,onerepresentingrainfallandtheother
representingpopulationdensity—withthelocationplayingtheroleofjoinattribute.In
general,giventworelations,eachcontainingspatialobjects,thespatialjoinofthetwo
relations generates either pairs of objects that intersect or the intersection regions of
such pairs. Spatial predicates such as ST Contains() or ST Overlaps() can be used as
joinpredicateswhenperformingspatialjoins.
Ingeneral,queriesonspatialdatamayhaveacombinationofspatialandnonspa-
tial requirements. For instance, we may want to find the nearest restaurant that has
vegetarianselectionsandthatchargeslessthan$10forameal.
8.5 Summary
• There are many application domains that need to store more complex data than
simpletableswithafixednumberofattributes.
• The SQL standard includes extensions of the SQL data-definition and query lan-
guagetodealwithnewdatatypesandwithobjectorientation.Theseincludesup-
portforcollection-valuedattributes,inheritance,andtuplereferences.Suchexten-
sionsattempttopreservetherelationalfoundations—inparticular,thedeclarative
accesstodata—whileextendingthemodelingpower.

--- Page 424 ---

8.5 Summary 395
• Semi-structured data are characterized by complex data, whose schema changes
often.
• A popular architecture for building information systems today is to create a web
servicethatallowsretrievalofdataandtobuildapplicationcodethatdisplaysthe
dataandallowsuserinteraction.
• Therelationaldatamodelhasbeenextendedinseveralwaystosupportthestorage
anddataexchangeneedsofmodernapplications.
° Some database systems allow each tuple to potentially have a different set of
attributes.
° Manydatarepresentationsallowattributestonon-atomicvalues.
° Manydatarepresentationsallowattributestobestructured,directlymodeling
compositeattributesintheE-Rmodel.
• TheJavaScriptObjectNotation(JSON)isatextualrepresentationofcomplexdata
typeswhichiswidelyusedfortransmittingdatabetweenapplicationsandforstor-
ingcomplexdata.
• XML representations provide flexibility in the set of attributes that a record con-
tainsaswellasthetypesoftheseattributes.
• The Resource Description Framework (RDF) is a data representation standard
based on the entity-relationship model. The RDF representation has a very nat-
ural graph interpretation. Entities and attribute values can be considered nodes,
andattributenamesandrelationshipscanbeconsiderededgesbetweenthenodes.
• SPARQL is a query language designed to query RDF data and is based on triple
patterns.
• Object orientation provides inheritance with subtypes and subtables as well as
object(tuple)references.
• Theobject-relationaldatamodelextendstherelationaldatamodelbyprovidinga
richertypesystem,includingcollectiontypesandobjectorientation.
• Object-relational database systems (i.e., database systems based on the object-
relational model) provide a convenient migration path for users of relational
databaseswhowishtouseobject-orientedfeatures.
• Object-relational mapping systems provide an object view of data that are stored
inarelationaldatabase.Objectsaretransient,andthereisnonotionofpersistent
objectidentity.Objectsarecreatedondemandfromrelationaldata,andupdatesto
objectsareimplementedbyupdatingtherelationaldata.Object-relationalmapping
systemshavebeenwidelyadopted,unlikethemorelimitedadoptionofpersistent
programminglanguages.

--- Page 425 ---

396 Chapter8 ComplexDataTypes
• Information-retrievalsystemsareusedtostoreandquerytextualdatasuchasdoc-
uments.Theyuseasimplerdatamodelthandodatabasesystemsbutprovidemore
powerfulqueryingcapabilitieswithintherestrictedmodel.
• Queriesattempttolocatedocumentsthatareofinterestbyspecifying,forexample,
setsofkeywords. Thequerythatauserhasinmindusuallycannotbestated pre-
cisely;hence,information-retrievalsystemsorderanswersonthebasisofpotential
relevance.
• Relevancerankingmakesuseofseveraltypesofinformation,suchas:
° Termfrequency:howimportanteachtermistoeachdocument.
° Inversedocumentfrequency.
° Popularityranking.
• Spatialdatamanagementisimportantformanyapplications.Geometricandgeo-
graphicdatatypesaresupportedbymanydatabasesystems,withsubtypesinclud-
ingpoints,linestringsandpolygons.Regionqueries,nearestneighborqueries,and
spatialgraphqueriesareamongthecommonlyusedtypesofspatialqueries.
Review Terms
• Widecolumn • Object-orienteddatabasesystem
• Sparsecolumn • Pathexpression
• Key-valuemap • Keywords
• Map • Keywordquery
• Arraydatabase • Term
• Tags • Relevance
• Triples • TF–IDF
• Resources • Stopwords
• Subject • Proximity
• Predicate • PageRank
• Object • Precision
• Knowledgegraph • Recall
• Reification • Geographicdata
• Quads • Geometricdata
• Linkedopendata • Geographicinformationsystem
• Object-relationaldatamodel • Computer-aided-design(CAD)
• Object-relationaldatabasesystem • Polyline
• Object-relationalmapping • Linestring

--- Page 426 ---

PracticeExercises 397
• Triangulation • Triangulatedirregularnetwork(TIN)
• Spatialnetwork • Overlays
• Spatialgraph • Nearnessqueries
• Rasterdata • Nearest-neighborquery
• Tiles • Regionqueries
• Vectordata • Spatialgraphqueries
• Topographicalinformation • Spatialjoin
Practice Exercises
8.1 Provide information about the student named Shankar in our sample univer-
sity database, including information from the student tuple corresponding to
Shankar, the takes tuples corresponding to Shankar and the course tuples cor-
respondingtothesetakestuples,ineachofthefollowingrepresentations:
a. UsingJSON,withanappropriatenestedrepresentation.
b. UsingXML,withthesamenestedrepresentation.
c. UsingRDFtriples.
d. AsanRDFgraph.
8.2 ConsidertheRDFrepresentationofinformationfromtheuniversityschemaas
showninFigure8.3.WritethefollowingqueriesinSPARQL.
a. FindthetitlesofallcoursestakenbyanystudentnamedZhang.
b. FindtitlesofallcoursessuchthatastudentnamedZhangtakesasection
ofthecoursethatistaughtbyaninstructornamedSrinivasan.
c. Find the attribute names and values of all attributes of the instruc-
tor named Srinivasan, without enumerating the attribute names in your
query.
8.3 A car-rental company maintains a database for all vehicles in its current fleet.
For all vehicles, it includes the vehicle identification number, license number,
manufacturer,model,dateofpurchase,andcolor.Specialdataareincludedfor
certaintypesofvehicles:
• Trucks:cargocapacity.
• Sportscars:horsepower,renteragerequirement.
• Vans:numberofpassengers.
• Off-roadvehicles:groundclearance,drivetrain(four-ortwo-wheeldrive).

--- Page 427 ---

398 Chapter8 ComplexDataTypes
instructor
ID
name
first_name
middle_inital
last_name
address
street
street_number
street_name
apt_number
city
state
zip
{phone_number}
date_of_birth
age ( )
Figure 8.7 E-Rdiagramwithcomposite,multivalued,andderivedattributes.
Construct an SQL schema definition for this database. Use inheritance where
appropriate.
8.4 ConsideradatabaseschemawitharelationEmpwhoseattributesareasshown
below,withtypesspecifiedformultivaluedattributes.
Emp=(ename,ChildrenSetmultiset(Children),SkillSetmultiset(Skills))
Children=(name,birthday)
Skills=(type,ExamSetsetof(Exams))
Exams=(year,city)
Define the above schemain SQL,using the SQLServertable type syntax from
Section8.2.1.1todeclaremultisetattributes.
8.5 Consider the E-R diagram in Figure 8.7 showing entity set instructor.
Give an SQL schema definition corresponding to the E-R diagram, treating
phone number asanarrayof10elements,usingOracleorPostgreSQLsyntax.
8.6 ConsidertherelationalschemashowninFigure8.8.
a. GiveaschemadefinitioninSQLcorrespondingtotherelationalschema
butusingreferencestoexpressforeign-keyrelationships.
b. Writeeachofthefollowingqueriesontheschema,usingSQL.
i. Findthecompanywiththemostemployees.

--- Page 428 ---

Exercises 399
employee(person name,street,city)
works(person name,company name,salary)
company(company name,city)
manages(person name,manager name)
Figure 8.8 RelationaldatabaseforExercise8.6.
ii. Findthecompanywiththesmallestpayroll.
iii. Findthosecompanieswhoseemployeesearnahighersalary,onaver-
age,thantheaveragesalaryatFirstBankCorporation.
8.7 Compute the relevance (using appropriate definitions of term frequency and
inverse document frequency) of each of the Practice Exercises in this chapter
tothequery“SQLrelation”.
8.8 ShowhowtorepresentthematricesusedforcomputingPageRankasrelations.
Then write an SQL query that implements one iterative step of the iterative
techniqueforfindingPageRank;theentirealgorithmcanthenbeimplemented
asaloopcontainingthequery.
8.9 Supposethestudentrelationhasanattributenamedlocationoftypepoint,and
the classroom relation has an attribute location of type polygon. Write the fol-
lowing queries in SQL using the PostGIS spatial functions and predicates that
wesawearlier:
a. Find the names of all students whose location is within the classroom
Packard101.
b. Findallclassroomsthatarewithin100metersorPackard101;assumeall
distancesarerepresentedinunitsofmeters.
c. Find the ID and name of student who is geographically nearest to the
studentwithID12345.
d. Find the ID and names of all pairs of students whose locations are less
than200metersapart.
Exercises
8.10 RedesignthedatabaseofExercise8.4intofirstnormalformandfourthnormal
form. List any functional or multivalued dependencies that you assume. Also
list all referential-integrity constraints that should be present in the first and
fourthnormalformschemas.

--- Page 429 ---

400 Chapter8 ComplexDataTypes
person
ID
name
address
employee student
salary tot_credits
instructor secretary
rank hours_per_week
Figure 8.9 Specializationandgeneralization.
8.11 Considertheschemasforthetablepeople,andthetablesstudentsandteachers,
whichwerecreatedunderpeople,inSection8.2.1.3.Givearelationalschemain
thirdnormalformthatrepresentsthesameinformation.Recalltheconstraints
on subtables, and give all constraints that must be imposed on the relational
schema so that every database instance of the relational schema can also be
representedbyaninstanceoftheschemawithinheritance.
8.12 Consider the E-R diagram in Figure 8.9, which contains specializations, using
subtypesandsubtables.
a. GiveanSQLschemadefinitionoftheE-Rdiagram.
b. GiveanSQLquerytofindthenamesofallpeoplewhoarenotsecretaries.
c. GiveanSQLquerytoprintthenamesofpeoplewhoareneitheremploy-
eesnorstudents.
d. Can you create a person who is an employee and a student with the
schemayoucreated?Explainhow,orexplainwhyitisnotpossible.
8.13 Supposeyouwishtoperformkeywordqueryingonasetoftuplesinadatabase,
where each tuple has only a few attributes, each containing only a few words.
Does the concept of term frequency make sense in this context? And that of
inverse document frequency? Explain your answer. Also suggest how you can
definethesimilarityoftwotuplesusingTF–IDFconcepts.
8.14 Websitesthatwanttogetsomepublicitycanjoinawebring,wheretheycreate
linkstoothersitesintheringinexchangeforothersitesintheringcreatinglinks

--- Page 430 ---

FurtherReading 401
to theirsite. What isthe effectof such rings on popularity ranking techniques
suchasPageRank?
8.15 TheGooglesearchengineprovidesafeaturewherebywebsitescandisplayad-
vertisementssuppliedbyGoogle.Theadvertisementssuppliedarebasedonthe
contentsofthepage.SuggesthowGooglemightchoosewhichadvertisements
tosupplyforapage,giventhepagecontents.
Further Reading
A tutorial on JSON can be found at www.w3schools.com/js/js json intro.asp. More
information about XML can be found in Chapter 30, available online. More informa-
tion about RDF can be found at www.w3.org/RDF/. Apache Jena provides an RDF
implementation, with support for SPARQL; a tutorial on SPARQL can be found at
jena.apache.org/tutorials/sparql.html
POSTGRES ([Stonebraker and Rowe (1986)] and [Stonebraker (1986)]) was an
earlyimplementationofanobject-relationalsystem.Oracleprovidesafairlycomplete
implementation of the object-relational features of SQL, whilePostgreSQL provides a
smaller subset of those features. More information on support for these features may
befoundintheirrespectivemanuals.
[Salton(1989)]isanearlytextbookoninformation-retrievalsystems,while[Man-
ning et al. (2008)] is a modern textbook on the subject. Information about spatial
databasesupportinOracle,PostgreSQL andSQLServermaybefoundintheirrespec-
tivemanualsonline.
Bibliography
[Manningetal.(2008)] C.D.Manning,P.Raghavan,andH.Sch¨utze,IntroductiontoInfor-
mationRetrieval,CambridgeUniversityPress(2008).
[Salton(1989)] G.Salton,AutomaticTextProcessing,AddisonWesley(1989).
[Stonebraker(1986)] M.Stonebraker,“InclusionofNewTypesinRelationalDatabaseSys-
tems”,InProc.oftheInternationalConf.onDataEngineering(1986),pages262–269.
[StonebrakerandRowe(1986)] M.StonebrakerandL.Rowe,“TheDesignofPOSTGRES”,
InProc.oftheACMSIGMODConf.onManagementofData(1986),pages340–355.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock

--- Page 432 ---

9
CHAPTER
Application Development
Practicallyalluseofdatabasesoccursfromwithinapplicationprograms.Correspond-
ingly, almost all user interaction with databases is indirect,via application programs.
In this chapter, we study tools and technologies that are used to build applications,
focusingoninteractiveapplicationsthatusedatabasestostoreandretrievedata.
A key requirement for any user-centric application is a good user interface. The
twomostcommontypesofuserinterfacestodayfordatabase-backedapplicationsare
thewebandmobileappinterfaces.
In the initial part of this chapter, we provide an introduction to application pro-
gramsanduserinterfaces(Section9.1),andtowebtechnologies(Section9.2).Wethen
discussdevelopmentofwebapplicationsusingthewidelyusedJavaServletstechnology
at the back end (Section 9.3), and using other frameworks (Section 9.4). Client-side
codeimplementedusingJavaScriptormobileapptechnologiesiscrucialforbuilding
responsiveuserinterfaces,andwediscusssomeofthesetechnologies(Section9.5).We
thenprovideanoverviewofwebapplicationarchitectures(Section9.6)andcoverper-
formance issues in building large web applications (Section 9.7). Finally, we discuss
issues in application security that are key to making applications resilient to attacks
(Section9.8),andencryptionanditsuseinapplications(Section9.9).
9.1 Application Programs and User Interfaces
Although many people interact with databases, very few people use a query language
to interact with a database system directly. The most common way in which users
interactwithdatabasesisthroughanapplicationprogramthatprovidesauserinterface
atthefrontendandinterfaceswithadatabaseatthebackend.Suchapplicationstake
inputfromusers,typicallythroughaforms-basedinterface,andeitherenterdatainto
a database or extract information from a database based on the user input, and they
thengenerateoutput,whichisdisplayedtotheuser.
As an example of an application, consider a university registration system. Like
othersuchapplications,theregistrationsystemfirstrequiresyoutoidentifyandauthen-
ticateyourself,typicallybyausernameandpassword.Theapplicationthenusesyour
403

--- Page 433 ---

404 Chapter9 ApplicationDevelopment
identitytoextractinformation,suchasyournameandthecoursesforwhichyouhave
registered,fromthedatabaseanddisplaystheinformation.Theapplicationprovidesa
numberofinterfacesthatletyouregisterforcoursesandqueryotherinformation,such
ascourseandinstructorinformation.Organizationsusesuchapplicationstoautomate
a variety of tasks, such as sales, purchases, accounting and payroll, human-resources
management,andinventorymanagement,amongmanyothers.
Applicationprogramsmaybeusedevenwhenitisnotapparentthattheyarebeing
used.Forexample,anewssitemayprovideapagethatistransparentlycustomizedto
individualusers,eveniftheuserdoesnotexplicitlyfillanyformswheninteractingwith
thesite.Todoso,itactuallyrunsanapplicationprogramthatgeneratesacustomized
pageforeachuser;customizationcan,forexample,bebasedonthehistoryofarticles
browsedbytheuser.
A typical application program includes a front-end component, which deals with
the user interface, a backend component, which communicates with a database, and
a middle layer, which contains “business logic,” that is, code that executes specific
requests for information or updates, enforcing rules of business such as what actions
shouldbecarriedouttoexecuteagiventaskorwhocancarryoutwhattask.
Applications such as airline reservations have been around since the 1960s. In
the early days of computer applications, applications ran on large “mainframe” com-
puters, and users interacted with the application through terminals, some of which
evensupportedforms.Thegrowthofpersonalcomputersresultedinthedevelopment
of database applications with graphical user interfaces, or GUIs. These interfaces de-
pended on code running on a personal computer that directly communicated with
a shared database. Such an architecture was called a client–server architecture. There
weretwodrawbackstousingsuchapplications:first,usermachineshaddirectaccess
to databases, leading to security risks. Second, any change to the application or the
databaserequiredallthecopiesoftheapplication,locatedonindividualcomputers,to
beupdatedtogether.
Twoapproacheshaveevolvedtoavoidtheaboveproblems:
• Web browsers provide a universal front end, used by all kinds of information
services. Browsers use a standardized syntax, the HyperText Markup Language
(HTML)standard,whichsupportsbothformatteddisplayofinformationandcre-
ationofforms-basedinterfaces.TheHTMLstandardisindependentoftheoperat-
ingsystem orbrowser,andprettymucheverycomputer todayhasawebbrowser
installed. Thus a web-based application can be accessed from any computer that
isconnectedtotheinternet.
Unlike client–server architectures, there is no need to install any application-
specificsoftwareonclientmachinesinordertouseweb-basedapplications.
However, sophisticated user interfaces, supporting features well beyond what
ispossibleusingplainHTML,arenowwidelyused,andarebuiltwiththescripting
language JavaScript, which is supported by most web browsers. JavaScript pro-
grams, unlike programs written in C, can be run in a safe mode, guaranteeing

--- Page 434 ---

9.2 WebFundamentals 405
theycannotcausesecurityproblems.JavaScriptprogramsaredownloadedtrans-
parently to the browser and do not need any explicit software installation on the
user’scomputer.
Whilethewebbrowserprovidesthefrontendforuserinteraction,application
programsconstitutethebackend.Typically,requestsfromabrowseraresenttoa
webserver,whichinturnexecutesanapplicationprogramtoprocesstherequest.
Avarietyoftechnologiesareavailableforcreatingapplicationprogramsthatrun
at the back end, including Java servlets, Java Server Pages (JSP), Active Server
Page(ASP),orscriptinglanguagessuchasPHPandPython.
• Applicationprogramsareinstalledonindividualdevices,whichareprimarilymo-
biledevices.TheycommunicatewithbackendapplicationsthroughanAPIanddo
nothavedirectaccesstothedatabase.Thebackendapplicationprovidesservices,
includinguserauthentication,andensuresthatuserscanonlyaccessservicesthat
theyareauthorizedtoaccess.
This approach is widely used in mobile applications. One of the motivations
forbuildingsuchapplicationswastocustomizethedisplayforthesmallscreenof
mobile devices. A second was to allow application code, which can be relatively
large,tobedownloadedorupdatedwhenthedeviceisconnectedtoahigh-speed
network,insteadofdownloadingsuchcodewhenawebpageisaccessed,perhaps
overalowerbandwidthormoreexpensivemobilenetwork.
WiththeincreasinguseofJavaScriptcodeaspartofwebfrontends,thedifference
between the two approaches above has today significantly decreased. The back end
often providesan APIthatcan be invoked from eithermobileapp orJavaScriptcode
tocarryoutanyrequiredtaskatthebackend.Infact,thesamebackendisoftenused
tobuildmultiplefrontends,whichcouldincludewebfrontendswithJavaScript,and
multiplemobileplatforms(primarilyAndroidandiOS,today).
9.2 Web Fundamentals
Inthissection,wereviewsomeofthefundamentaltechnologybehindtheWorldWide
Web,forreaderswhoarenotfamiliarwiththetechnologyunderlyingtheweb.
9.2.1 Uniform Resource Locators
A uniform resource locator (URL) is a globally unique name for each document that
canbeaccessedontheweb.AnexampleofaURLis:
http://www.acm.org/sigmod
ThefirstpartoftheURLindicateshowthedocumentistobeaccessed:“http”indi-
catesthatthedocumentistobeaccessedbytheHyperTextTransferProtocol(HTTP),

--- Page 435 ---

406 Chapter9 ApplicationDevelopment
<html>
<body>
<table border>
<tr> <th>ID</th> <th>Name</th> <th>Department</th></tr>
<tr> <td>00128</td> <td>Zhang</td> <td>Comp. Sci.</td> </tr>
<tr> <td>12345</td> <td>Shankar</td> <td>Comp. Sci.</td> </tr>
<tr> <td>19991</td> <td>Brandt</td> <td>History</td> </tr>
</table>
</body>
</html>
Figure 9.1 TabulardatainHTML format.
whichisaprotocolfortransferringHTMLdocuments;“https”wouldindicatethatthe
secure version of the HTTP protocol must be used, and is the preferred mode today.
Thesecondpartgivesthenameofamachinethathasawebserver.TherestoftheURL
is the path name of the file on the machine,or other unique identifier of adocument
withinthemachine.
AURLcancontaintheidentifierofaprogramlocatedonthewebservermachine,
aswellasargumentstobegiventotheprogram.AnexampleofsuchaURLis
https://www.google.com/search?q=silberschatz
whichsaysthattheprogramsearchontheserverwww.google.comshouldbeexecuted
with the argument q=silberschatz. On receiving a request for such a URL, the web
serverexecutestheprogram,usingthegivenarguments.TheprogramreturnsanHTML
documenttothewebserver,whichsendsitbacktothefrontend.
9.2.2 HyperText Markup Language
Figure9.1isanexample ofatable representedintheHTMLformat,whileFigure9.2
shows the displayed image generated by a browser from the HTML representation of
thetable.TheHTMLsourceshowsafewoftheHTMLtags.EveryHTMLpageshould
beenclosedinanhtmltag,whilethebodyofthepageisenclosedinabodytag.Atable
ID Name Department
00128 Zhang Comp. Sci.
12345 Shankar Comp. Sci.
19991 Brandt History
Figure 9.2 DisplayofHTMLsourcefromFigure9.1.

--- Page 436 ---

9.2 WebFundamentals 407
<html>
<body>
<form action="PersonQuery" method=get>
Search for:
<select name="persontype">
<option value="student" selected>Student </option>
<option value="instructor"> Instructor </option>
</select> <br>
Name: <input type=text size=20 name="name">
<input type=submit value="submit">
</form>
</body>
</html>
Figure 9.3 AnHTML form.
isspecifiedbyatabletag,whichcontainsrowsspecifiedbyatrtag.Theheaderrowof
thetablehastablecellsspecifiedbyathtag,whileregularrowshavetablecellsspecified
byatdtag.Wedonotgointomoredetailsaboutthetagshere;seethebibliographical
notesforreferencescontainingmoredetaileddescriptionsofHTML.
Figure 9.3 shows how to specify an HTML form that allows users to select the
persontype (studentorinstructor) fromamenuandtoinputanumberinatextbox.
Figure 9.4 shows how the above form is displayed in a web browser. Two methods
of accepting input are illustrated in the form, but HTML also supports several other
input methods. The action attribute of the form tag specifies that when the form is
submitted(byclickingonthesubmitbutton),theformdatashouldbesenttotheURL
PersonQuery (the URL is relative to that of the page). The web server is configured
suchthatwhenthisURLisaccessed,acorrespondingapplicationprogramisinvoked,
with the user-provided values for the arguments persontype and name (specified in
theselectandinput fields).Theapplicationprogramgenerates an HTMLdocument,
whichisthensentbackand displayedtotheuser;weshallsee howtoconstructsuch
programslaterinthischapter.
HTTPdefinestwowaysinwhichvaluesenteredbyauseratthebrowsercanbesent
tothewebserver.ThegetmethodencodesthevaluesaspartoftheURL.Forexample,
iftheGooglesearchpageusedaformwithaninputparameternamedqwiththeget
Search for: Student
Name:
submit
Figure 9.4 DisplayofHTML sourcefromFigure9.3.

--- Page 437 ---

408 Chapter9 ApplicationDevelopment
method, and the user typed in the string “silberschatz” and submitted the form, the
browserwouldrequestthefollowingURLfromthewebserver:
https://www.google.com/search?q=silberschatz
ThepostmethodwouldinsteadsendarequestfortheURLhttps://www.google.com,
andsendtheparametervaluesaspartoftheHTTPprotocolexchangebetweentheweb
server and the browser. The form in Figure 9.3 specifies that the form uses the get
method.
AlthoughHTMLcodecanbecreatedusingaplaintexteditor,thereareanumber
ofeditorsthatpermitdirectcreationofHTMLtextbyusingagraphicalinterface.Such
editorsallowconstructssuchasforms,menus,andtablestobeinsertedintotheHTML
documentfromamenuofchoices,insteadofmanuallytypinginthecodetogenerate
theconstructs.
HTMLsupportsstylesheets,whichcanalterthedefaultdefinitionsofhowanHTML
formattingconstructisdisplayed,aswellasotherdisplayattributessuchasbackground
colorofthepage.Thecascadingstylesheet(CSS)standardallowsthesamestylesheetto
beusedformultipleHTMLdocuments,givingadistinctivebutuniformlooktoallthe
pagesonawebsite.Youcanfindmoreinformationonstylesheetsonline,forexample
atwww.w3schools.com/css/.
TheHTML5standard,whichwasreleasedin2014,providesawidevarietyofform
inputtypes,includingthefollowing:
• Date and time selection, using <input type="date" name="abc">, and <input
type="time" name="xyz">.Browserswouldtypicallydisplayagraphicaldateor
timepickerforsuch an inputfield;the inputvalue issaved inthe form attributes
abcandxyz.Theoptionalattributesminandmaxcanbeusedtospecifyminimum
andmaximumvaluesthatcanbechosen.
• Fileselection,using<input type="file", name="xyz">, whichallowsafile tobe
chosen,anditsnamesavedintheformattributexyz.
• Input restrictions (constraints) on a variety of input types, including minimum,
maximum,formatmatchingaregularexpression,andsoon.Forexample,
<inputtype="number"name="start"min="0"max="55"step="5"value="0">
allowstheusertochooseoneof0,5,10,15,andsoontill55,withadefaultvalue
of0.
9.2.3 Web Servers and Sessions
A web server is a program running on the server machine that accepts requests from
a web browser and sends back results in the form of HTML documents. The browser
andwebservercommunicateviaHTTP.Webserversprovidepowerfulfeatures,beyond
thesimpletransferofdocuments.Themostimportantfeatureistheabilitytoexecute

--- Page 438 ---

9.2 WebFundamentals 409
web server
network
application server
database server
HTTP
browser data
server
Figure 9.5 Three-layerwebapplicationarchitecture.
programs, with arguments supplied by the user, and to deliver the results back as an
HTMLdocument.
Asaresult,awebservercanactasanintermediarytoprovideaccesstoavariety
of information services. A new service can be created by creating and installing an
application program that provides the service. The common gateway interface (CGI)
standard defines how the web server communicates with application programs. The
application program typically communicates with a database server, through ODBC,
JDBC,orotherprotocols,inordertogetorstoredata.
Figure9.5showsawebapplicationbuiltusingathree-layerarchitecture,withaweb
server,anapplicationserver,andadatabaseserver.Usingmultiplelevelsofserversin-
creasessystemoverhead;theCGIinterfacestartsanewprocesstoserviceeachrequest,
whichresultsinevengreateroverhead.
Mostwebapplicationstodaythereforeuseatwo-layerwebapplicationarchitecture,
wheretheweband applicationserversarecombinedintoasingleserver, asshownin
Figure 9.6. We study systems based on the two-layer architecture in more detail in
subsequentsections.
Thereisnocontinuousconnectionbetweentheclientandthewebserver;whena
webserverreceivesarequest,aconnectionistemporarilycreatedtosendtherequest
andreceivetheresponsefromthewebserver.Buttheconnectionmaythenbeclosed,
andthenextrequestcouldcomeoveranewconnection.Incontrast,whenauserlogs
ontoacomputer,orconnectstoadatabaseusingODBCorJDBC,asessioniscreated,
andsessioninformationisretainedattheserverandtheclientuntilthesessionistermi-
nated—informationsuchastheuser-identifieroftheuserandsessionoptionsthatthe
userhasset.OneimportantreasonthatHTTPisconnectionlessisthatmostcomputers
havelimitsonthenumberofsimultaneousconnectionstheycanaccommodate,andif
alargenumberofsitesonthewebopenconnectionstoasingleserver,thislimitwould
beexceeded,denyingservicetofurtherusers.Withaconnectionlessprotocol,thecon-

--- Page 439 ---

410 Chapter9 ApplicationDevelopment
network web server and
application server
database server
HTTP
browser data
server
Figure 9.6 Two-layerwebapplicationarchitecture.
nection can be broken as soon as a request is satisfied, leaving connections available
forotherrequests.1
Most web applications, however, need session information to allow meaningful
userinteraction.Forinstance,applicationstypicallyrestrictaccesstoinformation,and
thereforeneedtoauthenticateusers.Authenticationshouldbedoneoncepersession,
andfurtherinteractionsinthesessionshouldnotrequirereauthentication.
Toimplementsessionsinspiteofconnectionsgettingclosed,extrainformationhas
to be stored at the client and returned with each request in a session; the server uses
this information to identify that a request is part of a user session. Extra information
aboutthesessionalsohastobemaintainedattheserver.
Thisextra informationisusuallymaintainedintheform ofacookie attheclient;
a cookie is simply a small piece of text containing identifying information and with
anassociatedname.Forexample,google.commaysetacookiewiththenameprefs,
whichencodespreferencessetbytheusersuchasthepreferredlanguageandthenum-
ber of answers displayed per page. On each search request, google.com can retrieve
the cookie named prefs from the user’s browser, and display results according to the
specified preferences. A domain (web site) is permitted to retrieve only cookies that
it has set, not cookies set by other domains, and cookie names can be reused across
domains.
Forthepurpose oftrackingausersession, anapplicationmaygenerate asession
identifier (usually a random number not currently in use as a session identifier), and
send a cookie named (for instance) sessionid containing the session identifier. The
session identifier is also stored locally at the server. When a request comes in, the
application server requests the cookie named sessionid from the client. If the client
1Forperformancereasons,connectionsmaybekeptopenforashortwhile,toallowsubsequentrequeststoreusethe
connection.However,thereisnoguaranteethattheconnectionwillbekeptopen,andapplicationsmustbedesigned
assumingtheconnectionmaybeclosedassoonasarequestisserviced.

--- Page 440 ---

9.3 Servlets 411
doesnothave thecookie stored,orreturnsavalue thatisnotcurrentlyrecordedasa
valid session identifierat the server, the application concludes that the request is not
part of a current session. If the cookie value matches a stored session identifier, the
requestisidentifiedaspartofanongoingsession.
If an application needs to identify users securely, it can set the cookie only after
authenticatingtheuser;forexampleausermaybeauthenticatedonlywhenavaliduser
nameandpasswordaresubmitted.2
Forapplicationsthatdonotrequirehighsecurity,suchaspubliclyavailablenews
sites,cookiescanbestoredpermanentlyatthebrowserandattheserver;theyidentify
the user on subsequent visits to the same site, without any identification information
beingtypedin.Forapplicationsthatrequirehighersecurity,theservermayinvalidate
(drop)thesessionafteratime-outperiod,orwhentheuserlogsout.(Typicallyauser
logsoutbyclickingonalogoutbutton, whichsubmitsalogoutform,whoseactionis
to invalidate the current session.) Invalidating a session merely consists of dropping
thesessionidentifierfromthelistofactivesessionsattheapplicationserver.
9.3 Servlets
The Java servlet specification defines an application programming interface for com-
munication between the web/application server and the application program. The
HttpServletclassinJavaimplementstheservletAPIspecification;servletclassesused
toimplementspecificfunctionsaredefinedassubclassesofthisclass.3Oftentheword
servlet isusedtorefertoaJavaprogram(andclass)thatimplementstheservletinter-
face.Figure9.7showsaservletexample;weexplainitindetailshortly.
The code for a servlet is loaded into the web/application server when the server
is started, or when the server receives a remote HTTP request to execute a particular
servlet.Thetaskofaservletistoprocesssucharequest,whichmayinvolveaccessinga
databasetoretrievenecessaryinformation,anddynamicallygeneratinganHTMLpage
tobereturnedtotheclientbrowser.
9.3.1 A Servlet Example
Servlets are commonly used to generate dynamic responses to HTTP requests. They
canaccessinputsprovidedthroughHTMLforms,apply“businesslogic”todecidewhat
2Theuseridentifiercouldbestoredattheclientend,inacookienamed,forexample,userid.Suchcookiescanbe
usedforlow-securityapplications,suchasfreewebsitesidentifyingtheirusers.However,forapplicationsthatrequirea
higherlevelofsecurity,suchamechanismcreatesasecurityrisk:Thevalueofacookiecanbechangedatthebrowser
byamalicioususer,whocanthenmasqueradeasadifferentuser.Settingacookie(namedsessionid,forexample)to
arandomlygeneratedsessionidentifier(fromalargespaceofnumbers)makesithighlyimprobablethatausercan
masqueradeas(i.e.,pretendtobe)anotheruser.Asequentiallygeneratedsessionidentifier,ontheotherhand,would
besusceptibletomasquerading.
3Theservletinterfacecanalsosupportnon-HTTPrequests,althoughourexampleusesonlyHTTP.

--- Page 441 ---

412 Chapter9 ApplicationDevelopment
response to provide, and then generate HTML output to be sent back to the browser.
Servletcodeisexecutedonaweborapplicationserver.
Figure 9.7 shows an example of servlet code to implement the form in Fig-
ure 9.3. The servlet is called PersonQueryServlet, while the form specifies that
“action="PersonQuery".” The web/application server must be told that this servlet
is to be used to handle requests for PersonQuery, which is done by using the anno-
import java.io.*;
import javax.servlet.*;
import javax.servlet.http.*;
@WebServlet("PersonQuery")
public class PersonQueryServlet extends HttpServlet {
public void doGet(HttpServletRequestrequest,
HttpServletResponse response)
throws ServletException,IOException
{
response.setContentType("text/html");
PrintWriter out = response.getWriter();
... check if user is logged in ...
out.println("<HEAD><TITLE> Query Result</TITLE></HEAD>");
out.println("<BODY>");
String persontype = request.getParameter("persontype");
String name = request.getParameter("name");
if(persontype.equals("student")) {
... code to find students with the specified name ...
... using JDBC to communicate with the database ..
... Assume ResultSet rs has been retrieved,and
... contains attributesID, name, and department name
String headers = new String[]{"ID", "Name", "Department Name"};
Util::resultSetToHTML(rs, headers, out);
}
else {
... as above, but for instructors ...
}
out.println("</BODY>");
out.close();
}
}
Figure 9.7 Exampleofservletcode.

--- Page 442 ---

9.3 Servlets 413
tation @WebServlet("PersonQuery")shown in the code.The form specifies thatthe
HTTPget mechanismisused for transmitting parameters. So the doGet()method of
theservlet,asdefinedinthecode,isinvoked.
Each servlet request results in a new thread within which the call is executed, so
multiplerequestscanbehandledinparallel.Anyvaluesfromtheformmenusandinput
fieldsonthewebpage,aswellascookies,passthroughanobjectoftheHttpServletRe-
questclassthatiscreatedfortherequest,andthereplytotherequestpassesthrough
anobjectoftheclassHttpServletResponse.
ThedoGet()methodintheexampleextractsvaluesoftheparameterspersontype
and name by using request.getParameter(), and uses these values to run a query
against a database. The code used to access the database and to get attribute values
from the query result is not shown; refer to Section 5.1.1.5 for details of how to use
JDBC to access a database. We assume that the result of the query in the form of a
JDBCResultSetisavailableinthevariableresultset.
Theservletcodereturnstheresultsofthequerytotherequesterbyoutputtingthem
to the HttpServletResponse object response. Outputting the results to response is
implementedbyfirstgettingaPrintWriterobjectoutfromresponse,andthenprinting
thequeryresultinHTMLformattoout.Inourexample,thequeryresultisprintedby
callingthefunctionUtil::resultSetToHTML(resultset,header,out),whichisshownin
Figure9.8.ThefunctionusesJDBCmetadatafunctionontheResultSetrstofigureout
how many columns need to be printed. An array of column headers is passed to this
function to be printed out; the column names could have been obtained using JDBC
metadata,butthedatabasecolumnnamesmaynotbeappropriatefordisplaytoauser,
soweprovidemeaningfulcolumnnamestothefunction.
9.3.2 Servlet Sessions
Recallthattheinteractionbetweenabrowserandaweb/applicationserverisstateless.
Thatis,eachtimethebrowsermakesarequesttotheserver,thebrowserneedstocon-
necttotheserver,requestsomeinformation,thendisconnectfromtheserver.Cookies
can be used to recognize that a request is from the same browser session as an ear-
lierrequest. However,cookiesform alow-levelmechanism,andprogrammersrequire
abetterabstractiontodealwithsessions.
The servlet API provides a method of tracking a session and storing information
pertaining to it. Invocation of the method getSession(false) of the class HttpServle-
tRequestretrievestheHttpSessionobjectcorrespondingtothebrowserthatsentthe
request.Anargumentvalueoftruewouldhavespecifiedthatanewsessionobjectmust
becreatediftherequestisanewrequest.
WhenthegetSession()methodisinvoked,theserverfirstaskstheclienttoreturn
a cookie with a specified name. If the client does not have a cookie of that name, or
returnsavaluethatdoesnotmatchanyongoingsession,thentherequestisnotpartof
anongoingsession.Inthiscase,getSession()wouldreturnanullvalue,andtheservlet
coulddirecttheusertoaloginpage.

--- Page 443 ---

414 Chapter9 ApplicationDevelopment
import java.io.*;
import javax.servlet.*;
import javax.servlet.http.*;
public class Util{
public static void resultSetToHTML(ResultSet rs,
String headers[], PrintWriter out) {
ResultSetMetaData rsmd = rs.getMetaData();
int numCols = rsmd.getColumnCount();
out.println("<table border=1>");
out.println("<tr>");
for (int i=0; i < numCols; i++)
out.println("<th>"+ headers[i] + <∕th>
out.println("<∕tr>");
while (rs.next()){
out.println("<tr>");
for (int i=0; i < numCols; i++)
out.println("<td>"+ rs.getString(i)+ <∕td>
out.println("<∕tr>");
}
}
}
Figure 9.8 UtilityfunctiontooutputResultSetasatable.
The login page could allow the user to provide a user name and password. The
servlet corresponding to the login page could verify that the password matches the
user; for example, by using the user name to retrieve the password from the database
andcheckingifthepasswordenteredmatchesthestoredpassword.4
If the user is properly authenticated, the login servlet would execute getSes-
sion(true),whichwouldreturnanewsessionobject.Tocreateanewsession,theserver
would internally carry out the following tasks: set a cookie (called, for example, ses-
sionId) with a session identifier as its associated value at the client browser, create a
newsessionobject,andassociatethesessionidentifiervaluewiththesessionobject.
4Itisabadideatostoreunencryptedpasswordsinthedatabase,sinceanyonewithaccesstothedatabasecontents,such
asasystemadministratororahacker,couldstealthepassword.Instead,ahashingfunctionisappliedtothepassword,
andtheresultisstoredinthedatabase;evenifsomeoneseesthehashingresultstoredinthedatabase,itisveryhardto
inferwhatwastheoriginalpassword.Thesamehashingfunctionisappliedtotheuser-suppliedpassword,andtheresult
iscomparedwiththestoredhashingresult.Further,toensurethateveniftwousersusethesamepasswordthehash
valuesaredifferent,thepasswordsystemtypicallystoresadifferentrandomstring(calledthesalt)foreachuser,andit
appendstherandomstringtothepasswordbeforecomputingthehashvalue.Thus,thepasswordrelationwouldhave
theschemauserpassword(user,salt,passwordhash),wherepasswordhashisgeneratedbyhash(append(password,salt)).
EncryptionisdescribedinmoredetailinSection9.9.1.

--- Page 444 ---

9.3 Servlets 415
The servlet code can also store and look up (attribute-name, value) pairs in the
HttpSession object, to maintain state across multiple requests within a session. For
example, after the user is authenticated and the session object has been created, the
loginservletcouldstoretheuser-idoftheuserasasessionparameterbyexecutingthe
method
session.setAttribute(“userid”, userid)
onthesessionobjectreturnedbygetSession();theJavavariableuseridisassumedto
containtheuseridentifier.
Iftherequestwaspartofanongoingsession,thebrowserwouldhavereturnedthe
cookievalue,andthecorrespondingsessionobjectwouldbereturnedbygetSession().
The servlet could then retrieve session parameters such as user-id from the session
objectbyexecutingthemethod
session.getAttribute(“userid”)
on the session object returned above. If the attribute userid is not set, the function
would return a null value, which would indicate that the client user has not been au-
thenticated.
Consider the line in the servlet code in Figure 9.7 that says “... check if user is
loggedin...”.Thefollowingcodeimplementsthischeck;iftheuserisnotloggedin,it
sends an error message, and after a gap of 5 seconds, redirects the user to the login
page.
Session session = request.getSession(false);
if (session == null || session.getAttribute(userid) == null) {
out.println("You are not logged in.");
response.setHeader("Refresh","5;url=login.html");
return();
}
9.3.3 Servlet Life Cycle
Thelifecycleofaservletiscontrolledbytheweb/applicationserverinwhichtheservlet
hasbeendeployed.Whenthereisaclientrequestforaspecificservlet,theserverfirst
checks if an instance of the servlet exists or not. If not, the server loads the servlet
classintotheJavavirtualmachine(JVM)andcreatesaninstanceoftheservletclass.
Inaddition,theserver callsthe init()methodtoinitializetheservletinstance.Notice
thateachservletinstanceisinitializedonlyoncewhenitisloaded.
After making sure the servlet instance does exist, the server invokes the service
methodoftheservlet,witharequestobjectandaresponseobjectasparameters.By
default,the server createsanewthreadtoexecute the servicemethod;thus, multiple

--- Page 445 ---

416 Chapter9 ApplicationDevelopment
requestsonaservletcanexecuteinparallel,withouthavingtowaitforearlierrequests
tocompleteexecution.TheservicemethodcallsdoGetordoPostasappropriate.
When no longer required, a servlet can be shut down by calling the destroy()
method. The server can be set up to shut down a servlet automatically if no requests
have been made on a servlet within a time-out period; the time-out period is a server
parameterthatcanbesetasappropriatefortheapplication.
9.3.4 Application Servers
Manyapplicationserversprovidebuilt-insupportforservlets.Oneofthemostpopular
istheTomcatServerfrom theApacheJakartaProject.Otherapplicationserversthat
support servlets include Glassfish, JBoss, BEA Weblogic Application Server, Oracle
ApplicationServer,andIBM’sWebSphereApplicationServer.
ThebestwaytodevelopservletapplicationsisbyusinganIDEsuchasEclipseor
NetBeans,whichcomewithTomcatorGlassfishserversbuiltin.
Applicationserversusuallyprovideavarietyofusefulservices,inadditiontobasic
servlet support. They allow applications to be deployed or stopped, and they provide
functionality to monitor the status of the application server, including performance
statistics.ManyapplicationserversalsosupporttheJava2EnterpriseEdition(J2EE)
platform,whichprovidessupportandAPIsforavarietyoftasks,suchasforhandling
objects,andparallelprocessingacrossmultipleapplicationservers.
9.4 Alternative Server-Side Frameworks
ThereareseveralalternativestoJavaServletsforprocessingrequestsattheapplication
server, including scripting languages and web application frameworks developed for
languagessuchasPython.
9.4.1 Server-Side Scripting
Writing even a simple web application in a programming language such as Java or C
is a time-consuming task that requires many lines of code and programmers who are
familiar with the intricacies of the language. An alternative approach, that of server-
sidescripting,providesamucheasiermethodforcreatingmanyapplications.Scripting
languagesprovideconstructsthatcanbeembeddedwithinHTMLdocuments.
Inserver-sidescripting,beforedeliveringawebpage,theserverexecutesthescripts
embeddedwithintheHTMLcontentsofthepage.Eachpieceofscript,whenexecuted,
cangeneratetextthatisaddedtothepage(ormayevendeletecontentfromthepage).
The source code of the scripts is removed from the page, so the client may not even
beawarethatthepageoriginallyhadanycodeinit.Theexecutedscriptmayalsocon-
tainSQLcodethatisexecutedagainstadatabase.Manyoftheselanguagescomewith
libraries and tools that together constitute a framework for web application develop-
ment.

--- Page 446 ---

9.4 AlternativeServer-SideFrameworks 417
<html>
<head> <title> Hello </title> </head>
<body>
< % if (request.getParameter(“name”)== null)
{ out.println(“Hello World”); }
else { out.println(“Hello, ” + request.getParameter(“name”));}
%>
</body>
</html>
Figure 9.9 AJSPpagewithembeddedJavacode.
Some of the widely used scripting frameworks include Java Server Pages (JSP),
ASP.NETfromMicrosoft,PHP,andRubyonRails.Theseframeworksallowcodewrit-
teninlanguagessuchasJava,C#,VBScript,andRubytobeembeddedintoorinvoked
fromHTMLpages.Forinstance,JSPallowsJavacodetobeembeddedinHTMLpages,
whileMicrosoft’sASP.NETandASPsupportembeddedC#andVBScript.
9.4.1.1 JavaServerPages
Next we briefly describe Java Server Pages (JSP), a scripting language that allows
HTMLprogrammerstomixstaticHTMLwithdynamicallygeneratedHTML.Themo-
tivation is that, for many dynamic web pages, most of their content is still static (i.e.,
thesamecontentispresentwheneverthepageisgenerated).Thedynamiccontentof
the webpages (whicharegenerated, forexample, on thebasis ofform parameters) is
oftenasmallpartofthepage.Creatingsuchpagesbywritingservletcoderesultsina
largeamountofHTMLbeingcodedasJavastrings.JSPinsteadallowsJavacodetobe
embeddedinstaticHTML;theembeddedJavacodegeneratesthedynamicpartofthe
page.JSPscriptsareactuallytranslatedintoservletcodethatisthencompiled,butthe
applicationprogrammerissavedthetroubleofwritingmuchoftheJavacodetocreate
theservlet.
Figure9.9showsthesourcetextofaJSPpagethatincludesembeddedJavacode.
TheJavacodeinthescriptisdistinguishedfromthesurroundingHTMLcodebybeing
enclosedin<%…%>.Thecodeusesrequest.getParameter()togetthevalueofthe
attributename.
WhenaJSPpageisrequestedbyabrowser,theapplicationservergeneratesHTML
outputfromthepage,whichissenttothebrowser.TheHTMLpartoftheJSPpageis
outputasis.5 WhereverJavacodeisembeddedwithin<%…%>,thecodeisreplaced
intheHTMLoutputbythetextitprintstotheobjectout.IntheJSPcodeinFigure9.9,
5JSPallowsamorecomplexembedding,whereHTMLcodeiswithinaJavaif-elsestatement,andgetsoutputcondition-
allydependingonwhethertheifconditionevaluatestotrueornot.Weomitdetailshere.

--- Page 447 ---

418 Chapter9 ApplicationDevelopment
ifnovaluewasenteredfortheformparametername,thescriptprints“HelloWorld”;
ifavaluewasentered,thescriptprints“Hello”followedbythename.
Amorerealisticexample mayperformmorecomplexactions,suchaslookingup
valuesfromadatabaseusingJDBC.
JSP also supports the concept of a tag library, which allows the use of tags that
lookmuchlikeHTMLtagsbutareinterpretedattheserverandarereplacedbyappro-
priatelygeneratedHTMLcode.JSPprovidesastandardsetoftagsthatdefinevariables
and control flow (iterators, if-then-else), along with an expression language based on
JavaScript(butinterpretedattheserver).Thesetoftagsisextensible,andanumberof
taglibrarieshavebeen implemented.Forexample, thereisataglibrarythatsupports
paginateddisplayoflargedatasetsandalibrarythatsimplifiesdisplayandparsingof
datesandtimes.
9.4.1.2 PHP
PHPisascriptinglanguagethatiswidelyusedforserver-sidescripting.PHPcodecan
beintermixedwithHTMLinamannersimilartoJSP.Thecharacters“<?php”indicate
the start of PHP code, while the characters “?>” indicate the end of PHP code. The
followingcodeperformsthesameactionsastheJSPcodeinFigure9.9.
<html>
<head> <title> Hello </title> </head>
<body>
<?php if (!isset($ REQUEST['name']))
{ echo 'Hello World'; }
else { echo 'Hello, ' . $ REQUEST['name']; }
?>
</body>
</html>
The array $ REQUEST contains the request parameters. Note that the array is
indexedbytheparametername;inPHParrayscanbeindexedbyarbitrarystrings,not
justnumbers.Thefunctionissetchecksiftheelementofthearrayhasbeeninitialized.
TheechofunctionprintsitsargumenttotheoutputHTML.Theoperator“.”between
twostringsconcatenatesthestrings.
A suitably configured web server would interpret any file whose name ends in
“.php”tobeaPHPfile.Ifthefileisrequested,thewebserverprocessesitinamanner
similartohowJSPfilesareprocessedandreturnsthegeneratedHTMLtothebrowser.
A number of libraries are available for the PHP language, including libraries for
databaseaccessusingODBC(similartoJDBCinJava).
9.4.2 Web Application Frameworks
Web application development frameworks ease the task of constructing web applica-
tionsbyprovidingfeaturessuchasthese:

--- Page 448 ---

9.4 AlternativeServer-SideFrameworks 419
• AlibraryoffunctionstosupportHTMLandHTTPfeatures,includingsessions.
• Atemplatescriptingsystem.
• Acontrollerthatmapsuserinteractioneventssuchasformsubmitstoappropriate
functions that handle the event. The controller also manages authentication and
sessions.Someframeworksalsoprovidetoolsformanagingauthorizations.
• A (relatively) declarative way of specifying a form with validation constraints on
userinputs,fromwhichthesystem generatesHTMLandJavascript/Ajaxcodeto
implementtheform.
• An object-oriented model withan object-relationalmapping to store datain a re-
lationaldatabase(describedinSection9.6.2).
Thus, these frameworks provide a variety of features that are required to build web
applications in an integrated manner. By generating forms from declarative specifica-
tions and managing data access transparently, the frameworks minimize the amount
ofcodingthatawebapplicationprogrammerhastocarryout.
Therearealargenumberofsuchframeworks,basedondifferentlanguages.Some
of the more widely used frameworks include the Django framework for the Python
language, Ruby on Rails, which supports the Rails framework on the Ruby program-
minglanguage,ApacheStruts,Swing,Tapestry,andWebObjects,allbasedonJava/JSP.
ManyoftheseframeworksalsomakeiteasytocreatesimpleCRUDwebinterfaces;that
is,interfacesthatsupportcreate,read,updateanddeleteofobjects/tuplesbygenerat-
ingcodefromanobjectmodeloradatabase. Suchtoolsareparticularlyuseful toget
simple applications running quickly, and the generated code can be edited to build
moresophisticatedwebinterfaces.
9.4.3 The Django Framework
The Django framework for Python is a widely used web application framework. We
illustrateafewfeaturesoftheframeworkthroughexamples.
Views in Django are functions that are equivalent to servlets in Java. Django re-
quires a mapping, typically specified in a file urls.py, which maps URLs to Django
views.WhentheDjangoapplicationserverreceivesanHTTPrequest,itusestheURL
mappingtodecidewhichviewfunctiontoinvoke.
Figure9.10showssamplecodeimplementingthepersonquerytaskthatweearlier
implemented using Java servlets. The code shows a view called person query view.
WeassumethatthePersonQueryURLismappedtotheviewperson query view,and
isinvokedfromtheHTMLformshownearlierinFigure9.3.
We also assume that the root of the application is mapped to a login view. We
havenotshownthecodeforlogin view,butweassumeitdisplaysaloginform,andon
submit it invokes the authenticate view. We have not shown the authenticate view,

--- Page 449 ---

420 Chapter9 ApplicationDevelopment
either, but we assume that it checks the login name and password. If the password is
validated,theauthenticateviewredirectstoaperson query form,whichdisplaysthe
HTML code that we saw earlier in Figure 9.3; if password validation fails, it redirects
tothelogin view.
ReturningtoFigure9.10, the viewperson query view() firstchecksiftheuseris
loggedinbycheckingthesessionvariableusername.Ifthesessionvariableisnotset,
the browser is redirected to the login screen. Otherwise, the requested user informa-
from django.http import HttpResponse
from django.db import connection
def result set to html(headers, cursor):
html = "<table border=1>"
html += "<tr>"
for header in headers:
html += "<th>" + header + "</th>"
html += "</tr>"
for row in cursor.fetchall():
html += "<tr>"
for col in row:
html += "<td>" + col + "</td>"
html += "</tr>"
html += "</table>"
return html
def person query view(request):
if "username" not in request.session:
return login view(request)
persontype = request.GET.get("persontype")
personname = request.GET.get("personname")
if persontype == "student":
query tmpl = "select id, name, dept name from student where name=%s"
else:
query tmpl = "select id, name, dept name from instructor where name=%s"
with connection.cursor() as cursor:
cursor.execute(query tmpl, [personname])
headers = ["ID", "Name", "Department Name"]
return HttpResponse(result set to html(headers, cursor))
Figure 9.10 ThepersonqueryapplicationinDjango.

--- Page 450 ---

9.5 Client-SideCodeandWebServices 421
tion is fetched by connecting to the database; connection details for the database are
specifiedinaDjangoconfigurationfilesettings.pyandareomittedinourdescription.
Acursor(similartoaJDBCstatement)isopenedontheconnection,andthequeryis
executedusingthecursor.Notethatthefirstargumentofcursor.executeisthequery,
with parameters marked by “%s”, and the second argument is a list of values for the
parameters. The result of the database query is then displayed by calling a function
result set to html(), which iterates over the result set fetched from the database and
outputstheresultsinHTMLformattoastring;thestringisthenreturnedasanHttpRe-
sponse.
Django provides support for a number of other features, such as creating HTML
forms and validating data entered in the forms, annotations to simplify checking of
authentication,andtemplatesforcreatingHTMLpages,whicharesomewhatsimilarto
JSPpages.Djangoalsosupportsanobject-relationmappingsystem,whichwedescribe
inSection9.6.2.2.
9.5 Client-Side Code and Web Services
The two most widely used classes of user interfaces today are the web interfaces and
mobileapplicationinterfaces.
While early generation web browsers only displayed HTML code, the need was
soon felttoallowcodetorun onthebrowsers. Client-side scriptinglanguages arelan-
guagesdesignedtobeexecutedontheclient’swebbrowser.Theprimarymotivationfor
suchscriptinglanguagesisflexibleinteractionwiththeuser,providingfeaturesbeyond
thelimitedinteractionpowerprovidedbyHTMLandHTMLforms.Further,executing
programsattheclientsitespeedsupinteractiongreatlycomparedtoeveryinteraction
beingsenttoaserversiteforprocessing.
The JavaScript language is by far the most widely used client-side scripting lan-
guage.ThecurrentgenerationofwebinterfacesusestheJavaScriptscriptinglanguage
extensivelytoconstructsophisticateduserinterfaces.
Any client-side interface needs to store and retrieve data from the back end. Di-
rectlyaccessingadatabaseisnotagoodidea,sinceitnotonlyexposeslow-leveldetails,
but italsoexposes thedatabase toattacks. Instead, backendsprovide accesstostore
andretrievedatathroughwebservices.WediscusswebservicesinSection9.5.2.
Mobile applications are very widely used, and user interfaces for mobile devices
are very important today. Although we do not cover mobile application development
inthisbook,weofferpointerstosomemobileapplicationdevelopmentframeworksin
Section9.5.4.
9.5.1 JavaScript
JavaScript is used for a variety of tasks, including validation, flexible user interfaces,
andinteractionwithwebservices,whichwenowdescribe.

--- Page 451 ---

422 Chapter9 ApplicationDevelopment
9.5.1.1 InputValidation
Functions written in JavaScript can be used to perform error checks (validation) on
userinput,suchasadatestringbeingproperlyformatted,oravalueentered(suchas
age)beinginanappropriaterange.Thesechecksarecarriedoutonthebrowserasdata
areenteredevenbeforethedataaresenttothewebserver.
WithHTML5,manyvalidationconstraintscanbespecifiedaspartoftheinputtag.
Forexample,thefollowingHTMLcode:
<input type="number" name="credits" size="2" min="1" max="15">
ensuresthattheinputfortheparameter“credits”isanumberbetween1and15.More
complex validations that cannot be performed using HTML5 features are best done
usingJavaScript.
Figure9.11showsanexampleofaformwithaJavaScriptfunctionusedtovalidate
aforminput.ThefunctionisdeclaredintheheadsectionoftheHTMLdocument.The
formacceptsastartandanenddate.Thevalidationfunctionensuresthatthestartdate
<html>
<head>
<script type="text/javascript">
function validate() {
var startdate = new Date (document.getElementById("start").value);
var enddate = new Date (document.getElementById("end").value);
if(startdate > enddate) {
alert("Startdate is > end date");
return false;
}
}
</script>
</head>
<body>
<form action="submitDates" onsubmit="return validate()">
Start Date: <input type="date"id="start"><br />
End Date : <input type="date"id="end"><br />
<input type="submit" value="Submit">
</form>
</body>
</html>
Figure 9.11 ExampleofJavaScriptusedtovalidateforminput.

--- Page 452 ---

9.5 Client-SideCodeandWebServices 423
isnotgreaterthantheenddate.Theformtagspecifiesthatthevalidationfunctionis
tobeinvokedwhentheformissubmitted.Ifthevalidationfails,analertboxisshown
totheuser,andifitsucceeds,theformissubmittedtotheserver.
9.5.1.2 ResponsiveUserInterfaces
ThemostimportantbenefitofJavaScriptistheabilitytocreatehighlyresponsiveuser
interfaceswithinabrowserusingJavaScript.Thekeytobuildingsuchauserinterfaceis
theabilitytodynamicallymodifytheHTMLcodebeingdisplayedbyusingJavaScript.
The browser parses HTML code into an in-memory tree structure defined by a stan-
dard calledthe Document ObjectModel (DOM). JavaScriptcode can modify the tree
structuretocarryoutcertainoperations.Forexample,supposeauserneedstoentera
numberofrowsofdata,forexamplemultipleitemsinasinglebill.Atablecontaining
text boxes and other form input methods can be used to gather user input. The table
may have a default size, but if more rows are needed, the user may click on a button
labeled (for example) “Add Item.” This button can be set up to invoke a JavaScript
functionthatmodifiestheDOMtreebyaddinganextrarowinthetable.
AlthoughtheJavaScriptlanguagehasbeenstandardized,therearedifferencesbe-
tween browsers, particularly in the details of the DOM model. As a result, JavaScript
code that works on one browser may not work on another. To avoid such problems,
it is best to use a JavaScript library, such as the JQuery library, which allows code to
be written in a browser-independent way. Internally, the functions in the library can
find out which browser is in use and send appropriately generated JavaScript to the
browser.
JavaScript libraries such as JQuery provide a number of UI elements, such as
menus, tabs, widgets such as sliders, and features such as autocomplete, that can be
createdandexecutedusinglibraryfunctions.
The HTML5 standard supports a number of features for rich user interaction, in-
cluding drag-and-drop, geolocation (which allows the user’s location to be provided
totheapplicationwithuserpermission),allowingcustomizationofthedata/interface
basedonlocation.HTML5alsosupportsServer-SideEvents(SSE),whichallowsaback-
endtonotifythefrontendwhensomeeventoccurs.
9.5.1.3 InterfacingwithWebServices
Today,JavaScriptiswidelyusedtocreatedynamicwebpages, usingseveraltechnolo-
giesthatarecollectivelycalledAjax.ProgramswritteninJavaScriptcancommunicate
withthewebserverasynchronously(thatis,inthebackground,withoutblockinguser
interaction with the web browser), and can fetch data and display it. The JavaScript
ObjectNotation,orJSON,representationdescribedinSection8.1.2isthemostwidely
used data format for transferring data, although other formats such as XML are also
used.
The role of the code for the above tasks, which runs at the application server,
is to send data to the JavaScript code, which then renders the data on the browser.

--- Page 453 ---

424 Chapter9 ApplicationDevelopment
Suchbackendservices,whichservetheroleoffunctionswhichcanbeinvokedtofetch
requireddata,areknownaswebservices.SuchservicescanbeimplementedusingJava
Servlets,Python,oranyofanumberofotherlanguageframeworks.
AsanexampleoftheuseofAjax,considertheautocompletefeatureimplemented
bymanywebapplications.Astheusertypesavalueinatextbox,thesystem suggests
completionsforthevalue beingtyped.Suchautocomplete isveryuseful forhelpinga
user choose a value from a large number of values where a drop-down list would not
be feasible. Libraries such asjQueryprovidesupport forautocomplete byassociating
a function with a text box; the function takes partial input in the box, connected to
a web back end to get possible completions, and displays them as suggestions for the
autocomplete.
The JavaScript code shown in Figure 9.12 uses the jQuery library to implement
autocomplete and the DataTables plug-in for the jQuery library to provide a tabular
displayofdata.TheHTMLcodehasatextinputboxforname,whichhasanidattribute
set to name. The script associates an autocomplete function from the jQuery library
with the text box by using $("#name") syntax of jQuery to locate the DOM node for
text box with id “name”, and then associating the autocomplete function with the
node.Theattributesourcepassedtothefunctionidentifiesthewebservicethatmust
be invoked to get values for the autocomplete functionality. We assume that a servlet
/autocomplete name has been defined, which accepts a parameter term containing
the letters typed so far by the user, even as they are being typed. The servlet should
returnaJSONarrayofnamesofstudents/instructorsthatmatchthelettersintheterm
parameter.
TheJavaScriptcodealsoillustrateshowdatacanberetrievedfromawebservice
and then displayed. Our sample code uses the DataTables jQuery plug-in; there are a
number of other alternative libraries for displaying tabular data. We assume that the
person query ajaxServlet,whichisnotshown,returnstheID,name,anddepartment
nameofstudentsorinstructorswithagivenname,aswesawearlierinFigure9.7,but
encoded in JSON as an object with attribute data containing an array of rows; each
rowisaJSONobjectwithattributesid,name,anddept name.
ThelinestartingwithmyTableshowshowthejQueryplug-inDataTableisassoci-
ated with the HTML table shown later in the figure, whose identifier is personTable.
Whenthebutton“Showdetails”isclicked,thefunctionloadTableAsync()isinvoked.
This function first creates a URL stringurl that is used to invoke person query ajax
with values for person type and name. The function ajax.url(url).load() invoked on
myTable fills the rows of the table using the JSON data fetched from the web service
whose URL we created above. This happens asynchronously; that is, the function re-
turnsimmediately,butwhenthedatahavebeenfetched,thetablerowsarefilledwith
thereturneddata.
Figure 9.13 shows a screenshot of a browser displaying the result of the code in
Figure9.12.
AsanotherexampleoftheuseofAjax,considerawebsitewithaformthatallows
youtoselectacountry,andonceacountryhasbeenselected,youareallowedtoselect

--- Page 454 ---

9.5 Client-SideCodeandWebServices 425
<html> <head>
<script src="https://code.jquery.com/jquery-3.3.1.js"></script>
<script src="https://cdn.datatables.net/1.10.19/js/jquery.dataTables.min.js"></script>
<script src="https://code.jquery.com/ui/1.12.1/jquery-ui.min.js"></script>
<script src="https://cdn.datatables.net/1.10.19/js/jquery.dataTables.min.js"></script>
<link rel="stylesheet"
href="https://code.jquery.com/ui/1.12.1/themes/base/jquery-ui.css"/>
<link rel="stylesheet"
href="https://cdn.datatables.net/1.10.19/css/jquery.dataTables.min.css"/>
<script>
var myTable;
$(document).ready(function() {
$("#name").autocomplete({ source: "/autocomplete name" });
myTable = $("#personTable").DataTable({
columns: [{data:"id"}, {data:"name"}, {data:"dept name"}]
});
});
function loadTableAsync() {
var params= {persontype:$("#persontype").val(),name:$("#name").val()};
var url = "/person query ajax?"+ jQuery.param(params);
myTable.ajax.url(url).load();
}
</script>
</head> <body>
Search for:
<select id="persontype">
<option value="student" selected>Student </option>
<option value="instructor"> Instructor </option>
</select> <br>
Name: <input type=textsize=20 id="name">
<button onclick="loadTableAsync()"> Show details </button>
<table id="personTable" border="1">
<thead>
<tr> <th>ID</th> <th>Name</th> <th>Dept. Name</th> </tr>
</thead>
</table>
</body> </html>
Figure 9.12 HTMLpageusingJavaScriptandAjax.
astatefromalistofstatesinthatcountry.Untilthecountryisselected,thedrop-down
list of states is empty. The Ajax framework allows the list of states to be downloaded

--- Page 455 ---

426 Chapter9 ApplicationDevelopment
Figure 9.13 ScreenshotofdisplaygeneratedbyFigure9.12.
fromthewebsite inthebackgroundwhenthecountryisselected,andassoon asthe
list has been fetched, it is added to the drop-down list, which allows you to select the
state.
9.5.2 Web Services
Awebserviceisanapplicationcomponentthatcanbeinvokedoverthewebandfunc-
tions,ineffect,likeanapplicationprogramminginterface.Awebservicerequestissent
usingtheHTTPprotocol,itisexecutedatanapplicationserver,andtheresultsaresent
backtothecallingprogram.
Two approaches are widely used to implement web services. In the simpler ap-
proach,calledRepresentationStateTransfer(orREST),webservicefunctioncallsare
executedbyastandardHTTPrequesttoaURLatanapplicationserver,withparameters
sentasstandardHTTPrequestparameters.Theapplicationserverexecutestherequest
(which may involve updating the database at the server), generates and encodes the
result, and returns the result as the result of the HTTPrequest. The most widelyused
encodingfortheresultstodayistheJSONrepresentation,althoughXML,whichwesaw
earlierinSection8.1.3,isalsoused.Therequestorparsesthereturnedpage toaccess
thereturneddata.
InmanyapplicationsofsuchRESTfulwebservices(i.e.,webservicesusingREST),
therequestorisJavaScriptcoderunninginawebbrowser;thecodeupdatesthebrowser
screen using the result of the function call. For example, when you scroll the display
on a map interface on the web, the part of the map that needs to be newly displayed
maybefetchedbyJavaScriptcodeusingaRESTfulinterfaceandthendisplayedonthe
screen.
While some web services are not publicly documented and are used only inter-
nallybyspecificapplications,otherwebserviceshavetheirinterfacesdocumentedand
can be used by any application. Such services may allow use without any restriction,

--- Page 456 ---

9.5 Client-SideCodeandWebServices 427
may require users to be logged in before accessing the service, or may require users
orapplicationdeveloperstopaythewebserviceproviderfortheprivilegeofusingthe
service.
Today,averylargevarietyofRESTfulwebservicesareavailable,andmostfront-end
applications use one or more such services to perform backend activities. For exam-
ple,yourweb-basedemailsystem,yoursocialmediawebpage,oryourweb-basedmap
servicewouldalmostsurelybebuiltwithJavaScriptcodeforrenderingandwoulduse
backendwebservicestofetchdataaswellastoperformupdates.Similarly,anymobile
appthatstoresdataatthebackendalmostsurelyuseswebservicestofetchdataand
toperformupdates.
Web services are also increasingly used at the backend, to make use of function-
alities provided by other backend systems. For example, web-based storage systems
provide a web service API for storing and retrieving data; such services are provided
byanumberofproviders,suchasAmazonS3,GoogleCloud Storage,andMicrosoft
Azure. They are very popular with application developers since they allow storage of
very large amounts of data, and they support a very large number of operations per
second,allowingscalabilityfarbeyondwhatacentralizeddatabasecansupport.
There are many more such web-service APIs. For example, text-to-speech, speech
recognition, and vision web-service APIs allow developers to construct applications
incorporatingspeechandimagerecognitionwithverylittledevelopmenteffort.
Amorecomplexandlessfrequentlyusedapproach,sometimesreferredtoas“Big
WebServices,”uses XMLencodingofparameters aswellasresults, hasaformaldef-
initionofthewebAPIusingaspeciallanguage,andusesaprotocollayerbuiltontop
oftheHTTPprotocol.
9.5.3 Disconnected Operation
Manyapplicationswishtosupportsomeoperationsevenwhenaclientisdisconnected
fromtheapplicationserver. Forexample, astudentmaywishtocompletean applica-
tion form even if her laptop is disconnected from the network but have it saved back
whenthelaptopisreconnected.Asanotherexample,ifanemailclientisbuiltasaweb
application, a user may wish to compose an email even if her laptop is disconnected
from the network and have it sent when it is reconnected.Building such applications
requireslocalstorageintheclientmachine.
The HTML5 standard supports local storage, which can be accessed using
JavaScript.Thecode:
if (typeof(Storage) !== "undefined") { // browser supports local storage
...
}
checksifthebrowsersupportslocalstorage. Ifitdoes,thefollowingfunctionscanbe
usedtostore,load,ordeletevaluesforagivenkey.

--- Page 457 ---

428 Chapter9 ApplicationDevelopment
localStorage.setItem(key,value)
localStorage.getItem(key)
localStorage.deleteItem(key)
To avoid excessive data storage, the browser may limit a web site to storing at most
someamountofdata;thedefaultmaximumistypically5megabytes.
The above interface only allows storage/retrieval of key/value pairs. Retrieval re-
quires that a key be provided; otherwise the entire set of key/value pairs will need to
bescannedtofindarequiredvalue.Applicationsmayneedtostoretuplesindexedon
multiple attributes, allowing efficient access based on values of any of the attributes.
HTML5 supports IndexedDB, which allows storage of JSON objects with indices on
multipleattributes.IndexedDBalsosupportsschemaversionsandallowsthedeveloper
toprovidecodetomigratedatafromoneschemaversiontothenextversion.
9.5.4 Mobile Application Platforms
Mobile applications(or mobile apps, for short) are widelyused today, and they form
the primary user interface for a large class of users. The two most widely used mo-
bile platforms today are Androidand iOS. Each of these platforms provides a way of
buildingapplicationswithagraphicaluserinterface,tailoredtosmalltouch-screende-
vices.ThegraphicaluserinterfaceprovidesavarietyofstandardGUIfeaturessuchas
menus,lists,buttons,checkboxes,progressbars,andsoon,andtheabilitytodisplay
text,images,andvideo.
Mobile apps can be downloaded and stored and used later. Thus, the user can
download apps whenconnected toahigh-speed networkand then use the app witha
lower-speed network. In contrast, web apps may get downloaded when they are used,
resulting in a lot of data transfer when a user may be connected to a lower-speed net-
workoranetworkwheredatatransferisexpensive.Further,mobileappscanbebetter
tunedtosmall-sizeddevicesthanwebapps,withuserinterfacesthatworkwellonsmall
devices.Mobileappscanalsobecompiledtomachinecode,resultinginlowerpower
demandsthanwebapps.Moreimportantly,unlike(earliergeneration)webapps,mo-
bile apps can store data locally, allowing offline usage. Further, mobile apps have a
well-developedauthorizationmodel,allowingthemtouseinformationanddevicefea-
turessuchaslocation,cameras,contacts,andsoonwithuserauthorization.
However,oneofthedrawbacksofusingmobile-appinterfacesisthatcodewritten
fortheAndroidplatformcanonlyrunonthatplatformandnotoniOS,andviceversa.
As a result, developers are forced to code every application twice, once for Android
andonceforiOS,unlesstheydecidetoignoreoneoftheplatformscompletely,which
isnotverydesirable.
The ability to create applications where the same high-level code can run on ei-
ther Android or iOS is clearly very important. The React Native framework based on
JavaScript, developed by Facebook, and the Flutter framework based on the Dart lan-
guage developed by Google, are designed toallow cross-platform development. (Dart

--- Page 458 ---

9.6 ApplicationArchitectures 429
isalanguageoptimizedfordevelopinguserinterfaces,providingfeaturessuchasasyn-
chronousfunctioninvocationandfunctionsonstreams.)Bothframeworksallowmuch
of theapplication codetobe commonforboth Androidand iOS,but some function-
alitycanbemadespecifictotheunderlyingplatformincaseitisnotsupportedinthe
platform-independentpartoftheframework.
Withthewideavailabilityofhigh-speedmobilenetworks,someofthemotivation
for using mobile apps instead of web apps, such as the ability to download ahead of
time, is not as important anymore. A new generation of web apps, called Progressive
Web Apps (PWA) that combine the benefits of mobile apps with web apps is seeing
increasingusage.SuchappsarebuiltusingJavaScriptandHTML5andaretailoredfor
mobiledevices.
AkeyenablingfeatureforPWAsistheHTML5supportforlocaldatastorage,which
allowsappstobeusedevenwhenthedeviceisoffline.Anotherenablingfeatureisthe
support for compilationof JavaScriptcode;compilation isrestricted tocode thatfol-
lowsarestrictedsyntax,sincecompilationofarbitraryJavaScriptcodeisnotpractical.
Suchcompilationistypicallydonejust-in-time,thatis,itisdonewhenthecodeneeds
tobeexecuted,orifithasalreadybeenexecutedmultipletimes.Thus,bywritingCPU-
heavypartsofawebapplicationusingonlyJavaScriptfeaturesthatallowcompilation,
it is possible to ensure CPU and energy-efficient execution of the code on a mobile
device.
PWAsalsomakeuseofHTML5serviceworkers,whichallowascripttoruninthe
backgroundinthebrowser,separatefromawebpage.Suchserviceworkerscanbeused
toperformbackgroundsynchronizationoperationsbetweenthelocalstoreandaweb
service,ortoreceiveorpushnotificationsfromabackendservice.HTML5alsoallows
apps to get device location (after user authorization), allowing PWAs to use location
information.
Thus,PWAsarelikelytoseeincreasinguse,replacingmany(butcertainlynotall)
oftheusecasesformobileapps.
9.6 Application Architectures
Tohandletheircomplexity,largeapplicationsareoftenbrokenintoseverallayers:
• The presentation or user-interface layer, which deals with user interaction. A sin-
gleapplicationmayhaveseveraldifferentversionsofthislayer,correspondingto
distinct kinds of interfaces such as web browsers and user interfaces of mobile
phones,whichhavemuchsmallerscreens.
Inmanyimplementations,thepresentation/user-interfacelayerisitselfconcep-
tuallybrokenupintolayers,basedonthemodel-view-controller(MVC)architecture.
The model corresponds to the business-logic layer, described below. The view de-
finesthepresentationofdata;asingleunderlyingmodelcanhavedifferentviews
dependingonthespecificsoftware/deviceusedtoaccesstheapplication.Thecon-
troller receives events (user actions), executes actions on the model, and returns

--- Page 459 ---

430 Chapter9 ApplicationDevelopment
a view to the user. The MVC architecture is used in a number of web application
frameworks.
• The business-logic layer, which provides a high-level view of data and actions on
data.Wediscussthebusiness-logiclayerinmoredetailinSection9.6.1.
• Thedata-accesslayer,whichprovidestheinterfacebetweenthebusiness-logiclayer
and the underlying database. Many applications use an object-oriented language
to code the business-logic layer and use an object-oriented model of data, while
the underlying database is a relational database. In such cases, the data-access
layer alsoprovides the mappingfrom the object-oriented datamodel used by the
businesslogictotherelationalmodelsupportedbythedatabase.Wediscusssuch
mappingsinmoredetailinSection9.6.2.
Figure 9.14 shows these layers, along with a sequence of steps taken to process a
requestfromthewebbrowser.Thelabelsonthearrowsinthefigureindicatetheorder
ofthesteps.Whentherequestisreceivedbytheapplicationserver,thecontrollersends
a request to the model. The model processes the request, using business logic, which
may involve updating objects that are part of the model, followed by creatinga result
object.Themodelinturn usesthedata-accesslayertoupdate orretrieveinformation
from a database. The result object created by the model is sent to the view module,
which creates an HTML view of the result to be displayed on the web browser. The
viewmaybetailoredbasedonthecharacteristicsofthedeviceusedtoviewtheresult
—for example, whetherit isa computer monitor witha large screenor a small screen
onaphone.Increasingly,theviewlayerisimplementedbycoderunningattheclient,
insteadofattheserver.
1
internet controller
8
6 2
7 5
web browser
view model
3
data-access
layer
4
database
web/application server
Figure 9.14 Webapplicationarchitecture.

--- Page 460 ---

9.6 ApplicationArchitectures 431
9.6.1 The Business-Logic Layer
The business-logic layer of an application for managing a university may provide ab-
stractions of entitiessuch as students, instructors, courses, sections, etc.,and actions
such as admitting a student to the university, enrolling a student in a course, and so
on. The code implementingthese actions ensures that business rules are satisfied; for
example, the code would ensure that a student can enroll for a course only if she has
alreadycompletedcourseprerequisitesandhaspaidhertuitionfees.
Inaddition,thebusinesslogicincludesworkflows,whichdescribehowaparticular
taskthatinvolvesmultipleparticipantsishandled.Forexample,ifacandidateapplies
tothe university,thereisaworkflow thatdefineswhoshould see and approve the ap-
plication first, and if approved in the first step, who should see the application next,
and so on until either an offer is made to the student, or a rejection note is sent out.
Workflowmanagementalsoneedstodealwitherrorsituations;forexample,ifadead-
lineforapproval/rejectionisnotmet,asupervisormayneedtobeinformedsoshecan
interveneandensuretheapplicationisprocessed.
9.6.2 The Data-Access Layer and Object-Relational Mapping
Inthesimplestscenario,wherethebusiness-logiclayerusesthesamedatamodelasthe
database,thedata-accesslayersimplyhidesthedetailsofinterfacingwiththedatabase.
However,whenthebusiness-logiclayeriswrittenusinganobject-orientedprogramming
language,itisnaturaltomodeldataasobjects,withmethodsinvokedonobjects.
In early implementations, programmers had to write code for creatingobjects by
fetchingdatafromthedatabase andforstoringupdatedobjectsbackinthedatabase.
However, such manual conversions between data models is cumbersome and error
prone. One approach to handling this problem was to develop a database system
that natively stores objects, and relationships between objects, and allows objects in
the database to be accessed in exactly the same way as in-memory objects. Such
databases, called object-oriented databases, were discussed in Section 8.2. However,
object-orienteddatabasesdidnotachievecommercialsuccessforavarietyoftechnical
andcommercialreasons.
Analternativeapproachistousetraditionalrelationaldatabasestostoredata,but
to automate the mapping of data in relation to in-memory objects, which are created
ondemand(sincememoryisusuallynotsufficienttostorealldatainthedatabase),as
wellasthereversemappingtostoreupdatedobjectsbackasrelationsinthedatabase.
Severalsystemshavebeendevelopedtoimplementsuchobject-relationalmappings.
WedescribetheHibernateandDjangoORMsnext.
9.6.2.1 HibernateORM
TheHibernatesystemiswidelyusedformappingfromJavaobjectstorelations.Hiber-
nateprovidesanimplementationoftheJavaPersistenceAPI(JPA).InHibernate,the
mapping from each Java class to one or more relations is specified in a mapping file.

--- Page 461 ---

432 Chapter9 ApplicationDevelopment
Themappingfilecanspecify,forexample,thataJavaclasscalledStudentismapped
to the relation student, with the Java attribute ID mapped to the attribute student.ID,
andsoon.Informationaboutthedatabase,suchasthehostonwhichitisrunningand
user name and password for connecting to the database, are specified in a properties
file.Theprogramhastoopenasession,whichsetsuptheconnectiontothedatabase.
Oncethesession issetup,aStudent objectstud createdinJavacanbe storedinthe
databasebyinvokingsession.save(stud).TheHibernatecodegeneratestheSQLcom-
mandsrequiredtostorecorrespondingdatainthestudentrelation.
WhileentitiesinanE-Rmodelnaturallycorrespondtoobjectsinanobject-oriented
languagesuchasJava,relationshipsoftendonot.Hibernatesupportstheabilitytomap
such relationshipsassetsassociated withobjects. Forexample,the takesrelationship
between student and section can be modeledby associatinga setof sections witheach
student,andasetofstudentswitheachsection.Oncetheappropriatemappingisspec-
ified, Hibernate populates these sets automatically from the database relation takes,
andupdatestothesetsarereflectedbacktothedatabaserelationoncommit.
AsanexampleoftheuseofHibernate,wecreateaJavaclasscorrespondingtothe
studentrelationasfollows:
@Entity public class Student {
@Id String ID;
String name;
String department;
int tot cred;
}
Tobeprecise,theclassattributesshouldbedeclaredasprivate,andgetter/settermeth-
odsshouldbeprovidedtoaccesstheattributes,butweomitthesedetails.
ThemappingoftheclassattributesofStudenttoattributesoftherelationstudent
canbespecifiedinamappingfile,inanXMLformat,ormoreconveniently,bymeans
ofannotationsoftheJavacode.Intheexampleabove,theannotation@Entitydenotes
thattheclassismappedtoadatabaserelation,whosenamebydefaultistheclassname,
andwhoseattributesarebydefaultthesameastheclassattributes.Thedefaultrelation
nameandattributenamescanbeoverriddenusing@Tableand@Columnannotations.
The@IdannotationintheexamplespecifiesthatIDistheprimarykeyattribute.
The following code snippet then creates a Student object and saves it to the
database.
Session session = getSessionFactory().openSession();
Transaction txn = session.beginTransaction();
Student stud = new Student("12328", "John Smith", "Comp. Sci.", 0);
session.save(stud);
txn.commit();
session.close();

--- Page 462 ---

9.6 ApplicationArchitectures 433
HibernateautomaticallygeneratestherequiredSQLinsertstatementtocreateastudent
tupleinthedatabase.
Objects can be retrieved either by primary key or by a query, as illustrated in the
followingcodesnippet:
Session session = getSessionFactory().openSession();
Transaction txn = session.beginTransaction();
// Retrieve student object by identifier
Student stud1 = session.get(Student.class, "12328");
.. print out the Student information ..
List students =
session.createQuery("from Student as s order by s.IDasc").list();
for ( Iterator iter = students.iterator();iter.hasNext();) {
Student stud = (Student) iter.next();
.. print out the Student information ..
}
txn.commit();
session.close();
A single object can be retrieved using the session.get() method by providing its
class and its primary key. The retrieved object can be updated in memory; when
the transaction on the ongoing Hibernate session is committed, Hibernate automat-
ically saves the updated objects by making corresponding updates on relations in the
database.
TheprecedingcodesnippetalsoshowsaqueryinHibernate’sHQLquerylanguage,
which is based on SQL but designed to allow objects to be used directlyin the query.
TheHQLqueryisautomaticallytranslatedtoSQLbyHibernateandexecuted,andthe
resultsareconvertedintoalistofStudentobjects.Theforloopiteratesovertheobjects
inthislist.
These features help to provide the programmer with a high-level model of data
withoutbotheringaboutthedetailsoftherelationalstorage.However,Hibernate,like
otherobject-relationalmappingsystems,alsoallowsqueriestobewrittenusingSQLon
therelationsstored inthedatabase; suchdirectdatabase access,bypassingtheobject
model,canbequiteusefulforwritingcomplexqueries.
9.6.2.2 TheDjangoORM
SeveralORMshavebeendevelopedforthePythonlanguage.TheORMcomponentof
the Django framework is one of the most popular such ORMs, while SQLAlchemy is
anotherpopularPythonORM.
Figure 9.15 shows a model definition for Student and Instructor in Django. Ob-
serve that all of the fields of student and instructor have been defined as fields in the
classStudentandInstructor,withappropriatetypedefinitions.
In addition, the relation advisor has been modeled here as a many-to-many rela-
tionshipbetweenStudentandInstructor.Therelationshipisaccessedbyanattribute

--- Page 463 ---

434 Chapter9 ApplicationDevelopment
from django.db import models
class student(models.Model):
id = models.CharField(primary key=True, max length=5)
name = models.CharField(max length=20)
dept name = models.CharField(max length=20)
tot cred = models.DecimalField(max digits=3, decimal places=0)
class instructor(models.Model):
id = models.CharField(primary key=True, max length=5)
name = models.CharField(max length=20)
dept name = models.CharField(max length=20)
salary = models.DecimalField(max digits=8, decimal places=2)
advisees = models.ManyToManyField(student, related name="advisors")
Figure 9.15 ModeldefinitioninDjango.
calledadviseesinInstructor,whichstoresasetofreferencestoStudentobjects.The
reverserelationshipfromStudenttoInstructoriscreatedautomatically,andthemodel
specifiesthatthereverserelationshipattributeintheStudentclassisnamedadvisors;
thisattributestoresasetofreferencestoInstructorobjects.
TheDjangoviewperson query modelshowninFigure9.16illustrateshowtoac-
cessdatabaseobjectsdirectlyfromthePythonlanguage,withoutusingSQL.Theexpres-
sion Student.objects.filter() returns all student objects that satisfy the specified filter
condition;inthiscase,studentswiththegivenname.Thestudentnamesareprintedout
along with the names of their advisors. The expression Student.advisors.all()returns
alistofadvisors(advisorobjects)of agivenstudent, whose namesarethenretrieved
and returned by the get names() function. The case for instructors is similar, with
instructornamesbeingprintedoutalongwiththenamesoftheiradvisees.
Djangoprovidesatoolcalledmigrate,whichcreatesdatabaserelationsfromagiven
model. Models can be given version numbers. When migrate is invoked on a model
withanewversionnumber,whileanearlierversionnumberisalreadyinthedatabase,
the migrate tool also generates SQL codefor migratingthe existingdatafrom theold
databaseschematothenewdatabaseschema.ItisalsopossibletocreateDjangomod-
elsfromexistingdatabaseschemas.
9.7 Application Performance
Web sites may be accessed by millions of people from across the globe, at rates of
thousands of requests persecond, oreven more,forthe most popular sites. Ensuring

--- Page 464 ---

9.7 ApplicationPerformance 435
from models import Student, Instructor
def get names(persons):
res = ""
for p in persons:
res += p.name + ", "
return res.rstrip(",")
def person query model(request):
persontype = request.GET.get(’persontype’)
personname = request.GET.get(’personname’)
html = ""
if persontype == ’student’:
students = Student.objects.filter(name=personname)
for student in students:
advisors = students.advisors.all()
html = html + "Advisee: " + student.name + "<br>Advisors: "
+ get names(advisors) + "<br>∖n"
else:
instructors = Instructor.objects.filter(name=personname)
for instructor in instructors:
advisees = instructor.advisees.all()
html = html+"Advisor: " + instructor.name + "<br>Advisees: "
+ get names(advisees) + "<br>∖n"
return HttpResponse(html)
Figure 9.16 ViewdefinitioninDjangousingmodels.
that requests are served with low response times is a major challenge for web-site de-
velopers.Todoso,applicationdeveloperstrytospeeduptheprocessingofindividual
requests by using techniques such as caching, and they exploit parallel processing by
using multiple application servers. We describe these techniques briefly next. Tuning
of database applications is another way to improve performance and is described in
Section25.1.
9.7.1 Reducing Overhead by Caching
Suppose that the application code for servicing each user request connects to a
database through JDBC. Creating a new JDBC connection may take several millisec-
onds,soopeninganewconnectionforeachuserrequestisnotagoodideaifveryhigh
transactionratesaretobesupported.

--- Page 465 ---

436 Chapter9 ApplicationDevelopment
Theconnectionpoolingmethodisusedtoreducethisoverhead;itworksasfollows:
Theconnectionpoolmanager(typicallyapartoftheapplicationserver)createsapool
(thatis,aset)ofopenODBC/JDBCconnections.Insteadofopeninganewconnection
tothedatabase,thecodeservicingauserrequest(typicallyaservlet)asksfor(requests)
aconnectionfromtheconnectionpoolandreturnstheconnectiontothepoolwhenthe
code(servlet)completesitsprocessing.Ifthepoolhasnounusedconnectionswhena
connectionisrequested,anewconnectionisopenedtothedatabase(takingcarenot
toexceedthemaximumnumberofconnectionsthatthedatabasesystemcansupport
concurrently).Iftherearemanyopenconnectionsthathavenotbeenusedforawhile,
theconnectionpoolmanagermayclosesomeoftheopendatabaseconnections.Many
applicationserversandnewerODBC/JDBCdriversprovideabuilt-inconnectionpool
manager.
Details of how to create a connection pool vary by application server or JDBC
driver,butmostimplementationsrequirethecreationofaDataSourceobjectusingthe
JDBCconnectiondetailssuchasthemachine,port,database,user-idandpassword,as
wellasotherparametersrelatedtoconnectionpooling.ThegetConnection()method
invokedontheDataSourceobjectgetsaconnectionfromtheconnectionpool.Closing
theconnectionreturnstheconnectiontothepool.
Certain requests may result in exactly the same query being resubmitted to the
database. The cost of communication with the database can be greatly reduced by
caching the results of earlier queries and reusing them, so long as the query result
hasnotchangedatthedatabase.Somewebserverssupportsuchquery-resultcaching;
cachingcanotherwisebedoneexplicitlyinapplicationcode.
Costscanbefurtherreducedbycachingthefinalwebpagethatissentinresponse
to a request. If a new request comes with exactly the same parameters as a previous
request, the request does not perform any updates, and the resultant web page is in
thecache,thatpagecanbereusedtoavoidthecostofrecomputingthepage.Caching
canbedoneattheleveloffragmentsofwebpages,whicharethenassembledtocreate
completewebpages.
Cachedqueryresultsandcachedwebpagesareformsofmaterializedviews.Ifthe
underlyingdatabasedatachange,thecachedresultsmustbediscarded,orrecomputed,
orevenincrementallyupdated,asinmaterialized-viewmaintenance(describedinSec-
tion 16.5). Some database systems (such as Microsoft SQL Server) provide a way for
theapplicationservertoregisteraquerywiththedatabaseandgetanotificationfrom
thedatabasewhentheresultofthequerychanges.Suchanotificationmechanismcan
beusedtoensurethatqueryresultscachedattheapplicationserverareup-to-date.
Thereareseveralwidelyusedmain-memorycachingsystems;amongthemorepop-
ularonesarememcachedandRedis.Bothsystemsallowapplicationstostoredatawith
anassociatedkeyandretrievedataforaspecifiedkey.Thus,theyactashash-mapdata
structures that allow data to be stored in the main memory but also provide cache
evictionofinfrequentlyuseddata.

--- Page 466 ---

9.8 ApplicationSecurity 437
For example, with memcached, data can be stored using memcached.add(key,
data)andfetchedusingmemcached.fetch(key).Insteadofissuingadatabasequeryto
fetchuserdatawithaspecifiedkey,saykey1,fromarelationr,anapplicationwouldfirst
check if the required data are already cached by issuing a fetch("r:"+key1) (here, the
keyisappendedtotherelationname,todistinguishdatafromdifferentrelationsthat
maybestoredinthesamememcachedinstance).Ifthefetchreturnsnull,thedatabase
queryisissued,acopyofthedatafetchedfromthedatabaseisstoredinmemcached,
andthedataarethenreturnedtotheuser.Ifthefetchdoesfindtherequesteddata,it
canbeusedwithoutaccessingthedatabase,leadingtomuchfasteraccess.
A clientcan connectto multiplememcachedinstances, whichmayrun on differ-
ent machines and store/retrieve data from any of them. How to decide what data are
stored on which instance is left to the client code. By partitioning the data storage
acrossmultiplemachines,anapplicationcanbenefitfromtheaggregatemainmemory
availableacrossallthemachines.
Memcached does not support automatic invalidation of cached data, but the ap-
plication can track database changes and issue updates (using memcached set(key,
newvalue))ordeletes(usingmemcached delete(key))forthekeyvaluesaffectedby
update ordeletioninthedatabase.Redisoffersverysimilarfunctionality.Bothmem-
cachedandRedisprovideAPIsinmultiplelanguages.
9.7.2 Parallel Processing
Acommonlyusedapproachtohandlingsuchveryheavyloadsistousealargenumber
of application servers running in parallel, each handling a fraction of the requests. A
web server or a network router can be used to route each clientrequest to one of the
application servers. All requests from a particular client session must go to the same
application server, since the server maintains state for a client session. This property
can be ensured, for example, by routing all requests from a particular IP address to
the same application server. The underlying database is, however, shared by all the
applicationservers,sousersseeaconsistentviewofthedatabase.
Whiletheabove architectureensuresthatapplicationserversdonotbecomebot-
tlenecks,itcannotpreventthedatabasefrombecomingabottleneck,sincethereisonly
onedatabaseserver.Toavoidoverloadingthedatabase,applicationdesignersoftenuse
cachingtechniquestoreducethenumberofrequeststothedatabase.Inaddition,par-
allel database systems, described in Chapter 21 through Chapter 23, are used when
the database needs to handle very large amounts of data, or a very large query load.
ParalleldatastoragesystemsthatareaccessibleviawebserviceAPIsarealsopopular
inapplicationsthatneedtoscaletoaverylargenumberofusers.
9.8 Application Security
Applicationsecurityhastodealwithseveralsecuritythreatsandissuesbeyond those
handledbySQLauthorization.

--- Page 467 ---

438 Chapter9 ApplicationDevelopment
The first point where security has to be enforced is in the application. To do so,
applications must authenticate users and ensure that users are only allowed to carry
outauthorizedtasks.
Therearemanywaysinwhichanapplication’ssecuritycanbecompromised,even
if the database system is itself secure, due to badly written application code. In this
section, we first describe several security loopholes that can permit hackers to carry
outactionsthatbypasstheauthenticationandauthorizationcheckscarriedoutbythe
application, and we explain how to prevent such loopholes. Later in the section, we
describe techniques for secure authentication, and for fine-grained authorization. We
then describe audit trails that can help in recovering from unauthorized access and
fromerroneousupdates.Weconcludethesectionbydescribingissuesindataprivacy.
9.8.1 SQL Injection
InSQLinjectionattacks,theattackermanagestogetanapplicationtoexecuteanSQL
querycreatedbytheattacker.InSection5.1.1.5,wesawanexampleofanSQLinjection
vulnerabilityifuserinputsareconcatenateddirectlywithanSQLqueryandsubmitted
tothedatabase.AsanotherexampleofSQLinjectionvulnerability,considertheform
source text shown in Figure 9.3. Suppose the corresponding servlet shown in Figure
9.7createsanSQLquerystringusingthefollowingJavaexpression:
String query = “select * from student where name like ’%”
+ name + “%’ ”
wherenameisavariablecontainingthestringinputbytheuser,andthenexecutesthe
queryonthedatabase.Amaliciousattackerusingthewebformcanthentypeastring
suchas“’;<someSQLstatement>;––”,where<someSQLstatement>denotesany
SQL statement that the attacker desires, in place of a valid student name. The servlet
wouldthenexecutethefollowingstring.
select * from student where name like '%'; <some SQL statement>; – – %’
Thequoteinsertedbytheattackerclosesthestring,thefollowingsemicolonterminates
the query, and the followingtext inserted by the attackergets interpreted as asecond
SQLquery,whiletheclosingquotehasbeencommentedout.Thus,themalicioususer
hasmanagedtoinsertanarbitrarySQLstatementthatisexecutedbytheapplication.
The statement can cause significant damage, since it can perform any action on the
database,bypassingallsecuritymeasuresimplementedintheapplicationcode.
As discussed in Section 5.1.1.5, to avoid such attacks, it is best to use prepared
statements to execute SQL queries. When setting a parameter of a prepared query,
JDBC automatically adds escape characters so that the user-supplied quote would no
longer be able to terminate the string. Equivalently, a function that adds such escape

--- Page 468 ---

9.8 ApplicationSecurity 439
characterscouldbeappliedoninputstringsbeforetheyareconcatenatedwiththeSQL
query,insteadofusingpreparedstatements.
AnothersourceofSQL-injectionriskcomesfromapplicationsthatcreatequeries
dynamically,basedonselectionconditionsandorderingattributesspecifiedinaform.
Forexample,anapplicationmayallowausertospecifywhatattributeshouldbeused
for sorting the resultsof a query. An appropriate SQL query isconstructed, based on
theattributespecified.Suppose theapplicationtakestheattributenamefromaform,
inthevariableorderAttribute,andcreatesaquerystringsuchasthefollowing:
String query = “select * from takes order by ” + orderAttribute;
A malicious user can send an arbitrary string in place of a meaningful orderAt-
tributevalue,eveniftheHTMLformusedtogettheinputtriedtorestricttheallowed
valuesbyprovidingamenu.ToavoidthiskindofSQLinjection,theapplicationshould
ensure that the orderAttribute variable value is one of the allowed values (in our ex-
ample,attributenames)beforeappendingit.
9.8.2 Cross-Site Scripting and Request Forgery
Awebsitethatallowsuserstoentertext,suchasacommentoraname,andthenstores
itandlaterdisplaysittootherusers,ispotentiallyvulnerabletoakindofattackcalleda
cross-sitescripting(XSS)attack.Insuchanattack,amalicioususerenterscodewritten
inaclient-sidescriptinglanguagesuchasJavaScriptorFlashinsteadofenteringavalid
nameorcomment.Whenadifferentuserviewstheenteredtext,thebrowserexecutes
thescript,whichcancarryoutactionssuchassendingprivatecookieinformationback
tothemalicioususerorevenexecutinganactiononadifferentwebserverthattheuser
maybeloggedinto.
Forexample,suppose theuserhappenstobeloggedintoherbankaccountatthe
timethescriptexecutes.Thescriptcouldsendcookieinformationrelatedtothebank
accountloginbacktothemalicioususer,whocouldusetheinformationtoconnectto
thebank’swebserver,foolingitintobelievingthattheconnectionisfromtheoriginal
user.Orthescriptcouldaccessappropriate pagesonthebank’swebsite,withappro-
priately set parameters, to execute a money transfer. In fact, this particular problem
canoccurevenwithoutscriptingbysimplyusingalineofcodesuchas
<img src=
"https://mybank.com/transfermoney?amount=1000&toaccount=14523">
assumingthattheURLmybank.com/transfermoneyacceptsthespecifiedparameters
andcarriesoutamoneytransfer.Thislatterkindofvulnerabilityisalsocalledcross-site
requestforgeryorXSRF(sometimesalsocalledCSRF).
XSScanbedoneinotherways,suchasluringauserintovisitingawebsitethathas
malicious scripts embedded in its pages. There are other more complex kinds of XSS

--- Page 469 ---

440 Chapter9 ApplicationDevelopment
and XSRF attacks, which we shall not get into here. To protect against such attacks,
twothingsneedtobedone:
• PreventyourwebsitefrombeingusedtolaunchXSSorXSRFattacks.
The simplest technique isto disallow any HTMLtags whatsoever in text input by
users. There are functions that detect or strip all such tags. These functions can
beusedtopreventHTMLtags,andasaresult,anyscripts,frombeingdisplayedto
otherusers. Insome casesHTMLformattingisuseful, andinthatcasefunctions
thatparsethetextandallowlimitedHTMLconstructsbutdisallowotherdangerous
constructscanbeusedinstead;thesemustbedesignedcarefully,sincesomething
as innocuous as an image include could potentially be dangerous in case there is
abugintheimagedisplaysoftwarethatcanbeexploited.
• ProtectyourwebsitefromXSSorXSRFattackslaunchedfromothersites.
Ifthe userhasloggedintoyour website andvisitsadifferentwebsite vulnerable
toXSS,themaliciouscodeexecutingontheuser’sbrowsercouldexecuteactions
on your web site or pass session information related to your web site back to the
malicious user, who could try to exploit it. This cannot be prevented altogether,
butyoucantakeafewstepstominimizetherisk.
° The HTTP protocol allows a server to check the referer of a page access, that
is,theURLofthepagethathadthelinkthattheuserclickedontoinitiatethe
pageaccess.Bycheckingthattherefererisvalid,forexample,thatthereferer
URLisapageonthesamewebsite,XSSattacksthatoriginatedonadifferent
webpageaccessedbytheusercanbeprevented.
° Instead of using only the cookie to identify a session, the session could also
berestrictedtotheIPaddressfromwhichitwasoriginallyauthenticated.Asa
result,evenifamalicioususergetsacookie,hemaynotbeabletologinfrom
adifferentcomputer.
° Never use a GETmethodto perform any updates. This preventsattacks using
<imgsrc..>suchastheonewesawearlier.Infact,theHTTPstandardspecifies
thatGETmethodsshouldnotperformanyupdates.
° If you use a web application framework like Django, make sure to use the
XSRF/CSRFprotectionmechanismsprovidedbytheframework.
9.8.3 Password Leakage
Another problem that application developers must deal with is storing passwords in
clear text in the application code. For example, programs such as JSP scripts often
contain passwords in clear text. If such scripts are stored in a directory accessible by
awebserver,anexternalusermaybeabletoaccessthesourcecodeofthescriptand
getaccesstothepassword forthedatabaseaccountusedbytheapplication.Toavoid
such problems, many application servers provide mechanisms to store passwords in

--- Page 470 ---

9.8 ApplicationSecurity 441
encryptedform,whichtheserverdecryptsbeforepassingitontothedatabase.Sucha
feature removes the need for storing passwords as clear text in application programs.
However,ifthedecryptionkeyisalsovulnerabletobeingexposed,thisapproachisnot
fullyeffective.
Asanothermeasureagainstcompromiseddatabasepasswords,manydatabasesys-
temsallowaccesstothedatabase tobe restricted toagivensetofinternetaddresses,
typically, the machines running the application servers. Attempts to connect to the
database from other internet addresses are rejected. Thus, unless the malicious user
is able to log into the application server, she cannot do any damage even if she gains
accesstothedatabasepassword.
9.8.4 Application-Level Authentication
Authenticationreferstothetaskofverifyingtheidentityofaperson/softwareconnect-
ingtoanapplication.Thesimplestformofauthenticationconsistsofasecretpassword
that must be presented when a user connects to the application. Unfortunately, pass-
words are easily compromised, for example, by guessing, or by sniffing of packets on
thenetworkifthepasswordsarenotsentencrypted.Morerobustschemesareneeded
forcriticalapplications,suchasonlinebankaccounts.Encryptionisthebasisformore
robustauthenticationschemes.AuthenticationthroughencryptionisaddressedinSec-
tion9.9.3.
Many applications use two-factor authentication, where two independent factors
(i.e., pieces of information or processes) are used to identify a user. The two factors
should not share a common vulnerability; for example, if a system merely required
two passwords, both could be vulnerable to leakage in the same manner (by network
sniffing,orbyavirusonthecomputerusedbytheuser,forexample).Whilebiometrics
suchasfingerprintsoririsscannerscanbeusedinsituationswhereauserisphysically
presentatthepointofauthentication,theyarenotverymeaningfulacrossanetwork.
Passwords are used as the first factor in most such two-factor authentication
schemes. Smart cards or other encryption devices connected through the USB inter-
face,whichcanbeusedforauthenticationbasedonencryptiontechniques(seeSection
9.9.3),arewidelyusedassecondfactors.
One-time password devices, which generate a new pseudo-random number (say)
every minute are also widely used as a second factor. Each user is given one of these
devices and must enter the number displayed by the device at the time of authenti-
cation, along withthe password, to authenticate himself. Each devicegenerates adif-
ferent sequence of pseudo-random numbers. The application server can generate the
samesequenceofpseudo-randomnumbersasthedevicegiventotheuser,stoppingat
the number that would be displayed at the time of authentication, and verify that the
numbersmatch.Thisschemerequiresthattheclockinthedeviceandattheserverare
synchronizedreasonablyclosely.
Yetanothersecond-factorapproachistosendanSMSwitha(randomlygenerated)
one-timepasswordtotheuser’sphone(whosenumberisregisteredearlier)whenever

--- Page 471 ---

442 Chapter9 ApplicationDevelopment
the user wishes to log in to the application. The user must possess a phone with that
numbertoreceivetheSMSandthenentertheone-timepassword,alongwithherregular
password,tobeauthenticated.
Itisworthnotingthatevenwithtwo-factorauthentication,usersmaystillbevulner-
able toman-in-the-middle attacks. In such attacks, a user attempting toconnecttothe
applicationisdivertedtoafakewebsite,whichacceptsthepassword(includingsecond
factorpasswords)fromtheuserandusesitimmediatelytoauthenticatetotheoriginal
application.TheHTTPSprotocol,describedinSection9.9.3.2,isusedtoauthenticate
thewebsitetotheuser(sotheuserdoesnotconnecttoafakesitebelievingittobethe
intendedsite).TheHTTPSprotocolalsoencryptsdataandpreventsman-in-the-middle
attacks.
When users access multiple web sites, it is often annoying for a user to have to
authenticateherselftoeachsiteseparately,oftenwithdifferentpasswordsoneachsite.
There are systems that allow the user to authenticate herself to one central authenti-
cationservice,andotherwebsitesandapplicationscanauthenticatetheuserthrough
thecentralauthenticationservice;thesamepasswordcanthenbeusedtoaccessmul-
tiple sites. The LDAP protocol is widely used to implement such a central point of
authenticationforapplicationswithinasingleorganization;organizationsimplement
an LDAP server containing user names and password information, and applications
usetheLDAPservertoauthenticateusers.
In addition to authenticating users, a central authentication service can provide
otherservices,forexample,providinginformationabouttheusersuchasname,email,
andaddressinformation,totheapplication.Thisobviatestheneedtoenterthisinfor-
mation separately in each application. LDAP can be used for this task, as described
in Section 25.5.2. Other directory systems such Microsoft’s Active Directories also
providemechanismsforauthenticatingusersaswellasforprovidinguserinformation.
Asinglesign-onsystemfurtherallowstheusertobeauthenticatedonce,andmul-
tipleapplicationscanthenverifytheuser’sidentitythroughanauthenticationservice
withoutrequiringreauthentication.Inotherwords,onceauserisloggedinatonesite,
hedoesnothavetoenterhisusernameandpasswordatothersitesthatusethesame
singlesign-onservice.Suchsinglesign-onmechanismshavelongbeenusedinnetwork
authenticationprotocolssuchasKerberos,andimplementationsarenowavailablefor
webapplications.
The Security Assertion Markup Language (SAML) is a protocol for exchanging
authentication and authorization information between different security domains, to
provide cross-organization single sign-on. For example, suppose an application needs
to provide access to all students from a particular university, say Yale. The university
cansetupaweb-basedservicethatcarriesoutauthentication.Supposeauserconnects
totheapplicationwithausernamesuchas“joe@yale.edu”.Theapplication,insteadof
directlyauthenticating a user, diverts the user to Yale University’s authentication ser-
vice, which authenticates the user and then tells the application who the user is and

--- Page 472 ---

9.8 ApplicationSecurity 443
mayprovidesomeadditionalinformationsuchasthecategoryoftheuser(studentor
instructor)orotherrelevantinformation.Theuser’spasswordandotherauthentication
factors are never revealed to the application, and the user need not register explicitly
with the application. However, the application must trust the university’s authentica-
tionservicewhenauthenticatingauser.
The OpenID protocol is an alternative for single sign-on across organizations,
which works in a manner similar to SAML. The OAuth protocol is another protocol
thatallowsuserstoauthorizeaccesstocertainresources,viasharingofanauthoriza-
tiontoken.
9.8.5 Application-Level Authorization
AlthoughtheSQLstandardsupportsafairlyflexiblesystemofauthorizationbasedon
roles(describedinSection4.7),theSQLauthorizationmodelplaysaverylimitedrole
in managing user authorizations in a typical application. For instance, suppose you
wantallstudentstobeabletoseetheirowngrades,butnotthegradesofanyoneelse.
SuchauthorizationcannotbespecifiedinSQLforatleasttworeasons:
1. Lackofend-userinformation.Withthegrowthintheweb,databaseaccessescome
primarilyfromwebapplicationservers.Theenduserstypicallydonothaveindi-
vidualuseridentifiersonthedatabaseitself,andindeedtheremayonlybeasingle
useridentifierinthedatabasecorrespondingtoallusersofanapplicationserver.
Thus,authorizationspecificationinSQLcannotbeusedintheabovescenario.
Itispossibleforanapplicationservertoauthenticateendusersandthenpass
theauthenticationinformationontothedatabase.Inthissectionwewillassume
thatthefunctionsyscontext.user id()returnstheidentifieroftheapplicationuser
onwhosebehalfaqueryisbeingexecuted.6
2. Lackoffine-grainedauthorization.Authorizationmustbeatthelevelofindividual
tuples if we are to authorize students to see only their own grades. Such autho-
rizationisnotpossibleinthecurrentSQLstandard,whichpermitsauthorization
onlyonanentirerelationorview,oronspecifiedattributesofrelationsorviews.
Wecouldtrytogetaroundthislimitationbycreatingforeachstudentaview
onthetakesrelationthatshowsonlythatstudent’sgrades.Whilethiswouldwork
inprinciple,itwouldbeextremelycumbersomesincewewouldhavetocreateone
suchviewforeverysinglestudentenrolledintheuniversity,whichiscompletely
impractical.7
Analternativeistocreateaviewoftheform
6In Oracle, a JDBC connection using Oracle’s JDBC drivers can set the end user identifier using the method
OracleConnection.setClientIdentifier(userId), and an SQL query can use the function syscontext('USERENV',
'CLIENTIDENTIFIER')toretrievetheuseridentifier.
7Databasesystemsaredesignedtomanagelargerelationsbuttomanageschemainformationsuchasviewsinaway
thatassumessmallerdatavolumessoastoenhanceoverallperformance.

--- Page 473 ---

444 Chapter9 ApplicationDevelopment
createviewstudentTakesas
select*
fromtakes
wheretakes.ID=syscontext.user id()
Usersarethengivenauthorizationtothisview,ratherthantotheunderlyingtakes
relation.However,queriesexecutedonbehalfofstudentsmustnowbewrittenon
theviewstudentTakes,ratherthanontheoriginaltakesrelation,whereasqueries
executed on behalf of instructors may need to use a different view. The task of
developingapplicationsbecomesmorecomplexasaresult.
Thetaskofauthorizationisoftentypicallycarriedoutentirelyintheapplication,
bypassingtheauthorizationfacilitiesofSQL.Attheapplicationlevel,usersareautho-
rizedtoaccessspecificinterfaces,andtheymayfurtherberestrictedtovieworupdate
certaindataitemsonly.
Whilecarryingoutauthorizationintheapplicationgivesagreatdealofflexibility
toapplicationdevelopers,thereareproblems,too.
• The code for checkingauthorization becomesintermixed withthe rest of the ap-
plicationcode.
• Implementing authorization through application code, rather than specifying it
declaratively in SQL, makes it hard to ensure the absence of loopholes. Because
ofanoversight,oneoftheapplicationprogramsmaynotcheckforauthorization,
allowingunauthorizedusersaccesstoconfidentialdata.
Verifyingthatallapplicationprogramsmakeallrequiredauthorizationchecksinvolves
readingthroughalltheapplication-servercode,aformidabletaskinalargesystem.In
otherwords,applicationshaveaverylarge“surfacearea,”makingthetaskofprotecting
theapplicationsignificantlyharder.Andinfact,securityloopholeshavebeenfoundin
avarietyofreal-lifeapplications.
Incontrast,ifadatabasedirectlysupportedfine-grainedauthorization,authoriza-
tionpoliciescouldbespecifiedandenforcedattheSQLlevel,whichhasamuchsmaller
surface area. Even if some of the application interfaces inadvertently omit required
authorizationchecks,theSQL-levelauthorizationcouldpreventunauthorizedactions
frombeingexecuted.
Somedatabasesystemsprovidemechanismsforrow-levelauthorizationaswesaw
inSection4.7.7.Forexample,theOracleVirtualPrivateDatabase(VPD)allowsasys-
temadministratortoassociateafunctionwitharelation;thefunctionreturnsapredi-
catethatmustbeaddedtoanyquerythatusestherelation(differentfunctionscanbe
definedforrelationsthatarebeingupdated).Forexample,usingoursyntaxforretriev-
ingapplicationuseridentifiers,thefunctionforthetakesrelationcanreturnapredicate
suchas:

--- Page 474 ---

9.8 ApplicationSecurity 445
ID=sys context.user id()
Thispredicateisaddedtothewhereclauseofeveryquerythatusesthetakesrelation.
Asaresult(assumingthattheapplicationprogramsetstheuser idvaluetothestudent’s
ID),eachstudentcanseeonlythetuplescorrespondingtocoursesthatshetook.
As we discussed in Section 4.7.7, a potential pitfall with adding a predicate as
described above is that it may change the meaning of a query. For example, if a user
wroteaquerytofindtheaveragegradeoverallcourses,shewouldendupgettingthe
averageofhergrades,notallgrades.Althoughthesystemwouldgivethe“right”answer
for the rewritten query, that answer would not correspond to the query the user may
havethoughtshewassubmitting.
PostgreSQL and Microsoft SQLServer offer row-level authorization support with
similarfunctionalitytoOracleVPD.MoreinformationonOracleVPD andPostgreSQL
andSQLServerrow-levelauthorizationmaybefoundintheirrespectivesystemmanu-
alsavailableonline.
9.8.6 Audit Trails
An audit trail is a log of all changes (inserts, deletes, and updates) to the application
data, alongwithinformation such aswhichuser performed the changeand when the
changewasperformed.Ifapplicationsecurityisbreached,orevenifsecuritywasnot
breached,butsomeupdatewascarriedouterroneously,anaudittrailcan(a)helpfind
out what happened, and who may have carried out the actions, and (b) aid in fixing
thedamagecausedbythesecuritybreachorerroneousupdate.
For example, if a student’s grade is found to be incorrect, the audit log can be
examinedtolocatewhenandhowthegradewasupdated,aswellastofindwhichuser
carriedouttheupdates.Theuniversitycouldthenalsousetheaudittrailtotraceallthe
updatesperformedbythisuserinordertofindotherincorrectorfraudulentupdates,
andthencorrectthem.
Audittrailscanalsobeusedtodetectsecuritybreacheswhereauser’saccountis
compromisedandaccessedbyanintruder.Forexample,eachtimeauserlogsin,she
may be informed about all updates in the audit trail that were done from that login
intherecentpast; iftheuser seesanupdate thatshe didnotcarryout, itislikelythe
accounthasbeencompromised.
Itispossibletocreateadatabase-levelaudittrailbydefiningappropriatetriggerson
relationupdates(usingsystem-definedvariablesthatidentifytheusernameandtime).
However, many database systems provide built-in mechanisms to create audit trails
thataremuchmoreconvenienttouse.Detailsofhowtocreateaudittrailsvaryacross
databasesystems,andyoushouldrefertothedatabase-systemmanualsfordetails.
Database-level audit trails are usually insufficient for applications, since they are
usually unable totrack who was the end user of the application. Further, updates are
recorded at a low level, in terms of updates to tuples of a relation, rather than at a
higher level, in terms of the business logic. Applications, therefore, usually create a

--- Page 475 ---

446 Chapter9 ApplicationDevelopment
higher-levelaudittrail,recording,forexample,whatactionwascarriedout,bywhom,
when,andfromwhichIPaddresstherequestoriginated.
A related issue is that of protecting the audit trail itself from being modified or
deletedbyuserswhobreachapplicationsecurity.Onepossiblesolutionistocopythe
audit trail to a different machine, to which the intruder would not have access, with
eachrecordinthetrailcopiedassoon asitisgenerated.Amorerobustsolutionisto
useblockchaintechniques,whicharedescribedinChapter26;blockchaintechniques
storelogsinmultiplemachinesanduseahashingmechanismthatmakesitverydifficult
foranintrudertomodifyordeletedatawithoutbeingdetected.
9.8.7 Privacy
In a world where an increasing amount of personal data are available online, people
are increasingly worried about the privacy of their data. For example, most people
would want their personal medical data to be kept private and not revealed publicly.
However,themedicaldatamustbemadeavailabletodoctorsandemergencymedical
technicians who treat the patient. Many countries have laws on privacy of such data
thatdefinewhenandtowhomthedatamayberevealed.Violationofprivacylawcan
result in criminal penalties in some countries. Applications that access such private
datamustbebuiltcarefully,keepingtheprivacylawsinmind.
On the other hand, aggregated private data can play an important role in many
taskssuchasdetectingdrugsideeffects,orindetectingthespreadofepidemics.Howto
makesuchdataavailabletoresearcherscarryingoutsuchtaskswithoutcompromising
theprivacyofindividualsisanimportantreal-worldproblem.Asanexample,suppose
ahospitalhidesthenameofthepatientbutprovidesaresearcherwiththedateofbirth
and the postal code of the patient (both of which may be useful to the researcher).
Just these two pieces of information can be used to uniquely identify the patient in
manycases(usinginformationfromanexternaldatabase),compromisinghisprivacy.
Inthisparticularsituation,onesolutionwouldbetogivetheyearofbirthbutnotthe
dateofbirth,alongwiththeaddress,whichmaysufficefortheresearcher.Thiswould
notprovideenoughinformationtouniquelyidentifymostindividuals.8
As another example, web sites often collect personal data such as address, tele-
phone,email,andcredit-cardinformation.Suchinformationmayberequiredtocarry
outatransactionsuchaspurchasinganitemfromastore.However,thecustomermay
notwanttheinformationtobemadeavailabletootherorganizations,ormaywantpart
oftheinformation(suchascredit-cardnumbers)tobeerasedaftersomeperiodoftime
as a way to prevent it from falling into unauthorized hands in the event of a security
breach.Manywebsitesallowcustomerstospecifytheirprivacypreferences,andthose
websitesmustthenensurethatthesepreferencesarerespected.
8Forextremelyoldpeople,whoarerelativelyrare,eventheyearofbirthpluspostalcodemaybeenoughtouniquely
identifytheindividual,soarangeofvalues,suchas90yearsorolder,maybeprovidedinsteadoftheactualagefor
peopleolderthan90years.

--- Page 476 ---

9.9 EncryptionandItsApplications 447
9.9 Encryption and Its Applications
Encryption refers to the process of transforming data into a form that is unreadable,
unless the reverse process of decryption is applied. Encryption algorithms use an en-
cryption key to perform encryption, and they require a decryption key (which could
be the same as the encryption key, depending on the encryption algorithm used) to
performdecryption.
The oldest uses of encryption were for transmitting messages, encrypted using a
secretkeyknown onlytothesenderandtheintendedreceiver.Evenifthemessage is
interceptedbyanenemy,theenemy,notknowingthekey,willnotbeabletodecryptand
understandthemessage.Encryptioniswidelyusedtodayforprotectingdataintransit
in a variety of applications such as data transfer on the internet, and on cell-phone
networks. Encryption is also used to carry out other tasks, such as authentication, as
wewillseeinSection9.9.3.
In the context of databases, encryption is used to store data in a secure way, so
that even if the data are acquired by an unauthorized user (e.g., a laptop computer
containingthedataisstolen),thedatawillnotbeaccessiblewithoutadecryptionkey.
Many databases today store sensitive customer information, such as credit-card
numbers, names, fingerprints, signatures, and identification numbers such as, in the
United States, social security numbers. A criminal who gets access to such data can
usethemforavarietyofillegalactivities,suchaspurchasinggoodsusingacredit-card
number,orevenacquiringacreditcardinsomeoneelse’sname.Organizationssuchas
credit-card companies use knowledge of personal information as a way of identifying
who is requesting a service or goods. Leakage of such personal information allows a
criminaltoimpersonatesomeoneelseandgetaccesstoserviceorgoods;suchimper-
sonationisreferredtoasidentitytheft.Thus,applicationsthatstoresuchsensitivedata
musttakegreatcaretoprotectthemfromtheft.
To reduce the chanceof sensitive information being acquired by criminals,many
countries and states today require by law that any database storing such sensitive in-
formationmuststore theinformationinanencryptedform.Abusinessthatdoesnot
protectitsdatathuscouldbeheldcriminallyliableincaseofdatatheft.Thus,encryp-
tionisacriticalcomponentofanyapplicationthatstoressuchsensitiveinformation.
9.9.1 Encryption Techniques
There are a vast number of techniques for the encryption of data. Simple encryption
techniquesmaynotprovideadequatesecurity,sinceitmaybeeasyforanunauthorized
user to break the code. As an example of a weak encryption technique, consider the
substitutionofeachcharacterwiththenextcharacterinthealphabet.Thus,
Perryridge
becomes
Qfsszsjehf

--- Page 477 ---

448 Chapter9 ApplicationDevelopment
Ifanunauthorizeduserseesonly“Qfsszsjehf,”sheprobablyhasinsufficientinfor-
mation to break the code. However, if the intruder sees a large number of encrypted
branch names, she could use statistical data regarding the relative frequency of char-
acters to guess what substitution is being made (for example, E is the most common
letterinEnglishtext,followedbyT,A,O,N,I,andsoon).
Agoodencryptiontechniquehasthefollowingproperties:
• Itisrelativelysimpleforauthorizeduserstoencryptanddecryptdata.
• Itdependsnotonthesecrecyofthealgorithm,butratheronaparameteroftheal-
gorithmcalledtheencryptionkey,whichisusedtoencryptdata.Inasymmetric-key
encryptiontechnique,theencryptionkeyisalsousedtodecryptdata.Incontrast,
inpublic-key(alsoknownasasymmetric-key)encryptiontechniques,therearetwo
differentkeys,thepublickeyandtheprivatekey,usedtoencryptanddecryptthe
data.
• Its decryption key is extremely difficult for an intruder to determine, even if the
intruder has access to encrypted data. In the case of asymmetric-key encryption,
itisextremelydifficulttoinfertheprivatekeyevenifthepublickeyisavailable.
TheAdvancedEncryptionStandard(AES)isasymmetric-keyencryptionalgorithm
thatwasadoptedasanencryptionstandardbytheU.S.governmentin2000andisnow
widelyused.ThestandardisbasedontheRijndaelalgorithm(namedfortheinventors
V.RijmenandJ.Daemen).Thealgorithmoperatesona128-bitblockofdataatatime,
whilethekeycanbe128,192,or256bitsinlength.Thealgorithmrunsaseriesofsteps
tojumble upthebitsinadatablockinawaythatcanbereversedduringdecryption,
anditperformsanXORoperationwitha128-bit“roundkey”thatisderivedfromthe
encryptionkey.Anewroundkeyisgenerated fromtheencryptionkeyforeachblock
ofdatathatisencrypted.Duringdecryption,theroundkeysaregeneratedagainfrom
theencryptionkeyandtheencryptionprocessisreversedtorecovertheoriginaldata.
AnearlierstandardcalledtheDataEncryptionStandard (DES),adoptedin1977,was
verywidelyusedearlier.
Foranysymmetric-keyencryptionschemetowork,authorizedusersmustbepro-
vided with the encryption key via a secure mechanism. This requirement is a major
weakness, sincethe schemeisnomoresecurethanthe securityofthe mechanismby
whichtheencryptionkeyistransmitted.
Public-key encryption is an alternative scheme that avoids some of the problems
facedbysymmetric-keyencryptiontechniques.Itisbasedontwokeys:apublickeyand
aprivatekey.EachuserU hasapublickeyE andaprivatekeyD.Allpublickeysare
i i i
published:Theycanbeseenbyanyone.Eachprivatekeyisknowntoonlytheoneuser
towhomthekeybelongs.Ifuser U wantstostore encrypteddata,U encryptsthem
1 1
usingpublickeyE .DecryptionrequirestheprivatekeyD .
1 1
Becausetheencryptionkeyforeachuserispublic,itispossibletoexchangeinfor-
mation securely by this scheme. If user U wants to share data with U , U encrypts
1 2 1

--- Page 478 ---

9.9 EncryptionandItsApplications 449
the datausing E ,the public key ofU .Sinceonlyuser U knows how todecryptthe
2 2 2
data,informationcanbetransferredsecurely.
For public-key encryption to work, there must be a scheme for encryption such
thatitisinfeasible(thatis,extremelyhard)todeducetheprivatekey,giventhepublic
key.Suchaschemedoesexistandisbasedontheseconditions:
• Thereisanefficientalgorithmfortestingwhetherornotanumberisprime.
• Noefficientalgorithmisknownforfindingtheprimefactorsofanumber.
Forpurposesofthisscheme,dataaretreatedasacollectionofintegers.Wecreatea
publickeybycomputingtheproductoftwolargeprimenumbers:P andP .Theprivate
1 2
keyconsistsofthepair(P ,P ).Thedecryptionalgorithmcannotbeusedsuccessfully
1 2
ifonlytheproductP P isknown;itneedstheindividualvaluesP andP .Sinceallthat
1 2 1 2
ispublishedistheproductP P ,anunauthorizeduserwouldneedtobeabletofactor
1 2
P P to steal data. By choosing P and P to be sufficiently large (over 100 digits),
1 2 1 2
we can make the cost of factoring P P prohibitively high (on the order of years of
1 2
computationtime,oneventhefastestcomputers).
Thedetailsofpublic-keyencryptionandthemathematicaljustificationofthistech-
nique’spropertiesarereferencedinthebibliographicalnotes.
Althoughpublic-keyencryptionbythisschemeissecure,itisalsocomputationally
veryexpensive.Ahybridschemewidelyusedforsecurecommunicationisasfollows:
a symmetric encryption key (based, for example, on AES) israndomly generated and
exchanged in a secure manner using a public-key encryption scheme, and symmetric-
keyencryptionusingthatkeyisusedonthedatatransmittedsubsequently.
Encryption of small values, such as identifiersor names, is made complicated by
thepossibilityofdictionaryattacks,particularlyiftheencryptionkeyispubliclyavail-
able.Forexample,ifdate-of-birthfieldsareencrypted,anattackertryingtodecrypta
particularencrypted value ecouldtryencryptingeverypossible date ofbirth untilhe
findsonewhoseencryptedvaluematchese.Eveniftheencryptionkeyisnotpublicly
available,statisticalinformationaboutdatadistributionscanbeusedtofigureoutwhat
an encrypted value represents in some cases, such as age or address. For example, if
theage18isthemostcommonageinadatabase,theencryptedagevaluethatoccurs
mostoftencanbeinferredtorepresent18.
Dictionaryattacks can be deterred byaddingextra random bits tothe end of the
valuebeforeencryption(andremovingthemafterdecryption).Suchextrabits,referred
to as an initialization vector in AES, or as salt bits in other contexts, provide good
protectionagainstdictionaryattack.
9.9.2 Encryption Support in Databases
Many file systems and database systems today support encryption of data. Such en-
cryptionprotectsthedatafromsomeonewhoisabletoaccessthedatabutisnotable
to access the decryption key. In the case of file-system encryption, the data to be en-
cryptedareusuallylargefilesanddirectoriescontaininginformationaboutfiles.

--- Page 479 ---

450 Chapter9 ApplicationDevelopment
In the contextof databases, encryptioncan be done atseveral differentlevels.At
the lowest level, the disk blocks containing database data can be encrypted, using a
key available to the database-system software. When a block is retrieved from disk, it
isfirst decrypted and then used in the usual fashion. Such disk-block-levelencryption
protectsagainstattackerswhocan accessthediskcontentsbutdonothaveaccessto
theencryptionkey.
Atthe next higherlevel,specified (or all)attributes of arelationcan be stored in
encryptedform.Inthiscase,eachattributeofarelationcouldhaveadifferentencryp-
tion key. Many databases today support encryption at the level of specified attributes
as well as at the level of an entire relation, or all relations in a database. Encryption
of specified attributes minimizesthe overhead of decryption by allowingapplications
to encrypt only attributes that contain sensitive values such as credit-card numbers.
Encryption alsothen needstouse extrarandom bitstopreventdictionaryattacks, as
described earlier. However, databases typically do not allow primary and foreign key
attributestobeencrypted,andtheydonotsupportindexingonencryptedattributes.
A decryption key is obviously required to get access to encrypted data. A single
master encryption key may be used for all the encrypted data; with attribute level en-
cryption, differentencryption keys could be used for differentattributes. In this case,
the decryption keys for different attributes can be stored in a file or relation (often
referredtoas“wallet”),whichisitselfencryptedusingamasterkey.
Aconnectiontothedatabasethatneedstoaccessencryptedattributesmustthen
providethemasterkey;unlessthisisprovided,theconnectionwillnotbeabletoaccess
encrypteddata.Themasterkeywouldbestoredintheapplicationprogram(typically
on adifferentcomputer), ormemorizedbythedatabase user, andprovidedwhenthe
userconnectstothedatabase.
Encryptionatthedatabaselevelhastheadvantageofrequiringrelativelylowtime
andspaceoverheadanddoesnotrequiremodificationofapplications.Forexample,if
data in a laptop computer database need to be protected from theft of the computer
itself,suchencryptioncanbeused.Similarly,someonewhogetsaccesstobackuptapes
of a database would not be able to access the data contained in the backups without
knowingthedecryptionkey.
An alternative to performing encryption in the database is to perform it before
the data are sent to the database. The application must then encrypt the data before
sendingittothedatabaseanddecryptthedatawhentheyareretrieved.Thisapproach
to data encryption requires significant modifications to be done to the application,
unlikeencryptionperformedinadatabasesystem.
9.9.3 Encryption and Authentication
Password-basedauthenticationisusedwidelybyoperatingsystemsaswellasdatabase
systems.However,theuseofpasswordshassomedrawbacks,especiallyoveranetwork.
If an eavesdropper is able to “sniff” the databeing sent over the network, she may be
abletofindthepasswordasitisbeingsentacrossthenetwork.Oncetheeavesdropper

--- Page 480 ---

9.9 EncryptionandItsApplications 451
hasausernameandpassword, shecanconnecttothedatabase,pretendingtobethe
legitimateuser.
Amoresecureschemeinvolvesachallenge-responsesystem.Thedatabasesystem
sendsachallengestringtotheuser.Theuserencryptsthechallengestringusingasecret
passwordasencryptionkeyandthenreturnstheresult.Thedatabasesystemcanverify
theauthenticityoftheuserbydecryptingthestringwiththesamesecretpasswordand
checking the result with the original challenge string. This scheme ensures that no
passwordstravelacrossthenetwork.
Public-keysystemscanbeusedforencryptioninchallenge–responsesystems.The
databasesystemencryptsachallengestringusingtheuser’spublickeyandsendsitto
the user. The user decrypts the string using her private key and returns the result to
thedatabasesystem.Thedatabasesystem thencheckstheresponse.Thisschemehas
the added benefit of not storing the secret password in the database, where it could
potentiallybeseenbysystemadministrators.
Storing the private key of a user on a computer (even a personal computer) has
the risk that if the computer is compromised, the key may be revealed to an attacker
whocanthenmasqueradeastheuser.Smartcardsprovideasolutiontothisproblem.
In a smart card, the key can be stored on an embedded chip;the operating system of
thesmartcardguaranteesthatthekeycanneverberead,butitallowsdatatobesent
tothecardforencryptionordecryption,usingtheprivatekey.9
9.9.3.1 DigitalSignatures
Anotherinterestingapplicationofpublic-keyencryptionisindigitalsignaturestoverify
authenticityofdata;digitalsignaturesplaytheelectronicroleofphysicalsignatureson
documents.Theprivatekeyisusedto“sign,”thatis,encrypt,data,andthesigneddata
canbemadepublic.Anyonecanverifythesignaturebydecryptingthedatausingthe
publickey,butnoonecouldhavegeneratedthesigneddatawithouthavingtheprivate
key.(Notethereversaloftherolesofthepublicandprivatekeysinthisscheme.)Thus,
we can authenticate the data; that is, we can verify that the data were indeed created
bythepersonwhoissupposedtohavecreatedthem.
Furthermore,digitalsignaturesalsoservetoensurenonrepudiation.Thatis,incase
the person who created the data later claims she did not create them (the electronic
equivalent of claiming not to have signed the check), we can prove that that person
musthavecreatedthedata(unlessherprivatekeywasleakedtoothers).
9.9.3.2 DigitalCertificates
Authentication is, in general, a two-way process, where each of a pair of interacting
entities authenticates itself to the other. Such pairwise authentication is needed even
9Smartcardsprovideotherfunctionalitytoo,suchastheabilitytostorecashdigitallyandmakepayments,whichis
notrelevantinourcontext.

--- Page 481 ---

452 Chapter9 ApplicationDevelopment
whenaclientcontactsawebsite, topreventamalicioussite frommasquerading asa
legal web site. Such masquerading could be done, for example, ifthe networkrouters
werecompromisedanddatareroutedtothemalicioussite.
For a user to ensure that she is interacting with an authentic web site, she must
have the site’s public key. This raises the problem of how the user can get the public
key—ifitisstoredonthewebsite,themalicioussitecouldsupplyadifferentkey,and
the user would have no way of verifying if the supplied public key is itself authentic.
Authenticationcanbehandledbyasystem ofdigitalcertificates,wherebypublickeys
aresignedbyacertificationagency,whosepublickeyiswellknown.Forexample,the
publickeysoftherootcertificationauthoritiesarestoredinstandardwebbrowsers.A
certificateissuedbythemcanbeverifiedbyusingthestoredpublickeys.
Atwo-levelsystemwouldplaceanexcessiveburdenofcreatingcertificatesonthe
rootcertificationauthorities,soamultilevelsystem isusedinstead,withoneormore
root certification authorities and a tree of certification authorities below each root.
Each authority (other than the root authorities) has a digital certificate issued by its
parent.
AdigitalcertificateissuedbyacertificationauthorityAconsistsofapublickeyK
A
andanencryptedtextEthatcanbedecodedbyusingthepublickeyK .Theencrypted
A
textcontainsthenameofthepartytowhomthecertificatewasissuedandherpublic
key K . In case the certification authority A is not a root certification authority, the
c
encryptedtextalsocontainsthedigitalcertificateissuedtoAbyitsparentcertification
authority; thiscertificateauthenticates thekey K itself. (Thatcertificate mayin turn
A
containacertificatefromafurtherparentauthority,andsoon.)
To verify a certificate, the encrypted text E is decrypted by using the public key
K to retrieve the name of the party (i.e., the name of the organization owning the
A
web site); additionally, if A is not a root authority whose public key is known to the
verifier, the public key K is verified recursively by using the digital certificate con-
A
tainedwithinE;recursionterminateswhenacertificateissuedbytherootauthorityis
reached.Verifyingthecertificateestablishesthechainthroughwhichaparticularsite
wasauthenticatedandprovidesthenameandauthenticatedpublickeyforthesite.
Digitalcertificatesarewidelyusedtoauthenticatewebsitestousers,topreventma-
licioussitesfrommasqueradingasotherwebsites.IntheHTTPSprotocol(thesecure
version of the HTTP protocol), the site provides its digital certificate to the browser,
whichthen displays ittothe user. Iftheuser acceptsthecertificate,the browserthen
uses the provided public key to encrypt data. A malicious site will have access to the
certificate, but not the private key, and will thus not be able to decrypt the data sent
by thebrowser. Onlythe authenticsite, whichhas thecorrespondingprivate key, can
decryptthedatasentbythebrowser.Wenotethatpublic-/private-keyencryptionand
decryption costs are much higher than encryption/decryption costs using symmetric
privatekeys.Toreduceencryptioncosts,HTTPSactuallycreatesaone-timesymmetric
keyafterauthenticationandusesittoencryptdatafortherestofthesession.

--- Page 482 ---

9.10 Summary 453
Digitalcertificatescanalsobeusedforauthenticatingusers.Theusermustsubmit
adigitalcertificatecontainingherpublickeytoasite,whichverifiesthatthecertificate
has been signed by a trusted authority. The user’s public key can then be used in a
challenge-responsesystemtoensurethattheuserpossessesthecorrespondingprivate
key,therebyauthenticatingtheuser.
9.10 Summary
• Applicationprogramsthatusedatabasesasbackendsandinteractwithusershave
beenaroundsincethe1960s.Applicationarchitectureshaveevolvedoverthispe-
riod.Todaymostapplicationsusewebbrowsersastheirfrontend,andadatabase
astheirbackend,withanapplicationserverinbetween.
• HTMLprovidestheabilitytodefineinterfacesthatcombinehyperlinkswithforms
facilities.WebbrowserscommunicatewithwebserversbytheHTTPprotocol.Web
serverscanpassonrequeststoapplicationprogramsandreturntheresultstothe
browser.
• Web servers execute application programs to implement desired functionality.
Servlets are a widely used mechanism to write application programs that run as
partof the webserver process, inorderto reduceoverhead.Therearealso many
server-sidescriptinglanguagesthatareinterpretedbythewebserverandprovide
application-programfunctionalityaspartofthewebserver.
• There are several client-side scripting languages—JavaScript is the most widely
used—thatprovidericheruserinteractionatthebrowserend.
• Complex applications usually have a multilayer architecture, including a model
implementingbusinesslogic,acontroller,andaviewmechanismtodisplayresults.
They may also include a data access layer that implements an object-relational
mapping.Manyapplicationsimplementandusewebservices,allowingfunctions
tobeinvokedoverHTTP.
• Techniquessuch as cachingof various forms, includingquery result cachingand
connection pooling, and parallel processing are used to improve application per-
formance.
• Application developers must pay careful attention to security, to prevent attacks
suchasSQLinjectionattacksandcross-sitescriptingattacks.
• SQL authorization mechanisms are coarse grained and of limited value to appli-
cationsthatdealwithlargenumbersofusers.Todayapplicationprogramsimple-
ment fine-grained, tuple-level authorization, dealing with a large number of ap-
plication users, completely outside the database system. Database extensions to
provide tuple-level access control and to deal with large numbers of application
usershavebeendeveloped,butarenotstandardasyet.

--- Page 483 ---

454 Chapter9 ApplicationDevelopment
• Protecting the privacy of data are an important task for database applications.
Many countries have legal requirements on protection of certain kinds of data,
suchascredit-cardinformationormedicaldata.
• Encryption plays a key role in protecting information and in authentication of
usersandwebsites.Symmetric-keyencryptionandpublic-keyencryptionaretwo
contrastingbutwidelyusedapproachestoencryption.Encryptionofcertainsen-
sitivedatastoredindatabasesisalegalrequirementinmanycountriesandstates.
• Encryptionalsoplaysakeyroleinauthenticationofuserstoapplications,ofWeb
sitestousers,andfordigitalsignatures.
Review Terms
• Applicationprograms • Business-logiclayer
• Webinterfacestodatabases • Data-accesslayer
• HTML • Object-relationalmapping
• Hyperlinks • Hibernate
• Uniformresourcelocator(URL) • Django
• Forms • Webservices
• HyperTextTransferProtocol • RESTfulwebservices
(HTTP) • Webapplicationframeworks
• Connectionlessprotocols • Connectionpooling
• Cookie • Queryresultcaching
• Session • Applicationsecurity
• ServletsandServletsessions • SQLinjection
• Server-sidescripting • Cross-sitescripting(XSS)
• JavaServerPages(JSP) • Cross-siterequestforgery(XSRF)
• PHP • Authentication
• Client-sidescripting • Two-factorauthentication
• JavaScript • Man-in-the-middleattack
• DocumentObjectModel(DOM) • Centralauthentication
• Ajax • Singlesign-on
• ProgressiveWebApps • OpenID
• Applicationarchitecture • Authorization
• Presentationlayer • VirtualPrivateDatabase(VPD)
• Model-view-controller(MVC) • Audittrail
architecture

--- Page 484 ---

PracticeExercises 455
• Encryption • Challenge–response
• Symmetric-keyencryption • Digitalsignatures
• Public-keyencryption • Digitalcertificates
• Dictionaryattack
Practice Exercises
9.1 What is the main reason why servlets give better performance than programs
thatusethecommongatewayinterface(CGI),eventhoughJavaprogramsgen-
erallyrunslowerthanCorC++programs?
9.2 List some benefits and drawbacks of connectionless protocols over protocols
thatmaintainconnections.
9.3 Consideracarelesslywrittenwebapplicationforanonline-shoppingsite,which
storesthepriceofeachitemasahiddenformvariableinthewebpagesentto
the customer; when the customer submits the form, the information from the
hiddenformvariableisused tocompute thebillforthecustomer. Whatisthe
loophole in this scheme? (There was a real instance where the loophole was
exploitedbysomecustomersofanonline-shoppingsitebeforetheproblemwas
detectedandfixed.)
9.4 Consider another carelessly written web application which uses a servlet that
checks if there was an active session but does not check if the user is autho-
rizedtoaccessthatpage,insteaddependingonthefactthatalinktothepageis
shownonlytoauthorizedusers.Whatistheriskwiththisscheme?(Therewas
arealinstancewhereapplicantstoacollegeadmissionssitecould,afterlogging
intothewebsite,exploitthisloophole andviewinformationtheywerenotau-
thorizedtosee;theunauthorizedaccesswas,however,detected,andthosewho
accessedtheinformationwerepunishedbybeingdeniedadmission.)
9.5 WhyisitimportanttoopenJDBCconnectionsusingthetry-with-resources(try
(…){ … } )syntax?
9.6 List three ways in which caching can be used to speed up web server perfor-
mance.
9.7 Thenetstatcommand(availableonLinuxandonWindows)showstheactive
networkconnectionsonacomputer.Explainhowthiscommandcanbeusedto
findoutifaparticularwebpageisnotclosingconnectionsthatitopened,orif
connectionpoolingisused,notreturningconnectionstotheconnectionpool.
You should account for the fact that with connection pooling, the connection
maynotgetclosedimmediately.

--- Page 485 ---

456 Chapter9 ApplicationDevelopment
9.8 TestingforSQL-injectionvulnerability:
a. Suggestanapproachfortestinganapplicationtofindifitisvulnerableto
SQLinjectionattacksontextinput.
b. CanSQLinjectionoccurwithformsofHTMLinputotherthantextboxes?
Ifso,howwouldyoutestforvulnerability?
9.9 A database relationmayhave the values ofcertain attributes encrypted forse-
curity.Whydodatabasesystemsnotsupportindexingonencryptedattributes?
Usingyouranswertothisquestion,explainwhydatabasesystemsdonotallow
encryptionofprimary-keyattributes.
9.10 Exercise9.9addressestheproblemofencryptionofcertainattributes.However,
somedatabasesystemssupportencryptionofentiredatabases.Explainhowthe
problemsraisedinExercise9.9areavoidediftheentiredatabaseisencrypted.
9.11 Suppose someone impersonates a company and gets a certificate from a
certificate-issuing authority. What is the effect on things (such as purchase or-
dersorprograms)certifiedbytheimpersonatedcompany,andonthingscerti-
fiedbyothercompanies?
9.12 Perhapsthemostimportantdataitemsinanydatabasesystemarethepasswords
that control access to the database. Suggest a scheme for the secure storage
of passwords. Be sure that your scheme allows the system to test passwords
suppliedbyuserswhoareattemptingtologintothesystem.
Exercises
9.13 Write aservletand associatedHTMLcode for the followingvery simple appli-
cation:Auserisallowedtosubmitaformcontainingavalue,sayn,andshould
getaresponsecontainingn“*”symbols.
9.14 WriteaservletandassociatedHTMLcodeforthefollowingsimpleapplication:
Auserisallowedtosubmitaformcontaininganumber,sayn,andshouldgeta
responsesayinghowmanytimesthevaluenhasbeensubmittedpreviously.The
numberoftimeseachvaluehasbeensubmittedpreviouslyshouldbestoredin
adatabase.
9.15 Write a servlet that authenticates a user (based on user names and passwords
storedinadatabaserelation)andsetsasessionvariablecalleduserid afterau-
thentication.
9.16 What is an SQL injection attack? Explain how it works and what precautions
mustbetakentopreventSQLinjectionattacks.
9.17 Writepseudocodetomanageaconnectionpool.Yourpseudocodemustinclude
a function to create a pool (providing a database connection string, database
user name, and password as parameters), a function to request a connection

--- Page 486 ---

Exercises 457
fromthepool,aconnectiontoreleaseaconnectiontothepool,andafunction
toclosetheconnectionpool.
9.18 ExplainthetermsCRUDandREST.
9.19 ManywebsitestodayproviderichuserinterfacesusingAjax.Listtwofeatures
each of which reveals if a site uses Ajax, without having to look at the source
code. Using the above features, find three sites which use Ajax; you can view
theHTMLsourceofthepagetocheckifthesiteisactuallyusingAjax.
9.20 XSSattacks:
a. WhatisanXSSattack?
b. HowcantherefererfieldbeusedtodetectsomeXSSattacks?
9.21 What is multifactor authentication? How does it help safeguard against stolen
passwords?
9.22 Consider the Oracle Virtual Private Database (VPD) feature described in Sec-
tion9.8.5andanapplicationbasedonouruniversityschema.
a. Whatpredicate(usingasubquery)shouldbegeneratedtoalloweachfac-
ulty member to see only takes tuples corresponding to course sections
thattheyhavetaught?
b. Give an SQL query such that the query with the predicate added gives
a result that is a subset of the original query result without the added
predicate.
c. Give an SQL query such that the query with the predicate added gives
a result containing a tuple that is not in the result of the original query
withouttheaddedpredicate.
9.23 Whataretwoadvantagesofencryptingdatastoredinthedatabase?
9.24 Supposeyouwishtocreateanaudittrailofchangestothetakesrelation.
a. Definetriggerstocreateanaudittrail,loggingtheinformationintoare-
lation called, for example, takestrail. The logged information should in-
cludetheuser-id(assumeafunctionuser id()providesthisinformation)
andatimestamp,inadditiontooldandnewvalues.Youmustalsoprovide
theschemaofthetakestrail relation.
b. Cantheprecedingimplementationguaranteethatupdatesmadebyama-
licious database administrator (or someone who manages to get the ad-
ministrator’spassword)willbeintheaudittrail?Explainyouranswer.
9.25 Hackers may be able to fool you into believing that their web site is actually a
web site (such as a bank or credit card web site) that you trust. This may be
done by misleadingemail, or even by breaking into the networkinfrastructure

--- Page 487 ---

458 Chapter9 ApplicationDevelopment
and rerouting network traffic destined for, say mybank.com, to the hacker’s
site.Ifyouenteryourusernameandpasswordonthehacker’ssite,thesitecan
record it and use it later to break into your account at the real site. When you
useaURLsuchashttps://mybank.com,theHTTPSprotocolisusedtoprevent
such attacks. Explain how the protocol might use digital certificates to verify
authenticityofthesite.
9.26 Explainwhatisachallenge–responsesystemforauthentication.Whyisitmore
securethanatraditionalpassword-basedsystem?
Project Suggestions
Eachofthefollowingisalargeproject,whichcanbeasemester-longprojectdoneby
a group of students. The difficulty of the project can be adjusted easily by adding or
deletingfeatures.
Youcanchoosetouseeitherawebfront-endusingHTML5,oramobilefront-end
onAndroidoriOSforyourproject.
Project9.1 Pick your favorite interactive web site, such as Bebo, Blogger, Facebook,
Flickr,Last.FM,Twitter,Wikipedia;thesearejustafewexamples,therearemany
more. Most of these sites manage a large amount of data and use databases to
store and process the data. Implement a subset of the functionality of the web
siteyoupicked.Implementingevenasignificantsubsetofthefeaturesofsucha
siteiswellbeyondacourseproject,butitispossibletofindasetoffeaturesthat
isinterestingtoimplementyetsmallenoughforacourseproject.
Mostoftoday’spopularwebsitesmakeextensiveuseofJavascripttocreate
richinterfaces.Youmaywishtogoeasyonthisforyourproject,atleastinitially,
since ittakes time tobuild such interfaces, and then addmore features to your
interfaces,astimepermits.
Make use of web application development frameworks, or Javascript libraries
availableon theweb,suchasthejQuerylibrary,tospeed up yourfront-end de-
velopment.Alternatively,implementtheapplicationasamobileapponAndroid
oriOS.
Project9.2 Create a “mashup” which uses web services such as Google or Yahoo
map APIsto create an interactive web site. Forexample, the map APIsprovide
awaytodisplayamaponthewebpage,withotherinformationoverlaidonthe
maps. You could implement a restaurant recommendation system, with users
contributinginformationaboutrestaurantssuchaslocation,cuisine,pricerange,
andratings.Resultsofusersearchescouldbedisplayedonthemap.Youcould
allowWikipedia-likefeatures,suchasallowinguserstoaddinformationandedit

--- Page 488 ---

ProjectSuggestions 459
information added by other users, along with moderators who can weed out
maliciousupdates.Youcouldalsoimplementsocialfeatures,suchasgivingmore
importancetoratingsprovidedbyyourfriends.
Project9.3 Youruniversityprobablyusesacourse-managementsystemsuchasMoo-
dle, Blackboard, or WebCT. Implement a subset of the functionality of such a
course-management system. For example, you can provide assignment submis-
sion and grading functionality, including mechanisms for students and teach-
ers/teachingassistantstodiscussgradingofaparticularassignment.Youcould
alsoprovidepollsandothermechanismsforgettingfeedback.
Project9.4 ConsidertheE-RschemaofPracticeExercise6.3(Chapter6),whichrep-
resentsinformationaboutteamsinaleague.Designandimplementaweb-based
systemtoenter,update,andviewthedata.
Project9.5 Design and implementa shopping cart system that lets shoppers collect
items into a shopping cart (you can decide what information is to be supplied
foreachitem)andpurchasedtogether.YoucanextendandusetheE-Rschema
ofExercise6.21ofChapter6.Youshouldcheckforavailabilityoftheitemand
dealwithnonavailableitemsasyoufeelappropriate.
Project9.6 Designandimplementaweb-basedsystem torecordstudentregistration
andgradeinformationforcoursesatauniversity.
Project9.7 Design and implementa system thatpermits recordingof course perfor-
manceinformation—specifically,themarksgiventoeachstudentineachassign-
ment or exam of a course, and computation of a (weighted) sum of marks to
get the total course marks. The number of assignments/exams should not be
predefined;thatis,moreassignments/examscanbeaddedatanytime.Thesys-
tem should also support grading, permitting cutoffs to be specified for various
grades.
You may also wish to integrate it with the student registration system of
Project9.6(perhapsbeingimplementedbyanotherprojectteam).
Project9.8 Designandimplementaweb-basedsystemforbookingclassroomsatyour
university.Periodicbooking(fixeddays/timeseachweekforawholesemester)
mustbesupported.Cancellationofspecificlecturesinaperiodicbookingshould
alsobesupported.
You may also wish to integrate it with the student registration system of
Project9.6(perhapsbeingimplementedbyanotherprojectteam)sothatclass-
rooms can be booked for courses, and cancellationsof a lecture or addition of
extralecturescanbenotedatasingleinterfaceandwillbereflectedintheclass-
roombookingandcommunicatedtostudentsviaemail.

--- Page 489 ---

460 Chapter9 ApplicationDevelopment
Project9.9 Designandimplementasystemformanagingonlinemultiple-choicetests.
Youshouldsupportdistributedcontributionofquestions(byteachingassistants,
for example), editing of questions by whoever is in charge of the course, and
creation of tests from the available set of questions. You should also be able
to administer tests online, either at a fixed time for all students or at any time
butwithatimelimitfromstarttofinish(support oneorboth),andthesystem
shouldgivestudentsfeedbackontheirscoresattheendoftheallottedtime.
Project9.10 Design and implement a system for managing email customer service.
Incomingmailgoestoacommonpool.Thereisasetofcustomerserviceagents
who reply to email. If the email is part of an ongoing series of replies (tracked
using the in-reply-to field of email) the mail should preferably be replied to by
the same agent who replied earlier. The system should track all incoming mail
andreplies,soanagentcanseethehistoryofquestionsfromacustomerbefore
replyingtoanemail.
Project9.11 Designandimplementasimpleelectronicmarketplacewhereitemscan
belistedforsaleorforpurchaseundervariouscategories(whichshouldforma
hierarchy). You may also wish to support alerting services, wherebya user can
registerinterestinitemsinaparticularcategory,perhapswithotherconstraints
as well, without publicly advertising her interest, and is notified when such an
itemislistedforsale.
Project9.12 Design and implement a web-based system for managing a sports “lad-
der.” Many people register and may be given some initial rankings (perhaps
basedonpastperformance).Anyonecanchallengeanyoneelsetoamatch,and
therankingsareadjusted accordingtotheresult.Onesimplesystem foradjust-
ingrankingsjustmovesthewinneraheadoftheloserintherankorder,incase
the winner was behind earlier. You can try to invent more complicated rank-
adjustmentsystems.
Project9.13 Design and implement a publication-listing service. The service should
permit entering of information about publications, such as title, authors, year,
wherethepublicationappeared,andpages.Authorsshouldbeaseparateentity
withattributessuchasname,institution,department,email,address,andhome
page.
Your application should support multiple views on the same data. For in-
stance,youshouldprovideallpublicationsbyagivenauthor(sortedbyyear,for
example),orallpublicationsbyauthorsfromagiveninstitutionordepartment.
Youshouldalsosupport searchbykeywords, ontheoveralldatabaseaswellas
withineachoftheviews.
Project9.14 Acommontaskinanyorganizationistocollectstructuredinformation
fromagroupofpeople.Forexample,amanagermayneedtoaskemployeesto
entertheirvacationplans,aprofessormaywishtocollectfeedbackonaparticu-

--- Page 490 ---

ProjectSuggestions 461
lartopicfromstudents,orastudentorganizinganeventmaywishtoallowother
students to register for the event, or someone may wish to conduct an online
vote on some topic. Google Forms can be used for such activities; your task is
to create something like Google Forms, but with authorization on who can fill
aform.
Specifically,createasystemthatwillallowuserstoeasilycreateinformation
collectionevents.Whencreatinganevent,theeventcreatormustdefinewhois
eligibletoparticipate;todoso,yoursystemmustmaintainuserinformationand
allow predicatesdefiningasubset of users. The eventcreatorshould be able to
specifyasetofinputs(withtypes,defaultvalues,andvalidationchecks)thatthe
userswillhavetoprovide.Theeventshouldhaveanassociateddeadline,andthe
systemshouldhavetheabilitytosendreminderstouserswhohavenotyetsub-
mittedtheirinformation.Theeventcreatormaybegiventheoptionofautomatic
enforcementofthedeadlinebasedonaspecifieddate/time,orchoosingtologin
anddeclarethedeadlineisover.Statisticsaboutthesubmissionsshouldbegen-
erated—to doso, the eventcreatormay be allowedto create simple summaries
ontheenteredinformation.Theeventcreatormaychoosetomakesomeofthe
summariespublic,viewablebyallusers,eithercontinually(e.g.,howmanypeo-
ple have responded) or after the deadline (e.g., what was the average feedback
score).
Project9.15 Create a library of functions to simplify creation of web interfaces, us-
ing jQuery. You must implement at least the following functions: a function to
displayaJDBCresultset(withtabularformatting),functionstocreatedifferent
typesoftextandnumericinputs(withvalidationcriteriasuchasinputtypeand
optionalrange,enforcedattheclientbyappropriateJavaScriptcode),andfunc-
tionstocreatemenuitemsbasedonaresultset.Alsoimplementfunctionstoget
inputforspecifiedfieldsofspecifiedrelations,ensuringthatdatabaseconstraints
suchastypeandforeign-keyconstraintsareenforcedattheclientside.Foreign
key constraints can also be used to provide either autocomplete or drop-down
menus,toeasethetaskofdataentryforthefields.
Forextracredit,usesupportCSSstyleswhichallowtheusertochangestyle
parameters such as colors and fonts. Build a sample database application to
illustratetheuseofthesefunctions.
Project9.16 Design andimplementaweb-basedmultiusercalendarsystem. The sys-
temmusttrackappointmentsforeachperson,includingmultioccurrenceevents,
suchasweeklymeetings,andsharedevents(whereanupdatemadebytheevent
creator gets reflected to all those who share the event). Provide interfaces to
schedule multiuser events, where an event creator can add a number of users
whoareinvitedtotheevent.Provideemailnotificationofevents.Forextracred-
itsimplementawebservicethatcanbeusedbyareminderprogramrunningon
theclientmachine.

--- Page 491 ---

462 Chapter9 ApplicationDevelopment
Tools
There are several integrated development environments that provide support for web
application development. Eclipse (www.eclipse.org) and Netbeans (netbeans.org)
are popular open-source IDEs. IntelliJ IDEA (www.jetbrains.com/idea/) is
a popular commercial IDE which provides free licenses for students, teach-
ers and non-commercial open source projects. Microsoft’s Visual Studio
(visualstudio.microsoft.com) also supports web application development. All
these IDEs support integration with application servers, to allow web applications to
beexecuteddirectlyfromtheIDE.
The Apache Tomcat (jakarta.apache.org), Glassfish
(javaee.github.io/glassfish/), JBoss Enterprise Application Platform
(developers.redhat.com/products/eap/overview/), WildFly (wildfly.org) (which is
the communityedition of JBoss) and Caucho’s Resin (www.caucho.com), are appli-
cation servers that support servlets and JSP. The Apache web server (apache.org) is
themostwidelyusedwebservertoday.Microsoft’sIIS(InternetInformationServices)
is a web and application server that is widelyused on Microsoft Windows platforms,
supportingMicrosoft’sASP.NET(msdn.microsoft.com/asp.net/).
The jQuery JavaScript library jquery.com is among the most widely used
JavaScriptlibrariesforcreatinginteractivewebinterfaces.
Android Studio (developer.android.com/studio/) is a widely used IDE for de-
velopingAndroidapps.XCode(developer.apple.com/xcode/)fromAppleandApp-
Code(www.jetbrains.com/objc/)arepopularIDEsforiOSapplicationdevelopment.
Google’sFlutterframework(flutter.io),whichisbasedontheDartlanguage,andFace-
book’sReactNative(facebook.github.io/react-native/)whichisbasedonJavascript,
are frameworks that support cross-platform application development across Android
andiOS.
The Open Web Application Security Project (OWASP) (www.owasp.org) pro-
videsavarietyofresourcesrelatedtoapplicationsecurity,includingtechnicalarticles,
guides,andtools.
Further Reading
The HTML tutorials at www.w3schools.com/html, the CSS tutorials at
www.w3schools.com/css are good resources for learning HTML and CSS. A tutorial
on Java Servlets can be found at docs.oracle.com/javaee/7/tutorial/servlets.htm.
TheJavaScripttutorialsatwww.w3schools.com/jsareanexcellentsourceoflearning
material on JavaScript. You can also learn more about JSON and Ajax as part of the
JavaScripttutorial.ThejQuerytutorialatwww.w3schools.com/Jqueryisaverygood
resource for learning how to use jQuery. These tutorials allow you to modify sample
code and test it in the browser, with no software download. Information about the

--- Page 492 ---

FurtherReading 463
.NETframeworkandaboutwebapplicationdevelopmentusingASP.NETcanbefound
atmsdn.microsoft.com.
You can learn more about the Hibernate ORM and Django (including the
Django ORM) from the tutorials and documentation at hibernate.org/orm and
docs.djangoproject.comrespectively.
TheOpenWebApplicationSecurityProject(OWASP)(www.owasp.org)provides
avarietyoftechnicalmaterialsuchastheOWASPTestingGuide,theOWASPTopTen
documentwhichdescribescriticalsecurityrisks,andstandardsforapplicationsecurity
verification.
Theconceptsbehindcryptographichashfunctionsandpublic-keyencryptionwere
introducedin[DiffieandHellman(1976)]and[Rivestetal.(1978)].Agoodreference
for cryptography is [Katz and Lindell (2014)], while [Stallings (2017)] provides text-
bookcoverageofcryptographyandnetworksecurity.
Bibliography
[DiffieandHellman(1976)] W. Diffie and M. E. Hellman, “New Directions in Cryptogra-
phy”,IEEETransactionsonInformationTheory,Volume22,Number6(1976),pages644–
654.
[KatzandLindell(2014)] J. Katz and Y. Lindell, Introduction to Modern Cryptography, 3rd
edition,ChapmanandHall/CRC(2014).
[Rivestetal.(1978)] R. L. Rivest, A. Shamir, and L. Adleman, “A Method for Obtaining
DigitalSignaturesandPublic-KeyCryptosystems”,CommunicationsoftheACM,Volume21,
Number2(1978),pages120–126.
[Stallings(2017)] W. Stallings, Cryptography and Network Security - Principles and Practice,
7thedition,Pearson(2017).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 494 ---

4
PART
BIG DATA ANALYTICS
Traditionalapplicationsofrelationaldatabasesarebasedonstructureddataandthey
deal withdatafrom asingle enterprise. Modern data managementapplicationsoften
need to deal with data that are not necessarily in relational form; further, such appli-
cations also need to deal with volumes of data that are far larger than what a single
traditionalorganizationwouldhavegenerated.InChapter10,westudytechniquesfor
managing such data, often referred to as Big Data. Our coverage of Big Data in this
chapterisfromtheperspectiveofaprogrammerwhousesBigDatasystems.Westart
with storage systems for Big Data, and then cover querying techniques, includingthe
MapReduceframework,algebraicoperations,steamingdata,andgraphdatabases.
One major application of Big Data is data analytics, which refers broadly to the
processingofdatatoinferpatterns,correlations,ormodelsforprediction.Thefinancial
benefits of making correct decisions can be substantial, as can the costs of making
wrongdecisions.Organizationsthereforemakesubstantialinvestmentsbothtogather
or purchase required data and to build systems for data analytics. In Chapter 11, we
cover data analytics in general and, in particular, decision-making tasks that benefit
greatlybyusing dataabout the past topredictthe future and using the predictionsto
makedecisions.Topicscoveredincludedatawarehousing,onlineanalyticalprocessing,
anddatamining.
465

--- Page 496 ---

10
CHAPTER
Big Data
Traditionalapplicationsofrelationaldatabasesarebasedonstructureddata,andthey
deal withdatafrom asingle enterprise. Modern data managementapplicationsoften
need to deal with data that are not necessarily in relational form; further, such appli-
cations also need to deal with volumes of data that are far larger than what a single
enterprisewouldgenerate.Westudytechniquesformanagingsuchdata,oftenreferred
toasBigData,inthischapter.
10.1 Motivation
The growth of the World Wide Web in the 1990s and 2000s resulted in the need to
storeandquerydatawithvolumesthatfarexceededtheenterprisedatathatrelational
databasesweredesignedtomanage.Althoughmuchoftheuser-visibledataontheweb
intheearlydayswasstatic,websitesgeneratedaverylargeamountofdataaboutusers
whovisitedtheirsites,whatwebpagestheyaccessed,andwhen.Thesedataweretypi-
callystoredonlogfilesonthewebserver,intextualform.Peoplemanagingwebsites
soonrealizedthattherewasawealthofinformationintheweblogsthatcouldbeused
by companies to understand more about theirusers and to target advertisements and
marketing campaigns at users. Such information included details of which pages had
beenaccessedbyusers,whichcouldalsobelinkedwithuserprofiledata,suchasage,
gender,incomelevel,andsoon,thatwerecollectedbymanywebsites.Transactional
web sites such as shopping sites had other kinds of data as well, such as what prod-
uctsauserhadbrowsedorpurchased.The2000ssawexceptionallylargegrowthinthe
volumeofuser-generateddata,inparticularsocial-mediadata.
The volume of such data soon grew well beyond the scale that could be handled
by traditional database systems, and both storage and processing require a very high
degree of parallelism. Furthermore, much of the data were in textual form such as
log records, or in other semi-structured forms that we saw in Chapter 8. Such data,
are characterized by their size, speed at which they are generated, and the variety of
formats,aregenericallycalledBigData.
467

--- Page 497 ---

468 Chapter10 BigData
BigDatahasbeencontrastedwithtraditionalrelationaldatabasesonthefollowing
metrics:
• Volume:Theamountofdatatobestoredandprocessedismuchlargerthantradi-
tionaldatabases,includingtraditionalparallelrelationaldatabases,weredesigned
tohandle.Althoughthereisalonghistoryofparalleldatabasesystems,earlygen-
eration parallel databases were designed to work on tens to a few hundreds of
machines.Incontrast,someofthenewapplicationsrequiretheuseofthousands
ofmachinesinparalleltostoreandprocessthedata.
• Velocity: The rate of arrival of data are much higher in today’s networked world
than in earlier days. Data management systems must be able to ingest and store
dataatveryhighrates.Further,manyapplicationsneeddataitemstobeprocessed
as theyarrive, in orderto detectand respond quicklyto certain events(such sys-
tems are referred to a streaming data systems). Thus, processing velocity is very
importantformanyapplicationstoday.
• Variety: The relational representation of data, relational query languages, and re-
lationaldatabasesystemshavebeenverysuccessfuloverthepastseveraldecades,
andtheyformthecoreofthedatarepresentationofmostorganizations.However,
clearly,notalldataarerelational.
As we saw in Chapter 8, a variety of data representations are used for differ-
ent purposes today. While much of today’s data can be efficiently represented in
relational form, there are many data sources that have other forms of data, such
as semi-structured data, textual data, and graph data. The SQL query language is
well suited to specifying a variety of queries on relational data, and it has been
extendedtohandlesemi-structureddata.However,manycomputationscannotbe
easilyexpressedinSQLorefficientlyevaluatedifrepresentedusingSQL.
Anewgeneration oflanguagesandframeworks hasbeendevelopedforspeci-
fyingandefficientlyexecutingcomplexqueriesonnewformsofdata.
WeshallusethetermBigDatainagenericsense,torefertoanydata-processing
needthatrequiresahighdegreeofparallelismtohandle,regardlessofwhetherthedata
arerelationalorotherwise.
Overthepastdecade,severalsystemshavebeendevelopedforstoringandprocess-
ingBigData,usingverylargeclustersofmachines,withthousands,orinsomecases,
tensofthousandsofmachines.Thetermnodeisoftenusedtorefertoamachineina
cluster.
10.1.1 Sources and Uses of Big Data
The rapid growth of the web was the key driver for the enormous growth of data vol-
umesinthelate1990sandearly2000s.Theinitialsourcesofdatawerelogsfromweb
serversoftware,whichrecordeduserinteractionswiththewebservers.Witheachuser

--- Page 498 ---

10.1 Motivation 469
clickingonmultiplelinkseachday,andhundredsofmillionsofusers,whichlatergrew
to billions of users, the large web companies found they weregenerating multiple ter-
abytesofdataeachday.Webcompaniessoonrealizedthattherewasalotofimportant
informationintheweblogs,whichcouldbeusedformultiplepurposes,suchasthese:
• Decidingwhatposts,news,andotherinformationtopresenttowhichuser,tokeep
themmoreengagedwiththesite.Informationonwhattheuserhadviewedearlier,
as well as information on what other users with similar preferences had viewed,
arekeytomakingthesedecisions.
• Decidingwhatadvertisementstoshowtowhichusers,tomaximizethebenefitto
the advertiser, while also ensuring the advertisements that a user sees are more
likelytobeofrelevancetotheuser.Again,informationonwhatpagesauserhad
visited, or what advertisements a user had clicked on earlier, are key to making
suchdecisions.
• Deciding how a web site should be structured, to make it easy for most users to
findinformationthattheyarelookingfor.Knowingtowhatpagesuserstypically
navigate, and what page they typically view after visitinga particular page, is key
tomakingsuchdecisions.
• Determining user preferences and trends based on page views, which can help
a manufacturer or vendor decide what items to produce or stock more of, and
whatto produce or stock less of. This ispart of amore general topic of business
intelligence.
• Advertisement display and click-through information. A click-through refers to a
user clicking on an advertisement to get more information, and is a measure of
the success of the advertisement in getting user attention. A conversion occurs
whentheuseractuallypurchasestheadvertisedproductorservice.Websitesare
often paid when a click-through or conversion occurs. This makes click-through
andconversionratesfordifferentadvertisementsakeymetricforasitetodecide
whichadvertisementstodisplay.
Today, there are many other sources of very high-volume data. Examples include
thefollowing:
• Data from mobile phone apps that help in understanding user interaction with
the app, in the same way that clicks on a web site help in understanding user
interactionwiththewebsite.
• Transaction data from retain enterprises (both online and offline). Early users
of very large volumes of data included large retail chains such as Walmart, who
usedparalleldatabasesystemsevenintheyearsprecedingtheweb,tomanageand
analyzetheirdata.

--- Page 499 ---

470 Chapter10 BigData
• Datafromsensors.High-endequipmenttodaytypicallyhasalargenumberofsen-
sorstomonitorthehealthoftheequipment.Collectingsuchdatacentrallyhelps
to track status and predict the chances of problems with the equipment, helping
fix problems before they result in failure. The increasing use of such sensors to
the connection of sensors and other computing devices embedded within other
objectssuch as vehicles,buildings,machinery,and soforth tothe internet,often
referredtoastheinternetofthings.Thenumberofsuchdevicesisnowmorethan
thenumberofhumansontheinternet.
• Metadata from communication networks, including traffic and other monitoring
informationfordatanetworks,andcallinformationforvoicenetworks.Suchdata
are important for detecting potential problems before they occur, for detecting
problemsastheyoccur,andforcapacityplanningandotherrelateddecisions.
The amount of data stored in databases has been growing rapidly for multiple
decades,wellbeforethetermBigDatacameintouse.Buttheextremelyrapidgrowth
ofthewebcreatedaninflectionpoint,withthemajorwebsiteshavingtohandledata
generated by hundreds of millions to billions of users; this was a scale significantly
greaterthanmostoftheearlierapplications.
Evencompaniesthatarenotwebrelatedhavefounditnecessarytodealwithvery
large amounts of data. Many companies procure and analyze large volumes of data
generatedbyothercompanies.Forexample,websearchhistoriesannotatedwithuser
profile information, have become available to many companies, which can use such
informationtomakeavarietyofbusinessdecisions,suchasplanningadvertisingcam-
paigns,planningwhatproductstomanufactureandwhen,andsoon.
Companiestodayfinditessentialtomakeuseofsocialmediadatatomakebusiness
decisions.Reactionstonewproductlaunchesbyacompany,orachangeinexistingof-
ferings can be found on Twitter and other social media sites. Not only is the volume
of data on social media sites such as Twitter very high, but the data arrives at a very
highvelocity,andneedstobeanalyzedandrespondedtoveryquickly.Forexample,if
acompanyputsoutanadvertisement,andthereisstrongnegativereactiononTwitter,
thecompanywouldwanttodetecttheissuequickly,andperhapsstopusingtheadver-
tisement before there is too much damage. Thus, Big Data has become a key enabler
foravarietyofactivitiesofmanyorganizationstoday.
10.1.2 Querying Big Data
SQLisbyfarthemostwidelyusedlanguageforqueryingrelationaldatabases.However,
thereisawidervarietyofquerylanguageoptionsforBigDataapplications,drivenby
the need to handle more variety of data types, and by the need to scale to very large
datavolumes/velocity.
Building data management systems that can scale to a large volume/velocity of
data requires parallel storage and processing of data. Building a relational database
thatsupportsSQLalongwithotherdatabasefeatures,suchastransactions(whichwe

--- Page 500 ---

10.1 Motivation 471
study later in Chapter 17), and at the same time can support very high performance
by running on a very large number of machines, is not an easy task. There are two
categoriesofsuchapplications:
1. Transaction-processing systems that need very high scalability : Transaction-
processingsystemssupportalargenumberofshortrunningqueriesandupdates.
Itismucheasierforadatabasedesignedtosupporttransactionprocessingto
scaletoverylargenumbersofmachinesiftherequirementstosupportallfeatures
ofarelationaldatabasearerelaxed.Conversely,manytransaction-processingap-
plications that need to scale to very high volumes/velocity can manage without
fulldatabasesupport.
Theprimarymodeofdataaccessforsuchapplicationsistostoredatawithan
associatedkey,andtoretrievedatawiththatkey;suchastoragesystemiscalleda
key-valuestore.Intheprecedinguserprofileexample,thekeyforuser-profiledata
would be the user’s identifier. There are applications that conceptually require
joins but implement the joins either in application code or by a form of view
materialization.
Forexample,inasocial-networkingapplication,whenauserconnectstothe
system, the user should be shown new posts from all her friends. If the data
about posts and friends is maintained in relational format, this would require
a join. Suppose that instead, the system maintains an object for each user in a
key-valuestore,containingtheirfriendinformationaswellastheirposts.Instead
of a join done in the database, the application code could implement the join
by first finding the set of friends of the user, and then querying the data object
of each friend to find their posts. Another alternative is as follows: whenever a
useru makesapost,foreachfriendu oftheuser,amessageissenttothedata
0 i
objectrepresentingu,andthedataassociatedwiththefriendareupdatedwitha
i
summaryofthenewpost.Whenthatuseru checksforupdates,alldatarequired
i
toprovideasummaryviewofpostsbyfriendsareavailableinoneplaceandcan
beretrievedquickly.
Therearetrade-offsbetweenthetwoalternatives,suchashighercostatquery
timeforthefirstalternative,versushigherstoragecostandhighercostatthetime
of writes for the second alternative.1But both approaches allow the application
tocarryoutitstaskswithoutsupportforjoinsinthekey-valuestoragesystem.
2. Query processing systems that need very high scalability, and need to support non-
relationaldata:Typicalexamplesofsuchsystems arethosedesignedtoperform
analysisonlogsgeneratedbywebserversandotherapplications.Otherexamples
include document and knowledge storage and indexing systems, such as those
thatsupportkeywordsearchontheweb.
1Itisworthmentioningthatitappears(basedonlimitedpubliclyavailableinformationasof2018)thatFacebookuses
thefirstalternativeforitsnewsfeedtoavoidthehighstorageoverheadofthesecondalternative.

--- Page 501 ---

472 Chapter10 BigData
The data consumed by many such applications are stored in multiple files. A
system designed to support such applications first needs to be able to store a
large numberof large files.Second,itmustbe ableto support parallel querying
ofdatastoredinsuchfiles.Sincethedataarenotnecessarilyrelational,asystem
designed for querying such data must support arbitrary program code, not just
relationalalgebraorSQLqueries.
BigDataapplicationsoftenrequireprocessingofverylargevolumesoftext,image,
andvideodata.Traditionallysuchdatawerestoredinfilesystemsandprocessedusing
stand-aloneapplications.Forexample,keywordsearchontextualdata,anditssucces-
sor,keywordsearchontheweb,bothdependonpreprocessingtextualdata,followedby
query processing using data structures such as indices built during the preprocessing
step.ItshouldbeclearthattheSQLconstructswehaveseenearlierarenotsuitedfor
carryingoutsuchtasks,sincetheinputdataarenotinrelationalform,andtheoutput
toomaynotbeinrelationalform.
Inearlierdays,processingofsuchdatawasdoneusingstand-aloneprograms;thisis
verysimilartohoworganizationaldatawereprocessedpriortotheadventofdatabase
managementsystems.However,withtheveryrapidgrowthofdatasizes,thelimitations
ofstand-aloneprogramsbecameclear.Parallelprocessingiscriticalgiventheverylarge
scaleofBigData.Writingprogramsthatcanprocessdatainparallelwhiledealingwith
failures(whicharecommonwithlargescaleparallelism)isnoteasy.
Inthischapter,westudytechniquesforqueryingofBigDatathatarewidelyused
today.Akeytothesuccessofthesetechniquesisthefactthattheyallowspecificationof
complexdataprocessingtasks, whileenablingeasyparallelizationofthetasks. These
techniquesfreetheprogrammerfromhavingtodealwithissuessuchashowtoperform
parallelization, how to deal with failures, how to deal with load imbalances between
machines,andmanyothersimilarlow-levelissues.
10.2 Big Data Storage Systems
ApplicationsonBigDatahaveextremelyhighscalabilityrequirements.Popularappli-
cationshavehundredsofmillionsofusers,andmanyapplicationshaveseentheirload
increase many-fold within a single year, or even within a few months. To handle the
data management needs of such applications, data must be stored partitioned across
thousandsofcomputingandstoragenodes.
AnumberofsystemsforBigDatastoragehavebeendevelopedanddeployedover
the past two decades to address the data management requirements of such applica-
tions.Theseincludethefollowing:
• Distributed File Systems. These allow files to be stored across a number of ma-
chines,whileallowingaccesstofilesusingatraditionalfile-system interface.Dis-
tributed file systems are used to store large files, such as log files. They are also
usedasastoragelayerforsystemsthatsupportstorageofrecords.

--- Page 502 ---

10.2 BigDataStorageSystems 473
• Sharding across multiple databases. Sharding refers to the process of partition-
ingofrecordsacrossmultiplesystems;inotherwords,therecordsaredividedup
among the systems. A typical use case for sharding is to partition records corre-
sponding to different users across a collection of databases. Each database is a
traditional centralized database, which may not have any information about the
other databases. It is the job of client software to keep track of how records are
partitioned,andtosendeachquerytotheappropriatedatabase.
• Key-Value Storage Systems. These allow records to be stored and retrieved based
onakey,and mayadditionallyprovidelimitedqueryfacilities.However,theyare
notfull-fledgeddatabasesystems;theyaresometimescalledNoSQLsystems,since
suchstoragesystemstypicallydonotsupporttheSQLlanguage.
• ParallelandDistributedDatabases.Theseprovideatraditionaldatabaseinterface
but store data across multiple machines, and they perform query processing in
parallelacrossmultiplemachines.
Parallelanddistributeddatabasestoragesystems,includingdistributedfilesystemsand
key-valuestores,aredescribedindetailinChapter21.Weprovideauser-leveloverview
oftheseBigDatastoragesystemsinthissection.
10.2.1 Distributed File Systems
Adistributedfilesystemstoresfilesacrossalargecollectionofmachineswhilegivinga
single-file-systemviewtoclients.Aswithanyfilesystem,thereisasystemoffilenames
anddirectories,whichclientscanusetoidentifyandaccessfiles.Clientsdonotneed
tobotheraboutwherethefilesarestored.Suchdistributedfilesystemscanstorevery
large amounts of data, and support very large numbers of concurrent clients. Such
systems are ideal for storing unstructured data, such as web pages, web server logs,
images,andsoon,thatarestoredaslargefiles.
AlandmarksysteminthiscontextwastheGoogleFileSystem(GFS),developed
intheearly2000s,whichsawwidespreadusewithinGoogle.Theopen-sourceHadoop
FileSystem(HDFS)isbasedontheGFSarchitectureandisnowverywidelyused.
Distributedfilesystemsaredesignedforefficientstorageoflargefiles,whosesizes
rangefromtensofmegabytestohundredsofgigabytesormore.
Thedatainadistributedfilesystemisstoredacrossanumberofmachines.Filesare
brokenupintomultipleblocks.Theblocksofasinglefilecanbepartitionedacrossmul-
tiple machines. Further, each file block is replicated across multiple (typically three)
machines,sothatamachinefailuredoesnotresultinthefilebecominginaccessible.
Filesystems,whethercentralizedordistributed,typicallysupportthefollowing:
• Adirectorysystem, whichallowsahierarchicalorganization of filesintodirecto-
riesandsubdirectories.
• Amappingfromafilenametothesequenceofidentifiersofblocksthatstorethe
actualdataineachfile.

--- Page 503 ---

474 Chapter10 BigData
• Theabilitytostoreandretrievedatato/fromablockwithaspecifiedidentifier.
In the case of a centralized file system, the block identifiers help locate blocks in a
storagedevicesuchasadisk.Inthecaseofadistributedfilesystem,inadditiontopro-
vidingablockidentifier,thefilesystemmustprovidethelocation(machineidentifier)
where the block is stored; in fact, due to replication, the file system provides a set of
machineidentifiersalongwitheachblockidentifier.
Figure 10.1 shows the architecture of the Hadoop File System (HDFS), which is
derived from the architecture of the Google File System (GFS ). The core ofHDFS is
NameNode
Metadata (name, replicas, ..)
Metadata Ops
BackupNode
Metadata (name, replicas, ..)
Client
Block Read
DataNodes
Blocks
Client
Block Write
Replication
Rack 1 Rack 2
Figure 10.1 HadoopDistributedFileSystem(HDFS)architecture.

--- Page 504 ---

10.2 BigDataStorageSystems 475
a server running a machine referred to as the NameNode. All file system requests are
sent to the NameNode. A file system client program that wants to read an existing
filesends thefilename (whichcanbe apath, such as/home/avi/book/ch10 ) to the
NameNode.TheNameNodestoresalistofblockidentifiersoftheblocksineachfile;
for each block identifier, the NameNode also stores the identifiers of machines that
store copies of that block. The machines that store data blocks in HDFS are called
DataNodes.
For a file read request, the HDFS server sends back a list of block identifiers of
theblocksinthefileandtheidentifiersofthemachinesthatcontaineachblock.Each
blockisthenfetchedfromoneofthemachinesthatstoreacopyoftheblock.
For a file write, the HDFS server creates new block identifiers and assigns each
block identifier to several (usually three) machines, and returns the block identifiers
andmachineassignmenttotheclient.Theclientthensendstheblockidentifiersand
blockdatatotheassignedmachines,whichstorethedata.
FilescanbeaccessedbyprogramsbyusingHDFSfilesystemAPIsthatareavailable
in multiple languages, such as Javaand Python; theAPIsallow aprogram to connect
totheHDFSserverandaccessdata.
AnHDFSdistributed filesystem canalsobe connectedtothelocalfilesystem of
amachineinsuchawaythatfilesinHDFScanbeaccessedasthoughtheyarestored
locally. This requires providing the address of the NameNode machine, and the port
on which the HDFS server listens for requests, to the local file system. The local file
system recognizeswhichfile accessesare tofilesinHDFS based on the filepath, and
sendsappropriaterequeststotheHDFSserver.
MoredetailsaboutdistributedfilesystemimplementationmaybefoundinSection
21.6.
10.2.2 Sharding
Asingledatabasesystemtypicallyhassufficientstorageandperformancetohandleall
thetransactionprocessingneedsofanenterprise.However,usingasingledatabaseis
notsufficientforapplicationswithmillionsoreven billionsof users,includingsocial-
media or similar web-scale applications, but also the user-facing applications of very
largeorganizationssuchaslargebanks.
Supposeanorganizationhasbuiltanapplicationwithacentralizeddatabase,but
needs to scale to handle more users, and the centralized database is not capable of
handlingthestorageorprocessingspeedrequirements.Acommonlyusedwaytodeal
withsuchasituationistopartitionthedataacrossmultipledatabases,withasubsetof
usersassignedtoeachofthedatabases.Thetermshardingreferstothepartitioningof
dataacrossmultipledatabasesormachines.
Partitioning is usually done on one or more attributes, referred to as partitioning
attributes, partitioning keys , orshard keys. User or account identifiers are commonly
usedaspartitioningkeys.Partitioningcanbedonebydefiningarangeofkeysthateach
ofthedatabaseshandles;forexample,keysfrom1to100,000maybeassignedtothe

--- Page 505 ---

476 Chapter10 BigData
firstdatabase,keys from100,001 to200,000 totheseconddatabase,andsoon.Such
partitioningiscalledrangepartitioning.Partitioningmayalsobedonebycomputinga
hashfunctionthatmapsakeyvaluetoapartitionnumber;suchpartitioningiscalled
hashpartitioning.WestudypartitioningofdataindetailinChapter21.
When sharding is done in application code, the application must keep track of
which keys are stored on which database, and must route queries to the appropriate
database. Queries that read or update data from multiple databases cannot be pro-
cessed in a simple manner, since it is not possible to submit a single query that gets
executedacrossallthedatabases.Instead,theapplicationwouldneedtoreaddatafrom
multipledatabasesandcomputethefinalqueryresult.Updatesacrossdatabasescause
furtherissues,whichwediscussinSection10.2.5.
While sharding performed by modifying application code provided a simple way
toscaleapplications,thelimitationsoftheapproachsoonbecameapparent.First,the
applicationcodehastotrackhowdatawaspartitionedandroutequeriesappropriately.
Ifadatabasebecomesoverloaded,partsofthedatainthatdatabasehavetobeoffloaded
toanew database, orto one ofthe otherexistingdatabases; managingthisprocessis
a non-trivial task. As more databases are added, there is a greater chance of failure
leading to loss of access to data. Replication is needed to ensure data is accessible
despite failures, but managing the replicas, and ensuring they are consistent, poses
furtherchallenges.Key-valuestores,whichwestudynext,addresssomeoftheseissues.
Challengesrelatedtoconsistencyandavailabilityarediscussedlater,inSection10.2.5.
10.2.3 Key-Value Storage Systems
Manywebapplicationsneedtostoreverylargenumbers(manybillionsorinextreme
cases, trillions) of relatively small records (of size ranging from a few kilobytes to a
few megabytes). Storing each record as a separate file is infeasible, since file systems,
includingdistributedfilesystems,arenotdesignedtostoresuchlargenumbersoffiles.
Ideally,amassivelyparallelrelationaldatabaseshouldbeusedtostoresuchdata.
However, it is not easy to build relational database systems that can run in parallel
across a large number of machines while also supporting standard database features
suchasforeign-keyconstraintsandtransactions.
A number of storage systems have been developed that can scale to the needs
of web applications and store large amounts of data, scaling to thousands to tens of
thousandsofmachines,buttypicallyofferingonlyasimplekey-valuestorageinterface.
Akey-valuestoragesystem(orkey-valuestore)isasystemthatprovidesawaytostoreor
update arecord(value) withanassociatedkeyandtoretrievetherecordwithagiven
key.
Parallelkey-valuestorespartitionkeysacrossmultiplemachines,androuteupdates
and lookups to the correct machine. They also support replication, and ensure that
replicasarekeptconsistent.Further,theyprovidetheabilitytoaddmoremachinesto
asystemwhenrequired,andensurethattheloadisautomaticallybalancedacrossthe
machinesinasystemIncontrasttosystemsthatimplementshardingintheapplication

--- Page 506 ---

10.2 BigDataStorageSystems 477
code,systemsthatuseaparallelkey-valuestoredonotneedtoworryaboutanyofthe
above issues. Parallel key-value stores are therefore more widely used than sharding
today.
Widelyusedparallelkey-valuestoresincludeBigtablefromGoogle,ApacheHBase,
Dynamo from Amazon, Cassandra from Facebook, MongoDB, Azure cloud storage
fromMicrosoft,andSherpa/PNUTSfromYahoo!,amongmanyothers.
Whileseveralkey-valuedatastoresviewthevaluesstoredinthedatastoreasanun-
interpretedsequenceofbytes,anddonotlookattheircontent,otherdatastoresallow
someformofstructureorschematobeassociatedwitheachrecord.Severalsuchkey-
valuestoragesystemsrequirethestoreddatatofollowaspecifieddatarepresentation,
allowingthedatastoretointerpretthestoredvaluesandexecutesimplequeriesbased
on stored values. Such data stores are called document stores. MongoDB is a widely
useddatastorethatacceptsvaluesintheJSONformat.
Key-value storage systems are, at their core, based on two primitive functions,
put(key, value),usedtostorevalueswithanassociatedkey,andget(key),usedtore-
trievethestoredvalueassociatedwiththespecifiedkey.Somesystems,suchasBigtable,
additionallyproviderangequeriesonkeyvalues.Documentstoresadditionallysupport
limitedformsofqueryingonthedatavalues.
An important motivation for the use of key-value stores is their ability to handle
verylargeamountsofdataaswellasqueries,bydistributingtheworkacrossacluster
consistingofalargenumberofmachines.Recordsarepartitioned(dividedup)among
the machines in the cluster, with each machine storing a subset of the records and
processinglookupsandupdatesonthoserecords.
Notethatkey-valuestoresarenotfull-fledgeddatabases,sincetheydonotprovide
manyofthefeaturesthatareviewedasstandardondatabasesystemstoday.Key-value
storestypicallydonotsupportdeclarativequerying(usingSQLoranyotherdeclarative
querylanguage)anddonotsupporttransactions(which,asweshallseeinChapter17,
allow multiple updates to be committed atomically to ensure that the database state
remains consistent despite failures, and control concurrent access to data to ensure
that problems do not arise due to concurrent access by multiple transactions). Key-
value stores also typically do not support retrieval of records based on selections on
non-keyattributes,althoughsomedocumentstoresdosupportsuchretrieval.
An important reason for not supporting such features is that some of them are
noteasytosupportonverylargeclusters;thus,mostsystemssacrificethesefeaturesin
ordertoachievescalability.Applicationsthatneedscalabilitymaybewillingtosacrifice
thesefeaturesinexchangeforscalability.
Key-value stores are also called NoSQL systems, to emphasize that they do not
supportSQL,andthelackofsupportforSQLwasinitiallyviewedassomethingpositive,
ratherthanalimitation.However,itsoon becameclearthatlackofdatabase features
suchastransactionsupportandsupportforSQL,makeapplicationdevelopmentmore
complicated.Thus,manykey-valuestoreshaveevolvedtosupportfeatures,suchasthe
SQLlanguageandtransactions.

--- Page 507 ---

478 Chapter10 BigData
showdbs//Showsavailabledatabases
usesampledb//Usedatabasesampledb,creatingitifitdoesnotexist
db.createCollection("student")//Createacollection
db.createCollection("instructor")
showcollections//Showsallcollectionsinthedatabase
db.student.insert({"id":"00128","name":"Zhang",
"dept name":"Comp.Sci.","tot cred":102,"advisors":["45565"]})
db.student.insert({"id":"12345","name":"Shankar",
"dept name":"Comp.Sci.","tot cred":32,"advisors":["45565"]})
db.student.insert({"id":"19991","name":"Brandt",
"dept name":"History","tot cred":80,"advisors":[]})
db.instructor.insert({"id":"45565","name":"Katz",
"dept name":"Comp.Sci.","salary":75000,
"advisees":["00128","12345"]})
db.student.find()//FetchallstudentsinJSONformat
db.student.findOne({"ID":"00128"})//Findonematchingstudent
db.student.remove({"dept name":"Comp.Sci."})//Deletematchingstudents
db.student.drop()//Dropstheentirecollection
Figure 10.2 MongoDBshellcommands.
TheAPIsprovidedbythesesystemstostoreandaccessdataarewidelyused.While
thebasicget()andput()functionsmentionedearlierarestraightforward,mostsystems
support further features. As an example of such APIs, we provide a brief overview of
theMongoDBAPI.
Figure 10.2 illustrates access to the MongoDB document store through a
JavaScript shell interface. Such a shell can be opened by executing the mongo com-
mand on a system that has MongoDB installed and configured. MongoDB also pro-
vides equivalent API functions in a variety of languages, including Java and Python.
The use command shown in the figure opens the specified database, creating it if it
does not already exist. The db.createCollection() command is used to create collec-
tions,whichstoredocuments;adocumentinMongoDBisbasicallyaJSONobject.The
code in the figure creates two collections, student and instructor , and insertsJSON
objectsrepresentingstudentsandinstructorsintothetwocollections.
MongoDBautomaticallycreatesidentifiersfortheinsertedobjects,whichcanbe
used as keys to retrieve the objects. The key associated with an object can be fetched
usingthe idattribute,andanindexonthisattributeiscreatedbydefault.
MongoDBalsosupportsqueriesbasedonthestoredvalues.Thedb.student.find()
function returns a collection of all objects in the student collection, while the find-
One()functionreturnsoneobjectfromthecollection.Bothfunctionscantakeasargu-
mentaJSONobjectthatspecifiesaselectionondesiredattributes.Inourexample,the

--- Page 508 ---

10.2 BigDataStorageSystems 479
studentwithID00128isretrieved.Similarly,allobjectsmatchingsuchaselectioncan
be deleted by the remove() function shown in the figure. The drop() function shown
inthefiguredropsanentirecollection.
MongoDBsupportsavarietyofotherfeaturessuchascreationofindicesonspec-
ifiedattributesofthestoredJSONobjects,suchastheIDandnameattributes.
Since a key goal of MongoDB is to enable scaling to very large data sizes and
query/update loads, MongoDB allows multiple machines to be part of a single Mon-
goDB cluster. Data are then sharded (partitioned) across these machines. We study
partitioningofdataacrossmachinesindetailinChapter21,andwestudyparallelpro-
cessingofqueriesindetailinChapter22.Howeverweoutlinekeyideasinthissection.
InMongoDB(asinmanyotherdatabases),partitioningisdonebasedonthevalue
ofaspecifiedattribute,calledthepartitioningattributeorshardkey.Forexample,ifwe
specifythatthestudentcollectionshouldbepartitionedonthedept nameattribute,
allobjectsofaparticulardepartmentarestoredononemachine,butobjectsofdifferent
departmentsmaybestoredondifferentmachines.Toensuredatacanbeaccessedeven
ifamachinehasfailed,eachpartitionisreplicatedonmultiplemachines.Thisway,even
ifonemachinefails,thedatainthatpartitioncanbefetchedfromanothermachine.
RequestsfromaMongoDBclientaresenttoarouter,whichthenforwardsrequests
totheappropriatepartitionsinacluster.
Bigtableisanotherkey-valuestorethatrequiresdatavaluestofollowaformatthat
allowsthestoragesystemaccesstoindividualpartsofastoredvalue.InBigtable,data
values (records) can have multiple attributes; the set of attribute names is not prede-
termined and can vary across different records. Thus, the key for an attribute value
conceptuallyconsistsof(record-identifier,attribute-name).Eachattributevalueisjust
astringasfarasBigtableisconcerned.Tofetchallattributesofarecord,arangequery,
ormorepreciselyaprefix-matchqueryconsistingofjusttherecordidentifier,isused.
The get()function returnstheattribute namesalongwiththevalues. Forefficientre-
trievalofallattributesofarecord,thestoragesystem storesentriessortedbythekey,
soallattributevaluesofaparticularrecordareclusteredtogether.
In fact, the record identifier can itself be structured hierarchically, although to
Bigtable itself the record identifier is just a string. For example, an application that
storespagesretrievedfromawebcrawlcouldmapaURLoftheform:
www.cs.yale.edu/people/silberschatz.html
totherecordidentifier:
edu.yale.cs.www/people/silberschatz.html
Withthisrepresentation,allURLsofcs.yale.educanberetriedbyaquerythatfetches
all keys with the prefix edu.yale.cs, which would be stored in a consecutive range of
keyvaluesinthesortedkeyorder.Similarly,allURLsofyale.edu wouldhaveaprefix
ofedu.yaleandwouldbestoredinaconsecutiverangeofkeyvalues.

--- Page 509 ---

480 Chapter10 BigData
Although Bigtable does not support JSON natively, JSON data can be mapped to
thedatamodelofBigtable.Forexample,considerthefollowingJSONdata:
{ "ID": "22222",
"name": { "firstname: "Albert", "lastname: "Einstein" },
"deptname": "Physics",
"children": [
{"firstname": "Hans", "lastname": "Einstein" },
{"firstname": "Eduard", "lastname": "Einstein" } ]
}
The above data can be represented by a Bigtable record with identifier “22222”,
with multiple attribute names such as “name.firstname”, “deptname”, “chil-
dren[1].firstname”or“children[2].lastname”.
Further,asingleinstanceofBigtablecanstoredataformultipleapplications,with
multiple tables per application, by simply prefixing the application name and table
nametotherecordidentifier.
Manydata-storagesystemsallowmultipleversionsofdataitemstobestored.Ver-
sionsareoften identifiedbytimestamp,but theymaybe alternativelyidentifiedbyan
integer value that is incremented whenever a new version of a data item is created.
Lookups can specify the required version of a data item or can pick the version with
the highest version number. In Bigtable, for example, a key actually consists of three
parts:(record-identifier,attribute-name,timestamp).Bigtablecanbeaccessedasaser-
vicefromGoogle.Theopen-sourceversionofBigtable,HBase,iswidelyused.
10.2.4 Parallel and Distributed Databases
Parallel databases are databases that run on multiple machines (together referred to
as a cluster) and are designed to store data across multiple machines and to process
large queries using multiple machines. Parallel databases were initially developed in
the1980s,andthustheypredatethemoderngenerationofBigDatasystems. Froma
programmer viewpoint, parallel databases can be used just like databases running on
asinglemachine.
Earlygenerationparalleldatabasesdesignedfortransactionprocessingsupported
onlyafewmachinesinacluster,whilethosedesignedtoprocesslargeanalyticalqueries
were designed to support tens to hundreds of machines. Data are replicated across
multiplemachinesinacluster,toensurethatdataarenotlost,andtheycontinuetobe
accessible,evenifamachineinaclusterfails.Althoughfailuresdooccurandneedto
bedealtwith,failuresduringtheprocessingofaqueryarenotcommoninsystemswith
tenstohundredsofmachines.Ifaquerywasbeingprocessedonanodethatfailed,the
queryissimplyrestarted,usingreplicasofdatathatareonothernodes.
Ifsuchdatabasesystemsarerunonclusterswiththousandsofmachines,theprob-
abilityoffailureduringexecutionofaqueryincreasessignificantlyforqueriesthatpro-
cessalargeamountofdataandconsequentlyrunforalongtime.Restartingaqueryin

--- Page 510 ---

10.2 BigDataStorageSystems 481
theeventofafailureisnolongeranoption,sincethereisafairlyhighprobabilitythata
failurewillhappenyetagainwhilethequeryisexecuting.Techniquestoavoidcomplete
restart,allowingonlycomputationonthefailedmachinestoberedone,weredeveloped
inthecontextofmap-reducesystems, whichwestudy inSection10.3.However,these
techniques introduce significant overhead; given the fact that computation spanning
thousands to tens of thousands of nodes is needed only by some exceptionally large
applications, even today most parallel relational database systems target applications
thatrunontenstohundredsofmachinesandjustrestartqueriesintheeventoffailure.
Queryprocessinginsuchparallelanddistributeddatabasesiscoveredindetailin
Chapter22,whiletransactionprocessinginsuchdatabasesiscoveredinChapter23.
10.2.5 Replication and Consistency
Replicationiskeytoensuringavailabilityofdata,ensuringadataitemcanbeaccessed
despitefailureofsomeofthemachinesstoringthedataitem.Anyupdatetoadataitem
mustbeappliedtoallreplicasofthedataitem.Aslongasallthemachinescontaining
thereplicasareup andconnected toeachother,applyingthe update toallreplicasis
straightforward.
However, since machines do fail, there are two key problems. The first is how to
ensureatomicexecutionofatransactionthatupdatesdataatmorethanonemachine:
thetransactionexecutionissaidtobeatomicifdespitefailures,eitherallthedataitems
updatedbythetransactionaresuccessfullyupdated,orallthedataitemsarereverted
back to their original values. The second problem is, how to perform updates on a
dataitemthathasbeenreplicated,whensomeofthereplicasofthedataitemareona
machinethathasfailed.Akeyrequirementhereisconsistency, thatis,alllivereplicas
of a data item have the same value, and each read sees the latest version of the data
item.Thereareseveralpossiblesolutions,whichofferdifferentdegreesofresilienceto
failures.WestudysolutionstotheboththeseproblemsinChapter23.
Wenotethatthesolutionstothesecondproblemtypicallyrequirethatamajority
of the replicas are available for reading and update. If we had 3 replicas, this would
require not more than 1 fail, but if we had 5 replicas, even if two machines fail we
would still have a majority of replicasavailable. Under these assumptions, writes will
notgetblocked,andreadswillseethelatestvalueforanydataitem.
While the probability of multiple machines failing is relatively low, network link
failurescancausefurtherproblems.Inparticular,anetworkpartitionissaidtooccurif
twolivemachinesinanetworkareunabletocommunicatewitheachother.
It has been shown that no protocol can ensure availability, that is, the ability to
read and write data, while also guaranteeing consistency, in the presence of network
partitions.Thus,distributedsystemsneedtomaketradeoffs:iftheywanthighavailabil-
ity,theyneedtosacrificeconsistency, forexample byallowingreadstoseeoldvalues
of dataitems, or toallow differentreplicastohave differentvalues. In the lattercase,
howtobringthereplicastoacommonvaluebymergingtheupdatesisataskthatthe

--- Page 511 ---

482 Chapter10 BigData
Note 10.1 BuildingScalableDatabaseApplications
Whenfacedwiththetaskofcreatingadatabaseapplicationthatcanscaletoavery
large numberof users, application developerstypicallyhave to choose between a
databasesystemthatrunsonasingleserver,andakey-valuestorethatcanscaleby
running on a large number of servers. A database that supports SQL and atomic
transactions, and at the same time is highly scalable, would be ideal; as of 2018,
Google Cloud Spanner, which is only available on the cloud, and the recently
developedopensourcedatabaseCockroachDBaretheonlysuchdatabases.
Simpleapplicationscanbewrittenusingonlykey-valuestores,butmorecom-
plexapplicationsbenefitgreatlyfromhavingSQLsupport.Applicationdevelopers
thereforetypicallyuseacombinationofparallelkey-valuestoresanddatabases.
Some relations, such as those that store user account and user profile data
are queried frequently, but with simple select queries on a key, typically on the
useridentifier.Suchrelationsarestoredinaparallelkey-valuestore.Incaseselect
queriesonotherattributesarerequired,key-valuestoresthatsupportindexingon
attributesotherthantheprimarykey,suchasMongoDB,couldstillbeused.
Otherrelationsthatareusedinmorecomplexqueriesarestoredinarelational
database that runs on a single server. Databases running on a single server do
exploittheavailabilityofmultiplecorestoexecutetransactionsinparallel,butare
limitedbythenumberofcoresthatcanbesupportedinasinglemachine.
Mostrelationaldatabasessupportaformofreplicationwhereupdatetransac-
tions run on only one database (the primary), but the updates are propagated to
replicasofthedatabase runningon otherservers. Applicationscan executeread-
onlyqueriesonthesereplicas,butwiththeunderstandingthattheymayseedata
that is a few seconds behind in time, as compared to the primary database. Of-
floadingread-onlyqueriesfromtheprimarydatabaseallowsthesystemtohandle
aloadlargerthanwhatasingledatabaseservercanhandle.
In-memory caching systems, such as memcached or Redis, are also used to
get scalable read-only access to relations stored in a database. Applications may
storesomerelations,orsomepartsofsomerelations,insuchanin-memorycache,
whichmaybe replicatedorpartitionedacrossmultiplemachines.Thereby,appli-
cationscangetfastandscalableread-onlyaccesstothecacheddata.Updatesmust
howeverbeperformedonthedatabase,andtheapplicationisresponsibleforup-
datingthecachewheneverthedataisupdatedonthedatabase.
applicationhastodealwith.Someapplications,orsomepartsofanapplication,may
choosetoprioritizeavailabilityoverconsistency.Butotherapplications,orsomeparts
of an application, may choose to prioritize consistency even at the cost of potential
non-availabilityofthesystemintheeventoffailures.Theaboveissuesarediscussedin
moredetailinChapter23.

--- Page 512 ---

10.3 TheMapReduceParadigm 483
10.3 The MapReduce Paradigm
The MapReduce paradigm models a common situation in parallel processing, where
some processing, identified by the map() function, is applied to each of a large num-
ber of input records, and then some form of aggregation, identified by the reduce()
function, is applied to the result of the map() function. The map() function is also
permittedtospecifygroupingkeys,suchthattheaggregationspecifiedinthereduce()
functionisappliedwithineachgroup,identifiedbythegroupingkey,ofthemap()out-
put.WeexaminetheMapReduceparadigm,andthemap()andreduce()functionsin
detail,intherestofthissection.
The MapReduce paradigm for parallel processing has a long history, dating back
several decades, in the functional programming and parallel processing community
(themapandreducefunctionsweresupportedintheLisplanguage,forexample).
10.3.1 Why MapReduce?
As a motivating example for the use of the MapReduce paradigm, we consider the
following word count application, which takes a large number of files as input, and
outputs a count of the number of times each word appears, across all the files. Here,
theinputwouldbeintheformofapotentiallylargenumberoffilesstoredinadirectory.
We start by consideringthe case of a single file. In thiscase, itis straightforward
towriteaprogramthatreadsinthewordsinthefileandmaintainsanin-memorydata
structurethatkeepstrackofallthewordsencounteredsofar,alongwiththeircounts.
The question is, how to extend the above algorithm, which is sequential in nature, to
an environment where there are tens of thousands of files, each containing tens to
hundredsof megabytes of data. It isinfeasible to process such a large volume of data
sequentially.
One solution is to extend the above scheme by coding it as a parallel program
that would run across many machines with each machine processing a part of the
files.Thecountscomputedlocallyateachmachinemustthenbecombinedtogetthe
finalcounts.Inthiscase,theprogrammerwouldberesponsibleforallthe“plumbing”
requiredtostartupjobs ondifferentmachines,coordinate them,andtocompute the
finalanswer.Inaddition,the“plumbing”codemustalsodealwithensuringcompletion
oftheprograminspiteofmachinefailures;failuresarequitefrequentwhenthenumber
ofparticipatingmachinesislarge,suchasinthethousands,andtheprogramrunsfor
alongduration.
The “plumbing” code to implement the above requirements is quite complex; it
makessensetowriteitjustonceandreuseitforalldesiredapplications.
MapReduce systems provide the programmer a way of specifying the core logic
neededforanapplication,withthedetailsoftheearlier-mentionedplumbinghandled
bytheMapReducesystem.Theprogrammerneedstoprovideonlymap()andreduce()
functions, plus optionally functions for reading and writing data. The map() and re-
duce()functionsprovidedbytheprogrammerareinvokedonthedatabytheMapRe-

--- Page 513 ---

484 Chapter10 BigData
ducesystemtoprocessdatainparallel.Theprogrammerdoesnotneedtobeawareof
the plumbing or its complexity; in fact, she can for the most part ignore the fact that
theprogramistobeexecutedinparallelonmultiplemachines.
TheMapReduceapproach canbe used toprocesslarge amountsofdataforava-
riety of applications. The above-mentioned word count program is a toy example of
a class of text and document processing applications. Consider, for example, search
engineswhichtakekeywordsandreturndocumentscontainingthekeywords.MapRe-
ducecan,forexample,beusedtoprocessdocumentsandcreatetextindices,whichare
thenusedtoefficientlyfinddocumentscontainingspecifiedkeywords.
10.3.2 MapReduce By Example 1: Word Count
OurwordcountapplicationcanbeimplementedintheMapReduceframeworkusing
the following functions, which we defined in pseudocode. Note that our pseudocode
isnotinanyspecificprogramminglanguage;itisintendedtointroduceconcepts.We
describehowtowriteMapReducecodeinspecificlanguagesinlatersections.
1. IntheMapReduceparadigm,themap()functionprovidedbytheprogrammeris
invokedoneachinputrecordandemitszeroormoreoutputdataitems,whichare
thenpassedontothereduce()function.Thefirstquestionis,whatisarecord?
MapReduce systems provide defaults, treating each line of each input file as a
record; such a default works well for our word count application, but the pro-
grammersareallowedtospecifytheirownfunctionstobreakupinputfilesinto
records.
For the word count application, the map() function could break up each
record(line)intoindividualwordsandoutputanumberofrecords,eachofwhich
isapair(word,count),wherecountisthenumberofoccurrencesofthewordin
the record. In fact in our simplified implementation, the map() function does
even less work and outputs each word as it is found, with a count of 1. These
counts are added up later by the reduce(). Pseudocode for the map() function
forthewordcountprogramisshowninFigure10.3.
Thefunctionbreaksuptherecord(line)intoindividualwords.2Aseachword
isfound,themap()functionemits(outputs)arecord(word,1).Thus,ifthefile
containedjustthesentence:
“One a penny, two a penny, hot cross buns.”
therecordsoutputbythemap()functionwouldbe
(“one”, 1), (“a”, 1), (“penny”, 1),(“two”, 1), (“a”, 1), (“penny”, 1),
(“hot”, 1), (“cross”, 1), (“buns”, 1).
2Weomitdetailsofhowalineisbrokenupintowords.Inarealimplementation,non-alphabetcharacterswouldbe
removed,anduppercasecharactersmappedtolowercase,beforebreakingupthelinebasedonspacestogeneratealist
ofwords.

--- Page 514 ---

10.3 TheMapReduceParadigm 485
map(String record) {
For each word in record
emit(word, 1).
}
reduce(String key, List value list) {
String word = key;
int count = 0;
For each value in value list
count = count + value
output(word, count)
}
Figure 10.3 Pseudocodeofmap-reducejobforwordcountinginasetoffiles.
In general, the map() function outputs a set of (key, value) pairs for each input
record. The first attribute (key) of the map() output record is referred to as a
reducekey,sinceitisusedbythereducestep,whichwestudynext.
2. TheMapReducesystemtakesallthe(key,value)pairsemittedbythemap()func-
tionsandsorts (oratleast,groupsthem)suchthatallrecordswithaparticular
key are gathered together. All records whose keys match are grouped together,
and a list of all the associated values is created. The (key, list) pairs are then
passedtothereduce()function.
Inourwordcountexample,eachkeyisaword,andtheassociatedlistisalist
of counts generated for different lines of different files. With our example data,
theresultofthisstepisthefollowing:
(“a”, [1,1]), (“buns”, [1]) (“cross”, [1]), (“hot”, [1]), (“one”, [1]),
(“penny”, [1,1]), (“two”, [1])
The reduce() function for our example combines the list of word counts by
adding the counts, and outputs (word, total-count) pairs. For the example input,
therecordsoutputbythereduce()functionwouldbeasfollows:
(“one”, 1), (“a”, 2), (“penny”, 2), (“two”, 1), (“hot”, 1), (“cross”, 1),
(“buns”, 1).
Pseudocode for the reduce() function for the word count program is shown in
Figure10.3.Thecountsgeneratedbythemap()functionareall1,sothereduce()
functioncouldhavejustcountedthenumberofvaluesinthelist,butaddingup
thevaluesallowssomeoptimizationsthatwewillseelater.
Akeyissuehereisthatwithmanyfiles,theremaybemanyoccurrencesofthe
samewordacrossdifferentfiles.Reorganizingtheoutputsofthemap()functions

--- Page 515 ---

486 Chapter10 BigData
…
2013/02/2110:31:22.00EST /slide-dir/11.ppt
2013/02/2110:43:12.00EST /slide-dir/12.ppt
2013/02/2218:26:45.00EST /slide-dir/13.ppt
2013/02/2218:26:48.00EST /exer-dir/2.pdf
2013/02/2218:26:54.00EST /exer-dir/3.pdf
2013/02/2220:53:29.00EST /slide-dir/12.ppt
…
Figure 10.4 Logfiles.
isrequiredtobringallthevaluesforaparticularkeytogether.Inaparallelsystem
withmanymachines,thisrequiresdatafordifferentreducekeystobeexchanged
between machines, so all the values for any particular reduce key are available
at a single machine. This work is done by the shuffle step , which performs data
exchangebetweenmachinesandthensortsthe(key,value)pairstobringallthe
values for a key together. Observe in our example that the words have actually
been sorted alphabetically. Sorting the output records from the map() is one
wayforthesystemtocollectalloccurrencesofawordtogether;thelistsforeach
wordarecreatedfromthesortedrecords.
By default, the output of the reduce() function is sent to one or more files, but
MapReducesystemsallowprogrammerstocontrolwhathappenstotheoutput.
10.3.3 MapReduce by Example 2: Log Processing
As another example of the use of the MapReduce paradigm, which is closer to tradi-
tional database query processing, suppose we have a log file recording accesses to a
website,whichisstructuredasshowninFigure10.4.Thegoalofourfileaccesscount
applicationistofindhowmanytimeseachofthefilesintheslide-dirdirectorywasac-
cessedbetween2013/01/01and2013/01/31.Theapplicationillustratesoneofavariety
ofkindsofquestionsananalystmayaskusingdatafromweblogfiles.
For our log-file processing application, each line of the input file can be treated
as a record. The map() function would do the following: it would first break up the
input record into individual fields, namely date, time, and filename. If the date is in
therequireddaterange, the map()function would emitarecord (filename, 1), which
indicates that the filename appeared once in that record. Pseudocode for the map()
functionforthisexampleisshowninFigure10.5.
Theshufflestepbringsallthevaluesforaparticularreducekey(inourcase,afile
name)togetherasalist.Thereduce()functionprovidedbytheprogrammer,shownin
Figure10.6,istheninvokedforeachreducekeyvalue.Thefirstargumentofreduce()
isthereducekeyitself,whilethesecondargumentisalistcontainingthevaluesinthe

--- Page 516 ---

10.3 TheMapReduceParadigm 487
map(String record) {
String attribute[3];
break up record into tokens (based on space character),and
store the tokens in arrayattributes
String date = attribute[0];
String time = attribute[1];
String filename = attribute[2];
if(date between 2013/01/01and 2013/01/31
and filename starts with “http://db-book.com/slide-dir”)
emit(filename, 1).
}
Figure 10.5 Pseudocodeofmapfunctionsforcounting fileaccesses.
recordsemittedbythemap()function forthatreducekey. Inourexample, thevalues
foraparticularkeyareaddedtogetthetotalnumberofaccessesforafile.Thisnumber
isthenoutputbythereduce()function.
Ifweweretousethevaluesgeneratedbythemap()function,thevalueswouldbe
“1” for all emitted records, and we could have just counted the number of elements
in the list. However, MapReduce systems support optimizations such as performing
a partial addition of values from each input file, before they are redistributed. In that
case,thevaluesreceivedbythereduce()functionmaynotnecessarilybeones,andwe
thereforeaddthevalues.
Figure 10.7 shows a schematic view of the flow of keys and values through the
map() and reduce() functions. In the figure the mk’s denote map keys, mv’s denote
i i
mapinputvalues,rk’sdenotereducekeys,andrv’sdenotereduceinputvalues.Reduce
i i
outputsarenotshown.
reduce(String key, List value list) {
String filename = key;
int count = 0;
For each value in value list
count = count + value
output(filename, count)
}
Figure 10.6 Pseudocodeofreducefunctions forcountingfileaccesses.

--- Page 517 ---

488 Chapter10 BigData
rk 1 rv 1 rk 1 rv 1 ,rv 7 ,...
rk rv
7 2 rk rv ,rv,...
2 8 i
mk mv
1 1
rk rv ,...
rk rv 3 3
3 3
mk mv
2 2
rk rv
1 7
rk rv ,...
7 2
rk rv
2 8
rk ... rv ,...
i n
rk rv
2 i
mk mv
n n
rk rv
i n
reduce inputs
map inputs map outputs
(key, value)
(key, value)
Figure 10.7 FlowofkeysandvaluesinaMapReducejob.
10.3.4 Parallel Processing of MapReduce Tasks
Our description of the map() and reduce() functions so far has ignored the issue of
parallelprocessing.WecanunderstandthemeaningofMapReducecodewithoutcon-
sideringparallelprocessing.However,ourgoalinusingtheMapReduceparadigmisto
enable parallel processing. Thus, MapReduce systems execute the map() function in
parallel on multiple machines, with each map task processing some part of the data,
forexamplesomeofthefiles,orevenpartsofafileincasetheinputfilesareverylarge.
Similarly, the reduce() functions are also executed in parallel on multiple machines,
witheachreducetaskprocessingasubsetofthereducekeys(notethataparticularcall
tothereduce()functionisstillforasinglereducekey).
Parallel execution of map and reduce tasks is shown pictorially in Figure 10.8.
Inthefigure,theinputfilepartitions,denotedasParti,couldbefilesorpartsoffiles.
ThenodesdenotedasMapiarethemaptasks,andthenodesdenotedReduceiarethe
reducetasks.Themasternodesendscopiesofthemap()andreduce()codetothemap
and reduce tasks. The maptasks execute the codeand write output datato localfiles
onthemachineswherethetasksareexecuted,afterbeingsortedandpartitionedbased
on the reduce key values; separate files are created for each reduce task at each Map
node. These files are fetched across the network by the reduce tasks; the files fetched
by a reduce task (from different map tasks) are merged and sorted to ensure that all
occurrencesofaparticularreducekeyaretogetherinthesortedfile.Thereducekeys
andvaluesarethenfedtothereduce()functions.

--- Page 518 ---

10.3 TheMapReduceParadigm 489
User
Program
copy copy copy
Master
assign assign
map reduce
Part 1 Map 1 Reduce 1 File 1
Part 2
Part 3 Map 2 Reduce 1 write File 2
Part 4
local
write
Part n
read Map n Remote Reduce m File m
Read, Sort
Input file Intermediate Output files
partitions files
Figure 10.8 ParallelprocessingofMapReducejob.
MapReducesystems alsoneedtoparallelizefileinputandoutputacrossmultiple
machines;otherwisethesinglemachinestoringthedatawillbecomeabottleneck.Par-
allelizationoffileinputandoutputcanbedonebyusingadistributedfilesystem,such
astheHadoopFileSystem(HDFS).AswesawinSection10.2,distributedfilesystems
allow a number of machinesto cooperate in storing files, partitioning the files across
themachines.Further,filesystemdataarereplicated(copied)acrossseveral(typically
three)machines,sothatevenifafewofthemachinesfail,thedataareavailablefrom
othermachineswhichhavecopiesofthedatainthefailedmachine.
Today, in addition to distributed file systems such as HDFS , MapReduce systems
support input from a variety of Big Data storage systems such as HBase, MongoDB,
Cassandra, and AmazonDynamo, by usingstorage adapters. Output cansimilarlybe
senttoanyofthesestoragesystems.
10.3.5 MapReduce in Hadoop
The Hadoop project provides a widely used open-source implementation of MapRe-
duce in the Java language. We summarize its main features here using the Java API
providedbyHadoop.WenotethatHadoopprovidesMapReduceAPIsinseveralother
languages,suchasPythonandC++.
UnlikeourMapReducepseudocode,realimplementationssuchasHadooprequire
typestobespecifiedfortheinputkeysandvalues,aswellastheoutputkeysandvalue,
ofthemap()function.Similarly,thetypesoftheinputaswellasoutputkeysandval-
ues of the reduce() function need to be specified. Hadoop requires the programmer
to implement map() and reduce() functions as member functions of classes that ex-
tendHadoopMapperandReducerclasses.Hadoopallowstheprogrammertoprovide

--- Page 519 ---

490 Chapter10 BigData
functions to break up the file into records, or to specify that the file is one of the file
types forwhichHadoop providesbuilt-infunctionstobreakupfilesintorecords.For
example, the TextInputFormat specifies that the file should be broken up into lines,
witheachlinebeingaseparaterecord.Compressedfileformatsarewidelyusedtoday,
withAvro,ORC,andParquetbeingthemostwidelyusedcompressedfileformatsinthe
Hadoopworld(compressedfileformatsarediscussedinSection13.6).Decompression
isdonebythesystem,andaprogrammerwritingaqueryneedonlyspecifyoneofthe
supported types, and the uncompressed representation is made available to the code
implementingthequery.
InputfilesinHadoopcancomefromafilesystemofasinglemachine,butforlarge
datasets, a file system on a single machine would become a performance bottleneck.
Hadoop MapReduce allows input and output files to be stored in a distributed file
systemsuchasHDFS,allowingmultiplemachinestoreadandwritedatainparallel.
Inadditiontothereduce()function,Hadoopalsoallowstheprogrammertodefine
acombine()function,whichcanperformapartofthereduce()operationatthenode
wherethemap()functionisexecuted.Inourwordcountexample,thecombine()func-
tionwouldbethesameasthereduce()functionwesawearlier.Thereduce()function
wouldthenreceivealistofpartialcountsforaparticularword;sincethereduce()func-
tionforwordcountaddsupthevalues,itwouldworkcorrectlyevenwiththecombine()
function.Onebenefitofusingthecombine()functionisthatitreducestheamountof
datathathastobesentoverthenetwork:eachnodethatruns maptasks wouldsend
onlyoneentryforawordacrossthenetwork,insteadofmultipleentries.
A single MapReduce step in Hadoop executes a map and a reduce function. A
program may have multiple MapReduce steps, with each step having its own map
and reduce functions. The Hadoop API allows a program to execute multiple such
MapReduce steps. Thereduce() output from each step iswritten tothe (distributed)
filesystemandreadbackinthefollowingstep.Hadoopalsoallowstheprogrammerto
controlthenumberofmapandreducetaskstoberuninparallelforthejob.
TherestofthissectionassumesabasicknowledgeofJava(you mayskiptherest
ofthissectionwithoutlossofcontinuity,ifyouarenotfamiliarwithJava).
Figure 10.9 shows the Java implementation in Hadoop of the word count appli-
cation we saw earlier. For brevity we have omitted Java import statements. The code
defines two classes, one that implements the Mapper interface, and another that im-
plementstheReducerinterface.TheMapperandReducerclassesaregenericclasses
whichtakeasargumentsthetypesofthekeysandvalues.Specifically,thegenericMap-
per and Reducer interfaces both takes four type arguments that specify the types of
theinputkey,inputvalue,outputkey,andoutputvalue,respectively.
ThetypedefinitionoftheMapclassinFigure10.9,whichimplementstheMapper
interface,specifiesthatthemapkeyisoftypeLongWritable,isbasicallyalonginteger,
andthevaluewhichis(allorpartof)adocumentisoftypeText.Theoutputofmap
hasakeyoftypeText,sincethekeyisaword,whilethevalueisoftypeIntWritable,
whichisanintegervalue.

--- Page 520 ---

10.3 TheMapReduceParadigm 491
publicclassWordCount{
publicstaticclassMapextendsMapper<LongWritable,Text,Text,IntWritable>{
privatefinalstaticIntWritableone=newIntWritable(1);
privateTextword=newText();
publicvoidmap(LongWritablekey,Textvalue,Contextcontext)
throwsIOException,InterruptedException{
Stringline=value.toString();
StringTokenizertokenizer=newStringTokenizer(line);
while(tokenizer.hasMoreTokens()){
word.set(tokenizer.nextToken());
context.write(word,one);
}
}
}
publicstaticclassReduceextendsReducer<Text,IntWritable,Text,IntWritable>{
publicvoidreduce(Textkey,Iterable<IntWritable>values,Contextcontext)
throwsIOException,InterruptedException{
intsum=0;
for(IntWritableval:values){
sum+=val.get();
}
context.write(key,newIntWritable(sum));
}
}
publicstaticvoidmain(String[]args)throwsException{
Configurationconf=newConfiguration();
Jobjob=newJob(conf,"wordcount");
job.setOutputKeyClass(Text.class);
job.setOutputValueClass(IntWritable.class);
job.setMapperClass(Map.class);
job.setReducerClass(Reduce.class);
job.setInputFormatClass(TextInputFormat.class);
job.setOutputFormatClass(TextOutputFormat.class);
FileInputFormat.addInputPath(job,newPath(args[0]));
FileOutputFormat.setOutputPath(job, newPath(args[1]));
job.waitForCompletion(true);
}
}
Figure 10.9 ThewordcountprogramwritteninHadoop.
The map() code for the word count example breaks up the input text value into
wordsusingStringTokenizer,andthenforeachword,itinvokescontext.write(word,

--- Page 521 ---

492 Chapter10 BigData
one) to output a key and value pair; note that one is an IntWritable object with nu-
mericvalue1.
All the values output by the map() invocations that have a particular key (word,
inourexample)arecollectedinalistbytheMapReducesysteminfrastructure.Doing
sorequiresinterchangeofdatafrommultiplemaptaskstomultiplereducetasks;ina
distributedsetting,thedatawouldhavetobesentoverthenetwork.Toensurethatall
values for a particular key come together, the MapReduce system typically sorts the
keys output by the map functions, ensuring all values for a particular key will come
togetherinthesortedorder.Thislistofvaluesforeachkeyisprovidedtothereduce()
function.
The type of the reduce() input key is the same as the type of the map output
key.Thereduce()inputvalueinourexampleisaJavaIterable<IntWritable>object,
whichcontainsalistofmapoutputvalues(IntWritableisthetypeofthemapoutput
value).Theoutputkeyforreduce()isaword,oftypeText,whiletheoutputvalueisa
wordcount,oftypeIntWritable.
Inourexample,thereduce()simplyaddsupthevaluesitreceivesinitsinputtoget
thetotalcount;reduce()writesthewordandthetotalcountusingthecontext.write()
function.
Notethatinoursimpleexample,thevaluesareall1,soreduce()justneedstocount
thenumberofvaluesitreceives.Ingeneral,however,Hadoopallowstheprogrammer
todeclareaCombinerclass,whosecombine()functionisrunontheoutputofasingle
mapjob;theoutputofthisfunctionreplacesmultiplemap()outputvaluesforasingle
key with a single value. In our example, a combine() function could just count the
numberofoccurrencesofeachwordandoutputasinglevalue,whichisthelocalword
count at the map task. These outputs are then passed on to the reduce() function,
whichwouldaddupthelocalcountstogettheoverallcount.TheCombiner’sjobisto
reducethetrafficoverthenetwork.
A MapReduce job runs a map and a reduce step. A program may have multiple
MapReducesteps,andeachstepwouldhaveitsownsettingsforthemapandreduce
functions. The main() function sets up the parameters for each MapReduce job, and
thenexecutesit.
TheexamplecodeinFigure10.9executesasingleMapReducejob;theparameters
forthejobareasfollows:
• The classes that contain the map and reduce functions for the job, set by the
methodssetMapperClassandsetReducerClass.
• The types of the job’s output key and values, set to Text (for the words) and
IntWritable (for the count), respectively, by methods setOutputKeyClass and
setOutputValueClass,respectively.
• The input format of the job, set to TextInputFormat by the method
job.setInputFormatClass. The default input format in Hadoop is the TextInput-
Format,whichcreatesamapkeywhosevalueisabyteoffsetintothefile,andthe

--- Page 522 ---

10.3 TheMapReduceParadigm 493
mapvalueisthecontentsofonelineofthefile.Sincefilesareallowedtobebig-
gerthan4gigabytes,theoffsetisoftypeLongWritable.Programmerscanprovide
theirownimplementationsfortheinputformatclass,whichwouldprocessinput
filesandbreakthefilesintorecords.
• The output format of the job, set to TextOutputFormat by the method
job.setOutputFormatClass.
• Thedirectorieswheretheinputfilesarestored,andwheretheoutputfilesmustbe
created,setbythemethodsaddInputPathandaddOutputPath.
HadoopsupportsmanymoreparametersforMapReducejobs,suchasthenumberof
mapandreducetaskstoberuninparallelforthejobandtheamountofmemoryto
beallocatedtoeachmapandreducetask,amongmanyothers.
10.3.6 SQL on MapReduce
Many of the applications of MapReduce are for parallel processing of large amounts
ofnon-relationaldata,usingcomputationsthatcannotbeexpressedeasilyinSQL.For
example,ourwordcountprogramcannotbeexpressedeasilyinSQL.Therearemany
real-worldusesofMapReducethatcannotbeexpressedinSQL.Examplesincludecom-
putationof“invertedindices”whicharekeyforwebsearchenginestoefficientlyanswer
keywordqueries,andcomputationofGoogle’sPageRank,whichisanimportantmea-
sureoftheimportanceofwebsites,andisusedtorankanswerstowebsearchqueries.
However,therearealargenumberofapplicationsthathaveusedtheMapReduce
paradigm for data processing of various kinds, whose logic can be easily expressed
using SQL. If the data were in a database, it would make sense to write such queries
using SQL and execute the queries on a parallel database system (parallel database
systemsarediscussedindetailin Chapter22.UsingSQLismucheasierforusersthan
iscodingintheMapReduceparadigm.However,thedataformanysuchapplications
resideinafilesystem,andtherearesignificanttimeandspaceoverheaddemandswhen
loadingthemintoadatabase.
Relational operations can be implemented using map and reduce steps, as illus-
tratedbythefollowingexamples:
• Therelationalselectionoperationcanbeimplementedbyasinglemap()function,
without a reduce() function (or with a reduce() function that simply outputs its
inputs,withoutanychange).
• Therelationalgroupbyandaggregatefunctionγcanbeimplementedusingasingle
MapReducestep:themap()outputsrecordswiththegroupbyattributevaluesas
thereducekey;thereduce()functionreceivesalistofalltheattributevaluesfor
aparticulargroupbykeyandcomputestherequiredaggregateonthevaluesinits
inputlist.

--- Page 523 ---

494 Chapter10 BigData
• AjoinoperationcanbeimplementedusingasingleMapReducestep,Considerthe
equijoin operation r ⋈ s. We define a map()function whichfor each input
r.A=s.A
recordr outputsapair(r.A,r),andsimilarlyforeachinputrecords outputsapair
i i i i
(s.A,s);themapoutputalsoincludesatagtoindicatewhichrelation(r ors)the
i i
outputcamefrom.Thereduce()functionisinvokedforeachjoin-attributevalue,
with a list of all the r and s records with that join-attribute value. The function
i i
separatesoutther andstuples,andthenoutputsacrossproductsofther tuples
andthestuples,sinceallofthemhavethesamevalueforthejoinattribute.
Weleavedetailsasan exercisetothereader(Exercise10.4). Morecomplextasks, for
example a query with multiple operations, can be expressed using multiple stages of
mapandreducetasks.
WhileitisindeedpossibleforrelationalqueriestobeexpressedusingtheMapRe-
duce paradigm, it can be very cumbersome for a human to do so. Writing queries in
SQL is much more concise and easy to understand, but traditional databases did not
allowdataaccessfromfiles,nordidtheysupportparallelprocessingofsuchqueries.
A new generation of systems have been developed that allows queries written in
(variants of) the SQL language to be executed in parallel on data stored in file sys-
tems.ThesesystemsincludeApacheHive(whichwasinitiallydevelopedatFacebook),
SCOPE,whichdevelopedbyMicrosoft,bothofwhichusevariantsofSQL,andApache
Pig(whichwasinitiallydevelopedatYahoo!),whichusesadeclarativelanguagecalled
Pig Latin, based on the relational algebra. All these systems allow data to be read di-
rectlyfrom the filesystem but allowthe programmer todefine functions thatconvert
theinputdatatoarecordformat.
All these systems generate a program containing a sequence of map and reduce
taskstoexecuteagivenquery.TheprogramsarecompiledandexecutedonaMapRe-
duce framework such as Hadoop. These systems became very popular, and far more
queriesarewrittenusingthesesystemstodaythanarewrittendirectlyusingtheMapRe-
duceparadigm.
Today, Hive implementations provide an option of compiling SQL code to a tree
of algebraic operations that are executed on a parallel environment. Apache Tez and
Sparkaretwowidelyusedplatformsthatsupport theexecutionofatree(or DAG)of
algebraicoperationsonaparallelenvironment,whichwestudynextinSection10.4.
10.4 Beyond MapReduce: Algebraic Operations
Relationalalgebraformsthefoundationofrelationalqueryprocessing,allowingqueries
tobemodeledastreesofoperations.Thisideaisextendedtosettingswithmorecom-
plexdatatypesbysupportingalgebraicoperatorsthatcanworkondatasetscontaining
recordswithcomplexdatatypes,andreturningdatasetswithrecordscontainingsimilar
complexdatatypes.

--- Page 524 ---

10.4 BeyondMapReduce:AlgebraicOperations 495
10.4.1 Motivation for Algebraic Operations
As we saw in Section 10.3.6, relational operations can be expressed by a sequence of
mapandreducesteps.Expressingtasksinsuchasfashioncanbequitecumbersome.
Forexample,ifprogrammersneedtocomputethejoinoftwoinputs,theyshould
be able to express it as a single algebraic operation, instead of having to express it
indirectlyviamapandreducefunctions.Havingaccesstofunctionssuchasjoinscan
greatlysimplifythejobofaprogrammer.
The join operation can be executed in parallel, using a variety of techniques that
we will see later in Section 22.3. In fact, doing so can be much more efficient than
implementingthejoinusingmapandreducefunctions.Thus,evensystemslikeHive,
where programmers do not directly write MapReduce code, can benefit from direct
supportforoperationssuchasjoin.
Later-generationparalleldata-processingsystemsthereforeaddedsupportforother
relational operations such as joins (including variants such as outerjoins and semi-
joins),aswellasavarietyofotheroperationstosupportdataanalytics.Forexample,
manymachine-learningmodelscanbemodeledasoperatorsthattakeasetofrecords
as inputthen output a setof records thathave an extra attribute containingthe value
predicted by the model based on the otherattributes of the record.Machine-learning
algorithmscanthemselvesbemodeledasoperatorsthattakeasetoftrainingrecords
asinputandoutputalearnedmodel.Processingofdataofteninvolvesmultiplesteps,
whichcanbemodeledasasequence(pipeline)ortreeofoperators.
Aunifyingframeworkfortheseoperations istotreatthemasalgebraic operations
thattakeoneormoredatasetsasinputsandoutputoneormoredatasets.
Recall that in the relational algebra (Section 2.6) each operation takes one or
more relations as input, and outputs a relation. These later-generation parallel query-
processingsystemsarebasedonthesameidea,butthereareseveraldifferences.Akey
difference is that the input data could be of arbitrary types, instead of just consisting
ofcolumnswithatomicdatatypesasintherelationalmodel.Recallthattheextended
relational algebra required to support SQL could restrict itself to simple arithmetic,
string, and boolean expressions. In contrast, the new-generation algebraic operators
needtosupportmorecomplexexpressions,requiringthefullpowerofaprogramming
language.
Thereare a numberof frameworks thatsupport algebraic operations on complex
data;themostwidelyusedonestodayareApacheTezandApacheSpark.
ApacheTezprovidesalow-levelAPIwhichissuitableforsystemimplementors.For
example,HiveonTezcompilesSQLqueriesintoalgebraicoperationsthatrunonTez.
Tezprogrammerscancreatetrees(oringeneralDirectedAcyclicGraphs,orDAGs)of
nodes,andtheyprovidecodethatistobeexecutedoneachofthenodes.Inputnodes
would read in data from data sources and pass them to other nodes, which operate
onthedata.Datacanbepartitionedacrossmultiplemachines,andthecodeforeach
node can be executed on each of the machines. Since Tez is not really designed for
applicationprogrammerstousedirectly,wedonotdescribeitinfurtherdetail.

--- Page 525 ---

496 Chapter10 BigData
However,ApacheSparkprovideshigher-levelAPIswhicharesuitable forapplica-
tionprogrammers.WedescribeSparkinmoredetailnext.
10.4.2 Algebraic Operations in Spark
ApacheSparkisawidelyusedparalleldataprocessingsystemthatsupportsavarietyof
algebraicoperations.Datacanbeinputfromoroutputtoavarietyofstoragesystems.
Justasrelationaldatabasesuse arelationastheprimaryabstraction fordatarep-
resentation,SparkusesarepresentationcalledaResilientDistributed Dataset (RDD),
whichisacollectionofrecordsthatcanbestoredacrossmultiplemachines.Theterm
distributed referstotherecordsbeingstoredondifferentmachines,andresilientrefers
to the resilience to failure, in that even if one of the machines fails, records can be
retrievedfromothermachineswheretheyarestored.
OperatorsinSparktakeoneormoreRDDsasinput,andtheiroutputisanRDD.
ThetypesofrecordsstoredinRDDsisnotpredefinedandcanbeanythingthattheap-
plicationdesires.SparkalsosupportsarelationaldatarepresentationcalledaDataSet,
whichwedescribelater.
Spark provides API s for Java, Scala, and Python. Our coverage of Spark is based
ontheJavaAPI.
Figure 10.10 shows our word count application, written in Java using Apache
Spark; this program uses the RDD data representation, whose Java type is called
JavaRDD.NotethatJavaRDDsrequireatypefortherecord,specifiedinangularbrack-
ets(“<>”).IntheprogramwehaveRDDsofJavaStrings.TheprogramalsohasJava-
PairRDDtypes,whichstorerecordswithtwoattributesofspecifiedtypes.Recordswith
multipleattributescanberepresentedbyusingstructureddatatypesinsteadofprimi-
tivedatatypes.Whileanyuser-defineddatatypecanbeused,thepredefineddatatypes
Tuple2whichstorestwoattributes,Tuple3,whichstoresthreeattributes,andTuple4,
whichstoresfourattributes,arewidelyused.
The first step in processing data using Spark is to convert data from input rep-
resentation to the RDD representation, which is done by the spark.read().textfile()
function,whichcreatesarecordforeachlineintheinput.Notethattheinputcanbe
afileoradirectorywithmultiplefiles;aSparksystem runningonmultiplenodeswill
actuallypartition the RDDacrossmultiple machines,although the program can treat
it (for most purposes) as if it is a data structure on a single machine. In our sample
codeinFigure10.10,theresultistheRDDcalledlines.
ThenextstepinourSparkprogramistospliteachlineintoanarrayofwords,by
calling s.split(" ")) on the line; this function breaks up the line based on spaces and
returns an array of words; a more complete function would split the input on other
punctuationcharacterssuchasperiods,semicolons,andsoon.Thesplitfunctioncan
beinvokedoneachlineintheinputRDDbycallingthemap()function,whichinSpark
returnsasinglerecordforeachinputrecord.Inourexample,weinsteaduseavariant
calledflatMap(),whichworksasfollows:likemap(),flatMap()invokesauser-defined

--- Page 526 ---

10.4 BeyondMapReduce:AlgebraicOperations 497
importjava.util.Arrays;
importjava.util.List;
importscala.Tuple2;
importorg.apache.spark.api.java.JavaPairRDD;
importorg.apache.spark.api.java.JavaRDD;
importorg.apache.spark.sql.SparkSession;
publicclassWordCount{
publicstaticvoidmain(String[]args)throwsException{
if(args.length<1){
System.err.println("Usage:WordCount<file-or-directory-name>");
System.exit(1);
}
SparkSessionspark=
SparkSession.builder().appName("WordCount").getOrCreate();
JavaRDD<String>lines=spark.read().textFile(args[0]).javaRDD();
JavaRDD<String>words=lines.flatMap(s->Arrays.asList(s.split("")).iterator());
JavaPairRDD<String,Integer>ones=words.mapToPair(s->newTuple2<>(s,1));
JavaPairRDD<String,Integer>counts=ones.reduceByKey((i1,i2)->i1+i2);
counts.saveAsTextFile("outputDir");//Saveoutputfilesinthisdirectory
List<Tuple2<String,Integer»output=counts.collect();
for(Tuple2<String,Integer>tuple:output){
System.out.println(tuple);
}
spark.stop();
}
}
Figure 10.10 WordcountprograminSpark.
function on each input record; the function is expected to return an iterator. A Java
iteratorsupportsanext()functionthatcanbeusedtofetchmultipleresultsbycalling
thefunctionmultipletimes.TheflatMap()functioninvokestheuser-definedfunction
togetaniterator,invokesthenext()functionrepeatedlyontheiteratortogetmultiple
values,andthenreturnsanRDDcontainingtheunionofallthevaluesacrossallinput
records.
The code shown in Figure 10.10 uses the “lambda expression” syntax introduced
inJava8,whichallowsfunctionstobedefinedcompactly,withoutevengivingthema
name;intheJavacode,thesyntax
s −> Arrays.asList(s.split("")).iterator()

--- Page 527 ---

498 Chapter10 BigData
defines a function that takes a parameter s and returns an expression that does the
following: it applies the split function described earlier to create an array of words,
thenusesArrays.asListtoconvertthearraytoalist,andfinallyappliestheiterator()
methodonthelisttocreateaniterator.TheflatMap()functionworksonthisiterator
asdescribedearlier.
TheresultoftheabovestepsisanRDDcalledwords,whereeachrecordcontains
asingleword.
ThenextstepistocreateaJavaPairRDDcalledones,whichcontainspairsofthe
form“(word,1)”foreachwordinwords;ifawordappearsmultipletimesintheinput
file,therewouldcorrespondinglybeasmanyrecordsinwords andinones.
Finallythealgebraicoperation reduceByKey()implementsagroupbyandaggre-
gationstep.Inthesamplecode,wespecifythatadditionistobeusedforaggregation,
bypassingthelambdafunction(i1, i2) − > i1+i2tothereduceByKey()function.The
reduceByKey()functionworksonaJavaPairRDD,groupingbythefirstattribute,and
aggregating the values of the second attribute using the provided lambda function.
When applied on the ones RDD, grouping would be on the word, which is the first
attribute,andthevaluesofthesecondattribute(allones,intheonesRDD)wouldbe
addedup.TheresultisstoredintheJavaPairRDDcounts.
Ingeneral,anybinaryfunctioncanbeusedtoperformtheaggregation,aslongas
itgivesthesameresultregardlessoftheorderinwhichitisappliedonacollectionof
values.
Finally,thecountsRDDisstoredtothefilesystembysaveAsTextFile().Insteadof
creatingjustonefile,thefunctioncreatesmultiplefilesiftheRDDitselfispartitioned
acrossmachines.
Keytounderstandinghowparallelprocessingisachievedistounderstandthat
• RDDsmaybepartitionedandstoredonmultiplemachines,and
• each operation may be executed in parallel on multiple machines, on the RDD
partitionavailableatthemachine.Operationsmayfirstrepartitiontheirinput,to
bringrelatedrecordstothesamemachinebeforeexecutingoperationsinparallel.
Forexample,reduceByKey()wouldrepartitiontheinputRDDtobringallrecords
belongingtoagrouptogetheronasinglemachine;recordsofdifferentgroupsmay
beondifferentmachines.
AnotherimportantaspectofSparkisthatthealgebraicoperationsarenotneces-
sarily evaluated immediately on the function call, although the code seems to imply
thatthisiswhathappens.Instead,thecodeshowninthefigureactuallycreatesatree
ofoperations;inourcode,theleafoperationtextFile()readsdatafromafile;thenext
operationflatMap()hasthetextFile()operationasitschild;themapToPairs()inturn
hasflatMap()aschild,andsoon.Theoperatorscanbethoughtofinrelationalterms
asdefiningviews,whicharenotexecutedassoonastheyaredefinedbutgetexecuted
later.

--- Page 528 ---

10.4 BeyondMapReduce:AlgebraicOperations 499
The entire tree of operations actually get evaluated only when certain operations
demandthatthetreebeevaluated.Forexample,saveAsTextFile()forcesthetreetobe
evaluated; othersuch functions include collect(), whichevaluates the tree and brings
allrecordstoasinglemachine,wheretheycansubsequentlybeprocessed,forexample
byprintingthemout.
Animportantbenefitof suchlazy evaluation ofthetree(i.e.,the treeisevaluated
when required, rather than when it is defined) is that before actual evaluation, it is
possible for a query optimizer to rewrite the tree to another tree that computes the
sameresultbutmayexecutefaster.Queryoptimizationtechniques,whichwestudyin
Chapter16canbeappliedtooptimizesuchtrees.
Whiletheprecedingexamplecreatedatreeofoperations,ingeneraltheoperations
mayformaDirectedAcyclicGraph(DAG)structure,iftheresultofanoperationiscon-
sumedbymorethanoneotheroperation.Thatwouldresultinoperationshavingmore
thanoneparent,leadingtoaDAG structure,whereasoperationsinatreecanhaveat
mostoneparent.
WhileRDDsarewellsuitedforrepresentingcertaindatatypessuchastextualdata,
averylargefractionofBigDataapplicationsneedtodealwithstructureddata,where
eachrecordmayhavemultipleattributes.SparkthereforeintroducedtheDataSettype,
whichsupportsrecordswithattributes.TheDataSettypeworkswellwithwidelyused
Parquet, ORC, and Avro file formats (discussed in more detail later in Section 13.6),
whichare designed to store records withmultiple attributes in acompressed fashion.
SparkalsosupportsJDBCconnectorsthatcanreadrelationsfromadatabase.
The following code illustrates how data in Parquet format can be read and pro-
cessedinSpark,wheresparkisaSparksessionthathasbeenopenedearlier.
Dataset<Row> instructor = spark.read().parquet("...");
Dataset<Row> department = spark.read().parquet("...");
instructor.filter(instructor.col("salary").gt(100000))
.join(department,instructor.col("dept name")
.equalTo(department.col("dept name")))
.groupBy(department.col("building"))
.agg(count(instructor.col("ID")));
TheDataSet<Row>typeaboveusesthetypeRow,whichallowsaccesstocolumn
valuesbyname.Thecodereadsinstructor anddepartment relationsfromParquetfiles
(whose names are omitted in the code above); Parquet files store metadata such as
columnnamesinadditiontothevalues,whichallowsSparktocreateaschemaforthe
relations. The Spark code then applies a filter (selection) operation on the instructor
relation,whichretainsonlyinstructorswithsalarygreaterthan100000,thenjoinsthe
result with the department relation on the dept name attribute, performs a group by
onthebuildingattribute(anattributeofthedepartmentrelation),andforeachgroup
(here,eachbuilding),acountofthenumberofIDvaluesiscomputed.

--- Page 529 ---

500 Chapter10 BigData
Theabilitytodefinenewalgebraicoperationsandtousetheminquerieshasbeen
found to be very useful for many applications and has led to wideadoption of Spark.
TheSparksystemalsosupportscompilationofHiveSQLqueriesintoSparkoperation
trees,whicharethenexecuted.
SparkalsoallowsclassesotherthanRowtobeusedwithDataSets.Sparkrequires
that for each attribute Attrk of the class, methods getAttrk() and setAttrk() must be
defined to allow retrieval and storage of attribute values. Suppose we have created a
class Instructor, and we have a Parquet file whose attributes match those of the class.
ThenwecanreaddatafromParquetfilesasfollows:
Dataset<Instructor>instructor = spark.read().parquet("...").
as(Encoders.bean(Instructor.class));
In thiscase Parquet provides the names of attributes in the input file, whichare used
to map their values to attributes of the Instructor class. Unlike with Row , where the
types are not known at compile time the types of attributes of Instructor are known
at compile time, and can be represented more compactly than if we used the Row
type.Further,themethodsoftheclassInstructorcanbeusedtoaccessattributes;for
example, we could use getSalary() instead of using col("salary") , which avoids the
runtimecostofmappingattributenamestolocationsintheunderlyingrecords.More
informationonhowtousetheseconstructscanbefoundontheSparkdocumentation
availableonlineatspark.apache.org.
OurcoverageofSparkhasfocusedondatabaseoperations,butasmentionedear-
lier, Spark supports a number of other algebraic operations such as those related to
machinelearning,whichcanbeinvokedonDataSettypes.
10.5 Streaming Data
Queryingofdatacanbedoneinanadhocmanner—forexample,wheneverananalyst
wants to extract some information from a database. It can also be done in a periodic
manner—for example, queries may be executed at the beginning of each day to get a
summaryoftransactionsthathappenedonthepreviousday.
However, there are many applications where queries need to be executed contin-
uously, on datathatarrive in acontinuous fashion. The term streaming data refers to
data that arrive in a continuous fashion. Many application domains need to process
incomingdatainrealtime(i.e.,astheyarrive,withdelays,ifany,guaranteedtobeless
thansomebound).
10.5.1 Applications of Streaming Data
Hereareafewexamplesofstreamingdata,andthereal-timeneedsofapplicationsthat
usethedata.

--- Page 530 ---

10.5 StreamingData 501
• Stock market: In a stock market, each trade that is made (i.e., a stock is sold by
someone and bought by someone else) is represented by a tuple. Trades are sent
asastreamtoprocessingsystems.
Stock market traders analyze the stream of trades to look for patterns, and
theymakebuyorselldecisionsbasedonthepatternsthattheyobserve.Real-time
requirementsinsuchsystemsusedtobeoftheorderofsecondsinearlierdays,but
manyoftoday’ssystemsrequiredelaystobeoftheorderoftensofmicroseconds
(usuallytobeabletoreactbeforeothersdo,tothesamepatterns).
Stockmarketregulatorsmayusethesamestream,butforadifferentpurpose:
toseeiftherearepatternsoftradesthatareindicativeofillegalactivities.Inboth
cases, there isa need for continuous queriesthat look for patterns; the results of
thequeriesareusedtocarryoutfurtheractions.
• E-commerce:Inane-commercesite,eachpurchasemadeisrepresentedasatuple,
andthesequenceofallpurchasesformsastream.Further,eventhesearchesexe-
cutedbyacustomerareofvaluetothee-commercesite,evenifnoactualpurchase
ismade;thus,thesearchesexecutedbyusersformastream.
Thesestreamscanbeusedformultiplepurposes.Forexample,ifanadvertising
campaignislaunched,thee-commercesitemaywishtomonitorinrealtimehow
the campaign is affectingsearches and purchases. The e-commerce site may also
wish to detect any spikes in sales of specific products to which it may need to
respondbyorderingmoreofthatproduct.Similarly,thesitemaywishtomonitor
usersforpatternsofactivitiessuchasfrequentlyreturningitems,andblockfurther
returnsorpurchasesbytheuser.
• Sensors: Sensors are very widelyused in systems such as vehicles,buildings, and
factories. These sensors send readingsperiodically,and thus the readingsform a
stream. Readings in the stream are used to monitor the health of the system. If
somereadingsareabnormal,actionsmayneedtobetakentoraisealarms,andto
detectandfixanyunderlyingfaults,withminimaldelay.
Dependingonthecomplexityofthesystemandtherequiredfrequencyofread-
ings,thestreamcanbeofveryhighvolume.Inmanycases,themonitoringisdone
ata central facilityin the cloud,whichmonitorsa very large number of systems.
Parallel processing is essential in such a system to handle very large volumes of
dataintheincomingstreams.
• Networkdata:Anyorganizationthatmanagesalargecomputernetworkneedsto
monitoractivityonthenetworktodetectnetworkproblemsaswellasattackson
the network by malicious software (malware). The underlying data being moni-
tored can be represented as a stream of tuples containing data observed by each
monitoringpoint(suchasnetworkswitch).Thetuplescouldcontaininformation
about individual network packets, such as source and destination addresses, size
of the packet, and timestamp of packet generation. However, the rate of creation
oftuplesinsuchastreamisextremelyhigh,andtheycannotbehandledexceptus-

--- Page 531 ---

502 Chapter10 BigData
ingspecial-purposehardware.Instead,datacanbeaggregatedtoreducetherateat
whichtuplesaregenerated:forexample,individualtuplescouldrecorddatasuch
as source and destination addresses, time interval, and total bytes transmitted in
thetimeinterval.
Thisaggregatedstreammustthenbeprocessedtodetectproblems.Forexam-
ple,linkfailurescouldbedetectedbyobservingasuddendropintuplestraversing
aparticularlink.Excessivetrafficfrommultiplehoststoasingleorafewdestina-
tionscouldindicateadenial-of-serviceattack.Packetssentfromonehosttomany
other hosts in the network could indicate malware trying to propagate itself to
otherhosts inthe network.Detectionof such patterns mustbe donein realtime
sothatlinkscanbefixedoractiontakentostopthemalwareattack.
• Socialmedia:SocialmediasuchasFacebookandTwittergetacontinuousstream
of messages (such as posts or tweets) from users. Each message in the stream of
messages must be routed appropriately, for example by sending it to friends or
followers.Themessagesthatcanpotentiallybedeliveredtoasubscriberarethen
ranked and delivered in rank order, based on user preferences, past interactions,
oradvertisementcharges.
Social-media streams can be consumed not just by humans, but also by soft-
ware. For example, companies may keep a lookout for tweets regarding the com-
pany and raise an alert if there are many tweets that reflect a negative sentiment
aboutthecompanyoritsproducts.Ifacompanylaunchesanadvertisementcam-
paign,itmayanalyzetweetstoseeifthecampaignhadanimpactonusers.
There are many more examples of the need to process and query streaming data
acrossavarietyofdomains.
10.5.2 Querying Streaming Data
Datastoredinadatabasearesometimesreferredtoasdata-at-rest,incontrasttostream-
ingdata.Incontrasttostoreddata,streamsareunbounded,thatis,conceptuallythey
may never end. Queries that can output results only after seeing all the tuples in a
streamwouldthenneverbeabletooutputanyresult.Asanexample,aquerythatasks
forthenumberoftuplesinastreamcannevergiveafinalresult.
One way to deal with the unbounded nature of streams is to define windows on
the streams, where each window contains tuples with a certain timestamp range or
a certain number of tuples. Given information about timestamps of incoming tuples
(e.g., they are increasing), we can infer when all tuples in a particular window have
been seen. Based on the above, some query languages for streamingdata requirethat
windowsbedefinedonstreams,andqueriescanrefertooneorafewwindowsoftuples
ratherthantoastream.
Another option is to output results that are correct at a particular point in the
stream, but to output updates as more tuples arrive. For example, a count query can

--- Page 532 ---

10.5 StreamingData 503
outputthenumberoftuplesseenataparticularpointintime,andasmoretuplesarrive,
thequeryupdatesitsresultbasedonthenewcount.
Severalapproacheshavebeendevelopedforqueryingstreamingdata,basedonthe
twooptionsdescribedabove.
1. Continuous queries. In this approach the incoming data stream is treated as in-
sertstoarelation,andqueriesontherelationscanbewritteninSQL,orusingre-
lationalalgebraoperations.Thesequeriescanberegisteredascontinuousqueries,
that is, queries that are running continuously. The result of the query on initial
data are output when the system starts up. Each incoming tuple may result in
insertion,update,ordeletionoftuplesintheresultofthecontinuousquery.The
output of acontinuous query is then astream of updates to the query result,as
theunderlyingdatabaseisupdatedbytheincomingstreams.
Thisapproachhassomebenefitsinapplicationswhereuserswishtoviewall
databaseinsertsthatsatisfysomeconditions.However,amajordrawbackofthe
approachisthatconsumersofaqueryresultwouldbefloodedwithalargenum-
ber of updates to continuous queries if the input rate is high. In particular, this
approach is not desirable for applications that output aggregated values, where
usersmaywishtoseefinalaggregatesforsomeperiodoftime,ratherthanevery
intermediateresultaseachincomingtupleisinserted.
2. Stream query languages. A second approach is to define a query language by
extending SQL or relational algebra, where streams are treated differently from
storedrelations.
Most stream query languages use window operations, which are applied to
streams, and create relations corresponding to the contents of a window. For
example,awindowoperationonastreammaycreatesetsoftuplesforeachhour
oftheday;eachsuchsetisthusarelation.Relationaloperationscanbeexecuted
oneachsuchsetoftuples,includingaggregation,selection,andjoinswithstored
relationaldataorwithwindowsofotherstreams,togenerateoutputs.
We provide an outline of stream query languages in Section 10.5.2.1. These
languagesseparatestreamingdatafromstoredrelationsatthelanguageleveland
requirewindowoperationstobeappliedbeforeperformingrelationaloperations.
Doingsoensuresthatresultscanbeoutputafterseeingonlypartofastream.For
example,ifastreamguaranteesthattupleshaveincreasingtimestamps,awindow
basedontimecanbededucedtohavenomoretuplesonceatuplewithahigher
timestamp than the window end has been seen. The aggregation result for the
windowcanbeoutputatthispoint.
Somestreamsdonotguaranteethattupleshaveincreasingtimestamps.How-
ever,suchstreamswouldcontainpunctuations,thatis,metadatatuplesthatstate
thatallfuturetupleswillhaveatimestampgreaterthansomevalue.Suchpunc-
tuationsareemittedperiodicallyandcanbeusedbywindowoperatorstodecide

--- Page 533 ---

504 Chapter10 BigData
when an aggregate result, such as aggregates for an hourly window,is complete
andcanbeoutput.
3. Algebraicoperatorsonstreams.Athirdapproachistoallowuserstowriteoper-
ators (user-defined functions) thatare executed on each incomingtuple. Tuples
are routed from inputs to operators; outputs of an operator may be routed to
anotheroperator,toasystem output,ormaybestoredinadatabase.Operators
canmaintaininternalstateacrossthetuplesthatareprocessed,allowingthemto
aggregate incoming data. They may also be permitted to store data persistently
inadatabase,forlong-termuse.
Thisapproachhasseenwidespreadadoptioninrecentyears,andwedescribe
itinmoredetaillater.
4. Pattern matching. A fourth option istodefine apattern matchinglanguage and
allowuserstowritemultiplerules,eachwithapatternandanaction.Whenthe
system findsasubsequence oftuplesthatmatchaparticularpattern,theaction
correspondingtothepatternisexecuted.Suchsystemsarecalledcomplexevent
processing(CEP)systems.PopularcomplexeventprocessingsystemsincludeOr-
acleEventProcessing,MicrosoftStreamInsight,andFlinkCEP,whichispartof
theApacheFlinkproject,
Wediscussstreamquerylanguagesandalgebraicoperationsinmoredetaillaterinthis
section.
Many stream-processingsystems keep datain-memoryand donot providepersis-
tence guarantees; their goal is to generate results with minimum delay, to enable fast
response based on analysis of streaming data. On the other hand, the incoming data
may also need to be stored in a database for later processing. To support both pat-
ternsofquerying,manyapplicationsuseaso-calledlambdaarchitecture,whereacopy
oftheinputdataisprovidedtothestream-processingsystemandanothercopyispro-
videdtoadatabaseforstorageandlaterprocessing.Suchanarchitectureallowsstream-
processingsystemstobedevelopedrapidly,withoutworryingaboutpersistence-related
issues. However, the streaming system and database system are separate, resulting in
theseproblems:
• Queriesmayneedtobewrittentwice,onceforthestreamingsystemandoncefor
thedatabasesystem,indifferentlanguages.
• Streamingqueriesmaynotbeabletoaccessstoreddataefficiently.
Systemsthatsupportstreamingqueriesalongwithpersistentstorageandqueriesthat
spanstreamsandstoreddataavoidtheseproblems.
10.5.2.1 StreamExtensionstoSQL
SQL window operations were described in Section 5.5.2, but stream query languages
support further window types that are not supported by SQL window functions. For

--- Page 534 ---

10.5 StreamingData 505
example, a window that contains tuples for each hour cannot be specified using SQL
windowfunctions;note,however,thataggregatesonsuchwindowscanbespecifiedin
SQLinamoreroundaboutfashion,firstcomputinganextraattributethatcontainsjust
the hour component of a timestamp, and then grouping on the hour attribute. Win-
dowfunctionsinstreamingquerylanguagessimplifyspecificationofsuchaggregation.
Commonlysupportedwindowfunctionsinclude:
• Tumblingwindow:Hourlywindowsareanexampleoftumblingwindows.Windows
donotoverlapbutareadjacenttoeachother.Windowsarespecifiedbytheirwin-
dowsize(forexample,numberofhours,minutes,orseconds).
• Hoppingwindow:Anhourlywindowcomputedevery20minuteswouldbeanexam-
pleofahoppingwindow;thewindowwidthisfixed,similartotumblingwindows,
butadjacentwindowscanoverlap.
• Slidingwindow:Slidingwindowsarewindowsofaspecifiedsize(basedontime,or
number of tuples) around each incoming tuple. These are supported by the SQL
standard.
• Session window: Session windows model users who perform multiple operations
aspartofasession.Awindowisidentifiedbyauserandatime-outinterval,and
containsasequenceofoperationssuchthateachoperationoccurswithinthetime-
outintervalfromthepreviousoperation.Forexample,ifthetime-outis5minutes,
andauserperformsanoperationat10AM,asecondoperationat10:04AM,and
athirdoperation at11 AM,then thefirsttwooperations arepartofone session,
while the third is part of a different session. A maximum duration may also be
specified,sooncethatdurationexpires,thesessionwindowisclosedevenifsome
operationshavebeenperformedwithinthetime-outinterval.
The exact syntax for specifying windows varies by implementation. Suppose we
have a relation order(orderid, datetime, itemid, amount). In Azure Stream Analytics,
the total order amount for each item for each hour can be specified by the following
tumblingwindow:
selectitem,System.Timestampaswindow end,sum(amount)
fromorder timestampbydatetime
groupbyitemid,tumblingwindow(hour,1)
Each output tuple has a timestamp whose value is equal to the timestamp of the end
ofthewindow;thetimestampcanbeaccessedusingthekeywordSystem.Timestampas
showninthequeryabove.
SQL extensions to support streams differentiate between streams, where tuples
haveimplicittimestampsandareexpectedtoreceiveapotentiallyunboundednumber
of tuples and relations whose content is fixed at any point. For example, customers,
suppliers, and items associated with orders would be treated as relations, rather than

--- Page 535 ---

506 Chapter10 BigData
asstreams.Theresultsofquerieswithwindowingaretreatedasrelations,ratherthan
asstreams.
Joins are permitted between a stream and a relation, and the result is a stream;
the timestamp of a join result tuple is the same as the timestamp of the input stream
tuple. Joins between two streams have the problem that a tuple early in one stream
may match a tuple that occurs much later in the other stream; such a join condition
wouldrequirestoringtheentirestreamforapotentiallyunboundedamountoftime.To
avoidthisproblem,streamingSQLsystemsallowstream-to-streamjoinonlyifthereis
ajoinconditionthatboundsthetimedifferencebetweenmatchingtuples.Acondition
thatthetimestampsofthetwotuplesdifferbyatmost1hourisanexampleofsucha
condition.
10.5.3 Algebraic Operations on Streams
While SQL queries on streaming data are quite useful, there are many applications
whereSQLqueriesarenotagoodfit.Withthealgebraicoperationsapproachtostream
processing,user-definedcodecanbeprovidedforimplementinganalgebraicoperation;
anumberofpredefinedalgebraicoperations,suchasselectionandwindowedaggrega-
tion,arealsoprovided.
To perform computation, incoming tuples must be routed to operators that con-
sumethetuples,andoutputsofoperatorsmustberoutedtotheirconsumers.Akeytask
oftheimplementationistoprovidefault-tolerantroutingoftuplesbetweensystem in-
put,operators,andoutputs.ApacheStormandKafkaarewidelyusedimplementations
thatsupportsuchroutingofdata.
Thelogicalroutingoftuplesisdonebycreatingadirectedacyclicgraph(DAG)with
operatorsasnodes.Edgesbetweennodesdefinetheflowoftuples.Eachtupleoutputby
anoperatorissentalongalltheout-edgesoftheoperator,totheconsumingoperators.
Each operator receives tuples from all its in-edges. Figure 10.11a depicts the logical
Data
Source Data Op Op
Data
Op Sink Source Data
Data Sink
Source Data
Data
Op Source
Sink Publish-Subscribe Data
Data System Sink
Source Data Data
Op Op Source
Sink
Data Data
Source Data Sink
Source
Op Op
(a) DAG representation of streaming data flow (b) Publish-subscribe representation of streaming data flow
Figure 10.11 RoutingofstreamsusingDAGandpublish-subscriberepresentations.

--- Page 536 ---

10.5 StreamingData 507
routing of stream tuples through a DAG structure. Operation nodes are denoted as
“Op”nodesinthefigure.Theentrypointstothestream-processingsystemarethedata-
source nodes of the DAG; these nodes consume tuples from the stream sources and
injectthemintothestream-processingsystem.Theexitpointsofthestream-processing
systemaredata-sinknodes;tuplesexitingthesystemthroughadatasinkmaybestored
inadatastoreorfilesystemormaybeoutputinsomeothermanner.
One way of implementing a stream-processing system is by specifying the graph
as part of the system configuration, which is read when the system starts processing
tuples, and is then used to route tuples. The Apache Storm stream-processing system
is an example of a system that uses a configuration file to define the graph, which is
calledatopologyintheStormsystem.Data-sourcenodesarecalledspoutsintheStorm
system,whileoperatornodesarecalledbolts,andedgesconnectthesenodes.
An alternative way of creating such a routing graph is by using publish-subscribe
systems. A publish-subscribe system allows publication of documents or other forms
of data, with an associated topic. Subscribers correspondingly subscribe to specified
topics.Wheneveradocumentispublishedtoaparticulartopic,acopyofthedocument
issenttoallsubscriberswhohavesubscribedtothattopic.Publish-subscribesystems
arealsoreferredtoaspub-subsystemsforshort.
Whenapublish-subscribesystemisusedforroutingtuplesinastream-processing
system, tuples are considered documents, and each tuple is tagged with a topic. The
entrypointstothesystemconceptually“publish”tuples,eachwithanassociatedtopic.
Operatorssubscribetooneormoretopics;thesystemroutesalltupleswithaspecific
topictoallsubscribersofthattopic.Operatorscanalsopublishtheiroutputsbackto
thepublish-subscribesystem,withanassociatedtopic.
Amajorbenefitofthepublish-subscribeapproachisthatoperatorscanbeaddedto
thesystem,orremovedfromit,withrelativeease.Figure10.11bdepictstheroutingof
tuplesusingapublish-subscriberepresentation.Eachdatasourceisassignedaunique
topic name; the output of each operator is also assigned a unique topic name. Each
operatorsubscribestothetopicsofitsinputsandpublishestothetopicscorresponding
toitsoutput.Datasourcespublishtotheirassociatedtopic,whiledatasinkssubscribe
tothetopicsoftheoperatorswhoseoutputgoestothesink.
The Apache Kafka system uses the publish-subscribe model to manage routing
of tuples in streams. In the Kafka system, tuples published for a topic are retained
foraspecifiedperiodoftime(calledtheretentionperiod),evenifthereiscurrentlyno
subscriberforthetopic.Subscribersusuallyprocesstuplesattheearliestpossibletime,
butincaseprocessingisdelayedortemporarilystoppedduetofailures,thetuplesare
stillavailableforprocessinguntiltheretentiontimeexpires.
Moredetailsofrouting,andinparticularhowpublish-subscribeisimplementedin
aparallelsystem,areprovidedinSection22.8.
Thenextdetailtobeaddressedishowtoimplementthealgebraicoperations.We
sawearlierhowalgebraicoperationscanbecomputedusingdatafromfilesandother
datasourcesasinputs.

--- Page 537 ---

508 Chapter10 BigData
Apache Spark allows streaming data sources to be used as inputs for such opera-
tions.Thekeyissueisthatsomeoftheoperationsmaynotoutputanyresultsatalluntil
the entirestream isconsumed,whichmaytake potentiallyunbounded time.Toavoid
thisproblem,Sparkbreaksupstreamsintodiscretizedstreams,wherethestreamdata
for a particulartime window are treated as a datainput to algebraic operators. When
thedatainthatwindowhavebeenconsumed,theoperatorgeneratesitsoutput,justas
itwouldhaveifthedatasourcewereafileorarelation.
However, the above approach has the problem that the discretization of streams
has to be done before any algebraic operations are executed. Other systems such as
Apache Storm and Apache Flink support stream operations, which take a stream as
input and output another stream. This is straightforward for operations such as map
or relationalselectoperations; eachoutput tuple inheritsatimestamp from the input
tuple. On the other hand, relational aggregate operations and reduce operations may
beunabletogenerateanyoutputuntiltheentirestreamisconsumed.Tosupportsuch
operations, Flink supports a window operation which breaks up the stream into win-
dows; aggregates are computed within each window and are output once the window
iscomplete.Notethattheoutputistreatedasastream,wheretupleshaveatimestamp
basedontheendofthewindow.3
10.6 Graph Databases
Graphs are an important type of data that databases need to deal with. For example,
acomputernetworkwithmultipleroutersandlinksbetweenthemcanbemodeledas
agraph,withroutersasnodesandnetworklinksasedges.Roadnetworksareanother
common type of graph, with road intersections modeled as nodes and the road links
between intersections as edges. Web pages with hyperlinks between them are yet an-
other example of graphs, where web pages can be modeled as nodes and hyperlinks
betweenthemasedges.
Infact,ifweconsideranE-Rmodelofanenterprise,everyentitycanbemodeled
as anodeof agraph, and everybinaryrelationshipcanbe modeledas an edge ofthe
graph. Ternary and higher-degreerelationships are harder to model, but as we saw in
Section 6.9.4, such relationships can be modeled as a set of binary relationships if
desired.
Graphs can be represented using the relationalmodel using the followingtwo re-
lations:
1. node(ID,label,node data)
2. edge(fromID,toID,label,edge data)
wherenode dataandedge datacontainallthedatarelatedtonodesandedges,respec-
tively.
3Somesystemsgeneratetimestampsbasedonwhenthewindowisprocessed,butdoingsoresultsinoutputtimestamps
thatarenondeterministic.

--- Page 538 ---

10.6 GraphDatabases 509
Modeling a graph using just two relations is too simplistic for complex database
schemas.Forexample,applicationsrequiremodelingofmanytypesofnodes,eachwith
its own set of attributes, and many types of edges, each with itsown set of attributes.
Wecancorrespondinglyhavemultiplerelationsthatstorenodesofdifferenttypesand
multiplerelationsthatstoreedgesofdifferenttypes.
Althoughgraphdatacanbeeasilystoredinrelationaldatabases,graphdatabases
suchasthewidelyusedNeo4jprovideseveralextrafeatures:
• Theyallowrelationstobeidentifiedasrepresentingnodesoredgesandofferspe-
cialsyntaxfordefiningsuchrelations
• They support query languages designed for easily expressing path queries, which
maybehardertoexpressinSQL.
• Theyprovideefficientimplementationsforsuchqueries,whichcanexecutequeries
muchfasterthaniftheywereexpressedinSQLandexecutedonaregulardatabase.
• Theyprovidesupportforotherfeaturessuchasgraphvisualization.
Asanexampleofagraphquery,weconsideraqueryintheCypherquerylanguage
supported by Neo4j. Suppose the input graph has nodes corresponding to students
(stored in a relation student) and instructors (stored in a relation instructor , and an
edgetypeadvisorfromstudenttoinstructor.Weomitdetailsofhowtocreatesuchnode
andedgetypesinNeo4jandassumeappropriateschemasforthesetypes.Wecanthen
writethefollowingquery:
match(i:instructor)<−[:advisor]−(s:student)
wherei.deptname='Comp.Sci.'
returni.IDasID,i.nameasname,collect(s.name)asadvisees
Observe that the match clause in the query connects instructors to students via the
advisor relation, which is modeled as a graph path that traverses the advisor edge in
thebackwardsdirection(theedgepointsfromstudenttoinstructor),byusingthesyn-
tax (i:instructor)<−[:advisor]−(s:student). This step basically performs a join of the
instructor, advisor and student relations. The query then performs a group by on in-
structor ID and name, and collects all the students advised by the instructor into a
setcalledadvisees.Weomitdetails,andrefertheinterestedreadertoonlinetutorials
availableatneo4j.com/developer.
Neo4Jalsosupportsrecursivetraversalofedges.Forexample,supposewewishto
finddirectandindirectprerequisitesofcourses,withtherelationcoursemodeledwith
type node, and relation prereq(course id, prereq id) modeled with type edge. We can
thenwritethefollowingquery:
match(c1:course)−[:prereq*1..]−>(c2:course)
returnc1.course id,c2.course id

--- Page 539 ---

510 Chapter10 BigData
Here, the annotation “*1..” indicates we want to consider paths with multiple prereq
edges,withaminimumof1edge(withaminimumof0,acoursewouldappearasits
ownprerequisite).
We note that Neo4j is a centralized system and does not (as of 2018) support
parallel processing. However, there are many applications that need to process very
largegraphs,andparallelprocessingiskeyforsuchapplications.
ComputationofPageRank(whichwesawearlierinSection8.3.2.2)onverylarge
graphscontaininganodeforeverywebpage,andanedgeforeveryhyperlinkfromone
page to another, is a good example of a complex computation on very large graphs.
The web graph today has hundreds of billions of nodes and trillions of edges. Social
networks are another example of very large graphs, containing billions of nodes and
edges; computations on such graphs include shortest paths (to find connectivity be-
tween people), or computing how influential people are based on edges in the social
network.
Therearetwopopularapproachesforparallelgraphprocessing:
1. Map-reduce and algebraic frameworks: Graphs can be represented as relations,
and individual steps of many parallel graph algorithms can be represented as
joins.Graphscanthusbestoredinaparallelstorage system, partitionedacross
multiplemachines.Wecanthenusemap-reduceprograms,algebraicframeworks
such as Spark, or parallel relational database implementations to process each
stepofagraphalgorithminparallelacrossmultiplenodes.
Suchapproachesworkwellformanyapplications.However,whenperforming
iterative computations that traverse long paths in graphs, these approaches are
quiteinefficient,sincetheytypicallyreadtheentiregraphineachiteration.
2. Bulksynchronousprocessingframeworks:Thebulksynchronousprocessing(BSP)
frameworkforgraphalgorithmsframesgraphalgorithmsascomputationsasso-
ciated with vertices that operate in an iterative manner. Unlike the preceding
approach,herethegraphistypicallystoredinmemory,withverticespartitioned
acrossmultiplemachines;mostimportantly,thegraphdoesnothavetoberead
ineachiteration.
Each vertex (node) of the graph has data (state) associated with it. Similar
tohow programmersprovidemap()and reduce()functionsin theMapReduce
framework, in the BSP framework programmers provide methods that are exe-
cutedforeachnodeofthegraph.Themethodscansendmessagestoneighboring
nodes and receive messages from neighboring nodes of the graph. In each iter-
ation,calledasuperstep,themethodassociatedwitheachnodeisexecuted;the
methodconsumesanyincomingmessages,updatesthedataassociatedwiththe
node, and may optionally send messages to neighboring nodes. Messages sent
in one iteration are receivedby the recipientsin the next iteration. The method
executingateachvertexmayvotetohaltiftheydecidetheyhavenomorecompu-
tationtocarryout.Ifinsomeiterationallverticesvotetohalt,andnomessages
aresentout,thecomputationcanbehalted.

--- Page 540 ---

10.7 Summary 511
The result of the computation is contained in the state at each node. The state
canbecollectedandoutputastheresultofthecomputation.
The idea of bulk synchronous processing is quite old but was popularized by the
Pregel system developed by Google, which provided a fault-tolerant implementation
of the framework. The Apache Giraph system is an open-source version of the Pregel
system.
The GraphXcomponent of ApacheSparksupports graph computations on large
graphs.ItprovidesanAPIbasedonPregel,aswellasanumberofotheroperationsthat
take a graph as input, and output a graph. Operations supported by GraphX include
mapfunctions applied on verticesand edgesof graphs, join of agraph withan RDD,
and an aggregation operation that works as follows: a user-defined function is used
to create messages that are sent to all the neighbors of each node, and another user-
definedfunctionisusedtoaggregatethemessages.Alltheseoperationscanbeexecuted
inparalleltohandlelargegraphs.
For more information on how to write graph algorithms in such settings, see the
referencesintheFurtherReadingsectionattheendofthechapter.
10.7 Summary
• Modern data management applications often need to deal with datathat are not
necessarily in relational form, and these applications also need to deal with vol-
umesofdatathatarefarlargerthanwhatasingletraditionalorganizationwould
havegenerated.
• The increasing use of data sensors leads to the connection of sensors and other
computing devices embedded within other objects to the internet, often referred
toasthe“internetofthings.”
• ThereisnowawidervarietyofquerylanguageoptionsforBigDataapplications,
driven by the need to handle more varied of data types, and by the need to scale
toverylargedatavolumes/velocity.
• Buildingdatamanagementsystemsthatcanscaletolargevolume/velocityofdata
requiresparallelstorageandprocessingofdata.
• Distributedfilesystemsallowfilestobestoredacrossanumberofmachines,while
allowingaccesstofilesusingatraditionalfile-systeminterface.
• Key-valuestoragesystemsallowrecordstobestoredandretrievedbasedonakey
and may additionally provide limited query facilities. These systems are not full-
fledgeddatabasesystems,andtheyaresometimescalledNoSQLsystems.
• Parallelanddistributeddatabasesprovideatraditionaldatabaseinterface,butthey
storedataacrossmultiplemachines,andtheyperformqueryprocessinginparallel
acrossmultiplemachines.

--- Page 541 ---

512 Chapter10 BigData
• The MapReduce paradigm models a common situation in parallel processing,
where some processing, identified by the map() function, is applied to each of
alargenumberofinputrecords,andthensomeformofaggregation,identifiedby
thereduce()function,isappliedtotheresultofthemap()function.
• The Hadoop system provides a widely used open-source implementation of
MapReduceintheJavalanguage.
• There are a large number of applications that use the MapReduce paradigm for
dataprocessingofvariouskindswhoselogiccanbeeasilyexpressedusingSQL.
• Relational algebra forms the foundation of relational query processing, allowing
queries to be modeled as trees of operations. This idea is extended to settings
withmorecomplexdatatypesbysupportingalgebraicoperatorsthatcanworkon
datasetscontainingrecordswithcomplexdatatypes,andreturningdatasetswith
recordscontainingsimilarcomplexdatatypes.
• Therearemanyapplicationswherequeriesneedtobeexecutedcontinuously, on
data that arrive in a continuous fashion. The term streaming data refers to data
that arrive in a continuous fashion. Many application domains need to process
incomingdatainrealtime.
• Graphsareanimportanttypeofdatathatdatabasesneedtodealwith.
Review Terms
• Volume • Shufflestep
• Velocity • Streamingdata
• Conversion • Data-at-rest
• Internetofthings • Windowsonthestreams
• Distributedfilesystem • Continuousqueries
• NameNodeserver • Punctuations
• DataNodesmachines • Lambdaarchitecture
• Sharding • Tumblingwindow
• Partitioningattribute • Hoppingwindow
• Key-valuestoragesystem • Slidingwindow
• Key-valuestore • Sessionwindow
• Documentstores • Publish-subscribesystems
• NoSQLsystems • Pub-subsystems
• Shardkey • Discretizedstreams
• Paralleldatabases • Superstep
• Reducekey

--- Page 542 ---

PracticeExercises 513
Practice Exercises
10.1 Supposeyouneedtostoreaverylargenumberofsmallfiles,eachofsizesay2
kilobytes.Ifyourchoiceisbetweenadistributedfilesystem andadistributed
key-valuestore,whichwouldyouprefer,andexplainwhy.
10.2 Suppose you need to store data for a very large number of students in a dis-
tributed document store such as MongoDB. Suppose also that the data for
each student correspond to the data in the student and the takes relations.
Howwouldyourepresenttheabovedataaboutstudents,ensuringthatallthe
data for a particular student can be accessed efficiently? Give an example of
thedatarepresentationforonestudent.
10.3 Supposeyouwishtostoreutilitybillsforalargenumberofusers,whereeach
billisidentifiedbyacustomerIDandadate.Howwouldyoustorethebillsin
a key-value store that supports range queries, if queries request the bills of a
specifiedcustomerforaspecifieddaterange.
10.4 Givepseudocode forcomputingajoinr ⋈ susingasingleMapReduce
r.A=s.A
step, assuming that the map() function is invoked on each tuple of r and s.
Assumethatthemap()functioncanfindthenameoftherelationusingcon-
text.relname().
10.5 What is the conceptual problem with the following snippet of Apache Spark
codemeanttoworkonverylargedata.Notethatthecollect()functionreturns
aJavacollection,andJavacollections(fromJava8onwards)supportmapand
reducefunctions.
JavaRDD<String< lines = sc.textFile("logDirectory");
int totalLength = lines.collect().map(s −> s.length())
.reduce(0,(a,b)−> a+b);
10.6 ApacheSpark:
a. HowdoesApacheSparkperformcomputationsinparallel?
b. Explain the statement: “Apache Spark performs transformations on
RDDsinalazymanner.”
c. WhataresomeofthebenefitsoflazyevaluationofoperationsinApache
Spark?
10.7 Givenacollectionofdocuments,foreachwordw ,letn denotethenumberof
i i
timesthewordoccursinthecollection.LetN bethetotalnumberofwordoc-
currencesacrossalldocuments.Next,considerallpairsofconsecutivewords

--- Page 543 ---

514 Chapter10 BigData
(w,w)inthedocument;letn denotethenumberofoccurrencesoftheword
i j i,j
pair(w,w)acrossalldocuments.
i j
WriteanApacheSparkprogramthat,givenacollectionofdocumentsina
directory,computesN,allpairs(w,n),andallpairs((w,w),n ).Thenoutput
i i i j i,j
allwordpairssuchthatn ∕N ≥ 10 ∗ (n∕N) ∗ (n∕N).Thesearewordpairs
i,j i j
thatoccur10timesormoreasfrequentlyastheywouldbeexpectedtooccur
ifthetwowordsoccurredindependentlyofeachother.
You willfind thejoin operation on RDDs useful forthe last step, to bring
related counts together. For simplicity, do not bother about word pairs that
crosslines.Alsoassumeforsimplicitythatwordsonlyoccurinlowercaseand
thattherearenopunctuationmarks.
10.8 Considerthefollowingqueryusingthetumblingwindowoperator:
selectitem,System.Timestampaswindow end,sum(amount)
fromorder timestampbydatetime
groupbyitemid,tumblingwindow(hour,1)
GiveanequivalentqueryusingnormalSQLconstructs,withoutusingthetum-
blingwindowoperator.Youcanassumethatthetimestampcanbeconverted
toanintegervaluethatrepresentsthenumberofsecondselapsedsince(say)
midnight,January1,1970,usingthefunctionto seconds(timestamp).Youcan
also assume that the usual arithmetic functions are available, along with the
functionfloor(a)whichreturnsthelargestinteger≤ a.
10.9 Supposeyouwishtomodeltheuniversityschemaasagraph.Foreachofthe
followingrelations,explainwhethertherelationwouldbemodeledasanode
orasanedge:
(i)student,(ii)instructor,(iii)course,(iv)section,(v)takes,(vi)teaches.
Doesthemodelcaptureconnectionsbetweensectionsandcourses?
Exercises
10.10 Givefourways in whichinformationinweblogspertainingtothewebpages
visitedbyausercanbeusedbythewebsite.
10.11 OneofthecharacteristicsofBigDataisthevarietyofdata.Explainwhythis
characteristic has resulted in the need for languages other than SQL for pro-
cessingBigData.
10.12 Suppose your company has built a database application that runs on a cen-
tralizeddatabase,butevenwithahigh-endcomputerandappropriateindices
createdonthedata,thesystemisnotabletohandlethetransactionload,lead-

--- Page 544 ---

Tools 515
ingtoslowprocessingofqueries.Whatwouldbesomeofyouroptionstoallow
theapplicationtohandlethetransactionload?
10.13 Themap-reduceframeworkisquiteusefulforcreatinginvertedindicesonaset
of documents. An inverted index stores for each word a list of all document
IDsthatitappearsin(offsets inthedocumentsarealsonormallystored,but
weshallignoretheminthisquestion).
Forexample,iftheinputdocumentIDsandcontentsareasfollows:
1:dataclean
2:database
3:cleanbase
thentheinvertedlistswould
data:1,2
clean:1,3
base:2,3
Givepseudocodeformapandreducefunctionstocreateinvertedindicesona
givensetoffiles(eachfileisadocument).AssumethedocumentIDisavailable
usingafunction context.getDocumentID(),andthemapfunction isinvoked
onceperlineofthedocument.Theoutputinvertedlistforeachwordshouldbe
alistofdocumentIDsseparatedbycommas.ThedocumentIDsarenormally
sorted,butforthepurpose ofthisquestion youdonotneedtobothertosort
them.
10.14 Fill in the blanks below to complete the following Apache Spark program
whichcomputesthenumberofoccurrencesofeachwordinafile.Forsimplic-
ityweassumethatwordsonlyoccurinlowercase,andtherearenopunctuation
marks.
JavaRDD<String> textFile = sc.textFile("hdfs://...");
JavaPairRDD<String,Integer> counts =
textFile. (s −> Arrays.asList(s.split("")). ())
.mapToPair(word-> new ).reduceByKey((a,b) −> a + b);
10.15 Suppose a stream can deliver tuples out of order with respect to tuple times-
tamps. What extra information should the stream provide, so a stream query
processingsystemcandecidewhenalltuplesinawindowhavebeenseen?
10.16 Explainhowmultipleoperationscanbeexecutedonastreamusingapublish-
subscribesystemsuchasApacheKafka.
Tools
A wide variety of open-source Big Data tools are available, in addition to some
commercial tools. In addition, a number of these tools are available on cloud plat-

--- Page 545 ---

516 Chapter10 BigData
forms. We list below several popular tools, along with the URL s where they can
be found. Apache HDFS (hadoop.apache.org) is a widely used distributed file sys-
temimplementation.Open-sourcedistributed/parallelkey-valuestoresincludeApache
HBase (hbase.apache.org), Apache Cassandra (cassandra.apache.org), MongoDB
(www.mongodb.com),andRiak(basho.com).
Hosted cloud storage systems include the Amazon S3 storage system
(aws.amazon.com/s3) and Google Cloud Storage (cloud.google.com/storage).
Hosted key-value stores include Google BigTable (cloud.google.com/bigtable), and
AmazonDynamoDB(aws.amazon.com/dynamodb).
Google Spanner (cloud.google.com/spanner ) and the open source Cock-
roachDB(www.cockroachlabs.com)arescalableparalleldatabasesthatsupportSQL
andtransactions,andstronglyconsistentstorage.
Open-sourceMapReducesystemsincludeApacheHadoop(hadoop.apache.org),
and Apache Spark (spark.apache.org), while Apache Tez (tez.apache.org ) sup-
ports data processing using a DAG of algebraic operators. These are also available
ascloud-basedofferingsfromAmazonElasticMapReduce(aws.amazon.com/emr),
which also supports Apache HDFS and Apache HBase, and from Microsoft Azure
(azure.microsoft.com).
Apache Hive (hive.apache.org) is a popular open-source SQL implementation
that runs on top of the Apache MapReduce, Apache Tez, as well as Apache Spark;
thesesystemsaredesignedtosupportlargequeriesrunninginparallelonmultiplema-
chines. Apache Impala (impala.apache.org)is anSQL implementation that runs on
Hadoop,andisdesignedtohandlealargenumberofqueries,andtoreturnqueryresults
withminimaldelays(latency). Hosted SQLofferingsonthe cloudthatsupport paral-
lel processing include Amazon EMR (aws.amazon.com/emr), Google Cloud SQL
(cloud.google.com/sql),andMicrosoftAzureSQL(azure.microsoft.com).
Apache Kafka (kafka.apache.org) and Apache Flink (flink.apache.org ) are
open-source stream-processing systems; Apache Spark also provides support for
stream processing. Hosted stream-processing platforms include Amazon Kinesis
(aws.amazon.com/kinesis), Google Cloud Dataflow (cloud.google.com/dataflow)
and Microsoft Stream Analytics (azure.microsoft.com). Open source graph process-
ingplatformsincludeNeo4J(neo4j.com)andApacheGiraph(giraph.apache.org).
Further Reading
[Davoudianetal.(2018)]providesanicesurveyofNoSQLdatastores,includingdata
modelqueryingandinternals.MoreinformationaboutApacheHadoop,includingdoc-
umentationonHDFSandHadoopMapReduce,canbefoundontheApacheHadoop
homepage, hadoop.apache.org. Information about Apache Spark may be found on
theSparkhomepage,spark.apache.org.InformationabouttheApacheKafkastream-
ing data platform may be found on kafka.apache.org, and details of stream process-
inginApacheFlinkmaybefoundonflink.apache.org.BulkSynchronousProcessing

--- Page 546 ---

FurtherReading 517
was introduced in [Valiant (1990)]. A description of the Pregel system, including its
support for bulk synchronous processing, may be found in [Malewicz et al. (2010)],
whileinformationabouttheopensourceequivalent,ApacheGiraph,maybefoundon
giraph.apache.org.
Bibliography
[Davoudianetal.(2018)] A.Davoudian,L.Chen,andM.Liu,“ASurveyofNoSQLStores”,
ACMComputingSurveys,Volume51,Number2(2018),pages2–42.
[Malewiczetal.(2010)] G.Malewicz,M.H.Austern,A.J.C.Bik,J.C.Dehnert,I.Horn,
N.Leiser,andG.Czajkowski,“Pregel:asystemforlarge-scalegraphprocessing”,InProc.of
theACMSIGMODConf.onManagementofData(2010),pages135–146.
[Valiant(1990)] L.G.Valiant,“ABridging ModelforParallelComputation”,Communica-
tionsoftheACM,Volume33,Number8(1990),pages103–111.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 548 ---

11
CHAPTER
Data Analytics
Decision-makingtasksbenefitgreatlybyusingdataaboutthepasttopredictthefuture
and using the predictions to make decisions. For example, online advertisement sys-
temsneedtodecidewhatadvertisementtoshowtoeachuser.Analysisofpastactions
and profiles of other users, as well as past actions and profile of the current user, are
key to decidingwhichadvertisementthe user ismost likelyto respond to. Here, each
decisionislow-value,butwithhighvolumestheoverallvalueofmakingtherightdeci-
sionsisveryhigh.Attheotherendofthevaluespectrum,manufacturersandretailers
need to decidewhat items to manufacture or stock many months ahead of the actual
sale of the items. Predicting future demand of different types of items based on past
sales and other indicators is key to avoiding both overproduction or overstocking of
someitems,andunderproductionorunderstockingofotheritems.Errorscanleadto
monetarylossduetounsoldinventoryofsomeitems,orlossofpotentialrevenuedue
tononavailabilityofsomeitems.
The term data analytics refers broadly to the processing of data to infer patterns,
correlations, or models for prediction. The results of analytics are then used to drive
businessdecisions.
The financial benefits of making correct decisions can be substantial, as can the
costs of making wrong decisions. Organizations therefore invest a lot of money to
gatherorpurchaserequireddataandbuildsystemsfordataanalytics.
11.1 Overview of Analytics
Largecompanieshavediversesourcesofdatathattheyneedtouseformakingbusiness
decisions. The sources may store the data under different schemas. For performance
reasons (as well as for reasons of organization control), the data sources usually will
notpermitotherpartsofthecompanytoretrievedataondemand.
Organizations therefore typically gather data from multiple sources into one lo-
cation, referred to as a data warehouse. Data warehouses gather data from multiple
sources ata single site, under a unified schema(whichis usually designed to support
efficient analysis, even at the cost of redundant storage). Thus, they provide the user
519

--- Page 549 ---

520 Chapter11 DataAnalytics
a single uniform interface to data. However, data warehouses today also collect and
storedatafromnon-relationalsources,whereschemaunificationisnotpossible.Some
sources of data have errors that can be detected and corrected using business con-
straints;further,organizationsmaycollectdatafrommultiplesources,andtheremay
be duplicates in the data collected from different sources. These steps of collecting
data, cleaning/deduplicating the data, and loading the data into a warehouse are re-
ferred to as extract, transform and load (ETL) tasks. We study issues in building and
maintainingadatawarehouseinSection11.2.
The most basic form of analytics is generation of aggregates and reports summa-
rizingthedatainwaysthataremeaningfultotheorganization.Analystsneedtogeta
numberofdifferentaggregatesandcomparethemtounderstandpatternsinthedata.
Aggregates,andinsomecasestheunderlyingdata,aretypicallypresentedgraphically
as charts, to make it easy for humans to visualize the data. Dashboards that display
charts summarizing key organizational parameters, such as sales, expenses, product
returns,andsoforth,arepopularmeansofmonitoringthehealthofanorganization.
Analystsalsoneedtovisualizedatainwaysthatcanhighlightanomaliesorgiveinsights
intocausesforchangesinthebusiness.
Systemsthatsupportveryefficientanalysis,whereaggregatequeriesonlargedata
areansweredinalmostrealtime(asopposedtobeingansweredaftertensofminutesor
multiplehours)arepopularwithanalysts.Suchsystemsarereferredtoasonlineanalyti-
calprocessing(OLAP)systems.WediscussonlineanalyticalprocessinginSection11.3,
wherewecovertheconceptofmultidimensionaldata,OLAPoperations,relationalrep-
resentationofmultidimensionalsummaries.Wealsodiscussgraphicalrepresentation
ofdataandvisualizationinSection11.3.
Statistical analysis is an important part of data analysis. There are several tools
thataredesignedforstatisticalanalysis,includingtheRlanguage/environment,which
is open source, and commercial systems such as SAS and SPSS. The R language is
widelyusedtoday,andinadditiontofeaturesforstatisticalanalysis,itsupportsfacilities
for graphical display of data. A large number of R packages (libraries) are available
thatimplementawidevarietyofdataanalysistasks,includingmanymachine-learning
algorithms.RhasbeenintegratedwithdatabasesaswellaswithBigDatasystemssuch
asApacheSpark,whichallowsRprogramstobeexecutedinparallelonlargedatasets.
Statisticalanalysisisalargeareabyitself,andwedonotdiscussitfurtherinthisbook.
Referencesprovidingmoreinformationmaybe foundintheFurtherReadingsection
attheendofthischapter.
Predictionofdifferentformsisanotherkeyaspectofanalytics.Forexample,banks
needtodecidewhethertogivealoantoaloanapplicant,andonlineadvertisersneed
todecidewhichadvertisementtoshowtoaparticularuser.Asanotherexample,man-
ufacturersandretailersneedtomakedecisionsonwhatitemstomanufactureororder
inwhatquantities.
Thesedecisionsaredrivensignificantlybytechniquesforanalyzingpastdataand
using the past to predict the future. For example, the risk of loan default can be pre-
dicted as follows. First, the bank would examine the loan default history of past cus-

--- Page 550 ---

11.2 DataWarehousing 521
tomers,findkeyfeaturesofcustomers,suchassalary,educationlevel,jobhistory,and
soon,thathelpinpredictionofloandefault.Thebankwouldthenbuildaprediction
model(suchasadecisiontree,whichwestudylaterinthischapter)usingthechosen
features. When a customer then applies for aloan, the features of thatparticular cus-
tomerarefedintothemodelwhichmakesaprediction,suchasanestimatedlikelihood
ofloandefault.Thepredictionisusedtomakebusinessdecisions,suchaswhetherto
givealoantothecustomer.
Similarly,analystsmaylookatthepasthistoryofsalesanduseittopredictfuture
sales, to make decisions on what and how much to manufacture or order, or how to
targettheiradvertising.Forexample,acarcompanymaysearchforcustomerattributes
that help predict who buys different types of cars. It may find that most of its small
sports cars are bought by young women whose annual incomes are above $50,000.
The company may then target its marketing to attract more such women to buy its
small sports cars and may avoid wasting money trying to attract other categories of
peopletobuythosecars.
Machine-learningtechniquesarekeytofindingpatternsindataandinmakingpre-
dictions from these patterns. The field of data mining combines knowledge-discovery
techniques invented by machine-learning researchers with efficient implementation
techniques that enable them to be used on extremely large databases. Section 11.4
discussesdatamining.
The term business intelligence (BI) is used in a broadly similar sense to data an-
alytics. The term decision support is also used in a related but narrower sense, with
a focus on reporting and aggregation, but not including machine learning/data min-
ing.Decision-supporttaskstypicallyuseSQLqueriestoprocesslargeamountsofdata.
Decision-supportqueriesarecanbecontrastedwithqueriesforonlinetransactionpro-
cessing,whereeachquerytypicallyreadsonlyasmallamountofdataandmayperform
afewsmallupdates.
11.2 Data Warehousing
Largeorganizationshaveacomplexinternalorganizationstructure,andthereforedif-
ferent data may be present in differentlocations, or on differentoperational systems,
or under differentschemas. For instance, manufacturing-problem data and customer-
complaintdatamaybestoredondifferentdatabasesystems. Organizationsoftenpur-
chase data from external sources, such as mailing lists that are used for product pro-
motions, or credit scores of customers that are provided by credit bureaus, to decide
oncreditworthinessofcustomers.1
Corporate decision makers require access to information from multiple such
sources.Settingupqueriesonindividualsourcesisbothcumbersomeandinefficient.
1Creditbureausarecompaniesthatgatherinformationaboutconsumersfrommultiplesourcesandcomputeacredit-
worthinessscoreforeachconsumer.

--- Page 551 ---

522 Chapter11 DataAnalytics
Moreover, the sources of data may store only current data, whereas decision makers
mayneedaccesstopastdataaswell;forinstance,informationabouthowpurchasepat-
ternshavechangedinthepastfewyearscouldbeofgreatimportance.Datawarehouses
provideasolutiontotheseproblems.
Adatawarehouseisarepository(orarchive)ofinformationgatheredfrommulti-
plesources,storedunderaunifiedschema,atasinglesite.Oncegathered,thedataare
storedforalongtime,permittingaccesstohistoricaldata.Thus,datawarehousespro-
videthe userasingle consolidatedinterfacetodata, makingdecision-support queries
easier to write. Moreover, by accessing information for decision support from a data
warehouse,thedecisionmakerensuresthatonlinetransaction-processingsystemsare
notaffectedbythedecision-supportworkload.
11.2.1 Components of a Data Warehouse
Figure11.1showsthearchitectureofatypicaldatawarehouseandillustratesthegath-
eringofdata,thestorageofdata,andthequeryinganddataanalysissupport.Among
theissuestobeaddressedinbuildingawarehousearethefollowing:
• When and how to gather data. In a source-driven architecture for gathering data,
thedatasourcestransmitnewinformation,eithercontinually(astransactionpro-
cessingtakesplace),orperiodically(nightly,forexample).Inadestination-driven
architecture, the data warehouse periodically sends requests for new data to the
sources.
Unlessupdatesatthesourcesare“synchronously”replicatedatthewarehouse,
thewarehousewillneverbe quiteup-to-date withthesources. Synchronousrepli-
cationcan be expensive, somanydata warehousesdonotuse synchronousrepli-
cation,andtheyperformqueriesonlyondatathatareoldenoughthattheyhave
data source 1
data
loaders
data source 2
query and
DBMS
analysis tools
data warehouse
data source n
...
Figure 11.1 Data-warehouse architecture.

--- Page 552 ---

11.2 DataWarehousing 523
been completely replicated. Traditionally, analysts were happy with using yester-
day’s data, so data warehouses could be loaded with data up to the end of the
previousday.However,increasinglyorganizationswantmoreup-to-datedata.The
datafreshnessrequirementsdependontheapplication.Datathatarewithinafew
hoursoldmaybesufficientforsomeapplications;othersthatrequirereal-timere-
sponsestoeventsmayusestreamprocessinginfrastructure(describedinSection
10.5)insteadofdependingonawarehouseinfrastructure.
• What schemato use. Datasources thathave been constructed independentlyare
likelytohavedifferentschemas.Infact,theymayevenusedifferentdatamodels.
Part of the task of a warehouse is to perform schema integration and to convert
data to the integrated schema before they are stored. As a result, the data stored
in the warehouse are not just a copyof the data atthe sources. Instead, theycan
bethoughtofasamaterializedviewofthedataatthesources.
• Datatransformationandcleansing.Thetaskofcorrectingandpreprocessingdata
iscalleddatacleansing.Datasourcesoftendeliverdatawithnumerousminorin-
consistencies, which can be corrected. Forexample, names are often misspelled,
andaddressesmayhavestreet,area,orcitynamesmisspelled,orpostalcodesen-
tered incorrectly. These can be corrected to a reasonable extent by consulting a
databaseofstreetnamesandpostalcodesineachcity.Theapproximatematching
ofdatarequiredforthistaskisreferredtoasfuzzylookup.
Addresslistscollectedfrommultiplesourcesmayhaveduplicatesthatneedto
beeliminatedinamerge–purgeoperation(thisoperationisalsoreferredtoasdedu-
plication).Recordsformultipleindividualsinahousemaybegroupedtogetherso
onlyonemailingissenttoeachhouse;thisoperationiscalledhouseholding.
Datamay betransformed inways otherthan cleansing,such as changingthe
units of measure, or converting the data to a different schema by joining data
from multiple source relations. Data warehouses typically have graphical tools
to support data transformation. Such tools allow transformation to be specified
as boxes, and edges can be created between boxes to indicate the flow of data.
Conditionalboxescanroutedatatoanappropriatenextstepintransformation.
• Howtopropagateupdates.Updatesonrelationsatthedatasourcesmustbepropa-
gatedtothedatawarehouse.Iftherelationsatthedatawarehouseareexactlythe
same as those at the data source, the propagation is straightforward. If they are
not, the problem of propagating updates is basically the view-maintenance prob-
lem,whichwasdiscussedinSection4.2.3,andiscoveredinmoredetailinSection
16.5.
• Whatdatatosummarize.Therawdatageneratedbyatransaction-processingsys-
tem may be too large to store online. However, we can answer many queries by
maintainingjustsummarydataobtainedbyaggregationonarelation,ratherthan
maintaining the entire relation. For example, instead of storing data about every
saleofclothing,wecanstoretotalsalesofclothingbyitemnameandcategory.

--- Page 553 ---

524 Chapter11 DataAnalytics
Thedifferentstepsinvolvedingettingdataintoadatawarehousearecalledextract,
transform, and load or ETL tasks; extraction refers to getting data from the sources,
while load refers to loading the data into the data warehouse. In current generation
datawarehousesthatsupportuser-definedfunctionsorMapReduceframeworks,data
maybeextracted,loadedintothewarehouse,andthentransformed.Thestepsarethen
referredtoasextract,load,andtransformorELTtasks.TheELTapproachpermitsthe
useofparallelprocessingframeworksfordatatransformation.
11.2.2 Multidimensional Data and Warehouse Schemas
Datawarehousestypicallyhaveschemasthataredesignedfordataanalysis,usingtools
such as OLAP tools. The relations in a data warehouse schema can usually be classi-
fiedasfacttablesanddimensiontables.Facttablesrecordinformationaboutindividual
events, such as sales, and are usually very large. A table recording sales information
for a retail store, with one tuple for each item that is sold, is a typical example of a
facttable.Theattributesinfacttablecanbeclassifiedaseitherdimensionattributesor
measureattributes,Themeasureattributesstorequantitativeinformation,whichcanbe
aggregated upon; the measure attributes of a sales table would includethe number of
itemssoldandthepriceoftheitems.Incontrast,dimensionattributesaredimensions
uponwhichmeasureattributes,andsummariesofmeasureattributes,aregroupedand
viewed.Thedimensionattributesofasalestablewouldincludeanitemidentifier,the
datewhentheitemissold,whichlocation(store)theitemwassoldfrom,thecustomer
whoboughttheitem,andsoon.
Data that can be modeled using dimension attributes and measure attributes are
calledmultidimensionaldata.
To minimize storage requirements, dimension attributes are usually short identi-
fiersthatareforeignkeysintoothertablescalleddimensiontables.Forinstance,afact
tablesaleswouldhavedimensionattributesitem id,store id,customer id,anddate,and
measureattributesnumberandprice.Theattributestoreidisaforeignkeyintoadimen-
siontablestore,whichhasotherattributessuchasstorelocation(city,state,country).
The item id attribute of the sales table would be a foreign key into a dimension table
item info,whichwouldcontaininformationsuchasthenameoftheitem,thecategory
towhichtheitembelongs,andotheritemdetailssuchascolorandsize.Thecustomer
id attributewouldbeaforeignkeyintoacustomer tablecontainingattributessuchas
nameandaddressofthecustomer.Wecanalsoviewthedateattributeasaforeignkey
intoadate infotablegivingthemonth,quarter,andyearofeachdate.
The resultant schema appears in Figure 11.2. Such a schema, with a fact table,
multipledimensiontables,andforeignkeysfromthefacttabletothedimensiontables
iscalledastarschema.Morecomplexdata-warehousedesignsmayhavemultiplelevels
ofdimensiontables;forinstance,theitem infotablemayhaveanattributemanufacturer
id that is a foreign key into another table giving details of the manufacturer. Such
schemasarecalledsnowflakeschemas.Complexdata-warehousedesignsmayalsohave
morethanonefacttable.

--- Page 554 ---

11.2 DataWarehousing 525
item_info store
item_id store_id
itemname city
color state
sales
size country
item_id
category
store_id
customer_id
date customer
number customer_id
date_info
price name
date street
month city
quarter state
year zipcode
country
Figure 11.2 Starschemaforadatawarehouse.
11.2.3 Database Support for Data Warehouses
The requirementsof adatabase system designed fortransaction processingaresome-
whatdifferentfromonedesignedtosupportadata-warehousesystem.Onekeydiffer-
ence is that a transaction-processing database needs to support many small queries,
whichmayinvolveupdatesinadditiontoreads.Incontrast,datawarehousestypically
need to process far fewer queries, but each query accesses a much larger amount of
data.
Most importantly, while new records are inserted into relations in a data ware-
house,andoldrecordsmaybedeletedoncetheyarenolongerneeded,tomakespace
for new data, records are typically never updated once they are added to a relation.
Thus,datawarehousesdonotneedtopayanyoverheadforconcurrencycontrol.(As
describedinChapter17andChapter18,ifconcurrenttransactionsreadandwritethe
samedata,theresultantdatamaybecomeinconsistent.Concurrencycontrolrestricts
concurrentaccessesinawaythatensuresthereisnoerroneousupdatetothedatabase.)
Theoverheadofconcurrencycontrolcanbesignificantintermsofnotjusttimetaken
forqueryprocessing,butalsointermsofstorage,sincedatabasesoftenstoremultiple
versionsofdatatoavoidconflictsbetweensmallupdatetransactionsandlongread-only
transactions.Noneoftheseoverheadsareneededinadatawarehouse.
Databasestraditionallystoreallattributesofatupletogether,andtuplesarestored
sequentiallyinafile.Suchastoragelayoutisreferredtoasrow-orientedstorage.Incon-
trast,incolumn-orientedstorage,eachattributeofarelationisstoredinaseparatefile,
withvaluesfromsuccessivetuplesstoredatsuccessivepositionsinthefile.Assuming
fixed-sizedatatypes,thevalueofattributeAoftheithtupleofarelationcanbefound

--- Page 555 ---

526 Chapter11 DataAnalytics
byaccessingthefilecorrespondingtoattributeAandreadingthevalueatoffset(i−1)
timesthesize(inbytes)ofvaluesinattributeA.
Column-orientedstoragehasatleasttwomajorbenefitsoverrow-orientedstorage:
1. When a query needs to access only a few attributes of a relation with a large
numberofattributes,theremainingattributesneednotbefetchedfromdiskinto
memory. In contrast, in row-oriented storage, not only are irrelevant attributes
fetchedintomemory,buttheymayalsogetprefetchedintoprocessorcache,wast-
ingcachespaceandmemorybandwidth,iftheyarestoredadjacenttoattributes
usedinthequery.
2. Storingvaluesofthesametype togetherincreasestheeffectivenessofcompres-
sion;compression cangreatlyreduceboththediskstorage costand thetimeto
retrievedatafromdisk.
Ontheotherhand,column-orientedstoragehasthedrawbackthatstoringorfetching
asingletuplerequiresmultipleI/Ooperations.
As a result of these trade-offs, column-oriented storage is not widely used for
transaction-processingapplications.However,column-orientedstorageistodaywidely
used fordata-warehousingapplications,whereaccessesarerarelytoindividualtuples
butratherrequirescanningandaggregatingmultipletuples.Column-orientedstorage
isdescribedinmoredetailinSection13.6.
Database implementations that are designed purely for data warehouse applica-
tionsincludeTeradata,Sybase IQ,andAmazonRedshift.Manytraditionaldatabases
support efficient execution of data warehousing applications by adding features such
ascolumnarstorage;theseincludeOracle,SAPHANA,MicrosoftSQLServer,andIBM
DB2.
In the 2010s there has been an explosive growth in Big Data systems that are de-
signedtoprocessqueriesoverdatastoredinfiles.Suchsystemsarenowakeypartof
thedatawarehouseinfrastructure.AswesawinSection10.3,themotivationforsuch
systems was the growth of data generated by online systems in the form of log files,
which have a lot of valuable information that can be exploited for decision support.
However,thesesystemscanhandleanykindofdata,includingrelationaldata.Apache
Hadoopisonesuchsystem,andtheHivesystemallowsSQLqueriestobeexecutedon
topoftheHadoopsystem.
A number of companies provide software to optimize Hive query processing, in-
cludingClouderaandHortonworks.ApacheSparkisanotherpopularBigDatasystem
thatsupports SQLquerieson datastored in files.Compressed filestructures contain-
ingrecordswithcolumns,suchasOrcandParquet,areincreasinglyusedtostoresuch
logrecords,simplifyingintegrationwithSQL.Suchfileformatsarediscussedinmore
detailinSection13.6.

--- Page 556 ---

11.3 OnlineAnalyticalProcessing 527
11.2.4 Data Lakes
While data warehouses pay a lot of attention to ensuring a common data schema to
easethejobofqueryingthedata,therearesituationswhereorganizationswanttostore
data without paying the cost of creatinga common schemaand transforming data to
the common schema. The term data lake is used to refer to a repository where data
can be stored in multiple formats, including structured records and unstructured file
formats.Unlikedatawarehouses,datalakesdonotrequireup-frontefforttopreprocess
data,buttheydorequiremoreeffortwhencreatingqueries.Sincedatamaybestoredin
manydifferentformats,queryingtoolsalsoneedtobequiteflexible.ApacheHadoop
andApacheSparkarepopulartoolsforqueryingsuchdata,sincetheysupportquerying
ofbothunstructuredandstructureddata.
11.3 Online Analytical Processing
Data analysis often involves looking for patterns that arise when data values are
grouped in “interesting” ways. As a simple example, summing credit hours for each
department is a way to discover which departments have high teaching responsibili-
ties. In a retail business, we might group sales by product, the date or month of the
sale,thecolororsizeoftheproduct,ortheprofile(suchasagegroupandgender)of
thecustomerwhoboughttheproduct.
11.3.1 Aggregation on Multidimensional Data
Consideranapplicationwhereashopwantstofindoutwhatkindsofclothesarepop-
ular.Letussupposethatclothesarecharacterizedbytheiritem name,color,andsize,
andthatwehavearelationsaleswiththeschema.
sales(item name,color,clothes size,quantity)
Suppose that item name can take on the values (skirt, dress, shirt, pants), color can
takeonthevalues(dark,pastel,white),clothes sizecantakeonvalues(small,medium,
large),andquantityisanintegervaluerepresentingthetotalnumberofitemsofagiven
{item name,color,clothes size}.AninstanceofthesalesrelationisshowninFigure11.3.
Statistical analysis often requires grouping on multiple attributes. The attribute
quantity of the sales relation is a measure attribute, since it measures the number of
units sold, while item name, color, and clothes size are dimension attributes. (A more
realistic version of the sales relation would have additional dimensions, such as time
andsaleslocation,andadditionalmeasuressuchasmonetaryvalueofthesale.)
Toanalyzethemultidimensionaldata,amanagermaywanttoseedatalaidoutas
showninthetableinFigure11.4.Thetableshowstotalquantitiesfordifferentcombi-
nationsofitem nameandcolor.Thevalueofclothes sizeisspecifiedtobeall,indicating
that the displayed values are a summary across all values of clothes size (i.e., we want
togroupthe“small,”“medium,”and“large”itemsintoonesinglegroup.

--- Page 557 ---

528 Chapter11 DataAnalytics
item name color clothes size quantity
dress dark small 2
dress dark medium 6
dress dark large 12
dress pastel small 4
dress pastel medium 3
dress pastel large 3
dress white small 2
dress white medium 3
dress white large 0
pants dark small 14
pants dark medium 6
pants dark large 0
pants pastel small 1
pants pastel medium 0
pants pastel large 1
pants white small 3
pants white medium 0
pants white large 2
shirt dark small 2
shirt dark medium 6
shirt dark large 6
shirt pastel small 4
shirt pastel medium 1
shirt pastel large 2
shirt white small 17
shirt white medium 1
shirt white large 10
skirt dark small 2
skirt dark medium 5
skirt dark large 1
skirt pastel small 11
skirt pastel medium 9
skirt pastel large 15
skirt white small 2
skirt white medium 5
skirt white large 3
Figure 11.3 Anexampleofsalesrelation.
ThetableinFigure11.4isanexampleofacross-tabulation(orcross-tab,forshort),
alsoreferredtoasapivot-table.Ingeneral,across-tabisatablederivedfromarelation

--- Page 558 ---

11.3 OnlineAnalyticalProcessing 529
clothes_size all
color
dark pastel white total
skirt 8 35 10 53
dress 20 10 5 35
item_name
shirt 14 7 28 49
pants 20 2 5 27
total 62 54 48 164
Figure 11.4 Cross-tabulationofsalesbyitemnameandcolor.
(sayR),wherevaluesforoneattribute(sayA)formthecolumnheadersandvaluesfor
anotherattribute(sayB)formtherowheader.Forexample,inFigure11.4,theattribute
colorcorrespondstoA(withvalues“dark,”“pastel,”and“white”),andtheattributeitem
namecorrespondstoB(withvalues“skirt,”“dress,”“shirt,”and“pants”).
Each cell in the pivot-table can be identified by (a,b), where a is a value for A
i j i
andb avalueforB.Thevaluesofthevariouscellsinthepivot-tablearederivedfrom
j
the relationR as follows: If there is at most one tuple in R with any (a,b) value, the
i j
valueinthecellisderivedfromthatsingletuple(ifany);forinstance,itcouldbethe
valueofoneormoreotherattributesofthetuple.Iftherecanbemultipletupleswith
an(a,b)value,thevalueinthecellmustbederivedbyaggregationonthetupleswith
i j
thatvalue. Inour example, the aggregation used isthe sum of the values for attribute
quantity, across all values for clothes size, as indicated by “clothes size: all” above the
cross-tab in Figure 11.4. Thus, the value for cell (skirt, pastel) is 35, since there are
threetuplesinthesalestablethatmeetthatcriteria,withvalues11,9,and15.
In our example, the cross-tab also has an extra column and an extra row storing
thetotalsofthecellsintherow/column.Mostcross-tabshavesuchsummaryrowsand
columns.
The generalization of a cross-tab, which is two-dimensional, to n dimensions can
bevisualizedasann-dimensionalcube,calledthedatacube.Figure11.5showsadata
cubeonthesalesrelation.Thedatacubehasthreedimensions,item name,color,and
clothes size, and the measure attribute is quantity. Each cell is identified by values for
thesethreedimensions.Eachcellinthedatacubecontainsavalue,justasinacross-
tab. In Figure 11.5, the value contained in a cell is shown on one of the faces of the
cell;otherfacesofthecellareshownblankiftheyarevisible.Allcellscontainvalues,
eveniftheyarenotvisible.Thevalueforadimensionmaybeall,inwhichcasethecell
containsasummaryoverallvaluesofthatdimension,asinthecaseofcross-tabs.
Thenumberofdifferentways inwhichthetuplescanbe grouped foraggregation
can be large. In the example of Figure 11.5, there are 3 colors, 4 items, and 3 sizes
resultinginacubesizeof3×4×3 = 36.Includingthesummaryvalues,weobtaina

--- Page 559 ---

530 Chapter11 DataAnalytics
2 5 3 1 11
4 7 6 12 29
2 8 5 7 22
16
dark 8 20 14 20 62 4
34
18
pastel 35 10 7 2 54 9
21
45
white 10 5 28 5 48 42
small
77
all 53 35 49 27 164 larg
m
e
ediu
h
m
es
_size
all clot
skirt dress shirt pants all
item_name
roloc
Figure 11.5 Three-dimensionaldatacube.
4×5×4cube,whosesizeis80.Infact,foratablewithndimensions,aggregationcan
beperformedwithgroupingoneachofthe2n subsetsofthendimensions.2
Anonlineanalyticprocessing(OLAP)systemallowsadataanalysttolookatdiffer-
entcross-tabsonthesamedatabyinteractivelyselectingtheattributesinthecross-tab.
Each cross-tab is a two-dimensional view on a multidimensional data cube. For in-
stance, the analyst may select a cross-tab on item name and clothes size or a cross-tab
oncolorandclothes size.Theoperationofchangingthedimensionsusedinacross-tab
iscalledpivoting.
OLAP systems allow an analyst to see a cross-tab on item name and color for a
fixed value of clothes size, forexample, large,instead ofthe sum acrossallsizes.Such
an operation is referred to as slicing, since it can be thought of as viewing a slice of
the data cube. The operation is sometimes called dicing, particularly when values for
multipledimensionsarefixed.
Whenacross-tabisusedtoviewamultidimensionalcube,thevaluesofdimension
attributes that are not part of the cross-tab are shown above the cross-tab. The value
of such an attribute can be all, as shown in Figure 11.4, indicating that data in the
cross-tabareasummaryoverallvaluesfortheattribute.Slicing/dicingsimplyconsists
ofselectingspecificvaluesfortheseattributes,whicharethendisplayedontopofthe
cross-tab.
OLAP systems permit users to view data at any desired level of granularity. The
operation of moving from finer-granularity data to a coarser granularity (by means
of aggregation) is called a rollup. In our example, starting from the data cube on the
2Groupingonthesetofallndimensionsisusefulonlyifthetablemayhaveduplicates.

--- Page 560 ---

11.3 OnlineAnalyticalProcessing 531
salestable,wegotourexamplecross-tabbyrollingupontheattributeclothes size.The
opposite operation—that of moving from coarser-granularity data to finer-granularity
data—is called a drill down. Finer-granularity data cannot be generated from coarse-
granularity data; they must be generated either from the original data or from even
finer-granularitysummarydata.
Analysts may wish to view a dimension at different levels of detail. For instance,
consider an attribute of type datetime that contains a date and a time of day. Using
timeprecisetoasecond(orless)maynotbemeaningful:Ananalystwhoisinterested
inrough timeofday maylookatonlythe hourvalue. Ananalyst whoisinterested in
salesbydayoftheweekmaymapthedatetoadayoftheweekandlookonlyatthat.
Anotheranalyst may be interested in aggregates over a month, or a quarter, or for an
entireyear.
The different levels of detail for an attribute can be organized into a hierarchy.
Figure 11.6a shows ahierarchy on the datetime attribute. Asanother example, Figure
11.6bshowsahierarchyonlocation,withthecitybeingatthebottomofthehierarchy,
state above it, country at the next level, and region being the top level. In our earlier
example,clothescanbegroupedbycategory(forinstance,menswearorwomenswear);
category would then lie above item name in our hierarchy on clothes. At the level of
actualvalues,skirtsanddresseswouldfallunderthewomenswearcategoryandpants
andshirtsunderthemenswearcategory.
year
quarter
region
day of week month
country
hour of day date
state
date time city
(a) time hierarchy (b) location hierarchy
Figure 11.6 Hierarchiesondimensions.

--- Page 561 ---

532 Chapter11 DataAnalytics
clothes_size: all
category item_name color
dark pastel white total
womenswear skirt 8 8 10 53
dress 20 20 5 35
subtotal 28 28 15 88
menswear pants 14 14 28 49
shirt 20 20 5 27
subtotal 34 34 33 76
total 62 62 48 164
Figure 11.7 Cross-tabulationofsaleswithhierarchyonitemname.
Ananalystmaybeinterestedinviewingsalesofclothesdividedasmenswearand
womenswear, and not interested in individual values. After viewing the aggregates at
thelevelofwomenswearandmenswear,ananalystmaydrilldownthehierarchytolook
atindividualvalues. Ananalyst lookingatthedetailedlevelmaydrill upthe hierarchy
andlookatcoarser-levelaggregates.Bothlevelscanbedisplayedonthesamecross-tab,
asinFigure11.7.
11.3.2 Relational Representation of Cross-Tabs
Across-tabisdifferentfromrelationaltablesusuallystoredindatabases,sincethenum-
berofcolumnsinthecross-tabdependsontheactualdata.Achangeinthedatavalues
mayresultinaddingmorecolumns,whichisnotdesirablefordatastorage. However,
a cross-tab view is desirable for display to users. It is straightforward to represent a
cross-tabwithoutsummaryvaluesinarelationalformwithafixednumberofcolumns.
A cross-tab with summary rows/columns can be represented by introducing a special
value all to represent subtotals, as in Figure 11.8. The SQL standard actually uses the
nullvalueinplaceofall,buttoavoidconfusionwithregularnullvalues,weshallcon-
tinuetouseall.
Consider the tuples (skirt, all, all, 53) and (dress, all, all, 35). We have obtained
thesetuplesbyeliminatingindividualtupleswithdifferentvaluesforcolor andclothes
size, and by replacing the value of quantity with an aggregate—namely, the sum of
the quantities.Thevalue all canbe thought ofasrepresentingthesetofallvalues for
an attribute. Tupleswith the value all for the color and clothes size dimensionscan be
obtained by an aggregation on the sales relation with a group by on the column item
name.Similarly,agroupbyoncolor,clothes sizecanbeusedtogetthetupleswiththe
valueallforitem name,andagroupbywithnoattributes(whichcansimplybeomitted
inSQL)canbeusedtogetthetuplewithvalueallforitem name,color,andclothes size.

--- Page 562 ---

11.3 OnlineAnalyticalProcessing 533
item name color clothes size quantity
skirt dark all 8
skirt pastel all 35
skirt white all 10
skirt all all 53
dress dark all 20
dress pastel all 10
dress white all 5
dress all all 35
shirt dark all 14
shirt pastel all 7
shirt white all 28
shirt all all 49
pants dark all 20
pants pastel all 2
pants white all 5
pants all all 27
all dark all 62
all pastel all 54
all white all 48
all all all 164
Figure 11.8 RelationalrepresentationofthedatainFigure11.4.
Hierarchiescanalsobe representedbyrelations.Forexample, thefactthatskirts
and dresses fall under the womenswear category and the pants and shirts under the
menswearcategorycanberepresentedbyarelationitemcategory(item name,category).
This relation can be joined with the sales relation to get a relation that includes the
category for each item. Aggregation on this joined relation allows us to get a cross-
tab with hierarchy. As another example, a hierarchy on city can be represented by a
single relation city hierarchy (ID, city, state, country, region), or by multiple relations,
eachmappingvaluesinonelevelofthehierarchytovaluesatthenextlevel.Weassume
here that cities have unique identifiers, stored in the attribute ID, to avoid confusing
between two cities with the same name, for example, the Springfield in Missouri and
theSpringfieldinIllinois.
11.3.3 OLAP in SQL
AnalystsusingOLAPsystems needanswerstomultipleaggregatestobegenerated in-
teractively, without having to wait for multiple minutes or hours. This led initially to
thedevelopmentofspecializedsystems forOLAP(see Note11.1onpage535). Many
database systems now implement OLAP along with SQL constructs to express OLAP
queries. As we saw in Section 5.5.3, several SQL implementations, such as Microsoft

--- Page 563 ---

534 Chapter11 DataAnalytics
SQLServerandOracle,supportapivotclausethatallowscreationofcross-tabs.Given
thesalesrelationfromFigure11.3,thequery:
select*
fromsales
pivot(
sum(quantity)
forcolor in('dark','pastel','white')
)
orderbyitem name;
returns the cross-tab shown in Figure 11.9. Note that the for clause within the pivot
clausespecifiesthecolor valuesthatappearasattributenamesinthepivotresult.The
attribute color itself does not appear in the result, although all other attributes are
retained, except that the values for the newly created attributes are specified to come
from the attribute quantity. In case more than one tuple contributes values to a given
cell,theaggregateoperationwithinthepivotclausespecifieshowthevaluesshouldbe
combined.Intheaboveexample,thequantityvaluesaresummedup.
Note that the pivot clause by itself does not compute the subtotals we saw in the
pivot table from Figure11.4. However, wecan firstgenerate the relationalrepresenta-
tionshowninFigure11.8,usingacubeoperation,asoutlinedshortly,andthenapply
thepivotclauseonthatrepresentationtogetanequivalentresult.Inthiscase,thevalue
allmustalsobelistedintheforclause,andtheorderbyclauseneedstobemodifiedto
orderallattheend.
ThedatainadatacubecannotbegeneratedbyasingleSQLqueryifweuseonlythe
basicgroupbyconstructs,sinceaggregatesarecomputedforseveraldifferentgroupings
item name clothes size dark pastel white
dress small 2 4 2
dress medium 6 3 3
dress large 12 3 0
pants small 14 1 3
pants medium 6 0 0
pants large 0 1 2
shirt small 2 4 17
shirt medium 6 1 1
shirt large 6 2 10
skirt small 2 11 2
skirt medium 5 9 5
skirt large 1 15 3
Figure 11.9 ResultofSQLpivotoperationonthesalesrelationofFigure11.3.

--- Page 564 ---

11.3 OnlineAnalyticalProcessing 535
Note 11.1 OLAPIMPLEMENTATION
TheearliestOLAPsystemsusedmultidimensionalarraysinmemorytostoredata
cubes and are referred to as multidimensional OLAP (MOLAP) systems. Later,
OLAPfacilitieswereintegrated intorelationalsystems, withdatastored inarela-
tionaldatabase.SuchsystemsarereferredtoasrelationalOLAP(ROLAP)systems.
Hybridsystems,whichstoresomesummariesinmemoryandstorethebasedata
and other summaries in a relational database, are called hybrid OLAP (HOLAP)
systems.
ManyOLAPsystemsareimplementedasclient-serversystems.Theservercon-
tains the relational database as well as any MOLAP data cubes. Client systems
obtainviewsofthedatabycommunicatingwiththeserver.
Ana¨ıvewayofcomputingtheentiredatacube(allgroupings)onarelationis
touseanystandardalgorithmforcomputingaggregateoperations,onegroupingat
atime.Thena¨ıvealgorithmwouldrequirealargenumberofscansoftherelation.
A simple optimization is to compute an aggregation on, say, (item name, color)
from an aggregation (item name, color, clothes size), instead of from the original
relation. The amount of data read drops significantly by computing an aggregate
from another aggregate, instead of from the original relation. Further improve-
mentsarepossible;forinstance,multiplegroupingscanbecomputed onasingle
scanofthedata.
EarlyOLAPimplementationsprecomputedandstoredentiredatacubes,that
is, groupings on all subsets of the dimension attributes. Precomputation allows
OLAP queries to be answered within a few seconds, even on datasets that may
contain millions of tuples adding up to gigabytes of data. However, there are 2n
groupingswithndimensionattributes;hierarchiesonattributesincreasethenum-
berfurther.Asaresult,theentiredatacubeisoftenlargerthantheoriginalrelation
that formed the data cube and in many cases it is not feasible to store the entire
datacube.
Insteadofprecomputingandstoringallpossiblegroupings,itmakessenseto
precomputeandstoresomeofthegroupings,andtocomputeothersondemand.
Instead of computing queries from the original relation, which may take a very
long time, we can compute them from other precomputed queries. For instance,
suppose that a query requires grouping by (item name, color), and this has not
been precomputed. The query result can be computed from summaries by (item
name, color, clothes size), if that has been precomputed. See the bibliographical
notesforreferencesonhowtoselectagoodsetofgroupingsforprecomputation,
givenlimitsonthestorageavailableforprecomputedresults.

--- Page 565 ---

536 Chapter11 DataAnalytics
of the dimension attributes. Using only the basic group by construct, we would have
towrite manyseparate SQL queriesand combinethemusingaunion operation. SQL
supportsspecialsyntaxtoallowmultiplegroupbyoperationstobespecifiedconcisely.
AswesawinSection5.5.4,SQLsupportsgeneralizationsofthegroupbyconstruct
toperformthecubeandrollupoperations.Thecubeandrollupconstructsinthegroup
by clause allow multiple group by queries to be run in a single query with the result
returnedasasinglerelationinastylesimilartothatoftherelationofFigure11.8.
Consideragainourretailshopexampleandtherelation:
sales(item name,color,clothes size,quantity)
If we want to generate the entire data cube using individual group by queries, we
havetowriteaseparatequeryforeachofthefollowingeightsetsofgroupbyattributes:
{(item name,color,clothes size),(item name,color),(item name,clothes size),
(color,clothes size),(item name),(color),(clothes size),()}
where()denotesanemptygroupbylist.
AswesawinSection5.5.4,thecubeconstructallowsustoaccomplishthisinone
query:
selectitem name,color,clothes size,sum(quantity)
fromsales
groupbycube(item name,color,clothes size);
Theprecedingqueryproducesarelationwhoseschemais:
(item name,color,clothes size,sum(quantity))
Sothattheresultofthisqueryisindeedarelation,tuplesintheresultcontainnullas
thevalue ofthose attributesnotpresentinaparticulargrouping.Forexample,tuples
producedbygroupingonclothes sizehaveaschema(clothes size,sum(quantity)).They
are converted to tuples on (item name, color, clothes size, sum(quantity)) by inserting
nullforitem nameandcolor.
Data cube relations are often very large. The cube query above, with 3 possible
colors, 4 possible item names, and 3 sizes, has 80 tuples. The relation of Figure 11.8
is generated by doing a group by cube on item name and color, with an extra column
specifiedintheselectclauseshowingallforclothes size.
TogeneratethatrelationinSQL,wesubstituteallfornullusingthegroupingfunc-
tion,aswesawearlierinSection5.5.4.Thegroupingfunctiondistinguishesthosenulls
generated byOLAPoperationsfrom“normal”nullsactuallystoredinthedatabaseor
arisingfrom an outer join. Recallthatthegroupingfunction returns1 ifitsargument

--- Page 566 ---

11.3 OnlineAnalyticalProcessing 537
isanullvaluegeneratedbyacubeorrollupand0otherwise.Wemaythenoperateon
theresultofacalltogroupingusingcaseexpressionstoreplaceOLAP-generatednulls
withall.ThentherelationinFigure11.8,withoccurrencesofnull replacedbyall,can
becomputedbythequery:
selectcasewhengrouping(item name)=1then'all'
elseitem nameendasitem name,
casewhengrouping(color)=1then'all'
elsecolor endascolor,
'all'asclothes size,sum(quantity)asquantity
fromsales
groupbycube(item name,color);
Therollupconstructisthesameasthecubeconstructexceptthatrollupgenerates
fewergroupbyqueries.Wesawthatgroupbycube(item name,color,clothes size)gen-
erated all eight ways of forming a group by query using some (or all or none) of the
attributes.In:
selectitem name,color,clothes size,sum(quantity)
fromsales
groupbyrollup(item name,color,clothes size);
theclausegroupbyrollup(item name,color,clothes size)generatesonlyfourgroupings:
{(item name,color,clothes size),(item name,color),(item name),()}
Notice that the order of the attributes in the rollup makes a difference; the last
attribute (clothes size, in our example) appears in only one grouping, the penultimate
(second last) attribute in two groupings, and so on, with the first attribute appearing
inallgroupsbutone(theemptygrouping).
Whymightwewantthespecificgroupingsthatareusedinrollup?Thesegroupsare
of frequent practical interest for hierarchies (as in Figure 11.6, for example). For the
locationhierarchy(Region,Country,State,City),wemaywanttogroupbyRegiontoget
salesbyregion.Thenwemaywantto“drilldown”tothelevelofcountrieswithineach
region,whichmeanswewouldgroupbyRegion,Country.Drillingdownfurther,wemay
wish to group by Region, Country, State and then by Region, Country, State, City. The
rollupconstructallowsustospecifythissequenceofdrillingdownforfurtherdetail.
AswesawearlierinSection5.5.4,multiplerollupsandcubescanbeusedinasingle
groupbyclause.Forinstance,thefollowingquery:
selectitem name,color,clothes size,sum(quantity)
fromsales
groupbyrollup(item name),rollup(color,clothes size);

--- Page 567 ---

538 Chapter11 DataAnalytics
generatesthegroupings:
{(item name,color,clothes size),(item name,color),(item name),
(color,clothes size),(color),()}
Tounderstandwhy,observethatrollup(item name)generatestwogroupings,{(item
name), ()}, and rollup(color, clothes size) generates three groupings, {(color, clothes
size),(color),()}.TheCartesianproductofthetwogivesusthesixgroupingsshown.
Neither the rollup nor the cube clause gives complete control on the groupings
that are generated. For instance, we cannot use them to specify that we want only
groupings{(color,clothes size),(clothes size,item name)}.Suchrestrictedgroupingscan
begeneratedbyusingthegroupingsetsconstruct,inwhichonecanspecifythespecific
listofgroupingstobeused.Toobtainonlygroupings{(color,clothes size),(clothes size,
item name)},wewouldwrite:
selectitem name,color,clothes size,sum(quantity)
fromsales
groupbygroupingsets((color,clothes size),(clothes size,item name));
Specialized languages have been developed for querying multidimensional OLAP
schemas,whichallowsomecommontaskstobeexpressedmoreeasilythanwithSQL.
TheseincludetheMDXandDAXquerylanguagesdevelopedbyMicrosoft.
11.3.4 Reporting and Visualization Tools
Report generators are tools to generate human-readable summary reports from a
database.Theyintegratequeryingthedatabasewiththecreationofformattedtextand
summarycharts(suchasbarorpiecharts).Forexample,areportmayshowthetotal
salesineachofthepast2monthsforeachsalesregion.
The application developer can specify report formats by using the formatting fa-
cilities of the report generator. Variables can be used to store parameters such as the
month and the year and to define fields in the report. Tables, graphs, bar charts, or
other graphics can be defined via queries on the database. The query definitions can
makeuseoftheparametervaluesstoredinthevariables.
Oncewehavedefinedareportstructureonareport-generatorfacility,wecanstore
itandcanexecuteitatanytimetogenerateareport.Report-generatorsystemsprovide
avarietyoffacilitiesforstructuringtabularoutput,suchasdefiningtableandcolumn
headers,displayingsubtotalsforeachgroupinatable,automaticallysplittinglongta-
blesintomultiplepages,anddisplayingsubtotalsattheendofeachpage.
Figure11.10isanexampleofaformattedreport.Thedatainthereportaregener-
atedbyaggregationoninformationaboutorders.
Report-generationtoolsareavailablefromavarietyofvendors,suchasSAPCrystal
Reports and Microsoft (SQL Server Reporting Services). Several application suites,
such as Microsoft Office, provide a way of embedding formatted query results from

--- Page 568 ---

11.3 OnlineAnalyticalProcessing 539
Acme Supply Company, Inc.
Quarterly Sales Report
Period: Jan. 1 to March 31, 2009
Region Category Sales Subtotal
North Computer Hardware 1,000,000
Computer Software 500,000
All categories 1,500,000
South Computer Hardware 200,000
Computer Software 400,000
All categories 600,000
Total Sales 2,100,000
Figure 11.10 Aformatted report.
a database directly into a document. Chart-generation facilities provided by Crystal
ReportsorbyspreadsheetssuchasExcelcanbeusedtoaccessdatafromdatabasesand
to generate tabular depictions of data or graphical depictions using charts or graphs.
Such charts can be embedded within text documents. The charts are created initially
from data generated by executing queries against the database; the queries can be re-
executed and the charts regenerated when required, to generate a current version of
theoverallreport.
Techniquesfordatavisualization,thatis,graphicalrepresentationofdata,thatgo
beyond the basic chart types, are very important for data analysis. Data-visualization
systems help users to examine large volumes of data and to detect patterns visually.
Visual displays of data—such as maps, charts, and other graphical representations—
allowdatatobepresentedcompactlytousers.Asinglegraphicalscreencanencodeas
muchinformationasafarlargernumberoftextscreens.
For example, if the user wants to find out whether the occurrence of a disease is
correlatedtothelocationsofthepatients,thelocationsofpatientscanbeencodedin
aspecialcolor—say,red—onamap.Theusercanthenquicklydiscoverlocationswhere
problemsareoccurring.Theusermaythenform hypothesesaboutwhyproblemsare
occurring in those locations and may verify the hypotheses quantitatively against the
database.
Asanotherexample,informationaboutvaluescanbeencodedasacolorandcan
be displayed with as little as one pixel of screen area. To detect associations between
pairs of items, we can use a two-dimensional pixel matrix, with each row and each
columnrepresentinganitem.Thepercentageoftransactionsthatbuybothitemscan
be encoded by the color intensity of the pixel. Items with high association will show
upasbrightpixelsinthescreen—easytodetectagainstthedarkerbackground.

--- Page 569 ---

540 Chapter11 DataAnalytics
In recentyears a number of tools have been developed for web-based data visual-
izationandforthecreationofdashboardsthatdisplaymultiplechartsshowingkeyor-
ganizational information. These include Tableau (www.tableau.com), FusionCharts
(www.fusioncharts.com),plotly(plot.ly),Datawrapper(www.datawrapper.de),and
Google Charts (developers.google.com/chart), among others. Since their display is
basedonHTMLandJavaScript,theycanbeusedonawidevarietyofbrowsersandon
mobiledevices.
Interactionisakeyelementofvisualization.Forexample,ausercan“drilldown”
into areas of interest, such as moving from an aggregate view showing the total sales
acrossanentireyeartothemonthlysalesfiguresforaparticularyear.Analystsmaywish
tointeractivelyaddselectionconditionstovisualizesubsetsofdata.Datavisualization
toolssuchasTableauofferarichsetoffeaturesforinteractivevisualization.
11.4 Data Mining
Thetermdataminingreferslooselytotheprocessofanalyzinglargedatabasestofind
usefulpatterns.Likeknowledgediscoveryinartificialintelligence(alsocalledmachine
learning) or statistical analysis, data mining attempts to discover rules and patterns
from data.However,dataminingdiffersfrom traditionalmachinelearningandstatis-
tics in that it deals with large volumes of data, stored primarily on disk. Today, many
machine-learningalgorithmsalsoworkonverylargevolumesofdata,blurringthedis-
tinctionbetweendataminingandmachinelearning.Data-miningtechniquesformpart
oftheprocessofknowledgediscoveryindatabases(KDD).
Sometypesofknowledgediscoveredfrom adatabase canberepresentedbyaset
ofrules.Thefollowingisanexampleofarule,statedinformally:“Youngwomenwith
annual incomes greater than $50,000 are the most likely people to buy small sports
cars.”Ofcoursesuchrulesarenotuniversallytrueandhavedegreesof“support”and
“confidence,”as we shall see. Othertypes of knowledge are represented by equations
relatingdifferentvariablestoeachother.Moregenerally,knowledgediscoveredbyap-
plying machine-learning techniques on past instances in a database is represented by
amodel,whichisthenusedforpredictingoutcomesfornewinstances.Featuresorat-
tributesofinstancesareinputstothemodel,andtheoutputofamodelisaprediction.
There are a variety of possible types of patterns that may be useful, and different
techniquesare used tofind differenttypes of patterns. We shall study afew examples
ofpatternsandseehowtheymaybeautomaticallyderivedfromadatabase.
Usuallythereisamanualcomponenttodatamining,consistingofpreprocessing
datatoaformacceptabletothealgorithmsandpost-processingofdiscoveredpatterns
tofindnovelonesthatcouldbeuseful.Theremayalsobemorethanonetypeofpattern
thatcanbediscoveredfromagivendatabase, andmanual interactionmaybe needed
topickusefultypesofpatterns.Forthisreason,dataminingisreallyasemiautomatic
processinreallife.However,inourdescriptionweconcentrateontheautomaticaspect
ofmining.

--- Page 570 ---

11.4 DataMining 541
11.4.1 Types of Data-Mining Tasks
The most widely used applications of data mining are those that require some sort
of prediction. For instance, when a person applies for a credit card, the credit-card
company wants to predict if the person is a good credit risk. The prediction is to be
based on known attributes of the person, such as age, income, debts, and past debt-
repaymenthistory.Rulesformakingthepredictionarederivedfromthesameattributes
of past and current credit-card holders, along with their observed behavior, such as
whether they defaulted on their credit-card dues. Other types of prediction include
predictingwhichcustomersmayswitchovertoacompetitor(thesecustomersmaybe
offered special discounts to tempt them not to switch), predicting which people are
likelytorespondtopromotionalmail(“junkmail”),orpredictingwhattypesofphone
calling-cardusagearelikelytobefraudulent.
Anotherclassofapplicationslooksforassociations,forinstance,booksthattend
tobeboughttogether.Ifacustomerbuysabook,anonlinebookstoremaysuggestother
associated books. If a person buys a camera, the system may suggest accessoriesthat
tend to be bought along with cameras. A good salesperson is aware of such patterns
andexploitsthemtomakeadditionalsales.Thechallengeistoautomatetheprocess.
Othertypesofassociationsmayleadtodiscoveryofcausation.Forinstance,discovery
ofunexpectedassociationsbetweenanewlyintroducedmedicineandcardiacproblems
ledtothefindingthatthemedicinemaycausecardiacproblemsinsomepeople.The
medicinewasthenwithdrawnfromthemarket.
Associationsarean exampleofdescriptivepatterns.Clusters areanotherexample
ofsuchpatterns.Forexample,overacenturyagoaclusteroftyphoidcaseswasfound
aroundawell,whichledtothediscoverythatthewaterinthewellwascontaminated
and was spreading typhoid. Detection of clusters of disease remains important even
today.
11.4.2 Classification
Abstractly,theclassificationproblemisthis:Giventhatitemsbelongtooneofseveral
classes, and given past instances (called training instances) of items along with the
classes to which they belong, the problem is to predict the class to which a new item
belongs.Theclassofthenewinstanceisnotknown,sootherattributesoftheinstance
mustbeusedtopredicttheclass.
Asanexample,supposethatacredit-cardcompanywantstodecidewhetherornot
togiveacreditcardtoan applicant.Thecompanyhasavarietyofinformationabout
theperson,suchasherage,educationalbackground,annualincome,andcurrentdebts,
thatitcanuseformakingadecision.
To make the decision, the company assigns a creditworthiness level of excellent,
good,average,orbadtoeachofasamplesetofcurrentorpastcustomersaccordingto
eachcustomer’spaymenthistory.Theseinstancesformthesetoftraininginstances.
Then, the company attempts to learn rules or models that classify the credit-
worthiness of a new applicant as excellent, good, average, or bad, on the basis of the

--- Page 571 ---

542 Chapter11 DataAnalytics
informationabouttheperson,otherthantheactualpaymenthistory(whichisunavail-
able for new customers). There are a number of techniques for classification, and we
outlineafewoftheminthissection.
11.4.2.1 Decision-TreeClassifiers
Decision-tree classifiers are a widely used technique for classification. As the name
suggests,decision-treeclassifiersuseatree;eachleafnodehasanassociatedclass,and
each internal node has a predicate (or more generally, a function) associated with it.
Figure11.11showsanexampleofadecisiontree.Tokeeptheexamplesimple,weuse
justtwoattributes:educationlevel(highestdegreeearned)andincome.
Toclassifyanewinstance,westartattherootandtraversethetreetoreachaleaf;
ataninternalnodeweevaluatethepredicate(orfunction)onthedatainstancetofind
whichchildtogoto.Theprocesscontinuesuntilwereachaleafnode.Forexample,if
thedegreelevelofapersonismasters,andtheperson’sincomeis40K,startingfrom
therootwefollowtheedgelabeled“masters,”andfromtheretheedgelabeled“25Kto
75K,”toreachaleaf.Theclassattheleafis“good,”sowepredictthatthecreditrisk
ofthatpersonisgood.
Thereareanumberoftechniquesforbuildingdecision-treeclassifiersfromagiven
training set. We omit details, but you can learn more details from the references pro-
videdintheFurtherReadingsection.
degree
none bachelors masters doctorate
income income income income
<50K >100K <25K >75K
<25K >=25K
50 to 100K <50K >=50K 25 to 75K
bad average good
bad average good excellent
Figure 11.11 Classificationtree.

--- Page 572 ---

11.4 DataMining 543
11.4.2.2 BayesianClassifiers
Bayesianclassifiersfindthedistributionofattributevaluesforeachclassinthetraining
data; when given a new instance d, they use the distribution information to estimate,
foreachclassc,theprobabilitythatinstanced belongstoclassc,denotedbyp(c|d),
j j j
inamanneroutlinedhere.Theclasswithmaximumprobabilitybecomesthepredicted
classforinstanced.
To find the probability p(c|d) of instance d being in class c, Bayesian classifiers
j j
useBayes’theorem,whichsays:
p(d|c)p(c)
p(c|d) = j j
j p(d)
wherep(d|c)istheprobabilityofgeneratinginstancedgivenclassc,p(c)istheprob-
j j j
abilityofoccurrenceofclassc,andp(d)istheprobabilityofinstanced occurring.Of
j
these,p(d)canbeignoredsinceitisthesameforallclasses.p(c)issimplythefraction
j
oftraininginstancesthatbelongtoclassc.
j
For example, let us consider a special case where only one attribute, income, is
used for classification, and suppose we need to classify a person whose income is
76,000. We assume that income values are broken up into buckets, and we assume
thatthebucketcontaining76,000containsvaluesintherange(75,000, 80,000).Sup-
pose among instances of class excellent, the probability of income being in (75,000,
80,000)is0.1,whileamonginstancesofclassgood,theprobabilityofincomebeingin
(75,000,80,000)is0.05.Supposealsothatoverall0.1fractionofpeopleareclassified
as excellent, and 0.3 are classified as good. Then, p(d|c)p(c) forclass excellent is .01,
j j
whileforclassgood,itis0.015.Thepersonwouldthereforebeclassifiedinclassgood.
Ingeneral,multipleattributesneedtobeconsideredforclassification.Then,find-
ingp(d|c)exactlyisdifficult,sinceitrequiresthedistributionofinstancesofc,across
j j
allcombinationsofvaluesfortheattributesusedforclassification.Thenumberofsuch
combinations(forexampleofincomebuckets,withdegreevaluesandotherattributes)
canbeverylarge.Withalimitedtrainingsetusedtofindthedistribution,mostcombi-
nationswouldnothaveevenasingletrainingsetmatchingthem,leadingtoincorrect
classificationdecisions.Toavoidthisproblem,aswellastosimplifythetaskofclassifi-
cation,naiveBayesianclassifiersassumeattributeshaveindependentdistributionsand
therebyestimate:
p(d|c) = p(d |c) ∗ p(d |c) ∗ ⋯ ∗ p(d |c)
j 1 j 2 j n j
Thatis,theprobabilityoftheinstanced occurringistheproductoftheprobabilityof
occurrenceofeachoftheattributevaluesd ofd,giventheclassisc.
i j
Theprobabilitiesp(d|c)derivefromthedistributionofvaluesforeachattributei,
i j
foreachclassc.Thisdistributioniscomputedfromthetraininginstancesthatbelong
j
toeachclassc;thedistributionisusuallyapproximatedbyahistogram.Forinstance,
j
wemaydividetherangeofvaluesofattributeiintoequalintervals,andstorethefrac-
tionofinstancesofclassc thatfallineachinterval.Givenavalued forattributei,the
j i

--- Page 573 ---

544 Chapter11 DataAnalytics
valueofp(d|c)issimplythefractionofinstancesbelongingtoclassc thatfallinthe
i j j
intervaltowhichd belongs.
i
11.4.2.3 SupportVectorMachineClassifiers
The Support Vector Machine (SVM) is a type of classifier that has been found to give
very accurate classification across a range of applications. We provide some basic in-
formation about Support Vector Machine classifiers here; see the references in the
bibliographicalnotesforfurtherinformation.
Support Vector Machine classifiers can best be understood geometrically. In the
simplest case, considera set of points in a two-dimensionalplane, some belonging to
classA,andsomebelongingtoclassB.Wearegivenatrainingsetofpointswhoseclass
(AorB)isknown,andweneedtobuildaclassifierofpointsusingthesetrainingpoints.
ThissituationisillustratedinFigure11.12,wherethepointsinclassAaredenotedby
Xmarks,whilethoseinclassBaredenotedbyOmarks.
Supposewecandrawalineontheplane,suchthatallpointsinclassAlietoone
side and all points in line B lie to the other. Then, the line can be used to classify
newpoints,whoseclasswedon’talreadyknow.Buttheremaybemanypossiblesuch
lines that can separate points in class A from points in class B. A few such lines are
showninFigure11.12.TheSupportVectorMachineclassifierchoosesthelinewhose
distancefromthenearestpointineitherclass(fromthepointsinthetrainingdataset)
ismaximum.Thisline(calledthemaximummarginline)isthenusedtoclassifyother
pointsintoclassAorB,dependingonwhichsideofthelinetheylieon.InFigure11.12,
themaximummarginlineisshowninbold,whiletheotherlinesareshownasdashed
lines.
Figure 11.12 ExampleofaSupportVectorMachineclassifier.

--- Page 574 ---

11.4 DataMining 545
The preceding intuition can be generalized to more than two dimensions, allow-
ing multiple attributes to be used for classification; in this case, the classifier finds a
dividingplane,notaline.Further,byfirsttransformingtheinputpointsusingcertain
functions,calledkernelfunctions,SupportVectorMachineclassifierscanfindnonlin-
ear curves separating the sets of points. This is important for cases where the points
arenotseparablebyalineorplane.Inthepresenceofnoise,somepointsofoneclass
may lie in the midst of points of the other class. In such cases, there may not be any
lineormeaningfulcurvethatseparates thepointsinthetwoclasses;then,thelineor
curvethatmostaccuratelydividesthepointsintothetwoclassesischosen.
Although the basic formulation of Support Vector Machines is for binary classi-
fiers,i.e.,thosewithonlytwoclasses,theycanbeusedforclassificationintomultiple
classesasfollows:IfthereareN classes,webuildN classifiers,withclassifieriperform-
ingabinaryclassification,classifyingapointeitherasinclassiornotinclassi.Given
apoint,eachclassifieri alsooutputsavalueindicatinghowrelatedagivenpointisto
classi.WethenapplyallN classifiersonagivenpointandchoosetheclassforwhich
therelatednessvalueisthehighest.
11.4.2.4 NeuralNetworkClassifiers
Neural-netclassifiersusethetrainingdatatotrainartificialneuralnets.Thereisalarge
bodyofliterature on neural nets;wedonotprovide detailshere,butweoutlineafew
keypropertiesofneuralnetworkclassifiers.
Neuralnetworksconsistofseverallayersof“neurons,”eachofwhichareconnected
to neurons in the preceding layer. An input instance of the problem is fed to the first
layer; neurons at each layer are “activated” based on some function applied to the
inputsattheprecedinglayer.Thefunctionappliedateachneuroncomputesaweighted
combinationoftheactivationsoftheinputneuronsandgeneratesanoutputbasedon
the weighted combination. The activation of a neuron in one layer thus affects the
activationofneuronsinthenextlayer.Thefinaloutputlayertypicallyhasoneneuron
correspondingtoeachclassoftheclassificationproblembeingaddressed.Theneuron
withmaximumactivationforagiveninputdecidesthepredictedclassforthatinput.
Key to the success of a neural network is the weights used in the computation
described above. These weightsare learned, based on training data. They are initially
settosomedefaultvalue,andthentrainingdataareusedtolearntheweights.Training
istypicallydonebyapplyingeachinputtothecurrentstateoftheneuralnetworkand
checkingifthepredictioniscorrect.Ifnot,abackpropagationalgorithmisusedtotweak
theweightsoftheneuronsinthenetwork,tobringthepredictionclosertothecorrect
one for the current input. Repeating this process results in a trained neural network,
whichcanthenbeusedforclassificationonnewinputs.
Inrecentyears, neuralnetworkshaveachievedagreatdegreeofsuccessfortasks
which were earlier considered very hard, such as vision (e.g., recognition of objects
in images), speech recognition, and natural language translation. A simple example
ofavisiontaskisthatofidentifyingthespecies,suchascatordog,givenanimageof

--- Page 575 ---

546 Chapter11 DataAnalytics
ananimal;suchproblemsarebasicallyclassificationproblems.Otherexamplesinclude
identifyingobjectoccurrencesinanimageandassigningaclasslabeltoeachidentified
object.
Deep neural networks, which are neural networks with a large number of layers,
have proven very successful at such tasks, if given a very large number of training in-
stances. The term deep learning refers to the machine-learningtechniques that create
suchdeepneuralnetworks,andtrainthemonverylargenumbersoftraininginstances.
11.4.3 Regression
Regressiondealswiththepredictionofavalue,ratherthanaclass.Givenvaluesfora
setofvariables,X ,X ,…,X ,wewishtopredictthevalueofavariableY.Forinstance,
1 2 n
wecouldtreatthelevelofeducationasanumberandincomeasanothernumber,and,
onthebasisofthesetwovariables,wewishtopredictthelikelihoodofdefault,which
couldbeapercentagechanceofdefaulting,ortheamountinvolvedinthedefault.
Onewayistoinfercoefficientsa ,a ,a ,…,a suchthat:
0 1 2 n
Y = a +a ∗ X +a ∗ X +⋯+a ∗ X
0 1 1 2 2 n n
Findingsuchalinearpolynomialiscalledlinearregression.Ingeneral,wewishtofind
acurve(definedbyapolynomialorotherformula)thatfitsthedata;theprocessisalso
calledcurvefitting.
The fit may be only approximate, because of noise in the data or because the re-
lationshipisnotexactlyapolynomial,soregressionaimstofindcoefficientsthatgive
the best possible fit. There are standard techniques in statistics for finding regression
coefficients. We do not discuss these techniques here, but the bibliographical notes
providereferences.
11.4.4 Association Rules
Retail shops are often interested in associations between different items that people
buy.Examplesofsuchassociationsare:
• Someonewhobuysbreadisquitelikelyalsotobuymilk.
• ApersonwhoboughtthebookDatabaseSystemConceptsisquitelikelyalsotobuy
thebookOperatingSystemConcepts.
Associationinformationcanbeusedinseveralways.Whenacustomerbuysaparticu-
larbook,anonlineshopmaysuggestassociatedbooks.Agroceryshopmaydecideto
placebreadclosetomilk,sincetheyareoftenboughttogether,tohelpshoppersfinish
theirtaskfaster.Or,theshopmayplacethematoppositeendsofarowandplaceother
associateditemsinbetweentotemptpeopletobuythoseitemsaswellastheshoppers
walkfromoneendoftherowtotheother.Ashopthatoffersdiscountsononeassoci-

--- Page 576 ---

11.4 DataMining 547
ateditemmaynotofferadiscountontheother,sincethecustomerwillprobablybuy
theotheranyway.
Anexampleofanassociationruleis:
bread ⇒ milk
Inthecontextofgrocery-storepurchases,therulesaysthatcustomerswhobuybread
also tend to buy milk with a high probability. An association rule must have an as-
sociatedpopulation:Thepopulationconsistsofasetofinstances.Inthegrocery-store
example,thepopulationmayconsistofallgrocery-storepurchases;eachpurchaseisan
instance.Inthecaseofabookstore,thepopulationmayconsistofallpeoplewhomade
purchases,regardlessofwhentheymadeapurchase.Eachcustomerisaninstance.In
the bookstore example, the analyst has decided that when a purchase is made is not
significant, whereas for the grocery-store example, the analyst may have decided to
concentrateonsinglepurchases,ignoringmultiplevisitsbythesamecustomer.
Rules have an associated support, as well as an associated confidence. These are
definedinthecontextofthepopulation:
• Support is a measure of what fraction of the population satisfies both the an-
tecedentandtheconsequentoftherule.
For instance, suppose only 0.001 percent of all purchases include milk and
screwdrivers.Thesupportfortherule:
milk ⇒ screwdrivers
islow.Therulemaynotevenbestatisticallysignificant—perhapstherewasonlya
single purchase that included both milk and screwdrivers.Businesses are usually
notinterestedinrulesthathavelowsupport,sincetheyinvolvefewcustomersand
arenotworthbotheringabout.
Ontheotherhand,if50percentofallpurchasesinvolvemilkandbread,then
support for rules involving bread and milk (and no otheritem) is relativelyhigh,
andsuchrulesmaybeworthattention.Exactlywhatminimumdegreeofsupport
isconsidereddesirabledependsontheapplication.
• Confidenceisameasureofhowoftentheconsequentistruewhentheantecedent
istrue.Forinstance,therule:
bread ⇒ milk
has a confidence of 80 percent if 80 percent of the purchases that include bread
also include milk. A rule with a low confidence is not meaningful. In business
applications, rules usually have confidences significantly less than 100 percent,
whereasinotherdomains,suchasinphysics,rulesmayhavehighconfidences.
Note that the confidence of bread ⇒ milk may be very different from the
confidenceofmilk ⇒bread,althoughbothhavethesamesupport.

--- Page 577 ---

548 Chapter11 DataAnalytics
11.4.5 Clustering
Intuitively, clustering refers to the problem of finding clusters of points in the given
data. The problem of clustering can be formalized from distance metrics in several
ways.Onewayistophraseitastheproblemofgroupingpointsintoksets(foragiven
k) so that the average distance of points from the centroid of their assigned cluster
is minimized. 3 Another way is to group points so that the average distance between
every pair of points in each cluster is minimized.There are other definitions too; see
thebibliographicalnotesfordetails.Buttheintuitionbehindallthesedefinitionsisto
groupsimilarpointstogetherinasingleset.
Anothertypeofclusteringappearsinclassificationsystemsinbiology.(Suchclas-
sification systems do not attempt to predict classes; rather they attempt to cluster re-
lateditemstogether.)Forinstance,leopardsandhumansareclusteredundertheclass
mammalia, while crocodiles and snakes are clustered under reptilia. Both mammalia
andreptiliacomeunderthecommonclasschordata.Theclusteringofmammaliahas
furthersubclusters,suchascarnivoraandprimates.Wethushavehierarchicalcluster-
ing. Given characteristics of differentspecies, biologists have created a complex hier-
archical clustering scheme grouping related species together at different levels of the
hierarchy.
Thestatisticscommunityhasstudiedclusteringextensively.Databaseresearchhas
provided scalable clustering algorithms that can cluster very large datasets (that may
notfitinmemory).
Aninterestingapplicationofclusteringistopredictwhatnewmovies(orbooksor
music)apersonislikelytobeinterestedinonthebasisof:
1. Theperson’spastpreferencesinmovies.
2. Otherpeoplewithsimilarpastpreferences.
3. Thepreferencesofsuchpeoplefornewmovies.
Oneapproachtothisproblemisasfollows:Tofindpeoplewithsimilarpastpreferences
we create clusters of people based on their preferences for movies. The accuracy of
clusteringcanbeimprovedbypreviouslyclusteringmoviesbytheirsimilarity,soeven
if people have not seen the same movies, if they have seen similarmoviesthey would
beclusteredtogether.Wecanrepeattheclustering,alternatelyclusteringpeople,then
movies, then people, and so on until we reach an equilibrium. Given a new user, we
find a cluster of users most similarto that user, on the basis of the user’s preferences
for movies already seen. We then predict movies in movie clusters that are popular
withthatuser’sclusteraslikelytobeinterestingtothenewuser.Infact,thisproblem
3Thecentroidofasetofpointsisdefinedasapointwhosecoordinateoneachdimensionistheaverageofthecoor-
dinatesofallthepointsofthatsetonthatd(im
∑
ension
∑
.Fore)xample,intwodimensions,thecentroidofasetofpoints
{(x ,y ),(x ,y ),…,(x ,y )}isgivenby n i=1 xi, n i=1 yi .
1 1 2 2 n n n n

--- Page 578 ---

11.4 DataMining 549
is an instance of collaborative filtering, where users collaborate in the task of filtering
informationtofindinformationofinterest.
11.4.6 Text Mining
Textminingappliesdata-miningtechniquestotextualdocuments.Thereareanumber
of different text mining tasks. One such task is sentiment analysis. For example, sup-
pose a company wishes to find out how users have reacted to a new product. There
are typically a large number of product reviews on the web—for example, reviews by
different users on e-commerce platforms. Reading each review to find out reactions
is not practical for a human. Instead, the company may analyze reviews to find the
sentiment of the reviews of the product; the sentiment could be positive, negative, or
neutral.Theoccurrenceofspecificwordssuchasexcellent,good,awesome,beautiful,
andsoonarecorrelatedwithapositivesentiment,whilewordssuchasawful,average,
worthless,poorquality,andsoonarecorrelatedwithanegativesentiment.Sentiment
analysis techniques can be used to analyze the reviews and come up with an overall
scorereflectingthebroadsenseofthereviews.
Anothertaskisinformationextraction,whichcreatesstructuredinformationfrom
unstructured textual descriptions, or semi-structured data such as tabular displays of
dataindocuments.Akeysubtaskofthisprocessisentityrecognition,thatis,thetaskof
identifyingmentionsofentitiesintextanddisambiguatingthem.Forexample,anarti-
clemaymentionthenameMichaelJordan.Thereareatleasttwofamouspeoplenamed
MichaelJordan:onewasabasketballplayer,whiletheotherisaprofessorwhoisawell
known machine-learning expert. Disambiguation is the process of figuring out which
ofthesetwoisbeingreferredtoinaparticulararticle,anditcanbedonebasedonthe
articlecontext;inthiscase,anoccurrenceofthenameMichaelJordaninasportsarti-
cleprobablyreferstothebasketballplayer,whileanoccurrenceinamachine-learning
paperprobablyreferstotheprofessor. Afterentityrecognition,othertechniquesmay
beusedtolearnattributesofentitiesandtolearnrelationshipsbetweenentities.
Informationextraction can be used inmany ways. Forexample, itcan be used to
analyze customer support conversations or reviews posted on social media, to judge
customersatisfaction,andtodecidewheninterventionisneededtoretaincustomers.
Serviceprovidersmaywanttoknowwhataspectoftheservicesuchaspricing,quality,
hygiene,orbehaviorofthepersonprovidingtheservice,areviewwaspositiveornega-
tiveabout;informationextractiontechniquescanbeusedtoinferwhataspectanarticle
or a part of an article isabout, and to infer the associated sentiment. Attributes such
asthelocationofservicecanalsobeextractedandareimportantfortakingcorrective
action.
Information extracted from the enormous collection of documents and other re-
sourcesonthewebcanbevaluableformanytasks.Suchextractedinformationcanbe
represented in a graph, calleda knowledge graph, whichwe outlined in Section 8.1.4.
Such knowledge graphs are used by web search engines to generate more meaningful
answerstouserqueries.

--- Page 579 ---

550 Chapter11 DataAnalytics
11.5 Summary
• Dataanalyticssystemsanalyzeonlinedatacollectedbytransaction-processingsys-
tems,alongwithdatacollectedfromothersources,tohelppeoplemakebusiness
decisions. Decision-support systems come in various forms, including OLAP sys-
temsanddata-miningsystems.
• Datawarehouseshelpgatherandarchiveimportantoperationaldata.Warehouses
areusedfordecisionsupportandanalysisonhistoricaldata,forinstance,topre-
dict trends. Data cleansing from input data sources is often a major task in data
warehousing. Warehouse schemas tend to be multidimensional, involving one or
afewverylargefacttablesandseveralmuchsmallerdimensiontables.
• Onlineanalyticalprocessing(OLAP)toolshelpanalystsviewdatasummarizedin
differentways,sothattheycangaininsightintothefunctioningofanorganization.
° OLAP tools work on multidimensional data, characterized by dimension at-
tributesandmeasureattributes.
° Thedatacubeconsistsofmultidimensionaldatasummarizedindifferentways.
Precomputingthedatacubehelpsspeedupqueriesonsummariesofdata.
° Cross-tab displays permit users to view two dimensions of multidimensional
dataatatime,alongwithsummariesofthedata.
° Drilldown,rollup,slicing,anddicingareamongtheoperationsthatusersper-
formwithOLAPtools.
• TheSQLstandardprovidesavarietyofoperatorsfordataanalysis,includingcube,
rollup,andpivotoperations.
• Dataminingistheprocessofsemiautomaticallyanalyzinglargedatabasestofind
usefulpatterns.Thereareanumberofapplicationsofdatamining,suchaspredic-
tionofvaluesbasedonpastexamples,findingofassociationsbetweenpurchases,
andautomaticclusteringofpeopleandmovies.
• Classification deals with predicting the class of test instances by using attributes
ofthetestinstances,basedonattributesoftraininginstances,andtheactualclass
oftraininginstances.Thereareseveraltypesofclassifiers,suchas:
° Decision-tree classifiers, which perform classification by constructing a tree
basedontraininginstanceswithleaveshavingclasslabels.
° Bayesianclassifiers,whicharebasedonprobabilitytheory.
° Thesupportvectormachineisanotherwidelyusedclassificationtechnique.
° Neural networks, and in particular deep learning, has been very successful in
classificationandrelatedtasksinthecontextofvision,speechrecognition,and
languageunderstandingandtranslation.

--- Page 580 ---

PracticeExercises 551
• Association rules identify items that co-occur frequently, for instance, items that
tend to be bought by the same customer. Correlations look for deviations from
expectedlevelsofassociation.
• Othertypesofdataminingincludeclusteringandtextmining.
Review Terms
• Decision-supportsystems ° Rollupanddrilldown
• Businessintelligence ° SQLgroupbycube,groupbyrollup
• Datawarehousing
• Datavisualization
° Gatheringdata • Datamining
° Source-drivenarchitecture • Prediction
° Destination-drivenarchitecture • Classification
° Datacleansing ° Trainingdata
° Extract,transform,load(ETL) ° Testdata
° Extract,load,transform(ELT) • Decision-treeclassifiers
• Warehouseschemas • Bayesianclassifiers
° Facttable ° Bayes’theorem
° Dimensiontables ° NaiveBayesianclassifiers
° Starschema • SupportVectorMachine(SVM)
° Snowflakeschema • Regression
• Column-orientedstorage • Neural-networks
• Onlineanalyticalprocessing • Deeplearning
(OLAP) • Associationrules
• Multidimensionaldata • Clustering
• Textmining
° Measureattributes
° Dimensionattributes ° Sentimentanalysis
° Hierarchy ° Informationextraction
° Cross-tabulation/Pivoting ° Namedentityrecognition
° Datacube ° Knowledgegraph

--- Page 581 ---

552 Chapter11 DataAnalytics
Practice Exercises
11.1 Describebenefitsanddrawbacksofasource-drivenarchitectureforgathering
ofdataatadatawarehouse,ascomparedtoadestination-drivenarchitecture.
11.2 Drawadiagramthatshowshowtheclassroomrelationofouruniversityexam-
pleasshowninAppendixAwouldbestoredunderacolumn-orientedstorage
structure.
11.3 Consider the takes relation. Write an SQL query that computes a cross-tab
that has a column for each of the years 2017 and 2018, and a column for all,
and one row for each course, as well as a row for all. Each cell in the table
shouldcontainthenumberofstudentswhotookthecorrespondingcoursein
the corresponding year, with column all containing the aggregate across all
years,androwallcontainingtheaggregateacrossallcourses.
11.4 Consider the data warehouse schema depicted in Figure 11.2. Give an SQL
querytosummarizesalesnumbersandpricebystoreanddate,alongwiththe
hierarchiesonstoreanddate.
11.5 Classification can be done using classification rules, whichhave acondition, a
class,andaconfidence;theconfidenceisthepercentageoftheinputssatisfying
theconditionthatfallinthespecifiedclass.
For example, a classification rule for credit ratings may have a condition
that salary is between $30,000 and $50,000, and education level is graduate,
withthecreditratingclassofgood,andaconfidenceof80%.Asecondrulemay
have a condition that salary is between $30,000 and $50,000, and education
levelishigh-school,withthecreditratingclassofsatisfactory,andaconfidence
of 80%. A third rule may have a condition that salary is above $50,001, with
thecreditratingclassofexcellent,andconfidenceof90%.Showadecisiontree
classifiercorrespondingtotheaboverules.
Showhow thedecisiontreeclassifiercanbeextended torecordtheconfi-
dencevalues.
11.6 Consideraclassificationproblem wherethe classifierpredictswhethera per-
son has a particular disease. Suppose that 95% of the people tested do not
suffer from the disease. Let pos denote the fraction of true positives, which is
5%ofthetestcases,andletnegdenotethefractionoftruenegatives,whichis
95%ofthetestcases.Considerthefollowingclassifiers:
• ClassifierC ,whichalwayspredictsnegative(aratheruselessclassifier,of
1
course).
• ClassifierC ,whichpredictspositivein80%ofthecaseswheretheperson
2
actuallyhasthediseasebutalsopredictspositivein5%ofthecaseswhere
thepersondoesnothavethedisease.

--- Page 582 ---

Exercises 553
• ClassifierC ,whichpredictspositivein95%ofthecaseswheretheperson
3
actuallyhasthediseasebutalsopredictspositivein20%ofthecaseswhere
thepersondoesnothavethedisease.
Foreachclassifier,lett posdenotethetruepositivefraction,thatisthefraction
of cases where the classifier prediction was positive, and the person actually
hadthedisease.Letf posdenotethefalsepositivefraction,thatisthefraction
of cases where the prediction was positive, but the person did not have the
disease.Lett negdenotetruenegativeandf negdenotefalsenegativefractions,
which are defined similarly, but for the cases where the classifier prediction
wasnegative.
a. Computethefollowingmetricsforeachclassifier:
i. Accuracy,definedas(t pos+t neg)∕(pos+neg),thatis,thefractionof
thetimewhentheclassifiergivesthecorrectclassification.
ii. Recall (also known as sensitivity) defined as t pos∕pos, that is, how
manyoftheactualpositivecasesareclassifiedaspositive.
iii. Precision,definedast pos/(t pos+f pos),thatis,howoftenthepositive
predictioniscorrect.
iv. Specificity,definedast neg/neg.
b. Ifyouintendtousetheresultsofclassificationtoperformfurtherscreen-
ingforthedisease,howwouldyouchoosebetweentheclassifiers?
c. Ontheotherhand,ifyouintendtousetheresultofclassificationtostart
medication,wherethemedicationcouldhaveharmfuleffectsifgivento
someonewhodoesnothavethedisease,howwouldyouchoosebetween
theclassifiers?
Exercises
11.7 Whyiscolumn-orientedstoragepotentiallyadvantageousinadatabasesystem
thatsupportsadatawarehouse?
11.8 Considereachofthetakesandteachesrelationsasafacttable;theydonothave
an explicit measure attribute, but assume each table has a measure attribute
reg count whose value is always 1. What would the dimension attributes and
dimensiontablesbeineachcase.Wouldtheresultantschemasbestarschemas
orsnowflakeschemas?
11.9 Consider the star schema from Figure 11.2. Suppose an analyst finds that
monthlytotalsales(sumofthepricevaluesofallsalestuples)havedecreased,
insteadofgrowing,fromApril2018toMay2018.Theanalystwishestocheck
if there are specific item categories, stores, or customer countries that are re-
sponsibleforthedecrease.

--- Page 583 ---

554 Chapter11 DataAnalytics
a. Whataretheaggregatesthattheanalystwouldstartwith,andwhatare
the relevant drill-down operations that the analyst would need to exe-
cute?
b. WriteanSQLquerythatshowstheitemcategoriesthatwereresponsible
for the decrease in sales, ordered by the impact of the category on the
salesdecrease,withcategoriesthathadthehighestimpactsortedfirst.
11.10 Supposehalfofallthetransactionsinaclothesshoppurchasejeans,andone-
third of all transactions in the shop purchase T-shirts. Suppose also that half
ofthetransactionsthatpurchase jeansalsopurchase T-shirts.Write downall
the(nontrivial)associationrulesyoucandeducefromtheaboveinformation,
givingsupportandconfidenceofeachrule.
11.11 Theorganizationofparts,chapters,sections,andsubsectionsinabookisre-
latedtoclustering.Explainwhy,andtowhatformofclustering.
11.12 Suggesthowpredictiveminingtechniquescanbeusedbyasportsteam,using
yourfavoritesportasanexample.
Tools
DatawarehousesystemsareavailablefromTeradata,TeradataAster,SAPIQ(formerly
known as Sybase IQ), and Amazon Redshift, all of which support parallel process-
ingacrossalargenumberofmachines.AnumberofdatabasesincludingOracle,SAP
HANA, Microsoft SQLServer, and IBM DB2 support data warehouse applications by
adding features such as columnar storage. There are a number of commercial ETL
tools includingtools from Informatica,Business Objects, IBMInfoSphere,Microsoft
Azure Data Factory, Microsoft SQL Server Integration Services, Oracle Warehouse
Builder, and Pentaho Data Integration. Open-source ETL tools include Apache NiFi
(nifi.apache.org), Jasper ETL (www.jaspersoft.com/data-integration) and Talend
(sourceforge.net/projects/talend-studio). Apache Kafka (kafka.apache.org) can
alsobeusedtobuildETLsystems.
MostdatabasevendorsprovideOLAPtoolsaspartoftheirdatabasesystems,oras
add-onapplications.TheseincludeOLAPtoolsfromMicrosoftCorp.,Oracle,IBMand
SAP.TheMondrianOLAPserver(github.com/pentaho/mondrian)isanopen-source
OLAPserver.ApacheKylin(kylin.apache.org)isanopen-sourcedistributedanalytics
enginewhichcanprocessdatastoredinHadoop,buildOLAPcubesandstorethemin
the HBase key-value store, and then query the stored cubes using SQL. Many compa-
niesalsoprovideanalysistoolsforspecificapplications,suchascustomerrelationship
management.
Tools for visualization include Tableau (www.tableau.com), FusionCharts
(www.fusioncharts.com),plotly(plot.ly),Datawrapper(www.datawrapper.de),and
GoogleCharts(developers.google.com/chart).

--- Page 584 ---

FurtherReading 555
The Python language isvery popular for machine-learningtasks, due to the avail-
abilityofanumberofopen-sourcelibrariesformachine-learningtasks.TheRlanguage
isalsousedwidelyforstatisticalanalysisandmachinelearning,forthesamereasons.
Popular utility libraries in Python include are NumPy (www.numpy.org) which pro-
vides operations on arrays and matrices, SciPy (www.scipy.org), which provides lin-
ear algebra, optimization and statistics functions, and Pandas (pandas.pydata.org),
which provides a relational abstraction of data. Popular machine-learning libraries
in Python include SciKit-Learn (scikit-learn.org), which adds image-processing and
machine-learning functionality to SciPy. Deep learning libraries in Python include
Keras (keras.io), and TensorFlow (www.tensorflow.org) which was developed by
Google;TensorFlowprovidesAPIsinseverallanguages,withparticularlygoodsupport
forPython.Textminingissupported bynaturallanguageprocessinglibraries,suchas
NLTK(www.nltk.org)andwebcrawlinglibraries,suchasScrapy(scrapy.org).Visu-
alizationissupportedbylibrariessuchasMatplotlib(matplotlib.org),Plotly(plot.ly)
andBokeh(bokeh.pydata.org).
Open-source tools for data mining include RapidMiner (rapidminer.com), Weka
(www.cs.waikato.ac.nz/ml/weka),andOrange(orange.biolab.si).Commercialtools
includeSASEnterpriseMiner,IBMIntelligentMiner,andOracleDataMining.
Further Reading
[Kimball et al. (2008)] and [Kimball and Ross (2013)] provide textbook coverage of
datawarehousesandmultidimensionalmodeling.
[Mitchell(1997)] isaclassictextbook on machinelearningand coversclassifica-
tiontechniquesindetail.[Goodfellowetal.(2016)]isadefinitivetextondeeplearning.
[Wittenetal.(2011)]and[Hanetal.(2011)]providetextbookcoverageofdatamining.
[Agrawaletal.(1993)]introducedthenotionofassociationrules.
Information about the R language and environment may be found at
www.r-project.org;informationabouttheSparkRpackage,whichprovidesanRfron-
tendtoApacheSpark,maybefoundatspark.apache.org/docs/latest/sparkr.html.
[Chakrabarti(2002)],[Manningetal.(2008)]and[Baeza-YatesandRibeiro-Neto
(2011)]providetextbookdescriptionofinformationretrieval,includingextensivecov-
erage ofdata-miningtasks relatedtotextual andhypertext data,such asclassification
andclustering.
Bibliography
[Agrawaletal.(1993)] R.Agrawal,T.Imielinski,andA.Swami,“MiningAssociationRules
betweenSetsofItemsinLargeDatabases”,InProc.oftheACMSIGMODConf.onManage-
mentofData(1993),pages207–216.
[Baeza-YatesandRibeiro-Neto(2011)] R.Baeza-YatesandB.Ribeiro-Neto,ModernInforma-
tionRetrieval,2ndedition,ACMPress(2011).

--- Page 585 ---

556 Chapter11 DataAnalytics
[Chakrabarti(2002)] S.Chakrabarti,MiningtheWeb:DiscoveringKnowledgefromHyperText
Data,MorganKaufmann(2002).
[Goodfellowetal.(2016)] I. Goodfellow, Y.Bengio, and A. Courville, Deep Learning, MIT
Press(2016).
[Hanetal.(2011)] J. Han, M. Kamber, and J. Pei, Data Mining: Concepts and Techniques,
3rdedition,MorganKaufmann(2011).
[KimballandRoss(2013)] R. Kimball and M. Ross, “The Data Warehouse Tookit: The
DefinitiveGuidetoDimensionalModeling”,JohnWileyandSons(2013).
[Kimballetal.(2008)] R. Kimball, M. Ross, W. Thornthwaite, J. Mundy, and B. Becker,
“TheDataWarehouseLifecycleToolkit”,JohnWileyandSons(2008).
[Manningetal.(2008)] C.D.Manning,P.Raghavan,andH.Sch¨utze,IntroductiontoInfor-
mationRetrieval,CambridgeUniversityPress(2008).
[Mitchell(1997)] T.M.Mitchell,MachineLearning,McGrawHill(1997).
[Wittenetal.(2011)] I. H. Witten, E. Frank, and M. Hall, Data Mining: Practical Machine
Learning Tools and Techniques with Java Implementations, 3rd edition, Morgan Kaufmann
(2011).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 586 ---

5
PART
STORAGE MANAGEMENT
AND INDEXING
Althoughadatabasesystemprovidesahigh-levelviewofdata,ultimatelydatahaveto
bestored asbitsononeormorestorage devices.Avast majorityofdatabasesystems
todaystoredataonmagneticdisk,withdatahavinghigherperformancerequirements
storedonflash-basedsolid-statedrives.Databasesystemsfetchdataintomainmemory
for processing, and write data back to storage for persistence. Data are also copied
totapesandotherbackupdevicesforarchivalstorage.Thephysicalcharacteristicsof
storagedevicesplayamajorroleinthewaydataarestored,inparticularbecauseaccess
toarandompieceofdataonmagneticdiskismuchslowerthanmain-memoryaccess.
Magneticdiskaccesstakestensofmilliseconds,flash-basedstorageaccesstakes20to
100microseconds,whereasmain-memoryaccesstakesatenthofamicrosecond.
Chapter12beginswithanoverviewofphysicalstoragemedia,includingmagnetic
disksandflash-basedsolid-statedrives(SSD).Thechapterthencoversmechanismsto
minimizethe chanceof data loss due to devicefailures,includingRAID. The chapter
concludeswithadiscussionoftechniquesforefficientdisk-blockaccess.
Chapter13describeshowrecordsaremappedtofiles,whichinturn aremapped
to bits on the disk. The chapter then covers techniques for the efficient management
ofthemain-memorybufferfordisk-baseddata.Column-orientedstorage,usedindata
analyticssystems,isalsocoveredinthischapter.
Many queriesreference onlya smallproportion of the records ina file.An index
isastructurethathelpslocatedesiredrecordsofarelationquickly,withoutexamining
allrecords.Chapter14describesseveraltypesofindicesusedindatabasesystems.
557

--- Page 588 ---

12
CHAPTER
Physical Storage Systems
Inprecedingchapters,wehaveemphasizedthehigher-levelmodelsofadatabase.For
example, at the conceptual or logical level, we viewed the database, in the relational
model,asacollectionoftables.Indeed,thelogicalmodelofthedatabaseisthecorrect
level for database users to focus on. This is because the goal of a database system is
to simplify and facilitate access to data; users of the system should not be burdened
unnecessarilywiththephysicaldetailsoftheimplementationofthesystem.
In this chapter, however, as well as in Chapter 13, Chapter 14, Chapter 15, and
Chapter16,weprobebelowthehigherlevelsaswedescribevariousmethodsforimple-
mentingthedatamodelsandlanguagespresentedinprecedingchapters.Westartwith
characteristics of the underlying storage media, with a particular focus on magnetic
disks and flash-based solid-state disks, and then discuss how to create highly reliable
storagestructuresbyusingmultiplestoragedevices.
12.1 Overview of Physical Storage Media
Severaltypesofdatastorageexistinmostcomputersystems.Thesestoragemediaare
classifiedbythespeedwithwhichdatacanbeaccessed,bythecostperunitofdatato
buythemedium,andbythemedium’sreliability.Amongthemediatypicallyavailable
arethese:
• Cache.Thecacheisthefastestandmostcostlyformofstorage.Cachememoryis
relativelysmall;itsuseismanagedbythecomputersystemhardware.Weshallnot
beconcernedaboutmanagingcachestorageinthedatabasesystem.Itis,however,
worth noting thatdatabase implementorsdo pay attention to cacheeffectswhen
designingqueryprocessingdatastructuresandalgorithms,andweshallreturnto
thisissueinlaterchapters.
• Mainmemory.Thestoragemediumusedfordatathatareavailabletobeoperated
on is main memory. The general-purpose machine instructions operate on main
memory.Mainmemorymaycontaintensofgigabytesofdataonapersonalcom-
559

--- Page 589 ---

560 Chapter12 PhysicalStorageSystems
puter,andevenhundredstothousandsofgigabytesofdatainlargeserversystems.
Itisgenerallytoosmall(ortooexpensive)forstoringtheentiredatabaseforvery
largedatabases,butmanyenterprisedatabasescanfitinmainmemory.However,
the contents of main memory are lost in the event of a power failure or system
crash;mainmemoryisthereforesaidtobevolatile.
• Flash memory. Flash memory differs from main memory in that stored data are
retainedevenifpoweristurnedoff(orfails)—thatis,itisnon-volatile.Flashmem-
ory hasa lowercost per byte than main memory,but a highercostper byte than
magneticdisks.
Flashmemoryiswidelyusedfordatastorageindevicessuchascamerasand
cellphones.Flashmemoryisalsousedforstoringdatain“USBflashdrives,”also
knownas“pendrives,”whichcanbepluggedintotheUniversalSerialBus(USB)
slotsofcomputingdevices.
Flash memory is also increasingly used as a replacement for magnetic disks
in personal computers as well as in servers. A solid-state drive (SSD) uses flash
memory internally to store data but provides an interface similar to a magnetic
disk, allowingdatatobe stored or retrievedin units ofa block;such an interface
iscalledablock-orientedinterface.Blocksizestypicallyrangefrom512bytesto8-
kilobytes.Asof2018,a1-terabyteSSDcostsaround$250.Weprovidemoredetails
aboutflashmemoryinSection12.4.
• Magnetic-disk storage. The primary medium for the long-term online storage of
data is the magnetic disk drive, which is also referred to as the hard disk drive
(HDD). Magnetic disk, like flash memory, is non-volatile: that is, magnetic disk
storagesurvivespowerfailuresandsystemcrashes.Disksmaysometimesfailand
destroydata,butsuchfailuresarequiterarecomparedtosystemcrashesorpower
failures.
To access data stored on magnetic disk, the system must first move the data
fromdisktomainmemory,fromwheretheycanbeaccessed.Afterthesystemhas
performed the designated operations, the data that have been modified must be
writtentodisk.
Diskcapacitieshavegrownsteadilyovertheyears.Asof2018,thesizeofmag-
netic disks ranges from 500 gigabytes to 14 terabytes, and a 1-terabyte disk costs
about $50, while an 8-terabyte disk around $150. Although significantly cheaper
thanSSDs,magneticdisksprovidelowerperformanceintermsofnumberofdata
access operations that they can support per second. We provide further details
aboutmagneticdisksinSection12.3.
• Optical storage. The digital video disk (DVD) is an optical storage medium, with
datawrittenandreadbackusingalaserlightsource.TheBlu-rayDVDformathas
a capacity of 27 gigabytes to 128 gigabytes, depending on the number of layers
supported. Althoughtheoriginal(andstillmain)useofDVDswastostorevideo
data, they are capable of storing any type of digital data, including backups of

--- Page 590 ---

12.1 OverviewofPhysicalStorageMedia 561
databasecontents.DVDsarenotsuitableforstoringactivedatabasedatasincethe
time required to access a given piece of data can be quite long compared to the
timetakenbyamagneticdisk.
Some DVD versions are read-only, written at the factory where they are pro-
duced,otherversionssupportwrite-once,allowingthemtobewrittenonce,butnot
overwritten,andsomeversionscanberewrittenmultipletimes.Disksthatcanbe
writtenonlyoncearecalledwrite-once,read-many(WORM)disks.
Opticaldiskjukeboxsystemscontainafewdrivesandnumerousdisksthatcan
beloadedintooneofthedrivesautomatically(byarobotarm)ondemand.
• Tapestorage.Tapestorageisusedprimarilyforbackupandarchivaldata.Archival
datareferstodatathatmustbestoredsafelyforalongperiodoftime,oftenforlegal
reasons. Magnetic tape is cheaper than disks and can safely store data for many
years.However,accesstodataismuchslowerbecausethetapemustbeaccessed
sequentiallyfromthebeginningofthetape;tapescanbeverylong,requiringtens
tohundredsofsecondstoaccessdata.Forthisreason,tapestorageisreferredtoas
sequential-accessstorage. Incontrast,magneticdiskandSSDstorage arereferred
toasdirect-accessstoragebecauseitispossibletoreaddatafromanylocationon
disk.
Tapeshaveahighcapacity(1to12terabytecapacitiesarecurrentlyavailable),
andcanberemovedfromthetapedrive.Tapedrivestendtobeexpensive,butin-
dividual tapes are usually significantly cheaper than magnetic disks of the same
capacity. As a result, tapes are wellsuited to cheap archival storage and to trans-
ferringlargeamountsofdatabetweendifferentlocations.Archivalstorageoflarge
videofiles, as wellasstorage of large volumes of scientificdata, whichcan range
uptomanypetabytes(1petabyte=1015 bytes)ofdata,aretwocommonusecases
fortapes.
Tapelibraries(jukeboxes)areusedtoholdlargecollectionsoftapes,allowing
automatedstorageandretrievaloftapeswithouthumanintervention.
Thevariousstoragemediacanbeorganizedinahierarchy(Figure12.1)according
to their speed and their cost. The higher levels are expensive, but fast. As we move
downthehierarchy,thecostperbitdecreases,whereastheaccesstimeincreases.This
trade-off is reasonable; if a given storage system were both faster and less expensive
thananother—otherpropertiesbeingthesame—thentherewouldbenoreasontouse
theslower,moreexpensivememory.
Thefasteststoragemedia—forexample,cacheandmainmemory—arereferredto
as primary storage. The media in the next level in the hierarchy—for example, flash
memory and magnetic disks—are referred to as secondary storage, or online storage.
Themediainthelowestlevelinthehierarchy—forexample,magnetictapeandoptical-
diskjukeboxes—arereferredtoastertiarystorage,orofflinestorage.
In additionto the speed and cost of the various storage systems, thereis alsothe
issue of storage volatility. In the hierarchy shown in Figure 12.1, the storage systems

--- Page 591 ---

562 Chapter12 PhysicalStorageSystems
cache
main memory
flash memory
magnetic disk
optical disk
magnetic tapes
Figure 12.1 Storagedevicehierarchy.
from main memory up are volatile, whereas the storage systems from flash memory
downarenon-volatile.Datamustbewrittentonon-volatilestorageforsafekeeping.We
shallreturntothesubjectofsafestorageofdatainthefaceofsystemfailureslater,in
Chapter19.
12.2 Storage Interfaces
Magnetic disks as well as flash-based solid-state disks are connected to a computer
systemthroughahigh-speedinterconnection.DiskstypicallysupporteithertheSerial
ATA (SATA) interface, or the Serial Attached SCSI (SAS) interface; the SAS interface
is typically used only in servers. The SATA-3 version of SATA nominally supports 6
gigabytespersecond,allowingdatatransferspeedsofupto600megabytespersecond,
while SAS version 3 supports data transfer rates of 12 gigabits per second. The Non-
VolatileMemoryExpress(NVMe)interfaceisalogicalinterfacestandarddevelopedto
better support SSDs and is typically used with the PCIe interface (the PCI e interface
provideshigh-speeddatatransferinternaltocomputersystems).
While disks are usually connected directly by cables to the disk interface of the
computersystem,theycanbesituatedremotelyandconnectedbyahigh-speednetwork
tothecomputer.Inthestorageareanetwork(SAN)architecture,largenumbersofdisks
are connected by a high-speed network to a number of server computers. The disks
are usually organized locally using a storage organization technique called redundant
arraysofindependentdisks(RAID)(describedlater,inSection12.5),togivetheservers
alogicalviewofaverylargeandveryreliabledisk.Interconnectiontechnologiesused

--- Page 592 ---

12.3 MagneticDisks 563
in storage areanetworks includeiSCSI, whichallows SCSI commandsto be sent over
anIPnetwork,FiberChannelFC,whichsupportstransferratesof1.6to12gigabytes
persecond,dependingontheversion,andInfiniBand,whichprovidesverylowlatency
high-bandwidthnetworkcommunication.
Network attached storage (NAS) is an alternative to SAN. NAS is much like SAN,
exceptthatinsteadofthenetworkedstorageappearingtobealargedisk,itprovidesa
filesysteminterfaceusingnetworkedfilesystemprotocolssuchasNFSorCIFS.Recent
years have also seen the growth of cloud storage, where data are stored in the cloud
andaccessedviaanAPI.Cloudstoragehasaveryhighlatencyoftenstohundredsof
milliseconds,ifthe dataarenotco-locatedwiththe database, and isthus notidealas
theunderlyingstoragefordatabases.However,applicationsoftenusecloudstoragefor
storingobjects.Cloud-basedstoragesystemsarediscussedfurtherinSection21.7.
12.3 Magnetic Disks
Magnetic disks provide the bulk of secondary storage for modern computer systems.
Magnetic disk capacities have been growing steadily year after year, but the storage
requirementsoflargeapplicationshavealsobeengrowingveryfast,insomecaseseven
fasterthanthegrowthrateofdiskcapacities.Verylargedatabasesat“web-scale”require
thousandstotensofthousandsofdiskstostoretheirdata.1
In recent years, SSD storage sizes have grown rapidly, and the cost of SSDs has
comedownsignificantly;theincreasingaffordabilityofSSDscoupledwiththeirmuch
better performance has resulted in SSDs increasingly becoming a competitor to mag-
netic disk storage for several applications. However, the fact that the per-byte cost of
storage on SSDs is around six to eight times the per-byte cost of storage on magnetic
disks means that magnetic disks continue to be the preferred choice for storing very
large volumes of data in many applications. Example of such data include video and
imagedata,aswellasdatathatisaccessedlessfrequently,suchasuser-generateddata
inmanyweb-scaleapplications.SSDs havehowever,increasinglybecomethepreferred
choiceforenterprisedata.
12.3.1 Physical Characteristics of Disks
Figure 12.2 shows a schematic diagram of a magnetic disk, while Figure 12.3 shows
theinternalsofanactualmagneticdisk.Eachdiskplatterhasaflat,circularshape.Its
twosurfacesarecoveredwithamagneticmaterial,andinformationisrecordedonthe
surfaces.Plattersaremadefromrigidmetalorglass.
When the disk isin use, a drive motor spins it ata constant high speed, typically
5400to10,000revolutionsperminute,dependingonthemodel.Thereisaread-write
head positioned just above the surface of the platter. The disk surface is logically di-
1Westudylater,inChapter21,howtopartitionsuchlargeamountsofdataacrossmultiplenodesinaparallelcomputing
system.

--- Page 593 ---

564 Chapter12 PhysicalStorageSystems
track t spindle
arm assembly
sector s
cylinder c read–write
head
platter
arm
rotation
Figure 12.2 Schematicdiagramofamagneticdisk.
vided into tracks, which are subdivided into sectors. A sector is the smallest unit of
informationthatcanbereadfromorwrittentothedisk.Sectorsizesaretypically512
bytes,andcurrentgenerationdiskshavebetween2billionand24billionsectors.The
innertracks(closertothespindle)areofsmallerlengththantheoutertracks,andthe
outertrackscontainmoresectorsthantheinnertracks.
The read–write head stores information on a sector magnetically as reversals of
thedirectionofmagnetizationofthemagneticmaterial.
Figure 12.3 Internalsofanactualmagneticdisk.

--- Page 594 ---

12.3 MagneticDisks 565
Eachsideofaplatterofadiskhasaread-writeheadthatmovesacrosstheplatter
to access different tracks. A disk typically contains many platters, and the read-write
heads of all the tracks are mounted on a single assembly called a disk arm and move
together. The disk platters mounted on a spindle and the heads mounted on a disk
arm are together known as head-disk assemblies. Since the heads on all the platters
movetogether,whentheheadononeplatterisontheithtrack,theheadsonallother
plattersarealsoontheithtrackoftheirrespectiveplatters.Hence,theithtracksofall
theplatterstogetherarecalledtheithcylinder.
Theread-writeheadsarekeptascloseaspossibletothedisksurfacetoincreasethe
recordingdensity.Theheadtypicallyfloatsorfliesonlymicronsfromthedisksurface;
thespinningofthediskcreatesasmallbreeze,andtheheadassemblyisshapedsothat
thebreezekeepstheheadfloatingjustabovethedisksurface.Becausetheheadfloats
soclosetothesurface,plattersmustbemachinedcarefullytobeflat.
Headcrashescanbeaproblem.Iftheheadcontactsthedisksurface,theheadcan
scrape therecordingmediumoffthedisk,destroyingthedatathathadbeenthere.In
older-generation disks, the head touching the surface caused the removed medium to
becomeairborneandtocomebetweentheotherheadsandtheirplatters,causingmore
crashes;aheadcrashcouldthusresultinfailureoftheentiredisk.Current-generation
disk drives use a thin film of magnetic metal as recording medium. They are much
lesssusceptibletofailureoftheentiredisk,butaresusceptibletofailureofindividual
sectors.
Adiskcontrollerinterfacesbetweenthecomputersystemandtheactualhardware
of the disk drive; in modern disk systems, the disk controller is implemented within
the disk drive unit. A disk controller accepts high-level commands to read or write a
sector,andinitiatesactions,suchasmovingthediskarmtotherighttrackandactually
readingorwritingthedata.Diskcontrollersalsoattachchecksumstoeachsectorthat
is written; the checksum is computed from the data written to the sector. When the
sector is read back, the controller computes the checksum again from the retrieved
dataandcomparesitwiththestoredchecksum;ifthedataarecorrupted,withahigh
probabilitythenewlycomputedchecksumwillnotmatchthestoredchecksum.Ifsuch
an error occurs, the controllerwill retry the read several times; if the error continues
tooccur,thecontrollerwillsignalareadfailure.
Anotherinterestingtaskthatdiskcontrollersperformisremappingofbadsectors.
Ifthecontrollerdetectsthatasectorisdamagedwhenthediskisinitiallyformatted,or
whenanattemptismadetowritethesector,itcanlogicallymapthesectortoadifferent
physicallocation(allocatedfromapoolofextrasectorssetasideforthispurpose).The
remappingisnotedondiskorinnon-volatilememory,andthewriteiscarriedouton
thenewlocation.
12.3.2 Performance Measures of Disks
The main measures of the qualities of a disk are capacity, access time, data-transfer
rate,andreliability.

--- Page 595 ---

566 Chapter12 PhysicalStorageSystems
Access time is the time from when a read or write request is issued to when data
transferbegins.Toaccess(i.e.,toreadorwrite)dataonagivensectorofadisk,thearm
first must move so that it is positioned over the correcttrack, and then must wait for
thesectortoappearunderitasthediskrotates.Thetimeforrepositioningthearmis
calledtheseektime,anditincreaseswiththedistancethatthearmmustmove.Typical
seektimesrangefrom2to20millisecondsdependingonhowfarthetrackisfromthe
initialarmposition.Smallerdiskstendtohavelowerseektimessincetheheadhasto
travelasmallerdistance.
Theaverageseektimeistheaverageoftheseektimes,measuredoverasequenceof
(uniformlydistributed)randomrequests.Ifalltrackshavethesamenumberofsectors,
andwedisregardthetimerequiredfortheheadtostartmovingandtostopmoving,we
canshowthattheaverageseektimeisone-thirdtheworst-caseseektime.Takingthese
factors into account, the average seek time is around one-half of the maximum seek
time.Averageseektimescurrentlyrangebetween4and10milliseconds,dependingon
thediskmodel.2
Oncetheheadhasreachedthedesiredtrack,thetimespentwaitingforthesector
tobeaccessedtoappearundertheheadiscalledtherotationallatencytime.Rotational
speedsofdiskstodayrangefrom5400rotationsperminute(90rotationspersecond)
up to 15,000 rotations per minute (250 rotations per second), or, equivalently, 4 mil-
lisecondsto11.1millisecondsperrotation.Onanaverage,one-halfofarotationofthe
diskisrequiredforthebeginningofthedesiredsectortoappearunderthehead.Thus,
the average latency time of the disk is one-half the time for a full rotation of the disk.
Disks with higher rotational speeds are used for applications where latency needs to
beminimized.
The access time is then the sum of the seek time and the latency; average access
times range from 5 to 20 milliseconds depending on the disk model. Once the first
sector of the data to be accessed has come under the head, data transfer begins. The
data-transfer rateistherate atwhichdatacanberetrievedfromorstoredtothedisk.
Currentdisksystemssupportmaximumtransferratesof50to200megabytespersec-
ond; transfer rates are significantly lower than the maximum transfer rates for inner
tracksofthedisk,sincetheyhavefewersectors.Forexample,adiskwithamaximum
transferrateof100megabytespersecondmayhaveasustainedtransferrateofaround
30megabytespersecondonitsinnertracks.
RequestsfordiskI/Oaretypicallygeneratedbythefilesystembutcanbegenerated
directly by the database system. Each request specifies the address on the disk to be
referenced;thataddressisintheformofablocknumber.Adiskblockisalogicalunit
of storage allocation and retrieval, and block sizes today typically range from 4 to 16
2Smaller2.5-inchdiameterdiskshavealesserarmmovementdistancethanlarger3.5-inchdisks,andthushavelower
seektimes.Asaresult2.5-inchdiskshavebeenthepreferredchoiceforapplicationswherelatencyneedstobemini-
mized,althoughSSDsareincreasinglypreferredforsuchapplications.Larger3.5-inchdiameterdiskshavealowercost
perbyteandareusedindatastorageapplicationswherecostisanimportantfactor.

--- Page 596 ---

12.4 FlashMemory 567
kilobytes.Dataaretransferredbetweendiskandmainmemoryinunitsofblocks.The
term page is often used to refer to blocks, although in a few contexts (such as flash
memory)theyrefertodifferentthings.
Asequenceofrequestsforblocksfromdiskmaybeclassifiedasasequentialaccess
patternorarandomaccesspattern.Inasequentialaccesspattern,successiverequests
areforsuccessiveblocknumbers,whichareonthesametrack,oronadjacenttracks.
Toreadblocksinsequentialaccess,adiskseekmayberequiredforthefirstblock,but
successive requests would either not require a seek, or require a seek to an adjacent
track,whichisfasterthanaseektoatrackthatisfartheraway.Datatransferratesare
highestwithasequentialaccesspattern,sinceseektimeisminimal.
Incontrast,inarandomaccesspattern,successiverequestsareforblocksthatare
randomlylocatedondisk.Eachsuchrequestwouldrequireaseek.ThenumberofI/O
operations per second (IOPS), that is, the number random block accesses that can be
satisfied by a disk in a second, depends on the access time, and the block size, and
thedatatransferrateofthedisk.Witha4-kilobyteblocksize,currentgenerationdisks
supportbetween50and200IOPS,dependingonthemodel.Sinceonlyasmallamount
(oneblock)ofdataarereadperseek,thedatatransferrate issignificantlylowerwith
arandomaccesspatternthanwithasequentialaccesspattern.
The final commonly used measure of a disk is the mean time to failure (MTTF),3
whichisameasureofthereliabilityofthedisk.Themeantimetofailureofadisk(or
ofanyothersystem)istheamountoftimethat,onaverage,wecanexpectthesystem
toruncontinuouslywithoutanyfailure.Accordingtovendors’claims,themeantime
to failure of disks today ranges from 500,000 to 1,200,000 hours—about 57 to 136
years. In practice the claimed mean time to failure is computed on the probability of
failure when the disk is new—the figure means that given 1000 relatively new disks,
if the MTTF is 1,200,000 hours, on an average one of them will fail in 1200 hours. A
meantimetofailureof1,200,000 hoursdoesnotimplythatthediskcanbeexpected
to function for 136 years! Most disks have an expected life span of about 5 years and
havesignificantlyhigherratesoffailureoncetheybecomemorethanafewyearsold.
12.4 Flash Memory
There are two types of flash memory, NOR flash and NANDflash. NANDflash is the
variantthatispredominantlyusedfordatastorage.ReadingfromNANDflashrequires
anentirepageofdata,whichisverycommonly4096bytes,tobefetchedfromNAND
flashintomainmemory.PagesinaNANDflasharethussimilartosectorsinamagnetic
disk.
3Thetermmeantimebetweenfailures(MTBF)isoftenusedtorefertoMTTFinthecontextofdiskdrives,although
technicallyMTBFshouldonlybeusedinthecontextofsystemsthatcanberepairedafterfailure,andmayfailagain;
MTBFwouldthenbethesumofMTTFandthemeantimetorepair.Magneticdiskscanalmostneverberepairedafter
afailure.

--- Page 597 ---

568 Chapter12 PhysicalStorageSystems
Solid-state disks (SSDs) are built using NAND flash and provide the same block-
orientedinterfaceasdiskstorage.Comparedtomagneticdisks,SSDscanprovidemuch
fasterrandom access:thelatencytoretrieveapageofdatarangesfrom20to100mi-
crosecondsforSSDs,whereasarandomaccessondiskwouldtake5to10milliseconds.
ThedatatransferrateofSSDsishigherthanthatofmagneticdisksandisusuallylim-
ited by the interconnect technology; transfer rates range from around 500 megabytes
per second with SATA interfaces, up to 3 gigabytes per second using NVMe PCIe in-
terfaces, depending on the specific SSD model, in contrast to a maximum of about
200megabytespersecondwithmagneticdisk.ThepowerconsumptionofSSDsisalso
significantlylowerthanthatofmagneticdisks.
Writes to flash memory are a little more complicated. A write to a page of flash
memory typically takes about 100 microseconds. However, once written, a page of
flashmemorycannotbedirectlyoverwritten.Instead,ithastobeerasedandrewritten
subsequently. The erase operation must be performed on a group of pages, called an
erase block, erasing all the pages in the block, and takes about 2 to 5 milliseconds.
An erase block (often referred to as just “block” in flash literature), is typically 256
kilobytesto1megabyte,andcontainsaround128to256pages.Further,thereisalimit
tohowmanytimesaflash page canbe erased,typicallyaround 100,000 to1,000,000
times.Oncethislimitisreached,errorsinstoringbitsarelikelytooccur.
Flashmemorysystemslimittheimpactofboththeslowerasespeedandtheupdate
limitsbymappinglogicalpagenumberstophysicalpagenumbers.Whenalogicalpage
is updated, it can be remapped to any already erased physical page, and the original
locationcanbeerasedlater.Eachphysicalpagehasasmallareaofmemorywhereits
logicaladdressisstored;ifthelogicaladdressisremappedtoadifferentphysicalpage,
theoriginalphysicalpageismarkedasdeleted.Thus,byscanningthephysicalpages,
we can find where each logical page resides. The logical-to-physical page mapping is
replicatedinanin-memorytranslationtableforquickaccess.
Blocks containing multiple deleted pages are periodically erased, taking care to
firstcopynondeletedpagesinthoseblockstoadifferentblock(thetranslationtableis
updated forthesenondeleted pages). Sinceeachphysical page canbe updated onlya
fixed number of times, physical pages that have been erased many times are assigned
“colddata,”thatis,datathatarerarelyupdated,whilepagesthathavenotbeenerased
manytimesareusedtostore“hotdata,”thatis,datathatareupdatedfrequently.This
principle of evenly distributing erase operations across physical blocks is called wear
levelingandisusuallyperformedtransparentlybyflash-memorycontrollers.Ifaphys-
ical page is damaged due to an excessive number of updates, it can be removed from
usage,withoutaffectingtheflashmemoryasawhole.
Alltheaboveactionsarecarriedoutbyalayerofsoftwarecalledtheflashtransla-
tion layer; above this layer, flash storage looks identicalto magneticdisk storage, pro-
vidingthesamepage/sector-orientedinterface,exceptthatflashstorageismuchfaster.
File systems and database storage structures can thus see an identical logical view of
theunderlyingstoragestructure,regardlessofwhetheritisflashormagneticstorage.

--- Page 598 ---

12.4 FlashMemory 569
Note 12.1 STORAGECLASSMEMORY
Although flash is the most widely used type of non-volatile memory, there have
been a number of alternative non-volatile memory technologies developed over
theyears.Severalofthesetechnologiesallowdirectreadandwriteaccesstoindi-
vidualbytesorwords,avoidingtheneedtoreadorwriteinunitsofpages(andalso
avoiding the erase overhead of NAND flash). Such types of non-volatile memory
are referred to as storage class memory, since they can be treated as a large non-
volatileblockofmemory.The3D-XPointmemorytechnology,developedbyIntel
and Micron, is a recently developed storage class memory technology. In terms
of cost per byte, latency of access, and capacity, 3D-XPoint memory lies in be-
tween main memory and flash memory. Intel Optane SSDs based on 3D-XPoint
startedshippingin2017,andOptanepersistentmemorymoduleswereannounced
in2018.
SSDperformanceisusuallyexpressedintermsof:
1. The number of random block reads per second, with 4-kilobyte blocks being the
standard.Typicalvaluesin2018areabout10,000randomreadspersecond(also
referredtoas10,000IOPS)with4-kilobyteblocks,althoughsomemodelssupport
higherrates.
Unlikemagneticdisks,SSDscansupport multiplerandomrequestsinparal-
lel,with32parallelrequestsbeingcommonlysupported;aflashdiskwithSATA
interfacesupportsnearly100,000random4-kilobyteblockreadsinasecondwith
32requestssentinparallel,whileSSDsconnectedusingNVMePCIecansupport
over350,000random4-kilobyteblockreadspersecond.Thesenumbersarespec-
ifiedasQD-1forrateswithoutparallelismandQD-nforn-wayparallelism,with
QD-32beingthemostcommonlyusednumber.
2. Thedatatransferrateforsequentialreadsandsequentialwrites.Typicalratesfor
bothsequentialreadsandsequentialwritesare400to500megabytespersecond
forSSDswithaSATA3interface,and2to3gigabytespersecondforSSDsusing
NVMeoverthePCIe3.0x4interface.
3. The number of random block writes per second, with 4-kilobyte blocks being the
standard. Typical values in 2018 are about 40,000 random 4-kilobyte writes per
second for QD-1 (without parallelism), and around 100,000 IOPS for QD-32.
althoughsomemodelssupporthigherratesforbothQD-1andQD-32.
Hybrid disk drives are hard-disk systems that combine magnetic storage with a
smalleramountofflashmemory,whichisusedasacacheforfrequentlyaccesseddata.
Frequentlyaccesseddatathatarerarelyupdatedareidealforcachinginflashmemory.

--- Page 599 ---

570 Chapter12 PhysicalStorageSystems
Modern SAN and NAS systems support the use of a combination of magnetic disks
and SSDs, and they can be configured to use the SSDs as a cache for data that reside
onmagneticdisks.
12.5 RAID
The data-storage requirementsof some applications(in particularweb,database, and
multimedia applications) have been growing so fast that a large number of disks are
needed to store their data, even though disk-drive capacities have been growing very
fast.
Having a large number of disks in a system presents opportunities for improving
therateatwhichdatacanbereadorwritten,ifthedisksareoperatedinparallel.Several
independentreadsorwritescanalsobeperformedinparallel.Furthermore,thissetup
offers the potential for improving the reliability of data storage, because redundant
informationcanbestoredonmultipledisks.Thus,failureofonediskdoesnotleadto
lossofdata.
A variety of disk-organization techniques, collectively called redundant arrays of
independent disks (RAID), have been proposed to achieve improved performance and
reliability.
In the past, system designers viewed storage systems composed of several small,
cheap disks as a cost-effective alternative to using large, expensive disks; the cost per
megabyteofthesmallerdiskswaslessthanthatoflargerdisks.Infact,theIinRAID,
which now stands for independent, originally stood for inexpensive. Today, however,
all disks are physically small, and larger-capacity disks actually have a lower cost per
megabyte. RAID systems are used for their higher reliability and higher performance
rate,ratherthanforeconomicreasons.AnotherkeyjustificationforRAIDuseiseasier
managementandoperations.
12.5.1 Improvement of Reliability via Redundancy
Letusfirstconsiderreliability.ThechancethatatleastonediskoutofasetofN disks
willfailismuchhigherthanthechancethataspecificsinglediskwillfail.Supposethat
themeantimetofailureofadiskis100,000hours,orslightlyover11years.Then,the
meantimetofailureofsomediskinanarrayof100diskswillbe100,000∕100=1000
hours,oraround42days,whichisnotlongatall!Ifwestoreonlyonecopyofthedata,
theneachdiskfailurewillresultinlossofasignificantamountofdata(asdiscussedin
Section12.3.1).Suchahighfrequencyofdatalossisunacceptable.
The solution to the problem of reliability is to introduce redundancy; that is, we
store extra information that is not needed normally but that can be used in the event
of failure of a disk to rebuild the lost information. Thus, even if a disk fails, data are
notlost,sotheeffectivemeantimetofailureisincreased,providedthatwecountonly
failuresthatleadtolossofdataortonon-availabilityofdata.

--- Page 600 ---

12.5 RAID 571
The simplest (but most expensive) approach to introducing redundancy is to du-
plicate every disk. This technique is called mirroring (or, sometimes, shadowing). A
logicaldiskthenconsistsoftwophysicaldisks,andeverywriteiscarriedoutonboth
disks. If one of the disks fails, the data can be read from the other. Data will be lost
onlyiftheseconddiskfailsbeforethefirstfaileddiskisrepaired.
The mean time to failure (where failure is the loss of data) of a mirrored disk
dependsonthemeantimetofailureoftheindividualdisks,aswellasonthemeantime
torepair,whichisthetimeittakes(onanaverage)toreplaceafaileddiskandtorestore
thedataonit.Supposethatthefailuresofthetwodisksareindependent;thatis,thereis
noconnectionbetweenthefailureofonediskandthefailureoftheother.Then,ifthe
mean time to failure of a single disk is 100,000 hours, and the mean time to repair is
10hours,themeantimetodatalossofamirroreddisksystemis100,0002∕(2 ∗ 10) =
500 ∗ 106 hours,or57,000years!(Wedonotgointothederivationshere;references
inthebibliographicalnotesprovidethedetails.)
You should be aware that the assumption of independence of disk failures is not
valid. Power failures and natural disasters such as earthquakes, fires, and floods may
resultindamagetobothdisksatthesametime.Asdisksage,theprobabilityoffailure
increases, increasing the chance that a second disk will fail while the first is being
repaired.Inspiteofalltheseconsiderations,however,mirrored-disksystemsoffermuch
higherreliabilitythandosingle-disksystems.Mirrored-disksystemswithmeantimeto
datalossofabout500,000to1,000,000hours,or55to110years,areavailabletoday.
Power failures are a particular source of concern, since they occur far more fre-
quently than do natural disasters. Power failures are not a concern if there is no data
transfer to disk in progress when they occur. However, even with mirroring of disks,
if writes are in progress to the same block in both disks, and power fails before both
blocksarefullywritten,thetwoblockscanbeinaninconsistentstate.Thesolutionto
thisproblemistowriteonecopyfirst,thenthenext,sothatoneofthetwocopiesisal-
waysconsistent.Someextraactionsarerequiredwhenwerestartafterapowerfailure,
torecoverfromincompletewrites.ThismatterisexaminedinPracticeExercise12.6.
12.5.2 Improvement in Performance via Parallelism
Nowletusconsiderthebenefitofparallelaccesstomultipledisks.Withdiskmirroring,
the rateatwhichreadrequests canbehandledisdoubled,sinceread requestscanbe
sent to either disk (as long as both disks in a pair are functional, as is almost always
thecase).Thetransferrateofeachreadisthesameasinasingle-disksystem,butthe
numberofreadsperunittimehasdoubled.
Withmultipledisks,wecanimprovethetransferrateaswell(orinstead)bystriping
data across multiple disks. In its simplest form, data striping consists of splitting the
bits of each byte across multiple disks; such striping is called bit-level striping. For
example,ifwehaveanarrayofeightdisks,wewritebitiofeachbytetodiski.Insuch
anorganization,everydiskparticipatesineveryaccess(readorwrite),sothenumber
ofaccessesthatcanbeprocessedpersecondisaboutthesameasonasingledisk,but
eachaccesscanreadeighttimesasmuchdatainthesametimeasonasingledisk.

--- Page 601 ---

572 Chapter12 PhysicalStorageSystems
Block-levelstripingstripesblocksacrossmultipledisks.Ittreatsthearrayofdisks
asasinglelargedisk,anditgivesblockslogicalnumbers;weassumetheblocknumbers
startfrom0.Withanarrayofndisks,block-levelstripingassignslogicalblockiofthe
diskarraytodisk(imodn)+1;itusesthe⌊i∕n⌋thphysicalblockofthedisktostore
logicalblocki.Forexample,witheightdisks,logicalblock0isstoredinphysicalblock
0ofdisk1,whilelogicalblock11isstoredinphysicalblock1ofdisk4.Whenreading
a large file, block-level striping fetches n blocks at a time in parallel from the n disks,
giving a high data-transfer rate for large reads. When a single block is read, the data-
transferrateisthesameasononedisk,buttheremainingn−1disksarefreetoperform
otheractions.
Block-level striping offers several advantages over bit-level striping, including the
ability to support a larger number of block reads per second, and lower latency for
singleblockreads.Asaresult,bit-levelstripingisnotusedinanypracticalsystem.
Insummary,therearetwomaingoalsofparallelisminadisksystem:
1. Load-balancemultiplesmallaccesses(blockaccesses),sothatthethroughputof
suchaccessesincreases.
2. Parallelizelargeaccessessothattheresponsetimeoflargeaccessesisreduced.
12.5.3 RAID Levels
Mirroring provides high reliability, but it is expensive. Striping provides high data-
transferrates,butdoesnotimprovereliability.Variousalternativeschemesaimtopro-
videredundancyatlowercostbycombiningdiskstripingwith“parityblocks”.
BlocksinaRAIDsystemarepartitionedintosets,asweshallsee.Foragivenset
ofblocks,aparityblockcanbecomputedandstoredondisk;the ithbitoftheparity
block is computed as the “exclusive or” (XOR) of the ith bits of the all blocks in the
set. If the contents of any one of the blocks in a set is lost due to a failure, the block
contents can be recovered by computing the bitwise-XOR of the remaining blocks in
theset,alongwiththeparityblock.
Whenever a block is written, the parity block for its set must be recomputed and
writtentodisk.Thenewvalueoftheparityblockcanbecomputedbyeither(i)reading
alltheotherblocksinthesetfromdiskandcomputingthenewparityblock,or(ii)by
computingtheXORoftheoldvalueoftheparityblockwiththeoldandnewvalueof
theupdatedblock.
Theseschemeshavedifferentcost-performancetrade-offs.Theschemesareclassi-
fiedintoRAIDlevels.4.Figure12.4illustratesthefourlevelsthatareusedinpractice.In
thefigure,Pindicateserror-correctingbits,andCindicatesasecondcopyofthedata.
Foralllevels,thefiguredepictsfourdisks’worthofdata,andtheextradisksdepicted
areusedtostoreredundantinformationforfailurerecovery.
4Thereare7differentRAIDlevels,numbered0to6;Levels2,3,and4arenotusedinpracticeanymoreandthusare
notcoveredinthetext

--- Page 602 ---

12.5 RAID 573
(a) RAID 0: nonredundant striping
C C C C
(b) RAID 1: mirrored disks
P P P P P
(c) RAID 5: block-interleaved distributed parity
P Q PQ PQ PQ PQ PQ
(d) RAID 6: P + Q redundancy
Figure 12.4 RAIDlevels.
• RAID level 0 refers to disk arrays with striping at the level of blocks, but without
anyredundancy(suchasmirroringorparitybits).Figure12.4ashowsanarrayof
size4.
• RAID level 1 refers to disk mirroring with block striping. Figure 12.4b shows a
mirroredorganizationthatholdsfourdisks’worthofdata.
NotethatsomevendorsusethetermRAIDlevel1+0orRAIDlevel10torefer
tomirroringwithstriping,andtheyusethetermRAIDlevel1torefertomirroring
withoutstriping.Mirroringwithoutstripingcanalsobeusedwitharraysofdisks,
to give the appearance of a single large, reliable disk: if each disk has M blocks,
logicalblocks0toM −1arestoredondisk0,M to2M −1ondisk1(thesecond
disk),andsoon,andeachdiskismirrored.5
• RAIDlevel5referstoblock-interleaveddistributedparity.Thedataandparityare
partitioned among all N + 1 disks. For each set of N logical blocks, one of the
disks stores the parity, and the other N disks store the blocks. The parity blocks
are stored on different disks for different sets of N blocks. Thus, all disks can
participateinsatisfyingreadrequests.6
Figure12.4cshowsthesetup.TheP’saredistributedacrossallthedisks.For
example,withanarrayoffivedisks,theparityblock,labeledPk,forlogicalblocks
5NotethatsomevendorsusethetermRAID0+1torefertoaversionofRAIDthatusesstripingtocreateaRAID0
array,andmirrorsthearrayontoanotherarray,withthedifferencefromRAID1beingthatifadiskfails,theRAID
0arraycontainingthediskbecomesunusable.Themirroredarraycanstillbeused,sothereisnolossofdata.This
arrangementisinferiortoRAID1whenadiskhasfailed,sincetheotherdisksintheRAID0arraycancontinuetobe
usedinRAID1,butremainidleinRAID0+1.
6InRAIDlevel4(whichisnotusedinpractice)allparityblocksarestoredononedisk.Thatdiskwouldnotbeuseful
forreads,anditwouldalsohaveahigherloadthanotherdisksifthereweremanyrandomwrites.

--- Page 603 ---

574 Chapter12 PhysicalStorageSystems
4k,4k+1,4k +2,4k+3 is stored in disk kmod5; the corresponding blocks of
the other four disks store the four data blocks 4k to 4k +3. The following table
indicates how the first 20 blocks, numbered 0 to 19, and their parity blocks are
laidout.Thepatternshowngetsrepeatedonfurtherblocks.
P0 0 1 2 3
4 P1 5 6 7
8 9 P2 10 11
12 13 14 P3 15
16 17 18 19 P4
Notethataparityblockcannotstoreparityforblocksinthesamedisk,since
thenadiskfailurewouldresultinlossofdataaswellasofparity,andhencewould
notberecoverable.
• RAIDlevel6,theP+Qredundancyscheme,ismuchlikeRAIDlevel5,butitstores
extraredundantinformationtoguardagainstmultiplediskfailures.Insteadofus-
ingparity,level6useserror-correctingcodessuchastheReed-Solomoncodes(see
the bibliographical notes). In the scheme in Figure 12.4g, two bits of redundant
dataarestoredforeveryfourbitsofdata—unlikeoneparitybitinlevel5—andthe
systemcantoleratetwodiskfailures.
ThelettersPandQinthefiguredenoteblockscontainingthetwocorrespond-
ingerror-correctingblocksforagivensetofdatablocks.Thelayoutofblocksisan
extension of that for RAID 5. For example, with six disks, the two parity blocks,
labeled Pk and Qk, for logical blocks 4k,4k+1,4k+2,and4k +3 are stored in
diskkmod6and (k+1)mod6,and thecorrespondingblocksof theotherfour
disksstorethefourdatablocks4kto4k+3.
Finally, we note that several variations have been proposed to the basic RAID
schemesdescribedhere,anddifferentvendorsusedifferentterminologiesforthevari-
ants.SomevendorssupportnestedschemesthatcreatemultipleseparateRAIDarrays,
andthenstripedataacrosstheRAIDarrays;oneofRAIDlevels1,5or6ischosenfor
the individual arrays. References to further information on this idea are provided in
theFurtherReadingsectionattheendofthechapter.
12.5.4 Hardware Issues
RAID can be implemented with no change at the hardware level, using only software
modification.SuchRAIDimplementationsarecalledsoftwareRAID.However,thereare
significant benefits to be had by building special-purpose hardware to support RAID,
which we outline below; systems with special hardware support are called hardware
RAIDsystems.

--- Page 604 ---

12.5 RAID 575
Hardware RAID implementations can use non-volatile RAM to record writes be-
fore they are performed. In case of power failure, when the system comes back up,
itretrievesinformation about any incomplete writes from non-volatileRAM and then
completesthewrites.Normaloperationscanthencommence.
Incontrast,withsoftwareRAID extraworkneedstobedonetodetectblocksthat
mayhavebeenpartiallywrittenbeforepowerfailure.ForRAID1,allblocksofthedisks
are scanned to see if any pair of blocks on the two disks have different contents. For
RAID5,thedisksneedtobescannedandparityrecomputedforeachsetofblocksand
compared to the stored parity. Such scans take a long time, and they are done in the
background using a small fraction of the disks’ available bandwidth. See Practice Ex-
ercise12.6fordetailsofhowtorecoverdatatothelatestvalue,whenaninconsistency
isdetected;werevisitthisissue inthe contextofdatabase system recoveryinSection
19.2.1.TheRAIDsystemissaidtoberesynchronizing(orresynching)duringthisphase;
normalreadsandwritesareallowedwhileresynchronizationisinprogress,butafailure
ofadiskduringthisphasecouldresultindatalossforblockswithincompletewrites.
HardwareRAIDdoesnothavethislimitation.
Even if all writes are completed properly, there is a small chance of a sector in a
diskbecomingunreadableatsomepoint,eventhoughitwassuccessfullywrittenearlier.
Reasonsforlossofdataonindividualsectorscouldrangefrommanufacturingdefects
todatacorruptiononatrackwhenanadjacenttrackiswrittenrepeatedly.Suchlossof
datathatweresuccessfullywrittenearlierissometimesreferredtoasalatentfailure,or
asbitrot.Whensuchafailurehappens,ifitisdetectedearlythedatacanberecovered
fromtheremainingdisksintheRAIDorganization.However,ifsuchafailureremains
undetected, a single disk failure could lead to data loss if a sector in one of the other
diskshasalatentfailure.
To minimizethe chance of such data loss, good RAID controllersperform scrub-
bing;thatis,duringperiodswhendisksareidle,everysectorofeverydiskisread,and
ifanysectorisfoundtobeunreadable,thedataarerecoveredfromtheremainingdisks
intheRAIDorganization,andthesectoriswrittenback.(Ifthephysicalsectorisdam-
aged,thediskcontrollerwouldremapthelogicalsectoraddresstoadifferentphysical
sectorondisk.)
Serverhardwareisoftendesignedtopermithotswapping;thatis,faultydiskscan
beremovedandreplacedbynewoneswithoutturningpoweroff.TheRAIDcontroller
can detect that a disk was replaced by a new one and can immediately proceed to
reconstructthedatathatwasontheolddisk,andwriteittothenewdisk.Hotswapping
reducesthemeantimetorepair,sincereplacementofadiskdoesnothavetowaituntil
atimewhenthesystemcanbeshutdown.Infact,manycriticalsystemstodayrunon
a24×7schedule;thatis,theyrun24hoursaday,7daysaweek,providingnotimefor
shuttingdownandreplacingafaileddisk.Further,manyRAIDimplementationsassign
asparediskforeacharray(orforasetofdiskarrays). Ifadiskfails,thesparediskis
immediately used as a replacement. As a result, the mean time to repair is reduced
greatly, minimizing the chance of any data loss. The failed disk can be replaced at
leisure.

--- Page 605 ---

576 Chapter12 PhysicalStorageSystems
The powersupply, or the diskcontroller,or even the system interconnection in a
RAID system could become a single point of failure that could stop the functioning
oftheRAIDsystem.Toavoidthispossibility,goodRAIDimplementationshavemulti-
pleredundantpowersupplies(withbatterybackupssotheycontinuetofunctioneven
if power fails). Such RAID systems have multiple disk interfaces and multiple inter-
connections to connect the RAID system to the computer system (or to a network of
computersystems).Thus,failureofanysinglecomponentwillnotstopthefunctioning
oftheRAIDsystem.
12.5.5 Choice of RAID Level
ThefactorstobetakenintoaccountinchoosingaRAIDlevelare:
• Monetarycostofextradisk-storagerequirements.
• PerformancerequirementsintermsofnumberofI/Ooperationspersecond.
• Performancewhenadiskhasfailed.
• Performance during rebuild (i.e., while the data in a failed disk are being rebuilt
onanewdisk).
The time to rebuild the data of a failed disk can be significant, and it varies with
the RAID level that is used. Rebuilding is easiest for RAID level 1, since data can be
copiedfromanotherdisk;fortheotherlevels,weneedtoaccessalltheotherdisksin
the array to rebuild data of a failed disk. The rebuild performance of a RAID system
maybeanimportantfactorifcontinuousavailabilityofdataisrequired,asitisinhigh-
performancedatabasesystems.Furthermore,sincerebuildtimecanformasignificant
partoftherepairtime,rebuildperformancealsoinfluencesthemeantimetodataloss.
RAID level 0 is used in a few high-performance applications where data safety is
notcritical,butnotanywhereelse.
RAID level 1 is popular for applications such as storage of log files in a database
system, since it offers the best write performance. RAID level 5 has a lower storage
overhead than level 1, but it has a higher time overhead for writes. For applications
wheredataarereadfrequently,andwrittenrarely,level5isthepreferredchoice.
Disk-storage capacities have been increasing rapidly for many years. Capacities
were effectively doubling every 13 months at one point; although the current rate of
growth is much less now, capacities have continued to increase rapidly. The cost per
byteofdiskstoragehasbeenfallingataboutthesamerateasthecapacityincrease.As
aresult,formanyexistingdatabase applicationswithmoderate storage requirements,
the monetary cost of the extra disk storage needed for mirroring has become rela-
tivelysmall(theextramonetarycost,however,remainsasignificantissue forstorage-
intensive applications such as video data storage). Disk access speeds have not im-
proved significantly in recent years, while the number of I/O operations required per
secondhasincreasedtremendously,particularlyforwebapplicationservers.

--- Page 606 ---

12.6 Disk-BlockAccess 577
RAID level 5 has a significant overhead for random writes, since a single random
blockwriterequires2blockreads(togettheoldvaluesoftheblockandparityblock)
and2blockwritestowritetheseblocksback.Incontrast,theoverheadislowforlarge
sequentialwrites,sincetheparityblockcanbecomputedfromthenewblocksinmost
cases, without any reads. RAID level 1 is therefore the RAID level of choice for many
applicationswithmoderatestoragerequirementsandhighrandomI/Orequirements.
RAID level 6 offers better reliability than level 1 or 5, since it can tolerate two
disk failures without losing data. In terms of performance during normal operation,
it is similar to RAID level 5, but it has a higher storage cost than RAID level 5. RAID
level6isusedinapplicationswheredatasafetyisveryimportant.Itisbeingviewedas
increasinglyimportantsincelatentsectorfailuresarenotuncommon,anditmaytakea
longtimetobedetectedandrepaired.Afailureofadifferentdiskbeforealatentfailure
isdetectedandrepairedwouldthenbesimilartoatwo-diskfailureforthatsectorand
resultinlossofdataofthatsector.RAIDlevels1and5wouldsufferfromdatalossin
suchascenario,unlikelevel6.
Mirroring can also be extended to store copies on three disks instead of two to
survive two-disk failures. Such triple-redundancy schemes are not commonly used in
RAIDsystems,althoughtheyareusedindistributedfilesystems,wheredataarestored
in multiple machines, since the probability of machine failure is significantly higher
thanthatofdiskfailure.
RAIDsystemdesignershavetomakeseveralotherdecisionsaswell.Forexample,
how many disks should there be in an array? How many bits should be protected by
eachparitybit?Iftherearemoredisksinanarray,data-transferratesarehigher,butthe
systemwillbemoreexpensive.Iftherearemorebitsprotectedbyaparitybit,thespace
overheadduetoparitybitsislower,butthereisanincreasedchancethataseconddisk
willfailbeforethefirstfaileddiskisrepaired,andthatwillresultindataloss.
12.5.6 Other RAID Applications
TheconceptsofRAIDhavebeengeneralizedtootherstoragedevices,includinginthe
flash memory devices within SSDs, arrays of tapes, and even to the broadcast of data
overwirelesssystems.Individualflashpageshaveahigherrateofdatalossthansectors
of magnetic disks. Flash devices such as SSDs implement RAID internally, to ensure
that the device does not lose data due to the loss of a flash page. When applied to
arraysoftapes,theRAIDstructuresareabletorecoverdataevenifoneofthetapesin
an array of tapes is damaged. When applied to broadcast of data, a block of data are
splitintoshortunitsandisbroadcastalongwithaparityunit;ifoneoftheunitsisnot
receivedforanyreason,itcanbereconstructedfromtheotherunits.
12.6 Disk-Block Access
RequestsfordiskI/Oaregeneratedbythedatabasesystem,withthequeryprocessing
subsystemresponsibleformostofthediskI/O.Eachrequestspecifiesadiskidentifier
and a logical block number on the disk; in case database data are stored in operating

--- Page 607 ---

578 Chapter12 PhysicalStorageSystems
system files,therequestinsteadspecifiesthefileidentifierandablocknumberwithin
thefile.Dataaretransferredbetweendiskandmainmemoryinunitsofblocks.
Aswesawearlier,asequenceofrequestsforblocksfromdiskmaybeclassifiedas
asequentialaccesspatternorarandomaccesspattern.Inasequentialaccesspattern,
successive requests are for successive block numbers, which are on the same track,
or on adjacenttracks. In contrast, in a random access pattern, successive requests are
forblocksthatarerandomlylocatedondisk.Eachsuchrequestwouldrequireaseek,
resulting in a longer access time, and a lower number of random I/O operations per
second.
A number of techniques have been developed for improving the speed of access
to blocks, by minimizing the number of accesses, and in particular minimizing the
numberofrandomaccesses.Wedescribethesetechniquesbelow.Reducingthenumber
ofrandomaccessesisveryimportantfordatastoredonmagneticdisks;SSDssupport
muchfasterrandomaccessthandomagneticdisks,sotheimpactofrandomaccessis
lesswithSSDs,butdataaccessfromSSDscanstillbenefitfromsomeofthetechniques
describedbelow.
• Buffering.Blocksthatarereadfromdiskarestoredtemporarilyinanin-memory
buffer, to satisfy future requests. Buffering is done by both the operating system
andthedatabasesystem.DatabasebufferingisdiscussedinmoredetailinSection
13.5.
• Read-ahead.Whenadiskblockisaccessed,consecutiveblocksfromthesametrack
arereadintoanin-memorybufferevenifthereisnopendingrequestfortheblocks.
In the case of sequential access, such read-ahead ensures that many blocks are
alreadyinmemorywhentheyarerequested,anditminimizesthetimewasted in
diskseeksandrotationallatencyperblockread.Operatingsystemsalsoroutinely
performread-aheadforconsecutiveblocksofanoperatingsystemfile.Read-ahead
is,however,notveryusefulforrandomblockaccesses.
• Scheduling. If several blocks from a cylinder need to be transferred from disk to
mainmemory,wemaybeabletosaveaccesstimebyrequestingtheblocksinthe
orderin whichthey willpass underthe heads. Ifthedesiredblocks areon differ-
entcylinders,itisadvantageous torequest theblocks inan orderthatminimizes
disk-armmovement.Disk-arm–schedulingalgorithmsattempttoorderaccessesto
tracks in a fashion that increases the number of accesses that can be processed.
A commonly used algorithm is the elevator algorithm, which works in the same
waymanyelevatorsdo. Suppose that,initially,thearm ismovingfrom theinner-
mosttracktowardtheoutsideofthedisk.Undertheelevatoralgorithm’scontrol,
for each track for which there is an access request, the arm stops at that track,
servicesrequestsforthetrack,andthencontinuesmovingoutwarduntilthereare
nowaitingrequestsfortracksfartherout.Atthispoint,thearmchangesdirection
andmovestowardtheinside,againstoppingateachtrackforwhichthereisare-

--- Page 608 ---

12.6 Disk-BlockAccess 579
quest, until it reaches a track where there is no request for tracks farther toward
thecenter.Then,itreversesdirectionandstartsanewcycle.
Diskcontrollersusuallyperformthetaskofreorderingreadrequeststoimprove
performance,sincetheyareintimatelyawareoftheorganizationofblocksondisk,
oftherotationalpositionofthediskplatters,andofthepositionofthediskarm.To
enablesuchreordering,thediskcontrollerinterfacemustallowmultiplerequests
tobeaddedtoaqueue;resultsmaybereturnedinadifferentorderfromtherequest
order.
• Fileorganization.Toreduceblock-accesstime,wecanorganizeblocksondiskina
waythatcorrespondscloselytothewayweexpectdatatobeaccessed.Forexam-
ple,ifweexpectafiletobeaccessedsequentially,thenweshouldideallykeepall
theblocksofthefilesequentiallyonadjacentcylinders.Moderndiskshidetheex-
actblocklocationfromtheoperatingsystembutusealogicalnumberingofblocks
thatgivesconsecutivenumberstoblocksthatareadjacenttoeachother.Byallo-
catingconsecutiveblocksofafiletodiskblocksthatareconsecutivelynumbered,
operatingsystemsensurethatfilesarestoredsequentially.
Storingalargefileinasinglelongsequenceofconsecutiveblocksposeschal-
lenges to disk block allocation; instead, operating systems allocate some number
ofconsecutiveblocks(anextent)atatimetoafile.Differentextentsallocatedto
afilemaynotbeadjacenttoeachotherondisk.Sequentialaccesstothefileneeds
oneseekperextent,insteadofoneseekperblockifblocksarerandomlyallocated;
with large enough extents, the cost of seeks relative to data transfer costs can be
minimized.
Overtime,asequentialfilethathasmultiplesmallappendsmaybecomefrag-
mented; that is, its blocks become scattered all over the disk. To reduce fragmen-
tation, the system can make a backup copy of the data on disk and restore the
entiredisk.Therestoreoperationwritesbacktheblocksofeachfilecontiguously
(or nearly so). Some systems (such as different versions of the Windows operat-
ingsystem)haveutilitiesthatscanthediskandthenmoveblockstodecreasethe
fragmentation.Theperformanceincreasesrealizedfromthesetechniquescanbe
quitesignificant.
• Non-volatile writebuffers.Sincethecontentsofmainmemoryarelostinapower
failure, information about database updates has to be recorded on disk to sur-
vivepossiblesystemcrashes.Forthisreason,theperformanceofupdate-intensive
database applications, such as transaction-processing systems, is heavily depen-
dentonthelatencyofdiskwrites.
We can use non-volatile random-access memory (NVRAM) to speed up disk
writes. The contents of NVRAM are not lost in power failure. NVRAM was im-
plementedusing battery-backed-up RAMin earlierdays, butflash memoryiscur-
rentlytheprimarymediumfornon-volatilewritebuffering.Theideaisthat,when
thedatabasesystem (ortheoperatingsystem) requeststhatablockbewrittento
disk, the disk controller writes the block to a non-volatile write buffer and imme-

--- Page 609 ---

580 Chapter12 PhysicalStorageSystems
diately notifies the operating system that the write completed successfully. The
controller can subsequently write the data to their destination on disk in a way
thatminimizesdiskarm movement, usingthe elevatoralgorithm,for example. If
suchwritereorderingisdonewithoutusingnon-volatilewritebuffers,thedatabase
statemaybecomeinconsistentintheeventofasystemcrash;recoveryalgorithms
thatwestudy laterinChapter19 dependon writesbeingwritten inthespecified
order.Whenthedatabase system requestsablockwrite,itnoticesadelayonlyif
theNVRAMbufferisfull.Onrecoveryfromasystemcrash,anypendingbuffered
writes in the NVRAM are written back to the disk. NVRAM buffers are found in
certainhigh-enddisks,butaremorefrequentlyfoundinRAIDcontrollers.
Inadditiontotheabovelow-leveloptimizations,optimizationstominimizerandom
accessescanbedoneatahigherlevel,bycleverdesignofqueryprocessingalgorithms.
WestudyefficientqueryprocessingtechniquesinChapter15.
12.7 Summary
• Several types of data storage exist in most computer systems. They are classified
bythespeedwithwhichtheycanaccessdata,bytheircostperunitofdatatobuy
the memory, and by their reliability.Among the mediaavailable are cache, main
memory,flashmemory,magneticdisks,opticaldisks,andmagnetictapes.
• Magneticdisksaremechanicaldevices,anddataaccessrequiresaread–writehead
tomovetotherequiredcylinder,andtherotationoftheplattersmustthenbring
the required sector under the read–write head. Magnetic disks thus have a high
latencyfordataaccess.
• SSDs have a much lower latency for data access, and higher data transfer band-
width than magnetic disks. However, they also have a higher cost per byte than
magneticdisks.
• Disks are vulnerable to failure, which could result in loss of data stored on the
disk.Wecanreducethelikelihoodofirretrievabledatalossbyretainingmultiple
copiesofdata.
• Mirroringreducestheprobabilityofdatalossgreatly.Moresophisticatedmethods
based on redundant arrays of independent disks (RAID) offer further benefits.
By stripingdata acrossdisks, these methodsofferhigh throughput rates on large
accesses;byintroducingredundancyacrossdisks,theyimprovereliabilitygreatly.
• SeveraldifferentRAIDorganizationsarepossible,eachwithdifferentcost,perfor-
mance,and reliabilitycharacteristics.RAIDlevel1(mirroring)andRAID level5
arethemostcommonlyused.
• Severaltechniqueshavebeendevelopedtooptimizediskblockaccess,suchasread
ahead,buffering,diskarmscheduling,prefetching,andnon-volatilewritebuffers.

--- Page 610 ---

ReviewTerms 581
Review Terms
• Physicalstoragemedia • Diskblock
• Performancemeasuresofdisks
° Cache
° Mainmemory ° Accesstime
° Flashmemory ° Seektime
° Magneticdisk ° Latencytime
° Opticalstorage ° I/Ooperationspersecond(IOPS)
° Tapestorage ° Rotationallatency
• Volatilestorage ° Data-transferrate
• Non-volatilestorage ° Meantimetofailure(MTTF)
• Sequential-access • FlashStorage
• Direct-access
° EraseBlock
• Storageinterfaces
° Wearleveling
° SerialATA(SATA)
° Flashtranslationtable
° SerialAttachedSCSI(SAS)
° FlashTranslationLayer
° Non-Volatile Memory Express
(NVMe) • Storageclassmemory
° Storageareanetwork(SAN) ° 3D-XPoint
° Networkattachedstorage(NAS) • Redundant arrays of independent
• Magneticdisk disks(RAID)
° Platter ° Mirroring
° Harddisks ° Datastriping
° Tracks ° Bit-levelstriping
° Sectors ° Block-levelstriping
° Read–writehead • RAIDlevels
° Diskarm ° Level0(blockstriping,
noredundancy)
° Cylinder
° Level1(blockstriping,
° Diskcontroller
mirroring)
° Checksums
° Level5(blockstriping,
° Remappingofbadsectors distributedparity)

--- Page 611 ---

582 Chapter12 PhysicalStorageSystems
° Level6(blockstriping, ° Disk-armscheduling
P+Qredundancy)
° Elevatoralgorithm
• Rebuildperformance ° Fileorganization
• SoftwareRAID
° Defragmenting
• HardwareRAID
° Non-volatilewritebuffers
• Hotswapping
• Optimizationofdisk-blockaccess ° Logdisk
Practice Exercises
12.1 SSDscanbeusedasastoragelayerbetweenmemoryandmagneticdisks,with
somepartsofthedatabase(e.g.,some relations)storedonSSDsandtherest
on magnetic disks. Alternatively, SSDs can be used as a buffer or cache for
magnetic disks; frequently used blocks would reside on the SSD layer, while
infrequentlyusedblockswouldresideonmagneticdisk.
a. Whichofthetwoalternativeswouldyou chooseifyou needtosupport
real-timequeriesthatmustbeansweredwithinaguaranteedshortperiod
oftime?Explainwhy.
b. Whichofthetwoalternativeswouldyouchooseifyouhadaverylarge
customer relation, where only some disk blocks of the relation are ac-
cessedfrequently,withotherblocksrarelyaccessed.
12.2 Somedatabasesusemagneticdisksinawaythatonlysectorsinoutertracksare
used,whilesectorsininnertracksareleftunused.Whatmightbethebenefits
ofdoingso?
12.3 Flashstorage:
a. How is the flash translation table, which is used to map logical page
numberstophysicalpagenumbers,createdinmemory?
b. Suppose you have a 64-gigabyte flash storage system, with a 4096-byte
page size. How big would the flash translation table be, assuming each
pagehasa32-bitaddress,andthetableisstoredasanarray?
c. Suggesthowtoreducethesizeofthetranslationtableifveryoftenlong
ranges of consecutive logical page numbers are mapped to consecutive
physicalpagenumbers.
12.4 Considerthefollowingdataandparity-blockarrangementonfourdisks:

--- Page 612 ---

Exercises 583
Disk 1 Disk 2 Disk 3 Disk 4
B
1
P
1
B
8
…
B
2
B
5
P
2
…
B
3
B
6
B
9
…
B
4
B
7
B
10
…
TheBsrepresentdatablocks; thePsrepresentparityblocks.ParityblockP
i i i
istheparityblockfordatablocksB toB .What,ifany,problemmightthis
4i−3 4i
arrangementpresent?
12.5 A database administrator can choose how many disks are organized into a
single RAID 5 array. What are the trade-offs between having fewer disks ver-
sus more disks, in terms of cost, reliability, performance during failure, and
performanceduringrebuild?
12.6 Apowerfailurethatoccurswhileadiskblockisbeingwrittencouldresultin
theblockbeingonlypartiallywritten.Assumethatpartiallywrittenblockscan
be detected.Anatomicblockwrite isone whereeitherthediskblockisfully
writtenornothingiswritten(i.e.,therearenopartialwrites).Suggestschemes
forgettingtheeffectofatomicblockwriteswiththefollowingRAIDschemes.
Yourschemesshouldinvolveworkonrecoveryfromfailure.
a. RAIDlevel1(mirroring)
b. RAIDlevel5(blockinterleaved,distributedparity)
12.7 Storing all blocks of a large file on consecutive disk blocks would minimize
seeksduringsequentialfilereads.Whyisitimpracticaltodoso?Whatdoop-
eratingsystemsdoinstead,tominimizethenumberofseeksduringsequential
reads?
Exercises
12.8 Listthe physical storage mediaavailableon the computersyou use routinely.
Givethespeedwithwhichdatacanbeaccessedoneachmedium.
12.9 Howdoestheremappingofbadsectorsbydiskcontrollersaffectdata-retrieval
rates?
12.10 Operatingsystemstrytoensurethatconsecutiveblocksofafilearestoredon
consecutivediskblocks.Whyisdoingsoveryimportantwithmagneticdisks?
IfSSDswereusedinstead,isdoingsostillimportant,orisitirrelevant?Explain
why.

--- Page 613 ---

584 Chapter12 PhysicalStorageSystems
12.11 RAID systems typicallyallow you to replace faileddisks without stopping ac-
cesstothesystem.Thus,thedatainthefaileddiskmustberebuiltandwritten
to thereplacementdiskwhilethe system isin operation. Whichof the RAID
levelsyieldstheleastamountofinterferencebetweentherebuildandongoing
diskaccesses?Explainyouranswer.
12.12 Whatisscrubbing, inthecontextofRAIDsystems, andwhyisscrubbingim-
portant?
12.13 Supposeyouhavedatathatshouldnotbelostondiskfailure,andtheapplica-
tioniswrite-intensive.Howwouldyoustorethedata?
Further Reading
[Hennessy et al. (2017)] is a popular textbook on computer architecture, which in-
cludescoverageofcacheandmemoryorganization.
Thespecificationsofcurrent-generationmagneticdiskdrivescanbeobtainedfrom
the web sites of their manufacturers, such as Hitachi, Seagate, Maxtor, and Western
Digital. The specifications of current-generation SSDs can be obtained from the web
sitesoftheirmanufacturers,suchasCrucial,Intel,Micron,Samsung,SanDisk,Toshiba
andWesternDigital.
[Patterson et al. (1988)] provided early coverage of RAID levels and helped stan-
dardizetheterminology.[Chenetal.(1994)]presentsasurveyofRAIDprinciplesand
implementation.
A comprehensive coverage of RAID levels supported by most modern RAID sys-
tems, includingthe nested RAIDlevels,10, 50 and60, whichcombineRAID levels1,
5 and 6 with striping as in RAID level 0, can be found in the “Introduction to RAID”
chapterof[Cisco(2018)].Reed-Solomoncodesarecoveredin[Pless(1998)].
Bibliography
[Chenetal.(1994)] P.M.Chen,E.K.Lee,G.A.Gibson,R.H.Katz,andD.A.Patterson,
“RAID:High-Performance,ReliableSecondaryStorage”,ACMComputingSurveys,Volume
26,Number2(1994),pages145–185.
[Cisco(2018)] CiscoUCSServersRAIDGuide. Cisco(2018).
[Hennessyetal.(2017)] J.L.Hennessy,D.A.Patterson,andD.Goldberg,ComputerArchi-
tecture:AQuantitativeApproach,6thedition,MorganKaufmann(2017).
[Pattersonetal.(1988)] D.A.Patterson,G.Gibson,andR.H.Katz,“ACaseforRedundant
ArraysofInexpensiveDisks(RAID)”,InProc.oftheACMSIGMODConf.onManagement
ofData(1988),pages109–116.

--- Page 614 ---

FurtherReading 585
[Pless(1998)] V.Pless,IntroductiontotheTheoryofError-CorrectingCodes,3rdedition,John
WileyandSons(1998).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.
Figure12.3isdueto©Silberschatz,Korth,andSudarshan.

--- Page 616 ---

13
CHAPTER
Data Storage Structures
In Chapter 12 we studied the characteristics of physical storage media, focusing on
magneticdisksandSSDs,andsawhowtobuildfastandreliablestoragesystemsusing
multipledisksinaRAIDstructure.Inthischapter,wefocusontheorganizationofdata
storedontheunderlyingstoragemedia,andhowdataareaccessed.
13.1 Database Storage Architecture
Persistent data are stored on non-volatile storage, which, as we saw in Chapter 12, is
typically magnetic disk or SSD. Magnetic disks as well as SSDs are block structured
devices,thatis,dataarereadorwritteninunitsofablock.Incontrast,databasesdeal
with records, which are usually much smaller than a block (although in some cases
recordsmayhaveattributesthatareverylarge).
Most databases use operating system files as an intermediate layer for storing
records, which abstract away some details of the underlying blocks. However, to en-
sureefficientaccess,aswellastosupportrecoveryfromfailures(aswewillseelaterin
Chapter19),databasesmustcontinuetobeawareofblocks.Thus,inSection13.2,we
studyhowindividualrecordsarestoredinfiles,takingblockstructureintoaccount.
Given a set of records, the next decision lies in how to organize them in the file
structure; for example, they may stored in sorted order, in the order they are created,
orinanarbitraryorder.Section13.3studiesseveralalternativefileorganizations.
Section 13.4 then describes how databases organize data about the relational
schemas as well as storage organization, in the data dictionary. Information in the
datadictionaryiscrucialformanytasks,forexample,tolocateandretrieverecordsof
arelationwhengiventhenameoftherelation.
ForaCPUtoaccessdata,itmustbeinmainmemory,whereaspersistentdatamust
beresidentonnon-volatilestoragesuchasmagneticdisksorSSDs.Fordatabasesthat
arelargerthanmainmemory,whichistheusualcase,datamustbefetchedfromnon-
volatile storage and saved back if it is updated. Section 13.5 describes how databases
usearegionofmemorycalledthedatabasebuffertostoreblocksthatarefetchedfrom
non-volatilestorage.
587

--- Page 617 ---

588 Chapter13 DataStorageStructures
An approach to storing data based on storing all values of a particular column
together,ratherthanstoringallattributesofaparticularrowtogether,hasbeenfoundto
workverywellforanalyticalqueryprocessing.Thisidea,calledcolumn-orientedstorage,
isdiscussedinSection13.6.
Someapplicationsneedveryfastaccesstodataandhavesmallenoughdatasizes
that the entire database can fit into the main memory of a database server machine.
In such cases, we can keep a copyof the entire database in memory.1 Databases that
storetheentiredatabaseinmemoryandoptimizein-memorydatastructuresaswellas
queryprocessingandotheralgorithmsusedbythedatabasetoexploitthememoryresi-
dencyofdataarecalledmain-memorydatabases.Storageorganizationinmain-memory
databases is discussed in Section 13.7. We note that non-volatile memory that allows
direct access to individual bytes or cache lines, called storage class memory, is under
development.Main-memorydatabasearchitecturescanbefurtheroptimizedforsuch
storage.
13.2 File Organization
A database is mapped into a number of different files that are maintained by the un-
derlyingoperatingsystem.Thesefilesresidepermanentlyondisks.Afileisorganized
logicallyasasequenceofrecords.Theserecordsaremappedontodiskblocks.Filesare
providedasabasicconstructinoperatingsystems,soweshallassumetheexistenceof
anunderlyingfilesystem.Weneedtoconsiderwaysofrepresentinglogicaldatamodels
intermsoffiles.
Each file is also logicallypartitioned into fixed-length storage units called blocks,
which are the units of both storage allocation and data transfer. Most databases use
blocksizesof4to8kilobytesbydefault,butmanydatabasesallowtheblocksizetobe
specifiedwhenadatabaseinstanceiscreated.Largerblocksizescanbeusefulinsome
databaseapplications.
Ablockmaycontainseveralrecords;theexactsetofrecordsthatablockcontains
is determined by the form of physical data organization being used. We shall assume
thatnorecordislargerthanablock.Thisassumptionisrealisticformostdata-processing
applications,suchasouruniversityexample.Therearecertainlyseveralkindsoflarge
data items, such as images, that can be significantly larger than a block. We briefly
discuss how to handle such large data items in Section 13.2.2, by storing large data
itemsseparately,andstoringapointertothedataitemintherecord.
Inaddition,weshallrequirethateachrecordisentirelycontainedinasingleblock;
thatis,norecordiscontainedpartlyinoneblock,andpartlyinanother.Thisrestriction
simplifiesandspeedsupaccesstodataitems.
1Tobesafe,notonlyshouldthecurrentdatabasefitinmemory,butthereshouldbeareasonablecertaintythatthe
databasewillcontinuetofitinmemoryinthemediumtermfuture,despitepotentialgrowthoftheorganization.

--- Page 618 ---

13.2 FileOrganization 589
Inarelationaldatabase,tuplesofdistinctrelationsaregenerallyofdifferentsizes.
Oneapproachtomappingthedatabasetofilesistouseseveralfilesandtostorerecords
of only one fixed length in any given file. An alternative is to structure our files so
that we can accommodate multiple lengths for records; however, files of fixed-length
records are easier to implement than are files of variable-length records. Many of the
techniques used for the former can be applied to the variable-length case. Thus, we
begin by considering a file of fixed-length records and consider storage of variable-
lengthrecordslater.
13.2.1 Fixed-Length Records
As an example, let us consider a file of instructor records for our university database.
Eachrecordofthisfileisdefined(inpseudocode)as:
typeinstructor =record
IDvarchar(5);
namevarchar(20);
dept namevarchar(20);
salarynumeric(8,2);
end
Assume that each character occupies 1 byte and that numeric (8,2) occupies 8
bytes. Suppose that instead of allocatinga variable amount of bytes for the attributes
ID,name,anddept name,weallocatethemaximumnumberofbytesthateachattribute
canhold.Then,theinstructor recordis53byteslong.Asimpleapproachistousethe
first 53 bytes for the first record, the next 53 bytes for the second record, and so on
(Figure13.1).
record 0 10101 Srinivasan Comp. Sci. 65000
record 1 12121 Wu Finance 90000
record 2 15151 Mozart Music 40000
record 3 22222 Einstein Physics 95000
record 4 32343 El Said History 60000
record 5 33456 Gold Physics 87000
record 6 45565 Katz Comp. Sci. 75000
record 7 58583 Califieri History 62000
record 8 76543 Singh Finance 80000
record 9 76766 Crick Biology 72000
record 10 83821 Brandt Comp. Sci. 92000
record 11 98345 Kim Elec. Eng. 80000
Figure 13.1 Filecontaininginstructor records.

--- Page 619 ---

590 Chapter13 DataStorageStructures
record 0 10101 Srinivasan Comp. Sci. 65000
record 1 12121 Wu Finance 90000
record 2 15151 Mozart Music 40000
record 4 32343 El Said History 60000
record 5 33456 Gold Physics 87000
record 6 45565 Katz Comp. Sci. 75000
record 7 58583 Califieri History 62000
record 8 76543 Singh Finance 80000
record 9 76766 Crick Biology 72000
record 10 83821 Brandt Comp. Sci. 92000
record 11 98345 Kim Elec. Eng. 80000
Figure 13.2 FileofFigure13.1,withrecord3deletedandallrecordsmoved.
However,therearetwoproblemswiththissimpleapproach:
1. Unless the block size happens to be a multiple of 53 (which is unlikely), some
recordswillcross blockboundaries. Thatis,part of the recordwillbe stored in
one blockand part in another.Itwould thusrequiretwoblockaccessesto read
orwritesucharecord.
2. It is difficult to delete a record from this structure. The space occupied by the
recordtobedeletedmustbefilledwithsomeotherrecordofthefile,orwemust
haveawayofmarkingdeletedrecordssothattheycanbeignored.
Toavoidthefirstproblem,weallocateonlyasmanyrecordstoablockaswouldfit
entirelyintheblock(thisnumbercanbecomputedeasilybydividingtheblocksizeby
therecordsize,anddiscardingthefractionalpart).Anyremainingbytesofeachblock
areleftunused.
When a record is deleted, we could move the record that comes after it into the
spaceformerlyoccupiedbythedeletedrecord,andsoon,untileveryrecordfollowing
the deleted record has been moved ahead (Figure 13.2). Such an approach requires
moving a large number of records. It might be easier simply to move the final record
ofthefileintothespaceoccupiedbythedeletedrecord(Figure13.3).
It is undesirable to move records to occupy the space freed by a deleted record,
since doing so requires additional block accesses. Since insertions tend to be more
frequentthandeletions,itisacceptabletoleaveopenthespaceoccupiedbythedeleted
recordandtowaitforasubsequentinsertionbeforereusingthespace.Asimplemarker
on a deleted record is not sufficient, since it is hard to find this available space when
aninsertionisbeingdone.Thus,weneedtointroduceanadditionalstructure.
Atthebeginningofthefile,weallocateacertainnumberofbytesasafileheader.
The header will contain a variety of information about the file. For now, all we need

--- Page 620 ---

13.2 FileOrganization 591
record 0 10101 Srinivasan Comp. Sci. 65000
record 1 12121 Wu Finance 90000
record 2 15151 Mozart Music 40000
record 11 98345 Kim Elec. Eng. 80000
record 4 32343 El Said History 60000
record 5 33456 Gold Physics 87000
record 6 45565 Katz Comp. Sci. 75000
record 7 58583 Califieri History 62000
record 8 76543 Singh Finance 80000
record 9 76766 Crick Biology 72000
record 10 83821 Brandt Comp. Sci. 92000
Figure 13.3 FileofFigure13.1,withrecord3deletedandfinalrecordmoved.
tostorethereistheaddressofthefirstrecordwhosecontentsaredeleted.Weusethis
first record to store the address of the second available record, and so on. Intuitively,
wecanthinkofthesestoredaddressesaspointers,sincetheypointtothelocationofa
record.Thedeletedrecordsthusformalinkedlist,whichisoftenreferredtoasafree
list. Figure13.4showsthefileofFigure13.1, withthefreelist,afterrecords1, 4,and
6havebeendeleted.
On insertion of a new record, we use the record pointed to by the header. We
changetheheaderpointertopointtothenextavailablerecord.Ifnospaceisavailable,
weaddthenewrecordtotheendofthefile.
header
record 0 10101 Srinivasan Comp. Sci. 65000
record 1
record 2 15151 Mozart Music 40000
record 3 22222 Einstein Physics 95000
record 4
record 5 33456 Gold Physics 87000
record 6
record 7 58583 Califieri History 62000
record 8 76543 Singh Finance 80000
record 9 76766 Crick Biology 72000
record 10 83821 Brandt Comp. Sci. 92000
record 11 98345 Kim Elec. Eng. 80000
Figure 13.4 FileofFigure13.1,withfreelistafterdeletionofrecords1,4,and6.

--- Page 621 ---

592 Chapter13 DataStorageStructures
Insertion and deletion for files of fixed-length records are simple to implement
because the space made available by a deleted record is exactly the space needed to
insert a record. If we allow records of variable-length in a file, this match no longer
holds. An inserted record may not fit in the space left free by a deleted record, or it
mayfillonlypartofthatspace.
13.2.2 Variable-Length Records
Variable-lengthrecordsariseindatabasesystemsduetoseveralreasons.Themostcom-
mon reason is the presence of variable length fields, such as strings. Other reasons
includerecord types thatcontain repeatingfieldssuch as arrays or multisets, and the
presenceofmultiplerecordtypeswithinafile.
Differenttechniquesforimplementingvariable-lengthrecordsexist.Twodifferent
problemsmustbesolvedbyanysuchtechnique:
1. How torepresentasinglerecordinsuchawaythatindividualattributescanbe
extractedeasily,eveniftheyareofvariablelength
2. Howtostorevariable-lengthrecordswithinablock,suchthatrecordsinablock
canbeextractedeasily
The representation of a record with variable-length attributes typically has two
parts: an initial part with fixed-length information, whose structure is the same for
allrecordsofthesamerelation,followedbythecontentsofvariable-lengthattributes.
Fixed-lengthattributes,suchasnumericvalues,dates,orfixed-lengthcharacterstrings
areallocatedasmanybytesasrequiredtostoretheirvalue.Variable-lengthattributes,
such as varchar types, are represented in the initial part of the record by a pair (off-
set, length), where offset denotes where the data for that attribute begins within the
record, and length is the length in bytes of the variable-sized attribute. The values for
thevariable-lengthattributesarestoredconsecutively,aftertheinitialfixed-lengthpart
oftherecord.Thus,theinitialpartoftherecordstoresafixedsizeofinformationabout
eachattribute,whetheritisfixed-lengthorvariable-length.
An example of such a record representation is shown in Figure 13.5. The figure
shows an instructor record whose first three attributes ID, name, and dept name are
variable-length strings, and whose fourth attribute salary is a fixed-sized number. We
assume that the offset and length values are stored in two bytes each, for a total of 4
Null bitmap (stored in 1 byte)
0000
21, 5 26, 10 36, 10 65000 10101 Srinivasan Comp. Sci.
Bytes 0 4 8 12 2021 26 36 45
Figure 13.5 Representationofavariable-lengthrecordoftheinstructor relation.

--- Page 622 ---

13.2 FileOrganization 593
Block Header Records
Size # Entries Free Space
Location
End of Free Space
Figure 13.6 Slotted-page structure.
bytes per attribute. The salary attribute is assumed to be stored in 8 bytes, and each
stringtakesasmanybytesasithascharacters.
Thefigurealsoillustratestheuseofanullbitmap,whichindicateswhichattributes
of the record have a null value. In this particular record, if the salary were null, the
fourth bit of the bitmap would be set to 1, and the salary value stored in bytes 12
through19wouldbeignored.Sincetherecordhasfourattributes,thenullbitmapfor
thisrecordfitsin1byte,althoughmorebytesmayberequiredwithmoreattributes.In
somerepresentations,thenullbitmapisstoredatthebeginningoftherecord,andfor
attributesthatarenull,nodata(value,oroffset/length)arestoredatall.Sucharepre-
sentationwouldsavesomestoragespace,atthecostofextraworktoextractattributes
oftherecord.Thisrepresentationisparticularlyuseful forcertainapplicationswhere
recordshavealargenumberoffields,mostofwhicharenull.
We next address the problem of storing variable-length records in a block. The
slotted-page structure is commonly used for organizing records within a block and is
showninFigure13.6.2Thereisaheaderatthebeginningofeachblock,containingthe
followinginformation:
• Thenumberofrecordentriesintheheader
• Theendoffreespaceintheblock
• Anarraywhoseentriescontainthelocationandsizeofeachrecord
The actual records are allocated contiguously in the block, starting from the end
of the block. The free space in the block is contiguous between the final entry in the
headerarrayandthefirstrecord.Ifarecordisinserted,spaceisallocatedforitatthe
endoffreespace,andanentrycontainingitssizeandlocationisaddedtotheheader.
Ifarecordisdeleted,thespacethatitoccupiesisfreed,anditsentryissettodeleted
(itssizeissetto−1,forexample).Further,therecordsintheblockbeforethedeleted
recordaremoved,sothatthefreespacecreatedbythedeletiongetsoccupied,andall
2Here,“page”issynonymouswith“block.”

--- Page 623 ---

594 Chapter13 DataStorageStructures
freespaceisagainbetweenthefinalentryintheheaderarrayandthefirstrecord.The
end-of-free-space pointer in the header is appropriately updated as well. Records can
be grown or shrunk by similar techniques, as long as there is space in the block. The
costof movingthe recordsisnottoohigh,sincethesize ofablockislimited:typical
valuesarearound4to8kilobytes.
Theslotted-pagestructurerequiresthattherebenopointersthatpointdirectlyto
records.Instead,pointersmustpointtotheentryintheheaderthatcontainstheactual
locationoftherecord.Thislevelofindirectionallowsrecordstobemovedtoprevent
fragmentationofspaceinsideablock,whilesupportingindirectpointerstotherecord.
13.2.3 Storing Large Objects
Databasesoftenstoredatathatcanbemuchlargerthanadiskblock.Forinstance,an
image or an audio recording may be multiple megabytes in size, while a video object
may be multiple gigabytes in size. Recall that SQL supports the types blob and clob,
whichstorebinaryandcharacterlargeobjects.
Manydatabasesinternallyrestrictthesizeofarecordtobenolargerthanthesize
of a block.3 These databases allow records to logicallycontain large objects, but they
store the large objects separate from the other (short) attributes of records in which
theyoccur.A(logical)pointertotheobjectisthenstoredintherecordcontainingthe
largeobject.
Large objects may be stored either as files in a file system area managed by the
database,orasfilestructuresstoredinandmanagedbythedatabase.Inthelattercase,
suchin-databaselargeobjectscanoptionallyberepresentedusingB+-treefileorganiza-
tions,whichwestudyinSection14.4.1,toallowefficientaccesstoanylocationwithin
theobject.B+-treefileorganizationspermitustoreadanentireobject,orspecifiedbyte
rangesintheobject,aswellastoinsertanddeletepartsoftheobject.
However, there are some performance issues with storing very large objects in
databases.Theefficiencyofaccessinglargeobjectsviadatabaseinterfacesisonecon-
cern.Asecondconcernisthesizeofdatabasebackups.Manyenterprisesperiodically
create“databasedumps,”thatis,backupcopiesoftheirdatabases;storinglargeobjects
inthedatabasecanresultinalargeincreaseinthesizeofthedatabasedumps.
Manyapplicationsthereforechoosetostoreverylargeobjects,suchasvideodata,
outside of the database, in a file system. In such cases, the application may store the
filename(usuallyapathinthefilesystem)asanattributeofarecordinthedatabase.
Storingdatainfilesoutsidethedatabasecanresultinfilenamesinthedatabasepoint-
ingtofilesthatdonotexist,perhapsbecausetheyhavebeendeleted,whichresultsin
aformofforeign-keyconstraintviolation.Further,databaseauthorizationcontrolsare
notapplicabletodatastoredinthefilesystem.
3Thisrestrictionhelpssimplifybuffermanagement;asweseeinSection13.5,diskblocksarebroughtintoanareaof
memorycalledthebufferbeforetheyareaccessed.Recordslargerthanablockwouldgetsplitbetweenblocks,which
maybedifferentareasofthebuffer,andthuscannotbeguaranteedtobeinacontiguousareaofmemory.

--- Page 624 ---

13.3 OrganizationofRecordsinFiles 595
Some databases support file system integration with the database, to ensure that
constraints are satisfied (for example, deletion of files will be blocked if the database
has a pointer to the file), and to ensure that accessauthorizations are enforced. Files
canbeaccessedbothfromafilesysteminterfaceandfromthedatabaseSQLinterface.
For example, Oracle supports such integration through its SecureFiles and Database
FileSystemfeatures.
13.3 Organization of Records in Files
Sofar, wehave studied how recordsare representedin afilestructure. A relationisa
set of records. Given a set of records, the next question is how to organize them in a
file.Severalofthepossiblewaysoforganizingrecordsinfilesare:
• Heapfileorganization.Anyrecordcanbeplacedanywhereinthefilewherethere
isspacefortherecord.Thereisnoorderingofrecords.Typically,thereiseithera
singlefile orasetoffilesforeachrelation.Heap fileorganization isdiscussedin
Section13.3.1.
• Sequential file organization. Records are stored in sequential order, according to
thevalueofa“searchkey”ofeachrecord.Section13.3.2describesthisorganiza-
tion.
• Multitable clustering file organization: Generally, a separate file or set of files is
used to store the records of each relation. However, in a multitable clustering file
organization, recordsofseveral differentrelationsarestoredinthesame file,and
infactinthesameblockwithinafile,toreducethecostofcertainjoinoperations.
Section13.3.3describesthemultitableclusteringfileorganization.
• B+-treefileorganization.Thetraditionalsequentialfileorganizationdescribedin
Section 13.3.2 does support ordered access even if there are insert, delete, and
update operations, which may change the ordering of records. However, in the
face of a large number of such operations, efficiency of ordered access suffers.
Westudyanotherwayoforganizingrecords,calledtheB+-treefileorganization,in
Section14.4.1.TheB+-treefileorganizationisrelatedtotheB+-treeindexstructure
describedinthatchapterandcanprovideefficientorderedaccesstorecordsevenif
therearealargenumberofinsert,delete,orupdateoperations.Further,itsupports
veryefficientaccesstospecificrecords,basedonthesearchkey.
• Hashingfileorganization.Ahashfunctioniscomputedonsomeattributeofeach
record.Theresultofthehashfunctionspecifiesinwhichblockofthefiletherecord
should be placed. Section14.5 describesthisorganization; itiscloselyrelated to
theindexingstructuresdescribedinthatchapter.

--- Page 625 ---

596 Chapter13 DataStorageStructures
13.3.1 Heap File Organization
Inaheapfileorganization,arecordmaybestoredanywhereinthefilecorresponding
toarelation.Onceplacedinaparticularlocation,therecordisnotusuallymoved.4
Whenarecordisinsertedinafile,oneoptionforchoosingthelocationistoalways
add itat theend of the file. However, ifrecordsget deleted,itmakes sense touse the
space thus freed up to store new records. It is important for a database system to be
abletoefficientlyfindblocksthathavefreespace,withouthavingtosequentiallysearch
throughalltheblocksofthefile.
Mostdatabasesuseaspace-efficientdatastructurecalledafree-spacemaptotrack
whichblockshavefreespacetostorerecords.Thefree-spacemapiscommonlyrepre-
sented by an array containing 1 entry for each block in the relation. Each entry rep-
resents a fraction f such that at least a fraction f of the space in the block is free. In
PostgreSQL, for example, an entry is 1 byte, and the value stored in the entry must
be divided by 256 to get the free-space fraction. The array is stored in a file, whose
blocksarefetchedintomemory,5 asrequired.Wheneverarecordisinserted,deleted,
orchangedinsize,iftheoccupancyfractionchangesenoughtoaffecttheentryvalue,
the entry is updated in the free-space map. An example of a free-space map for a file
with16blocksisshownbelow.Weassumethat3bitsareusedtostoretheoccupancy
fraction;thevalueatpositionishouldbedividedby8togetthefree-spacefractionfor
blocki.
4 2 1 4 7 3 6 5 1 2 0 1 1 0 5 6
Forexample,avalueof7indicatesthatatleast7∕8thofthespaceintheblockisfree.
To find a block to store a new record of a given size, the database can scan the
free-spacemaptofindablockthathasenoughfreespacetostorethatrecord.Ifthere
isnosuchblock,anewblockisallocatedfortherelation.
While such a scan is much faster than actually fetching blocks to find free space,
itcanstillbeveryslowforlargefiles.Tofurtherspeedupthetaskoflocatingablock
withsufficientfreespace,wecancreateasecond-levelfree-spacemap,whichhas,say1
entryforevery100entriesofthemainfree-spacemap.That1entrystoresthemaximum
value amongst the 100 entriesin the mainfree-space mapthatitcorrespondsto. The
free-space map below is a second level free-space map for our earlierexample, with 1
entryforevery4entriesinthemainfree-spacemap.
4 7 2 6
4Recordsmaybeoccasionallymoved,forexample,ifthedatabasesortstherecordsoftherelation;butnotethateven
iftherelationisreorderedbysorting,subsequentinsertionsandupdatesmayresultintherecordsnolongerbeing
ordered.
5Viathedatabasebuffer,whichwediscussinSection13.5.

--- Page 626 ---

13.3 OrganizationofRecordsinFiles 597
With1entryforevery100entriesinthemainfree-spacemap,ascanofthesecond-
level free space map would take only 1/100th of the time to scan the main free-space
map;onceasuitableentryindicatingenoughfreespaceisfoundthere,itscorrespond-
ing100entriesinthemainfree-spacemapcanbeexaminedtofindablockwithsuffi-
cient free space. Such a block must exist, since the second-level free-space map entry
storesthemaximumoftheentriesinthemainfree-spacemap.Todealwithverylarge
relations,wecancreatemorelevelsbeyondthesecondlevel,usingthesameidea.
Writingthefree-spacemaptodiskeverytimeanentryinthemapisupdatedwould
be very expensive. Instead, the free-space map is written periodically; as a result, the
free-space map on disk may be outdated, and when a database starts up, it may get
outdated dataaboutavailablefreespace.Thefree-spacemapmay,asaresult,claima
blockhasfreespacewhenitdoesnot;suchanerrorwillbedetectedwhentheblockis
fetched,andcanbedealtwithbyafurthersearchinthefree-spacemaptofindanother
block.Ontheotherhand,thefree-spacemapmayclaimthatablockdoesnothavefree
spacewhenitdoes;generallythiswillnotresultinanyproblemotherthanunusedfree
space. To fix any such errors, the relation is scanned periodically and the free-space
maprecomputedandwrittentodisk.
13.3.2 Sequential File Organization
Asequentialfileisdesignedforefficientprocessingofrecordsinsortedorderbasedon
some search key. A search key is any attribute or set of attributes; it need not be the
primarykey,orevenasuperkey.Topermitfastretrievalofrecordsinsearch-keyorder,
we chain together records by pointers. The pointer in each record points to the next
recordinsearch-keyorder.Furthermore,tominimizethenumberofblockaccessesin
sequential file processing, we store records physically in search-key order, or as close
tosearch-keyorderaspossible.
Figure13.7shows asequential fileofinstructor recordstaken fromour university
example. In that example, the records are stored in search-key order, using ID as the
searchkey.
Thesequentialfileorganizationallowsrecordstobereadinsortedorder;thatcan
be useful fordisplay purposes, as wellas for certain query-processing algorithmsthat
weshallstudyinChapter15.
Itisdifficult,however,tomaintainphysicalsequentialorderasrecordsareinserted
anddeleted,sinceitiscostlytomovemanyrecordsasaresultofasingleinsertionor
deletion. We can manage deletion by using pointer chains, as we saw previously. For
insertion,weapplythefollowingtworules:
1. Locatetherecordinthefilethatcomesbeforetherecordtobeinsertedinsearch-
keyorder.
2. If there is a free record (i.e., space left after a deletion) within the same block
as this record, insert the new record there. Otherwise, insert the new record in

--- Page 627 ---

598 Chapter13 DataStorageStructures
10101 Srinivasan Comp. Sci. 65000
12121 Wu Finance 90000
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 El Said History 60000
33456 Gold Physics 87000
45565 Katz Comp. Sci. 75000
58583 Califieri History 62000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp. Sci. 92000
98345 Kim Elec. Eng. 80000
Figure 13.7 Sequentialfileforinstructor records.
an overflow block. In either case, adjust the pointers so as to chain together the
recordsinsearch-keyorder.
Figure13.8showsthefileofFigure13.7aftertheinsertionoftherecord(32222,
Verdi,Music,48000).ThestructureinFigure13.8allowsfastinsertionofnewrecords,
butitforcessequentialfile-processingapplicationstoprocessrecordsinanorderthat
doesnotmatchthephysicalorderoftherecords.
Ifrelativelyfewrecordsneedtobestoredinoverflowblocks,thisapproachworks
well. Eventually, however, the correspondence between search-key order and physical
ordermaybetotallylostoveraperiodoftime,inwhichcasesequentialprocessingwill
becomemuchlessefficient.Atthispoint,thefileshouldbereorganizedsothatitisonce
againphysicallyinsequentialorder.Suchreorganizationsarecostlyandmustbedone
during times when the system load is low. The frequency with which reorganizations
areneededdependsonthefrequencyofinsertionofnewrecords.Intheextremecase
inwhichinsertionsrarelyoccur,itispossiblealwaystokeepthefileinphysicallysorted
order.Insuchacase,thepointerfieldinFigure13.7isnotneeded.
TheB+-treefileorganization,whichwedescribeinSection14.4.1,providesefficient
ordered access even if there are many inserts, deletes,and updates, without requiring
expensivereorganizations.
13.3.3 Multitable Clustering File Organization
Mostrelationaldatabasesystemsstoreeachrelationinaseparatefile,oraseparateset
offiles.Thus,eachfile,andasaresult,eachblock,storesrecordsofonlyonerelation,
insuchadesign.

--- Page 628 ---

13.3 OrganizationofRecordsinFiles 599
10101 Srinivasan Comp. Sci. 65000
12121 Wu Finance 90000
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 El Said History 60000
33456 Gold Physics 87000
45565 Katz Comp. Sci. 75000
58583 Califieri History 62000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp. Sci. 92000
98345 Kim Elec. Eng. 80000
32222 Verdi Music 48000
Figure 13.8 Sequentialfileafteraninsertion.
However,insomecasesitcanbeusefultostorerecordsofmorethanonerelation
in a single block. To see the advantage of storing records of multiple relations in one
block,considerthefollowingSQLqueryfortheuniversitydatabase:
selectdept name,building,budget,ID,name,salary
fromdepartmentnaturaljoininstructor;
This query computes a join of the department and instructor relations. Thus, for each
tuple of department, the system must locate the instructor tuples with the same value
fordept name.Ideally,theserecordswillbelocatedwiththehelpofindices,whichwe
shalldiscussinChapter14.Regardlessofhowtheserecordsarelocated,however,they
needtobetransferredfromdiskintomainmemory.Intheworstcase,eachrecordwill
resideonadifferentblock,forcingustodooneblockreadforeachrecordrequiredby
thequery.
Asaconcreteexample,considerthedepartment andinstructor relationsofFigure
13.9 andFigure13.10, respectively(for brevity,weincludeonlyasubset of thetuples
dept name building budget
Comp.Sci. Taylor 100000
Physics Watson 70000
Figure 13.9 Thedepartment relation.

--- Page 629 ---

600 Chapter13 DataStorageStructures
ID name dept name salary
10101 Srinivasan Comp.Sci. 65000
33456 Gold Physics 87000
45565 Katz Comp.Sci. 75000
83821 Brandt Comp.Sci. 92000
Figure 13.10 Theinstructor relation.
of the relations we have used thus far). In Figure 13.11, we show a file structure de-
signed for the efficient execution of queries involving the natural join of department
and instructor. All the instructor tuples for a particular dept name are stored near the
departmenttupleforthatdept name.Wesaythatthetworelationsareclusteredonthe
key dept name. We assume that each record contains the identifier of the relation to
whichitbelongs,althoughthisisnotshowninFigure13.11.
Although not depicted in the figure, it is possible to store the value of the dept
name attribute, which defines the clustering, only once for a group of tuples (from
bothrelations),reducingstorageoverhead.
This structure allows for efficient processing of the join. When a tuple of the de-
partmentrelationisread,theentireblockcontainingthattupleiscopiedfromdiskinto
mainmemory.Sincethecorrespondinginstructortuplesarestoredonthedisknearthe
department tuple, theblockcontainingthedepartment tuple containstuples of thein-
structor relationneededtoprocessthequery.Ifadepartmenthassomanyinstructors
that the instructor records do not fit in one block, the remaining records appear on
nearbyblocks.
Amultitableclusteringfileorganizationisafileorganization,suchasthatillustrated
in Figure 13.11, that stores related records of two or more relations in each block.6
The cluster key is the attribute that defines which records are stored together; in our
precedingexample,theclusterkeyisdept name.
Comp.Sci. Taylor 100000
10101 Srinivasan Comp.Sci. 65000
45565 Katz Comp.Sci. 75000
83821 Brandt Comp.Sci. 92000
Physics Watson 70000
33456 Gold Physics 87000
Figure 13.11 Multitableclusteringfilestructure.
6Notethatthewordclusterisoftenusedtorefertoagroupofmachinesthattogetherconstituteaparalleldatabase;
thatuseofthewordclusterisunrelatedtotheconceptofmultitableclustering.

--- Page 630 ---

13.3 OrganizationofRecordsinFiles 601
Althoughamultitableclusteringfileorganizationcanspeedupcertainjoinqueries,
it can result in slowing processing of other types of queries. For example, in our pre-
cedingexample,
select*
fromdepartment;
requires more block accesses than it did in the scheme under which we stored each
relationinaseparatefile,sinceeachblocknowcontainssignificantlyfewerdepartment
records. To locate efficiently all tuples of the department relation within a particular
block, we can chain together all the records of that relation using pointers; however,
thenumberofblocksreaddoesnotgetaffectedbyusingsuchchains.
Whenmultitableclusteringistobeuseddependsonthetypesofqueriesthatthe
databasedesignerbelievestobemostfrequent.Carefuluseofmultitableclusteringcan
producesignificantperformancegainsinqueryprocessing.
MultitableclusteringissupportedbytheOracledatabasesystem.Clusterscanbe
created by using acreate cluster command,with a specified cluster key. An extension
of the create table command can be used to specify that a relation is to be stored in
aspecificcluster,withaparticularattributeusedastheclusterkey.Multiplerelations
canthusbeallocatedtoacluster.
13.3.4 Partitioning
Manydatabasesallowtherecordsinarelationtobepartitionedintosmallerrelations
that are stored separately. Such table partitioning is typically done on the basis of an
attributevalue;forexample,recordsinatransactionrelationinanaccountingdatabase
may be partitioned by year intosmallerrelations correspondingto each year, such as
transaction 2018,transaction 2019,andsoon.Queriescanbewrittenbasedonthetrans-
actionrelationbutaretranslatedintoqueriesontheyear-wiserelations.Mostaccesses
aretorecordsofthecurrentyearandincludeaselectionbasedontheyear.Queryop-
timizerscanrewritesuchaquerytoonlyaccessthesmallerrelationcorrespondingto
the requested year, and they can avoid reading records corresponding to other years.
Forexample,aquery
select*
fromtransaction
whereyear=2019
would only access the relation transaction 2019, ignoring the other relations, while a
querywithouttheselectionconditionwouldreadalltherelations.
Thecostofsomeoperations,suchasfindingfreespaceforarecord,increasewith
relationsize;byreducingthesizeofeachrelation,partitioninghelpsreducesuchover-
heads. Partitioning can also be used to store different parts of a relation on different

--- Page 631 ---

602 Chapter13 DataStorageStructures
storage devices;forexample, in theyear2019, transaction 2018 andearlieryeartrans-
actions can which are infrequently accessed could be stored on magnetic disk, while
transaction 2019couldbestoredonSSD,forfasteraccess.
13.4 Data-Dictionary Storage
Sofar,wehaveconsideredonlytherepresentationoftherelationsthemselves.Arela-
tionaldatabasesystemneedstomaintaindataabouttherelations,suchastheschema
oftherelations.Ingeneral,such“dataaboutdata”arereferredtoasmetadata.
Relational schemas and other metadata about relations are stored in a structure
calledthe data dictionary or system catalog. Amongthe types of information thatthe
systemmuststorearethese:
• Namesoftherelations
• Namesoftheattributesofeachrelation
• Domainsandlengthsofattributes
• Namesofviewsdefinedonthedatabase,anddefinitionsofthoseviews
• Integrityconstraints(e.g.,keyconstraints)
Inaddition,manysystemskeepthefollowingdataonusersofthesystem:
• Namesofusers,thedefaultschemasoftheusers,andpasswordsorotherinforma-
tiontoauthenticateusers
• Informationaboutauthorizationsforeachuser
Further,thedatabasemaystorestatisticalanddescriptivedataabouttherelationsand
attributes, such as the number of tuples in each relation, or the number of distinct
valuesforeachattribute.
Thedatadictionarymayalsonotethestorageorganization(heap,sequential,hash,
etc.)ofrelations,andthelocationwhereeachrelationisstored:
• If relations are stored in operating system files, the dictionary would note the
namesofthefile(orfiles)containingeachrelation.
• Ifthedatabasestoresallrelationsinasinglefile,thedictionarymaynotetheblocks
containingrecordsofeachrelationinadatastructuresuchasalinkedlist.
InChapter14,inwhichwestudyindices,weshallseeaneedtostoreinformationabout
eachindexoneachoftherelations:
• Nameoftheindex

--- Page 632 ---

13.4 Data-DictionaryStorage 603
• Nameoftherelationbeingindexed
• Attributesonwhichtheindexisdefined
• Typeofindexformed
All this metadata information constitutes, in effect, a miniature database. Some
database systems store such metadata by using special-purpose data structures and
code.Itisgenerallypreferable tostorethedataaboutthedatabase asrelationsinthe
database itself. By using database relations to store system metadata, we simplify the
overallstructureofthesystemandharnessthefullpowerofthedatabaseforfastaccess
tosystemdata.
Theexactchoiceofhowtorepresentsystemmetadatabyrelationsmustbemade
bythesystemdesigners.WeshowtheschemadiagramofatoydatadictionaryinFigure
13.12,storingpartoftheinformationmentionedabove.Theschemaisonlyillustrative;
realimplementationsstorefarmoreinformationthanwhatthefigureshows.Readthe
manualsforwhicheverdatabaseyouusetoseewhatsystemmetadataitmaintains.
Inthemetadatarepresentationshown,theattributeindex attributesoftherelation
Index metadata is assumed to contain a list of one or more attributes, which can be
represented by a character string such as “dept name, building”. The Index metadata
relationisthusnotinfirstnormalform;itcanbenormalized,buttheprecedingrepre-
sentationislikelytobemoreefficienttoaccess.Thedatadictionaryisoftenstoredin
anonnormalizedformtoachievefastaccess.
Relation_metadata Attribute_metadata
relation_name relation_name
number_of_attributes attribute_name
storage_organization domain_type
location position
length
Index_metadata
index_name
relation_name
index_type
User_metadata
index_attributes
user_name
encrypted_password
group
View_metadata
view_name
definition
Figure 13.12 Relationalschemarepresentingpartofthesystemmetadata.

--- Page 633 ---

604 Chapter13 DataStorageStructures
Whenever the database system needs to retrieve records from a relation, it must
firstconsulttheRelation metadatarelationtofindthelocationandstorageorganization
oftherelation,andthenfetchrecordsusingthisinformation.
However, the storage organization and location of the Relation metadata relation
itself must be recorded elsewhere (e.g., in the database code itself, or in a fixed loca-
tion in the database), since we need this information to find the contents of Relation
metadata.
Since system metadata are frequently accessed, most databases read it from the
database into in-memory data structures that can be accessed very efficiently. This is
doneaspartofthedatabasestartup,beforethedatabasestartsprocessinganyqueries.
13.5 Database Buffer
The size of main memory on servers has increased greatly over the years, and many
medium-sized databases can fit in memory. However, a server has many demands on
itsmemory,andtheamountofmemoryitcangivetoadatabasemaybemuchsmaller
thanthedatabasesizeevenformedium-sizeddatabases.Andmanylargedatabasesare
muchlargerthantheavailablememoryonservers.
Thus, even today, database data reside primarily on disk in most databases, and
theymustbebroughtintomemorytobereadorupdated;updateddatablocksmustbe
writtenbacktodisksubsequently.
Since data access from disk is much slower than in-memory data access, a major
goalofthedatabasesystem istominimizethenumberofblocktransfersbetweenthe
diskand memory.Onewaytoreducethe numberof diskaccessesistokeepas many
blocks as possible in main memory. The goal is to maximizethe chancethat, when a
blockisaccessed,itisalreadyinmainmemory,and,thus,nodiskaccessisrequired.
Sinceitisnotpossibletokeepallblocksinmainmemory,weneedtomanagethe
allocationofthespaceavailableinmainmemoryforthestorageofblocks.Thebuffer
is that part of main memory available for storage of copies of disk blocks. There is
alwaysacopykeptondiskofeveryblock,butthecopyondiskmaybeaversionofthe
blockolderthantheversioninthebuffer.Thesubsystemresponsiblefortheallocation
ofbufferspaceiscalledthebuffermanager.
13.5.1 Buffer Manager
Programsinadatabasesystemmakerequests(i.e.,calls)onthebuffermanagerwhen
they need a block from disk. If the block is already in the buffer, the buffer manager
passestheaddressoftheblockinmainmemorytotherequester.Iftheblockisnotin
thebuffer,thebuffermanagerfirstallocatesspaceinthebufferfortheblock,throwing
out some other block, if necessary, to make space for the new block. The thrown-out
block is written back to disk only if it has been modified since the most recent time
that it was written to the disk. Then, the buffer manager reads in the requested block
fromthedisktothebuffer,andpassestheaddressoftheblockinmainmemorytothe

--- Page 634 ---

13.5 DatabaseBuffer 605
requester. Theinternalactionsofthebuffermanageraretransparent totheprograms
thatissuedisk-blockrequests.
If you are familiar with operating-system concepts, you will note that the buffer
managerappearstobenothingmorethanavirtual-memorymanager,likethosefound
in most operating systems. One difference is that the size of the database might be
larger than the hardware address space of a machine, so memory addresses are not
sufficient to address all disk blocks. Further, to serve the database system well, the
buffer manager must use techniques more sophisticated than typical virtual-memory
managementschemes:
13.5.1.1 Bufferreplacementstrategy
Whenthereisnoroomleftinthebuffer,ablockmustbeevicted,thatis,removed,from
thebufferbeforeanewonecanbereadin.Mostoperatingsystemsusealeastrecently
used (LRU) scheme, in which the block that was referenced least recently is written
backtodiskandisremovedfromthebuffer.Thissimpleapproachcanbeimprovedon
fordatabaseapplications(seeSection13.5.2).
13.5.1.2 Pinnedblocks
Once a block has been brought into the buffer, a database process can read the con-
tents of the block from the buffer memory. However, while the block is being read, if
aconcurrentprocessevictstheblockandreplacesitwithadifferentblock,thereader
thatwasreadingthecontentsoftheoldblockwillseeincorrectdata;iftheblockwas
being written when it was evicted, the writer would end up damaging the contents of
thereplacementblock.
It is therefore important that before a process reads data from a buffer block, it
ensuresthattheblockwillnotgetevicted.Todoso,theprocessexecutesapinoperation
on the block; the buffer manager never evicts a pinned block. When it has finished
readingdata,theprocessshould executean unpinoperation,allowingtheblocktobe
evictedwhenrequired.Thedatabasecodeshouldbewrittencarefullytoavoidpinning
too many blocks: if all the blocks in the buffer get pinned, no blocks can be evicted,
andnootherblockcanbebroughtintothebuffer.Ifthishappens,thedatabasewillbe
unabletocarryoutanyfurtherprocessing!
Multipleprocessescanreaddatafromablockthatisinthebuffer.Eachofthemis
requiredtoexecuteapinoperationbeforeaccessingdata,andanunpinaftercompleting
access. The block cannot be evicted until all processes that have executed a pin have
thenexecutedanunpinoperation.Asimplewaytoensurethispropertyistokeepapin
count for each buffer block. Each pin operation increments the count, and an unpin
operationdecrementsthecount.Apagecanbeevictedonlyifthepincountequals0.
13.5.1.3 SharedandExclusiveLocksonBuffer
Aprocessthataddsordeletesatuplefromapagemayneedtomovethepagecontents
around;duringthisperiod,nootherprocessshouldreadthecontentsofthepage,since

--- Page 635 ---

606 Chapter13 DataStorageStructures
theymaybeinconsistent.Databasebuffermanagersallowprocessestogetsharedand
exclusivelocksonthebuffer.
We willstudy lockingin more detail in Chapter 18, but here we discuss a limited
form oflockinginthecontext ofthe buffermanager.The lockingsystem provided by
the buffer manager allows a database process to lock a buffer block either in shared
mode or in exclusive mode before accessing the block, and to release the lock later,
aftertheaccessiscompleted.Herearetherulesforlocking:
• Anynumberofprocessesmayhavesharedlocksonablockatthesametime.
• Only one process is allowed to get an exclusive lock at a time, and further when
a process has an exclusive lock, no other process may have a shared lock on the
block. Thus, an exclusive lock can be granted only when no other process has a
lockonthebufferblock.
• Ifaprocessrequestsanexclusivelockwhenablockisalreadylockedinsharedor
exclusivemode,therequestiskeptpendinguntilallearlierlocksarereleased.
• If a process requests a shared lock when a block is not locked, or alreadyshared
locked,thelockmaybegranted;however,ifanotherprocesshasanexclusivelock,
thesharedlockisgrantedonlyaftertheexclusivelockhasbeenreleased.
Locksareacquiredandreleasedasfollows:
• Beforecarryingoutanyoperationonablock,aprocessmustpintheblockaswe
saw earlier. Locks are obtained subsequently and must be released before unpin-
ningtheblock.
• Before reading data from a buffer block, a process must get a shared lock on the
block.Whenitisdonereadingthedata,theprocessmustreleasethelock.
• Beforeupdatingthecontentsofabufferblock,aprocessmustgetanexclusivelock
ontheblock;thelockmustbereleasedaftertheupdateiscomplete.
Theserulesensurethatablockcannotbeupdatedwhileanotherprocessisreading
it, and conversely,a block cannotbe read whileanother process isupdating it. These
rulesarerequiredforsafetyofbufferaccess;however,toprotectadatabasesystemfrom
problemsduetoconcurrentaccess,thesestepsarenotsufficient:furtherstepsneedto
betaken.ThesearediscussedfurtherinChapter17andChapter18.
13.5.1.4 Outputofblocks
Itispossibletooutputablockonlywhenthebufferspaceisneededforanotherblock.
However,itmakessensetonotwaituntilthebufferspaceisneeded,buttoratherwrite
out updated blocks ahead of such a need. Then, when space is requiredin the buffer,

--- Page 636 ---

13.5 DatabaseBuffer 607
a block that has already been written out can be evicted, provided it is not currently
pinned.
However,forthedatabasesystemtobeabletorecoverfromcrashes(Chapter19),
it is necessary to restrict those times when a block may be written back to disk. For
instance,mostrecoverysystemsrequirethatablockshouldnotbewrittentodiskwhile
anupdateontheblockisinprogress.Toenforcethisrequirement,aprocessthatwishes
towritetheblocktodiskmustobtainasharedlockontheblock.
Mostdatabaseshaveaprocessthatcontinuallydetectsupdatedblocksandwrites
thembacktodisk.
13.5.1.5 Forcedoutputofblocks
There are situations in which it is necessary to write a block to disk, to ensure that
certaindataondiskareinaconsistentstate.Suchawriteiscalledaforcedoutputofa
block.WeshallseethereasonforforcedoutputinChapter19.
Memory contents and thus buffer contents are lost in a crash, whereas data on
disk (usually) survive a crash. Forced output is used in conjunction with a logging
mechanism to ensure that when a transaction that has performed updates commits,
enough datahasbeenwrittentodisktoensuretheupdates ofthetransaction arenot
lost.HowexactlythisisdoneiscoveredindetailinChapter19.
13.5.2 Buffer-Replacement Strategies
The goal of a replacementstrategy for blocks in the buffer is to minimizeaccesses to
the disk. For general-purpose programs, it is not possible to predictaccurately which
blocks will be referenced. Therefore, operating systems use the past pattern of block
references as a predictor of future references. The assumption generally made is that
blocksthathavebeenreferencedrecentlyarelikelytobereferencedagain.Therefore,if
ablockmustbereplaced,theleastrecentlyreferencedblockisreplaced.Thisapproach
iscalledtheleastrecentlyused(LRU)block-replacementscheme.
LRUisanacceptablereplacementschemeinoperatingsystems. However,adata-
base system is able to predict the pattern of future references more accurately than
anoperatingsystem.Auserrequesttothedatabasesysteminvolvesseveralsteps.The
databasesystemisoftenabletodetermineinadvancewhichblockswillbeneededby
looking at each of the steps required to perform the user-requested operation. Thus,
unlike operating systems, which must rely on the past to predict the future, database
systemsmayhaveinformationregardingatleasttheshort-termfuture.
To illustrate how information about future block access allows us to improve the
LRUstrategy,considertheprocessingoftheSQLquery:
select*
frominstructor naturaljoindepartment;

--- Page 637 ---

608 Chapter13 DataStorageStructures
Assumethatthestrategychosentoprocessthisrequestisgivenbythepseudocode
program shown in Figure 13.13. (We shall study other, more efficient, strategies in
Chapter15.)
Assume that the two relations of this example are stored in separate files. In this
example, we can see that, once a tuple of instructor has been processed, that tuple is
notneededagain.Therefore,onceprocessingofan entireblockofinstructor tuplesis
completed, that block is no longer needed in main memory, even though it has been
usedrecently.Thebuffermanagershouldbeinstructedtofreethespaceoccupiedbyan
instructorblockassoonasthefinaltuplehasbeenprocessed.Thisbuffer-management
strategyiscalledthetoss-immediatestrategy.
Now consider blocks containing department tuples. We need to examine every
blockofdepartmenttuplesonceforeachtupleoftheinstructorrelation.Whenprocess-
ing of a department block is completed, we know that that block will not be accessed
again until all other department blocks have been processed. Thus, the most recently
useddepartmentblockwillbethefinalblocktobere-referenced,andtheleastrecently
used department block is the block that will be referenced next. This assumption set
isthe exactopposite ofthe onethatformsthebasisfortheLRUstrategy. Indeed,the
optimal strategy for block replacement for the above procedure is the most recently
used(MRU)strategy.Ifadepartmentblockmustberemovedfromthebuffer,theMRU
strategychoosesthemostrecentlyusedblock(blocksarenoteligibleforreplacement
whiletheyarebeingused).
foreachtupleiofinstructor do
foreachtupled ofdepartmentdo
ifi[dept name]=d[dept name]
thenbegin
letxbeatupledefinedasfollows:
x[ID]:=i[ID]
x[dept name]:=i[dept name]
x[name]:=i[name]
x[salary]:=i[salary]
x[building]:=d[building]
x[budget]:=d[budget]
includetuplexaspartofresultofinstructor ⋈department
end
end
end
Figure 13.13 Procedureforcomputing join.

--- Page 638 ---

13.5 DatabaseBuffer 609
FortheMRU strategy toworkcorrectlyforour example, thesystem must pinthe
departmentblockcurrentlybeingprocessed.Afterthefinaldepartmenttuplehasbeen
processed,theblockisunpinned,anditbecomesthemostrecentlyusedblock.
Inadditiontousing knowledgethatthe system mayhave about therequest being
processed,thebuffermanagercanusestatisticalinformationabouttheprobabilitythat
a request will reference a particular relation. For example, the data dictionary, which
we saw in Section 13.4, is one of the most frequently accessed parts of the database,
sincetheprocessingofeveryqueryneedstoaccessthedatadictionary.Thus,thebuffer
manager should try not to remove data-dictionary blocks from main memory, unless
otherfactorsdictatethatitdoso.InChapter14,wediscussindicesforfiles.Sincean
index for a file may be accessed more frequently than the file itself, the buffer man-
agershould,ingeneral,notremoveindexblocksfrommainmemoryifalternativesare
available.
The ideal database block-replacement strategy needs knowledge of the database
operations—both those being performed and those that will be performed in the fu-
ture. No single strategy is known that handles all the possible scenarios well.Indeed,
asurprisinglylargenumberofdatabasesystemsuseLRU,despitethatstrategy’sfaults.
Thepracticequestionsandexercisesexplorealternativestrategies.
The strategy that the buffer manager uses for block replacement is influenced by
factorsotherthanthetimeatwhichtheblockwillbereferencedagain.Ifthesystemis
processing requests by several users concurrently,the concurrency-controlsubsystem
(Chapter 18) may need to delay certain requests, to ensure preservation of database
consistency. If the buffer manager is given information from the concurrency-control
subsystem indicatingwhich requests are being delayed, it can use this information to
alteritsblock-replacementstrategy.Specifically,blocksneededbyactive(nondelayed)
requests can be retained in the buffer at the expense of blocks needed by the delayed
requests.
Thecrash-recoverysubsystem(Chapter19)imposesstringentconstraintsonblock
replacement.Ifablockhasbeenmodified,the buffermanagerisnotallowedtowrite
back the new version of the block in the buffer to disk, since that would destroy the
oldversion.Instead,theblockmanagermustseekpermissionfromthecrash-recovery
subsystembeforewritingoutablock.Thecrash-recoverysubsystemmaydemandthat
certainotherblocksbeforce-outputbeforeitgrantspermissiontothebuffermanagerto
outputtheblockrequested.InChapter19,wedefinepreciselytheinteractionbetween
thebuffermanagerandthecrash-recoverysubsystem.
13.5.3 Reordering of Writes and Recovery
Databasebuffersallowwritestobeperformedin-memoryandoutputtodiskatalater
time,possiblyinanorderdifferentfromtheorderinwhichthewriteswereperformed.
Filesystems,too,routinelyreorderwriteoperations.However,suchreorderingcanlead
toinconsistentdataondiskintheeventofasystemcrash.

--- Page 639 ---

610 Chapter13 DataStorageStructures
Tounderstandtheprobleminthecontextofafilesystem,supposethatafilesystem
usesalinkedlisttotrackwhichblocksarepartofafile.Suppose alsothatitinsertsa
newnodeattheendofthelistbyfirstwritingthedataforthenewnode,thenupdating
thepointerfromthepreviousnode.Supposefurtherthatthewriteswerereordered,so
the pointer was updated first, and the system crashes before the new node is written.
Thecontentsofthenodewouldthenbewhateverhappenedtobeonthatdiskearlier,
resultinginacorrupteddatastructure.
Todealwiththepossibilityofsuchdatastructurecorruption,earlier-generationfile
systemshadtoperformafilesystemconsistencycheckonsystemrestart,toensurethat
the data structures were consistent. And if they were not, extra steps had to be taken
to restore them to consistency. These checks resulted in long delays in system restart
afteracrash,andthedelaysbecameworseasdisksystemsgrewtohighercapacities.
Thefilesystemcanavoidinconsistenciesinmanycasesifitwritesupdatestometa-
datainacarefullychosenorder.Butdoingsowouldmeanthatoptimizationssuchas
disk arm scheduling cannot be done, affecting the efficiency of the update. If a non-
volatile write buffer were available, it could be used to perform the writes in order to
non-volatileRAMandlaterreorderthewriteswhenwritingthemtodisk.
However, most disks do not come with a non-volatile write buffer; instead, mod-
ern file systems assign a disk for storing a log of the writes in the order that they are
performed.Suchadiskiscalledalogdisk.Foreachwrite,thelogcontainstheblock
number to be written to, and the data to be written, in the order in which the writes
were performed. All access to the log disk is sequential, essentially eliminating seek
time, and several consecutive blocks can be written at once, making writes to the log
diskseveraltimesfasterthanrandomwrites.Asbefore,thedatahavetobewrittento
their actual location on disk as well, but the write to the actual location can be done
later;thewritescanbereorderedtominimizedisk-armmovement.
If the system crashes before some writes to the actual disk location have been
completed, when the system comes back up it reads the log disk to find those writes
that had not been completed and carries them out then. After the writes have been
performed,therecordsaredeletedfromthelogdisk.
Filesystemsthatsupportlogdisksasabovearecalledjournalingfilesystems.Jour-
nalingfilesystemscanbeimplementedevenwithoutaseparatelogdisk,keepingdata
and the log on the same disk. Doing so reduces the monetary cost at the expense of
lowerperformance.
Mostmodernfilesystemsimplementjournalingandusethelogdiskwhenwriting
file system metadatasuch asfile allocationinformation.Journalingfilesystems allow
quickrestartwithouttheneedforsuchfilesystemconsistencychecks.
However,writesperformedbyapplicationsareusuallynotwrittentothelogdisk.
Database systems instead implement their own forms of logging, which we study in
Chapter 19, to ensure that the contents of a database can be safely recovered in the
eventofafailure,evenifwriteswerereordered.

--- Page 640 ---

13.6 Column-OrientedStorage 611
13.6 Column-Oriented Storage
Databasestraditionallystoreallattributesofatupletogetherinarecord,andtuplesare
storedinafileaswehavejustseen.Suchastoragelayoutisreferredtoasarow-oriented
storage.
In contrast, in column-oriented storage, also called a columnar storage, each at-
tribute of a relation is stored separately, with values of the attribute from successive
tuples stored at successive positions in the file. Figure 13.14 shows how the instructor
relation would be stored in column-oriented storage, with each attribute stored sepa-
rately.
Inthesimplestformofcolumn-orientedstorage,eachattributeisstoredinasepa-
ratefile.Further,eachfileiscompressed,toreduceitssize.(Wediscussmorecomplex
schemesthatstorecolumnsconsecutivelyinasinglefilelaterinthissection.)
Ifaqueryneedstoaccesstheentirecontentsoftheithrowofatable,thevaluesat
theith position ineachofthe columnsare retrievedand used toreconstructtherow.
Column-oriented storage thus has the drawback that fetching multiple attributes of a
single tuple requires multiple I/O operations. Thus, it is not suitable for queries that
fetchmultipleattributesfromafewrowsofarelation.
However, column-oriented storage is well suited for data analysis queries, which
process many rows of a relation, but often only access some of the attributes. The
reasonsareasfollows:
• ReducedI/O.Whenaqueryneedstoaccessonlyafewattributesofarelationwitha
largenumberofattributes,theremainingattributesneednotbefetchedfromdisk
intomemory.Incontrast,inrow-orientedstorage,irrelevantattributesarefetched
intomemoryfrom disk. The reductionin I/Ocanlead tosignificantreductionin
queryexecutioncost.
10101 Srinivasan Comp.Sci. 65000
12121 Wu Finance 90000
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 ElSaid History 60000
33456 Gold Physics 87000
45565 Katz Comp.Sci. 75000
58583 Califieri History 62000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp.Sci. 92000
98345 Kim Elec.Eng. 80000
Figure 13.14 Columnarrepresentationoftheinstructor relation.

--- Page 641 ---

612 Chapter13 DataStorageStructures
• Improved CPU cache performance. When the query processor fetches the con-
tentsofaparticularattribute,withmodernCPUarchitecturesmultipleconsecutive
bytes, called a cache line, are fetched from memory to CPU cache. If these bytes
are accessed later, access is much faster if they are in cache than if they have to
befetchedfrommainmemory.However,iftheseadjacentbytescontainvaluesfor
attributes that are not be needed by the query, fetching them into cache wastes
memorybandwidthandusesupcachespacethatcouldhavebeenusedforother
data. Column-oriented storage does not suffer from this problem, since adjacent
bytesarefromthesamecolumn,anddataanalysisqueriesusuallyaccessallthese
valuesconsecutively.
• Improved compression. Storing values of the same type together significantly in-
creases the effectiveness of compression, when compared to compressing data
storedinrowformat;inthelattercase,adjacentattributesareofdifferenttypes,re-
ducingtheefficiencyofcompression.Compressionsignificantlyreducesthetime
taken to retrieve data from disk, which is often the highest-cost component for
many queries. If the compressed files are stored in memory, the in-memory stor-
age space is also reduced correspondingly, which is particularly important since
mainmemoryissignificantlymoreexpensivethandiskstorage.
• Vector processing. Many modern CPU architectures support vector processing,
which allows a CPU operation to be applied in parallel on a number of elements
ofanarray.Storingdatacolumnwiseallowsvectorprocessingofoperationssuch
ascomparinganattribute withaconstant,whichisimportantforapplyingselec-
tion conditions on a relation. Vector processing can also be used to compute an
aggregateofmultiplevaluesinparallel,insteadofaggregatingthevaluesoneata
time.
Asaresultofthesebenefits,column-orientedstorage isincreasinglyusedindata-
warehousingapplications,wherequeriesareprimarilydataanalysisqueries.Itshould
benotedthatindexingandqueryprocessingtechniquesneedtobecarefullydesigned
to get the performance benefits of column-oriented storage. We outline indexing and
queryprocessingtechniquesbasedonbitmaprepresentations,whicharewellsuitedto
column-orientedstorage,inSection14.9;furtherdetailsareprovidedinSection24.3.
Databasesthatusecolumn-orientedstoragearereferredtoascolumnstores,while
databasesthatuserow-orientedstoragearereferredtoasrowstores.
It should be noted that column-oriented storage does have several drawbacks,
whichmakethemunsuitablefortransactionprocessing.
• Cost of tuple reconstruction. As we saw earlier, reconstructing a tuple from the
individualcolumnscanbeexpensive,negatingthebenefitsofcolumnarrepresen-
tation if many columns need to be reconstructed. While tuple reconstruction is
commonintransaction-processingapplications,dataanalysisapplicationsusually

--- Page 642 ---

13.6 Column-OrientedStorage 613
output only a few columns out of many that are stored in “fact tables” in data
warehouses.
• Cost of tuple deletion and update. Deleting or updating a single tuple in a com-
pressed representation would requirerewritingthe entire sequence of tuples that
arecompressedasoneunit.Sinceupdatesanddeletesarecommonintransaction-
processing applications, column-oriented storage would result in a high cost for
theseoperationsifalargenumberoftupleswerecompressedasoneunit.
In contrast, data-warehousing systems typically do not support updates to tu-
ples, and instead support only insert of new tuples and bulk deletes of a large
number of old tuples at a time. Inserts are done at the end of the relation repre-
sentation,thatis,newtuplesareappendedtotherelation.Sincesmalldeletesand
updatesdonotoccurinadatawarehouse,largesequencesofattributevaluescan
be stored and compressed together as one unit, allowing for better compression
thanwithsmallsequences.
• Cost of decompression. Fetchingdata from a compressed representation requires
decompression,whichinthesimplestcompressedrepresentationsrequiresreading
all the data from the beginning of a file. Transaction processing queries usually
onlyneedtofetchafewrecords;sequentialaccessisexpensiveinsuchascenario,
sincemanyirrelevantrecordsmayhavetobedecompressedtoaccessafewrelevant
records.
Sincedataanalysisqueriestendtoaccessmanyconsecutiverecords,thetimespent
ondecompressionistypicallynotwasted.However,evendataanalysisqueriesdonot
need to access records that fail selection conditions, and attributes of such records
shouldbeskippedtoreducediskI/O.
To allow skipping of attribute values from such records, compressed representa-
tions for column stores allow decompression to start at any of a number of points in
the file, skipping earlier parts of the file. This could be done by starting compression
afreshafterevery10,000values(forexample).Bykeepingtrackofwhereinthefilethe
datastartforeachgroupof10,000values,itispossibletoaccesstheithvaluebygoing
tothestartofthegroup⌊i∕10000⌋andstartingdecompressionfromthere.
ORC and Parquet are columnar file representations used in many big-data pro-
cessing applications. In ORC, a row-oriented representation is converted to column-
oriented representation as follows: A sequence of tuples occupying several hundred
megabytes is broken up into a columnar representation called a stripe. An ORC file
containsseveralsuchstripes,witheachstripeoccupyingaround250megabytes.
Figure13.15illustratessomedetailsoftheORCfileformat.Eachstripehasindex
data followed by row data. The row data area stores a compressed representation of
thesequenceofvalueforthefirstcolumn,followedbythecompressedrepresentation
of the second column, and so on. The index data region of a stripe stores for each
attribute the starting point within the stripe for each group of (say) 10,000 values of

--- Page 643 ---

614 Chapter13 DataStorageStructures
Index Data
Stripe 1 Col1 Index
Row Data
Col2 Index
Col3 Index
Stripe Footer
Col4 Index
Index Data
Col5 Index
Stripe 2
Row Data
Col1 Data
Col2 Data
Stripe Footer
Col3 Data
Col4 Data
Col5 Data
Index Data
Stripe n
Row Data
Stripe Footer
File Footer
Figure 13.15 ColumnardatarepresentationintheORCfileformat.
that attribute.7 The index is useful for quick access to a desired tuple or sequence of
tuples; the index also allows queries containing selections to skip groups of tuples if
the query determines that no tuple in those groups satisfies the selections. ORC files
store several otherpiecesof information in the stripe footer and file footer, whichwe
skiphere.
Some column-store systems allow groups of columns that are often accessed to-
gether to be stored together, instead of breaking up each column into a different file.
Suchsystems thusallowaspectrumofchoicesthatrangefrompurecolumn-oriented
storage,whereeverycolumnisstoredseparately,topurerow-orientedstorage,whereall
columnsarestoredtogether.Thechoiceofwhichattributestostoretogetherdepends
onthequeryworkload.
7ORCfileshavesomeotherinformationthatweignorehere.

--- Page 644 ---

13.7 StorageOrganizationinMain-MemoryDatabases 615
Some of the benefits of column-oriented storage can be obtained even in a row-
orientedstoragesystembylogicallydecomposingarelationintomultiplerelations.For
example, the instructor relation could be decomposed into three relations, containing
(ID, name), (ID, dept name) and (ID, salary), respectively. Then, queries that access
only the name do not have to fetch the dept name and salary attributes. However, in
thiscasethesameIDattributeoccursinthreetuples,resultinginwastedspace.
Somedatabasesystemsuseacolumn-orientedrepresentationfordatawithinadisk
block,withoutusingcompression.8 Thus,ablockcontainsdataforasetoftuples,and
allattributesforthatsetoftuplesarestoredinthesameblock.Suchaschemeisuseful
intransaction-processingsystems,sinceretrievingallattributevaluesdoesnotrequire
multiple disk accesses. At the same time, using column-oriented storage within the
block provides the benefits of more efficient memory accessand cache usage, as well
as the potential for using vector processing on the data. However, this scheme does
notallowirrelevantdiskblockstobeskippedwhenonlyafewattributesareretrieved,
nor does it give the benefits of compression. Thus, it represents a point in the space
betweenpurerow-orientedstorageandpurecolumn-orientedstorage.
Somedatabases,suchasSAPHANA supporttwounderlyingstoragesystems,one
a row-oriented one designed for transaction processing, and the second a column-
oriented one, designed for data analysis. Tuples are normally created in the row-
oriented store but are later migrated to the column-oriented store when they are no
longer likely to be accessed in a row-oriented manner. Such systems are calledhybrid
row/columnstores.
In other cases, applications store transactional data in a row-oriented store, but
copy data periodically (e.g., once a day or a few times a day) to a data warehouse,
whichmayuseacolumn-orientedstoragesystem.
SybaseIQwasoneoftheearlyproductstousecolumn-orientedstorage,butthere
arenowseveralresearchprojectsandcompaniesthathavedevelopeddatabasesystems
basedoncolumnstores,includingC-Store,Vertica,MonetDB,Vectorwise,amongoth-
ers.SeeFurtherReadingattheendofthechapterformoredetails.
13.7 Storage Organization in Main-Memory Databases
Today,main-memorysizesarelargeenough,andmainmemoryischeapenough,that
manyorganizationaldatabasesfitentirelyinmemory.Suchlargemainmemoriescan
beusedbyallocatingalargeamountofmemorytothedatabasebuffer,whichwillallow
the entire database to be loaded into buffer, avoiding disk I/O operations for reading
data;updatedblocksstillhavetobewrittenbacktodiskforpersistence.Thus,sucha
setupwouldprovidemuchbetterperformancethanonewhereonlypartofthedatabase
canfitinthebuffer.
8Compressioncanbeappliedtodatainadiskblock,butaccessingthemrequiresdecompression,andthedecom-
presseddatamaynolongerfitinablock.Significantchangesneedtobemadetothedatabasecode,includingbuffer
management,tohandlesuchissues.

--- Page 645 ---

616 Chapter13 DataStorageStructures
However,iftheentiredatabasefitsinmemory,performancecanbeimprovedsig-
nificantlybytailoringthestorageorganizationanddatabasedatastructurestoexploit
the fact that data are fully in memory. A main-memory database is a database where
all data reside in memory; main-memory database systems are typically designed to
optimize performance by making use of this fact. In particular, they do away entirely
withthebuffermanager.
Asanexampleofoptimizationsthatcanbedonewithmemory-residentdata,con-
siderthecostofaccessingarecord,givenarecordpointer.Withdisk-baseddatabases,
records are stored in blocks, and pointers to records consist of a block identifier and
an offset or slot number within the block. Following such a record pointer requires
checkingiftheblockisinthebuffer(usuallydonebyusinganin-memoryhashindex),
and if it is, finding where in the buffer it is located. If it is not in buffer, it has to be
fetched.AlltheseactionstakeasignificantnumberofCPUcycles.
In contrast, in a main-memory database, it is possible to keep direct pointers to
recordsinmemory,andaccessingarecordisjustanin-memorypointertraversal,which
isaveryefficientoperation.Thisispossibleaslongasrecordsarenotmovedaround.
Indeed,one reason forsuch movement,namelyloadingintobuffer andevictionfrom
buffer,isnolongeranissue.
Ifrecordsarestoredinaslotted-page structure withinablock,recordsmaymove
within a block as other records are deleted or resized. Direct pointers to records are
notpossibleinthatcase,althoughrecordscanbeaccessedwithonelevelofindirection
throughtheentriesintheslottedpageheader.Lockingoftheblockmayberequiredto
ensure that a record does not get moved whileanother process is readingits data. To
avoid these overheads, many main-memorydatabases do not use a slotted-page struc-
tureforallocatingrecords.Insteadtheydirectlyallocaterecordsinmainmemory,and
ensurethatrecordsnevergetmovedduetoupdatestootherrecords.However,aprob-
lem with direct allocation of records is that memory may get fragmented if variable
sizedrecordsarerepeatedlyinsertedanddeleted.Thedatabasemustensurethatmain
memorydoesnotgetfragmentedovertime,eitherbyusingsuitablydesignedmemory
managementschemesorbyperiodicallyperformingcompactionofmemory;thelatter
schemewillresultinrecordmovement,butitcanbedonewithoutacquiringlockson
blocks.
If a column-oriented storage scheme is used in main memory, all the values of
a column can be stored in consecutive memory locations. However, if there are ap-
pends to the relation, ensuring contiguous allocation would require existing data be
reallocated.Toavoidthisoverhead,thelogicalarrayforacolumnmaybedividedinto
multiplephysicalarrays.Anindirectiontablestorespointerstoallthephysicalarrays.
ThisschemeisdepictedinFigure13.16.Tofindtheithelementofalogicalarray,the
indirection table is used to locate the physical array containing the ith element, and
thenanappropriateoffsetiscomputedandlookedupwithinthatphysicalarray.
There are other ways in which processing can be optimized with main-memory
databases,asweshallseeinlaterchapters.

--- Page 646 ---

13.8 Summary 617
Col1 Data
Col2 Data
Col3 Data
Col4 Data
Col5 Data
Col1 Data
Col2 Data
Col3 Data
Col4 Data
Col5 Data
Col1 Data
Col2 Data
Col3 Data
Indirection Table
Col4 Data
Col5 Data
Figure 13.16 In-memorycolumnardatarepresentation.
13.8 Summary
• Wecanorganizeafilelogicallyasasequenceofrecordsmappedontodiskblocks.
Oneapproachtomappingthedatabasetofilesistouseseveralfiles,andtostore
records of only one fixed length in any given file. An alternative is to structure
filessothattheycanaccommodatemultiplelengthsforrecords.Theslotted-page
methodiswidelyusedtohandlevarying-lengthrecordswithinadiskblock.
• Since data are transferred between disk storage and main memory in units of a
block, it is worthwhileto assign file records to blocks in such a way that a single
blockcontainsrelatedrecords.Ifwecanaccessseveraloftherecordswewantwith
only one block access, we save disk accesses. Since disk accesses are usually the
bottleneckintheperformanceofadatabasesystem,carefulassignmentofrecords
toblockscanpaysignificantperformancedividends.
• Thedatadictionary,alsoreferredtoasthesystemcatalog,keepstrackofmetadata,
thatis,dataaboutdata,suchasrelationnames,attributenamesandtypes,storage
information,integrityconstraints,anduserinformation.

--- Page 647 ---

618 Chapter13 DataStorageStructures
• Onewaytoreducethenumberofdiskaccessesistokeepasmanyblocksaspos-
sibleinmainmemory.Sinceitisnotpossibletokeepallblocksinmainmemory,
we need to manage the allocation of the space available in main memory for the
storage ofblocks.Thebuffer isthatpartofmainmemoryavailableforstorage of
copiesofdiskblocks.Thesubsystemresponsiblefortheallocationofbufferspace
iscalledthebuffermanager.
• Column-orientedstorage systems providegoodperformanceformanydataware-
housingapplications.
Review Terms
• FileOrganization ° Systemcatalog
° File • Databasebuffer
° Blocks ° Buffermanager
• Fixed-lengthrecords
° Pinnedblocks
• Fileheader
° Evictedblocks
• Freelist
• Variable-lengthrecords ° Forcedoutputofblocks
• Nullbitmap ° Sharedandexclusivelocks
• Slotted-pagestructure • Buffer-replacementstrategies
• Largeobjects ° Leastrecentlyused(LRU)
• Organizationofrecords
° Toss-immediate
° Heapfileorganization
° Mostrecentlyused(MRU)
° Sequentialfileorganization
• Outputofblocks
° Multitableclusteringfileorganiza-
• Forcedoutputofblocks
tion
• Logdisk
° B+-treefileorganizations • Journalingfilesystems
° Hashingfileorganization • Column-orientedstorage
• Free-spacemap ° Columnarstorage
• Sequentialfile
° Vectorprocessing
• Searchkey
° Columnstores
• Clusterkey
• Tablepartitioning ° Rowstores
• Data-dictionarystorage ° Stripe
° Metadata ° Hybridrow/columnstorage
° Datadictionary • Main-memorydatabase

--- Page 648 ---

PracticeExercises 619
Practice Exercises
13.1 Consider the deletion of record 5 from the file of Figure 13.3. Compare the
relativemeritsofthefollowingtechniquesforimplementingthedeletion:
a. Moverecord6tothespaceoccupiedbyrecord5,andmoverecord7to
thespaceoccupiedbyrecord6.
b. Moverecord7tothespaceoccupiedbyrecord5.
c. Markrecord5asdeleted,andmovenorecords.
13.2 ShowthestructureofthefileofFigure13.4aftereachofthefollowingsteps:
a. Insert(24556,Turnamian,Finance,98000).
b. Deleterecord2.
c. Insert(34556,Thompson,Music,67000).
13.3 Consider the relations section and takes. Give an example instance of these
tworelations,withthreesections,eachofwhichhasfivestudents. Giveafile
structureoftheserelationsthatusesmultitableclustering.
13.4 Consider the bitmap representation of the free-space map, where for each
blockinthefile,twobitsaremaintainedinthebitmap.Iftheblockisbetween
0 and 30 percent full the bits are 00, between 30 and 60 percent the bits are
01, between 60 and 90 percent the bits are 10, and above 90 percent the bits
are11.Suchbitmapscanbekeptinmemoryevenforquitelargefiles.
a. Outline two benefits and one drawback to using two bits for a block,
insteadofonebyteasdescribedearlierinthischapter.
b. Describe how to keep the bitmap up to date on record insertions and
deletions.
c. Outline the benefit of the bitmap technique over free lists in searching
forfreespaceandinupdatingfreespaceinformation.
13.5 Itisimportanttobeabletoquicklyfindoutifablockispresentinthebuffer,
and if so where in the buffer it resides. Given that database buffer sizes are
verylarge,what(in-memory)datastructurewouldyouuseforthistask?
13.6 Supposeyouruniversityhasaverylargenumberoftakesrecords,accumulated
overmanyyears.Explainhowtablepartitioningcanbedoneonthetakesrela-
tion,and whatbenefits itcouldoffer. Explain also one potential drawbackof
thetechnique.

--- Page 649 ---

620 Chapter13 DataStorageStructures
13.7 Giveanexampleofarelational-algebraexpressionandaquery-processingstrat-
egyineachofthefollowingsituations:
a. MRUispreferabletoLRU.
b. LRUispreferabletoMRU.
13.8 PostgreSQL normally uses a small buffer, leaving it to the operating system
buffer manager to manage the rest of main memory available for file system
buffering. Explain (a) what is the benefit of this approach, and (b) one key
limitationofthisapproach.
Exercises
13.9 Inthe variable-lengthrecordrepresentation,anull bitmapisused toindicate
ifanattributehasthenullvalue.
a. Forvariable-lengthfields,ifthevalueisnull,whatwouldbestoredinthe
offsetandlengthfields?
b. Insomeapplications,tupleshaveaverylargenumberofattributes,most
of which are null. Can you modify the record representation such that
theonlyoverheadforanullattributeisthesinglebitinthenullbitmap?
13.10 Explainwhytheallocationofrecordstoblocksaffectsdatabase-systemperfor-
mancesignificantly.
13.11 Listtwoadvantagesandtwodisadvantagesofeachofthefollowingstrategies
forstoringarelationaldatabase:
a. Storeeachrelationinonefile.
b. Storemultiplerelations(perhapseventheentiredatabase)inonefile.
13.12 Inthesequentialfileorganization,whyisanoverflowblockusedevenifthere
is,atthemoment,onlyoneoverflowrecord?
13.13 Give a normalized version of the Index metadata relation, and explain why
usingthenormalizedversionwouldresultinworseperformance.
13.14 Standardbuffermanagersassumeeachblockisofthesamesizeandcoststhe
same to read. Consider a buffer manager that, instead of LRU, uses the rate
of reference to objects, that is, how often an object has been accessed in the
lastnseconds.Supposewewanttostoreinthebufferobjectsofvaryingsizes,
and varying read costs (such as web pages, whose read cost depends on the
site from whichthey arefetched). Suggest how abuffermanager maychoose
whichblocktoevictfromthebuffer.

--- Page 650 ---

FurtherReading 621
Further Reading
[Hennessy et al. (2017)] is a popular textbook on computer architecture, which in-
cludes coverage of hardware aspects of translation look-aside buffers, caches, and
memory-managementunits.
Thestoragestructureofspecificdatabasesystems,suchasIBMDB2,Oracle,Mi-
crosoftSQLServer,andPostgreSQLaredocumentedintheirrespectivesystem man-
uals,whichareavailableonline.
Algorithmsforbuffermanagementindatabasesystems,alongwithaperformance
evaluation, were presented by [Chou and Dewitt (1985)]. Buffer management in op-
eratingsystemsisdiscussedinmostoperating-systemtexts,includingin[Silberschatz
etal.(2018)].
[Abadietal.(2008)]presentsacomparisonofcolumn-orientedandrow-oriented
storage,includingissuesrelatedtoqueryprocessingandoptimization.
Sybase IQ, developed in the mid 1990s, was the first commercially successful
column-orienteddatabase,designedforanalytics.MonetDBandC-Storewerecolumn-
oriented databases developed as academic research projects. The Vertica column-
orienteddatabaseisacommercialdatabasethatgrewoutofC-Store,whileVectorWise
isacommercialdatabasethatgrewoutofMonetDB.Asitsnamesuggests,VectorWise
supportsvectorprocessingofdata,andasaresultsupportsveryhighprocessingrates
formanyanalyticalqueries.[Stonebrakeretal.(2005)]describeC-Store,while[Idreos
et al. (2012)] give an overview of the MonetDB project and [Zukowski et al. (2012)]
describesVectorwise.
TheORCandParquetcolumnarfileformatsweredevelopedtosupportcompressed
storageofdataforbig-dataapplicationsthatrunontheApacheHadoopplatform.
Bibliography
[Abadietal.(2008)] D. J. Abadi, S. Madden, and N. Hachem, “Column-Stores vs. Row-S-
tores:HowDifferentAreTheyReally?”,InProc.oftheACMSIGMODConf.onManagement
ofData(2008),pages967–980.
[ChouandDewitt(1985)] H.T.ChouandD.J.Dewitt,“AnEvaluationofBufferManage-
mentStrategiesforRelationalDatabaseSystems”,InProc.oftheInternationalConf.onVery
LargeDatabases(1985),pages127–141.
[Hennessyetal.(2017)] J.L.Hennessy,D.A.Patterson,andD.Goldberg,ComputerArchi-
tecture:AQuantitativeApproach,6thedition,MorganKaufmann(2017).
[Idreosetal.(2012)] S.Idreos,F.Groffen,N.Nes,S.Manegold,K.S.Mullender,andM.L.
Kersten, “MonetDB: Two Decades of Research in Column-oriented Database Architec-
tures”,IEEEDataEngineeringBulletin,Volume35,Number1(2012),pages40–45.
[Silberschatzetal.(2018)] A. Silberschatz, P. B. Galvin, and G. Gagne, Operating System
Concepts,10thedition,JohnWileyandSons(2018).

--- Page 651 ---

622 Chapter13 DataStorageStructures
[Stonebrakeretal.(2005)] M.Stonebraker,D.J.Abadi,A.Batkin,X.Chen,M.Cherniack,
M.Ferreira,E.Lau,A.Lin,S.Madden,E.J.O’Neil,P.E.O’Neil,A.Rasin,N.Tran,and
S. B. Zdonik, “C-Store: A Column-oriented DBMS”, In Proc. of the International Conf. on
VeryLargeDatabases(2005),pages553–564.
[Zukowskietal.(2012)] M. Zukowski, M. van de Wiel, and P. A. Boncz, “Vectorwise: A
VectorizedAnalyticalDBMS”,InProc.oftheInternationalConf.onDataEngineering(2012),
pages1349–1350.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 652 ---

14
CHAPTER
Indexing
Manyqueriesreferenceonlyasmallproportionoftherecordsinafile.Forexample,a
querylike“FindallinstructorsinthePhysicsdepartment”or“Findthetotalnumberof
creditsearnedbythestudentwithID22201”referencesonlyafractionoftheinstructor
or student records. It is inefficient for the system to read every tuple in the instructor
relation to checkif the dept name value is “Physics”. Likewise, it isinefficientto read
the entire student relation just to find the one tuple for the ID “22201”. Ideally, the
system shouldbeabletolocatetheserecordsdirectly.Toallowtheseformsofaccess,
wedesignadditionalstructuresthatweassociatewithfiles.
14.1 Basic Concepts
Anindexforafileinadatabasesystemworksinmuchthesamewayastheindexinthis
textbook.Ifwewanttolearnaboutaparticulartopic(specifiedbyawordoraphrase)
inthistextbook, wecansearchforthetopicintheindexatthebackofthebook,find
the pages where it occurs, and then read the pages to find the information for which
we are looking. The words in the indexare in sorted order, making iteasy to find the
word we want. Moreover, the index is much smaller than the book, further reducing
theeffortneeded.
Database-systemindicesplaythesameroleasbookindicesinlibraries.Forexam-
ple,toretrieveastudentrecordgivenanID,thedatabasesystemwouldlookupanindex
tofindonwhichdiskblock1 thecorrespondingrecordresides,andthenfetchthedisk
block,togettheappropriatestudentrecord.
Indicesarecriticalforefficientprocessingofqueriesindatabases.Withoutindices,
every query would end up reading the entire contents of every relation that it uses;
doingsowouldbeunreasonablyexpensiveforqueriesthatonlyfetchafewrecords,for
example,asinglestudent record,ortherecordsinthetakesrelationcorrespondingto
asinglestudent.
1Asinearlierchapters,weusethetermdisktorefertopersistentstoragedevices,suchasmagneticdisksandsolid-state
drives.
623

--- Page 653 ---

624 Chapter14 Indexing
Implementinganindexonthestudentrelationbykeepingasortedlistofstudents’
ID would not work well on very large databases, since (i) the index would itself be
very big, (ii) even though keeping the index sorted reduces the search time, finding a
studentcanstillberathertime-consuming,and(iii)updatingasortedlistasstudentsare
addedorremovedfromthedatabasecanbeveryexpensive.Instead,moresophisticated
indexing techniques are used in database systems. We shall discuss several of these
techniquesinthischapter.
Therearetwobasickindsofindices:
• Orderedindices.Basedonasortedorderingofthevalues.
• Hashindices.Basedonauniformdistributionofvaluesacrossarangeofbuckets.
Thebuckettowhichavalueisassignedisdeterminedbyafunction,calledahash
function.
Weshallconsiderseveraltechniquesfororderedindexing.Noonetechniqueisthe
best. Rather, each technique is best suited to particular database applications. Each
techniquemustbeevaluatedonthebasisofthesefactors:
• Accesstypes: Thetypes ofaccessthatare supported efficiently.Accesstypescan
includefindingrecordswithaspecifiedattributevalueandfindingrecordswhose
attributevaluesfallinaspecifiedrange.
• Accesstime:Thetimeittakestofindaparticulardataitem,orsetofitems,using
thetechniqueinquestion.
• Insertiontime:Thetimeittakestoinsertanewdataitem.Thisvalueincludesthe
time it takes to find the correct place to insert the new data item, as well as the
timeittakestoupdatetheindexstructure.
• Deletiontime:Thetimeittakestodeleteadataitem.Thisvalueincludesthetime
it takes to find the item to be deleted, as well as the time it takes to update the
indexstructure.
• Spaceoverhead:Theadditionalspaceoccupiedbyanindexstructure.Providedthat
the amount of additional space is moderate, it is usually worthwhile to sacrifice
thespacetoachieveimprovedperformance.
We often want to have more than one index for a file. For example, we may wish
tosearchforabookbyauthor,bysubject,orbytitle.
Anattributeorsetofattributesusedtolookuprecordsinafileiscalledasearch
key. Note that this definition of key differs from that used in primary key, candidate
key,andsuperkey.Thisduplicatemeaningforkeyis(unfortunately)wellestablishedin
practice.Usingournotionofasearchkey,weseethatifthereareseveralindicesona
file,thereareseveralsearchkeys.

--- Page 654 ---

14.2 OrderedIndices 625
10101 Srinivasan Comp. Sci. 65000
12121 Wu Finance 90000
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 El Said History 60000
33456 Gold Physics 87000
45565 Katz Comp. Sci. 75000
58583 Califieri History 62000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp. Sci. 92000
98345 Kim Elec. Eng. 80000
Figure 14.1 Sequentialfileforinstructor records.
14.2 Ordered Indices
To gain fast random access to records in a file, we can use an index structure. Each
indexstructureisassociatedwithaparticularsearchkey.Justliketheindexofabook
oralibrarycatalog,anorderedindexstoresthevaluesofthesearchkeysinsortedorder
andassociateswitheachsearchkeytherecordsthatcontainit.
Therecordsintheindexedfilemaythemselvesbestoredinsomesortedorder,just
asbooksinalibraryarestoredaccordingtosomeattributesuchastheDeweydecimal
number.Afilemayhaveseveralindices,ondifferentsearchkeys.Ifthefilecontaining
the records is sequentially ordered, a clustering index is an index whose search key
alsodefinesthesequentialorderofthefile.Clusteringindicesarealsocalledprimary
indices; the term primary index may appear to denote an index on a primary key, but
suchindicescaninfactbebuiltonanysearchkey.Thesearchkeyofaclusteringindex
isoftentheprimarykey,althoughthatisnotnecessarilyso.Indiceswhosesearchkey
specifiesanorderdifferentfromthesequentialorderofthefilearecallednonclustering
indices,orsecondaryindices.Theterms“clustered”and“nonclustered”areoftenused
inplaceof“clustering”and“nonclustering.”
In Section 14.2.1 through Section 14.2.3, we assume that all files are ordered se-
quentially on some search key. Such files, with a clustering index on the search key,
are called index-sequential files. They represent one of the oldest index schemes used
in database systems. They are designed for applications that require both sequential
processingoftheentirefileandrandomaccesstoindividualrecords.InSection14.2.4
wecoversecondaryindices.
Figure 14.1 shows a sequential file of instructor records taken from our university
example. In the example of Figure 14.1, the records are stored in sorted order of in-
structorID,whichisusedasthesearchkey.

--- Page 655 ---

626 Chapter14 Indexing
14.2.1 Dense and Sparse Indices
An index entry, or index record, consists of a search-key value and pointers to one or
morerecordswiththatvalueastheirsearch-keyvalue.Thepointertoarecordconsists
oftheidentifierofadiskblockandanoffsetwithinthediskblocktoidentifytherecord
withintheblock.
Therearetwotypesoforderedindicesthatwecanuse:
• Dense index: In a dense index, an index entry appears for every search-key value
in the file. In a dense clustering index, the index record contains the search-key
valueandapointertothefirstdatarecordwiththatsearch-keyvalue.Therestof
therecordswiththesamesearch-keyvalue wouldbestored sequentiallyafterthe
firstrecord,since,becausetheindexisaclusteringone,recordsaresortedonthe
samesearchkey.
In a dense nonclustering index, the index must store a list of pointers to all
recordswiththesamesearch-keyvalue.
• Sparseindex:Inasparseindex,anindexentryappearsforonlysomeofthesearch-
keyvalues.Sparseindicescanbeusedonlyiftherelationisstoredinsortedorder
of the search key; that is, if the index is a clustering index. As is true in dense
indices,eachindexentrycontainsasearch-keyvalueandapointertothefirstdata
recordwiththatsearch-keyvalue.Tolocatearecord,wefindtheindexentrywith
the largest search-key value that is less than or equal to the search-key value for
which we are looking. We start at the record pointed to by that index entry and
followthepointersinthefileuntilwefindthedesiredrecord.
Figure 14.2 and Figure 14.3 show dense and sparse indices, respectively, for the
instructorfile.SupposethatwearelookinguptherecordofinstructorwithID“22222”.
Using the dense index of Figure 14.2, we follow the pointer directly to the desired
record. Since ID is a primary key, there exists only one such record and the search is
complete.Ifweareusingthesparseindex(Figure14.3),wedonotfindanindexentry
for “22222”. Since the last entry (in numerical order) before “22222” is “10101”, we
followthatpointer.Wethenreadtheinstructorfileinsequentialorderuntilwefindthe
desiredrecord.
Considera(printed)dictionary.Theheaderofeachpageliststhefirstwordalpha-
betically on that page. The words at the top of each page of the book index together
formasparseindexonthecontentsofthedictionarypages.
Asanotherexample,supposethatthesearch-keyvalueisnotaprimarykey.Figure
14.4 shows a dense clustering index for the instructor file with the search key being
dept name.Observethatinthiscasetheinstructor fileissortedonthesearchkeydept
name,insteadofID,otherwisetheindexondept namewouldbeanonclusteringindex.
Suppose that we are looking up records for the History department. Using the dense
index of Figure 14.4, we follow the pointer directly to the first History record. We
process this record and follow the pointer in that record to locate the next record in

--- Page 656 ---

14.2 OrderedIndices 627
10101 10101 Srinivasan Comp. Sci. 65000
12121 12121 Wu Finance 90000
15151 15151 Mozart Music 40000
22222 22222 Einstein Physics 95000
32343 32343 El Said History 60000
33456 33456 Gold Physics 87000
45565 45565 Katz Comp. Sci. 75000
58583 58583 Califieri History 62000
76543 76543 Singh Finance 80000
76766 76766 Crick Biology 72000
83821 83821 Brandt Comp. Sci. 92000
98345 98345 Kim Elec. Eng. 80000
Figure 14.2 Denseindex.
search-key (dept name) order. We continue processing records until we encounter a
recordforadepartmentotherthanHistory.
As we have seen, it is generally faster to locate a record if we have a dense index
ratherthanasparseindex.However,sparseindiceshaveadvantagesoverdenseindices
inthattheyrequirelessspaceandtheyimposelessmaintenanceoverheadforinsertions
anddeletions.
There is a trade-off that the system designer must make between access time and
spaceoverhead.Althoughthedecisionregardingthistrade-offdependsonthespecific
application, a good compromise is to have a sparse index with one index entry per
10101 10101 Srinivasan Comp. Sci. 65000
32343 12121 Wu Finance 90000
76766
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 El Said History 60000
33456 Gold Physics 87000
45565 Katz Comp. Sci. 75000
58583 Califieri History 62000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp. Sci. 92000
98345 Kim Elec. Eng. 80000
Figure 14.3 Sparseindex.

--- Page 657 ---

628 Chapter14 Indexing
Biology 76766 Crick Biology 72000
Comp. Sci. 10101 Srinivasan Comp. Sci. 65000
Elec. Eng. 45565 Katz Comp. Sci. 75000
Finance 83821 Brandt Comp. Sci. 92000
History 98345 Kim Elec. Eng. 80000
Music 12121 Wu Finance 90000
Physics 76543 Singh Finance 80000
32343 El Said History 60000
58583 Califieri History 62000
15151 Mozart Music 40000
22222 Einstein Physics 95000
33465 Gold Physics 87000
Figure 14.4 Denseindexwithsearchkeydeptname.
block.Thereasonthisdesignisagoodtrade-offisthatthedominantcostinprocessinga
databaserequestisthetimethatittakestobringablockfromdiskintomainmemory.
Once we have brought in the block, the time to scan the entire block is negligible.
Usingthissparseindex,welocatetheblockcontainingtherecordthatweareseeking.
Thus,unlesstherecordisonanoverflowblock(seeSection13.3.2),weminimizeblock
accesseswhilekeepingthesizeoftheindex(andthusourspaceoverhead)assmallas
possible.
Fortheprecedingtechniquetobe fullygeneral, wemust considerthecasewhere
recordsforonesearch-keyvalueoccupyseveralblocks.Itiseasytomodifyourscheme
tohandlethissituation.
14.2.2 Multilevel Indices
Supposewebuildadenseindexonarelationwith1,000,000tuples.Indexentriesare
smaller than data records, so let us assume that 100 index entries fit on a 4-kilobyte
block.Thus,ourindexoccupies10,000blocks.Iftherelationinsteadhad100,000,000
tuples,theindexwouldinsteadoccupy1,000,000blocks,or4gigabytesofspace.Such
largeindicesarestoredassequentialfilesondisk.
If an index is small enough to be kept entirely in main memory, the search time
to find an entry is low. However, if the index is so large that not all of it can be kept
in memory, index blocks must be fetched from disk when required. (Even if an index
is smaller than the main memory of a computer, main memory is also required for a
numberofothertasks,soitmaynotbepossibletokeeptheentireindexinmemory.)
Thesearchforanentryintheindexthenrequiresseveraldisk-blockreads.
Binarysearchcanbe used on theindexfiletolocatean entry,but thesearchstill
hasalargecost.Iftheindexwouldoccupybblocks,binarysearchrequiresasmanyas
⌈log (b)⌉blockstoberead.(⌈x⌉denotestheleastintegerthatisgreaterthanorequal
2
to x; that is, we round upward.) Note that the blocks that are read are not adjacent

--- Page 658 ---

14.2 OrderedIndices 629
toeachother,soeachreadrequiresarandom(i.e.,non-sequential)I/Ooperation.For
a 10,000-block index, binary search requires 14 random block reads. On a magnetic
disk system where a random block read takes on average 10 milliseconds, the index
search will take 140 milliseconds. This may not seem much, but we would be able to
carryoutonlysevenindexsearchesasecondonasingledisk,whereasamoreefficient
searchmechanismwouldletuscarryoutfarmoresearchespersecond,asweshallsee
shortly.Notethat,ifoverflowblockshavebeenused,binarysearchisonlypossibleon
thenon-overflow blocks,and theactualcostmaybe evenhigherthanthe logarithmic
bound above. A sequential search requires b sequential block reads, which may take
evenlonger(althoughinsomecasesthelowercostofsequentialblockreadsmayresult
insequentialsearchbeingfasterthanabinarysearch).Thus,theprocessofsearching
alargeindexmaybecostly.
To deal with this problem, we treat the index just as we would treat any other
sequential file,andwe constructasparse outer indexon theoriginalindex,whichwe
nowcalltheinnerindex,asshowninFigure14.5.Notethattheindexentriesarealways
in sorted order, allowing the outer index to be sparse. To locate a record, we first use
binarysearchontheouterindextofindtherecordforthelargestsearch-keyvalueless
…
…
…
…
index data
block 0 block 0
index data
block 1 block 1
outer index
inner index
Figure 14.5 Two-levelsparseindex.

--- Page 659 ---

630 Chapter14 Indexing
thanorequaltotheonethatwedesire.Thepointerpointstoablockoftheinnerindex.
We scan this block until we find the record that has the largest search-key value less
thanorequaltotheonethatwedesire.Thepointerinthisrecordpointstotheblock
ofthefilethatcontainstherecordforwhichwearelooking.
Inourexample,aninnerindexwith10,000blockswouldrequire10,000entriesin
theouterindex,whichwouldoccupyjust100blocks.Ifweassumethattheouterindex
is already in main memory, we would read only one index block for a search using a
multilevelindex,ratherthanthe14blockswereadwithbinarysearch.Asaresult,we
canperform14timesasmanyindexsearchespersecond.
Ifourfileisextremelylarge,eventheouterindexmaygrowtoolargetofitinmain
memory. With a 100,000,000-tuple relation, the inner index would occupy 1,000,000
blocks,andtheouterindexwouldoccupy10,000blocks,or40megabytes.Sincethere
aremanydemandsonmainmemory,itmaynotbepossibletoreservethatmuchmain
memoryjust forthisparticularouter index.In such a case,we can create yetanother
levelofindex.Indeed,wecanrepeatthisprocessasmanytimesasnecessary.Indices
withtwoormorelevelsarecalledmultilevelindices.Searchingforrecordswithamul-
tilevelindexrequiressignificantlyfewerI/Ooperationsthandoessearchingforrecords
bybinarysearch.2
Multilevel indices are closely related to tree structures, such as the binary trees
usedforin-memoryindexing.Weshallexaminetherelationshiplater,inSection14.3.
14.2.3 Index Update
Regardless of what form of index is used, every index must be updated whenever a
record is either inserted into or deleted from the file. Further, in case a record in the
fileisupdated,anyindexwhosesearch-keyattributeisaffectedbytheupdatemustalso
be updated; for example, if the department of an instructor is changed, an index on
the dept name attribute of instructor must be updated correspondingly. Such a record
update can be modeled as a deletion of the old record, followed by an insertion of
the new value of the record, which results in an index deletion followed by an index
insertion.Asaresultweonlyneedtoconsiderinsertionanddeletiononanindex,and
wedonotneedtoconsiderupdatesexplicitly.
Wefirstdescribealgorithmsforupdatingsingle-levelindices.
14.2.3.1 Insertion
First,thesystemperformsalookupusingthesearch-keyvaluethatappearsintherecord
tobeinserted.Theactionsthesystemtakesnextdependonwhethertheindexisdense
orsparse:
2Intheearlydaysofdisk-basedindices,eachleveloftheindexcorrespondedtoaunitofphysicalstorage.Thus,wemay
haveindicesatthetrack,cylinder,anddisklevels.Suchahierarchydoesnotmakesensetodaysincedisksubsystems
hidethephysicaldetailsofdiskstorage,andthenumberofdisksandplattersperdiskisverysmallcomparedtothe
numberofcylindersorbytespertrack.

--- Page 660 ---

14.2 OrderedIndices 631
• Denseindices:
1.If the search-key value does not appear in the index, the system inserts an
indexentrywiththesearch-keyvalueintheindexattheappropriateposition.
2.Otherwisethefollowingactionsaretaken:
a. Iftheindexentrystorespointerstoallrecordswiththesamesearch-key
value,thesystemaddsapointertothenewrecordintheindexentry.
b. Otherwise,the indexentry storesapointer toonlythefirstrecord with
the search-key value. The system then places the record being inserted
aftertheotherrecordswiththesamesearch-keyvalues.
• Sparse indices: We assume that the index stores an entry for each block. If the
systemcreatesanewblock,itinsertsthefirstsearch-keyvalue(insearch-keyorder)
appearinginthenewblockintotheindex.Ontheotherhand,ifthenewrecordhas
theleastsearch-keyvalueinitsblock,thesystemupdatestheindexentrypointing
totheblock;ifnot,thesystemmakesnochangetotheindex.
14.2.3.2 Deletion
Todeletea record,the system firstlooks upthe record tobe deleted.The actionsthe
systemtakesnextdependonwhethertheindexisdenseorsparse:
• Denseindices:
1.Ifthedeletedrecordwastheonlyrecordwithitsparticularsearch-keyvalue,
thenthesystemdeletesthecorrespondingindexentryfromtheindex.
2.Otherwisethefollowingactionsaretaken:
a. Iftheindexentrystorespointerstoallrecordswiththesamesearch-key
value,thesystemdeletesthepointertothedeletedrecordfromtheindex
entry.
b. Otherwise,the indexentry storesapointer toonlythefirstrecord with
thesearch-keyvalue.Inthiscase,ifthedeletedrecordwasthefirstrecord
withthesearch-keyvalue,thesystemupdatestheindexentrytopointto
thenextrecord.
• Sparseindices:
1.Iftheindexdoesnotcontainanindexentrywiththesearch-keyvalueofthe
deletedrecord,nothingneedstobedonetotheindex.
2.Otherwisethesystemtakesthefollowingactions:
a. Ifthedeletedrecordwastheonlyrecordwithitssearchkey,thesystem
replaces the corresponding index record with an index record for the
next search-key value (in search-key order). If the next search-key value
alreadyhasanindexentry,theentryisdeletedinsteadofbeingreplaced.

--- Page 661 ---

632 Chapter14 Indexing
b. Otherwise,iftheindexentryforthesearch-keyvaluepointstotherecord
being deleted, the system updates the index entry to point to the next
recordwiththesamesearch-keyvalue.
Insertion and deletion algorithms for multilevel indicesare a simple extension of
the scheme just described. On deletion or insertion, the system updates the lowest-
levelindexasdescribed.Asfarasthesecondlevelisconcerned,thelowest-levelindex
ismerelyafilecontainingrecords—thus,ifthereisanychangeinthelowest-levelindex,
thesystemupdatesthesecond-levelindexasdescribed.Thesametechniqueappliesto
furtherlevelsoftheindex,ifthereareany.
14.2.4 Secondary Indices
Secondaryindicesmustbedense,withanindexentryforeverysearch-keyvalue,anda
pointertoeveryrecordinthefile.Aclusteringindexmaybesparse,storingonlysome
of the search-key values, since it is always possible to find records with intermediate
search-key values by a sequential access to a part of the file, as described earlier. If a
secondary index stores only some of the search-key values, records with intermediate
search-key values may be anywhere in the file and, in general, we cannot find them
withoutsearchingtheentirefile.
A secondary index on a candidate key looks just like a dense clustering index,
except that the records pointed to by successive values in the index are not stored
sequentially.Ingeneral,however,secondaryindicesmayhaveadifferentstructurefrom
clusteringindices.Ifthesearchkeyofaclusteringindexisnotacandidatekey,itsuffices
if the index points to the first record with a particular value for the search key, since
theotherrecordscanbefetchedbyasequentialscanofthefile.
In contrast, if the search key of a secondary index is not a candidate key, it is
notenoughtopointtojustthefirstrecordwitheachsearch-keyvalue.Theremaining
recordswiththesamesearch-keyvaluecouldbeanywhereinthefile,sincetherecords
are ordered by the search key of the clustering index, rather than by the search key
ofthesecondaryindex.Therefore,asecondaryindexmustcontainpointerstoallthe
records.
Ifarelationcanhavemorethanonerecordcontainingthesamesearchkeyvalue
(thatis,twoormorerecordscanhavethesamevaluesfortheindexedattributes),the
searchkeyissaidtobeanonuniquesearchkey.
Onewaytoimplementsecondaryindicesonnonuniquesearchkeys isasfollows:
Unlikethecaseofprimaryindices,thepointersinsuchasecondaryindexdonotpoint
directly to the records. Instead, each pointer in the index points to a bucket that in
turncontainspointerstothefile.Figure14.6showsthestructureofasecondaryindex
thatusessuchanextralevelofindirectionontheinstructorfile,onthesearchkeydept
name.
However,thisapproachhasafewdrawbacks.First,indexaccesstakeslonger,due
to an extra level of indirection, which may require a random I/O operation. Second,

--- Page 662 ---

14.2 OrderedIndices 633
10101 Srinivasan Comp. Sci. 65000
12121 Wu Finance 90000
Biology 15151 Mozart Music 40000
Comp. Sci. 22222 Einstein Physics 95000
32343 El Said History 60000
Elec. Eng.
33456 Gold Physics 87000
Finance
45565 Katz Comp. Sci. 75000
History
58583 Califieri History 62000
Music
76543 Singh Finance 80000
Physics
76766 Crick Biology 72000
83821 Brandt Comp. Sci. 92000
98345 Kim Elec. Eng. 80000
Figure 14.6 Secondaryindexoninstructor file,onnoncandidate keydeptname.
if a key has very few or no duplicates, if a whole block is allocated to its associated
bucket, a lot of space would be wasted. Later in this chapter, we study more efficient
alternativesforimplementingsecondaryindices,whichavoidthesedrawbacks.
A sequential scan in clustering index order is efficient because records in the file
arestoredphysicallyinthesameorderastheindexorder.However,wecannot(except
inrarespecialcases)storeafilephysicallyorderedbyboththesearchkeyoftheclus-
teringindexandthesearchkeyofasecondaryindex.Becausesecondary-keyorderand
physical-key order differ, if we attempt to scan the file sequentially in secondary-key
order, the reading of each record is likely to require the reading of a new block from
disk,whichisveryslow.
The procedure described earlierfor deletion and insertion can also be applied to
secondary indices; the actions taken are those described for dense indices storing a
pointer to every record in the file. If a file has multiple indices, whenever the file is
modified,everyindexmustbeupdated.
Secondary indices improve the performance of queries that use keys other than
the search key of the clustering index. However, they impose a significant overhead
onmodificationofthedatabase.Thedesignerofadatabasedecideswhichsecondary
indicesaredesirableonthebasisofanestimateoftherelativefrequencyofqueriesand
modifications.
14.2.5 Indices on Multiple Keys
Althoughtheexampleswehaveseensofarhavehadasingleattributeinasearchkey,
ingeneralasearchkeycanhavemorethanoneattribute.Asearchkeycontainingmore
thanoneattributeisreferredtoasacompositesearchkey.Thestructureoftheindexis
thesameasthatofanyotherindex,theonlydifferencebeingthatthesearchkeyisnot
asingleattribute,butratherisalistofattributes.Thesearchkeycanberepresentedas
atupleofvalues, oftheform(a ,…,a ),wheretheindexedattributesareA ,…,A .
1 n 1 n

--- Page 663 ---

634 Chapter14 Indexing
The ordering of search-key values is the lexicographic ordering. For example, for the
case of two attribute search keys, (a ,a ) < (b ,b ) if either a < b or a = b and
1 2 1 2 1 1 1 1
a < b .Lexicographicorderingisbasicallythesameasalphabeticorderingofwords.
2 2
As an example, consider an index on the takes relation, on the composite search
key(course id,semester,year).Suchanindexwouldbeusefultofindallstudentswho
haveregisteredforaparticularcourseinaparticularsemester/year.Anorderedindex
onacompositekeycanalsobeusedtoanswerseveralotherkindsofqueriesefficiently,
asweshallseeinSection14.6.2.
+
14.3 B -Tree Index Files
The main disadvantage of the index-sequential file organization is that performance
degradesasthefilegrows,bothforindexlookupsandforsequentialscansthroughthe
data.Althoughthisdegradationcanberemediedbyreorganizationofthefile,frequent
reorganizationsareundesirable.
TheB+-treeindexstructureisthemostwidelyusedofseveralindexstructuresthat
maintaintheirefficiencydespite insertion and deletionof data. AB+-treeindextakes
the form of a balanced tree in which every path from the root of the tree to a leaf of
the tree is of the same length. Each nonleaf node in the tree (other than the root)
has between ⌈n∕2⌉ and n children,where n is fixed for a particular tree; the root has
between2andnchildren.
WeshallseethattheB+-treestructureimposesperformanceoverheadoninsertion
anddeletionandaddsspaceoverhead.Theoverheadisacceptableevenforfrequently
modifiedfiles,sincethecostoffilereorganizationisavoided.Furthermore,sincenodes
may be as much as half empty (if they have the minimumnumber of children),there
is some wasted space. This space overhead, too, is acceptable given the performance
benefitsoftheB+-treestructure.
+
14.3.1 Structure of a B -Tree
AB+-treeindexisamultilevelindex,butithasastructurethatdiffersfromthatofthe
multilevelindex-sequentialfile.Weassume fornowthattherearenoduplicatesearch
key values, that is, each search key is unique and occurs in at most one record; we
considertheissueofnonuniquesearchkeyslater.
Figure14.7showsatypicalnodeofaB+-tree.Itcontainsupton − 1search-key
valuesK , K ,…,K ,andnpointersP , P ,…,P .Thesearch-keyvalueswithina
1 2 n−1 1 2 n
nodearekeptinsortedorder;thus,ifi < j,thenK < K.
i j
P K P … P K P
1 1 2 n 1 n 1 n
Figure 14.7 Typical nodeofaB+-tree.

--- Page 664 ---

14.3 B+-TreeIndexFiles 635
leaf node
Brandt Califieri Crick Pointer to next leaf node
10101 Srinivasan Comp. Sci. 65000
12121 Wu Finance 90000
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 El Said History 80000
33456 Gold Physics 87000
45565 Katz Comp. Sci. 75000
58583 Califieri History 60000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp. Sci. 92000
98345 Kim Elec. Eng. 80000
instructor file
Figure 14.8 Aleafnodeforinstructor B+-treeindex(n = 4).
Weconsiderfirstthestructureoftheleafnodes.Fori = 1,2,…,n−1,pointerP
i
points to a file record with search-key value K. Pointer P has a special purpose that
i n
weshalldiscussshortly.
Figure14.8showsoneleafnodeofaB+-treefortheinstructorfile,inwhichwehave
chosenntobe4,andthesearchkeyisname.
Nowthatwehaveseenthestructureofaleafnode,letusconsiderhowsearch-key
values are assigned to particular nodes. Each leaf can hold up to n − 1 values. We
allow leaf nodes to contain as few as ⌈(n−1)∕2⌉ values. With n = 4 in our example
B+-tree,eachleafmustcontainatleasttwovalues,andatmostthreevalues.
IfL andL areleafnodesandi < j(thatis,L istotheleftofL inthetree),then
i j i j
everysearch-keyvaluev inL islessthaneverysearch-keyvaluev inL.
i i j j
IftheB+-treeindexisusedasadenseindex(asisusuallythecase),everysearch-key
valuemustappearinsomeleafnode.
NowwecanexplaintheuseofthepointerP .Sincethereisalinearorderonthe
n
leavesbasedonthesearch-keyvaluesthattheycontain,weuseP tochaintogetherthe
n
leafnodesinsearch-keyorder.Thisorderingallowsforefficientsequentialprocessing
ofthefile.
ThenonleafnodesoftheB+-treeformamultilevel(sparse)indexontheleafnodes.
Thestructureofnonleafnodesisthesameasthatforleafnodes,exceptthatallpointers
are pointers to tree nodes. A nonleaf node may hold up to n pointers and must hold
at least ⌈n∕2⌉ pointers. The number of pointers in a node is called the fanout of the
node.Nonleafnodesarealsoreferredtoasinternalnodes.

--- Page 665 ---

636 Chapter14 Indexing
Mozart Root node
Einstein Gold Srinivasan Internal nodes
Leaf nodes
Brandt Califieri Crick Einstein El Said Gold Katz Kim Mozart Singh Srinivasan Wu
10101 Srinivasan Comp. Sci. 65000
12121 Wu Finance 90000
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 El Said History 80000
33456 Gold Physics 87000
45565 Katz Comp. Sci. 75000
58583 Califieri History 60000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp. Sci. 92000
98345 Kim Elec. Eng. 80000
Figure 14.9 B+-treeforinstructor file(n = 4).
Let us consider a node containing m pointers (m ≤ n). For i = 2,3,…,m −1,
pointerP pointstothesubtreethatcontainssearch-keyvalueslessthanK andgreater
i i
thanorequaltoK .PointerP pointstothepartofthesubtreethatcontainsthose
i−1 m
keyvaluesgreaterthanorequaltoK ,andpointerP pointstothepartofthesubtree
m−1 1
thatcontainsthosesearch-keyvalueslessthanK .
1
Unlike other nonleaf nodes, the root node can hold fewer than ⌈n∕2⌉ pointers;
however,itmustholdatleasttwopointers,unlessthetreeconsistsofonlyonenode.It
isalwayspossibletoconstructaB+-tree,foranyn,thatsatisfiestheprecedingrequire-
ments.
Figure14.9showsacompleteB+-treefortheinstructorfile(withn = 4).Wehave
omitted null pointers for simplicity; any pointer field in the figure that does not have
anarrowisunderstoodtohaveanullvalue.
Figure 14.10 shows another B+-tree for the instructor file, this time with n = 6.
Observe that the height of this tree is less than that of the previous tree, which had
n = 4.
El Said Mozart
Brandt Califieri Crick Einstein El Said Gold Katz Kim Mozart Singh Srinivasan Wu
Figure 14.10 B+-treeforinstructor filewithn = 6.

--- Page 666 ---

14.3 B+-TreeIndexFiles 637
TheseexamplesofB+-treesareallbalanced.Thatis,thelengthofeverypathfrom
theroottoaleafnodeisthesame.ThispropertyisarequirementforaB+-tree.Indeed,
the “B” in B+-tree stands for “balanced.” It is the balance property of B+-trees that
ensuresgoodperformanceforlookup,insertion,anddeletion.
In general, search keys could have duplicates. One way to handle the case of
nonuniquesearchkeysistomodifythetreestructuretostoreeachsearchkeyataleaf
node as many times as it appears in records, with each copy pointing to one record.
TheconditionthatK < K ifi < j willneedtobemodifiedtoK ≤ K.However,this
i j i j
approachcanresultinduplicatesearchkeyvaluesatinternalnodes,makingtheinser-
tionand deletionproceduresmorecomplicatedand expensive. Anotheralternative is
tostoreaset(orbucket)ofrecordpointerswitheachsearchkeyvalue,aswesawear-
lier.Thisapproachismorecomplicatedandcanresultininefficientaccess,especially
ifthenumberofrecordpointersforaparticularkeyisverylarge.
Mostdatabaseimplementationsinsteadmakesearchkeysuniqueasfollows:Sup-
posethedesiredsearchkeyattributea ofrelationrisnonunique.LetA betheprimary
i p
keyofr.Thentheuniquecompositesearchkey(a,A )isusedinsteadofa whenbuild-
i p i
ingtheindex.(Anysetofattributesthattogetherwitha guaranteeuniquenesscanalso
i
be used instead of A .) For example, if we wished to create an index on the instructor
p
relationontheattributename,weinsteadcreateanindexonthecompositesearchkey
(name,ID),sinceIDistheprimarykeyforinstructor.Indexlookupsonjustnamecan
be efficiently handled using this index, as we shall see shortly. Section 14.3.5 covers
issuesinhandlingofnonuniquesearchkeysinmoredetail.
Inourexamples,weshowindicesonsomenonuniquesearchkeys,suchasinstruc-
tor.name,assumingforsimplicitythattherearenoduplicates;inrealitymostdatabases
wouldautomaticallyaddextraattributesinternally,toensuretheabsenceofduplicates.
+
14.3.2 Queries on B -Trees
Let us consider how we process queries on a B+-tree. Suppose that we wish to find a
recordwithagiven value vfor thesearch key. Figure14.11 presentspseudocode fora
function find(v)tocarryoutthistask, assumingtherearenoduplicates,thatis,there
isatmostonerecordwithaparticularsearchkey.Weaddresstheissueofnonunique
searchkeyslaterinthissection.
Intuitively, the function starts at the root of the tree and traverses the tree down
until it reaches a leaf node that would contain the specified value if it exists in the
tree. Specifically, starting with the root as the current node, the function repeats the
followingstepsuntilaleafnodeisreached.First,thecurrentnodeisexamined,looking
for the smallest i such that search-key value K is greater than or equal to v. Suppose
i
suchavalueisfound;then,ifK isequaltov,thecurrentnodeissettothenodepointed
i
tobyP ,otherwiseK > v,andthecurrentnodeissettothenodepointedtobyP.If
i+1 i i
nosuchvalueK isfound,thenv > K ,whereP isthelastnonnullpointerinthe
i m−1 m
node.InthiscasethecurrentnodeissettothatpointedtobyP .Theaboveprocedure
m
isrepeated,traversingdownthetreeuntilaleafnodeisreached.

--- Page 667 ---

638 Chapter14 Indexing
functionfind(v)
/*Assumesnoduplicatekeys,andreturnspointertotherecordwith
*searchkeyvaluevifsucharecordexists,andnullotherwise*/
SetC =rootnode
while(C isnotaleafnode)begin
Leti=smallestnumbersuchthatv ≤ C.K
i
ifthereisnosuchnumberithenbegin
LetP =lastnon-nullpointerinthenode
m
SetC =C.P
m
end
elseif(v = C.K)thenSetC =C.P
i i+1
elseSetC =C.P /*v < C.K */
i i
end
/*C isaleafnode*/
ifforsomei,K = v
i
thenreturnP
i
elsereturnnull;/*Norecordwithkeyvaluevexists*/
Figure 14.11 QueryingaB+-tree.
At the leaf node, if there is a search-key value K = v, pointer P directs us to a
i i
record with search-key value K. The function then returns the pointer to the record,
i
P. If no search key with value v is found in the leaf node, no record with key value v
i
existsintherelation,andfunctionfind returnsnull,toindicatefailure.
B+-trees can also be used to find all records with search key values in a specified
range[lb,ub].Forexample,withaB+-treeonattributesalaryofinstructor,wecanfind
allinstructorrecordswithsalaryinaspecifiedrangesuchas[50000,100000](inother
words,allsalariesbetween50000and100000).Suchqueriesarecalledrangequeries.
To execute such queries, we can create a procedure findRange(lb,ub), shown in
Figure14.12. Theproceduredoesthefollowing:itfirsttraversestoaleafinamanner
similar to find(lb); the leaf may or may not actually contain value lb. It then steps
through records in that and subsequent leaf nodes collecting pointers to all records
withkeyvaluesC.K s.t.lb ≤ C.K ≤ ubintoasetresultSet.Thefunctionstops when
i i
C.K > ub,ortherearenomorekeysinthetree.
i
ArealimplementationwouldprovideaversionoffindRangesupportinganiterator
interfacesimilartothatprovidedbytheJDBCResultSet,whichwesawinSection5.1.1.
Suchaniteratorinterfacewouldprovideamethodnext(),whichcanbecalledrepeat-
edlytofetchsuccessiverecords.Thenext()methodwouldstep throughtheentriesat
the leaf level, in a mannersimilar to findRange, but each call takes only one step and
records where it left off, so that successive calls to next() step through successive en-

--- Page 668 ---

14.3 B+-TreeIndexFiles 639
functionfindRange(lb,ub)
/*ReturnsallrecordswithsearchkeyvalueV suchthatlb ≤V ≤ ub.*/
SetresultSet={};
SetC =rootnode
while(C isnotaleafnode)begin
Leti=smallestnumbersuchthatlb ≤ C.K
i
ifthereisnosuchnumberithenbegin
LetP =lastnon-nullpointerinthenode
m
SetC =C.P
m
end
elseif(lb = C.K)thenSetC =C.P
i i+1
elseSetC =C.P /*lb <C.K */
i i
end
/*C isaleafnode*/
LetibetheleastvaluesuchthatK ≥ lb
i
ifthereisnosuchi
thenSeti=1+numberofkeysinC;/*Toforcemovetonextleaf*/
Setdone=false;
while(notdone)begin
Letn=numberofkeysinC.
if(i ≤ nandC.K ≤ ub)thenbegin
i
AddC.P toresultSet
i
Seti = i+1
end
elseif (i ≤ nandC.K > ub)
i
thenSetdone=true;
elseif(i > nandC.P isnotnull)
n+1
thenSetC = C.P ,andi =1/*Movetonextleaf*/
n+1
elseSetdone=true;/*Nomoreleavestotheright*/
end
returnresultSet;
Figure 14.12 RangequeryonaB+-tree.
tries.Weomitdetailsforsimplicity,andleavethepseudocodefortheiteratorinterface
asanexercisefortheinterestedreader.
We now consider the cost of querying on a B+-tree index. In processing a query,
wetraverseapathinthetreefromtheroottosomeleafnode.IfthereareN recordsin
thefile,thepathisnolongerthan⌈log (N)⌉.
⌈n∕2⌉
Typically,thenodesizeischosentobethesameasthesizeofadiskblock,which
is typically 4 kilobytes. With a search-key size of 12 bytes, and a disk-pointer size of

--- Page 669 ---

640 Chapter14 Indexing
8 bytes, n is around 200. Even with a more conservative estimate of 32 bytes for the
search-keysize,nisaround100.Withn = 100,ifwehave1millionsearch-keyvaluesin
thefile,alookuprequiresonly⌈log (1,000,000)⌉ = 4nodestobeaccessed.Thus,at
50
mostfourblocksneedtobereadfromdisktotraversethepathfromtheroottoaleaf.
Therootnodeofthetreeisusuallyheavilyaccessedandislikelytobeinthebuffer,so
typicallyonlythreeorfewerblocksneedtobereadfromdisk.
AnimportantdifferencebetweenB+-treestructuresandin-memorytreestructures,
such as binary trees, is the size of a node, and as a result, the height of the tree. In a
binary tree, each node is small and has at most two pointers. In a B+-tree, each node
islarge—typicallyadiskblock—andanodecanhavealargenumberofpointers.Thus,
B+-treestendtobefatandshort,unlikethinandtallbinarytrees.Inabalancedbinary
tree, the path for a lookup can be of length ⌈log (N)⌉, where N is the number of
2
records in the file being indexed. With N = 1,000,000 as in the previous example, a
balancedbinarytreerequiresaround20nodeaccesses.Ifeachnodewereonadifferent
disk block, 20 block reads would be required to process a lookup, in contrast to the
fourblockreadsfortheB+-tree.Thedifferenceissignificantwithamagneticdisk,since
eachblockreadcouldrequireadiskarmseekwhich,togetherwiththeblockread,takes
about 10 milliseconds on a magnetic disk. The difference is not quite as drastic with
flashstorage,whereareadofa4kilobytepagetakesaround10to100microseconds,
butitisstillsignificant.
Aftertraversingdowntotheleaflevel,queriesonasinglevalueofauniquesearch
keyrequireonemorerandomI/Ooperationtofetchanymatchingrecord.
Range queries have an additional cost, after traversing down to the leaf level: all
thepointersinthegivenrangemustberetrieved.Thesepointersareinconsecutiveleaf
nodes;thus,ifM suchpointersareretrieved,atmost⌈M∕(n∕2)⌉+1leafnodesneed
tobeaccessedtoretrievethepointers(sinceeachleafnodehasatleastn∕2pointers,
buteventwopointersmaybesplitacrosstwopages).Tothiscost,weneedtoaddthe
cost of accessing the actual records. For secondary indices, each such record may be
onadifferentblock,whichcouldresultinM randomI/Ooperationsintheworstcase.
For clustered indices, these records would be in consecutive blocks, with each block
containingmultiplerecords,resultinginasignificantlylowercost.
Now, let us consider the case of nonunique keys. As explained earlier, if we wish
to create an index on an attribute a that is not a candidate key, and may thus have
i
duplicates, we instead create an index on a composite key that is duplicate-free. The
composite key is created by adding extra attributes, such as the primary key, to a, to
i
ensureuniqueness.Supposewecreatedanindexonthecompositekey(a,A )instead
i p
ofcreatinganindexona.
i
An important question, then, is how do we retrieve all tuples with a given value
v for a using the above index? This question is easily answered by using the function
i
findRange(lb,ub), with lb = (v,−∞) and ub = (v,∞), where −∞ and ∞ denote the
smallest and largest possible values of A . All records with a = v would be returned
p i
bytheabovefunctioncall.Range queriesona canbehandledsimilarly.Theserange
i

--- Page 670 ---

14.3 B+-TreeIndexFiles 641
queriesretrievepointerstotherecordsquiteefficiently,althoughretrievaloftherecords
maybeexpensive,asdiscussedearlier.
+
14.3.3 Updates on B -Trees
Whenarecordisinsertedinto,ordeletedfromarelation,indicesontherelationmust
beupdatedcorrespondingly.Recallthatupdatestoarecordcanbemodeledasadele-
tion of the old record followed by insertion of the updated record. Hence we only
considerthecaseofinsertionanddeletion.
Insertion and deletion are more complicated than lookup, since it may be neces-
sarytosplitanodethatbecomestoolargeastheresultofaninsertion,ortocoalesce
nodes(i.e.,combinenodes)ifanodebecomestoosmall(fewerthan⌈n∕2⌉pointers).
Furthermore,whenanodeissplitorapairofnodesiscombined,wemustensurethat
balanceispreserved.TointroducetheideabehindinsertionanddeletioninaB+-tree,
we shall assume temporarily that nodes never become too large or too small. Under
thisassumption,insertionanddeletionareperformedasdefinednext.
• Insertion.Usingthesametechniqueasforlookupfromthefind()function(Figure
14.11),wefirstfindtheleafnodeinwhichthesearch-keyvaluewouldappear.We
then insert an entry (i.e., a search-key value and record pointer pair) in the leaf
node,positioningitsuchthatthesearchkeysarestillinorder.
• Deletion.Usingthesametechniqueasforlookup,wefindtheleafnodecontaining
the entry to be deleted by performing a lookup on the search-key value of the
deleted record; if there are multiple entries with the same search-key value, we
searchacrossallentrieswiththesamesearch-keyvalueuntilwefindtheentrythat
pointstotherecordbeingdeleted.Wethenremovetheentryfromtheleafnode.
Allentriesintheleafnodethataretotherightofthedeletedentryareshiftedleft
byoneposition,sothattherearenogapsintheentriesaftertheentryisdeleted.
We now consider the general case of insertion and deletion, dealing with node
splittingandnodecoalescing.
14.3.3.1 Insertion
Wenowconsideranexampleofinsertioninwhichanodemustbesplit.Assumethat
a record is inserted on the instructor relation, with the name value being Adams. We
then need to insert an entry for “Adams” into the B+-tree of Figure 14.9. Using the
algorithmforlookup,wefindthat“Adams”shouldappearintheleafnodecontaining
“Brandt”, “Califieri”, and “Crick.” There is no room in this leaf to insert the search-
keyvalue“Adams.”Therefore,thenodeissplitintotwonodes.Figure14.13showsthe
two leaf nodes that result from the split of the leaf node on inserting “Adams”. The
search-key values “Adams” and “Brandt” are in one leaf, and “Califieri” and “Crick”
areintheother.Ingeneral,wetakethensearch-keyvalues(then−1valuesintheleaf

--- Page 671 ---

642 Chapter14 Indexing
Adams Brandt Califieri Crick
Figure 14.13 Splitofleafnodeoninsertionof“Adams”.
node plus the value being inserted), and put the first ⌈n∕2⌉ in the existing node and
theremainingvaluesinanewlycreatednode.
Havingsplitaleafnode,wemustinsertthenewleafnodeintotheB+-treestructure.
Inourexample,thenewnodehas“Califieri”asitssmallestsearch-keyvalue.Weneed
to insert an entry with this search-key value, and a pointer to the new node, into the
parentoftheleafnodethatwassplit.TheB+-treeofFigure14.14showstheresultofthe
insertion.Itwaspossibletoperformthisinsertionwithnofurthernodesplit,because
therewasroomintheparentnodeforthenewentry.Iftherewerenoroom,theparent
would have had to be split, requiring an entry to be added to its parent. In the worst
case, all nodes along the path to the root must be split. If the root itself is split, the
entiretreebecomesdeeper.
Splittingofanonleafnodeisalittledifferentfromsplittingofaleafnode.Figure
14.15 shows the result of inserting a record with search key “Lamport” into the tree
showninFigure14.14.Theleafnodeinwhich“Lamport”istobeinsertedalreadyhas
entries “Gold”, “Katz”, and “Kim”, and as a result the leaf node has to be split. The
newright-hand-sidenoderesultingfromthesplitcontainsthesearch-keyvalues“Kim”
and“Lamport”.Anentry(Kim,n1)mustthenbeaddedtotheparentnode,wheren1
isapointertothenewnode,However,thereisnospaceintheparentnodetoaddanew
entry, and the parent node has to be split. To do so, the parent node is conceptually
expandedtemporarily,theentryadded,andtheoverfullnodeisthenimmediatelysplit.
When an overfull nonleaf node is split, the child pointers are divided among the
original and the newly created nodes; in our example, the original node is left with
thefirstthreepointers,andthenewlycreatednodetotherightgetstheremainingtwo
pointers.Thesearchkeyvaluesare,however,handledalittledifferently.Thesearchkey
valuesthatliebetweenthepointersmovedtotherightnode(inourexample,thevalue
“Kim”) are moved along with the pointers, while those that lie between the pointers
thatstayontheleft(inourexample,“Califieri”and“Einstein”)remainundisturbed.
Mozart
Califieri Einstein Gold Srinivasan
Adams Brandt Califieri Crick Einstein El Said Gold Katz Kim Mozart Singh Srinivasan Wu
Figure 14.14 Insertionof“Adams”intotheB+-treeofFigure14.9.

--- Page 672 ---

14.3 B+-TreeIndexFiles 643
Gold Mozart
Califieri Einstein Kim Srinivasan
Adams Brandt Califieri Crick Einstein El Said Gold Katz Kim Lamport Mozart Singh Srinivasan Wu
Figure 14.15 Insertionof“Lamport” intotheB+-treeofFigure14.14.
However, the search key value thatliesbetween the pointersthat stay on the left,
andthepointersthatmovetotherightnodeistreateddifferently.Inourexample,the
searchkeyvalue“Gold”liesbetweenthethreepointersthatwenttotheleftnode,and
thetwopointersthatwenttotherightnode.Thevalue“Gold”isnotaddedtoeitherof
thesplitnodes.Instead,anentry(Gold,n2)isaddedtotheparentnode,wheren2isa
pointertothenewlycreatednodethatresultedfromthesplit.Inthiscase,theparent
nodeistheroot,andithasenoughspaceforthenewentry.
The general technique for insertion into a B+-tree is to determine the leaf node l
intowhichinsertionmustoccur.Ifasplitresults,insertthenewnodeintotheparent
procedureinsert(valueK,pointerP)
if(treeisempty)createanemptyleafnodeL,whichisalsotheroot
elseFindtheleafnodeLthatshouldcontainkeyvalueK
if(Lhaslessthann−1keyvalues)
theninsert in leaf(L,K,P)
elsebegin/*Lhasn−1keyvaluesalready,splitit*/
CreatenodeL′
CopyL.P …L.K toablockofmemoryT thatcan
1 n−1
holdn(pointer,key-value)pairs
insert in leaf(T,K,P)
SetL′.P = L.P ;SetL.P =L′
n n n
EraseL.P throughL.K fromL
1 n−1
CopyT.P throughT.K fromT intoLstartingatL.P
1 ⌈n∕2⌉ 1
CopyT.P throughT.K fromT intoL′ startingatL′.P
⌈n∕2⌉+1 n 1
LetK′ bethesmallestkey-valueinL′
insert in parent(L,K′,L′)
end
Figure 14.16 InsertionofentryinaB+-tree.

--- Page 673 ---

644 Chapter14 Indexing
ofnodel.Ifthisinsertioncausesasplit,proceedrecursivelyupthetreeuntileitheran
insertiondoesnotcauseasplitoranewrootiscreated.
Figure 14.16 outlines the insertion algorithm in pseudocode. The procedure in-
sert inserts a key-value pointer pair into the index, using two subsidiary procedures
insert in leaf and insert in parent, shown in Figure 14.17. In the pseudocode, L,N,P
andT denotepointerstonodes,withLbeingusedtodenotealeafnode.L.K andL.P
i i
denotetheithvalueandtheithpointerinnodeL,respectively;T.K andT.P areused
i i
similarly.Thepseudocodealsomakesuseofthefunctionparent(N)tofindtheparent
ofanodeN.Wecancomputealistofnodesinthepathfromtheroottotheleafwhile
initiallyfindingtheleafnode,andwecanuseitlatertofindtheparentofanynodein
thepathefficiently.
procedureinsert in leaf (nodeL,valueK,pointerP)
if(K < L.K )
1
theninsertP,K intoLjustbeforeL.P
1
elsebegin
LetK bethehighestvalueinLthatislessthanorequaltoK
i
InsertP,K intoLjustafterL.K
i
end
procedureinsert in parent(nodeN,valueK′,nodeN′)
if(N istherootofthetree)
thenbegin
CreateanewnodeRcontainingN,K′,N′ /*N andN′ arepointers*/
MakeRtherootofthetree
return
end
LetP =parent(N)
if(P haslessthannpointers)
theninsert(K′,N′)inP justafterN
elsebegin/*SplitP */
CopyP toablockofmemoryT thatcanholdP and(K′,N′)
Insert(K′,N′)intoT justafterN
EraseallentriesfromP;CreatenodeP′
CopyT.P …T.P intoP
1 ⌈(n+1)∕2⌉
LetK′′ = T.K
⌈(n+1)∕2⌉
CopyT.P …T.P intoP′
⌈(n+1)∕2⌉+1 n+1
insert in parent(P,K′′,P′)
end
Figure 14.17 SubsidiaryproceduresforinsertionofentryinaB+-tree.

--- Page 674 ---

14.3 B+-TreeIndexFiles 645
The procedure insert in parent takes as parameters N,K′,N′, where node N was
split into N and N′, with K′ being the least value in N′. The procedure modifies the
parent of N to record the split. The procedures insert into index and insert in parent
use a temporary area of memory T to store the contents of a node being split. The
procedurescanbemodifiedtocopydatafromthenodebeingsplitdirectlytothenewly
created node, reducing the time required for copying data. However, the use of the
temporaryspaceT simplifiestheprocedures.
14.3.3.2 Deletion
Wenowconsiderdeletionsthatcausetreenodestocontaintoofewpointers.First,let
usdelete“Srinivasan”from theB+-treeofFigure14.14.TheresultingB+-treeappears
in Figure 14.18. We now consider how the deletion is performed. We first locate the
entry for “Srinivasan” by using our lookup algorithm. When we delete the entry for
“Srinivasan” from its leaf node, the node is left with only one entry, “Wu”. Since, in
our example, n = 4 and 1 < ⌈(n − 1)∕2⌉, we must either merge the node with a
sibling node or redistribute the entries between the nodes, to ensure that each node
isatleasthalf-full.Inourexample,theunderfullnodewiththeentryfor“Wu”canbe
mergedwithitsleftsiblingnode.Wemergethenodesbymovingtheentriesfromboth
thenodesintotheleftsiblinganddeletingthenow-emptyrightsibling.Oncethenode
is deleted, we must also delete the entry in the parent node that pointed to the just
deletednode.
In our example, the entry to be deleted is (Srinivasan, n3), where n3 is a pointer
totheleafcontaining“Srinivasan”.(Inthiscasetheentrytobedeletedinthenonleaf
nodehappenstobethesamevalueasthatdeletedfromtheleaf;thatwouldnotbethe
case for most deletions.) After deleting the above entry, the parent node, which had
a search key value “Srinivasan” and two pointers, now has one pointer (the leftmost
pointerinthenode)andnosearch-keyvalues.Since1 < ⌈n∕2⌉forn = 4,theparent
node isunderfull. (Forlargern, anode thatbecomes underfull would stillhave some
valuesaswellaspointers.)
Gold
Califieri Einstein Mozart
Adams Brandt Califieri Crick Einstein El Said Gold Katz Kim Mozart Singh Wu
Figure 14.18 Deletionof“Srinivasan”fromtheB+-treeofFigure14.14.

--- Page 675 ---

646 Chapter14 Indexing
Inthiscase,welookatasiblingnode;inourexample,theonlysiblingisthenonleaf
nodecontainingthesearchkeys“Califieri”,“Einstein”,and“Gold”.Ifpossible,wetry
tocoalescethenodewithitssibling.Inthiscase,coalescingisnotpossible,sincethe
nodeanditssiblingtogetherhavefivepointers,againstamaximumoffour.Thesolution
inthiscaseistoredistributethepointersbetweenthenodeanditssibling,suchthateach
has at least ⌈n∕2⌉ = 2 child pointers. To do so, we move the rightmost pointer from
theleftsibling(theone pointingtotheleafnodecontaining“Gold”)totheunderfull
rightsibling.However,theunderfullrightsiblingwouldnowhavetwopointers,namely,
its leftmost pointer, and the newly moved pointer, with no value separating them. In
fact, the value separating them is not present in either of the nodes, but is present
in the parent node, between the pointers from the parent to the node and its sibling.
In our example, the value “Mozart” separates the two pointers and is present in the
rightsiblingaftertheredistribution.Redistributionofthepointersalsomeansthatthe
value“Mozart”intheparentnolongercorrectlyseparatessearch-keyvaluesinthetwo
siblings. In fact, the value that now correctly separates search-key values in the two
siblingnodesisthevalue“Gold”,whichwasintheleftsiblingbeforeredistribution.
As a result, as can be seen in the B+-tree in Figure 14.18, after redistribution of
pointers between siblings, the value “Gold” has moved up into the parent, while the
valuethatwasthereearlier,“Mozart”,hasmoveddownintotherightsibling.
Wenextdeletethesearch-keyvalues“Singh”and“Wu”fromtheB+-treeofFigure
14.18.TheresultisshowninFigure14.19.Thedeletionofthefirstofthesevaluesdoes
not make the leaf node underfull, but the deletion of the second value does. It is not
possible to merge the underfull node with its sibling, so a redistribution of values is
carried out, moving the search-key value “Kim” into the node containing “Mozart”,
resulting in the tree shown in Figure 14.19. The value separating the two siblings has
beenupdatedintheparent,from“Mozart”to“Kim”.
Nowwedelete“Gold”fromtheabovetree;theresultisshowninFigure14.20.This
results in an underfull leaf, which can now be merged with its sibling. The resultant
deletionofanentryfromtheparentnode(thenonleafnodecontaining“Kim”)makes
the parent underfull (it is left with just one pointer). This time around, the parent
nodecanbemergedwithitssibling.Thismergeresultsinthesearch-keyvalue“Gold”
Gold
Califieri Einstein Kim
Adams Brandt Califieri Crick Einstein El Said Gold Katz Kim Mozart
Figure 14.19 Deletionof“Singh”and“Wu”fromtheB+-treeofFigure14.18.

--- Page 676 ---

14.3 B+-TreeIndexFiles 647
Califieri Einstein Gold
Adams Brandt Califieri Crick Einstein El Said Katz Kim Mozart
Figure 14.20 Deletionof“Gold”fromtheB+-treeofFigure14.19.
movingdownfromtheparentintothemergednode.Asaresultofthismerge,anentry
is deleted from its parent, which happens to be the root of the tree. And as a result
of that deletion, the root is left with only one child pointer and no search-key value,
violating the condition that the root must have at least two children. As a result, the
rootnode isdeletedand itssole childbecomesthe root,and thedepth ofthe B+-tree
hasbeendecreasedby1.
Itisworthnotingthat,asaresultofdeletion,akeyvaluethatispresentinanonleaf
node oftheB+-treemaynotbe presentatanyleafofthe tree.Forexample, inFigure
14.20, the value “Gold” has been deleted from the leaf level but is still present in a
nonleafnode.
In general, to delete a value in a B+-tree, we perform a lookup on the value and
delete it. If the node is too small, we delete it from its parent. This deletion results
in recursive application of the deletion algorithm until the root is reached, a parent
remainsadequatelyfullafterdeletion,orredistributionisapplied.
Figure 14.21 outlines the pseudocode for deletion from a B+-tree. The procedure
swap variables(N,N′) merely swaps the values of the (pointer) variables N and N′;
thisswaphasnoeffectonthetreeitself.Thepseudocodeusesthecondition“toofew
pointers/values.”Fornonleafnodes,thiscriterionmeanslessthan⌈n∕2⌉pointers;for
leafnodes,itmeanslessthan⌈(n−1)∕2⌉values.Thepseudocoderedistributesentries
byborrowingasingleentryfromanadjacentnode.Wecanalsoredistributeentriesby
repartitioningentriesequallybetweenthetwonodes.Thepseudocodereferstodeleting
anentry(K,P)fromanode.Inthecaseofleafnodes,thepointertoanentryactually
precedesthekeyvalue,sothepointerP precedesthekeyvalueK.Fornonleafnodes,
P followsthekeyvalueK.
+
14.3.4 Complexity of B -Tree Updates
Althoughinsertion and deletionoperations on B+-treesarecomplicated,theyrequire
relatively few I/O operations, which is an important benefit since I/O operations are
expensive.ItcanbeshownthatthenumberofI/Ooperationsneededintheworstcase
for an insertion is proportional to log (N), where n is the maximum number of
⌈n∕2⌉
pointersinanode,andN isthenumberofrecordsinthefilebeingindexed.
The worst-case complexity of the deletion procedure is also proportional to
log (N), provided there are no duplicate values for the search key; we discuss the
⌈n∕2⌉
caseofnonuniquesearchkeyslaterinthischapter.

--- Page 677 ---

648 Chapter14 Indexing
proceduredelete(valueK,pointer P)
findtheleafnodeLthatcontains(K,P)
delete entry(L, K, P)
proceduredelete entry(nodeN,valueK,pointer P)
delete(K,P)fromN
if(N istherootandN hasonlyoneremainingchild)
thenmakethechildofN thenewrootofthetreeanddeleteN
elseif(N hastoofewvalues/pointers)thenbegin
LetN′ bethepreviousornextchildofparent(N)
LetK′ bethevaluebetweenpointersN andN′ inparent(N)
if(entriesinN andN′ canfitinasinglenode)
thenbegin/*Coalescenodes*/
if(N isapredecessorofN′)thenswap variables(N,N′)
if(N isnotaleaf)
thenappendK′ andallpointersandvaluesinN toN′
else appendall(K,P)pairsinN toN′;setN′.P =N.P
i i n n
delete entry(parent(N),K′,N);deletenodeN
end
elsebegin/*Redistribution:borrowanentryfromN′ */
if(N′ isapredecessorofN)thenbegin
if(N isanonleafnode)thenbegin
letmbesuchthatN′.P isthelastpointerinN′
m
remove(N′.K ,N′.P )fromN′
m−1 m
insert(N′.P ,K′)asthefirstpointerandvalueinN,
m
byshiftingotherpointersandvaluesright
replaceK′ inparent(N)byN′.K
m−1
end
elsebegin
letmbesuchthat(N′.P ,N′.K )isthelastpointer/value
m m
pairinN′
remove(N′.P ,N′.K )fromN′
m m
insert(N′.P ,N′.K )asthefirstpointerandvalueinN,
m m
byshiftingotherpointersandvaluesright
replaceK′ inparent(N)byN′.K
m
end
end
else …symmetrictothethencase…
end
end
Figure 14.21 DeletionofentryfromaB+-tree.

--- Page 678 ---

14.3 B+-TreeIndexFiles 649
Inotherwords,thecostofinsertionanddeletionoperationsintermsofI/Ooper-
ationsisproportionaltotheheightoftheB+-tree,andisthereforelow.Itisthespeed
ofoperationonB+-treesthatmakesthemafrequentlyusedindexstructureindatabase
implementations.
In practice, operations on B+-trees result in fewer I/O operations than the worst-
case bounds. With fanout of 100, and assuming accesses to leaf nodes are uniformly
distributed,theparentofaleafnodeis100timesmorelikelytogetaccessedthanthe
leafnode.Conversely,withthesamefanout,thetotalnumberofnonleafnodesinaB+-
treewouldbejustalittlemorethan1/100th ofthenumberofleafnodes.Asaresult,
withmemorysizesofseveralgigabytesbeingcommontoday,forB+-treesthatareused
frequently, even if the relation is very large it is quite likely that most of the nonleaf
nodes are alreadyin the database buffer when they are accessed. Thus, typically only
oneortwoI/Ooperationsarerequiredtoperformalookup.Forupdates,theprobability
ofanodesplitoccurringiscorrespondinglyverysmall.Dependingontheorderingof
inserts, with a fanout of 100, only from 1 in 100 to 1 in 50 insertions will result in a
nodesplit,requiringmorethanone blocktobewritten.Asaresult,on anaverage an
insertwillrequirejustalittlemorethanoneI/Ooperationtowriteupdatedblocks.
AlthoughB+-treesonlyguaranteethatnodeswillbeatleasthalffull,ifentriesare
inserted in random order, nodes can be expected to be more than two-thirds full on
average. If entries are inserted in sorted order, on the other hand, nodes will be only
halffull.(Weleaveitasanexercisetothereadertofigureoutwhynodeswouldbeonly
halffullinthelattercase.)
14.3.5 Nonunique Search Keys
We have assumed so far that search keys are unique. Recall also that we described
earlier, in Section 14.3.1, how to make search keys unique by creating a composite
search key containing the original search key and extra attributes, that together are
uniqueacrossallrecords.
Theextraattributecanbearecord-id,whichisapointertotherecord,oraprimary
key, or any other attribute whose value is unique among all records with the same
search-keyvalue.Theextraattributeiscalledauniquifierattribute.
A search with the original search-key attribute can be carried out using a range
searchaswesawinSection14.3.2;alternatively,wecancreateavariantofthefindRange
functionthattakesonlytheoriginalsearchkeyvalueasparameterandignoresthevalue
oftheuniquifierattributewhencomparingsearch-keyvalues.
ItisalsopossibletomodifytheB+-treestructuretosupportduplicatesearchkeys.
Theinsert,delete,andlookupmethodsallhavetobemodifiedcorrespondingly.
• One alternative is to store each key value only once in the tree, and to keep a
bucket (or list) of record pointers with a search-key value, to handle nonunique
searchkeys.Thisapproachisspaceefficientsinceitstoresthekeyvalueonlyonce;
however, it creates several complications when B+-trees are implemented. If the

--- Page 679 ---

650 Chapter14 Indexing
buckets are kept in the leaf node, extra code is needed to deal with variable-size
buckets,andtodealwithbucketsthatgrowlargerthanthesizeoftheleafnode.If
thebucketsarestoredinseparate blocks,anextraI/Ooperation mayberequired
tofetchrecords.
• Another option is to store the search key value once per record; this approach
allowsaleafnodetobesplitintheusualwayifitisfoundtobefullduringanin-
sert.However,thisapproachmakeshandlingofsplitandsearchoninternalnodes
significantlymorecomplicated,sincetwoleavesmaycontainthesamesearchkey
value. It also has a higher space overhead, since key values are stored as many
timesastherearerecordscontainingthatvalue.
A major problem withboth these approaches, as compared to the unique search-
keyapproach,liesintheefficiencyofrecorddeletion.(Thecomplexityoflookupand
insertionarethesamewithboththeseapproaches,aswellaswiththeuniquesearch-key
approach.)Supposeaparticularsearch-keyvalueoccursalargenumberoftimes,and
oneoftherecordswiththatsearchkeyistobedeleted.Thedeletionmayhavetosearch
throughanumberofentrieswiththesamesearch-keyvalue,potentiallyacrossmultiple
leafnodes,tofindtheentrycorrespondingtotheparticularrecordbeingdeleted.Thus,
theworst-casecomplexityofdeletionmaybelinearinthenumberofrecords.
In contrast, record deletion can be done efficiently using the unique search key
approach.Whenarecordistobedeleted,thecompositesearch-keyvalueiscomputed
from the record and then used to look up the index. Since the value is unique, the
corresponding leaf-level entry can be found with a single traversal from root to leaf,
withnofurtheraccessesattheleaflevel.Theworst-casecostofdeletionislogarithmic
inthenumberofrecords,aswesawearlier.
Due to the inefficiency of deletion, as well as other complications due to du-
plicate search keys, B+-tree implementations in most database systems only handle
unique searchkeys, andtheyautomaticallyaddrecord-idsorotherattributes tomake
nonuniquesearchkeysunique.
+
14.4 B -Tree Extensions
Inthissection,wediscussseveralextensionsandvariationsoftheB+-treeindexstruc-
ture.
+
14.4.1 B -Tree File Organization
AsmentionedinSection14.3,themaindrawbackofindex-sequentialfileorganization
isthedegradationofperformanceasthefilegrows:Withgrowth,anincreasingpercent-
ageofindexentriesandactualrecordsbecomeoutoforderandarestoredinoverflow
blocks.WesolvethedegradationofindexlookupsbyusingB+-treeindicesonthefile.

--- Page 680 ---

14.4 B+-TreeExtensions 651
I
C F K M
(A,4) (B,8) (C,1) (D,9) (E,4) (F,7) (G,3) (H,3)
(I,4) (J,8) (K,1) (L,6) (M,4) (N,8) (P,6)
Figure 14.22 B+-treefileorganization.
Wesolvethedegradationproblemforstoringtheactualrecordsbyusingtheleaflevel
oftheB+-treetoorganizetheblockscontainingtheactualrecords.WeusetheB+-tree
structurenotonlyasanindex,butalsoasanorganizerforrecordsinafile.InaB+-tree
fileorganization,theleafnodesofthetreestorerecords,insteadofstoringpointersto
records. Figure 14.22 shows an example of a B+-tree file organization. Since records
are usually larger than pointers, the maximum number of records that can be stored
inaleafnodeislessthanthenumberofpointersinanonleafnode.However,theleaf
nodesarestillrequiredtobeatleasthalffull.
Insertion and deletion of records from a B+-tree file organization are handled in
the same way as insertion and deletion of entries in a B+-tree index. When a record
with a given key value v is inserted, the system locates the block that should contain
therecordbysearchingtheB+-treeforthelargestkeyinthetreethatis≤ v.Iftheblock
locatedhasenoughfreespacefortherecord,thesystemstorestherecordintheblock.
Otherwise,asinB+-treeinsertion,thesystemsplitstheblockintwoandredistributes
therecordsinit(intheB+-tree–keyorder)tocreatespaceforthenewrecord.Thesplit
propagatesuptheB+-treeinthenormalfashion.Whenwedeletearecord,thesystem
first removes it from the block containing it. If a block B becomes less than half full
asaresult,therecordsinBareredistributedwiththerecordsinanadjacentblockB′.
Assumingfixed-sizedrecords,eachblockwillholdatleastone-halfasmanyrecordsas
themaximumthatitcanhold.ThesystemupdatesthenonleafnodesoftheB+-treein
theusualfashion.
WhenweuseaB+-treeforfileorganization,spaceutilizationisparticularlyimpor-
tant,sincethespaceoccupiedbytherecordsislikelytobemuchmorethanthespace
occupiedbykeysandpointers.WecanimprovetheutilizationofspaceinaB+-treeby
involvingmoresiblingnodesinredistributionduringsplitsandmerges.Thetechnique
isapplicabletobothleafnodesandnonleafnodes,anditworksasfollows:
During insertion, if a node is full, the system attempts to redistribute some of its
entriestooneoftheadjacentnodes,tomakespaceforanewentry.Ifthisattemptfails
becausetheadjacentnodesarethemselvesfull,thesystemsplitsthenodeanddivides
theentriesevenlyamongoneoftheadjacentnodesandthetwonodesthatitobtained
bysplittingtheoriginalnode.Sincethethreenodestogethercontainonemorerecord

--- Page 681 ---

652 Chapter14 Indexing
thancanfitintwonodes,eachnodewillbeabouttwo-thirdsfull.Moreprecisely,each
nodewillhaveatleast⌊2n∕3⌋entries,wherenisthemaximumnumberofentriesthat
thenodecanhold.(⌊x⌋denotesthegreatestintegerthatislessthanorequaltox;that
is,wedropthefractionalpart,ifany.)
During deletion of a record, if the occupancy of a node falls below ⌊2n∕3⌋, the
systemattemptstoborrowanentryfromoneofthesiblingnodes.Ifbothsiblingnodes
have⌊2n∕3⌋records,insteadofborrowinganentry,thesystemredistributestheentries
inthenodeandinthetwosiblingsevenlybetweentwoofthenodesanddeletesthethird
node. We can use this approach because the total number of entries is 3⌊2n∕3⌋−1,
whichislessthan2n.Withthreeadjacentnodesusedforredistribution,eachnodecan
beguaranteedtohave⌊3n∕4⌋entries.Ingeneral,ifmnodes(m−1siblings)areinvolved
inredistribution,eachnodecanbeguaranteedtocontainatleast⌊(m−1)n∕m⌋entries.
However,thecostofupdatebecomeshigherasmoresiblingnodesareinvolvedinthe
redistribution.
NotethatinaB+-treeindexorfileorganization,leafnodesthatareadjacenttoeach
other in the tree may be located at different places on disk. When a file organization
is newly created on a set of records, it is possible to allocate blocks that are mostly
contiguous on disk to leaf nodes that are contiguous in the tree. Thus, a sequential
scanofleafnodeswouldcorrespondtoamostlysequentialscanondisk.Asinsertions
anddeletionsoccuronthetree,sequentialityisincreasinglylost,andsequentialaccess
hastowaitfordiskseeksincreasinglyoften.Anindexrebuildmayberequiredtorestore
sequentiality.
B+-treefileorganizationscanalsobeusedtostorelargeobjects,suchasSQLclobs
and blobs, which may be larger than a disk block, and as large as multiple gigabytes.
Suchlargeobjectscanbestoredbysplittingthemintosequencesofsmallerrecordsthat
areorganizedinaB+-treefileorganization.Therecordscanbesequentiallynumbered,
or numbered by the byte offset of the record within the large object, and the record
numbercanbeusedasthesearchkey.
14.4.2 Secondary Indices and Record Relocation
Somefileorganizations,suchastheB+-treefileorganization,maychangethelocation
ofrecordsevenwhentherecordshavenotbeenupdated. Asanexample, whenaleaf
node is split in a B+-tree file organization, a number of records are moved to a new
node.Insuchcases,allsecondaryindicesthatstorepointerstotherelocatedrecords
wouldhavetobeupdated,eventhoughthevaluesintherecordsmaynothavechanged.
Eachleafnodemaycontainafairlylargenumberofrecords,andeachofthemmaybe
indifferentlocationsoneachsecondaryindex.Thus,aleaf-nodesplitmayrequiretens
orevenhundredsofI/Ooperationstoupdateallaffectedsecondaryindices,makingit
averyexpensiveoperation.
Awidelyusedsolutionforthisproblemisasfollows:Insecondaryindices,inplace
ofpointerstotheindexedrecords,westorethevaluesoftheprimary-indexsearch-key

--- Page 682 ---

14.4 B+-TreeExtensions 653
attributes.Forexample,supposewehaveaprimaryindexontheattributeIDofrelation
instructor; then a secondary index on dept name would store with each department
name a list of instructor’s ID values of the corresponding records, instead of storing
pointerstotherecords.
Relocationofrecordsbecauseofleaf-nodesplitsthendoesnotrequireanyupdate
on any such secondary index. However, locating a record using the secondary index
now requires two steps: First we use the secondary index to find the primary-index
search-keyvalues,andthenweusetheprimaryindextofindthecorrespondingrecords.
Thisapproachthusgreatlyreducesthecostofindexupdateduetofilereorganiza-
tion,althoughitincreasesthecostofaccessingdatausingasecondaryindex.
14.4.3 Indexing Strings
CreatingB+-treeindicesonstring-valuedattributesraisestwoproblems.Thefirstprob-
lemisthatstringscanbeofvariablelength.Thesecondproblemisthatstringscanbe
long,leadingtoalowfanoutandacorrespondinglyincreasedtreeheight.
Withvariable-lengthsearchkeys,differentnodescanhavedifferentfanoutsevenif
they are full. A node must then be split if it is full, that is, there is no space to add a
newentry,regardlessofhowmanysearchentriesithas.Similarly,nodescanbemerged
orentriesredistributed dependingon whatfraction ofthespace inthenodesisused,
insteadofbeingbasedonthemaximumnumberofentriesthatthenodecanhold.
The fanout of nodes can be increasedby using a technique calledprefixcompres-
sion. With prefix compression, we do not store the entire search key value at nonleaf
nodes. We only store a prefix of each search key value that is sufficient to distinguish
betweenthekeyvaluesinthesubtreesthatitseparates.Forexample,ifwehadanindex
on names, the key value at a nonleaf node could be a prefix of a name; it may suffice
tostore“Silb”atanonleafnode,insteadofthefull“Silberschatz”iftheclosestvalues
inthetwosubtreesthatitseparatesare,say,“Silas”and“Silver”respectively.
+
14.4.4 Bulk Loading of B -Tree Indices
Aswesawearlier,insertionofarecordinaB+-treerequiresanumberofI/Ooperations
that in the worst case is proportional to the height of the tree, which is usually fairly
small(typicallyfiveorless,evenforlargerelations).
NowconsiderthecasewhereaB+-treeisbeingbuiltonalarge relation.Suppose
the relation is significantly larger than main memory, and we are constructing a non-
clustering index on the relation such that the index is also larger than main memory.
Inthiscase,aswescantherelationandaddentriestotheB+-tree,itisquitelikelythat
eachleafnodeaccessedisnotinthedatabasebufferwhenitisaccessed,sincethereis
noparticularorderingoftheentries.Withsuchrandomlyorderedaccessestoblocks,
eachtimean entryisaddedtothe leaf, adiskseek willbe requiredtofetchthe block
containingtheleafnode.Theblockwillprobablybeevictedfromthediskbufferbefore
anotherentryisaddedtotheblock,leadingtoanotherdiskseektowritetheblockback

--- Page 683 ---

654 Chapter14 Indexing
todisk.Thus, arandom readandarandom writeoperation maybe requiredforeach
entryinserted.
Forexample,iftherelationhas100millionrecords,andeachI/Ooperationtakes
about 10 milliseconds on a magnetic disk, it would take at least 1 million seconds to
buildtheindex,countingonlythecostofreadingleafnodes,notevencountingthecost
ofwritingtheupdatednodesbacktodisk.Thisisclearlyaverylargeamountoftime;
incontrast,ifeachrecordoccupies100bytes,andthedisksubsystemcantransferdata
at50megabytespersecond,itwouldtakejust200secondstoreadtheentirerelation.
Insertionofalargenumberofentriesatatimeintoanindexisreferredtoasbulk
loadingoftheindex.Anefficientwaytoperformbulkloadingofanindexisasfollows:
First, create a temporary file containing index entries for the relation, then sort the
file on the search key of the index being constructed, and finally scan the sorted file
and insert the entries into the index. There are efficient algorithms for sorting large
relations, described later in Section 15.4, which can sort even a large file with an I/O
costcomparabletothatofreadingthefileafewtimes,assumingareasonableamount
ofmainmemoryisavailable.
There is a significant benefit to sorting the entries before inserting them into the
B+-tree.Whentheentriesareinsertedinsortedorder,allentriesthatgotoaparticular
leaf node will appear consecutively, and the leaf needs to be written out only once;
nodeswillneverhave tobe read from diskduringbulk load,iftheB+-treewasempty
tostartwith.EachleafnodewillthusincuronlyoneI/Ooperationeventhoughmany
entries may be inserted into the node. If each leaf contains 100 entries, the leaf level
will contain 1 million nodes, resulting in only 1 million I/O operations for creating
the leaf level. Even these I/O operations can be expected to be sequential, if succes-
sive leaf nodes are allocated on successive disk blocks, and few disk seeks would be
required. With magnetic disks, 1 millisecond per block is a reasonable estimate for
mostlysequentialI/Ooperations,incontrastto10millisecondsperblockforrandom
I/Ooperations.
We shall study the cost of sorting a large relation later, in Section 15.4, but as a
roughestimate,theindexwhichwouldhaveotherwisetakenupto1,000,000seconds
tobuildonamagneticdiskcanbeconstructedinwellunder1000secondsbysorting
theentriesbeforeinsertingthemintotheB+-tree.
IftheB+-treeisinitiallyempty,itcanbe constructed fasterbybuildingitbottom-
up, from the leaf level, instead of using the usual insert procedure. In bottom-up B+-
treeconstruction,aftersortingtheentriesaswejustdescribed,webreakupthesorted
entries into blocks, keeping as many entries in a block as can fit in the block; the
resulting blocks form the leaf level of the B+-tree. The minimum value in each block,
alongwiththepointertotheblock,isusedtocreateentriesinthenextleveloftheB+-
tree,pointingtotheleafblocks.Eachfurtherlevelofthetreeissimilarlyconstructed
usingtheminimumvaluesassociatedwitheachnodeonelevelbelow,untiltherootis
created.Weleavedetailsasanexerciseforthereader.
Mostdatabasesystemsimplementefficienttechniquesbasedonsortingofentries,
and bottom-up construction, when creatingan index on a relation, although they use

--- Page 684 ---

14.4 B+-TreeExtensions 655
Einstein Katz Singh
Einstein Katz Singh
record record record
Brandt Califieri Crick El Said Gold Kim Mozart Srinivasan Wu
Brandt Califieri
... and so on for other records...
record record
Figure 14.23 B-treeequivalentofB+-treeinFigure14.9.
thenormalinsertionprocedurewhentuplesareaddedoneatatimetoarelationwith
an existing index. Some database systems recommend that if a very large number of
tuplesareaddedatoncetoanalreadyexistingrelation,indicesontherelation(other
than any index on the primary key) should be dropped, and then re-created after the
tuplesareinserted,totakeadvantageofefficientbulk-loadingtechniques.
14.4.5 B-Tree Index Files
B-tree indices are similar to B+-tree indices. The primary distinction between the two
approachesisthataB-treeeliminatestheredundantstorageofsearch-keyvalues.Inthe
B+-treeofFigure14.9,thesearchkeys“Einstein”,“Gold”,“Mozart”,and“Srinivasan”
appear in nonleaf nodes, in addition to appearing in the leaf nodes. Every search-key
valueappearsinsomeleafnode;severalarerepeatedinnonleafnodes.
A B-tree allowssearch-key values to appear only once (if they are unique), unlike
a B+-tree, where a value may appear in a nonleaf node, in addition to appearing in
a leaf node. Figure 14.23 shows a B-tree that represents the same search keys as the
B+-tree of Figure 14.9. Since search keys are not repeated in the B-tree, we may be
able to store the index in fewer tree nodes than in the corresponding B+-tree index.
However, since search keys that appear in nonleaf nodes appear nowhere else in the
B-tree, we are forced to include an additional pointer field for each search key in a
nonleaf node.These additionalpointers pointto eitherfile recordsor buckets forthe
associatedsearchkey.
It is worth noting that many database system manuals, articles in industry litera-
ture, and industry professionals use the term B-tree to refer to the data structure that
wecalltheB+-tree.Infact,itwouldbefairtosaythatincurrentusage,thetermB-tree
is assumed to be synonymous with B+-tree. However, in this book we use the terms
B-treeandB+-treeastheywereoriginallydefined,toavoidconfusionbetweenthetwo
datastructures.
AgeneralizedB-treeleafnodeappearsinFigure14.24a;anonleafnodeappearsin
Figure 14.24b. Leaf nodes are the same as in B+-trees.In nonleaf nodes, the pointers
P arethetreepointersthatweusedalsoforB+-trees,whilethepointersB arebucket
i i
or file-record pointers. In the generalized B-tree in the figure, there are n−1 keys in

--- Page 685 ---

656 Chapter14 Indexing
P 1 K 1 P 2 … P n-1 K n-1 P n
(a)
P B K P B K … P B K P
1 1 1 2 2 2 m-1 m-1 m-1 m
(b)
Figure 14.24 Typical nodesofaB-tree.(a)Leafnode.(b)Nonleafnode.
the leaf node, but there are m−1 keys in the nonleaf node. This discrepancy occurs
because nonleaf nodes must include pointers B, thus reducing the number of search
i
keysthatcanbeheldinthesenodes.Clearly,m < n,buttheexactrelationshipbetween
mandndependsontherelativesizeofsearchkeysandpointers.
ThenumberofnodesaccessedinalookupinaB-treedependsonwherethesearch
key islocated.Alookup on aB+-treerequirestraversalof apath from therootofthe
treetosomeleafnode.Incontrast,itissometimespossibletofindthedesiredvalueina
B-treebeforereachingaleafnode.However,roughlyntimesasmanykeysarestoredin
theleaflevelofaB-treeasinthenonleaflevels,and,sincenistypicallylarge,thebenefit
of finding certain values early is relatively small. Moreover, the fact that fewer search
keys appear in a nonleaf B-tree node, compared to B+-trees, implies that a B-tree has
asmallerfanoutandthereforemayhavedepthgreaterthanthatofthecorresponding
B+-tree. Thus, lookup in a B-tree is faster for some search keys but slower for others,
although, in general, lookup time isstill proportional to the logarithm of the number
ofsearchkeys.
Deletion in a B-tree is more complicated. In a B+-tree, the deleted entry always
appearsinaleaf.InaB-tree,thedeletedentrymayappearinanonleafnode.Theproper
value must be selected as a replacement from the subtree of the node containing the
deletedentry.Specifically,ifsearchkeyK isdeleted,thesmallestsearchkeyappearing
i
in the subtree of pointer P must be moved to the field formerly occupied by K.
i+1 i
Furtheractionsneedtobetakeniftheleafnodenowhastoofewentries.Incontrast,
insertioninaB-treeisonlyslightlymorecomplicatedthanisinsertioninaB+-tree.
The space advantages of B-treesare marginal forlarge indicesand usually donot
outweighthedisadvantagesthatwehavenoted.Thus,prettymuchalldatabase-system
implementations use the B+-tree data structure, even if (as we discussed earlier) they
refertothedatastructureasaB-tree.
14.4.6 Indexing on Flash Storage
Inourdescriptionofindexingsofar,wehaveassumed thatdataareresidentonmag-
neticdisks.Althoughthisassumptioncontinuestobetrueforthemostpart,flashstor-
age capacities have grown significantly, and the cost of flash storage per gigabyte has
droppedcorrespondingly,andflashbasedSSDstoragehasnowreplacedmagnetic-disk
storageformanyapplications.

--- Page 686 ---

14.4 B+-TreeExtensions 657
Standard B+-tree indices can continue to be used even on SSDs, with acceptable
updateperformanceandsignificantlyimprovedlookupperformancecomparedtodisk
storage.
Flash storage is structured as pages, and the B+-tree index structure can be used
withflashbasedSSDs.SSDsprovidemuchfasterrandomI/Ooperationsthanmagnetic
disks, requiringonlyaround20to100microsecondsforarandom page read,instead
ofabout5to10millisecondswithmagneticdisks.Thus,lookupsrunmuchfasterwith
dataonSSDs,comparedtodataonmagneticdisks.
The performance of write operations is more complicated with flash storage. An
importantdifferencebetweenflashstorageandmagneticdisksisthatflashstoragedoes
not permit in-place updates to data at the physical level, although it appears to do so
logically.Everyupdateturnsintoacopy+writeofanentireflash-storagepage,requiring
theoldcopyofthepagetobeerasedsubsequently.Anewpagecanbewrittenin20to
100microseconds,buteventuallyoldpagesneedtobeerasedtofreeupthepagesfor
furtherwrites.Erasesaredoneatthelevelofblockscontainingmultiplepages,anda
blockerasetakes2to5milliseconds.
TheoptimumB+-treenodesizeforflashstorageissmallerthanthatwithmagnetic
disk, sinceflash pages are smallerthan diskblocks; itmakes sense fortree-nodesizes
tomatchtoflashpages, sincelargernodeswouldleadtomultiplepage writeswhena
node is updated. Although smallerpages lead to taller trees and more I/O operations
toaccessdata,randompagereadsaresomuchfasterwithflashstoragethattheoverall
impactonreadperformanceisquitesmall.
Although random I/O ismuchcheaperwithSSDsthan withmagneticdisks, bulk
loadingstillprovidessignificantperformancebenefits, comparedtotuple-at-a-timein-
sertion,withSSDs.Inparticular,bottom-upconstructionreducesthenumberofpage
writescomparedtotuple-at-a-timeinsertion,eveniftheentriesaresortedonthesearch
key. Since page writes on flash cannot be done in place and require relatively expen-
sive blockerasesatalaterpointintime,thereductionofnumberofpage writeswith
bottom-upB+-treeconstructionprovidessignificantperformancebenefits.
Several extensions and alternatives to B+-trees have been proposed for flash stor-
age, with a focus on reducing the number of erase operations that result due to page
rewrites. One approach is to add buffers to internal nodes of B+-trees and record up-
datestemporarilyinbuffersathigherlevels,pushingtheupdatesdowntolowerlevels
lazily. The key idea is that when a page is updated, multiple updates are applied to-
gether,reducingthenumberofpagewritesperupdate.Anotherapproachcreatesmul-
tipletreesandmergesthem;thelog-structuredmergetreeanditsvariantsarebasedon
thisidea.Infact,boththeseapproachesarealsousefulforreducingthecostofwrites
onmagneticdisks;weoutlineboththeseapproachesinSection14.8.
14.4.7 Indexing in Main Memory
Main memory today is large and cheap enough that many organizations can afford
to buy enough main memory to fit all their operational data in-memory. B+-trees can

--- Page 687 ---

658 Chapter14 Indexing
be used to index in-memory data, with no change to the structure. However, some
optimizationsarepossible.
First, since memory is costlier than disk space, internal data structures in main
memorydatabaseshavetobedesignedtoreducespacerequirements.Techniquesthat
we saw in Section 14.4.1 to improve B+-tree storage utilization can be used to reduce
memoryusageforin-memoryB+-trees.
Data structures that require traversal of multiple pointers are acceptable for in-
memory data, unlike in the case of disk-based data, where the cost of the I/Os to tra-
versemultiplepageswouldbeexcessivelyhigh.Thus,treestructuresinmainmemory
databasescanberelativelydeep,unlikeB+-trees.
Thespeeddifferencebetweencachememoryandmainmemory,andthefactthat
dataaretransferredbetweenmainmemoryandcacheinunitsofacache-line(typically
about64bytes),resultsinasituationwheretherelationshipbetweencacheandmain
memoryisnotdissimilartotherelationshipbetweenmainmemoryanddisk(although
with smaller speed differences). When reading a memory location, if it is present in
cache the CPU can complete the read in 1 or 2 nanoseconds, whereas a cache miss
resultsinabout50to100nanosecondsofdelaytoreaddatafrommainmemory.
B+-treeswithsmallnodesthatfitinacachelinehave been found toprovide very
good performance with in-memory data. Such B+-trees allow index operations to be
completed withfarfewercachemissesthan tall,skinny treestructures such asbinary
trees,sinceeachnodetraversalislikelytoresultinacachemiss.ComparedtoB+-trees
withnodesthatmatchcachelines,treeswithlargenodesalsotendtohavemorecache
missessincelocatingdatawithinanoderequireseitherafullscanofthenodecontent,
spanningmultiplecachelines,orabinarysearch,whichalsoresultsinmultiplecache
misses.
For databases where data do not fit entirely in memory, but frequently used data
areoftenmemoryresident,thefollowingideaisusedtocreateB+-treestructuresthat
offergoodperformanceondiskaswellasin-memory.Largenodesareusedtooptimize
disk-basedaccess,butinsteadoftreatingdatainanodeassinglelargearrayofkeysand
pointers,thedatawithinanodearestructuredasatree,withsmallernodesthatmatch
thesizeofacacheline.Insteadofscanningdatalinearlyorusingbinarysearchwithin
anode,thetree-structurewithinthelargeB+-treenodeisusedtoaccessthedatawith
aminimalnumberofcachemisses.
14.5 Hash Indices
Hashingisawidelyusedtechniqueforbuildingindicesinmainmemory;suchindices
maybetransientlycreatedtoprocessajoinoperation(aswewillseeinSection15.5.5)
ormay be apermanentstructure inamain memorydatabase. Hashinghas alsobeen
used as a way of organizing records in a file, although hash file organizations are not
verywidelyused.Weinitiallyconsideronlyin-memoryhashindices,andweconsider
disk-basedhashinglaterinthissection.

--- Page 688 ---

14.5 HashIndices 659
In our description of hashing, we shall use the term bucket to denote a unit of
storagethatcanstoreoneormorerecords.Forin-memoryhashindices,abucketcould
bealinkedlistofindexentriesorrecords.Fordisk-basedindices,abucketwouldbea
linkedlistofdiskblocks.Inahashfileorganization,insteadofrecordpointers,buckets
store the actual records;such structures onlymake sense withdisk-residentdata.The
restof our descriptiondoesnotdepend on whetherthe bucketsstore recordpointers
oractualrecords.
Formally, let K denote the set of all search-key values, and let B denote the set
of all bucket addresses. A hash function h is a function from K to B. Let h denote a
hash function. With in-memory hash indices, the set of buckets is simply an array of
pointers, with the ith bucket at offset i. Each pointer stores the head of a linked list
containingtheentriesinthatbucket.
Toinsert arecord with search key K, we compute h(K), whichgives the address
i i
ofthebucketforthatrecord.Weaddtheindexentryfortherecordtothelistatoffset
i. Note that there are other variants of hash indices that handle the case of multiple
recordsinabucketdifferently;theformdescribedhereisthemostwidelyusedvariant
andiscalledoverflowchaining.
Hash indexing using overflow chaining is also called closed addressing (or, less
commonly, closed hashing). An alternative hashing scheme called open addressing is
usedinsomeapplications,butisnotsuitableformostdatabaseindexingapplications
sinceopenaddressingdoesnotsupportdeletesefficiently.Wedonotconsideritfurther.
Hash indices efficiently support equality queries on search keys. To perform a
lookuponasearch-keyvalueK,wesimplycomputeh(K),thensearchthebucketwith
i i
thataddress.Supposethattwosearchkeys,K andK ,havethesamehashvalue;that
5 7
is,h(K ) = h(K ).Ifweperformalookup onK ,thebucketh(K )containsrecords
5 7 5 5
withsearch-keyvaluesK andrecordswithsearch-keyvaluesK .Thus,wehavetocheck
5 7
the search-keyvalue ofeveryrecord inthe buckettoverify thattherecord isone that
wewant.
Unlike B+-tree indices, hash indicesdo not support range queries; for example, a
query that wishes to retrieve all search key values v such that l ≤ v ≤ u cannot be
efficientlyansweredusingahashindex.
Deletion is equally straightforward. If the search-key value of the record to be
deletedisK,wecomputeh(K),thensearchthecorrespondingbucketforthatrecord
i i
anddeletetherecordfromthebucket.Withalinkedlistrepresentation,deletionfrom
thelinkedlistisstraightforward.
Inadisk-basedhashindex,whenweinsertarecord,welocatethebucketbyusing
hashingonthesearchkey,asdescribedearlier.Assumefornowthatthereisspaceinthe
buckettostoretherecord.Then,therecordisstoredinthatbucket.Ifthebucketdoes
nothaveenoughspace,abucketoverflowissaidtooccur.Wehandlebucketoverflowby
usingoverflowbuckets.Ifarecordmustbeinsertedintoabucketb,andbisalreadyfull,
the system provides an overflow bucket for b and inserts the record into the overflow
bucket.Iftheoverflowbucketisalsofull,thesystemprovidesanotheroverflowbucket,
andsoon.Alltheoverflow bucketsofagivenbucketarechainedtogetherinalinked

--- Page 689 ---

660 Chapter14 Indexing
bucket 0
bucket 1
overflow buckets for bucket 1
bucket 2
bucket 3
Figure 14.25 Overflowchaininginadisk-basedhashstructure.
list,asinFigure14.25.Withoverflowchaining,givensearchkeyk,thelookupalgorithm
mustthensearchnotonlybucketh(k),butalsotheoverflowbucketslinkedfrombucket
h(k).
Bucketoverflowcanoccurifthereareinsufficientbucketsforthegivennumberof
records.Ifthenumberofrecordsthatareindexedisknownaheadoftime,therequired
number of buckets can be allocated; we will shortly see how to deal with situations
wherethenumberofrecordsbecomessignificantlymorethanwhatwasinitiallyantic-
ipated.Bucketoverflowcanalsooccurifsomebucketsareassignedmorerecordsthan
areothers,resultinginonebucketoverflowingevenwhenotherbucketsstillhavealot
offreespace.
Such skew in the distribution of records can occur if multiple records may have
the same search key. But even if there is only one record per search key, skew may
occur if the chosen hash function results in nonuniform distribution of search keys.
This chance of this problem can be minimized by choosing hash functions carefully,
toensurethedistributionofkeysacrossbucketsisuniformandrandom.Nevertheless,
someskewmayoccur.
So that the probability of bucket overflow is reduced, the number of buckets is
chosentobe(n ∕f ) ∗ (1+d),wheren denotesthenumberofrecords,f denotesthe
r r r r
number of records per bucket, d is a fudge factor, typically around 0.2. With a fudge
factorof0.2,about20percentofthespaceinthebucketswillbeempty.Butthebenefit
isthattheprobabilityofoverflowisreduced.
Despite allocation of a few more buckets than required, bucket overflow can still
occur,especiallyifthenumberofrecordsincreasesbeyondwhatwasinitiallyexpected.

--- Page 690 ---

14.6 Multiple-KeyAccess 661
Hashindexingasdescribedabove,wherethenumberofbucketsisfixedwhenthe
indexiscreated,iscalledstatichashing.Oneoftheproblemswithstatichashingisthat
weneedtoknowhowmanyrecordsaregoingtobestoredintheindex.Ifovertimea
largenumberofrecordsareadded,resultinginfarmorerecordsthanbuckets,lookups
wouldhavetosearchthroughalargenumberofrecordsstoredinasinglebucket,orin
oneormoreoverflowbuckets,andwouldthusbecomeinefficient.
Tohandlethisproblem,thehashindexcanberebuiltwithanincreasednumberof
buckets.Forexample,ifthenumberofrecordsbecomestwicethenumberofbuckets,
theindexcanberebuiltwithtwiceasmanybucketsasbefore.However,rebuildingthe
index has the drawback that it can take a long time if the relations are large, causing
disruption of normal processing. Several schemes have been proposed that allow the
number of buckets to be increased in a more incremental fashion. Such schemes are
called dynamic hashing techniques; the linear hashing technique and the extendable
hashing technique are two such schemes; see Section 24.5 for further details of these
techniques.
14.6 Multiple-Key Access
Untilnow,wehaveassumedimplicitlythatonlyoneindexononeattribute isusedto
processaqueryonarelation.However,forcertaintypesofqueries,itisadvantageous
tousemultipleindicesiftheyexist,ortouseanindexbuiltonamultiattributesearch
key.
14.6.1 Using Multiple Single-Key Indices
Assume that the instructor file has two indices: one for dept name and one for salary.
Consider the following query: “Find all instructors in the Finance department with
salaryequalto$80,000.”Wewrite
selectID
frominstructor
wheredept name='Finance'andsalary=80000;
Therearethreestrategiespossibleforprocessingthisquery:
1. Usetheindexondept nametofindallrecordspertainingtotheFinancedepart-
ment.Examineeachsuchrecordtoseewhethersalary=80000.
2. Use the index on salary to find all records pertaining to instructors with salary
of $80,000. Examine each such record to see whether the department name is
“Finance”.

--- Page 691 ---

662 Chapter14 Indexing
3. Use the index on dept name to find pointers to all records pertaining to the Fi-
nance department. Also, use the index on salary to find pointers to all records
pertainingtoinstructorswithasalaryof$80,000.Taketheintersectionofthese
twosetsofpointers.Thosepointersthatareintheintersectionpointtorecords
pertainingtoinstructorsoftheFinancedepartmentandwithsalaryof$80,000.
Thethirdstrategyistheonlyoneofthethreethattakesadvantageoftheexistenceof
multipleindices.However,eventhisstrategymaybeapoorchoiceifallofthefollowing
hold:
• TherearemanyrecordspertainingtotheFinancedepartment.
• Therearemanyrecordspertainingtoinstructorswithasalaryof$80,000.
• There are only a few records pertaining to both the Finance department and in-
structorswithasalaryof$80,000.
Ifthese conditionshold,wemust scan alarge number of pointerstoproduce a small
result.Anindexstructure calleda“bitmapindex”caninsome casesgreatlyspeedup
the intersection operation used in the third strategy. Bitmap indices are outlined in
Section14.9.
14.6.2 Indices on Multiple Keys
Analternativestrategyforthiscaseistocreateanduseanindexonacompositesearch
key (dept name, salary)—that is, the search key consisting of the department name
concatenatedwiththeinstructorsalary.
We can use an ordered (B+-tree)indexon the precedingcomposite search key to
answerefficientlyqueriesoftheform
selectID
frominstructor
wheredept name='Finance'andsalary=80000;
Queriessuchasthefollowingquery,whichspecifiesanequalityconditiononthefirst
attributeofthesearchkey(dept name)andarangeonthesecondattributeofthesearch
key(salary),canalsobehandledefficientlysincetheycorrespondtoarangequeryon
thesearchattribute.
selectID
frominstructor
wheredept name='Finance'andsalary<80000;
Wecanevenuseanorderedindexonthesearchkey(dept name,salary)toanswerthe
followingqueryononlyoneattributeefficiently:

--- Page 692 ---

14.6 Multiple-KeyAccess 663
selectID
frominstructor
wheredept name='Finance';
An equality condition dept name = “Finance” is equivalent to a range query on the
rangewithlowerend(Finance,−∞)andupperend(Finance,+∞).Rangequerieson
justthedept nameattributecanbehandledinasimilarmanner.
The use of an ordered-index structure on a composite search key, however, has a
fewshortcomings.Asanillustration,considerthequery
selectID
frominstructor
wheredept name<'Finance'andsalary<80000;
Wecananswerthisquerybyusinganorderedindexonthesearchkey(dept name,
salary):Foreachvalueofdept namethatislessthan“Finance”inalphabeticorder,the
system locatesrecordswithasalary value of80000. However,eachrecordislikelyto
be in a different disk block, because of the ordering of records in the file, leading to
manyI/Ooperations.
Thedifferencebetweenthisqueryandtheprevioustwoqueriesisthatthecondition
on the first attribute (dept name) is a comparison condition, rather than an equality
condition.Theconditiondoesnotcorrespondtoarangequeryonthesearchkey.
Tospeedtheprocessingofgeneralcompositesearch-keyqueries(whichcaninvolve
one or more comparison operations), we can use several special structures. We shall
consider bitmap indices in Section 14.9. There is another structure, called the R-tree,
that can be used for this purpose. The R-tree is an extension of the B+-tree to handle
indexingonmultipledimensionsandisdiscussedinSection14.10.1.
14.6.3 Covering Indices
Covering indices are indices that store the values of some attributes (other than the
search-keyattributes)alongwiththepointerstotherecord.Storingextraattributeval-
uesisusefulwithsecondaryindices,sincetheyallowustoanswersomequeriesusing
justtheindex,withoutevenlookinguptheactualrecords.
Forexample,supposethatwehaveanonclusteringindexontheIDattributeofthe
instructor relation. If we store the value of the salary attribute along with the record
pointer,wecananswerqueriesthatrequirethesalary(butnottheotherattribute,dept
name)withoutaccessingtheinstructor record.
The same effect could be obtained by creating an index on the search key (ID,
salary),butacoveringindexreducesthesizeofthesearchkey,allowingalargerfanout
inthenonleafnodes,andpotentiallyreducingtheheightoftheindex.

--- Page 693 ---

664 Chapter14 Indexing
14.7 Creation of Indices
AlthoughtheSQLstandarddoesnotspecifyanyspecificsyntaxforcreationofindices,
mostdatabasessupportSQLcommandstocreateanddropindices.AswesawinSec-
tion4.6,indicescanbecreatedusingthefollowingsyntax,whichissupportedbymost
databases.
createindex<index-name>on<relation-name>(<attribute-list>);
Theattribute-lististhelistofattributesoftherelationsthatformthesearchkeyforthe
index.Indicescanbedroppedusingacommandoftheform
dropindex<index-name>;
For example, to define an index named dept index on the instructor relation with
dept nameasthesearchkey,wewrite:
createindexdept indexoninstructor (dept name);
Todeclarethatan attribute or listof attributes isacandidatekey, we canuse the
syntaxcreateuniqueindexinplaceof createindexabove.Databasesthatsupportmul-
tiple types of indices also allow the type of index to be specified as part of the index
creationcommand.Refertothemanualofyourdatabasesystemtofindoutwhatindex
typesareavailable,andthesyntaxforspecifyingtheindextype.
WhenausersubmitsanSQLquerythatcanbenefitfromusinganindex,theSQL
queryprocessorautomaticallyusestheindex.
Indicescanbeveryusefulonattributesthatparticipateinselectionconditionsor
joinconditionsofqueries,sincetheycanreducethecostofqueriessignificantly.Con-
sideraquerythatretrievestakesrecordsforaparticularstudent ID12345 (expressed
inrelationalalgebraasσ (takes)). IftherewereanindexontheIDattribute of
ID=12345
takes, pointers to the required records could be obtained with only a few I/O opera-
tions.Sincestudentstypicallyonlytakeafewtensofcourses,evenfetchingtheactual
recordswould take onlyafew tens ofI/O operations subsequently. In contrast, inthe
absenceofthisindex,thedatabasesystemwouldbeforcedtoreadalltakesrecordsand
selectthosewithmatchingIDvalues.Readinganentirerelationcanbeveryexpensive
iftherearealargenumberofstudents.
However,indicesdohaveacost,sincetheyhavetobeupdatedwheneverthereisan
updatetotheunderlyingrelation.Creatingtoomanyindiceswouldslowdownupdate
processing,sinceeachupdatewouldhavetoalsoupdateallaffectedindices.
Sometimes performance problems are apparent during testing, for example, if a
query takes tens of seconds, it is clear that it is quite slow. However, suppose each
querytakes1secondtoscanalargerelationwithoutanindex,versus10milliseconds
toretrievethesamerecordsusinganindex.Iftestersrunonequeryatatime,queries

--- Page 694 ---

14.8 Write-OptimizedIndexStructures 665
respondquickly,evenwithoutanindex.However,supposethatthequeriesarepartof
a registration system that is used by a thousand students in an hour, and the actions
ofeachstudentrequire10suchqueriestobeexecuted.Thetotalexecutiontimewould
thenbe10,000secondsforqueriessubmittedin1hour,thatis,3600seconds.Students
arethenlikelytofindthattheregistrationsystemisextremelyslow,oreventotallyunre-
sponsive.Incontrast,iftherequiredindiceswerepresent,theexecutiontimerequired
would be 100 seconds for queries submitted in 1 hour, and the performance of the
registrationsystemwouldbeverygood.
Itisthereforeimportantwhenbuildinganapplicationtofigureoutwhichindices
areimportantforperformanceandtocreatethembeforetheapplicationgoeslive.
Ifarelationisdeclaredtohaveaprimarykey,mostdatabasesystemsautomatically
createanindexontheprimarykey.Wheneveratupleisinsertedintotherelation,the
index can be used to check that the primary-key constraint is not violated (i.e., there
are no duplicates on the primary-key value). Without the index on the primary key,
whenever a tuple is inserted, the entire relation has to be scanned to ensure that the
primary-keyconstraintissatisfied.
Although most database systems do not automatically create them, it is often
a good idea to create indices on foreign-key attributes, too. Most joins are between
foreign-keyandprimary-keyattributes,andqueriescontainingsuchjoins,wherethere
is also a selection condition on the referenced table, are not uncommon. Consider a
querytakes ⋈ σ (student),wheretheforeign-keyattributeIDoftakesrefer-
name=Shankar
encesthe primary-key attribute ID of student. Since veryfew students arelikelyto be
namedShankar,theindexontheforeign-keyattributetakes.IDcanbeusedtoefficiently
retrievethetakestuplescorrespondingtothesestudents.
Manydatabasesystemsprovidetoolsthathelpdatabaseadministratorstrackwhat
queries and updates are being executed on the system and recommend the creation
of indices depending on the frequencies of the queries and updates. Such tools are
referredtoasindextuningwizardsoradvisors.
Somerecentcloud-baseddatabasesystemsalsosupportcompletelyautomatedcre-
ationofindiceswheneverthesystemfindsthatdoingsowouldavoidrepeatedrelation
scans,withouttheinterventionofadatabaseadministrator.
14.8 Write-Optimized Index Structures
Oneof thedrawbacks of theB+-treeindexstructure isthatperformancecanbe quite
poor with random writes. Consider an index that is too large to fit in memory; since
the bulk of the space is at the leaf level, and memory sizes are quite large these days,
weassumeforsimplicitythathigherlevelsoftheindexfitinmemory.
Now suppose writes or inserts are done in an order that does not match the sort
orderoftheindex.Then,eachwrite/insertislikelytotouchadifferentleafnode;ifthe
number of leafnodes issignificantlylarger than the buffer size,most of these leafac-
cesseswouldrequirearandomreadoperation,aswellasasubsequentwriteoperation

--- Page 695 ---

666 Chapter14 Indexing
to write the updated leafpage back todisk. On a system witha magneticdisk, witha
10-millisecondaccesstime,theindexwouldsupportnotmorethan100writes/inserts
per second per disk; and this is an optimistic estimate, assuming that the seek takes
thebulkofthetime,andtheheadhasnotmovedbetweenthereadandthewriteofa
leaf page. On a system with flash based SSDs, random I/O is much faster, but a page
writestillhasasignificantcostsinceit(eventually)requiresapageerase,whichisan
expensiveoperation.Thus,thebasicB+-treestructureisnotidealforapplicationsthat
needtosupportaverylargenumberofrandomwrites/insertspersecond.
Severalalternativeindexstructureshavebeenproposedtohandleworkloadswith
ahighwrite/insertrate.Thelog-structuredmergetreeorLSMtreeanditsvariantsare
write-optimized index structures that have seen very significant adoption. The buffer
tree is an alternative approach, which can be used with a variety of search tree struc-
tures.Weoutlinethesestructuresintherestofthissection.
14.8.1 LSM Trees
An LSM tree consists of several B+-trees, starting with an in-memory tree, called L ,
0
and on-disk trees L ,L ,…,L for some k, where k is called the level. Figure 14.26
1 2 k
depictsthestructureofanLSMtreefork = 3.
An index lookup is performed by using separate lookup operations on each of
thetreesL ,…,L ,andmergingtheresultsofthelookups. (Weassume fornowthat
0 k
there are only inserts, and no updates or deletes; index lookups in the presence of
updates/deletesaremorecomplicatedandarediscussedlater.)
WhenarecordisfirstinsertedintoanLSMtree,itisinsertedintothein-memory
B+-treestructure L .Afairlylarge amountof memoryspace isallocatedforthistree.
0
The tree grows as more inserts are processed, until it fillsthe memoryallocated to it.
Atthispoint,weneedtomovedatafromthein-memorystructuretoaB+-treeondisk.
L0
Memory
L1
Disk
L2
L3
Figure 14.26 Log-structured mergetreewiththreelevels.

--- Page 696 ---

14.8 Write-OptimizedIndexStructures 667
If tree L is empty, the entire in-memory tree L is written to disk to create the
1 0
initialtreeL .However,ifL isnotempty,theleaflevelofL isscannedinincreasing
1 1 0
key order, and entries are merged with the leaf level entries of L (also scanned in
1
increasing key order). The merged entries are used to create a new B+-tree, using the
bottom-up build process. The new tree with the merged entries then replaces the old
L . In either case, after entries of L have been moved to L , all entries in L as well
1 0 1 0
astheoldL ,ifitexisted,aredeleted.Insertscanthenbemadetothenow emptyL
1 0
in-memory.
NotethatallentriesintheleafleveloftheoldL tree,includingthoseinleafnodes
1
thatdonothaveanyupdates,arecopiedtothenewtreeinsteadofperformingupdates
ontheexistingL treenode.Thisgivesthefollowingbenefits.
1
1. Theleavesofthenewtreearesequentiallylocated,avoidingrandomI/Oduring
subsequentmerges.
2. The leaves are full, avoiding the overhead of partially occupied leaves that can
occurwithpagesplits.
Thereis,however,acosttousingtheLSMstructureasdescribedabove:theentire
contents of the tree are copied each time a set of entries from L are copied into L .
0 1
Oneoftwotechniquesisusedtoreducethiscost:
1. Multiple levels are used, with level L trees having a maximum size that is k
i+1
timesthemaximumsizeoflevelL trees.Thus,eachrecordiswrittenatmostk
i
timesataparticularlevel.Thenumberoflevelsisproportionallog (I∕M)where
k
I isthenumberofentriesandM isthenumberofentriesthatfitinthein-memory
treeL .
0
2. Each level (other than L ) can have up to some number b of trees, instead of
0
just 1 tree. When an L tree is written to disk, a new L tree is created instead
0 1
of merging it with an existing L tree. When there are b such L trees, they are
1 1
mergedintoasinglenewL tree.Similarly,whentherearebtreesatlevelL they
2 i
aremergedintoanewL tree.
i+1
This variant of the LSM tree is called a stepped-merge index. The stepped-
mergeindexdecreasestheinsertcostsignificantlycomparedtohavingonlyone
tree per level, but it can result in an increase in query cost, since multiple trees
mayneedtobesearched.Bitmap-basedstructurescalledBloomfilters,described
inSection24.1,areusedtoreducethenumberoflookupsbyefficientlydetecting
that a search key is not present in a particular tree. Bloom filters occupy very
littlespace,buttheyarequiteeffectiveatreducingquerycost.
DetailsofallthesevariantsofLSMtreescanbefoundinSection24.2.
So far we have only described inserts and lookups. Deletes are handled in an in-
teresting manner. Instead of directly finding an index entry and deleting it, deletion

--- Page 697 ---

668 Chapter14 Indexing
results in insertion of a new deletion entry that indicates which index entry is to be
deleted.Theprocessofinsertingadeletionentryisidenticaltotheprocessofinserting
anormalindexentry.
However, lookups have to carry out an extra step. As mentioned earlier, lookups
retrieveentriesfromallthetreesandmergetheminsortedorderofkeyvalue.Ifthere
isadeletionentryforsomeentry,bothofthemwouldhavethesamekeyvalue.Thus,
alookupwouldfindboththedeletionentryandtheoriginalentryforthatkey,which
isto be deleted.Ifa deletionentryis found, the to-be-deleted entryisfiltered out and
notreturnedaspartofthelookupresult.
When trees are merged, if one of the trees contains an entry, and the other had
a matching deletion entry, the entries get matched up during the merge (both would
havethesamekey),andarebothdiscarded.
Updatesarehandledinamannersimilartodeletes,byinsertingan update entry.
Lookups need to match update entries with the original entries and return the latest
value. The update isactuallyapplied duringamerge, whenone tree hasan entryand
anotherhasitsmatchingupdate entry;themerge processwouldfind arecordand an
updaterecordwiththesamekey,applytheupdate,anddiscardtheupdateentry.
LSM trees were initiallydesigned to reduce the write and seek overheads of mag-
neticdisks.FlashbasedSSDshavearelativelylowoverheadforrandomI/Ooperations
sincetheydonotrequireseek, andthusthebenefitofavoidingrandomI/OthatLSM
treevariantsprovideisnotparticularlyimportantwithSSDs.
However,recallthatflashmemorydoesnotallowin-placeupdate,andwritingeven
asinglebytetoapagerequiresthewholepagetoberewrittentoanewphysicallocation;
the original location of the page needs to be erased eventually, which is a relatively
expensive operation. The reduction in number of writes using LSM tree variants, as
compared to traditional B+-trees, can provide substantial performance benefits when
LSMtreesareusedwithSSDs.
AvariantoftheLSMtreesimilartothestepped-mergeindex,withmultipletreesin
eachlayer,wasusedinGoogle’sBigTablesystem,aswellasinApacheHBase,theopen
sourcecloneofBigTable.Thesesystemsarebuiltontopofdistributedfilesystemsthat
allow appends to files but do not support updates to existing data. The fact that LSM
treesdonotperformin-placeupdatemadeLSMtreesaverygoodfitforthesesystems.
Subsequently, a large number of BigData storage systems such as Apache Cas-
sandra, Apache AsterixDB, and MongoDB added support for LSM trees, with most
implementingversionswithmultipletreesineachlayer.LSMtreesarealsosupported
inMySQL(usingtheMyRocksstorageengine)andintheembeddeddatabasesystems
SQLite4andLevelDB.
14.8.2 Buffer Tree
The buffer tree is an alternative to the log-structured merge tree approach. The key
ideabehindthebuffertreeistoassociateabufferwitheachinternalnodeofaB+-tree,

--- Page 698 ---

14.8 Write-OptimizedIndexStructures 669
Internal node
p 1 k 1 p 2 k 2 p 3 k 3 p 4 k 4 p 5 k 5 p 6 Buffer
Figure 14.27 Structure ofaninternalnodeofabuffertree.
includingtherootnode;thisisdepictedpictoriallyinFigure14.27.Wefirstoutlinehow
insertsandlookupsarehandled,andsubsequentlyweoutlinehowdeletesandupdates
arehandled.
Whenanindexrecordisinsertedintothebuffertree,insteadoftraversingthetree
totheleaf,theindexrecordisinsertedintothebufferoftheroot.Ifthebufferbecomes
full,eachindexrecordinthebufferispushedoneleveldownthetreetotheappropriate
childnode.Ifthechildnodeisaninternalnode,theindexrecordisaddedtothechild
node’sbuffer;ifthatbufferisfull,allrecordsinthatbufferaresimilarlypusheddown.
All records in a buffer are sorted on the search key before being pushed down. If the
childnodeisaleafnode,indexrecordsareinsertedintotheleafintheusualmanner.If
theinsertresultsinanoverfullleafnode,thenodeissplitintheusualB+-treemanner,
withthesplitpotentiallypropagatingtoparentnodes.Splittingofanoverfullinternal
nodeisdoneintheusualway,withtheadditionalstepofalsosplittingthebuffer;the
bufferentriesarepartitionedbetweenthetwosplitnodesbasedontheirkeyvalues.
LookupsaredonebytraversingtheB+-treestructureintheusualway,tofindleaves
thatcontainrecordsmatchingthelookupkey.Butthereisoneadditionalstep:ateach
internalnodetraversedbyalookup,thenode’sbuffermustbeexaminedtoseeifthere
areanyrecordsmatchingthelookupkey. Rangelookups aredoneasinanormalB+-
tree,buttheymustalsoexaminethebuffersofallinternalnodesaboveanyoftheleaf
nodesthatareaccessed.
Supposethebufferataninternalnodeholdsktimesasmanyrecordsasthereare
childnodes.Then,onaverage,krecordswouldbepusheddownatatimetoeachchild
(regardlessofwhetherthechildisaninternalnodeoraleafnode).Sortingofrecords
before they are pushed ensures that all these records are pushed down consecutively.
Thebenefitofthebuffer-treeapproachforinsertsisthatthecostofaccessingthechild
node from storage, and of writing the updated node back, is amortized (divided), on
average,betweenkrecords.Withsufficientlylargek,thesavingscanbequitesignificant
comparedtoinsertsinaregularB+-tree.
Deletes and updates can be processed in a manner similar to LSM trees, using
deletionentriesorupdateentries.Alternatively,deletesandupdatescouldbeprocessed
usingthenormalB+-treealgorithms,attheriskofahigherI/Ocostperdelete/update
ascomparedtothecostwhenusingdeletion/updateentries.
Buffer trees provide better worst-case complexity bounds on the number of I/O
operationsthandoLSMtreevariants.Intermsofreadcost,buffertreesaresignificantly
faster than LSM trees. However, write operations on buffer trees involve random I/O,

--- Page 699 ---

670 Chapter14 Indexing
requiringmoreseeks,incontrasttosequentialI/OoperationswithLSMtreevariants.
For magnetic disk storage, the high cost of seeks results in buffer trees performing
worsethanLSMtreesonwrite-intensiveworkloads.LSMtreeshavethusfoundgreater
acceptanceforwrite-intensiveworkloadswithdatastoredonmagneticdisk.However,
sincerandomI/OoperationsareveryefficientonSSDs,andbuffertreestendtoperform
fewer write operations overall compared to LSM trees, buffer trees can provide better
write performance on SSDs. Several index structures designed for flash storage make
useofthebufferconceptintroducedbybuffertrees.
Anotherbenefitofbuffertreesisthatthekeyideaofassociatingbufferswithinter-
nalnodes,toreducethenumberofwrites,canbeusedwithanytypeoftree-structured
index.Forexample,bufferinghasbeenusedasawayofsupportingbulkloadingofspa-
tialindicessuchasR-trees(whichwestudyinSection14.10.1), aswellasothertypes
ofindices,forwhichsortingandbottom-upconstructionarenotapplicable.
BuffertreeshavebeenimplementedaspartoftheGeneralizedSearchTree(GiST)
indexstructureinPostgreSQL.TheGiSTindexallowsuser-definedcodetobeexecuted
to implementsearch,update, and split operations on nodes and has been used to im-
plementR-treesandotherspatialindexstructures.
14.9 Bitmap Indices
Bitmapindicesareaspecializedtype ofindexdesignedforeasyqueryingonmultiple
keys, although each bitmap index is built on a single key. We describe key features of
bitmapindicesinthissectionbutprovidefurtherdetailsinSection24.3.
Forbitmapindicestobeused,recordsinarelationmustbenumberedsequentially,
startingfrom,say,0.Givenanumbern,itmustbeeasytoretrievetherecordnumbered
n.Thisisparticularlyeasytoachieveifrecordsarefixedinsizeandallocatedoncon-
secutiveblocksofafile.Therecordnumbercanthenbetranslatedeasilyintoablock
numberandanumberthatidentifiestherecordwithintheblock.
Considerarelationwithanattributethatcantakeononlyoneofasmallnumber
(e.g.,2to20)ofvalues.Forinstance,considerarelationinstructor info,whichhas(in
additiontoan IDattribute) anattribute gender,whichcantake onlyvaluesm(male)
orf(female).Supposetherelationalsohasanattributeincome level,whichstoresthe
incomelevel,whereincomehasbeenbrokenupintofivelevels:L1:0–9999,L2:10,000
–19,999, L3: 20,000–39,999, L4: 40,000–74,999, and L5: 75,000−∞. Here, the
raw data can take on many values, but a data analyst has split the values into a small
numberofrangestosimplifyanalysisofthedata.Aninstanceofthisrelationisshown
ontheleftsideofFigure14.28.
A bitmap is simply an array of bits. In its simplest form, a bitmap index on the
attribute A of relation r consists of one bitmap for each value that A can take. Each
bitmap has as many bits as the number of records in the relation. The ith bit of the
bitmapforvalue v issetto1iftherecordnumberedi hasthevaluev forattribute A.
j j
Allotherbitsofthebitmaparesetto0.

--- Page 700 ---

14.9 BitmapIndices 671
Bitmaps for gender Bitmaps for
income_level
record
m 10010
number ID gender income_level
L1 10100
0 76766 m L1 f 01101
1 22222 f L2 L2 01000
2 12121 f L1 L3 00001
3 15151 m L4
L4 00010
4 58583 f L3
L5 00000
Figure 14.28 Bitmapindicesonrelationinstructorinfo.
In our example, there is one bitmap for the value m and one for f. The ith bit of
thebitmapformissetto1ifthegendervalueoftherecordnumberediism.Allother
bitsofthebitmapformaresetto0.Similarly,thebitmapforfhasthevalue1forbits
correspondingtorecordswiththevaluefforthegenderattribute;allotherbitshavethe
value 0. Figure 14.28 shows bitmap indices on the gender and income level attributes
ofinstructor inforelation,fortherelationinstanceshowninthesamefigure.
We now consider when bitmaps are useful. The simplest way of retrieving all
recordswithvaluem(orvaluef)wouldbetosimplyreadallrecordsoftherelationand
selectthoserecordswithvaluem(orf,respectively).Thebitmapindexdoesn’treally
help to speed up such a selection. While it would allow us to read only those records
foraspecificgender,itislikelythateverydiskblockforthefilewouldhavetoberead
anyway.
In fact, bitmap indices are useful for selections mainly when there are selections
on multiple keys. Suppose we create a bitmap index on attribute income level, which
wedescribedearlier,inadditiontothebitmapindexongender.
Consider now a query that selects women with income in the range 10,000 to
19,999.Thisquerycanbeexpressedas
select*
frominstructor info
wheregender='f'andincome level='L2';
To evaluate this selection, we fetch the bitmaps for gender value f and the bitmap for
income levelvalueL2,andperformanintersection(logical-and)ofthetwobitmaps.In
otherwords,wecomputeanewbitmapwherebitihasvalue1iftheithbitofthetwo
bitmaps are both 1, and has a value 0 otherwise. In the example in Figure 14.28, the
intersectionofthebitmapforgender =𝖿 (01101)andthebitmapforincome level = L2
(01000)givesthebitmap01000.

--- Page 701 ---

672 Chapter14 Indexing
Sincethefirstattributecantaketwovalues,andthesecondcantakefivevalues,we
wouldexpectonlyabout1in10records,onanaverage,tosatisfyacombinedcondition
onthetwoattributes.Iftherearefurtherconditions,thefractionofrecordssatisfying
all the conditions is likely to be quite small. The system can then compute the query
resultbyfindingallbitswithvalue1intheintersectionbitmapandretrievingthecor-
respondingrecords.Ifthefraction islarge, scanningtheentirerelationwouldremain
thecheaperalternative.
Moredetailedcoverageofbitmapindices,includinghowtoefficientlyimplement
aggregateoperations,howtospeedupbitmapoperations,andhybridindicesthatcom-
bineB+-treeswithbitmaps,canbefoundinSection24.3.
14.10 Indexing of Spatial and Temporal Data
Traditional index structures, such as hash indices and B+-trees, are not suitable for
indexing of spatial data, which are typically of two or more dimensions. Similarly,
when tuples have temporal intervals associated with them, and queries may specify
timepointsortimeintervals,thetraditionalindexstructuresmayresultinpoorperfor-
mance.
14.10.1 Indexing of Spatial Data
Inthissectionweprovideanoverviewoftechniquesforindexingspatialdata.Further
detailscanbefoundinSection24.4.Spatialdatareferstodatareferringtoapointor
aregionintwoorhigherdimensionalspace.Forexample,thelocationofrestaurants,
identifiedbya(latitude,longitude)pair,isaformofspatialdata.Similarly,thespatial
extentofafarmoralakecanbeidentifiedbyapolygon,witheachcorneridentifiedby
a(latitude,longitude)pair.
Therearemanyformsofqueriesonspatialdata,whichneedtobeefficientlysup-
portedusingindices.Aquerythatasksforrestaurantsatapreciselyspecified(latitude,
longitude)paircanbeansweredbycreatingaB+-treeonthecompositeattribute(lati-
tude,longitude).However,suchaB+-treeindexcannotefficientlyansweraquerythat
asks for all restaurants that are within a 500-meter radius of a user’s location, which
isidentifiedbya(latitude,longitude)pair.Norcansuchanindexefficientlyanswera
querythatasksforallrestaurantsthatarewithinarectangularregionofinterest.Both
oftheseareformsofrangequeries,whichretrieveobjectswithinaspecifiedarea.Nor
can such an index efficiently answer a query that asks for the nearest restaurant to a
specifiedlocation;suchaqueryisanexampleofanearestneighborquery.
The goal of spatial indexing is to support different forms of spatial queries, with
range and nearest neighbor queries being of particular interest, since they are widely
used.
Tounderstandhowtoindexspatialdataconsistingoftwoormoredimensions,we
considerfirstthe indexingof pointsin one-dimensionaldata.Tree structures, such as
binarytreesandB+-trees,operatebysuccessivelydividingspaceintosmallerparts.For

--- Page 702 ---

14.10 IndexingofSpatialandTemporalData 673
3 3
2
2
3 1 3
Figure 14.29 Divisionofspacebyak-dtree.
instance, each internal node of a binary tree partitions a one-dimensional interval in
two.Pointsthatlieintheleftpartitiongointotheleftsubtree;pointsthatlieintheright
partitiongointotherightsubtree.Inabalancedbinarytree,thepartitionischosenso
that approximately one-half of the points stored in the subtree fall in each partition.
Similarly,eachlevelofaB+-treesplitsaone-dimensionalintervalintomultipleparts.
Wecanusethatintuitiontocreatetreestructuresfortwo-dimensionalspaceaswell
asinhigher-dimensionalspaces.Atreestructurecalledak-dtreewasoneoftheearly
structuresusedforindexinginmultipledimensions.Eachlevelofak-dtreepartitions
thespaceintotwo.Thepartitioningisdonealongonedimensionatthenodeatthetop
levelofthetree,alonganotherdimensioninnodesatthenextlevel,andsoon,cycling
through the dimensions. The partitioning proceeds in such a way that, at each node,
approximately one-half of the points stored in the subtree fall on one side and one-
half fall on the other. Partitioningstops when a node has less than agiven maximum
numberofpoints.
Figure14.29shows asetofpointsintwo-dimensionalspace, andak-d treerepre-
sentationofthesetofpoints,wherethemaximumnumberofpointsinaleafnodehas
beensetat1.Eachlineinthefigure(otherthantheoutsidebox)correspondstoanode
inthek-dtree.Thenumberingofthelinesinthefigureindicatesthelevelofthetreeat
whichthecorrespondingnodeappears.
Rectangularrange queries, whichask for points withina specified rectangular re-
gion, can be answered efficiently using a k-d tree as follows: Such a query essentially
specifies an interval on each dimension. For example, a range query may ask for all
points whose x dimension lies between 50 and 80, and y dimension lies between 40
and70.Recallthateachinternalnodesplitsspaceononedimension,andasinaB+-

--- Page 703 ---

674 Chapter14 Indexing
tree.Range searchcanbe performedbythefollowingrecursiveprocedure,startingat
theroot:
1. Supposethenodeisaninternalnode,andletitbesplitonaparticulardimension,
sayx,atapointx.Entriesintheleftsubtreehavexvalues< x,andthoseinthe
i i
right subtree have x values ≥ x. If the query range contains x, search is recur-
i i
sivelyperformedonbothchildren.Ifthequeryrangeistotheleftofx,searchis
i
recursivelyperformedonlyon the leftchild,andotherwiseitisperformed only
ontherightsubtree.
2. Ifthenodeisaleaf,allentriesthatarecontainedinthequeryrangeareretrieved.
Nearest neighbor search is more complicated, and we shall not describe it here, but
nearestneighborqueriescanalsobeansweredquiteefficientlyusingk-dtrees.
The k-d-Btreeextends the k-d treetoallow multiplechildnodesforeach internal
node,justasaB-treeextendsabinarytree,toreducetheheightofthetree.k-d-Btrees
are bettersuited forsecondarystorage than k-d trees.Range searchas outlinedabove
canbeeasilyextendedtok-d-Btrees,andnearestneighborqueriestoocanbeanswered
quiteefficientlyusingk-d-Btrees.
There are a number of alternative index structures for spatial data. Instead of di-
vidingthedataonedimensionatatime,quadtreesdivideupatwo-dimensionalspace
intofourquadrantsateachnodeofthetree.DetailsmaybefoundinSection24.4.1.
Indexingofregionsofspace,suchaslinesegments,rectangles,andotherpolygons,
presents new problems. There are extensions of k-d trees and quadtrees for this task.
A key idea is that if a line segment or polygon crosses a partitioning line, it is split
alongthepartitioninglineandrepresentedineachofthesubtreesinwhichitspieces
occur.Multipleoccurrencesofalinesegmentorpolygoncanresultininefficienciesin
storage,aswellasinefficienciesinquerying.
A storage structure called an R-tree is useful for indexing of objects spanning re-
gions of space, such as line segments, rectangles, and other polygons, in addition to
points. An R-tree is a balanced tree structure with the indexed objects stored in leaf
nodes,muchlikeaB+-tree.However,insteadofarangeofvalues,arectangularbound-
ingboxisassociatedwitheachtreenode.Theboundingboxofaleafnodeisthesmall-
est rectangle parallel tothe axes thatcontainsall objects stored in the leafnode. The
boundingboxofinternalnodesis,similarly,thesmallestrectangleparalleltotheaxes
that contains the bounding boxes of its child nodes. The bounding box of an object
(such as a polygon) isdefined, similarly,as the smallest rectangle parallel to the axes
thatcontainstheobject.
Each internal node stores the bounding boxes of the child nodes along with the
pointerstothechildnodes.Eachleafnodestorestheindexedobjects.
Figure14.30showsanexampleofasetofrectangles(drawnwithasolidline)and
theboundingboxes(drawnwithadashedline)ofthenodesofanR-treeforthesetof
rectangles. Note that the bounding boxes are shown with extra space inside them, to
make them stand out pictorially. In reality, the boxes would be smaller and fit tightly

--- Page 704 ---

14.10 IndexingofSpatialandTemporalData 675
A B
1
C
BB BB BB
1 2 3
G
3
H A B C D E F G H I
D I
2
E
F
Figure 14.30 AnR-tree.
ontheobjectsthattheycontain;thatis,eachsideofaboundingboxBwouldtouchat
leastoneoftheobjectsorboundingboxesthatarecontainedinB.
The R-tree itself is at the right side of Figure 14.30. The figure refers to the coor-
dinates of bounding box i as BB in the figure. More details about R-trees, including
i
detailsofhowtoanswerrangequeriesusingR-trees,maybefoundinSection24.4.2.
Unlikesomealternativestructuresforstoringpolygonsandlinesegments,suchas
R∗-treesandintervaltrees,R-treesstoreonlyonecopyofeachobject,andwecanensure
easily that each node is at least half full. However, querying may be slower than with
someofthealternatives,sincemultiplepathshavetobesearched.However,becauseof
theirbetterstorage efficiencyandtheirsimilaritytoB-trees,R-treesandtheirvariants
haveprovedpopularindatabasesystemsthatsupportspatialdata.
14.10.2 Indexing Temporal Data
Temporaldatareferstodatathathasanassociatedtimeperiod,asdiscussedinSection
7.10.Thetimeperiodassociatedwithatupleindicatestheperiodoftimeforwhichthe
tuple isvalid.Forexample, aparticularcourseidentifiermayhave itstitlechangedat
somepointoftime.Thus,acourseidentifierisassociatedwithatitleforagiventime
interval,afterwhichthesamecourseidentifierisassociatedwithadifferenttitle.This
canbemodeledbyhavingtwoormoretuplesinthecourserelationwiththesamecourse
id,butdifferenttitlevalues,eachwithitsownvalidtimeinterval.
Atimeintervalhasastarttimeandanendtime.Furtheratimeintervalindicates
whethertheintervalstartsatthestarttime,orjustafterthestarttime,thatis,whether
the interval is closed or open at the start time. Similarly, the time interval indicates
whetheritisclosedoropenattheendtime.Torepresentthefactthatatupleisvalid
currently, until it is next updated, the end time is conceptually set to infinity (which
canberepresentedbyasuitablylargetime,suchasmidnightof9999-12-31).

--- Page 705 ---

676 Chapter14 Indexing
In general, the valid period for a particular fact may not consist of just one time
interval; for example, a student may be registered in a university one academic year,
take a leave of absence for the next year, and register again the following year. The
valid period for the student’s registration at the university is clearly not a single time
interval. However, any valid period can be represented by multiple intervals; thus, a
tuplewithanyvalidperiodcanberepresentedbymultipletuples,eachofwhichhasa
validperiodthatisasingletimeinterval.Weshallthereforeonlyconsidertimeintervals
whenmodelingtemporaldata.
Supposewewishtoretrievethevalueofatuple,givenavaluevforanattributea,
andapointintimet .Wecancreateanindexonthea,anduseittoretrievealltuples
1
withvaluevforattributea.Whilesuchanindexmaybeadequateifthenumberoftime
intervalsforthatsearch-keyvalueissmall,ingeneraltheindexmayretrieveanumber
oftupleswhosetimeintervalsdonotincludethetimepointt .
1
AbettersolutionistouseaspatialindexsuchasanR-tree,withtheindexedtuple
treated as having two dimensions, one being the indexed attribute a, and the other
beingthetimedimension.Inthiscase,thetupleformsalinesegment,withvaluevfor
dimensiona,andthevalidtimeintervalofthetupleasintervalinthetimedimension.
One issue that complicatesthe use of a spatial index such as an R-tree is that the
endtimeintervalmaybeinfinity(perhapsrepresentedbyaverylargevalue),whereas
spatial indices typically assume that bounding boxes are finite, and may have poor
performanceifboundingboxesareverylarge.Thisproblemcanbedealtwithasfollows:
• Allcurrenttuples(i.e.,thosewithendtimeasinfinity,whichisperhapsrepresented
byalargetimevalue)arestoredinaseparateindexfromthosetuplesthathavea
non-infinite end time. The index on current tuples can be a B+-tree index on (a,
start time), whereaisthe indexedattribute and start time isthestart time,while
theindexfornon-currenttupleswouldbeaspatialindexsuchasanR-tree.
• Lookupsforakeyvaluevatapointintimet wouldneedtosearchonbothindices;
i
the search on the current-tuple index would be for tuples witha = v, and start ts
≤ t,whichcanbedonebyasimplerangequery.Querieswithatimerangecanbe
i
handledsimilarly.
Instead of using spatial indices that are designed for multidimensional data, one
can use specialized indices, such as the interval B+-tree, that are designed to index
intervals in a single dimension, and provide better complexity guarantees than R-tree
indices.However,mostdatabaseimplementationsfinditsimplertouseR-treeindices
insteadofimplementingyetanothertypeofindexfortimeintervals.
Recallthatwithtemporaldata,morethanonetuplemayhavethesamevaluefora
primarykey,aslongasthetupleswiththesameprimary-keyvaluehavenon-overlapping
timeintervals.Temporalindicesontheprimarykeyattributecanbeusedtoefficiently
determine if the temporal primary key constraint is violated when a new tuple is in-
sertedorthevalidtimeintervalofanexistingtupleisupdated.

--- Page 706 ---

14.11 Summary 677
14.11 Summary
• Manyqueriesreferenceonlyasmallproportionoftherecordsinafile.Toreduce
the overhead in searchingfor these records, we can construct indices for the files
thatstorethedatabase.
• Thereare twotypes of indicesthat wecan use: dense indicesand sparse indices.
Dense indices contain entries for every search-key value, whereas sparse indices
containentriesonlyforsomesearch-keyvalues.
• Ifthesortorderofasearchkeymatchesthesortorderofarelation,anindexon
thesearchkeyiscalledaclusteringindex.Theotherindicesarecallednonclustering
or secondary indices. Secondary indices improve the performance of queries that
use search keys other than the search key of the clustering index. However, they
imposeanoverheadonmodificationofthedatabase.
• Index-sequentialfilesareoneoftheoldestindexschemesusedindatabasesystems.
To permit fast retrieval of records in search-key order, records are stored sequen-
tially,andout-of-orderrecordsarechainedtogether.Toallowfastrandomaccess,
weuseanindexstructure.
• The primary disadvantage of the index-sequential file organization is that perfor-
mancedegradesasthefilegrows.Toovercomethisdeficiency,wecanuseaB+-tree
index.
• A B+-tree index takes the form of a balanced tree, in which every path from the
root of the tree to a leaf of the tree is of the same length. The height of a B+-
treeisproportionaltothelogarithmtothebaseN ofthenumberofrecordsinthe
relation,whereeachnonleafnodestoresN pointers;thevalueofN isoftenaround
50 or 100. B+-trees are much shorter than other balanced binary-tree structures
suchasAVLtrees,andthereforerequirefewerdiskaccessestolocaterecords.
• Lookup on B+-treesisstraightforward and efficient. Insertion and deletion,how-
ever,aresomewhatmorecomplicated,butstillefficient.Thenumberofoperations
requiredforlookup,insertion,anddeletiononB+-treesisproportionaltothelog-
arithmtothebaseN ofthenumberofrecordsintherelation,whereeachnonleaf
nodestoresN pointers.
• We can use B+-trees for indexing a file containing records, as well as to organize
recordsintoafile.
• B-treeindicesare similartoB+-treeindices.The primaryadvantage ofaB-treeis
that the B-tree eliminates the redundant storage of search-key values. The major
disadvantages are overall complexity and reduced fanout for a given node size.
System designers almost universally prefer B+-tree indices over B-tree indices in
practice.

--- Page 707 ---

678 Chapter14 Indexing
• Hashing is a widely used technique for building indices in main memory as well
asindisk-basedsystems.
• OrderedindicessuchasB+-treescanbeusedforselectionsbasedonequalitycon-
ditionsinvolvingsingleattributes.Whenmultipleattributesareinvolvedinaselec-
tioncondition,wecanintersectrecordidentifiersretrievedfrommultipleindices.
• The basic B+-tree structure is not ideal for applications that need to support a
verylarge numberofrandom writes/insertspersecond.Several alternativeindex
structures have been proposed to handleworkloadswithahigh write/insertrate,
includingthelog-structuredmergetreeandthebuffertree.
• Bitmapindicesprovideaverycompactrepresentationforindexingattributeswith
very few distinct values. Intersection operations are extremely fast on bitmaps,
makingthemidealforsupportingqueriesonmultipleattributes.
• R-treesareamultidimensionalextensionofB-trees;withvariantssuchasR+-trees
andR∗-trees,theyhaveprovedpopularinspatialdatabases.Indexstructuresthat
partition space in a regular fashion, such as quadtrees, help in processing spatial
joinqueries.
• Thereareanumberoftechniquesforindexingtemporaldata,includingtheuseof
spatialindexandtheintervalB+-treespecializedindex.
Review Terms
• Indextype ° Primaryindices;
° Orderedindices ° Nonclusteringindices
° Hashindices ° Secondaryindices
• Evaluationfactors ° Index-sequentialfiles
° Accesstypes • Indexentry
• Indexrecord
° Accesstime
• Denseindex
° Insertiontime
• Sparseindex
° Deletiontime
• Multilevelindices
° Spaceoverhead • Nonuniquesearchkey
• Searchkey • Compositesearchkey
• Orderedindices • B+-treeindexfiles
° Orderedindex ° Balancedtree
° Clusteringindex ° Leafnodes

--- Page 708 ---

PracticeExercises 679
° Nonleafnodes ° Dynamichashing
° Internalnodes • Multiple-keyaccess
° Rangequeries • Coveringindices
° Nodesplit • Write-optimizedindexstructure
° Nodecoalesce ° Log-structuredmerge(LSM)tree
° Redistributeofpointers ° Stepped-mergeindex
° Uniquifier ° Buffertree
• B+-treeextensions
• Bitmapindex
° Prefixcompression • Bitmapintersection
° Bulkloading • Indexingofspatialdata
° Bottom-upB+-treeconstruction
° Rangequeries
• B-treeindices
° Nearestneighborqueries
• Hashfileorganization
° k-dtree
° Hashfunction
° k-d-Btree
° Bucket
° Quadtrees
° Overflowchaining
° R-tree
° Closedaddressing
° Boundingbox
° Closedhashing
• Temporalindices
° Bucketoverflow
• Timeinterval
° Skew • Closedinterval
° Statichashing • Openinterval
Practice Exercises
14.1 Indicesspeedqueryprocessing,butitisusuallyabadideatocreateindiceson
everyattribute, andeverycombinationofattributes, thatarepotentialsearch
keys.Explainwhy.
14.2 Isitpossibleingeneraltohavetwoclusteringindicesonthesamerelationfor
differentsearchkeys?Explainyouranswer.
14.3 ConstructaB+-treeforthefollowingsetofkeyvalues:
(2,3,5,7,11,17,19,23,29,31)

--- Page 709 ---

680 Chapter14 Indexing
Assumethatthetreeisinitiallyemptyandvaluesareaddedinascendingorder.
Construct B+-trees for the cases where the number of pointers that willfit in
onenodeisasfollows:
a. Four
b. Six
c. Eight
14.4 ForeachB+-treeofExercise14.3,show theformofthetreeaftereachofthe
followingseriesofoperations:
a. Insert9.
b. Insert10.
c. Insert8.
d. Delete23.
e. Delete19.
14.5 Consider the modified redistribution scheme for B+-trees described on page
651.Whatistheexpectedheightofthetreeasafunctionofn?
14.6 GivepseudocodeforaB+-treefunctionfindRangeIterator(),whichislikethe
function findRange(), except that it returns an iterator object, as described
in Section 14.3.2. Also give pseudocode for the iterator class, including the
variablesintheiteratorobject,andthenext()method.
14.7 What would the occupancy of each leaf node of a B+-tree be if index entries
wereinsertedinsortedorder?Explainwhy.
14.8 Suppose you have a relation r withn tuples on whicha secondary B+-tree is
r
tobeconstructed.
a. GiveaformulaforthecostofbuildingtheB+-treeindexbyinsertingone
recordatatime.Assumeeachblockwillholdanaverageoff entriesand
thatalllevelsofthetreeabovetheleafareinmemory.
b. Assuminga random disk accesstakes 10 milliseconds,whatis the cost
ofindexconstructiononarelationwith10millionrecords?
c. Write pseudocode for bottom-up construction of a B+-tree, which was
outlinedinSection14.4.4.Youcanassumethatafunctiontoefficiently
sortalargefileisavailable.
14.9 The leafnodesofaB+-treefileorganizationmaylose sequentialityafterase-
quenceofinserts.
a. Explainwhysequentialitymaybelost.

--- Page 710 ---

PracticeExercises 681
b. To minimizethe number of seeks in a sequential scan, many databases
allocate leaf pages in extents of n blocks, for some reasonably large n.
WhenthefirstleafofaB+-treeisallocated,onlyoneblockofann-block
unit is used, and the remaining pages are free. If a page splits, and its
n-block unit has a free page, that space is used for the new page. If the
n-blockunitisfull,anothern-blockunitisallocated,andthefirstn∕2leaf
pagesareplacedinonen-blockunitandtheremainingoneinthesecond
n-blockunit.Forsimplicity,assumethattherearenodeleteoperations.
i. What is the worst-case occupancy of allocated space, assuming no
deleteoperations,afterthefirstn-blockunitisfull?
ii. Isitpossiblethatleafnodesallocatedtoann-nodeblockunitarenot
consecutive, that is, is it possible that two leaf nodes are allocated
to one n-node block, but another leaf node in between the two is
allocatedtoadifferentn-nodeblock?
iii. Under the reasonable assumption that buffer space is sufficient to
storeann-pageblock,howmanyseekswouldbe requiredforaleaf-
level scan of the B+-tree, in the worst case? Compare this number
withtheworstcaseifleafpagesareallocatedablockatatime.
iv. The technique of redistributing values to siblings to improve space
utilizationislikelytobemoreefficientwhenusedwiththepreceding
allocationschemeforleafblocks.Explainwhy.
14.10 Supposeyouaregivenadatabaseschemaandsomequeriesthatareexecuted
frequently. How would you use the above information to decide what indices
tocreate?
14.11 Inwrite-optimizedtreessuchastheLSMtreeorthestepped-mergeindex,en-
tries in one level are merged into the next level only when the level is full.
Suggest how this policy can be changed to improve read performance during
periodswhentherearemanyreadsbutnoupdates.
14.12 WhattradeoffsdobuffertreesposeascomparedtoLSMtrees?
14.13 Considertheinstructor relationshowninFigure14.1.
a. Construct abitmapindexontheattribute salary,dividingsalaryvalues
intofourranges:below50,000,50,000tobelow60,000,60,000tobelow
70,000,and70,000andabove.
b. ConsideraquerythatrequestsallinstructorsintheFinancedepartment
withsalaryof80,000ormore.Outlinethestepsinansweringthequery,
andshowthefinalandintermediatebitmapsconstructedtoanswerthe
query.
14.14 Suppose you have a relation containing the x,y coordinates and names of
restaurants. Suppose also that the only queries that will be asked are of the

--- Page 711 ---

682 Chapter14 Indexing
followingform:Thequeryspecifiesapointandasksifthereisarestaurantex-
actlyatthatpoint.Whichtypeofindexwouldbepreferable,R-treeorB-tree?
Why?
14.15 Supposeyouhaveaspatialdatabasethatsupportsregionquerieswithcircular
regions, but not nearest-neighbor queries. Describe an algorithm to find the
nearestneighborbymakinguseofmultipleregionqueries.
Exercises
14.16 Whenisitpreferabletouseadenseindexratherthanasparseindex?Explain
youranswer.
14.17 Whatisthedifferencebetweenaclusteringindexandasecondaryindex?
14.18 For each B+-tree of Exercise 14.3, show the steps involved in the following
queries:
a. Findrecordswithasearch-keyvalueof11.
b. Findrecordswithasearch-keyvaluebetween7and17,inclusive.
14.19 The solution presented in Section 14.3.5 to deal with nonunique search keys
addedanextraattributetothesearchkey.Whateffectcouldthischangehave
ontheheightoftheB+-tree?
14.20 Suppose there is a relation r(A,B,C), with a B+-tree index with search key
(A,B).
a. What is the worst-case cost of finding records satisfying 10 < A < 50
usingthisindex,intermsofthenumberofrecordsretrievedn andthe
1
heighthofthetree?
b. Whatistheworst-casecostoffindingrecordssatisfying10 < A < 50∧
5 < B < 10usingthisindex,intermsof thenumberofrecords n that
2
satisfythisselection,aswellasn andhdefinedabove?
1
c. Underwhatconditionsonn andn wouldtheindexbeanefficientway
1 2
offindingrecordssatisfying10 < A <50∧5 <B < 10?
14.21 SupposeyouhavetocreateaB+-treeindexonalargenumberofnames,where
themaximumsizeofanamemaybequitelarge(say40characters)andtheav-
eragenameisitselflarge(say10characters).Explainhowprefixcompression
canbeusedtomaximizetheaveragefanoutofnonleafnodes.
14.22 SupposearelationisstoredinaB+-treefileorganization.Supposesecondary
indicesstorerecordidentifiersthatarepointerstorecordsondisk.

--- Page 712 ---

FurtherReading 683
a. What would be the effect on the secondary indices if a node split hap-
penedinthefileorganization?
b. What would be the cost of updating allaffected recordsin a secondary
index?
c. Howdoesusingthesearchkeyofthefileorganizationasalogicalrecord
identifiersolvethisproblem?
d. Whatistheextracostduetotheuseofsuchlogicalrecordidentifiers?
14.23 What trade-offs do write-optimized indices pose as compared to B+-tree in-
dices?
14.24 An existence bitmap has a bit for each record position, with the bit set to 1
if the record exists, and 0 if there is no record at that position (for example,
ifthe record weredeleted).Show how to compute the existence bitmap from
other bitmaps. Make sure that your technique works even in the presence of
nullvaluesbyusingabitmapforthevaluenull.
14.25 Spatialindicesthatcanindexspatialintervalscanconceptuallybeusedtoin-
dextemporaldatabytreatingvalidtimeasatimeinterval.Whatistheproblem
withdoingso,andhowistheproblemsolved?
14.26 Some attributes of relations may contain sensitive data, and may be required
to be stored in an encrypted fashion. How does data encryption affect index
schemes?Inparticular,howmightitaffectschemesthatattempttostoredata
insortedorder?
Further Reading
B-tree indices were first introduced in [Bayer and McCreight (1972)] and [Bayer
(1972)].B+-treesarediscussedin[Comer(1979)],[BayerandUnterauer(1977)],and
[Knuth(1973)].[GrayandReuter(1993)]provideagooddescriptionofissuesinthe
implementationofB+-trees.
Thelog-structuredmerge(LSM)treeispresentedin[O’Neiletal.(1996)], while
the stepped merge tree is presented in [Jagadish et al. (1997)]. The buffer tree is
presented in [Arge (2003)]. [Vitter (2001)] provides an extensive survey of external-
memorydatastructuresandalgorithms.
Bitmap indices are described in [O’Neil and Quass (1997)]. They were first in-
troduced in the IBM Model 204 file manager on the AS 400 platform. They provide
very large speedups on certain types of queries and are today implemented on most
databasesystems.
[Samet (2006)] and [Shekhar and Chawla (2003)] provide textbook coverage of
spatial data structures and spatial databases. [Bentley (1975)] describes the k-d tree,

--- Page 713 ---

684 Chapter14 Indexing
and[Robinson(1981)]describesthek-d-Btree.TheR-treewasoriginallypresentedin
[Guttman(1984)].
Bibliography
[Arge(2003)] L.Arge,“TheBufferTree:ATechniqueforDesigningBatchedExternalData
Structures”,Algorithmica,Volume37,Number1(2003),pages1–24.
[Bayer(1972)] R.Bayer,“SymmetricBinaryB-trees:DataStructureandMaintenanceAlgo-
rithms”,ActaInformatica,Volume1,Number4(1972),pages290–306.
[BayerandMcCreight(1972)] R. Bayer and E. M. McCreight, “Organization and Mainte-
nanceofLargeOrderedIndices”,ActaInformatica,Volume1,Number3(1972),pages173–
189.
[BayerandUnterauer(1977)] R.BayerandK.Unterauer,“PrefixB-trees”,ACMTransactions
onDatabaseSystems,Volume2,Number1(1977),pages11–26.
[Bentley(1975)] J.L.Bentley,“MultidimensionalBinarySearchTreesUsedforAssociative
Searching”,CommunicationsoftheACM,Volume18,Number9(1975),pages509–517.
[Comer(1979)] D. Comer, “The Ubiquitous B-tree”, ACM Computing Surveys, Volume 11,
Number2(1979),pages121–137.
[GrayandReuter(1993)] J.GrayandA.Reuter,TransactionProcessing:ConceptsandTech-
niques,MorganKaufmann(1993).
[Guttman(1984)] A.Guttman,“R-Trees:ADynamicIndexStructureforSpatialSearching”,
InProc.oftheACMSIGMODConf.onManagementofData(1984),pages47–57.
[Jagadishetal.(1997)] H. V. Jagadish, P. P. S. Narayan, S. Seshadri, S. Sudarshan, and
R. Kanneganti, “Incremental Organization for Data Recording and Warehousing”, In Pro-
ceedings of the 23rd International Conference on Very Large Data Bases, VLDB ’97 (1997),
pages16–25.
[Knuth(1973)] D.E.Knuth,TheArtofComputerProgramming,Volume3,AddisonWesley,
SortingandSearching(1973).
[O’NeilandQuass(1997)] P. O’Neil and D. Quass, “Improved Query Performance with
VariantIndexes”,InProc.oftheACMSIGMODConf.onManagementofData(1997),pages
38–49.
[O’Neiletal.(1996)] P.O’Neil,E.Cheng,D.Gawlick,andE.O’Neil,“TheLog-structured
Merge-tree(LSM-tree)”,ActaInf.,Volume33,Number4(1996),pages351–385.
[Robinson(1981)] J.Robinson,“Thek-d-BTree:ASearchStructureforLargeMultidimen-
sional Indexes”, InProc.ofthe ACMSIGMOD Conf.onManagement ofData(1981),pages
10–18.
[Samet(2006)] H.Samet,FoundationsofMultidimensionalandMetricDataStructures,Mor-
ganKaufmann(2006).

--- Page 714 ---

FurtherReading 685
[ShekharandChawla(2003)] S.ShekharandS.Chawla,SpatialDatabases:ATOUR,Pear-
son(2003).
[Vitter(2001)] J.S.Vitter,“ExternalMemoryAlgorithmsandDataStructures:Dealingwith
MassiveData”,ACMComputingSurveys,Volume33,(2001),pages209–271.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 716 ---

6
PART
QUERY PROCESSING AND
OPTIMIZATION
User queries have to be executed on the database contents, which reside on storage
devices. It is usually convenient to break up queries into smaller operations, roughly
correspondingto the relational-algebraoperations. Chapter 15 describes how queries
areprocessed,presentingalgorithmsforimplementingindividualoperationsandthen
outlining how the operations are executed in synchrony to process a query. The algo-
rithms covered include those that can work on data much larger than main-memory,
aswellasthosethatareoptimizedforin-memorydata.
Therearemanyalternativewaysofprocessingaquery,andthesecanhavewidely
varying costs. Query optimization refers to the process of finding the lowest-cost
method of evaluating a given query. Chapter 16 describes the process of query opti-
mization, coveringtechniques for estimating query plan cost, and techniques for gen-
erating alternative query plans and picking the lowest cost plans. The chapter also
describes other optimization techniques, such as materialized views, for speeding up
queryprocessing.
687

--- Page 718 ---

15
CHAPTER
Query Processing
Query processing refers to the range of activities involved in extracting data from a
database.Theactivitiesincludetranslationofqueriesinhigh-leveldatabaselanguages
into expressions that can be used at the physical level of the file system, a variety of
query-optimizingtransformations,andactualevaluationofqueries.
15.1 Overview
ThestepsinvolvedinprocessingaqueryappearinFigure15.1.Thebasicstepsare:
1. Parsingandtranslation.
2. Optimization.
3. Evaluation.
Beforequery processingcan begin,thesystem must translate the queryintoaus-
able form. A language such as SQL is suitable for human use, but it is ill suited to be
thesystem’s internalrepresentationofaquery.Amoreuseful internalrepresentation
isonebasedontheextendedrelationalalgebra.
Thus,thefirstactionthesystemmusttakeinqueryprocessingistotranslateagiven
queryintoitsinternalform.Thistranslationprocessissimilartotheworkperformed
by the parser of a compiler. In generating the internal form of the query, the parser
checksthesyntaxoftheuser’squery,verifiesthattherelationnamesappearinginthe
query are names of the relations in the database, and so on. The system constructs a
parse-treerepresentationofthequery,whichitthentranslatesintoarelational-algebra
expression. If the query was expressed in terms of a view, the translation phase also
replacesallusesoftheviewbytherelational-algebraexpressionthatdefinestheview.1
Mostcompilertextscoverparsingindetail.
1Formaterializedviews,theexpressiondefiningtheviewhasalreadybeenevaluatedandstored.Therefore,thestored
relationcanbeused,insteadofusesoftheviewbeingreplacedbytheexpressiondefiningtheview.Recursiveviewsare
handleddifferently,viaafixed-pointprocedure,asdiscussedinSection5.4andSection27.4.7.
689

--- Page 719 ---

690 Chapter15 QueryProcessing
parser and relational-algebra
query
translator expression
optimizer
query
evaluation engine execution plan
output
data statistics
about data
Figure 15.1 Stepsinqueryprocessing.
Givenaquery,therearegenerallyavarietyofmethodsforcomputingtheanswer.
For example, we have seen that, in SQL, a query could be expressed in several differ-
entways.EachSQLquerycanitselfbetranslatedintoarelational-algebraexpressionin
oneofseveralways.Furthermore,therelational-algebrarepresentationofaqueryspec-
ifies only partially how to evaluate a query; there are usually several ways to evaluate
relational-algebraexpressions.Asanillustration,considerthequery:
selectsalary
frominstructor
wheresalary<75000;
Thisquerycanbetranslatedintoeitherofthefollowingrelational-algebraexpressions:
• σ (Π (instructor))
salary<75000 salary
• Π (σ (instructor))
salary salary<75000
Further, we can execute each relational-algebra operation by one of several dif-
ferent algorithms. For example, to implement the preceding selection, we can search
everytupleininstructor tofindtupleswithsalarylessthan75000.IfaB+-treeindexis
availableontheattributesalary,wecanusetheindexinsteadtolocatethetuples.
Tospecifyfullyhowtoevaluateaquery,weneednotonlytoprovidetherelational-
algebraexpression,butalsotoannotateitwithinstructionsspecifyinghowtoevaluate
each operation. Annotations may state the algorithm to be used for a specific opera-
tionortheparticularindexorindicestouse.Arelational-algebraoperationannotated

--- Page 720 ---

15.1 Overview 691
withinstructionsonhowtoevaluateitiscalledanevaluationprimitive.Asequenceof
primitive operations that can be used to evaluate a query is a query-execution plan or
query-evaluationplan.Figure15.2illustratesanevaluationplanforourexamplequery,
inwhichaparticularindex(denotedinthefigureas“index1”)isspecifiedforthese-
lection operation. The query-execution engine takes a query-evaluation plan, executes
thatplan,andreturnstheanswerstothequery.
The different evaluation plans for a given query can have different costs. We do
notexpectuserstowritetheirqueriesinawaythatsuggeststhemostefficientevalua-
tionplan.Rather,itistheresponsibilityofthesystemtoconstructaquery-evaluation
planthatminimizesthecostofqueryevaluation;thistaskiscalledqueryoptimization.
Chapter16describesqueryoptimizationindetail.
Oncethequeryplanischosen,thequeryisevaluatedwiththatplan,andtheresult
ofthequeryisoutput.
The sequence of steps already described for processing a query is representative;
notalldatabasesexactlyfollowthosesteps.Forinstance,insteadofusingtherelational-
algebra representation, several databases use an annotated parse-tree representation
basedonthestructureofthegivenSQLquery.However,theconceptsthatwedescribe
hereformthebasisofqueryprocessingindatabases.
Inordertooptimizeaquery,aqueryoptimizermustknowthecostofeachopera-
tion.Althoughtheexactcostishardtocompute,sinceitdependsonmanyparameters
suchasactualmemoryavailabletotheoperation,itispossibletogetaroughestimate
ofexecutioncostforeachoperation.
Inthischapter,westudyhowtoevaluateindividualoperationsinaqueryplanand
howtoestimatetheircost;wereturntoqueryoptimizationinChapter16.Section15.2
outlineshowwemeasurethecostofaquery.Section15.3throughSection15.6cover
the evaluation of individual relational-algebra operations. Several operations may be
groupedtogetherintoapipeline,inwhicheachoftheoperationsstartsworkingonits
inputtuplesevenastheyarebeinggeneratedbyanotheroperation.InSection15.7,we
examinehowtocoordinatetheexecutionofmultipleoperationsinaqueryevaluation
π
salary
σ
salary < 75000; use index 1
instructor
Figure 15.2 Aquery-evaluationplan.

--- Page 721 ---

692 Chapter15 QueryProcessing
plan,inparticular,howtousepipelinedoperationstoavoidwritingintermediateresults
todisk.
15.2 Measures of Query Cost
Therearemultiplepossibleevaluationplansforaquery,anditisimportanttobeable
tocomparethealternativesintermsoftheir(estimated)cost,andchoosethebestplan.
Todoso,wemustestimatethecostofindividualoperationsandcombinethemtoget
the cost of a query evaluation plan. Thus, as we study evaluation algorithms for each
operationlaterinthischapter,wealsooutlinehowtoestimatethecostoftheoperation.
The cost of query evaluation can be measured in terms of a number of different
resources, including disk accesses, CPU time to execute a query, and, in parallel and
distributeddatabasesystems,thecostofcommunication.(Wediscussparallelanddis-
tributeddatabasesystemsinChapter21throughChapter23.)
For large databases resident on magnetic disk, the I/O cost to access data from
diskusuallydominatestheothercosts;thus,earlycostmodelsfocusedontheI/Ocost
when estimating the cost of query operations. However, with flash storage becoming
larger and less expensive, most organizational data today can be stored on solid-state
drives(SSDs)inacosteffectivemanner.Inaddition,mainmemorysizeshaveincreased
significantly,andthecostofmainmemoryhasdecreasedenoughinrecentyearsthatfor
manyorganizations,organizationaldatacanbestoredcost-effectivelyinmainmemory
forquerying,althoughitmustofcoursebestoredonflashormagneticstoragetoensure
persistence.
Withdataresidentin-memoryoronSSDs,I/Ocostdoesnotdominatetheoverall
cost, and we must include CPU costs when computing the cost of query evaluation.
WedonotincludeCPUcostsinourmodeltosimplifyourpresentation,butnotethat
they can be approximated by simple estimators. Forexample, the cost model used by
PostgreSQL(asof2018)includes(i)aCPUcostpertuple,(ii)aCPUcostforprocessing
each index entry (in addition to the I/O cost), and (iii) a CPU cost per operator or
function(suchasarithmeticoperators,comparisonoperators,andrelatedfunctions).
The database has default values for each of these costs, which are multiplied by the
number of tuples processed, the number of index entries processed, and the number
of operators and functions executed, respectively. The defaults can be changed as a
configurationparameter.
WeusethenumberofblockstransferredfromstorageandthenumberofrandomI/O
accesses,eachofwhichwillrequireadiskseekonmagneticstorage,astwoimportant
factorsinestimatingthecostofaquery-evaluationplan.Ifthedisksubsystemtakesan
averageoft secondstotransferablockofdataandhasanaverageblock-accesstime
T
(diskseektimeplusrotationallatency)oft seconds,thenanoperationthattransfers
S
bblocksandperformsS randomI/Oaccesseswouldtakeb ∗ t +S ∗ t seconds.
T S
Thevaluesoft andt mustbecalibratedforthedisksystemused.Wesummarize
T S
performancedatahere;seeChapter12forfulldetailsonstoragesystems.Typicalvalues
forhigh-endmagneticdisksintheyear2018wouldbet = 4millisecondsandt = 0.1
S T

--- Page 722 ---

15.2 MeasuresofQueryCost 693
milliseconds,assuminga4-kilobyteblocksizeandatransferrateof40megabytesper
second.2
Although SSDs do not perform a physical seek operation, they have an overhead
for initiating an I/O operation; we refer to the latency from the time an I/O request
is made to the time when the first byte of data is returned as t . For mid-range SSDs
S
in 2018 using the SATA interface, t is around 90 microseconds, while the transfer
S
timet isabout10microsecondsfora4-kilobyteblock.Thus,SSDscansupportabout
T
10,000 random 4-kilobyte reads per second, and they support 400 megabytes/second
throughputonsequentialreadsusingthestandardSATAinterface.SSDsusingthePCIe
3.0x4 interface have smaller t , of 20 to 60 microseconds, and much higher transfer
S
rates of around 2 gigabytes/second, corresponding to t of 2 microseconds, allowing
T
around50,000to15,000random4-kilobyteblockreadspersecond,dependingonthe
model.3
For data that are already present in main memory, reads happen at the unit of
cache lines, instead of disk blocks. But assuming entire blocks of data are read, the
timetotransfert fora4-kilobyteblockislessthan1microsecondfordatainmemory.
T
Thelatencytofetchdatafrommemory,t ,islessthan100nanoseconds.
S
Given the wide diversity of speeds of different storage devices, database systems
must ideally perform test seeks and block transfers to estimate t and t for specific
S T
systems/storagedevices,aspartofthesoftwareinstallationprocess.Databasesthatdo
notautomaticallyinferthesenumbersoftenallowuserstospecifythenumbersaspart
ofconfigurationfiles.
Wecanrefineourcostestimatesfurtherbydistinguishingblockreadsfromblock
writes.Blockwritesaretypicallyabouttwiceasexpensiveasreadsonmagneticdisks,
sincedisksystemsreadsectorsbackaftertheyarewrittentoverifythatthewritewas
successful. On PCIe flash, write throughput may be about 50 percent less than read
throughput, but the difference is almost completely masked by the limited speed of
SATAinterfaces,leadingtowritethroughputmatchingreadthroughput.However,the
throughput numbers do not reflect the cost of erases that are required if blocks are
overwritten.Forsimplicity,weignorethisdetail.
The cost estimates we give do not include the cost of writing the final result of
an operation back to disk. These are taken into account separately where required.
2Storagedevicespecificationsoftenmentionthetransferrate,andthenumberofrandomI/Ooperationsthatcanbe
carriedoutin1second.Thevaluest canbecomputedasblocksizedividedbytransferrate,whilet canbecomputed
T S
as(1∕N)−t
T
,whereNisthenumberofrandomI/Ooperationspersecondthatthedevicesupports,sincearandom
I/OoperationperformsarandomI/Oaccess,followedbydatatransferof1block.
3TheI/OoperationspersecondnumberusedhereareforthecaseofsequentialI/Orequests,usuallydenotedasQD-1
intheSSDspecifications.SSDscansupportmultiplerandomrequestsinparallel,with32to64parallelrequestsbeing
commonlysupported;anSSDwithSATAinterfacesupportsnearly100,000random4-kilobyteblockreadsinasecond
ifmultiplerequestsaresentinparallel,whilePCIediskscansupportover350,000random4-kilobyteblockreadsper
second;thesenumbersarereferredtoastheQD-32orQD-64numbersdependingonhowmanyrequestsaresentin
parallel.Wedonotexploreparallelrequestsinourcostmodel,sinceweonlyconsidersequentialqueryprocessing
algorithmsinthischapter.Shared-memoryparallelqueryprocessingtechniques,discussedinSection22.6,canbeused
toexploittheparallelrequestcapabilitiesofSSDs.

--- Page 723 ---

694 Chapter15 QueryProcessing
The costs of all the algorithms that we consider depend on the size of the buffer in
main memory. In the best case, if data fits in the buffer, the data can be read into
the buffers, and the disk does not need to be accessed again. In the worst case, we
may assume that the buffer can hold only a few blocks of data—approximately one
blockperrelation.However,withlargemainmemoriesavailabletoday,suchworst-case
assumptions are overly pessimistic. In fact, a good deal of main memory is typically
available for processing a query, and our cost estimates use the amount of memory
availabletoanoperator,M,asaparameter.InPostgreSQLthetotalmemoryavailable
to a query, called the effective cache size, is assumed by default to be 4 gigabytes, for
thepurposeofcostestimation;ifaqueryhasseveraloperatorsthatrunconcurrently,
theavailablememoryhastobedividedamongsttheoperators.
In addition, although we assume that data must be read from disk initially, it is
possiblethatablockthatisaccessedisalreadypresentinthein-memorybuffer.Again,
for simplicity, we ignore this effect; as a result, the actual disk-access cost during the
executionofaplanmaybelessthantheestimatedcost.Toaccount(atleastpartially)
forbufferresidence,PostgreSQLusesthefollowing“hack”:thecostofarandompage
readisassumedtobe1/10thoftheactualrandompagereadcost,tomodelthesituation
that90%ofreadsarefoundtoberesidentincache.Further,tomodelthesituationthat
internal nodes of B+-tree indices are traversed often, most database systems assume
thatallinternalnodesarepresentinthein-memorybuffer,andassumethatatraversal
ofanindexonlyincursasinglerandomI/Ocostfortheleafnode.
Theresponsetimeforaquery-evaluationplan(thatis,thewall-clocktimerequired
to execute the plan), assuming no other activity is going on in the computer, would
account for all these costs, and could be used as a measure of the cost of the plan.
Unfortunately, the response time of a plan is very hard to estimate without actually
executingtheplan,forthefollowingtworeasons:
1. Theresponsetimedependsonthecontentsofthebufferwhenthequerybegins
execution; this information is not available when the query is optimized and is
hardtoaccountforevenifitwereavailable.
2. Inasystemwithmultipledisks,theresponsetimedependsonhowaccessesare
distributed among disks, which is hard to estimate without detailed knowledge
ofdatalayoutondisk.
Interestingly, a plan may get a better response time at the cost of extra resource con-
sumption.Forexample,ifasystemhasmultipledisks,aplanAthatrequiresextradisk
reads, but performs the reads in parallel across multiple disks may, finish faster than
another plan B that has fewer disk reads, but performs reads from only one disk at a
time.However,ifmanyinstancesofaqueryusingplanArunconcurrently,theoverall
responsetimemayactuallybemorethanifthesameinstancesareexecutedusingplan
B,sinceplanAgeneratesmoreloadonthedisks.
As a result, instead of trying to minimizethe response time, optimizersgenerally
trytominimizethetotalresourceconsumptionofaqueryplan.Ourmodelofestimating

--- Page 724 ---

15.3 SelectionOperation 695
the total disk access time (including seek and data transfer) is an example of such a
resourceconsumption–basedmodelofquerycost.
15.3 Selection Operation
Inqueryprocessing,thefilescanisthelowest-leveloperatortoaccessdata.Filescans
aresearchalgorithmsthatlocateandretrieverecordsthatfulfillaselectioncondition.
Inrelationalsystems,afilescanallowsanentirerelationtobereadinthosecaseswhere
therelationisstoredinasingle,dedicatedfile.
15.3.1 Selections Using File Scans and Indices
Consider a selection operation on a relation whose tuples are stored together in one
file.Themoststraightforwardwayofperformingaselectionisasfollows:
• A1 (linear search). In a linear search, the system scans each file block and tests
all records to see whether they satisfy the selection condition. An initial seek is
requiredtoaccessthefirstblockofthefile.Incaseblocksofthefilearenotstored
contiguously,extraseeksmayberequired,butweignorethiseffectforsimplicity.
Although it may be slower than other algorithms for implementing selection,
the linear-search algorithm can be applied to any file, regardless of the ordering
of the file, or the availability of indices, or the nature of the selection operation.
Theotheralgorithmsthatweshallstudyarenotapplicableinallcases,butwhen
applicabletheyaregenerallyfasterthanlinearsearch.
Costestimatesforlinearscan,aswellasforotherselectionalgorithms,areshown
inFigure15.3.Inthefigure,weuseh torepresenttheheightoftheB+-tree,andassume
i
a random I/O operation is required for each node in the path from the root to a leaf.
Most real-lifeoptimizersassume thatthe internal nodesof the tree are present in the
in-memorybuffersincetheyarefrequentlyaccessed,andusuallylessthan1percentof
the nodes of a B+-tree are nonleaf nodes. The cost formulae can be correspondingly
simplified,chargingonlyonerandomI/Ocostforatraversalfromtheroottoaleaf,by
settingh = 1.
i
Indexstructuresarereferredtoasaccesspaths,sincetheyprovideapaththrough
whichdatacanbelocatedandaccessed.InChapter14,wepointedoutthatitisefficient
toreadtherecordsofafileinanordercorrespondingcloselytophysicalorder.Recall
thata clustering index(also referredto as a primary index)is an indexthat allowsthe
records of a file to be read in an order that corresponds to the physical order in the
file.Anindexthatisnotaclusteringindexiscalledasecondaryindexoranonclustering
index.

--- Page 725 ---

696 Chapter15 QueryProcessing
Search algorithms that use an index are referred to as index scans. We use the
selectionpredicatetoguideusinthechoiceoftheindextouseinprocessingthequery.
Searchalgorithmsthatuseanindexare:
Algorithm Cost Reason
A1 LinearSearch t +b ∗ t One initial seek plus b block transfers,
S r T r
whereb denotesthenumberofblocksin
r
thefile.
A1 LinearSearch, Averagecase Sinceatmostonerecordsatisfiesthecon-
EqualityonKey t +(b ∕2) ∗ t dition,scancanbeterminatedassoon as
S r T
the requiredrecord isfound. Inthe worst
case,b blocktransfersarestillrequired.
r
A2 Clustering (h +1) ∗ (Where h denotes the height of the in-
i i
B+-treeIndex, (t +t ) dex.)Indexlookuptraversestheheightof
T S
EqualityonKey the tree plus one I/O to fetch the record;
each of these I/O operations requires a
seekandablocktransfer.
A3 Clustering h ∗ (t +t )+ One seek for each level of the tree, one
i T S
B+-treeIndex, t +b ∗ t seekforthefirstblock.Herebisthenum-
S T
Equalityon ber of blocks containingrecords with the
Non-key specifiedsearchkey,allofwhichareread.
Theseblocksareleafblocksassumedtobe
storedsequentially(sinceitisaclustering
index)anddon’trequireadditionalseeks.
A4 Secondary (h +1) ∗ Thiscaseissimilartoclusteringindex.
i
B+-treeIndex, (t +t )
T S
EqualityonKey
A4 Secondary (h +n) ∗ (Where n is the number of records
i
B+-treeIndex, (t +t ) fetched.) Here, cost of index traversal is
T S
Equalityon the same as for A3, but each record may
Non-key be on a different block, requiring a seek
perrecord.Costispotentiallyveryhighif
nislarge.
A5 Clustering h ∗ (t +t )+ Identical to the case of A3, equality on
i T S
B+-treeIndex, t +b ∗ t non-key.
S T
Comparison
A6 Secondary (h +n) ∗ Identical to the case of A4, equality on
i
B+-treeIndex, (t +t ) non-key.
T S
Comparison
Figure 15.3 Costestimatesforselectionalgorithms.

--- Page 726 ---

15.3 SelectionOperation 697
• A2 (clustering index, equality on key). For an equality comparison on a key at-
tributewithaclusteringindex,wecanusetheindextoretrieveasinglerecordthat
satisfiesthecorrespondingequalitycondition.CostestimatesareshowninFigure
15.3. To model the common situation that the internal nodes of the index are in
thein-memorybuffer,h canbesetto1.
i
• A3 (clustering index, equality on non-key). We can retrieve multiple records by
using a clustering index when the selection condition specifies an equality com-
parison on a non-key attribute, A. The only difference from the previous case is
thatmultiplerecordsmayneedtobefetched.However,therecordsmustbestored
consecutively in the file since the file is sorted on the search key. Cost estimates
areshowninFigure15.3.
• A4 (secondary index, equality). Selections specifying an equality condition can
use a secondary index. This strategy can retrieve a single record if the equality
conditionisonakey;multiplerecordsmayberetrievediftheindexingfieldisnot
akey.
Inthefirstcase,onlyonerecordisretrieved.Thecostinthiscaseisthesame
asthatforaclusteringindex(caseA2).
Inthesecondcase,eachrecordmayberesidentonadifferentblock,whichmay
resultinoneI/Ooperationperretrievedrecord,witheachI/Ooperationrequiring
aseekandablocktransfer.Theworst-casecostinthiscaseis(h +n) ∗ (t +t ),
i S T
wherenisthenumberofrecordsfetched,ifeachrecordisinadifferentdiskblock,
and the block fetches are randomly ordered. The worst-case cost could become
evenworsethanthatoflinearsearchifalargenumberofrecordsareretrieved.
If the in-memory buffer is large, the block containing the record may already
be in the buffer. It is possible to construct an estimate of the average or expected
costoftheselectionbytakingintoaccounttheprobabilityoftheblockcontaining
therecordalreadybeinginthebuffer.Forlargebuffers,thatestimatewillbemuch
lessthantheworst-caseestimate.
Incertainalgorithms,includingA2,theuseofaB+-treefileorganizationcansave
oneaccesssincerecordsarestoredattheleaflevelofthetree.
AsdescribedinSection14.4.2,whenrecordsarestoredinaB+-treefileorganiza-
tion or other file organizations that may require relocation of records, secondary in-
dicesusuallydonotstorepointerstotherecords.4Instead,secondaryindicesstorethe
valuesoftheattributesusedasthesearchkeyinaB+-treefileorganization.Accessing
a record through such a secondary indexis then more expensive: Firstthe secondary
index is searched to find the B+-tree file organization search-key values, then the B+-
treefileorganizationislookeduptofindtherecords.Thecostformulaedescribedfor
secondaryindiceshavetobemodifiedappropriatelyifsuchindicesareused.
4RecallthatifB+-treefileorganizationsareusedtostorerelations,recordsmaybemovedbetweenblockswhenleaf
nodesaresplitormerged,andwhenrecordsareredistributed.

--- Page 727 ---

698 Chapter15 QueryProcessing
15.3.2 Selections Involving Comparisons
Consider a selection of the form σ (r). We can implement the selection either by
A≤v
usinglinearsearchorbyusingindicesinoneofthefollowingways:
• A5(clusteringindex,comparison).Aclusteringorderedindex(forexample,aclus-
tering B+-tree index) can be used when the selection condition is a comparison.
For comparison conditions of the form A > v or A ≥ v, a clustering index on A
canbeusedtodirecttheretrievaloftuples,asfollows:ForA ≥ v,welookupthe
valuevintheindextofindthefirsttupleinthefilethathasavalueofA ≥ v.Afile
scanstartingfromthattupleuptotheendofthefilereturnsalltuplesthatsatisfy
the condition. For A > v, the file scan starts with the first tuple such that A > v.
ThecostestimateforthiscaseisidenticaltothatforcaseA3.
ForcomparisonsoftheformA < vorA ≤ v,anindexlookupisnotrequired.
For A < v, we use a simple file scan starting from the beginning of the file, and
continuingupto(butnotincluding)thefirsttuplewithattribute A = v.Thecase
of A ≤ v is similar, except that the scan continues up to (but not including) the
firsttuplewithattributeA > v.Ineithercase,theindexisnotuseful.
• A6(secondaryindex,comparison).Wecanuseasecondaryorderedindextoguide
retrievalforcomparisonconditionsinvolving<,≤,≥,or>.Thelowest-levelindex
blocksarescanned,eitherfromthesmallestvalueuptov(for<and≤),orfrom
vuptothemaximumvalue(for>and≥).
The secondary index provides pointers to the records, but to get the actual
recordswehave tofetch the recordsbyusing the pointers. Thisstep may require
an I/O operation for each record fetched, since consecutive records may be on
differentdiskblocks;asbefore,eachI/Ooperationrequiresadiskseekandablock
transfer.Ifthenumberofretrievedrecordsislarge,usingthesecondaryindexmay
be even more expensive than using linearsearch. Therefore, the secondary index
shouldbeusedonlyifveryfewrecordsareselected.
As long as the number of matching tuples is known ahead of time, a query opti-
mizercanchoosebetweenusingasecondaryindexorusingalinearscanbasedonthe
cost estimates. However, ifthe numberof matchingtuples isnotknown accuratelyat
compilationtime,eitherchoicemayleadtobadperformance,dependingontheactual
numberofmatchingtuples.
Todealwiththeabovesituation,PostgreSQLusesahybridalgorithmthatitcallsa
bitmap index scan,5 when a secondary indexisavailable, but the numberof matching
recordsisnotknownprecisely.Thebitmapindexscanalgorithmfirstcreatesabitmap
withasmanybitsasthenumberofblocksintherelation,withallbitsinitializedto0.
Thealgorithmthenusesthesecondaryindextofindindexentriesformatchingtuples,
but instead of fetching the tuples immediately, it does the following. As each index
5Thisalgorithmshouldnotbeconfusedwithascanusingabitmapindex.

--- Page 728 ---

15.3 SelectionOperation 699
entryisfound,thealgorithmgetstheblocknumberfromtheindexentry,andsetsthe
correspondingbitinthebitmapto1.
Onceallindexentrieshavebeenprocessed,thebitmapisscannedtofindallblocks
whose bit is set to 1. These are exactly the blocks containing matching records. The
relationisthenscannedlinearly,butblockswhosebitisnotsetto1areskipped;only
blocks whose bit is set to 1 are fetched, and then a scan within each block is used to
retrieveallmatchingrecordsintheblock.
In the worst case, this algorithmis only slightlymore expensive than linearscan,
butinthebestcaseitismuchcheaperthanlinearscan.Similarly,intheworstcaseitis
onlyslightlymoreexpensivethanusingasecondaryindexscantodirectlyfetchtuples,
butinthebestcaseitismuchcheaperthanasecondaryindexscan.Thus,thishybrid
algorithm ensures that performance is never much worse than the best plan for that
databaseinstance.
A variant of this algorithm collects all the index entries, and sorts them (using
sortingalgorithmswhichwestudylaterinthischapter),andthenperformsarelation
scanthatskipsblocksthatdonothaveanymatchingentries.Usingabitmapasabove
canbecheaperthansortingtheindexentries.
15.3.3 Implementation of Complex Selections
Sofar,wehaveconsideredonlysimpleselectionconditionsoftheformAopB,where
op is an equality or comparison operation. We now consider more complex selection
predicates.
• Conjunction:Aconjunctiveselectionisaselectionoftheform:
σ (r)
θ ∧θ ∧⋯∧θ
1 2 n
• Disjunction:Adisjunctiveselectionisaselectionoftheform:
σ (r)
θ ∨θ ∨⋯∨θ
1 2 n
A disjunctive condition is satisfied by the union of all records satisfying the indi-
vidual,simpleconditionsθ.
i
• Negation: The result of a selection σ (r) is the set of tuples of r for which the
¬θ
conditionθevaluatestofalse.Intheabsenceofnulls,thissetissimplythesetof
tuplesinr thatarenotinσ (r).
θ
We can implement a selection operation involving either a conjunction or a dis-
junctionofsimpleconditionsbyusingoneofthefollowingalgorithms:
• A7 (conjunctive selection using one index). We first determine whether an access
pathisavailableforanattributeinoneofthesimpleconditions.Ifoneis,oneofthe

--- Page 729 ---

700 Chapter15 QueryProcessing
selectionalgorithmsA2throughA6canretrieverecordssatisfyingthatcondition.
Wecompletetheoperationbytesting,inthememorybuffer,whetherornoteach
retrievedrecordsatisfiestheremainingsimpleconditions.
To reduce the cost, we choose a θ and one of algorithms A1 through A6 for
i
which the combination results in the least cost for σ (r). The cost of algorithm
θ
i
A7isgivenbythecostofthechosenalgorithm.
• A8(conjunctiveselection usingcomposite index). Anappropriate composite index
(thatis,anindexonmultipleattributes)maybeavailableforsomeconjunctivese-
lections.Iftheselectionspecifiesanequalityconditionontwoormoreattributes,
and a composite index exists on these combined attribute fields, then the index
can be searched directly. The type of index determines which of algorithms A2,
A3,orA4willbeused.
• A9(conjunctiveselectionbyintersectionofidentifiers).Anotheralternativeforim-
plementing conjunctive selection operations involves the use of record pointers
orrecordidentifiers.Thisalgorithmrequiresindiceswithrecordpointers,onthe
fields involved in the individual conditions. The algorithm scans each index for
pointers to tuples that satisfy an individual condition. The intersection of all the
retrievedpointersisthesetofpointerstotuplesthatsatisfytheconjunctivecondi-
tion.Thealgorithmthenusesthepointerstoretrievetheactualrecords.Ifindices
are not available on all the individual conditions,then the algorithm tests the re-
trievedrecordsagainsttheremainingconditions.
ThecostofalgorithmA9isthesumofthecostsoftheindividualindexscans,
plus the cost of retrieving the records in the intersection of the retrieved lists of
pointers. This cost can be reduced by sorting the list of pointers and retrieving
records in the sorted order. Thereby, (1) all pointers to records in a block come
together,henceallselectedrecordsintheblockcanberetrievedusingasingleI/O
operation,and(2)blocksarereadinsortedorder,minimizingdisk-armmovement.
Section15.4describessortingalgorithms.
• A10 (disjunctive selection by union of identifiers). If access paths are available on
alltheconditionsofadisjunctiveselection,eachindexisscannedforpointersto
tuplesthatsatisfytheindividualcondition.Theunionofalltheretrievedpointers
yields the set of pointers to all tuples that satisfy the disjunctive condition. We
thenusethepointerstoretrievetheactualrecords.
However,ifevenoneoftheconditionsdoesnothaveanaccesspath,wehave
to perform a linear scan of the relation to find tuples that satisfy the condition.
Therefore, if there is even one such condition in the disjunct, the most efficient
accessmethodisalinearscan,withthedisjunctiveconditiontestedoneachtuple
duringthescan.
The implementation of selections with negation conditions is left to you as an
exercise(PracticeExercise15.6).

--- Page 730 ---

15.4 Sorting 701
15.4 Sorting
Sortingofdataplaysanimportantroleindatabasesystemsfortworeasons.First,SQL
queriescanspecifythattheoutputbesorted.Second,andequallyimportantforquery
processing,several ofthe relationaloperations, such asjoins, canbe implementedef-
ficiently if the input relations are first sorted. Thus, we discuss sorting here before
discussingthejoinoperationinSection15.5.
We can sort a relation by building an index on the sort key and then using that
indextoreadtherelationinsortedorder.However,suchaprocessorderstherelation
only logically, through an index, rather than physically. Hence, the reading of tuples
in the sorted order may lead to a disk access (disk seek plus block transfer) for each
record,whichcanbeveryexpensive,sincethenumberofrecordscanbe muchlarger
than the number of blocks. For this reason, it may be desirable to order the records
physically.
The problem of sorting has been studied extensively, both for relations that fit
entirely in main memory and for relations that are bigger than memory. In the first
case,standardsortingtechniquessuchasquick-sortcanbeused.Here,wediscusshow
tohandlethesecondcase.
15.4.1 External Sort-Merge Algorithm
Sortingofrelationsthatdonotfitinmemoryiscalledexternalsorting.Themostcom-
monly used technique for external sorting is the external sort–merge algorithm. We
describe the external sort–merge algorithm next. Let M denote the number of blocks
in the main memory buffer available for sorting, that is, the number of disk blocks
whosecontentscanbebufferedinavailablemainmemory.
1. In the first stage, a number of sorted runs are created; each run is sorted but
containsonlysomeoftherecordsoftherelation.
i=0;
repeat
readM blocksoftherelation,ortherestoftherelation,
whicheverissmaller;
sortthein-memorypartoftherelation;
writethesorteddatatorunfileR;
i
i=i+1;
untiltheendoftherelation
2. Inthesecondstage,therunsaremerged.Suppose,fornow,thatthetotalnumber
ofruns,N,islessthanM,sothatwecanallocateoneblocktoeachrunandhave
spacelefttoholdoneblockofoutput.Themergestageoperatesasfollows:

--- Page 731 ---

702 Chapter15 QueryProcessing
readoneblockofeachoftheN filesR intoabufferblockinmemory;
i
repeat
choosethefirsttuple(insortorder)amongallbufferblocks;
writethetupletotheoutput,anddeleteitfromthebufferblock;
ifthebufferblockofanyrunR isemptyandnotend-of-file(R)
i i
thenreadthenextblockofR intothebufferblock;
i
untilallinputbufferblocksareempty
Theoutputofthemergestage isthesortedrelation.Theoutputfileisbufferedto
reducethenumberofdiskwriteoperations.Theprecedingmergeoperationisagener-
alizationofthetwo-waymergeusedbythestandardin-memorysort–mergealgorithm;
itmergesN runs,soitiscalledanN-waymerge.
In general, if the relation is much larger than memory, there may be M or more
runsgeneratedinthefirststage,anditisnotpossibletoallocateablockforeachrun
duringthemergestage.Inthiscase,themergeoperationproceedsinmultiplepasses.
SincethereisenoughmemoryforM−1inputbufferblocks,eachmergecantakeM−1
runsasinput.
Theinitialpassfunctionsinthisway:ItmergesthefirstM −1runs(asdescribed
in item 2 above) to geta single run forthe next pass. Then,itmerges the next M −1
runs similarly, and so on, until it has processed all the initial runs. At this point, the
numberofrunshasbeenreducedbyafactorofM −1.Ifthisreducednumberofruns
is still greater than or equal to M, anotherpass is made, with the runs created by the
first pass as input. Each pass reduces the number of runs by a factor of M −1. The
passesrepeatasmanytimesasrequired,untilthenumberofrunsislessthanM;afinal
passthengeneratesthesortedoutput.
Figure15.4illustratesthestepsoftheexternalsort–mergeforanexamplerelation.
Forillustrationpurposes,weassumethatonlyonetuplefitsinablock(f = 1),andwe
r
assume that memory holds at most three blocks. During the merge stage, two blocks
areusedforinputandoneforoutput.
15.4.2 Cost Analysis of External Sort-Merge
We compute the disk-access cost for the external sort–merge in this way: Let
b denote the number of blocks containing records of relation r. The first stage
r
readseveryblockoftherelationandwritesthemoutagain,givingatotalof2b block
r
transfers. The initial number of runs is ⌈b ∕M⌉. During the merge pass, reading in
r
eachrunoneblockatatimeleadstoalargenumberofseeks;toreducethenumberof
seeks,alargernumberofblocks,denotedb ,arereadorwrittenatatime,requiringb
b b
bufferblockstobeallocatedtoeachinputrunandtotheoutputrun.Then,⌊M∕b ⌋−1
b
runscanbe mergedineachmergepass, decreasingthenumberofrunsbyafactorof
⌊M∕b ⌋−1.Thetotalnumberofmergepassesrequiredis⌈log (b ∕M)⌉.Each
b ⌊M∕b ⌋−1 r
b
ofthesepassesreadseveryblockoftherelationonceandwritesitoutonce,withtwo
exceptions.First,thefinalpasscanproducethesortedoutputwithoutwritingitsresult

--- Page 732 ---

15.4 Sorting 703
a 19
a 19
g 24 d 31 a 14
b 14
a 19 g 24 a 19
c 33
d 31 b 14
b 14 d 31
c 33 c 33
c 33 e 16
b 14 d 7
e 16 g 24
e 16 d 21
r 16 d 31
d 21
a 14
d 21 e 16
m 3
d 7
m 3 g 24
r 16
d 21
p 2 m 3
m 3
d 7 a 14 p 2
p 2
a 14 d 7 r 16
r 16
p 2
initial sorted
relation runs runs output
create merge merge
runs pass–1 pass–2
Figure 15.4 Externalsortingusingsort–merge.
to disk. Second, there may be runs that are not read in or written out during a pass
—for example, ifthere are ⌊M∕b ⌋ runs to be merged in a pass, ⌊M∕b ⌋−1are read
b b
in and merged, and one run is not accessed during the pass. Ignoring the (relatively
small)savingsdue tothelattereffect,thetotal numberof blocktransfers forexternal
sortingoftherelationis:
b (2⌈log (b ∕M)⌉+1)
r ⌊M∕b ⌋−1 r
b
ApplyingthisequationtotheexampleinFigure15.4,withb setto1,wegetatotalof
b
12 ∗ (4+1) = 60 block transfers, as you can verify from the figure. Note that these
abovenumbersdonotincludethecostofwritingoutthefinalresult.
Wealsoneedtoaddthedisk-seekcosts.Rungenerationrequiresseeksforreading
data for each of the runs as well as for writing the runs. Each merge pass requires
around⌈b ∕b ⌉seeksforreadingdata.6 Althoughtheoutputiswrittensequentially,if
r b
itisonthesamediskastheinputruns,theheadmayhavemovedawaybetweenwrites
of consecutive blocks. Thus we would have to add a total of 2⌈b ∕b ⌉ seeks for each
r b
merge pass, exceptthe finalpass (since we assume thefinal resultisnotwritten back
todisk).
6Tobemoreprecise,sincewereadeachrunseparatelyandmaygetfewerthanb blockswhenreadingtheendofa
b
run,wemayrequireanextraseekforeachrun.Weignorethisdetailforsimplicity.

--- Page 733 ---

704 Chapter15 QueryProcessing
2⌈b ∕M⌉+⌈b ∕b ⌉(2⌈log (b ∕M)⌉−1)
r r b ⌊M∕b ⌋−1 r
b
Applying this equation to the example in Figure 15.4, we get a total of 8+12 ∗ (2 ∗
2−1) = 44diskseeksifwesetthenumberofbufferblocksperrunb to1.
b
15.5 Join Operation
Inthissection,westudyseveralalgorithmsforcomputingthejoinofrelations,andwe
analyzetheirrespectivecosts.
Weusethetermequi-jointorefertoajoinoftheformr ⋈ s,whereAandB
r.A=s.B
areattributesorsetsofattributesofrelationsr ands,respectively.
Weuseasarunningexampletheexpression:
student ⋈ takes
usingthe same relationschemasthatweused in Chapter2. We assume the following
informationaboutthetworelations:
• Numberofrecordsofstudent:n = 5000.
student
• Numberofblocksofstudent:b = 100.
student
• Numberofrecordsoftakes:n = 10,000.
takes
• Numberofblocksoftakes:b = 400.
takes
15.5.1 Nested-Loop Join
Figure15.5showsasimplealgorithmtocomputethethetajoin,r ⋈ s,oftworelations
θ
rands.Thisalgorithmiscalledthenested-loopjoinalgorithm,sinceitbasicallyconsists
of a pair of nested for loops. Relation r is called the outer relation and relation s the
inner relation of the join, since the loop for r encloses the loop for s. The algorithm
usesthenotationt ⋅t ,wheret andt aretuples;t ⋅t denotesthetupleconstructed
r s r s r s
byconcatenatingtheattributevaluesoftuplest andt .
r s
Likethelinearfile-scanalgorithmforselection,thenested-loopjoinalgorithmre-
quiresnoindices,anditcanbeusedregardlessofwhatthejoinconditionis.Extending
thealgorithmtocomputethenaturaljoinisstraightforward,sincethenaturaljoincan
beexpressedasathetajoinfollowedbyeliminationofrepeatedattributesbyaprojec-
tion.Theonlychangerequiredisanextrastepofdeletingrepeatedattributesfromthe
tuplet ⋅t ,beforeaddingittotheresult.
r s
Thenested-loopjoinalgorithmisexpensive,sinceitexamineseverypairoftuples
inthetworelations.Considerthecostofthenested-loopjoinalgorithm.Thenumber
ofpairsoftuplestobeconsideredisn ∗ n ,wheren denotesthenumberoftuplesin
r s r
r, and n denotes the number of tuples ins. Foreach record inr, we have to perform
s

--- Page 734 ---

15.5 JoinOperation 705
foreachtuplet inrdobegin
r
foreachtuplet insdobegin
s
testpair(t ,t )toseeiftheysatisfythejoinconditionθ
r s
iftheydo,addt ⋅t totheresult;
r s
end
end
Figure 15.5 Nested-loopjoin.
a complete scan on s. In the worst case, the buffer can hold only one block of each
relation,andatotalofn ∗ b +b blocktransferswouldberequired,whereb andb
r s r r s
denote the number of blocks containing tuples of r and s, respectively. We need only
one seek for eachscan on the innerrelationssince itisreadsequentially, and atotal
ofb seekstoreadr,leadingtoatotalofn +b seeks.Inthebestcase,thereisenough
r r r
spaceforbothrelationstofitsimultaneouslyinmemory,soeachblockwouldhaveto
be read only once; hence, only b +b block transfers would be required, along with
r s
twoseeks.
If one of the relations fits entirely in main memory, it is beneficial to use that
relation as the inner relation, since the inner relation would then be read only once.
Therefore,ifsissmallenoughtofitinmainmemory,ourstrategyrequiresonlyatotal
b +b block transfers and two seeks—the same cost as that for the case where both
r s
relationsfitinmemory.
Nowconsiderthenaturaljoinofstudent andtakes.Assumefornowthatwehave
no indices whatsoever on either relation, and that we are not willing to create any
index. We can use the nested loops to compute the join; assume that student is the
outerrelationandtakesistheinnerrelationinthejoin.Wewillhavetoexamine5000
∗ 10,000 = 50 ∗ 106 pairs of tuples. In the worst case, the number of block transfers
is 5000 ∗ 400 + 100 = 2,000,100, plus 5000 + 100 = 5100 seeks. In the best-case
scenario,however,wecanreadbothrelationsonlyonceandperformthecomputation.
This computation requires at most 100 +400 = 500 block transfers, plus two seeks
—a significant improvement over the worst-case scenario. If we had used takes as the
relation for the outer loop and student for the inner loop, the worst-case cost of our
final strategy would have been 10,000 ∗ 100+400 = 1,000,400 block transfers, plus
10,400diskseeks.Thenumberofblocktransfersissignificantlyless,andalthoughthe
number of seeks is higher, the overall cost is reduced, assuming t = 4 milliseconds
S
andt =0.1milliseconds.
T
15.5.2 Block Nested-Loop Join
Ifthebufferistoosmalltoholdeitherrelationentirelyinmemory,wecanstillobtain
amajorsavinginblockaccessesifweprocesstherelationsonaper-blockbasis,rather

--- Page 735 ---

706 Chapter15 QueryProcessing
thanonaper-tuplebasis.Figure15.6showsblocknested-loopjoin,whichisavariantof
thenested-loopjoinwhereeveryblockoftheinnerrelationispairedwitheveryblock
oftheouterrelation.Withineachpairofblocks,everytupleinoneblockispairedwith
every tuple in the other block, to generate all pairs of tuples. As before, all pairs of
tuplesthatsatisfythejoinconditionareaddedtotheresult.
The primary difference in cost between the block nested-loop join and the basic
nested-loopjoinisthat,intheworstcase,eachblockintheinnerrelationsisreadonly
once for each block in the outer relation, instead of once for each tuple in the outer
relation. Thus, in the worst case, there will be a total of b ∗ b + b block transfers,
r s r
whereb andb denotethenumberofblockscontainingrecordsofrands,respectively.
r s
Each scan of the inner relation requires one seek, and the scan of the outer relation
requires one seek per block, leading to a total of 2 ∗ b seeks. It is more efficient to
r
use the smaller relation as the outer relation, in case neither of the relations fits in
memory.Inthebestcase,wheretheinnerrelationfitsinmemory,therewillbeb +b
r s
block transfers and just two seeks (we would choose the smaller relation as the inner
relationinthiscase).
Nowreturntoourexampleofcomputingstudent ⋈ takes,usingtheblocknested-
loopjoinalgorithm.Intheworstcase,wehavetoreadeachblockoftakesonceforeach
block of student. Thus, in the worst case, a total of 100 ∗ 400+100 = 40,100 block
transfersplus2 ∗ 100 = 200seeksarerequired.Thiscostisasignificantimprovement
overthe5000 ∗ 400+100 =2,000,100blocktransfersplus5100seeksneededinthe
worstcaseforthebasicnested-loopjoin.Thebest-casecostremainsthesame—namely,
100+400 = 500blocktransfersandtwoseeks.
Theperformanceofthenested-loopandblocknested-loopprocedurescanbefur-
therimproved:
foreachblockB ofrdobegin
r
foreachblockB ofsdobegin
s
foreachtuplet inB dobegin
r r
foreachtuplet inB dobegin
s s
testpair(t ,t )toseeiftheysatisfythejoincondition
r s
iftheydo,addt ⋅t totheresult;
r s
end
end
end
end
Figure 15.6 Blocknested-loopjoin.

--- Page 736 ---

15.5 JoinOperation 707
• Ifthejoinattributesinanaturaljoinoranequi-joinformakeyontheinnerrela-
tion,thenforeachouterrelationtupletheinnerloopcanterminateassoonasthe
firstmatchisfound.
• In the block nested-loop algorithm, instead of using disk blocks as the blocking
unitfortheouterrelation,wecanusethebiggestsizethatcanfitinmemory,while
leavingenoughspaceforthebuffersoftheinnerrelationandtheoutput.Inother
words,ifmemoryhasM blocks,wereadinM −2blocksoftheouterrelationat
a time, and when we read each block of the inner relation we join it with all the
M −2 blocks of the outer relation. This change reduces the number of scans of
the inner relation from b to ⌈b ∕(M −2)⌉, where b is the number of blocks of
r r r
the outer relation. The total cost is then ⌈b ∕(M −2)⌉ ∗ b +b block transfers
r s r
and2⌈b ∕(M −2)⌉seeks.
r
• We can scan the inner loop alternately forward and backward. This scanning
methodorderstherequestsfordiskblockssothatthedataremaininginthebuffer
fromthepreviousscancanbereused,thusreducingthenumberofdiskaccesses
needed.
• Ifanindexisavailableontheinnerloop’sjoinattribute,wecanreplacefilescans
withmoreefficientindexlookups.Section15.5.3describesthisoptimization.
15.5.3 Indexed Nested-Loop Join
In a nested-loop join (Figure 15.5), if an index is available on the inner loop’s join
attribute,indexlookupscanreplacefilescans.Foreachtuplet intheouterrelationr,
r
theindexisusedtolookuptuplesinsthatwillsatisfythejoinconditionwithtuplet .
r
Thisjoinmethodiscalledanindexednested-loopjoin;itcanbeusedwithexisting
indices,aswellaswithtemporaryindicescreatedforthesolepurposeofevaluatingthe
join.
Looking up tuples in s that will satisfy the join conditions with a given tuple t is
r
essentially a selection on s. For example, consider student ⋈ takes. Suppose that we
haveastudent tuplewithID“00128”. Then,therelevanttuplesintakesarethosethat
satisfytheselection“ID=00128”.
Thecostofanindexednested-loopjoincanbecomputedasfollows:Foreachtuple
intheouterrelationr,alookupisperformedontheindexfors,andtherelevanttuples
areretrieved.Intheworstcase,thereisspaceinthebufferforonlyoneblockofr and
oneblockoftheindex.Then,b I/Ooperationsareneededtoreadrelationr,whereb
r r
denotes the number of blocks containingrecords of r; each I/O requires a seek and a
blocktransfer,sincethediskheadmayhavemovedinbetweeneachI/O.Foreachtuple
inr,weperforman indexlookup ons.Then,thecostofthejoincanbe computedas
b (t +t )+n ∗ c,wheren isthenumberofrecordsinrelationr,andcisthecostof
r T S r r
a single selection on s using the join condition. We have seen in Section 15.3 how to
estimatethecostofasingleselectionalgorithm(possiblyusingindices);thatestimate
givesusthevalueofc.

--- Page 737 ---

708 Chapter15 QueryProcessing
Thecostformulaindicatesthat,ifindicesareavailableonbothrelationsrands,it
isgenerallymostefficienttousetheonewithfewertuplesastheouterrelation.
Forexample,consideranindexednested-loopjoinofstudent ⋈ takes,withstudent
astheouterrelation.SupposealsothattakeshasaclusteringB+-treeindexonthejoin
attributeID,whichcontains20entriesonaverageineachindexnode.Sincetakeshas
10,000 tuples, the height of the tree is 4, and one more access is needed to find the
actual data. Since n is 5000, the total cost is 100 + 5000 ∗ 5 = 25,100 disk
student
accesses, each of which requires a seek and a block transfer. In contrast, as we saw
before,40,100blocktransfersplus200seekswereneededforablocknested-loopjoin.
Although the number of block transfers has been reduced, the seek cost has actually
increased,increasingthetotalcostsinceaseekisconsiderablymoreexpensivethana
blocktransfer. However,ifwehadaselectionon thestudent relationthatreducesthe
numberofrowssignificantly,indexednested-loopjoincouldbesignificantlyfasterthan
blocknested-loopjoin.
15.5.4 Merge Join
The merge-join algorithm (also called the sort-merge-join algorithm) can be used to
computenaturaljoinsandequi-joins.Letr(R)ands(S)betherelationswhosenatural
join istobe computed, and letR ∩ S denote theircommonattributes. Suppose that
bothrelationsaresortedontheattributesR ∩ S.Then,theirjoincanbecomputedby
aprocessmuchlikethemergestageinthemerge–sortalgorithm.
15.5.4.1 Merge-JoinAlgorithm
Figure 15.7 shows the merge-join algorithm. In the algorithm, JoinAttrs refers to the
attributesinR∩S,andt ⋈ t ,wheret andt aretuplesthathavethesamevaluesfor
r s r s
JoinAttrs,denotestheconcatenationoftheattributesofthetuples,followedbyproject-
ingoutrepeatedattributes.Themerge-joinalgorithmassociatesonepointerwitheach
relation. These pointers point initiallyto the first tuple of the respective relations. As
the algorithm proceeds, the pointers move through the relation. A group of tuples of
one relation with the same value on the join attributes is read into S . The algorithm
s
in Figure 15.7 requires that every set of tuples S fit in main memory; we discuss ex-
s
tensions of the algorithm to avoid this requirement shortly. Then, the corresponding
tuples(ifany)oftheotherrelationarereadinandareprocessedastheyareread.
Figure 15.8 shows two relations that are sorted on their join attribute a1. It is
instructivetogothroughthestepsofthemerge-joinalgorithmontherelationsshown
inthefigure.
Themerge-joinalgorithmofFigure15.7requiresthateachsetS ofalltupleswith
s
the same value for the join attributes must fit in main memory. Thisrequirementcan
usuallybemet,eveniftherelationsislarge.Iftherearesomejoinattributevaluesfor

--- Page 738 ---

15.5 JoinOperation 709
pr:=addressoffirsttupleofr;
ps:=addressoffirsttupleofs;
while(ps≠nullandpr≠null)do
begin
t :=tupletowhichpspoints;
s
S :={t };
s s
setpstopointtonexttupleofs;
done:=false;
while(notdoneandps≠null)do
begin
t ′ :=tupletowhichpspoints;
s
if(t ′[JoinAttrs] = t [JoinAttrs])
s s
thenbegin
S :=S ∪{t ′};
s s s
setpstopointtonexttupleofs;
end
elsedone:=true;
end
t :=tupletowhichprpoints;
r
while(pr ≠nullandt [JoinAttrs] < t [JoinAttrs])do
r s
begin
setprtopointtonexttupleofr;
t :=tupletowhichprpoints;
r
end
while(pr ≠nullandt [JoinAttrs] = t [JoinAttrs])do
r s
begin
foreacht inS do
s s
begin
addt ⋈ t toresult;
s r
end
setprtopointtonexttupleofr;
t :=tupletowhichprpoints;
r
end
end.
Figure 15.7 Mergejoin.
which S is larger than available memory, a block nested-loop join can be performed
s
forsuchsetsS ,matchingthemwithcorrespondingblocksoftuplesinrwiththesame
s
valuesforthejoinattributes.

--- Page 739 ---

710 Chapter15 QueryProcessing
a1 a2 a1 a3
pr ps
a 3 a A
b 1 b G
d 8 c L
d 13 d N
f 7 m B
m 5 s
q 6
r
Figure 15.8 Sortedrelationsformergejoin.
Ifeitheroftheinputrelationsrandsisnotsortedonthejoinattributes,theycanbe
sortedfirst,andthenthemerge-joinalgorithmcanbeused.Themerge-joinalgorithm
canalsobeeasilyextendedfromnaturaljoinstothemoregeneralcaseofequi-joins.
15.5.4.2 CostAnalysis
Oncetherelationsareinsortedorder,tupleswiththesamevalueonthejoinattributes
areinconsecutiveorder.Thereby,eachtupleinthesortedorderneedstobereadonly
once, and, as a result, each block is also read only once. Since it makes only a single
passthroughbothfiles(assumingallsetsS fitinmemory),themerge-joinmethodis
s
efficient;thenumberofblocktransfersisequaltothesumofthenumberofblocksin
bothfiles,b +b .
r s
Assumingthatb buffer blocks are allocatedto eachrelation,the numberof disk
b
seeks required would be ⌈b ∕b ⌉ + ⌈b ∕b ⌉ disk seeks. Since seeks are much more
r b s b
expensive thandatatransfer, itmakessense toallocatemultiplebufferblockstoeach
relation,providedextramemoryisavailable.Forexample,witht = 0.1milliseconds
T
per 4-kilobyte block, and t = 4 milliseconds, the buffer size is 400 blocks (or 1.6
S
megabytes), so the seek time would be 4 milliseconds for every 40 milliseconds of
transfertime;inotherwords,seektimewouldbejust10percentofthetransfertime.
Ifeitheroftheinputrelationsrandsisnotsortedonthejoinattributes,theymust
besortedfirst;thecostofsortingmustthenbeaddedtotheabovecosts.Ifsomesets
S donotfitinmemory,thecostwouldincreaseslightly.
s
Suppose the merge-join scheme is applied to our example of student ⋈ takes.
ThejoinattributehereisID.Suppose thattherelationsarealreadysortedonthejoin
attributeID.Inthiscase,themergejointakesatotalof400+100 = 500blocktransfers.
If we assume that in the worst case only one buffer block is allocated to each input
relation(thatis,b = 1),atotalof400+100 = 500seekswouldalsoberequired;in
b
realityb canbesetmuchhighersinceweneedtobufferblocksforonlytworelations,
b
andtheseekcostwouldbesignificantlyless.

--- Page 740 ---

15.5 JoinOperation 711
Suppose therelationsarenotsorted,andthememorysizeistheworstcase,only
threeblocks.Thecostisasfollows:
1. Using the formulae that we developed in Section 15.4, we can see that sorting
relation takes requires ⌈log (400∕3)⌉ = 8 merge passes. Sorting of relation
3−1
takesthentakes400 ∗ (2⌈log (400∕3)⌉+1),or6800, blocktransfers, with
3−1
400 more transfers to write out the result. The number of seeks required is 2 ∗
⌈400∕3⌉+400 ∗ (2 ∗ 8−1)or6268seeksforsorting,and400seeksforwriting
theoutput, foratotalof6668 seeks, sinceonlyone bufferblockisavailablefor
eachrun.
2. Similarly, sorting relation student takes ⌈log (100∕3)⌉ = 6 merge passes and
3−1
100 ∗ (2⌈log (100∕3)⌉+1),or1300,blocktransfers,with100moretransfers
3−1
towriteitout.Thenumberofseeksrequiredforsortingstudentis2 ∗ ⌈100∕3⌉+
100 ∗ (2 ∗ 6−1) = 1168,and100seeksarerequiredforwritingtheoutput,for
atotalof1268seeks.
3. Finally,mergingthetworelationstakes400+100 = 500blocktransfersand500
seeks.
Thus, the total cost is 9100 block transfers plus 8932 seeks if the relations are not
sorted,andthememorysizeisjust3blocks.
Withamemorysizeof25blocks,andtherelationsnotsorted,thecostofsorting
followedbymergejoinwouldbeasfollows:
1. Sortingtherelationtakescanbedonewithjustonemergestepandtakesatotal
of just 400 ∗ (2⌈log (400∕25)⌉+1) = 1200 block transfers. Similarly,sorting
24
studenttakes300blocktransfers.Writingthesortedoutputtodiskrequires400
+ 100 = 500 block transfers, and the merge step requires 500 block transfers
to read the data back. Adding up these costs gives a total cost of 2500 block
transfers.
2. Ifweassumethatonlyonebufferblockisallocatedforeachrun,thenumberof
seeksrequiredinthiscaseis2 ∗ ⌈400∕25⌉+400+400 = 832seeksforsorting
takesandwritingthesortedoutputtodisk,andsimilarly2 ∗ ⌈100∕25⌉+100+
100 = 208 for student, plus 400+100 seeks for reading the sorted data in the
merge-joinstep.Addingupthesecostsgivesatotalcostof1640seeks.
Thenumberofseekscanbesignificantlyreducedbysettingasidemorebuffer
blocks for each run. For example, if 5 buffer blocks are allocated for each run
and for the output from merging the 4 runs of student, the cost is reduced to
2 ∗ ⌈100∕25⌉+⌈100∕5⌉+⌈100∕5⌉ = 48seeks, from208seeks.Ifthemerge-
join step sets aside 12 blocks each for buffering takes and student, the number
ofseeksforthemerge-joinstepgoesdownto⌈400∕12⌉+⌈100∕12⌉ = 43,from
500.Thetotalnumberofseeksisthen251.

--- Page 741 ---

712 Chapter15 QueryProcessing
Thus,thetotalcostis2500blocktransfersplus251seeksiftherelationsarenotsorted,
andthememorysizeis25blocks.
15.5.4.3 HybridMergeJoin
Itispossibletoperformavariationofthemerge-joinoperationonunsorted tuples,if
secondaryindicesexistonbothjoinattributes.Thealgorithmscanstherecordsthrough
the indices, resulting in their being retrieved in sorted order. This variation presents
a significant drawback, however, since records may be scattered throughout the file
blocks.Hence,eachtupleaccesscouldinvolveaccessingadiskblock,andthatiscostly.
Toavoidthiscost,wecanuseahybridmerge-jointechniquethatcombinesindices
withmergejoin.Supposethatoneoftherelationsissorted;theotherisunsorted,but
has a secondary B+-tree index on the join attributes. The hybrid merge-join algorithm
merges the sorted relation with the leaf entries of the secondary B+-tree index. The
result file contains tuples from the sorted relation and addresses for tuples of the un-
sortedrelation.Theresultfileisthensortedontheaddressesoftuplesoftheunsorted
relation,allowingefficientretrievalofthecorrespondingtuples,inphysicalstorageor-
der,tocompletethejoin.Extensionsofthetechniquetohandletwounsortedrelations
areleftasanexerciseforyou.
15.5.5 Hash Join
Likethemerge-joinalgorithm,thehash-joinalgorithmcanbeusedtoimplementnatu-
raljoinsandequi-joins.Inthehash-joinalgorithm,ahashfunctionhisusedtopartition
tuplesofbothrelations.Thebasicideaistopartitionthetuplesofeachoftherelations
intosetsthathavethesamehashvalueonthejoinattributes.
Weassumethat:
• h is a hash function mapping JoinAttrs values to {0, 1,…,n }, where JoinAttrs
h
denotesthecommonattributesofr andsusedinthenaturaljoin.
• r , r ,…,r denote partitions of r tuples, each initiallyempty. Each tuple t ∈ r
0 1 n r
h
isputinpartitionr,wherei = h(t [JoinAttrs]).
i r
• s ,s ,...,s denotepartitionsofstuples,eachinitiallyempty.Eachtuplet ∈ sis
0 1 n s
h
putinpartitions,wherei =h(t [JoinAttrs]).
i s
The hash function h should have the “goodness” properties of randomness and uni-
formity that we discussed in Chapter 14. Figure 15.9 depicts the partitioning of the
relations.
15.5.5.1 Basics
Theideabehindthehash-joinalgorithmisthis:Supposethatanrtupleandanstuple
satisfythejoincondition;then,theyhavethesamevalueforthejoinattributes.Ifthat
valueishashedtosomevaluei,thertuplehastobeinr andthestupleins.Therefore,
i i

--- Page 742 ---

15.5 JoinOperation 713
0
0
. 1 1
.
.
.
.
2 2 .
.
.
3 3
s
4 4
r
partitions partitions
of r of s
Figure 15.9 Hashpartitioningofrelations.
rtuplesinr needonlybecomparedwithstuplesins;theydonotneedtobecompared
i i
withstuplesinanyotherpartition.
For example, if d is a tuple in student, c a tuple in takes, and h a hash function
on the ID attributes of the tuples, then d and c must be tested only if h(c) = h(d). If
h(c) ≠ h(d),thencanddmusthavedifferentvaluesforID.However,ifh(c) = h(d),we
musttest canddtoseewhetherthevaluesintheirjoin attributesarethe same,since
itispossiblethatcanddhavedifferentiidsthathavethesamehashvalue.
Figure 15.10 shows the details of the hash-join algorithm to compute the natural
joinofrelationsrands.Asinthemerge-joinalgorithm,t ⋈ t denotestheconcatena-
r s
tionoftheattributesoftuplest andt ,followedbyprojectingoutrepeatedattributes.
r s
After the partitioning of the relations,the rest of the hash-join code performs asepa-
rateindexednested-loopjoinoneachofthepartitionpairsi,fori = 0,…,n .Todoso,
h
itfirstbuildsahashindexoneachs,andthenprobes(thatis,looksups)withtuples
i i
fromr.Therelationsisthebuildinput,andr istheprobeinput.
i
The hash indexon s isbuiltin memory,so thereisno needto accessthe diskto
i
retrieve the tuples. The hash function used to build this hash index must be different
fromthehashfunctionhusedearlier,butitisstillappliedtoonlythejoinattributes.In
thecourseoftheindexednested-loopjoin,thesystem usesthishashindextoretrieve
recordsthatmatchrecordsintheprobeinput.
Thebuildandprobephasesrequireonlyasinglepassthroughboththebuildand
probeinputs.Itisstraightforwardtoextendthehash-joinalgorithmtocomputegeneral
equi-joins.
Thevaluen mustbechosentobelargeenoughsuchthat,foreachi,thetuplesin
h
the partition s of the build relation,along with the hash index on the partition, fit in
i
memory.Itisnotnecessaryforthepartitionsoftheproberelationtofitinmemory.Itis

--- Page 743 ---

714 Chapter15 QueryProcessing
/*Partitions*/
foreachtuplet insdobegin
s
i:=h(t [JoinAttrs]);
s
H :=H ∪ {t };
s s s
i i
end
/*Partitionr */
foreachtuplet inrdobegin
r
i:=h(t [JoinAttrs]);
r
H :=H ∪{t };
r r r
i i
end
/*Performjoinoneachpartition*/
fori:=0ton dobegin
h
readH andbuildanin-memoryhashindexonit;
s
i
foreachtuplet inH dobegin
r r
i
probethehashindexonH tolocatealltuplest
s s
i
suchthatt [JoinAttrs] = t [JoinAttrs];
s r
foreachmatchingtuplet inH dobegin
s s
addt ⋈ t totheresult; i
r s
end
end
end
Figure 15.10 Hashjoin.
besttousethesmallerinputrelationasthebuildrelation.Ifthesizeofthebuildrelation
isb blocks,then,foreachofthen partitionstobeofsizelessthanorequaltoM,n
s h h
mustbeatleast⌈b ∕M⌉.Morepreciselystated,wehavetoaccountfortheextraspace
s
occupied by the hash index on the partition as well, so n should be correspondingly
h
larger.Forsimplicity,wesometimesignorethespacerequirementofthehashindexin
ouranalysis.
15.5.5.2 RecursivePartitioning
Ifthevalueofn isgreaterthanorequaltothenumberofblocksofmemory,therela-
h
tions cannot be partitioned in one pass, since there will not be enough buffer blocks.
Instead, partitioning has to be done in repeated passes. In one pass, the input can be
split into at most as many partitions as there are blocks available for use as output
buffers.Eachbucketgeneratedbyonepassisseparatelyreadinandpartitionedagain
in the next pass, to create smaller partitions. The hash function used in a pass is dif-
ferentfromtheone used inthepreviouspass. Thesystem repeatsthissplittingofthe

--- Page 744 ---

15.5 JoinOperation 715
inputuntileachpartitionofthebuildinputfitsinmemory.Suchpartitioningiscalled
recursivepartitioning.
A relation does not need recursive partitioning if M √ > n h + 1, or equivalently
M > (b ∕M)+1,whichsimplifies(approximately)toM > b .Forexample,consider
s s
amemorysizeof12megabytes,dividedinto4-kilobyteblocks;itwouldcontainatotal
of 3-kilobyte (3072) blocks. We can use a memory of this size to partition relations
ofsizeupto3-kilobyte∗3-kilobyte√blocks,whichis36gigabytes.Similarly,arelation
ofsize1gigabyterequiresjustover 256K blocks,or2megabytes,toavoidrecursive
partitioning.
15.5.5.3 HandlingofOverflows
Hash-table overflow occurs in partition i of the build relation s if the hash index on s
i
islargerthanmainmemory.Hash-tableoverflowcanoccuriftherearemanytuplesin
the build relation with the same values for the join attributes, or if the hash function
does not have the properties of randomness and uniformity. In either case, some of
the partitions will have more tuples than the average, whereas others will have fewer;
partitioningisthensaidtobeskewed.
Wecanhandleasmallamountofskewbyincreasingthenumberofpartitionsso
that the expected size of each partition (includingthe hash index on the partition) is
somewhatlessthanthesizeofmemory.Thenumberofpartitionsisthereforeincreased
byasmallvalue,calledthefudgefactor,thatisusuallyabout20percentofthenumber
ofhashpartitionscomputedasdescribedinSection15.5.5.
Evenif,byusingafudgefactor,weareconservativeonthesizesofthepartitions,
overflows can still occur. Hash-table overflows can be handled by either overflow reso-
lutionoroverflowavoidance.Overflowresolutionisperformedduringthebuildphaseif
a hash-index overflow is detected. Overflow resolution proceeds in this way: If s, for
i
anyi,isfoundtobetoolarge,itisfurtherpartitionedintosmallerpartitionsbyusing
adifferenthashfunction.Similarly,r isalsopartitionedusingthenewhashfunction,
i
andonlytuplesinthematchingpartitionsneedtobejoined.
Incontrast,overflowavoidanceperformsthepartitioningcarefully,sothatoverflows
neveroccurduringthebuildphase.Inoverflowavoidance,thebuildrelationsisinitially
partitionedintomanysmallpartitions,andthensomepartitionsarecombinedinsuch
awaythateachcombinedpartitionfitsinmemory.Theproberelationr ispartitioned
inthesamewayasthecombinedpartitionsons,butthesizesofr donotmatter.
i
If a large number of tuples in s have the same value for the join attributes, the
resolutionandavoidancetechniquesmayfailonsomepartitions.Inthatcase,instead
ofcreatinganin-memoryhashindexandusinganested-loopjointojointhepartitions,
wecanuseotherjointechniques,suchasblocknested-loopjoin,onthosepartitions.
15.5.5.4 CostofHashJoin
We now consider the cost of a hash join. Our analysis assumes that there is no hash-
tableoverflow.First,considerthecasewhererecursivepartitioningisnotrequired.

--- Page 745 ---

716 Chapter15 QueryProcessing
• The partitioning of the two relations r and s callsfor a complete reading of both
relationsandasubsequentwritingbackofthem.Thisoperationrequires2(b +b )
r s
block transfers, where b and b denote the number of blocks containingrecords
r s
of relations r and s, respectively. The build and probe phases read each of the
partitions once, calling for further b +b block transfers. The number of blocks
r s
occupiedbypartitionscouldbeslightlymorethanb +b ,asaresultofpartially
r s
filledblocks.Accessingsuchpartiallyfilledblockscanaddanoverheadofatmost
2n foreachoftherelations,sinceeachofthen partitionscouldhaveapartially
h h
filledblockthathastobewrittenandreadback.Thus,ahashjoinisestimatedto
require:
3(b +b )+4n
r s h
block transfers. The overhead 4n is usually quite small compared to b +b and
h r s
canbeignored.
• Assumingb blocksareallocatedfortheinputbufferandeachoutputbuffer,parti-
b
tioningrequiresatotalof2(⌈b ∕b ⌉+⌈b ∕b ⌉)seeks.Thebuildandprobephases
r b s b
requireonlyoneseekforeachofthen partitionsofeachrelation,sinceeachpar-
h
titioncanbereadsequentially.Thehashjointhusrequires2(⌈b ∕b ⌉+⌈b ∕b ⌉)+
r b s b
2n seeks.
h
Nowconsiderthecasewhererecursivepartitioningisrequired.Againweassume
thatb blocksareallocatedforbufferingeachpartition.Eachpassthenreducesthesize
b
ofeachofthepartitionsbyanexpectedfactorof⌊M∕b ⌋−1;andpassesarerepeated
b
untileachpartitionisofsizeatmostMblocks.Theexpectednumberofpassesrequired
forpartitioningsistherefore⌈log (b ∕M)⌉.
⌊M∕b ⌋−1 s
b
• Since, in each pass, every block of s is read in and written out, the total number
of blocktransfers forpartitioningof sis2b ⌈log (b ∕M)⌉.The numberof
s ⌊M∕b ⌋−1 s
b
passesforpartitioningofristhesameasthenumberofpassesforpartitioningof
s,thereforethejoinisestimatedtorequire
2(b +b )⌈log (b ∕M)⌉+b +b
r s ⌊M∕b ⌋−1 s r s
b
blocktransfers.
• Ignoringtherelativelysmall numberof seeks duringthe build and probe phases,
hashjoinwithrecursivepartitioningrequires
2(⌈b ∕b ⌉+⌈b ∕b ⌉)⌈log (b ∕M)⌉
r b s b ⌊M∕b ⌋−1 s
b
diskseeks.
Consider,forexample,thenaturaljointakes ⋈ student.Withamemorysizeof20
blocks,thestudentrelationcanbepartitionedintofivepartitions,eachofsize20blocks,
which size will fit into memory. Only one pass is required for the partitioning. The

--- Page 746 ---

15.5 JoinOperation 717
relationtakesissimilarlypartitionedintofivepartitions,eachofsize80.Ignoringthe
costofwritingpartiallyfilledblocks,thecostis3(100+400) = 1500blocktransfers.
Thereisenoughmemorytoallocatethebuffersfortheinputandeachofthefiveoutputs
duringpartitioning(i.e,b =3)leadingto2(⌈100∕3⌉+⌈400∕3⌉) = 336seeks.
b
Thehashjoincanbeimprovedifthemainmemorysizeislarge.Whentheentire
buildinputcanbekeptinmainmemory,n canbesetto0;then,thehash-joinalgorithm
h
executes quickly, without partitioning the relations into temporary files, regardless of
theprobeinput’ssize.Thecostestimategoesdowntob +b blocktransfersandtwo
r s
seeks.
Indexed nested loops join can have a much lower cost than hash join in case the
outer relation is small, and the index lookups fetch only a few tuples from the inner
(indexed) relation. However, in case a secondary index is used, and the number of
tuplesintheouterrelationislarge,indexednestedloopsjoincanhaveaveryhighcost,
as compared to hash join. If the number of tuples in the outer relation is known at
queryoptimizationtime,thebestjoinalgorithmcanbechosenatthattime.However,
insomecases,forexample,whenthereisaselectionconditionontheouterinput,the
optimizermakesadecisionbasedonanestimatethatmaypotentiallybeimprecise.The
numberoftuplesintheouterrelationmaybefoundonlyatruntime,forexample,after
executingselection.Somesystemsallowadynamicchoicebetweenthetwoalgorithms
atruntime,afterfindingthenumberoftuplesintheouterinput.
15.5.5.5 HybridHashJoin
Thehybridhash-joinalgorithmperformsanotheroptimization;itisusefulwhenmem-
orysizesarerelativelylargebutnotallofthebuildrelationfitsinmemory.Theparti-
tioningphaseofthehash-joinalgorithmneedsaminimumofoneblockofmemoryas
abufferforeachpartitionthatiscreated,andoneblockofmemoryasaninputbuffer.
To reduce the impact of seeks, a larger number of blocks would be used as a buffer;
let b denote the number of blocks used as a buffer for the input and for each parti-
b
tion.Hence,atotalof(n +1) ∗ b blocksofmemoryareneededforpartitioningthe
h b
two relations. If memory is larger than (n +1) ∗ b , we can use the rest of memory
h b
(M −(n +1) ∗ b blocks) to buffer the first partition of the build input (i.e, s ) so
h b 0
that it will not need to be written out and read back in. Further, the hash function is
designed in such a way that the hash index on s fits in M −(n +1) ∗ b blocks, in
0 h b
orderthat,attheendofpartitioningofs,s iscompletelyinmemoryandahashindex
0
canbebuiltons .
0
Whenthesystempartitionsr,itagaindoesnotwritetuplesinr todisk;instead,as
0
it generates them, the system uses them to probe the memory-residenthash index on
s ,andtogenerateoutputtuplesofthejoin.Aftertheyareusedforprobing,thetuples
0
canbediscarded,sothepartitionr doesnotoccupyanymemoryspace.Thus,awrite
0
andareadaccesshavebeensavedforeachblockofbothr ands .Thesystemwrites
0 0
out tuples in the other partitions as usual and joins them later. The savings of hybrid
hashjoincanbesignificantifthebuildinputisonlyslightlybiggerthanmemory.

--- Page 747 ---

718 Chapter15 QueryProcessing
Ifthesizeofthebuildrelationisb
s
,n
h
isapproximatel
√
yequaltob
s
∕M.Thus,hybrid
hashjoinismostusefulifM >> (b ∕M)∗ b ,orM >> b ∗ b ,wherethenotation
s b s b
>> denotes much larger than. For example, suppose the block size is 4 kilobytes, the
build relation size is 5 gigabytes, and b is 20. Then, the hybrid hash-join algorithm
b
isuseful ifthesizeofmemoryissignificantlymorethan20megabytes;memorysizes
ofgigabytesormorearecommononcomputerstoday.Ifwedevote1gigabyteforthe
joinalgorithm,s wouldbenearly1gigabyte,andhybridhashjoinwouldbenearly20
0
percentcheaperthanhashjoin.
15.5.6 Complex Joins
Nested-loopandblocknested-loopjoinscanbeusedregardlessofthejoinconditions.
Theotherjointechniquesaremoreefficientthanthenested-loopjoinanditsvariants,
buttheycanhandleonlysimplejoinconditions,suchasnaturaljoinsorequi-joins.We
can implementjoinswith complexjoin conditions,such asconjunctions and disjunc-
tions, by using the efficient join techniques, if we apply the techniques developed in
Section15.3.3forhandlingcomplexselections.
Considerthefollowingjoinwithaconjunctivecondition:
r ⋈ s
θ ∧θ ∧⋯∧θ
1 2 n
Oneormoreofthejointechniquesdescribedearliermaybeapplicableforjoinsonthe
individualconditionsr ⋈ s,r ⋈ s,r ⋈ s,andsoon.Wecancomputetheoverall
θ θ θ
join by first computing the 1 result o 2 f one o 3 f these simpler joins r ⋈ s; each pair of
θ
i
tuplesintheintermediateresultconsistsofonetuplefromrandonefroms.Theresult
ofthecompletejoinconsistsofthosetuplesintheintermediateresultthatsatisfythe
remainingconditions:
θ ∧⋯∧θ ∧θ ∧⋯∧θ
1 i−1 i+1 n
Theseconditionscanbetestedastuplesinr ⋈ sarebeinggenerated.
θ
i
Ajoinwhoseconditionisdisjunctivecanbecomputedinthisway.Consider:
r ⋈ s
θ ∨θ ∨⋯∨θ
1 2 n
Thejoincanbecomputedastheunionoftherecordsinindividualjoinsr ⋈ s:
θ
i
(r ⋈ s)∪(r ⋈ s)∪⋯∪(r ⋈ s)
θ θ θ
1 2 n
Section15.6describesalgorithmsforcomputingtheunionofrelations.

--- Page 748 ---

15.6 OtherOperations 719
15.5.7 Joins over Spatial Data
Thejoinalgorithmswehavepresentedmakenospecificassumptionsaboutthetypeof
databeingjoined,buttheydoassumetheuseofstandardcomparisonoperationssuch
asequality,lessthan,orgreaterthan,wherethevaluesarelinearlyordered.
Selection and join conditions on spatial data involve comparison operators that
checkifoneregioncontainsoroverlapsanother,orwhetheraregioncontainsapartic-
ular point; and the regions may be multi-dimensional.Comparisons may pertain also
to the distance between points, for example, finding a set of points closest to a given
pointinatwo-dimensionalspace.
Merge-joincannotbeusedwithsuchcomparisonoperations,sincethereisnosim-
plesortorderoverspatialdataintwoormoredimensions.Partitioningofdatabased
on hashing is also not applicable, since there is no way to ensure that tuples that sat-
isfy an overlap or containment predicate are hashed to the same value. Nested loops
joincanalwaysbeusedregardlessofthecomplexityoftheconditions,butcanbevery
inefficientonlargedatasets.
Indexed nested-loops join can however be used, if appropriate spatial indices are
available. In Section 14.10, we saw several types of indices for spatial data, including
R-trees,k-dtrees,k-d-Btrees,andquadtrees.Additionaldetailsonthoseindicesappear
in Section 24.4. These index structures enable efficient retrieval of spatial data based
on predicates such as contains, contained in, or overlaps, and can also be effectively
usedtofindnearestneighbors.
Mostmajordatabasesystemstodayincorporatesupportforindexingspatialdata,
andmakeuseofthemwhenprocessingqueriesusingspatialcomparisonconditions.
15.6 Other Operations
Otherrelationaloperationsandextendedrelationaloperations—suchasduplicateelim-
ination,projection,setoperations,outerjoin,andaggregation—canbeimplementedas
outlinedinSection15.6.1throughSection15.6.5.
15.6.1 Duplicate Elimination
Wecanimplementduplicateeliminationeasilybysorting.Identicaltupleswillappear
adjacenttoeachotherasaresultofsorting,andallbutonecopycanberemoved.With
external sort–merge, duplicates found while a run is being created can be removed
beforethe run iswrittentodisk,therebyreducingthenumberofblocktransfers. The
remaining duplicates can be eliminated during merging, and the final sorted run has
noduplicates.Theworst-casecostestimateforduplicateeliminationisthesameasthe
worst-casecostestimateforsortingoftherelation.
Wecanalsoimplementduplicateeliminationbyhashing,asinthehash-joinalgo-
rithm. First, the relation is partitioned on the basis of a hash function on the whole
tuple. Then, each partition is read in, and an in-memory hash index is constructed.

--- Page 749 ---

720 Chapter15 QueryProcessing
Whileconstructingthehashindex,atupleisinsertedonlyifitisnotalreadypresent.
Otherwise,thetupleisdiscarded.Afteralltuplesinthepartitionhavebeenprocessed,
thetuplesinthehashindexarewrittentotheresult.Thecostestimateisthesameas
that for the cost of processing (partitioning and reading each partition) of the build
relationinahashjoin.
Becauseoftherelativelyhighcostofduplicateelimination,SQLrequiresanexplicit
requestbytheusertoremoveduplicates;otherwise,theduplicatesareretained.
15.6.2 Projection
We can implement projection easily by performing projection on each tuple, which
gives a relation that could have duplicate records, and then removing duplicate rec-
ords.DuplicatescanbeeliminatedbythemethodsdescribedinSection15.6.1.Iftheat-
tributesintheprojectionlistincludeakeyoftherelation,noduplicateswillexist;hence,
duplicate elimination is not required. Generalized projection can be implemented in
thesamewayasprojection.
15.6.3 Set Operations
Wecanimplementtheunion,intersection, andset-differenceoperationsbyfirstsorting
bothrelations,andthenscanningoncethrougheachofthesortedrelationstoproduce
theresult.Inr∪s,whenaconcurrentscanofbothrelationsrevealsthesametuplein
bothfiles,onlyoneofthetuplesisretained.Theresultofr∩swillcontainonlythose
tuples that appear in both relations. We implement set difference, r − s, similarly, by
retainingtuplesinr onlyiftheyareabsentins.
Foralltheseoperations,onlyonescanofthetwosortedinputrelationsisrequired,
so the cost is b +b block transfers if the relations are sorted in the same order. As-
r s
sumingaworstcaseofoneblockbufferforeachrelation,atotalofb +b diskseeks
r s
would be required in addition to b +b block transfers. The number of seeks can be
r s
reducedbyallocatingextrabufferblocks.
Iftherelationsarenotsortedinitially,thecostofsortinghastobeincluded.Any
sort order can be used in the evaluation of set operations, provided that both inputs
havethatsamesortorder.
Hashingprovidesanotherwaytoimplementthesesetoperations.Thefirststepin
eachcaseistopartitionthetworelationsbythesamehashfunctionandtherebycreate
thepartitionsr ,r ,…,r ands ,s ,…,s .Dependingontheoperation,thesystem
0 1 n 0 1 n
h h
thentakesthesestepsoneachpartitioni = 0,1,…,n :
h
• r∪s
1.Buildanin-memoryhashindexonr.
i
2.Addthetuplesins tothehashindexonlyiftheyarenotalreadypresent.
i
3.Addthetuplesinthehashindextotheresult.

--- Page 750 ---

15.6 OtherOperations 721
Note 15.1 AnsweringKeywordQueries
Keyword search on documents is widely used in the context of web search. In
itssimplestform,akeywordqueryprovidesasetofwordsK ,K ,…,K ,andthe
1 2 n
goal is to find documents d from a collection of documents D such that d con-
i i
tainsallthekeywordsinthequery.Real-lifekeywordsearchismorecomplicated,
sinceitrequiresrankingofdocumentsbasedonvariousmetricssuchTF–IDFand
PageRank,aswesawearlierinSection8.3.
Documentsthatcontainaspecifiedkeywordcanbelocatedefficientlybyusing
an index (often referred to as an inverted index) that maps each keyword K to a
i
list S of identifiersof the documents that contain K. The list is kept sorted. For
i i
example,ifdocumentsd ,d andd containtheterm“Silberschatz”,theinverted
1 9 21
list for the keyword Silberschatz would be “d ;d ;d ”. Compression techniques
1 9 21
are used to reduce the size of the inverted lists. A B+-tree index can be used to
mapeachkeywordK toitsassociatedinvertedlistS.
i i
ToansweraquerywithkeywordK ,K ,…,K ,weretrievetheinvertedlistS
1 2 n i
foreachkeywordK,andthencomputetheintersectionS ∩S ∩⋯∩S tofind
i 1 2 n
documentsthatappearinallthelists.Sincethelistsaresorted,theintersectioncan
be efficiently implemented by merging the lists using concurrent scans of all the
lists. Many information-retrieval systems return documents that contain several,
even if not all, of the keywords; the merge step can be easily modified to output
documentsthatcontainatleastkofthenkeywords.
Tosupportrankingofkeyword-queryresults,extrainformationcanbestored
in each inverted list, including the inverse document frequency of the term, and
for each document the PageRank, the term frequency of the term, as well as the
positions within the document where the term occurs. This information can be
used to compute scores that are then used to rank the documents. For example,
documents where the keywords occur close to each other may receive a higher
scoreforkeywordproximitythanthosewheretheyoccurfartherfromeachother.
ThekeywordproximityscoremaybecombinedwiththeTF–IDFscore,andPageR-
anktocomputeanoverallscore.Documentsarethenrankedonthisscore.Since
mostwebsearchesretrieveonlythetopfewanswers,searchenginesincorporatea
numberofoptimizationsthathelptofindthetopfewanswersefficiently,without
computingthefulllistandthenfindingtheranking.Referencesprovidingfurther
detailsmaybefoundintheFurtherReadingsectionattheendofthechapter.
• r∩s
1.Buildanin-memoryhashindexonr.
i
2.Foreachtupleins,probethehashindexandoutputthetupletotheresult
i
onlyifitisalreadypresentinthehashindex.

--- Page 751 ---

722 Chapter15 QueryProcessing
• r−s
1.Buildanin-memoryhashindexonr.
i
2.Foreachtupleins,probethehashindex,and,ifthetupleispresentinthe
i
hashindex,deleteitfromthehashindex.
3.Addthetuplesremaininginthehashindextotheresult.
15.6.4 Outer Join
Recalltheouter-joinoperationsdescribedinSection4.1.3.Forexample,thenaturalleft
outer join takes⟕student containsthe join of takesand student,and, inaddition,for
eachtakestupletthathasnomatchingtupleinstudent(i.e,whereIDisnotinstudent),
the following tuple t is added to the result. For all attributes in the schema of takes,
1
tuple t has the same values as tuple t. The remainingattributes (from the schemaof
1
student)oftuplet containthevaluenull.
1
Wecanimplementtheouter-joinoperationsbyusingoneoftwostrategies:
1. Computethecorrespondingjoin,andthenaddfurthertuplestothejoinresultto
gettheouter-joinresult.Considertheleftouter-joinoperationandtworelations:
r(R) and s(S). To evaluate r⟕ s, we first compute r ⋈ s and save that result
θ θ
astemporaryrelationq .Next,wecomputer−Π (q )toobtainthosetuplesin
1 R 1
r thatdo notparticipate in the thetajoin. We can use any of the algorithmsfor
computingthejoins,projection,andsetdifferencedescribedearliertocompute
theouter joins.Wepad eachof thesetupleswithnullvalues forattributes from
s,andaddittoq togettheresultoftheouterjoin.
1
Therightouter-joinoperationr⟖ sisequivalenttos⟕ randcantherefore
θ θ
beimplementedinasymmetricfashiontotheleftouterjoin.Wecanimplement
thefullouter-joinoperationr⟗ sbycomputingthejoinr ⋈ sandthenadding
θ
theextratuplesofboththeleftandrightouter-joinoperations,asbefore.
2. Modify the join algorithms. It is easy to extend the nested-loop join algorithms
tocomputetheleftouterjoin:Tuplesintheouterrelationthatdonotmatchany
tupleintheinnerrelationarewrittentotheoutputafterbeingpaddedwithnull
values.However,itishardtoextendthenested-loopjointocomputethefullouter
join.
Natural outer joins and outer joins with an equi-join condition can be com-
puted by extensions of the merge-join and hash-join algorithms.Merge join can
beextendedtocomputethefullouterjoinasfollows:Whenthemergeofthetwo
relations is being done, tuples in either relation that do not match any tuple in
theotherrelationcanbepaddedwithnullsandwrittentotheoutput.Similarly,
wecanextendmergejointocomputetheleftandrightouterjoinsbywritingout
nonmatchingtuples(paddedwithnulls)fromonlyoneoftherelations.Sincethe
relationsaresorted,itiseasytodetectwhetherornotatuplematchesanytuples

--- Page 752 ---

15.6 OtherOperations 723
from the other relation.Forexample, when a merge join of takesand student is
done, the tuples are read in sorted order of ID, and it is easy to check, for each
tuple,whetherthereisamatchingtupleintheother.
The cost estimates for implementing outer joins using the merge-join algo-
rithm are the same as are those for the correspondingjoin. The only difference
liesinthesizeoftheresult,andthereforeintheblocktransfersforwritingitout,
whichwedidnotcountinourearliercostestimates.
Theextensionofthehash-joinalgorithmtocomputeouterjoinsisleftforyou
todoasanexercise(Exercise15.21).
15.6.5 Aggregation
Recalltheaggregationfunction(operator),discussedinSection3.7.Forexample,the
function
selectdept name,avg(salary)
frominstructor
groupbydept name;
computestheaveragesalaryineachuniversitydepartment.
Theaggregationoperationcanbeimplementedinthesamewayasduplicateelim-
ination.Weuseeithersortingorhashing,justaswedidforduplicateelimination,but
based on the grouping attributes (dept name in the preceding example). However, in-
stead of eliminating tuples with the same value for the grouping attribute, we gather
themintogroupsandapplytheaggregationoperationsoneachgrouptogettheresult.
The cost estimate for implementing the aggregation operation is the same as the
costofduplicateeliminationforaggregatefunctionssuchasmin,max,sum,count,and
avg.
Instead of gathering all the tuples in a group and then applying the aggregation
operations, we can implement the aggregation operations sum, min, max, count, and
avgontheflyasthegroupsarebeingconstructed.Forthecaseofsum,min,andmax,
when twotuples in the same group are found, the system replacesthem with asingle
tuple containingthe sum,min, ormax,respectively,ofthe columnsbeingaggregated.
Forthecountoperation,itmaintainsarunningcountforeachgroupforwhichatuple
has been found. Finally, we implement the avg operation by computing the sum and
thecountvaluesonthefly,andfinallydividingthesumbythecounttogettheaverage.
If all tuples of the result fit in memory, the sort-based and the hash-based imple-
mentationsdonotneedtowriteanytuplestodisk.Asthetuplesarereadin,theycan
be inserted in a sorted tree structure or in a hash index. When we use on-the-fly ag-
gregationtechniques,onlyonetupleneedstobestoredforeachofthegroups.Hence,
thesortedtreestructureorhashindexfitsinmemory,andtheaggregationcanbepro-
cessedwithjustb blocktransfers(and1seek)insteadofthe3b transfers(andaworst
r r
caseofupto2b seeks)thatwouldberequiredotherwise.
r

--- Page 753 ---

724 Chapter15 QueryProcessing
15.7 Evaluation of Expressions
So far, we have studied how individual relational operations are carried out. Now we
consider how to evaluate an expression containing multiple operations. The obvious
way to evaluate an expression is simply to evaluate one operation at a time, in an ap-
propriate order. The result of each evaluation is materialized in a temporary relation
forsubsequent use.Adisadvantage tothisapproachistheneedtoconstructthetem-
poraryrelations,which(unlesstheyaresmall)mustbewrittentodisk.Analternative
approachistoevaluateseveraloperationssimultaneouslyinapipeline,withtheresults
ofoneoperationpassedontothenext,withouttheneedtostoreatemporaryrelation.
InSection15.7.1andSection15.7.2,weconsiderboththematerializationapproach
andthepipeliningapproach.Weshallseethatthecostsoftheseapproachescandiffer
substantially, but also thatthere are cases whereonly the materialization approach is
feasible.
15.7.1 Materialization
It is easiest to understand intuitively how to evaluate an expression by looking at a
pictorialrepresentationoftheexpressioninanoperatortree.Considertheexpression:
Π (σ (department) ⋈ instructor)
name building=“Watson”
inFigure15.11.
Ifweapplythematerializationapproach,westartfromthelowest-leveloperations
in the expression (at the bottom of the tree). In our example, there is only one such
operation: the selection operation on department. The inputs to the lowest-level oper-
ationsarerelationsinthedatabase.Weexecutetheseoperationsusingthealgorithms
thatwestudiedearlier,andwestoretheresultsintemporaryrelations.Wecanusethese
temporaryrelationstoexecutetheoperationsatthenextlevelupinthetree,wherethe
inputs now are either temporary relations or relations stored in the database. In our
Π
name
σ instructor
building = “Watson”
department
Figure 15.11 Pictorialrepresentationofanexpression.

--- Page 754 ---

15.7 EvaluationofExpressions 725
example, the inputs to the join are the instructor relation and the temporary relation
createdbytheselectionondepartment.Thejoincannowbeevaluated,creatinganother
temporaryrelation.
Byrepeatingtheprocess,wewilleventuallyevaluatetheoperationattherootofthe
tree,givingthefinalresultoftheexpression.Inourexample,wegetthefinalresultby
executingtheprojectionoperationattherootofthetree,usingasinputthetemporary
relationcreatedbythejoin.
Evaluation as just described is called materialized evaluation, since the results of
eachintermediateoperationarecreated(materialized)andthenareusedforevaluation
ofthenext-leveloperations.
The cost of a materialized evaluation is not simply the sum of the costs of the
operationsinvolved.Whenwecomputedthecostestimatesofalgorithms,weignored
thecostofwritingtheresultoftheoperationtodisk.Tocomputethecostofevaluating
an expression as done here, we have to add the costs of all the operations, as well as
thecostofwritingtheintermediateresultstodisk.Weassumethattherecordsofthe
resultaccumulateinabuffer,and,whenthebufferisfull,theyarewrittentodisk.The
number of blockswritten out, b , can be estimated asn ∕f ,where n isthe estimated
r r r r
numberoftuplesintheresultrelationrandf istheblockingfactoroftheresultrelation,
r
that is, the number of records of r that will fit in a block. In addition to the transfer
time,some disk seeks may be required,since the diskhead may have moved between
successivewrites.Thenumberofseekscanbeestimatedas⌈b ∕b ⌉whereb isthesize
r b b
oftheoutputbuffer(measuredinblocks).
Doublebuffering(usingtwobuffers,withonecontinuingexecutionofthealgorithm
while the other is being written out) allows the algorithm to execute more quickly by
performing CPU activity in parallel with I/O activity. The number of seeks can be re-
duced by allocating extra blocks to the output buffer and writing out multiple blocks
atonce.
15.7.2 Pipelining
Wecanimprovequery-evaluationefficiencybyreducingthenumberoftemporaryfiles
thatareproduced.Weachievethisreductionbycombiningseveralrelationaloperations
into a pipeline of operations, in which the results of one operation are passed along
to the next operation in the pipeline. Evaluation as just described is called pipelined
evaluation.
For example, consider the expression (Π (r ⋈ s)). If materialization were ap-
a1,a2
plied,evaluation wouldinvolve creatingatemporary relationtohold theresultofthe
join and then reading back in the result to perform the projection. These operations
canbecombined:Whenthejoinoperationgeneratesatupleofitsresult,itpassesthat
tuple immediatelyto the projectoperation forprocessing. By combiningthe join and
the projection, we avoid creating the intermediate result and instead create the final
resultdirectly.

--- Page 755 ---

726 Chapter15 QueryProcessing
Creatingapipelineofoperationscanprovidetwobenefits:
1. It eliminates the cost of reading and writing temporary relations, reducing the
costofqueryevaluation.Notethatthecostformulaethatwesawearlierforeach
operation included the cost of reading the result from disk. If the input to an
operator o is pipelined from a preceding operator o, the cost of o should not
i j i
include the cost of reading the input from disk; the cost formulae that we saw
earliercanbemodifiedaccordingly.
2. It can start generating query results quickly, if the root operator of a query-
evaluationplaniscombinedinapipelinewithitsinputs.Thiscanbequiteuseful
iftheresultsaredisplayedtoauserastheyaregenerated,sinceotherwisethere
maybealongdelaybeforetheuserseesanyqueryresults.
15.7.2.1 ImplementationofPipelining
We can implement a pipeline by constructing a single, complex operation that com-
binestheoperationsthatconstitutethepipeline.Althoughthisapproachmaybefeasi-
bleforsomefrequentlyoccurringsituations,itisdesirableingeneraltoreusethecode
forindividualoperationsintheconstructionofapipeline.
In the example of Figure 15.11, all three operations can be placed in a pipeline,
which passes the results of the selection to the join as they are generated. In turn,
it passes the results of the join to the projection as they are generated. The memory
requirements are low, since results of an operation are not stored for long. However,
as a result of pipelining, the inputs to the operations are not available all at once for
processing.
Pipelinescanbeexecutedineitheroftwoways:
1. In ademand-drivenpipeline, thesystem makes repeatedrequests fortuples from
the operation at the top of the pipeline. Each time that an operation receives
a request for tuples, it computes the next tuple (or tuples) to be returned and
thenreturnsthattuple.Iftheinputsoftheoperationarenotpipelined,thenext
tuple(s)tobereturnedcanbecomputedfromtheinputrelations,whilethesys-
temkeepstrackofwhathasbeenreturnedsofar.Ifithassomepipelinedinputs,
theoperationalsomakesrequestsfortuplesfromitspipelinedinputs.Usingthe
tuples received from its pipelined inputs, the operation computes tuples for its
outputandpassesthemuptoitsparent.
2. In a producer-driven pipeline, operations do not wait for requests to produce tu-
ples,butinsteadgeneratethetupleseagerly.Eachoperationinaproducer-driven
pipelineismodeledasaseparateprocessorthreadwithinthesystem thattakes
astreamoftuplesfromitspipelinedinputsandgenerates astreamoftuplesfor
itsoutput.

--- Page 756 ---

15.7 EvaluationofExpressions 727
We describe next how demand-driven and producer-driven pipelines can be imple-
mented.
Eachoperationinademand-drivenpipelinecanbeimplementedasaniteratorthat
providesthefollowingfunctions:open(),next(),andclose().Afteracalltoopen(),each
calltonext()returnsthenextoutputtupleoftheoperation.Theimplementationofthe
operation in turn calls open() and next() on its inputs, to get its input tuples when
required. The function close() tells an iterator that no more tuples are required. The
iterator maintains the state of its execution in between calls so that successive next()
requestsreceivesuccessiveresulttuples.
Forexample,foraniteratorimplementingtheselectoperationusinglinearsearch,
theopen()operationstartsafilescan,andtheiterator’sstaterecordsthepointtowhich
the file has been scanned. When the next() function is called, the file scan continues
from afterthepreviouspoint; whenthenexttuple satisfying theselectionisfound by
scanning the file, the tuple is returned after storing the point where it was found in
the iterator state. A merge-join iterator’s open() operation would open its inputs, and
iftheyarenotalreadysorted,itwouldalsosorttheinputs.Oncallstonext(),itwould
return the next pair of matchingtuples. The state information would consist of up to
whereeachinputhadbeenscanned.Detailsoftheimplementationofiteratorsareleft
foryoutocompleteinPracticeExercise15.7.
Producer-drivenpipelines,ontheotherhand,areimplementedinadifferentman-
ner.Foreachpairofadjacentoperationsinaproducer-drivenpipeline,thesystemcre-
atesabuffertoholdtuplesbeingpassedfromoneoperationtothenext.Theprocesses
orthreadscorrespondingtodifferentoperationsexecuteconcurrently.Eachoperation
at the bottom of a pipeline continually generates output tuples, and puts them in its
outputbuffer,untilthebufferisfull.Anoperationatanyotherlevelofapipelinegen-
eratesoutputtupleswhenitgetsinputtuplesfromlowerdowninthepipelineuntilits
outputbufferisfull.Oncetheoperationusesatuplefromapipelinedinput,itremoves
thetuplefromitsinputbuffer.Ineithercase,oncetheoutputbufferisfull,theopera-
tion waits until its parent operation removes tuples from the buffer so that the buffer
hasspaceformoretuples.Atthispoint,theoperationgeneratesmoretuplesuntilthe
buffer isfull again.The operation repeatsthisprocess untilall theoutput tuples have
beengenerated.
It is necessary for the system to switch between operations only when an output
bufferisfullorwhenaninputbufferisemptyandmoreinputtuplesareneededtogen-
erateanymoreoutputtuples.Inaparallel-processingsystem,operationsinapipeline
mayberunconcurrentlyondistinctprocessors(seeSection22.5.1).
Using producer-driven pipelining can be thought of as pushing data up an oper-
ation tree from below, whereas using demand-driven pipelining can be thought of as
pulling data up an operation tree from the top. Whereas tuples are generated eagerly
inproducer-drivenpipelining,theyaregeneratedlazily,ondemand,indemand-driven
pipelining. Demand-driven pipelining is used more commonly than producer-driven
pipelining because it is easier to implement. However, producer-driven pipelining is
very useful in parallel processing systems. Producer-driven pipelining has also been

--- Page 757 ---

728 Chapter15 QueryProcessing
foundtobemoreefficientthandemand-drivenpipeliningonmodernCPUssinceitre-
ducesthenumberoffunctioncallinvocationsascomparedtodemand-drivenpipelin-
ing. Producer-driven pipelining is increasingly used in systems that generate machine
codeforhighperformancequeryevaluation.
15.7.2.2 EvaluationAlgorithmsforPipelining
Queryplanscanbeannotatedtomarkedgesthatarepipelined;suchedgesarecalled
pipelined edges. In contrast, non-pipelined edges are referred to as blocking edges or
materializededges.Thetwooperatorsconnectedbyapipelinededgemustbeexecuted
concurrently,sinceoneconsumestuplesastheothergeneratesthem.Sinceaplancan
havemultiplepipelinededges,thesetofalloperatorsthatareconnectedbypipelined
edges must be executed concurrently.A query plan can be dividedintosubtrees such
thateachsubtreehasonlypipelinededges,andtheedgesbetweenthesubtreesarenon-
pipelined. Each such subtree is called a pipeline stage. The query processor executes
theplanone pipelinestage atatime,and concurrentlyexecutesalltheoperatorsina
singlepipelinestage.
Some operations, such assorting, areinherentlyblockingoperations, that is,they
maynotbeabletooutputanyresultsuntilalltuplesfromtheirinputshavebeenexam-
ined.7 Butinterestingly,blockingoperatorscanconsumetuplesastheyaregenerated,
andcanoutputtuplestotheirconsumersastheyaregenerated;suchoperationsactu-
allyexecute in twoormorestages, and blockingactuallyhappens betweentwostages
oftheoperation.
For example, the external sort-merge operation actually has two steps: (i) run-
generation,followedby(ii)merging.Therun-generationstepcanaccepttuplesasthey
are generated by the input to the sort, and can thus be pipelined with the sort input.
Themergestep,ontheotherhand,cansendtuplestoitsconsumerastheyaregener-
ated,andcanthusbepipelinedwiththeconsumerofthesortoperation.Butthemerge
step can start only after the run-generation step has finished. We can thus model the
sort-merge operator as two sub-operators connected to each other by a non-pipelined
edge,buteachofthesub-operatorscanbeconnectedbypipelinededgestotheirinput
andoutputrespectively.
Otheroperations,suchasjoin,arenotinherentlyblocking,butspecificevaluation
algorithmsmaybeblocking.Forexample,theindexednestedloopsjoinalgorithmcan
outputresulttuplesasitgetstuplesfortheouterrelation.Itisthereforepipelinedonits
outer (left-handside)relation;however,itisblockingon itsindexed(right-handside)
input, since the index must be fully constructed before the indexed nested-loop join
algorithmcanexecute.
The hash-join algorithm is a blocking operation on both inputs, since it requires
both itsinputstobe fullyretrievedandpartitioned beforeitoutputs anytuples. How-
7Blockingoperationssuchassortingmaybeabletooutputtuplesearlyiftheinputisknowntosatisfysomespecial
propertiessuchasbeingsorted,orpartiallysorted,already.However,intheabsenceofsuchinformation,blocking
operationscannotoutputtuplesearly.

--- Page 758 ---

15.7 EvaluationofExpressions 729
r r
Part.
γ
HJ-BP HA-IM
Part.
s s
(a) Logical Query (b) Pipelined Plan
Figure 15.12 Queryplanwithpipelining.
ever, hash-join partitions each of its inputs, and then performs multiple build-probe
steps,onceperpartition.Thus,thehash-joinalgorithmhas3steps:(i)partitioningof
thefirstinput,(ii)partitioningofthesecondinput,and(iii)thebuild-probestep.The
partitioning step for each input can accept tuples as they are generated by the input,
andcanthusbepipelinedwithitsinput.Thebuild-probestepcanoutputtuplestoits
consumer as the tuples are generated, and can thus be pipelined with its consumer.
But the twopartitioningsteps are connected tothe build-probe step by non-pipelined
edges, since build-probe can start onlyafter partitioninghas been completed on both
inputs.
Hybridhashjoincanbeviewedaspartiallypipelinedontheproberelation,since
itcanoutputtuplesfromthefirstpartitionastuplesarereceivedfortheproberelation.
However, tuples that are not in the first partition will be output only after the entire
pipelinedinputrelationisreceived.Hybridhashjointhusprovidesfullypipelinedeval-
uationonitsprobeinputifthebuildinputfitsentirelyinmemory,ornearlypipelined
evaluationifmostofthebuildinputfitsinmemory.
Figure15.12ashowsaquerythatjoinstworelationsrands,andthenperformsan
aggregation on the result; details of the join predicate, group by attributes and aggre-
gation functions are omitted for simplicity. Figure 15.12b shows a pipelined plan for
thequeryusinghashjoinandin-memoryhashaggregation.Pipelinededgesareshown
usinganormalline,whileblockingedgesareshownusingaboldline.Pipelinestages
are enclosed in dashed boxes. Note that hash join has been split into three suboper-
ators. Two of suboperators, shown abbreviated to Part., partition r and s respectively.
Thethird,abbreviatedtoHJ-BP,performsthebuildandprobephaseofthehashjoin.
TheHA-IM operatoristhein-memoryhashaggregationoperator.Theedgesfromthe
partitionoperatorstotheHJ-BP operatorareblockingedges,sincetheHJ-BP operator
can start execution only after the partition operators have completed execution. The
edgesfromtherelations(assumedtobescannedusingarelationscanoperator)tothe
partitionoperatorsarepipelined,asistheedgefromtheHJ-BP operatortotheHA-IM
operator.Theresultantpipelinestagesareshownenclosedindashedboxes.
Ingeneral,foreachmaterializededgeweneedtoaddthecostofwritingthedata
todisk, andthe costof theconsumeroperator should includethecost ofreadingthe
datafromdisk.However,whenamaterializededgeisbetweensuboperatorsofasingle

--- Page 759 ---

730 Chapter15 QueryProcessing
done :=false;
r
done :=false;
s
r :=∅;
s:=∅;
result:=∅;
whilenotdone ornotdone do
r s
begin
ifqueueisempty,thenwaituntilqueueisnotempty;
t:=topentryinqueue;
ift=End thendone :=true
r r
elseift=End thendone :=true
s s
elseiftisfrominputr
then
begin
r:=r∪{t};
result:=result∪({t}⋈s);
end
else/*tisfrominputs*/
begin
s:=s∪{t};
result:=result∪(r⋈{t});
end
end
Figure 15.13 Double-pipelinedjoinalgorithm.
operator,forexamplebetweenrungenerationandmerge,thematerializationcosthas
alreadybeenaccountedforintheoperatorscost,andshouldnotbeaddedagain.
In some applications, a join algorithm thatis pipelined on both its inputs and its
outputisdesirable.Ifbothinputsaresortedonthejoinattribute,andthejoincondition
isanequi-join,mergejoincanbeused,withbothitsinputsanditsoutputpipelined.
However,inthemorecommoncasethatthetwoinputsthatwedesiretopipeline
intothejoinarenotalreadysorted,anotheralternativeisthedouble-pipelinedjointech-
nique, shown in Figure 15.13. The algorithm assumes that the input tuples for both
input relations, r and s, are pipelined. Tuples made available for both relations are
queued for processing in a single queue. Special queue entries, called End and End ,
r s
whichserveasend-of-filemarkers,areinsertedinthequeueafteralltuplesfromrands
(respectively)havebeengenerated.Forefficientevaluation,appropriateindicesshould
bebuiltontherelationsrands.Astuplesareaddedtorands,theindicesmustbekept

--- Page 760 ---

15.8 QueryProcessinginMemory 731
uptodate.Whenhashindicesareusedonrands,theresultantalgorithmiscalledthe
double-pipelinedhash-jointechnique.
Thedouble-pipelinedjoinalgorithminFigure15.13assumesthatbothinputsfitin
memory. In case the two inputs are larger than memory, it is still possible to use the
double-pipelinedjointechniqueasusualuntilavailablememoryisfull.Whenavailable
memorybecomesfull,r andstuplesthathavearriveduptothatpointcanbetreated
asbeinginpartitionr ands ,respectively.Tuplesforr andsthatarrivesubsequently
0 0
are assigned to partitions r and s , respectively, which are written to disk, and are
1 1
not added to the in-memory index. However, tuples assigned to r and s are used to
1 1
probe s and r , respectively, before they are written to disk. Thus, the join of r with
0 0 1
s , and s with r , is also carried out in a pipelined fashion. After r and s have been
0 1 0
fullyprocessed,thejoinofr tupleswiths tuplesmustbecarriedouttocompletethe
1 1
join;anyofthejointechniqueswehaveseenearliercanbeusedtojoinr withs .
1 1
15.7.3 Pipelines for Continuous-Stream Data
Pipelining is also applicable in situations where data are entered into the database
in a continuous manner, as is the case, for example, for inputs from sensors that are
continuouslymonitoringenvironmentaldata.Suchdataarecalleddatastreams,aswe
sawearlierinSection10.5.Queriesmaybewrittenoverstreamdatainordertorespond
todataastheyarrive.Suchqueriesarecalledcontinuousqueries.
The operations in a continuous query should be implemented using pipelined al-
gorithms, so that results from the pipeline can be output without blocking. Producer-
drivenpipelines(whichwediscussedearlierinSection15.7.2.1)arethebestsuitedfor
continuousqueryevaluation.
Manysuchqueriesperformaggregationwithwindowing;tumblingwindowswhich
dividetimeintofixedsizeintervals, such as1minute,or1hour, arecommonlyused.
Grouping and aggregation is performed separately on each window, as tuples are re-
ceived; assuming memory size is large enough, an in-memory hash index is used to
performaggregation.
Theresultofaggregationonawindowcanbeoutputoncethesystemknowsthatno
furthertuplesinthatwindowwillbereceivedinfuture.Iftuplesareguaranteedtoarrive
sorted by timestamp, the arrival of a tuple of a following window indicates no more
tupleswillbereceivedforanearlierwindow.Iftuplesmayarriveoutoforder,streams
mustcarrypunctuationsthatindicatethatallfuturetupleswillhaveatimestampgreater
thansomespecifiedvalue.Thearrivalofapunctuationallowstheoutputofaggregates
of windows whose end-timestamp is less than or equal to the timestamp specified by
thepunctuation.
15.8 Query Processing in Memory
The query processing algorithms that we have described so far focus on minimizing
I/Ocost.Inthissection,wediscussextensionstothequeryprocessingtechniquesthat

--- Page 761 ---

732 Chapter15 QueryProcessing
help minimize memory access costs by using cache-conscious query processing algo-
rithmsandquerycompilation.Wethendiscussqueryprocessingwithcolumn-oriented
storage.Thealgorithmswedescribeinthissectiongivesignificantbenefitsformemory
residentdata;theyarealsoveryusefulwithdisk-residentdata,sincetheycanspeedup
processingoncedatahasbeenbroughtintothein-memorybuffer.
15.8.1 Cache-Conscious Algorithms
When dataisresidentin memory,accessismuchfaster than ifdatawereresidenton
magnetic disks, or even SSDs. However, it must be kept in mind that data already in
CPUcachecanbeaccessedasmuchas100timesfasterthandatainmemory.Modern
CPUshaveseverallevelsofcache.CommonlyusedCPUstodayhaveanL1cacheofsize
around64kilobytes,withalatencyofabout1nanosecond,anL2cacheofsizearound
256kilobytes,withalatencyofaround5nanoseconds,andanL3cacheofhavingasize
ofaround 10megabytes, withalatencyof 10to15 nanoseconds.Incontrast, reading
data in memory results in a latency of around 50 to 100 nanoseconds. For simplicity
in the rest of this section we ignore the difference between the L1, L2 and L3 cache
levels,andassumethatthereisonlyasinglecachelevel.
AswesawinSection14.4.7,thespeeddifferencebetweencachememoryandmain
memory,andthefactthatdataaretransferredbetweenmainmemoryandcacheinunits
of a cache-line (typically about 64 bytes), results in a situation where the relationship
between cache and main memory is not dissimilar to the relationship between main
memoryanddisk(althoughwithsmallerspeeddifferences).Butthereisadifference:
while the contents of the main memory buffers disk-based data are controlled by the
database system, CPU cache is controlled by the algorithms built into the computer
hardware.Thus,thedatabasesystemcannotdirectlycontrolwhatiskeptincache.
However,queryprocessingalgorithmscanbedesignedinawaythatthemakesthe
bestuseofcache,tooptimizeperformance.Herearesomewaysthiscanbedone:
• Tosortarelationthatisin-memory,weusetheexternalmerge-sortalgorithm,with
therunsizechosensuchthattherunfitsintothecache;assumingwefocusonthe
L3cache,eachrunshouldbeafewmegabytesinsize.Wethenuseanin-memory
sortingalgorithmoneachrun;sincetherunfitsincache,cachemissesarelikelyto
beminimalwhentherunissorted.Thesortedruns(allofwhichareinmemory)
arethenmerged.Mergingiscacheefficient,sinceaccesstotherunsissequential:
when a particular word is accessed from memory, the cache line that is fetched
willcontainthewordsthatwouldbeaccessednextfromthatrun.
To sort a relation larger than memory, we can use external sort-merge with
much larger run sizes, but use the in-memory merge-sort technique we just de-
scribedtoperformthein-memorysortofthelargeruns.
• Hash-join requiresprobing of an indexon the build relation.Ifthe build relation
fitsinmemory,anindexcouldbebuiltonthewholerelation;however,cachehits
during probe can be maximized by partitioning the relations into smaller pieces

--- Page 762 ---

15.8 QueryProcessinginMemory 733
suchthateachpartitionofthebuild-relationalongwiththeindexfitsinthecache.
Each partition is processed separately, with a build and a probe phase; since the
build partition and its index fit in cache, cache misses are minimized during the
buildaswellastheprobephase.
Forrelationslargerthan memory, the first stage of hash-join should partition
the two relations such that for each partition, the partitions of the two relations
togetherfitinmemory.Thetechniquejustdescribedcanthenbeusedtoperform
thehashjoinoneachofthesepartitions,afterfetchingthecontentsintomemory.
• Attributesinatuplecanbearrangedsuchthatattributesthattendtobeaccessed
togetherarelaidoutconsecutively.Forexample,ifarelationisoftenusedforaggre-
gation,thoseattributesusedasgroupbyattributes,andthosethatareaggregated
upon, can be stored consecutively. As a result, if there is a cache miss on one at-
tribute,thecachelinethatisfetchedwouldcontainattributesthatarelikelytobe
usedimmediately.
Cache-awarealgorithmsareofincreasingimportanceinmoderndatabasesystems,
sincememorysizesareoftenlargeenoughthatmuchofthedataismemory-resident.
In cases where the requisite data item is not in cache, there is a processing stall
whilethedataitemisretrievedfrommemoryand loadedintocache.Inordertocon-
tinuetomakeuseofthecorethatmadetherequestresultinginthestall,theoperating
system maintains multiple threads of execution on which a core may work. Parallel
query processing algorithms, which we study in Chapter 22 can use multiple threads
running on a single CPU core; if one thread is stalled, another can start execution so
theCPUcoreisutilizedbetter.
15.8.2 Query Compilation
Withdataresidentinmemory,CPUcostbecomesthebottleneck,andminimizingCPU
cost can give significant benefits. Traditional databases query processors act as inter-
pretersthatexecuteaqueryplan.However,thereisasignificantoverheadduetointer-
pretation: for example, to access an attribute of a record, the query execution engine
mayrepeatedlylookuptherelationmeta-datatofindtheoffsetoftheattributewithin
the record, since the same code must work for all relations. There is also significant
overhead due to function calls that are performed for each record processed by an
operation.
To avoid overhead due to interpretation, modern main-memory databases com-
pile query plans into machine code or intermediate level byte-code. For example, the
compiler can compute the offset of an attribute at compile time, and generate code
where the offset is a constant. The compiler can also combine the code for multiple
functions in a way that minimizes function calls. With these, and other related opti-
mizations,compiledcodehasbeenfoundtoexecutefaster,byuptoafactorof10,than
interpretedcode.

--- Page 763 ---

734 Chapter15 QueryProcessing
15.8.3 Column-Oriented Storage
In Section 13.6, we saw that in data-analytic applications, only a few attributes of a
large schema may be needed, and that in such cases, storing a relation by column
insteadofbyrowmaybeadvantageous. Selectionoperationsonasingleattribute (or
smallnumberofattributes) havesignificantlylowercostinacolumnstore sinceonly
the relevant attributes need to be accessed. However, since accessing each attribute
requires its own data access, the cost of retrieving many attributes is higher and may
incuradditionalseeksifdataarestoredondisk.
Becausecolumnstorespermitefficientaccesstomanyvaluesforagivenattribute
at once, they are well suited to exploit the vector-processing capabilities of modern
processors.Thiscapabilityallowscertainoperations(suchascomparisonsandaggre-
gations) to be performed in a parallel on multiple attribute values. When compiling
queryplanstomachinecode,thecompilercangeneratevector-processinginstructions
supportedbytheprocessor.
15.9 Summary
• Thefirstactionthatthesystemmustperformonaqueryistotranslatethequery
intoitsinternalform,which(forrelationaldatabasesystems) isusuallybasedon
therelationalalgebra.Intheprocessofgeneratingtheinternalformofthequery,
the parser checks the syntax of the user’s query, verifies that the relation names
appearing in the query are names of relations in the database, and so on. If the
query was expressed in terms of a view, the parser replaces all references to the
viewnamewiththerelational-algebraexpressiontocomputetheview.
• Givenaquery,therearegenerallyavarietyofmethodsforcomputingtheanswer.
Itistheresponsibilityofthequeryoptimizertotransformthequeryasenteredby
theuserintoanequivalentquerythatcanbecomputedmoreefficiently.Chapter
16coversqueryoptimization.
• We can process simple selection operations by performing a linear scan or by
making use of indices. We can handle complex selections by computing unions
andintersectionsoftheresultsofsimpleselections.
• Wecansortrelationslargerthanmemorybytheexternalsort–mergealgorithm.
• Queries involving a natural join may be processed in several ways, depending on
theavailabilityofindicesandtheformofphysicalstoragefortherelations.
° IfthejoinresultisalmostaslargeastheCartesianproductofthetworelations,
ablocknested-loopjoinstrategymaybeadvantageous.
° Ifindicesareavailable,theindexednested-loopjoincanbeused.

--- Page 764 ---

ReviewTerms 735
° Iftherelationsaresorted,amergejoinmaybedesirable.Itmaybeadvantageous
tosortarelationpriortojoincomputation(soastoallowuseofthemerge-join
strategy).
° The hash-join algorithm partitions the relations into several pieces, such that
each piece of one of the relations fits in memory. The partitioning is carried
out with a hash function on the join attributes so that correspondingpairs of
partitionscanbejoinedindependently.
• Duplicate elimination, projection, set operations (union, intersection, and differ-
ence),andaggregationcanbedonebysortingorbyhashing.
• Outer-joinoperationscanbeimplementedbysimpleextensionsofjoinalgorithms.
• Hashing and sorting are dual, in the sense that any operation such as duplicate
elimination,projection,aggregation,join,andouterjointhatcanbeimplemented
byhashingcanalsobeimplementedbysorting,andviceversa;thatis,anyopera-
tionthatcanbeimplementedbysortingcanalsobeimplementedbyhashing.
• An expression can be evaluated by means of materialization, where the system
computestheresultofeachsubexpressionandstoresitondiskandthenusesitto
computetheresultoftheparentexpression.
• Pipelining helps to avoid writing the results of many subexpressions to disk by
usingtheresultsintheparentexpressionevenastheyarebeinggenerated.
Review Terms
• Queryprocessing • Disjunctiveselection
• Evaluationprimitive • Compositeindex
• Query-executionplan • Intersectionofidentifiers
• Query-evaluationplan • Externalsorting
• Query-executionengine • Externalsort–merge
• Measuresofquerycost • Runs
• SequentialI/O • N-waymerge
• RandomI/O • Equi-join
• Filescan • Nested-loopjoin
• Linearsearch • Blocknested-loopjoin
• Selectionsusingindices • Indexednested-loopjoin
• Accesspaths • Mergejoin
• Indexscans • Sort-mergejoin
• Conjunctiveselection • Hybridmergejoin

--- Page 765 ---

736 Chapter15 QueryProcessing
• Hash-join • Spatialjoin
° Build • Operatortree
• Materializedevaluation
° Probe
• Doublebuffering
° Buildinput
• Pipelinedevaluation
° Probeinput
° Demand-drivenpipeline
° Recursivepartitioning
(lazy,pulling)
° Hash-tableoverflow
° Producer-drivenpipeline
° Skew (eager,pushing)
° Fudgefactor ° Iterator
° Overflowresolution ° Pipelinestages
° Overflowavoidance • Double-pipelinedjoin
• Hybridhash-join • Continuousqueryevaluation
Practice Exercises
15.1 Assume(forsimplicityinthisexercise)thatonlyonetuplefitsinablockand
memory holds at most three blocks. Show the runs created on each pass of
thesort-mergealgorithmwhenappliedtosortthefollowingtuplesonthefirst
attribute: (kangaroo, 17), (wallaby, 21), (emu, 1), (wombat, 13), (platypus,
3),(lion,8),(warthog,4),(zebra,11),(meerkat,6),(hyena,9),(hornbill,2),
(baboon,12).
15.2 Consider the bank database of Figure 15.14, where the primary keys are un-
derlined,andthefollowingSQLquery:
selectT.branch name
frombranchT,branchS
whereT.assets>S.assetsandS.branch city=“Brooklyn”
Writeanefficientrelational-algebraexpressionthatisequivalenttothisquery.
Justifyyourchoice.
15.3 Let relations r (A,B,C) and r (C,D,E) have the following properties: r has
1 2 1
20,000 tuples, r has 45,000 tuples, 25 tuples of r fit on one block, and 30
2 1
tuplesofr fitononeblock.Estimatethenumberofblocktransfersandseeks
2
requiredusingeachofthefollowingjoinstrategiesforr ⋈ r :
1 2
a. Nested-loopjoin.
b. Blocknested-loopjoin.

--- Page 766 ---

PracticeExercises 737
c. Mergejoin.
d. Hashjoin.
15.4 The indexed nested-loop join algorithm described in Section 15.5.3 can be
inefficientiftheindexisasecondaryindexandtherearemultipletupleswith
the same value for the join attributes. Why is it inefficient? Describe a way,
usingsorting,toreducethecostofretrievingtuplesoftheinnerrelation.Under
whatconditionswouldthisalgorithmbemoreefficientthanhybridmergejoin?
15.5 Letr andsberelationswithnoindices,andassumethattherelationsarenot
sorted.Assuminginfinitememory,whatisthelowest-costway(intermsofI/O
operations) to compute r ⋈ s? What is the amount of memory required for
thisalgorithm?
15.6 Consider the bank database of Figure 15.14, where the primary keys are un-
derlined. Suppose that a B+-tree index on branch city is available on relation
branch, and thatno otherindexis available.List differentways tohandle the
followingselectionsthatinvolvenegation:
a. σ (branch)
¬(branchcity<“Brooklyn”)
b. σ (branch)
¬(branchcity=“Brooklyn”)
c. σ (branch)
¬(branchcity<“Brooklyn”∨assets<5000)
15.7 Write pseudocode for an iterator that implements indexed nested-loop join,
where the outer relation is pipelined. Your pseudocode must define the stan-
darditeratorfunctionsopen(),next(),andclose().Showwhatstateinformation
theiteratormustmaintainbetweencalls.
15.8 Designsort-based and hash-basedalgorithmsforcomputingtherelationaldi-
visionoperation (seePracticeExercise2.9foradefinitionofthedivisionop-
eration).
branch(branch name,branch city,assets)
customer (customer name,customer street,customer city)
loan(loan number,branch name,amount)
borrower (customer name,loan number)
account (account number,branch name,balance)
depositor (customer name,account number)
Figure 15.14 Bankdatabase.

--- Page 767 ---

738 Chapter15 QueryProcessing
15.9 Whatisthe effecton thecost ofmergingruns ifthe numberof bufferblocks
perrunisincreasedwhileoverallmemoryavailableforbufferingrunsremains
fixed?
15.10 Considerthefollowingextendedrelational-algebraoperators.Describehowto
implementeachoperationusingsortingandusinghashing.
a. Semijoin(⋉ ):Themultisetsemijoinoperatorr⋉ sisdefinedasfollows:
θ θ
if a tuple r appears n times in r, itappears n timesin the resultof r⋉
i θ
if there is at least one tuple s such that r and s satisfy predicate θ;
j i j
otherwiser doesnotappearintheresult.
i
b. Anti-semijoin (⋉ ): The multiset anti-semijoin operator r⋉ s is defined
θ θ
asfollows:ifatupler appearsntimesinr,itappearsntimesintheresult
i
of r⋉ if there does not exist any tuple s in s such that r and s satisfy
θ j i j
predicateθ;otherwiser doesnotappearintheresult.
i
15.11 Suppose a query retrieves only the first K results of an operation and termi-
natesafterthat.Whichchoiceofdemand-drivenorproducer-drivenpipelining
(with buffering) would be a good choice for such a query? Explain your an-
swer.
15.12 Current generation CPUs include an instruction cache, which caches recently
usedinstructions.Afunctioncallthenhasasignificantoverheadbecausethe
set of instructions being executed changes, resulting in cache misses on the
instructioncache.
a. Explainwhyproducer-drivenpipeliningwithbufferingislikelytoresult
in a better instruction cache hit rate, as compared to demand-driven
pipelining.
b. Explainwhymodifyingdemand-drivenpipeliningbygeneratingmultiple
results on one call to next(), and returning them together, can improve
theinstructioncachehitrate.
15.13 Supposeyouwanttofinddocumentsthatcontainatleastkofagivensetofn
keywords.Supposealsoyouhaveakeywordindexthatgivesyoua(sorted)list
ofidentifiersofdocumentsthatcontainaspecifiedkeyword.Giveanefficient
algorithmtofindthedesiredsetofdocuments.
15.14 Suggest how a document containing a word (such as “leopard”) can be in-
dexedsuchthatitisefficientlyretrievedbyqueriesusingamoregeneral con-
cept (such as “carnivore” or “mammal”). You can assume that the concept
hierarchy is not very deep, so each concept has only a few generalizations (a
concept can, however, have a large number of specializations). You can also
assumethatyouareprovidedwithafunctionthatreturnstheconceptforeach
wordinadocument.Alsosuggesthowaqueryusingaspecializedconceptcan
retrievedocumentsusingamoregeneralconcept.

--- Page 768 ---

Exercises 739
15.15 Explainwhythenested-loopsjoinalgorithm(seeSection15.5.1) wouldwork
poorlyonadatabasestoredinacolumn-orientedmanner.Describeanalterna-
tivealgorithmthatwouldworkbetter,andexplainwhyyoursolutionisbetter.
15.16 Consider the following queries. For each query, indicate if column-oriented
storageislikelytobebeneficialornot,andexplainwhy.
a. FetchID,nameanddept nameofthestudentwithID12345.
b. Groupthetakesrelationbyyearandcourse id,andfindthetotalnumber
ofstudentsforeach(year,course id)combination.
Exercises
15.17 Suppose you need to sort a relation of 40 gigabytes, with 4-kilobyte blocks,
usingamemorysizeof40megabytes.Supposethecostofaseekis5millisec-
onds,whilethedisktransferrateis40megabytespersecond.
a. Find the cost of sorting the relation, in seconds, with b = 1 and with
b
b = 100.
b
b. Ineachcase,howmanymergepassesarerequired?
c. Suppose a flash storage device is used instead of a disk, and it has a
latencyof20microsecondandatransferrateof400megabytespersec-
ond.Recomputethecostofsortingtherelation,inseconds,withb = 1
b
andwithb = 100,inthissetting.
b
15.18 Why is it not desirable to force users to make an explicit choice of a query-
processingstrategy?Aretherecasesinwhichitisdesirableforuserstobeaware
ofthecostsofcompetingquery-processingstrategies?Explainyouranswer.
15.19 Design a variant of the hybrid merge-join algorithm for the case where both
relationsarenotphysicallysorted,butbothhaveasortedsecondaryindexon
thejoinattributes.
15.20 Estimatethenumberofblocktransfersandseeksrequiredbyyoursolutionto
Exercise15.19forr ⋈ r ,wherer andr areasdefinedinExercise15.3.
1 2 1 2
15.21 The hash-join algorithm as described in Section 15.5.5 computes the natural
joinoftworelations.Describehowtoextendthehash-joinalgorithmtocom-
putethenaturalleftouterjoin,thenaturalrightouterjoin,andthenaturalfull
outerjoin.(Hint:Keepextrainformationwitheachtupleinthehashindexto
detect whether any tuple in the probe relation matches the tuple in the hash
index.)Tryoutyouralgorithmonthetakesandstudentrelations.

--- Page 769 ---

740 Chapter15 QueryProcessing
15.22 Supposeyouhavetocompute γ (r)aswellas γ (r).Describehow
A sum(C) A,B sum(C)
tocomputethesetogetherusingasinglesortingofr.
15.23 Writepseudocodeforaniteratorthatimplementsaversionofthesort–merge
algorithm where the result of the final merge is pipelined to its consumers.
Your pseudocode must define the standard iterator functions open(), next(),
and close(). Show whatstate informationthe iteratormust maintainbetween
calls.
15.24 Explainhowtosplitthehybridhash-joinoperatorintosub-operatorstomodel
pipelining.Alsoexplainhowthissplitisdifferentfromthesplitforahash-join
operator.
15.25 Suppose youneedtosortrelationr usingsort—mergeandmerge—jointhere-
sultwithanalreadysortedrelations.
a. Describehowthesortoperatorisbrokenintosuboperatorstomodelthe
pipelininginthiscase.
b. Thesameideaisapplicableevenifbothinputstothemergejoinarethe
outputsofsort—mergeoperations.However,theavailablememoryhasto
besharedbetweenthetwomergeoperations(themerge—joinalgorithm
itself needs very little memory). What is the effect of having to share
memoryonthecostofeachsort-mergeoperation?
Further Reading
[Graefe(1993)]presentsanexcellentsurveyofquery-evaluationtechniques.[Faerber
et al. (2017)] describe main-memory database implementation techniques, including
queryprocessingtechniquesformain-memorydatabases,while[Kemperetal.(2012)]
describes techniques for query processing with in-memory columnar data. [Samet
(2006)]providesatextbookdescriptionofspatialdatastructures,while[Shekharand
Chawla(2003)]providesatextbookdescriptionofspatialdatabases,includingindex-
ingandqueryprocessingtechniques.Textbookdescriptionsoftechniquesforindexing
documents,andefficientlycomputingrankedanswerstokeywordqueriesmaybefound
in[Manningetal.(2008)].
Bibliography
[Faerberetal.(2017)] F.Faerber,A.Kemper,P.-A.Larson,J.Levandoski,T.Neumann,and
A.Pavlo,“MainMemoryDatabaseSystems”,FoundationsandTrendsinDatabases,Volume
8,Number1-2(2017),pages1–130.
[Graefe(1993)] G.Graefe,“QueryEvaluationTechniquesforLargeDatabases”,ACMCom-
putingSurveys,Volume25,Number2(1993).

--- Page 770 ---

FurtherReading 741
[Kemperetal.(2012)] A. Kemper, T. Neumann, F. Funke, V. Leis, and H. M¨uhe, “HyPer:
AdaptingColumnarMain-MemoryDataManagementforTransactionANDQueryProcess-
ing”,IEEEDataEngineeringBulletin,Volume35,Number1(2012),pages46–51.
[Manningetal.(2008)] C.D.Manning,P.Raghavan,andH.Sch¨utze,IntroductiontoInfor-
mationRetrieval,CambridgeUniversityPress(2008).
[Samet(2006)] H.Samet,FoundationsofMultidimensionalandMetricDataStructures,Mor-
ganKaufmann(2006).
[ShekharandChawla(2003)] S.ShekharandS.Chawla,SpatialDatabases:ATOUR,Pear-
son(2003).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 772 ---

16
CHAPTER
Query Optimization
Queryoptimizationistheprocessofselectingthemostefficientquery-evaluationplan
fromamongthemanystrategiesusuallypossibleforprocessingagivenquery,especially
ifthequeryiscomplex.Wedonotexpectuserstowritetheirqueriessothattheycanbe
processedefficiently.Rather,weexpectthesystemtoconstructaquery-evaluationplan
that minimizes the cost of query evaluation. This is where query optimization comes
intoplay.
Oneaspectofoptimizationoccursattherelational-algebralevel,wherethesystem
attempts to find an expression that is equivalent to the given expression, but more
efficient to execute. Another aspect is selecting a detailed strategy for processing the
query,suchaschoosingthealgorithmtouseforexecutinganoperation,choosingthe
specificindicestouse,andsoon.
Thedifferenceincost(intermsofevaluationtime)betweenagoodstrategyanda
bad strategy is often substantial and may be several orders of magnitude. Hence, it is
worthwhileforthesystemtospendasubstantialamountoftimeontheselectionofa
goodstrategyforprocessingaquery,evenifthequeryisexecutedonlyonce.
16.1 Overview
Considerthefollowingrelational-algebraexpression,forthequery“Findthenamesof
allinstructorsintheMusicdepartmenttogetherwiththecoursetitleofallthecourses
thattheinstructorsteach.”1
Π (σ (instructor ⋈ (teaches ⋈ Π (course))))
name,title deptname=“Music” courseid,title
The subexpression instructor ⋈ teaches ⋈ Π (course) in the preceding ex-
courseid,title
pressioncancreateaverylargeintermediateresult.However,weareinterestedinonly
a few tuples of this intermediate result, namely, those pertaining to instructors in the
1Notethattheprojection ofcourseon(courseid, title)isrequiredsincecoursesharesanattributedeptnamewith
instructor;ifwedidnotremovethisattributeusingtheprojection, theaboveexpressionusingnaturaljoinswould
returnonlycoursesfromtheMusicdepartment,evenifsomeMusicdepartmentinstructorstaughtcoursesinother
departments.
743

--- Page 773 ---

744 Chapter16 QueryOptimization
∏
name, title
∏
σ name, title
dept_name = Music
instructor σ
dept_name = Music
teaches ∏ instructor teaches ∏
course_id, title course_id, title
course course
(a) Initial expression tree (b) Transformed expression tree
Figure 16.1 Equivalentexpressions.
Musicdepartment,andinonlytwoofthenineattributesofthisrelation.Sinceweare
concerned with only those tuples in the instructor relation that pertain to the Music
department, we do not need to consider those tuples that do not have dept name =
“Music”. By reducing the number of tuples of the instructor relation that we need to
access,wereducethesizeoftheintermediateresult.Ourqueryisnowrepresentedby
therelational-algebraexpression:
Π ((σ (instructor)) ⋈ (teaches ⋈ Π (course)))
name,title deptname=“Music” courseid,title
which is equivalent to our original algebra expression, but which generates smaller
intermediaterelations.Figure16.1depictstheinitialandtransformedexpressions.
An evaluation plan defines exactly what algorithm should be used for each op-
eration and how the execution of the operations should be coordinated. Figure 16.2
illustrates one possible evaluation plan for the expression from Figure 16.1(b). As we
haveseen,severaldifferentalgorithmscanbeusedforeachrelationaloperation,giving
rise to alternative evaluation plans. In the figure, hash join has been chosen for one
of the join operations, while the other uses merge join, after sorting the relations on
the join attribute, which is ID. All edges are assumed to be pipelined, unless marked
as materialized. With pipelined edges the output of the producer is sent directly to
theconsumer,withoutbeingwrittenouttodisk;withmaterializededges,ontheother
hand,theoutputiswrittentodisk,andthenreadfromthediskbytheconsumer.There
are nomaterializededges inthe evaluation plan in Figure16.2, although some of the
operators,suchassortandhashjoin,canberepresentedusingsuboperatorswithma-
terializededgesbetweenthesuboperators,aswesawinSection15.7.2.2.
Givenarelational-algebraexpression,itisthejobofthequeryoptimizertocome
upwithaquery-evaluationplanthatcomputesthesameresultasthegivenexpression,
andistheleastcostlywayofgeneratingtheresult(or,atleast,isnotmuchcostlierthan
theleastcostlyway).

--- Page 774 ---

16.1 Overview 745
(sort to remove duplicates)
Π
name, title
(merge join)
sort
ID
sort (hash join)
ID
σ Π
dept_name = Music course_id, title
(use index 1)
instructor teaches course
Figure 16.2 Anevaluationplan.
The expression that we saw in Figure 16.1 may not necessarily lead to the least-
cost evaluation plan for computing the result, since it still computes the join of the
entireteachesrelationwiththecourserelation.Thefollowingexpressiongivesthesame
final result,but generates smallerintermediateresults, sinceitjoins teaches withonly
instructor tuples corresponding to the Music department, and then joins that result
withcourse.
Π ((σ (instructor) ⋈ teaches) ⋈ Π (course))
name,title deptname=“Music” courseid,title
Regardless of the way the query is written, it is the job of the optimizer to find the
least-costplanforthequery.
To find the least costly query-evaluation plan, the optimizer needs to generate al-
ternativeplansthatproducethesameresultasthegivenexpressionandtochoosethe
least costly one. Generation of query-evaluation plans involves three steps: (1) gener-
ating expressions that are logically equivalent to the given expression, (2) annotating
the resultant expressions in alternative ways to generate alternative query-evaluation
plans,and(3)estimatingthecostofeachevaluationplan,andchoosingtheonewhose
estimatedcostistheleast.
Steps (1), (2), and (3) are interleaved in the query optimizer—some expressions
aregeneratedandannotatedtogenerateevaluationplans,thenfurtherexpressionsare
generatedandannotated,andsoon.Asevaluationplansaregenerated,theircostsare
estimatedbyusingstatisticalinformationabouttherelations,suchasrelationsizesand
indexdepths.
Toimplementthefirststep,thequeryoptimizermustgenerateexpressionsequiv-
alent to a given expression. It does so by means of equivalence rules that specify how
to transform an expression intoa logically equivalentone. We describe these rules in
Section16.2.
InSection16.3wedescribehowtoestimatestatisticsoftheresultsofeachopera-
tioninaqueryplan.UsingthesestatisticswiththecostformulaeinChapter15allows

--- Page 775 ---

746 Chapter16 QueryOptimization
Note 16.1 VIEWINGQUERYEVALUATIONPLANS
Mostdatabasesystemsprovideawaytoviewtheevaluationplanchosentoexecute
agivenquery.ItisusuallybesttousetheGUIprovidedwiththedatabasesystem
to view evaluation plans. However, if you use a command line interface, many
databases support variations of a command “explain <query>”, which displays
theexecutionplanchosenforthespecifiedquery<query>.Theexactsyntaxvaries
withdifferentdatabases:
• PostgreSQLusesthesyntaxshownabove.
• Oracle uses the syntax explain plan for. However, the command stores the
resultant plan in a table calledplan table, instead of displaying it. The query
“select*fromtable(dbms xplan.display);”displaysthestoredplan.
• DB2followsasimilarapproachtoOracle,butrequirestheprogramdb2exfmt
tobeexecutedtodisplaythestoredplan.
• SQLServerrequiresthecommandsetshowplan textontobeexecutedbefore
submitting the query; then, when a query is submitted, instead of executing
thequery,theevaluationplanisdisplayed.
• MySQLusesthesameexplain<query>syntaxasPostgreSQL,buttheoutputis
atable whose contents are not easy tounderstand. However, executing show
warnings after the explain command displays the evaluation plan in a more
human-readableformat.
The estimated costs for the plan are also displayed along with the plan. It is
worthnotingthatthecostsareusuallynotinanyexternallymeaningfulunit,such
assecondsorI/Ooperations, butratherinunitsofwhatevercostmodeltheopti-
mizer uses. Some optimizers such as PostgreSQL display two cost-estimate num-
bers; the first indicates the estimated cost for outputting the first result, and the
secondindicatestheestimatedcostforoutputtingallresults.
us to estimate the costs of individual operations. The individual costs are combined
todeterminethe estimated cost of evaluatingagiven relational-algebraexpression, as
outlinedinSection15.7.
InSection16.4,wedescribehowtochooseaquery-evaluationplan.Wecanchoose
onebasedontheestimatedcostoftheplans.Sincethecostisanestimate,theselected
planisnotnecessarilytheleastcostlyplan;however,aslongastheestimatesaregood,
theplanislikelytobetheleastcostlyone,ornotmuchmorecostlythanit.

--- Page 776 ---

16.2 TransformationofRelationalExpressions 747
Finally,materializedviewshelptospeedupprocessingofcertainqueries.InSec-
tion16.5,westudyhowto“maintain”materializedviews—thatis,tokeepthemup-to-
date—andhowtoperformqueryoptimizationwithmaterializedviews.
16.2 Transformation of Relational Expressions
Aquerycanbeexpressedinseveraldifferentways,withdifferentcostsofevaluation.In
thissection,ratherthantaketherelationalexpressionasgiven,weconsideralternative,
equivalentexpressions.
Tworelational-algebraexpressionsaresaidtobeequivalentif,oneverylegaldata-
baseinstance,thetwoexpressionsgeneratethesamesetoftuples.(Recallthatalegal
databaseinstanceisonethatsatisfiesalltheintegrityconstraintsspecifiedinthedata-
baseschema.)Notethattheorderofthetuplesisirrelevant;thetwoexpressionsmay
generate the tuples in different orders, but would be considered equivalent as long as
thesetoftuplesisthesame.
InSQL,theinputsandoutputsaremultisetsoftuples,andthemultisetversionof
therelationalalgebra(describedinNote3.1onpage80,Note3.2onpage97,andNote
3.3 on page 108) is used for evaluating SQL queries. Two expressions in the multiset
versionoftherelationalalgebraaresaidtobeequivalentifoneverylegaldatabasethe
two expressions generate the same multiset of tuples. The discussion in this chapter
is based on the relational algebra. We leave extensions to the multiset version of the
relationalalgebratoyouasexercises.
16.2.1 Equivalence Rules
Anequivalencerulesaysthatexpressionsoftwoformsareequivalent.Wecanreplace
an expression of the first form with an expression of the second form, or vice versa—
that is, we can replace an expression of the second form by an expression of the first
form—since the two expressions generate the same result on any valid database. The
optimizer uses equivalence rules to transform expressions into other logically equiva-
lentexpressions.
Wenowdescribeseveralequivalencerulesonrelational-algebraexpressions.Some
oftheequivalenceslistedappearinFigure16.3.Weuseθ,θ ,θ ,andsoontodenote
1 2
predicates,L ,L ,L ,andsoontodenotelistsofattributes, andE,E ,E ,andsoon
1 2 3 1 2
to denote relational-algebraexpressions. A relation name r is simply a special case of
arelational-algebraexpressionandcanbeusedwhereverE appears.
1. Conjunctive selection operations can be deconstructed into a sequence of indi-
vidualselections.Thistransformationisreferredtoasacascadeofσ.
σ (E) ≡ σ (σ (E))
θ ∧θ θ θ
1 2 1 2
2. Selectionoperationsarecommutative.
σ (σ (E)) ≡ σ (σ (E))
θ θ θ θ
1 2 2 1

--- Page 777 ---

748 Chapter16 QueryOptimization
Rule 5
θ θ
E E E E
1 2 2 1
Rule 6.a
E E
3 1
E E E E
1 2 2 3
σ Rule 7.a
θ
If θ only has
attributes from E 1 σ θ E 2
E E E
1 2 1
Figure 16.3 Pictorialrepresentationofequivalences.
3. Onlythefinaloperationsinasequenceofprojectionoperationsareneeded;the
otherscan be omitted. Thistransformation can alsobe referred toas a cascade
ofΠ.
Π (Π (…(Π (E))…)) ≡ Π (E)
L L L L
1 2 n 1
whereL ⊆ L ⊆ … ⊆ L .
1 2 n
4. SelectionscanbecombinedwithCartesianproductsandthetajoins.
a. σ (E ×E ) ≡ E ⋈ E
θ 1 2 1 θ 2
Thisexpressionisjustthedefinitionofthethetajoin.
b. σ (E ⋈ E ) ≡ E ⋈ E
θ 1 θ 2 1 θ ∧θ 2
1 2 1 2
5. Theta-joinoperationsarecommutative.
E ⋈ E ≡ E ⋈ E
1 θ 2 2 θ 1
Recall that the natural-join operator is simply a special case of the theta-join
operator;hence,naturaljoinsarealsocommutative.
Theorderofattributesdiffersbetweentheleft-handsideandright-handside
of the commutativity rule, so the equivalence does not hold if the order of at-
tributesistakenintoaccount.Sinceweuseaversionofrelationalalgebrawhere
every attribute must have a name for it to be referenced, the order of attributes

--- Page 778 ---

16.2 TransformationofRelationalExpressions 749
does not actually matter, except when the result is finally displayed. When the
orderdoesmatter,aprojectionoperationcanbeaddedtooneofthesidesofthe
equivalencetoappropriatelyreorderattributes.However,forsimplicity,weomit
theprojectionandignoretheattributeorderinallourequivalencerules.
6. a. Natural-joinoperationsareassociative.
(E ⋈ E ) ⋈ E ≡ E ⋈ (E ⋈ E )
1 2 3 1 2 3
b. Thetajoinsareassociativeinthefollowingmanner:
(E ⋈ E ) ⋈ E ≡ E ⋈ (E ⋈ E )
1 θ 2 θ ∧θ 3 1 θ ∧θ 2 θ 3
1 2 3 1 3 2
whereθ involvesattributesfromonlyE andE .Anyoftheseconditions
2 2 3
may be empty; hence, itfollows thatthe Cartesian product (×) operation
isalsoassociative.Thecommutativityandassociativityofjoinoperations
areimportantforjoinreorderinginqueryoptimization.
7. The selection operation distributes over the theta-join operation under the fol-
lowingtwoconditions:
a. Selectiondistributesoverthetheta-joinoperationwhenalltheattributesin
selectionconditionθ involveonlytheattributesofoneoftheexpressions
1
(say,E )beingjoined.
1
σ (E ⋈ E ) ≡ (σ (E )) ⋈ E
θ 1 θ 2 θ 1 θ 2
1 1
b. Selectiondistributesoverthetheta-joinoperationwhenselectioncondition
θ involves only the attributes of E and θ involves onlythe attributes of
1 1 2
E .
2
σ (E ⋈ E ) ≡ (σ (E )) ⋈ (σ (E ))
θ ∧θ 1 θ 2 θ 1 θ θ 2
1 2 1 2
8. The projectionoperation distributes over thetheta-joinoperation underthefol-
lowingconditions.
a. LetL andL beattributesofE andE ,respectively.Supposethatthejoin
1 2 1 2
conditionθinvolvesonlyattributesinL ∪L .Then,
1 2
Π (E ⋈ E ) ≡ (Π (E )) ⋈ (Π (E ))
L ∪L 1 θ 2 L 1 θ L 2
1 2 1 2
b. ConsiderajoinE ⋈ E .LetL andL besetsofattributesfromE and
1 θ 2 1 2 1
E ,respectively.LetL beattributesofE thatareinvolvedinjoincondition
2 3 1
θ,butarenotinL and letL be attributes ofE thatareinvolved injoin
1 4 2
conditionθ,butarenotinL .Then,
2
Π (E ⋈ E ) ≡ Π ((Π (E )) ⋈ (Π (E )))
L ∪L 1 θ 2 L ∪L L ∪L 1 θ L ∪L 2
1 2 1 2 1 3 2 4
Similarequivalencesholdforouterjoinoperations⟕,⟖and⟗.

--- Page 779 ---

750 Chapter16 QueryOptimization
9. Thesetoperationsunionandintersectionarecommutative.
a. E ∪ E ≡ E ∪ E
1 2 2 1
b. E ∩ E ≡ E ∩ E
1 2 2 1
Setdifferenceisnotcommutative.
10. Setunionandintersectionareassociative.
a. (E ∪ E ) ∪ E ≡ E ∪ (E ∪ E )
1 2 3 1 2 3
b. (E ∩ E ) ∩ E ≡ E ∩ (E ∩ E )
1 2 3 1 2 3
11. The selection operation distributes over the union, intersection, and set-
differenceoperations.
a. σ (E ∪ E ) ≡ σ (E ) ∪ σ (E )
θ 1 2 θ 1 θ 2
b. σ (E ∩ E ) ≡ σ (E ) ∩ σ (E )
θ 1 2 θ 1 θ 2
c. σ (E − E ) ≡ σ (E ) − σ (E )
θ 1 2 θ 1 θ 2
d. σ (E ∩ E ) ≡ σ (E ) ∩ E
θ 1 2 θ 1 2
e. σ (E − E ) ≡ σ (E ) − E
θ 1 2 θ 1 2
Theprecedingequivalencedoesnotholdif−isreplacedby∪.
12. Theprojectionoperationdistributesovertheunionoperation
Π (E ∪E ) ≡ (Π (E ))∪(Π (E ))
L 1 2 L 1 L 2
providedE andE havethesameschema.
1 2
13. Selection distributes over aggregation under the following conditions. Let G be
a set of group by attributes, and A a set of aggregate expressions. When θ only
involvesattributesinG,thefollowingequivalenceholds.
σ ( γ (E) ≡ γ (σ (E))
θ G A G A θ
14. a. Fullouterjoiniscommutative.
E ⟗E ≡ E ⟗E
1 2 2 2
b. Leftandrightouterjoinarenotcommutative.However,leftouterjoinand
rightouterjoincanbeexchangedasfollows.
E ⟕E ≡ E ⟖E
1 2 2 1
15. Selectiondistributesoverleftandrightouterjoinundersomeconditions.Specif-
ically,whentheselectionconditionθ involvesonlytheattributes ofoneofthe
1
expressionsbeingjoined,sayE ,thefollowingequivalenceshold.
1

--- Page 780 ---

16.2 TransformationofRelationalExpressions 751
a. σ (E ⟕ E ) ≡ (σ (E ))⟕ E
θ 1 θ 2 θ 1 θ 2
1 1
b. σ (E ⟖ E ) ≡ (E ⟖ (σ (E )))
θ 2 θ 1 2 θ θ 1
1 1
16. Outerjoinscanbereplacedbyinnerjoinsundersomeconditions.Specifically,if
θ hasthepropertythatitevaluatestofalseorunknownwhenevertheattributes
1
ofE arenull,thenthefollowingequivalenceshold.
2
a. σ (E ⟕ E ) ≡ σ (E ⋈ E )
θ 1 θ 2 θ 1 θ 2
1 1
b. σ (E ⟖ E ) ≡ σ (E ⋈ E )
θ 2 θ 1 θ 2 θ 2
1 1
Apredicateθ satisfyingtheabovepropertyissaidtobenullrejectingonE .For
1 2
example,ifθ isoftheformA < 4whereAisanattributefromE ,thenθ would
1 2 1
evaluate to unknown whenever A isnull, and as a resultany tuples inE ⟕ E
1 θ 2
thatarenotinE ⋈ E wouldberejectedbyσ .Wecanthereforereplacethe
1 θ 2 θ
1
outerjoinbyaninnerjoin(orviceversa).
Moregenerally,theconditionwouldholdifθ isoftheformθ1∧θ2∧…∧θk,
1 1 1 1
and at least one of the terms θi is of the form e relop e , where e and e are
1 1 2 1 2
arithmeticorstringexpressionsinvolvingatleastoneattributefromE ,andrelop
2
isanyof<,≤,=,≥,>.
This is only a partial list of equivalences. More equivalences are discussed in the
exercises.
Someequivalencesthatholdforjoinsdonotholdforouterjoins.Forexample,the
selection operation does not distribute over outer join when the conditions specified
inrule15.aorrule15.bdohold.Toseethis,welookattheexpression:
σ (instructor⟕teaches)
year=2017
and consider the case of an instructor who teaches no courses at all, regardless of
year.Intheaboveexpression,theleftouterjoinretainsatupleforeachsuchinstructor
with a null value for year. Then the selection operation removes those tuples since
the predicate null=2017 evaluates to unknown, and such instructors do not appear in
the result. However, if we push the selection operation down to teaches, the resulting
expression:
instructor⟕σ (teaches)
year=2017
is syntactically correct since the selection predicate includes only attributes from
teaches,buttheresultisdifferent.Foraninstructorthatdoesnotteachatall,theinstruc-
tor tuple appears in the result of instructor⟕σ (teaches), but not in the result
year=2017
ofσ (instructor⟕teaches).Thefollowingequivalence,however,doeshold:
year=2017
σ (instructor⟕teaches) ≡ σ (instructor ⋈ teaches)
year=2017 year=2017
As another example, unlike inner joins, outer joins are not associative. We show
thus using an example for the natural left outer join. Similar examples can be con-

--- Page 781 ---

752 Chapter16 QueryOptimization
structed for natural right and natural full outer join, as well as for the corresponding
theta-joinversionsoftheouterjoinoperations.
Let relation r(A,B) be a relation consisting of the single tuple (1,1), s(B,C) be a
relationconsistingof the single tuple (1,1), and t(A,C) be an empty relationwithno
tuples.Weshallshowthatforthisexample,
(r⟕s)⟕t ≢ r⟕(s⟕t)
To see this, note first that(r⟕s) produces aresult withschema(A,B,C) havingone
tuple (1,1,1). Computing the left outer join of that result with relation t produces a
resultwithschema(A,B,C)havingonetuple(1,1,1).Next,welookattheexpression
r⟕(s⟕t), and note that s⟕t produces a result with schema (A,B,C) having one
tuple (null,1,1). Computing the left outer join of r with that result produces a result
withschema(A,B,C)havingonetuple(1,1,null).
16.2.2 Examples of Transformations
Wenowillustratetheuseoftheequivalencerules.Weuseouruniversityexamplewith
therelationschemas:
instructor(ID,name,dept name,salary)
teaches(ID,course id,sec id,semester,year)
course(course id,title,dept name,credits)
InourexampleinSection16.1,theexpression:
Π (σ (instructor ⋈ (teaches ⋈ Π (course))))
name,title deptname=“Music” courseid,title
wastransformedintothefollowingexpression:
Π ((σ (instructor)) ⋈ (teaches ⋈ Π (course)))
name,title deptname=“Music” courseid,title
whichisequivalenttoouroriginalalgebraexpressionbutgeneratessmallerintermedi-
ate relations. We can carry out this transformation by using rule 7.a. Remember that
therulemerelysaysthatthetwoexpressionsareequivalent;itdoesnotsaythatoneis
betterthantheother.
Multipleequivalencerulescanbeused,oneaftertheother,onaqueryoronparts
of the query. As an illustration, suppose that we modify our original query to restrict
attention to instructors who have taught a course in 2017. The new relational-algebra
queryis:
Π (σ
name,title deptname=“Music”∧year=2017
(instructor ⋈ (teaches ⋈ Π (course))))
courseid,title

--- Page 782 ---

16.2 TransformationofRelationalExpressions 753
We cannot apply the selection predicate directly to the instructor relation, since the
predicate involves attributes of both the instructor and teaches relations. However, we
canfirstapplyrule6.a(associativityofnaturaljoin)totransformthejoininstructor ⋈
(teaches ⋈ Π (course))into(instructor ⋈ teaches) ⋈ Π (course):
courseid,title courseid,title
Π (σ
name,title deptname=“Music”∧year=2017
((instructor ⋈ teaches) ⋈ Π (course)))
courseid,title
Then,usingrule7.a,wecanrewriteourqueryas:
Π ((σ
name,title deptname=“Music”∧year=2017
(instructor ⋈ teaches)) ⋈ Π (course))
courseid,title
Let us examine the selection subexpression within this expression. Using rule 1,
wecanbreaktheselectionintotwoselectionstogetthefollowingsubexpression:
σ (σ (instructor ⋈ teaches))
deptname=“Music” year=2017
Both of the preceding expressions select tuples with dept name = “Music” and
course id=2017.However,thelatterformoftheexpressionprovidesanewopportunity
toapplyrule7.a(“performselectionsearly”),resultinginthesubexpression:
σ (instructor) ⋈ σ (teaches)
deptname=“Music” year=2017
Figure 16.4 depicts the initial expression and the final expression after all these
transformations. We could equally well have used rule 7.b to get the final expression
directly,withoutusingrule1tobreaktheselectionintotwoselections.Infact,rule7.b
canitselfbederivedfromrules1and7.a.
∏ name, title ∏ name, title
σ
dept_name = Music
^ year = 2017
∏
course_id, title
σ σ
dept_name = Music year = 2017
instructor
teaches ∏ instructor teaches course
course_id, title
course
(a) Initial expression tree (b) Tree after multiple transformations
Figure 16.4 Multipletransformations.

--- Page 783 ---

754 Chapter16 QueryOptimization
Asetofequivalencerulesissaidtobeminimalifnorulecanbederivedfromany
combination of the others. The preceding example illustrates that the set of equiva-
lence rules in Section 16.2.1 is not minimal. An expression equivalent to the original
expressionmaybegeneratedindifferentways;thenumberofdifferentwaysofgenerat-
inganexpressionincreaseswhenweuseanonminimalsetofequivalencerules.Query
optimizersthereforeuseminimalsetsofequivalencerules.
Nowconsiderthefollowingformofourexamplequery:
Π ((σ (instructor) ⋈ teaches) ⋈ Π (course))
name,title deptname=“Music” courseid,title
Whenwecomputethesubexpression:
(σ (instructor) ⋈ teaches)
deptname=“Music”
weobtainarelationwhoseschemais:
(ID,name,dept name,salary,course id,sec id,semester,year)
Wecaneliminateseveralattributesfromtheschemabypushingprojectionsbasedon
equivalencerules8.aand8.b.Theonlyattributesthatwemustretainarethosethatei-
therappearintheresultofthequeryorareneededtoprocesssubsequentoperations.
Byeliminatingunneededattributes,wereducethenumberofcolumnsoftheinterme-
diate result. Thus, we reduce the size of the intermediate result. In our example, the
onlyattributesweneedfromthejoinofinstructor andteachesarenameandcourse id.
Therefore,wecanmodifytheexpressionto:
Π ((Π ((σ (instructor)) ⋈ teaches))
name,title name,courseid deptname=“Music”
⋈ Π (course))
courseid,title
TheprojectionΠ reducesthesizeoftheintermediatejoinresults.
name,courseid
16.2.3 Join Ordering
A good ordering of join operations is important for reducing the size of temporary
results;hence,mostqueryoptimizerspayalotofattentiontothejoinorder.Asmen-
tioned in equivalence rule 6.a, the natural-join operation is associative. Thus, for all
relationsr , r ,andr :
1 2 3
(r ⋈ r ) ⋈ r ≡ r ⋈ (r ⋈ r )
1 2 3 1 2 3
Although these expressions are equivalent, the costs of computing them may differ.
Consideragaintheexpression:
Π ((σ (instructor)) ⋈ teaches ⋈ Π (course))
name,title deptname=“Music” courseid,title

--- Page 784 ---

16.2 TransformationofRelationalExpressions 755
We couldchoose tocompute teaches ⋈ Π (course)first, and thentojoin the
courseid,title
resultwith:
σ (instructor)
deptname=“Music”
However, teaches ⋈ Π (course) is likely to be a large relation, since it
courseid,title
containsonetupleforeverycoursetaught.Incontrast:
σ (instructor) ⋈ teaches
deptname=“Music”
is probably a small relation. To see that it is, we note that a university has fewer in-
structors than courses and, since a university has a large number of departments, it
is likely that only a small fraction of the university instructors are associated with
the Music department. Thus, the preceding expression results in one tuple for each
course taught by an instructor in the Music department. Therefore, the temporary
relation that we must store is smaller than it would have been had we computed
teaches ⋈ Π (course) first.
courseid,title
Thereareotheroptionstoconsiderforevaluatingourquery.Wedonotcareabout
theorderinwhichattributesappearinajoin,sinceitiseasytochangetheorderbefore
displayingtheresult.Thus,forallrelationsr andr :
1 2
r ⋈ r ≡ r ⋈ r
1 2 2 1
Thatis,naturaljoiniscommutative(equivalencerule5).
Usingtheassociativityandcommutativityofthenaturaljoin(rules5and6),con-
siderthefollowingrelational-algebraexpression:
(instructor ⋈ Π (course)) ⋈ teaches
courseid,title
Note thattherearenoattributes incommonbetween Π (course) andinstruc-
courseid,title
tor,sothejoinisjustaCartesianproduct.Ifthereareatuplesininstructorandbtuples
in Π (course), this Cartesian product generates a ∗ b tuples, one for every
courseid,title
possible pair of instructor tuple and course (without regard for whether the instruc-
tor taught the course). This Cartesian productwould produce a very large temporary
relation. However, if the user had entered the precedingexpression, we could use the
associativityandcommutativityofthenaturaljointotransformthisexpressiontothe
moreefficientexpression:
(instructor ⋈ teaches) ⋈ Π (course)
courseid,title
16.2.4 Enumeration of Equivalent Expressions
Query optimizers can use equivalence rules to systematically generate expressions
equivalenttothegivenqueryexpression.Thecostofanexpressioniscomputedbased

--- Page 785 ---

756 Chapter16 QueryOptimization
proceduregenAllEquivalent(E)
EQ={E}
repeat
MatcheachexpressionE inEQwitheachequivalenceruleR
i j
ifanysubexpressione ofE matchesonesideofR
i i j
CreateanewexpressionE′ whichisidenticaltoE,exceptthat
i
e istransformedtomatchtheothersideofR
i j
AddE′ toEQifitisnotalreadypresentinEQ
untilnonewexpressioncanbeaddedtoEQ
Figure 16.5 Proceduretogenerateallequivalentexpressions.
onstatisticsthatarediscussedinSection16.3.Cost-basedqueryoptimizers,described
inSection16.4computethecostofeachalternativeandpicktheleastcostalternative.
Conceptually, enumeration of equivalent expressions can be done as outlined in
Figure 16.5. The process proceeds as follows: Given a query expression E, the set of
equivalent expressions EQ initially contains only E. Now, each expression in EQ is
matched with each equivalence rule. If a subexpression e of any expression E ∈ EQ
j i
(as a special case, e could be E itself) matches one side of an equivalence rule, the
j i
optimizergeneratesacopyE ofE,inwhiche istransformedtomatchtheotherside
k i j
oftherule,andaddsE toEQ.Thisprocesscontinuesuntilnomorenewexpressions
k
canbegenerated.Withaproperlychosensetofequivalencerules,thesetofequivalent
expressionsisfinite,andtheprocesscanbeguaranteedtoterminate.
Forexample, given an expression r ⋈ (s ⋈ t), thecommutativityrule canmatch
the subexpression (s ⋈ t), and would create a new expression r ⋈ (t ⋈ s). The
commutativity rule also matches the join at the root of r ⋈ (s ⋈ t), and creates a
new expression (s ⋈ t) ⋈ r. Associativity and commutativity rules can continue to
be applied to generate new expressions. But eventually applying any equivalence rule
willonlygenerateexpressionsthatwerealreadygeneratedearlier,andtheprocesswill
terminate.
Theprecedingprocessisextremelycostlybothinspaceandintime,butoptimizers
cangreatlyreduceboththespaceandtimecost,usingtwokeyideas.
1. If we generate an expression E′ from an expression E by using an equivalence
1
ruleonsubexpressione,thenE′andE haveidenticalsubexpressionsexceptfor
i 1
e anditstransformation.Evene anditstransformedversionusuallysharemany
i i
identical subexpressions. Expression-representation techniques that allow both
expressionstopointtosharedsubexpressionscanreducethespacerequirement
significantly.

--- Page 786 ---

16.3 EstimatingStatisticsofExpressionResults 757
2. It is not always necessary to generate every expression that can be generated
withtheequivalencerules.Ifanoptimizertakescostestimatesofevaluationinto
account,itmaybeabletoavoidexaminingsomeoftheexpressions, asweshall
see in Section 16.4. We can reduce the time required for optimization by using
techniquessuchasthese.
Withtheseandothertechniquestoreducetheoptimizationtime,equivalencerulescan
beusedtoenumeratealternativeplans,whosecostscanbecomputed;thelowest-cost
plan amongst the alternatives is then chosen. We discuss efficient implementation of
cost-basedqueryoptimizationbasedonequivalencerulesinSection16.4.2.
Somequeryoptimizersuseequivalencerulesinaheuristicmanner.Withsuchan
approach,iftheleft-handsideofanequivalencerulematchesasubtreeinaqueryplan,
thesubtreeisrewrittentomatchtheright-handsideoftherule.Thisprocessisrepeated
till the query plan cannot be further rewritten. Rules must be carefully chosen such
thatthecostdecreaseswhenaruleisapplied,andrewritingmusteventuallyterminate.
Althoughthisapproachcanbeimplementedtoexecutequitefast,thereisnoguarantee
thatitwillfindtheoptimalplan.
Yetotherqueryoptimizersfocusonjoinorderselection,whichisoftenakeyfactor
inquerycost.Wediscussalgorithmsforjoin-orderoptimizationinSection16.4.1.
16.3 Estimating Statistics of Expression Results
The cost of an operation depends on the size and other statistics of its inputs. Given
an expression such as r ⋈ (s ⋈ t) to estimate the cost of joining r with (s ⋈ t), we
needtohaveestimatesofstatisticssuchasthesizeofs⋈ t.
Inthissection,wefirstlistsomestatisticsaboutdatabaserelationsthatarestored
indatabase-systemcatalogs,andthenshowhowtousethestoredstatisticstoestimate
statisticsontheresultsofvariousrelationaloperations.
Given a query expression, we consider it as a tree; we can start from the bottom-
leveloperations,andestimatetheirstatistics,andcontinuetheprocessonhigher-level
operations, till we reach the root of the tree. The size estimates that we compute as
part of these statistics can be used to compute the cost of algorithms for individual
operations in the tree, and these costs can be added up to find the cost of an entire
queryplan,aswesawinChapter15.
Onethingthatwillbecomeclearlaterinthissectionisthattheestimatesarenot
veryaccurate,sincetheyarebasedonassumptionsthatmaynotholdexactly.Aquery-
evaluationplanthathasthelowestestimatedexecutioncostmaythereforenotactually
have the lowestactual execution cost. However, real-worldexperience hasshown that
evenifestimatesarenotprecise,theplanswiththelowestestimatedcostsusuallyhave
actual execution costs that are eitherthe lowestactual execution costs orare close to
thelowestactualexecutioncosts.

--- Page 787 ---

758 Chapter16 QueryOptimization
16.3.1 Catalog Information
Thedatabase-systemcatalogstoresthefollowingstatisticalinformationaboutdatabase
relations:
• n ,thenumberoftuplesintherelationr.
r
• b ,thenumberofblockscontainingtuplesofrelationr.
r
• l ,thesizeofatupleofrelationrinbytes.
r
• f ,theblockingfactorofrelationr—thatis,thenumberoftuplesofrelationrthat
r
fitintooneblock.
• V(A,r),thenumberofdistinctvaluesthatappearintherelationrforattributeA.
ThisvalueisthesameasthesizeofΠ (r).IfAisakeyforrelationr,V(A,r)isn .
A r
Thelaststatistic,V(A,r),canalsobemaintainedforsetsofattributes,ifdesired,instead
ofjustforindividualattributes.Thus,givenasetofattributes,,V(,r)isthesizeof
Π (r).

Ifweassumethatthetuplesofrelationrarestoredtogetherphysicallyinafile,the
followingequationholds:
⌈ ⌉
n
b = r
r f
r
Statisticsaboutindices,suchastheheightsofB+-treeindicesandnumberofleafpages
intheindices,arealsomaintainedinthecatalog.
Ifwewishtomaintainaccuratestatistics,theneverytimearelationismodified,we
must also update the statistics. This update incurs a substantial amount of overhead.
Therefore, most systems do not update the statistics on every modification. Instead,
theyupdatethestatisticsduringperiodsoflightsystemload.Asaresult,thestatistics
used for choosing a query-processing strategy may not be completely accurate. How-
ever,ifnottoomanyupdatesoccurintheintervalsbetweentheupdatesofthestatistics,
the statistics will be sufficiently accurate to provide a good estimation of the relative
costsofthedifferentplans.
The statistical information noted here is simplified. Real-world optimizers often
maintainfurtherstatisticalinformationtoimprovetheaccuracyoftheircostestimates
of evaluation plans. For instance, most databases store the distribution of values for
each attribute as a histogram: in a histogram, the values for the attribute are divided
into a number of ranges, and with each range the histogram associates the number
of tuples whose attribute value lies in that range. Figure 16.6 shows an example of a
histogramforaninteger-valuedattributethattakesvaluesintherange1to25.
Asanexampleofahistogram,therangeofvaluesforanattributeageofarelation
personcouldbedividedinto0—9,10—19,...,90—99(assumingamaximumageof99).
Witheachrangewestoreacountofthenumberofpersontupleswhoseagevalueslie
inthatrange.

--- Page 788 ---

16.3 EstimatingStatisticsofExpressionResults 759
value
ycneuqerf
50
40
30
20
10
1–5 6–10 11–15 16–20 21–25
Figure 16.6 Exampleofhistogram.
ThehistogramshowninFigure16.6,isanequi-widthhistogramsinceitdividesthe
rangeofvaluesintoequal-sizedranges.Incontrast,anequi-depthhistogramadjuststhe
boundaries of the ranges such that each range has the same number of values. Thus,
an equi-depth histogram merely stores the boundaries of partitions of the range, and
neednotstorethenumberofvalues.Forexample,thefollowingcouldbetheequidepth
histogramforthedatawhoseequi-widthhistogramisshowninFigure16.6:
(4,8,14,19)
The histogram indicates that 1∕5th of the tuples have age less than 4, another 1∕5th
haveage≥ 4but< 8,andsoon,withthelast1∕5thhavingage≥ 19.Informationabout
the total number of tuples is also stored with the equi-width histogram. Equi-depth
histogramsarepreferredtoequi-widthhistogramssincetheyprovidebetterestimates,
andoccupylessspace.
Histogramsusedindatabasesystemscanalsorecordthenumberofdistinctvalues
in each range, in addition to the number of tuples with attribute values in that range.
Inourexample,thehistogramcouldstorethenumberofdistinctagevaluesthatliein
eachrange.Withoutsuchhistograminformation,anoptimizerwouldhavetoassume
that the distribution of values is uniform; that is, each range has the same number of
distinctvalues.
Inmanydatabaseapplications,somevaluesareveryfrequent,comparedtoother
values. To get better estimates for queries that specify these values, many databases
storealistofnmostfrequentvaluesforsomen(say5or10),alongwiththenumberof
timeseachvalue appears. Inourexample, ifages4,7,18,19, and23arethefivemost
frequently occurring values, the database could store the number of persons having
eachofthese ages.Thehistogram thenonlystoresstatistics forage valuesotherthan
thesefivevalues,sincewehavenowhaveexactcountsforthesevalues.

--- Page 789 ---

760 Chapter16 QueryOptimization
A histogram takes up only a little space, so histograms on several different at-
tributescanbestoredinthesystemcatalog.
16.3.2 Selection Size Estimation
Thesizeestimateoftheresultofaselectionoperationdependsontheselectionpredi-
cate.Wefirstconsiderasingleequalitypredicate,thenasinglecomparisonpredicate,
andfinallycombinationsofpredicates.
• σ (r): If a is a frequently occurring value for which the occurrence count is
A=a
available,wecanusethatvaluedirectlyasthesizeestimatefortheselection.
Otherwise if there is no histogram available, we assume uniform distribution
of values (i.e., each value appears with equal probability), the selection result is
estimatedtohaven ∕V(A,r)tuples,assumingthatthevalueaappearsinattribute
r
Aofsomerecordofr.Theassumptionthatthevalueaintheselectionappearsin
somerecordisgenerallytrue,andcostestimatesoftenmakeitimplicitly.However,
it is often not realistic to assume that each value appears with equal probability.
The course id attribute in the takes relation is an example where the assumption
is not valid. It is reasonable to expect that a popular undergraduate course will
have many more students than a smaller specialized graduate course. Therefore,
certaincourse idvaluesappearwithgreaterprobabilitythandoothers.Despitethe
factthattheuniform-distributionassumptionisoftennotcorrect,itisareasonable
approximation of reality in many cases, and it helps us to keep our presentation
relativelysimple.
IfahistogramisavailableonattributeA,wecanlocatetherangethatcontains
the value a, and modify the above-mentioned estimate n ∕V(A,r) by using the
r
frequency count for that range instead of n , and the number of distinct values
r
thatoccursinthatrangeinsteadofV(A,r).
• σ (r): Consider a selection of the form σ (r). Suppose that the lowest and
A≤v A≤v
highestvalues(min(A,r)andmax(A,r))fortheattributearestoredinthecatalog.
Assuming that values are uniformly distributed, we can estimate the number of
recordsthatwillsatisfytheconditionA ≤ vas:
° 0ifv <min(A,r)
° n ifv ≥ max(A,r),and,
r
° n ⋅ v−min(A,r) ,otherwise.
r max(A,r)−min(A,r)
IfahistogramisavailableonattributeA,wecangetamoreaccurateestimate;
weleavethedetailsasanexerciseforyou.
Insomecases,suchaswhenthequeryispartofastoredprocedure,thevalue
vmaynotbeavailablewhenthequeryisoptimized.Insuchcases,weassumethat
approximatelyone-halftherecordswillsatisfythecomparisoncondition.Thatis,

--- Page 790 ---

16.3 EstimatingStatisticsofExpressionResults 761
Note 16.2 COMPUTINGANDMAINTAININGSTATISTICS
Conceptually,statisticsonrelationscanbethoughtofasmaterializedviews,which
should be automatically maintained when relations are modified. Unfortunately,
keepingstatisticsup-to-dateoneveryinsert,deleteorupdatetothedatabasecanbe
very expensive. On the otherhand, optimizersgenerallydo not need exact statis-
tics:anerrorofafew percentmayresultinaplanthatisnotquite optimalbeing
chosen, but the alternative plan chosen is likely to have a cost which is within a
few percent of the optimal cost. Thus, it is acceptable to have statistics that are
approximate.
Databasesystemsreducethecostofgeneratingandmaintainingstatistics,as
outlinedbelow,byexploitingthefactthatstatisticscanbeapproximate.
• Statistics are often computed from a sample of the underlying data, instead
ofexaminingtheentirecollectionofdata.Forexample, afairlyaccurate his-
togram can be computed from a sample of a few thousand tuples, even on a
relation that has millions, or hundreds of millions of records. However, the
sampleusedmustbearandomsample;asamplethatisnotrandommayhave
anexcessiverepresentationofonepartoftherelationandcangivemisleading
results.Forexample,ifweusedasampleofinstructorstocomputeahistogram
onsalaries,ifthesample hasan overrepresentationoflower-paidinstructors
the histogram would result in wrong estimates. Database systems today rou-
tinelyuserandomsamplingtocreatestatistics.Seethebibliographicalnotes
onlineforreferencesonsampling.
• Statistics are not maintained on every update to the database. In fact, some
databasesystemsneverupdatestatisticsautomatically.Theyrelyondatabase
administrators periodically running a command to update statistics. Oracle
andPostgreSQLprovideanSQLcommandcalledanalyzethatgeneratesstatis-
ticsonspecifiedrelations,oronallrelations.IBMDB2supportsanequivalent
commandcalledrunstats. Seethesystem manualsfordetails.Youshouldbe
awarethatoptimizerssometimeschooseverybadplansduetoincorrectstatis-
tics.Manydatabasesystems,suchasIBMDB2,Oracle,andSQLServer,update
statisticsautomaticallyatcertainpointsoftime.Forexample,thesystemcan
keep approximate track of how many tuples there are in a relation and re-
compute statistics if this number changes significantly. Another approach is
tocompareestimatedcardinalitiesofarelationscanwithactualcardinalities
whenaqueryisexecuted,andiftheydiffersignificantly,initiateanupdateof
statisticsforthatrelation.

--- Page 791 ---

762 Chapter16 QueryOptimization
we assume the result has n ∕2 tuples; the estimate may be very inaccurate, but it
r
isthebestwecandowithoutanyfurtherinformation.
• Complexselections:
° Conjunction:Aconjunctiveselectionisaselectionoftheform:
σ (r)
θ ∧θ ∧⋯∧θ
1 2 n
We can estimate the result size of such a selection: For each θ, we estimate
i
thesizeoftheselectionσ (r),denotedbys,asdescribedpreviously.Thus,the
θ i
probabilitythatatuplein i therelationsatisfiesselectionconditionθ iss∕n .
i i r
The preceding probability is called the selectivity of the selection σ (r).
θ
i
Assumingthattheconditionsareindependentofeachother,theprobabilitythat
atuplesatisfiesalltheconditionsissimplytheproductofalltheseprobabilities.
Thus,weestimatethenumberoftuplesinthefullselectionas:
s ∗ s ∗ ⋯ ∗ s
n ∗ 1 2 n
r nn
r
° Disjunction:Adisjunctiveselectionisaselectionoftheform:
σ (r)
θ ∨θ ∨⋯∨θ
1 2 n
A disjunctive condition is satisfied by the union of all records satisfying the
individual,simpleconditionsθ.
i
Asbefore,lets∕n denotetheprobabilitythatatuplesatisfiesconditionθ.
i r i
The probability that the tuple will satisfy the disjunction is then 1 minus the
probabilitythatitwillsatisfynoneoftheconditions:
s s s
1−(1− 1) ∗ (1− 2) ∗ ⋯∗ (1− n)
n n n
r r r
Multiplyingthisvaluebyn givesustheestimatednumberoftuplesthatsatisfy
r
theselection.
° Negation:Intheabsenceofnulls,theresultofaselectionσ (r)issimplythe
¬θ
tuplesofrthatarenotinσ (r).Wealreadyknowhowtoestimatethenumber
θ
oftuplesinσ (r).Thenumberoftuplesinσ (r)isthereforeestimatedtobe
θ ¬θ
n minustheestimatednumberoftuplesinσ (r).
r θ
We can account for nulls by estimating the number of tuples for which
theconditionθwouldevaluatetounknown,andsubtractingthatnumberfrom
theaboveestimate,ignoringnulls.Estimatingthatnumberwouldrequireextra
statisticstobemaintainedinthecatalog.
16.3.3 Join Size Estimation
Inthissection,weseehowtoestimatethesizeoftheresultofajoin.

--- Page 792 ---

16.3 EstimatingStatisticsofExpressionResults 763
The Cartesian product r ×scontainsn ∗ n tuples. Each tuple of r ×s occupies
r s
l +l bytes,fromwhichwecancalculatethesizeoftheCartesianproduct.
r s
Estimatingthesizeofanaturaljoinissomewhatmorecomplicatedthanestimating
thesizeofaselectionorofaCartesianproduct.Letr(R)ands(S)berelations.
• IfR ∩ S = ∅—thatis,therelationshavenoattributeincommon—thenr ⋈ sis
thesameasr × s,andwecanuseourestimationtechniqueforCartesianproducts.
• If R ∩ S is a key for R, then we know that a tuple of s will join with at most
one tuple from r. Therefore,the number of tuples inr ⋈ sis nogreaterthan the
number of tuples in s. The case where R ∩ S is a key for S is symmetric to the
case just described. If R∩S forms a foreign key of S, referencing R, the number
oftuplesinr ⋈ sisexactlythesameasthenumberoftuplesins.
• ThemostdifficultcaseiswhenR∩S isakeyforneitherRnorS.Inthiscase,we
assume, as we did for selections, that each value appears with equal probability.
Consideratupletofr,andassumeR∩S ={A}.Weestimatethattupletproduces
n
s
V(A,s)
tuplesinr ⋈ s,sincethisnumberistheaveragenumberoftuplesinswithagiven
value for the attributes A. Considering all the tuples in r, we estimate that there
are
n ∗ n
r s
V(A,s)
tuples in r ⋈ s. Observe that, if we reverse the roles of r and s in the preceding
estimate,weobtainanestimateof
n ∗ n
r s
V(A,r)
tuples in r ⋈ s. These two estimates differ if V(A,r) ≠ V(A,s). If this situation
occurs, there are likely to be dangling tuples that do not participate in the join.
Thus,thelowerofthetwoestimatesisprobablythemoreaccurateone.
The preceding estimate of join size may be too high if the V(A,r) values for
attributeAinr havefewvaluesincommonwiththeV(A,s)valuesforattributeA
ins.However,thissituationisunlikelytohappenintherealworld,sincedangling
tupleseitherdonotexistorconstituteonlyasmallfractionofthetuples,inmost
real-worldrelations.
Moreimportant,theprecedingestimatedependsontheassumptionthateach
value appears with equal probability. More sophisticated techniques for size esti-
mationhavetobeusedifthisassumptiondoesnothold.Forexample,ifwehave
histogramson thejoinattributesofbothrelations,andbothhistogramshavethe
same ranges, then we can use the above estimation technique within each range,

--- Page 793 ---

764 Chapter16 QueryOptimization
using the number of rows with values in the range instead of n or n , and the
r s
numberofdistinctvaluesinthatrange,insteadofV(A,r)orV(A,s).Wethenadd
up the size estimates obtained for each range to get the overall size estimate. We
leavethecasewherebothrelationshavehistogramsonthejoinattribute,butthe
histogramshavedifferentranges,asanexerciseforyou.
We can estimate the size of a theta join r ⋈ s by rewriting the join as σ (r ×s)
θ θ
and using the size estimates for Cartesian products along with the size estimates for
selections,whichwesawinSection16.3.2.
Toillustrateallthesewaysofestimatingjoinsizes,considertheexpression:
student ⋈ takes
Assumethefollowingcataloginformationaboutthetworelations:
• n = 5000.
student
• n = 10000.
takes
• V(ID,takes) = 2500, which implies that only half the students have taken any
course(thisisunrealistic,butweuseittoshowthatoursizeestimatesarecorrect
eveninthiscase),andonaverage,eachstudentwhohastakenacoursehastaken
fourcourses.
NotethatsinceIDisaprimarykeyofstudent,V(ID,student) = n = 5000.
student
TheattributeIDintakesisaforeignkeyonstudent,andnullvaluesdonotoccurin
takes.ID,sinceIDispartoftheprimarykeyoftakes;thus,thesizeofstudent ⋈ takes
isexactlyn ,whichis10000.
takes
Wenowcomputethesizeestimatesforstudent ⋈ takeswithoutusinginformation
about foreign keys. Since V(ID,takes) = 2500 and V(ID,student) = 5000, the two
estimateswegetare5000 ∗ 10000∕2500 = 20000and5000 ∗ 10000∕5000 = 10000,
andwechoosethelowerone.Inthiscase,theloweroftheseestimatesisthesameas
thatwhichwecomputedearlierfrominformationaboutforeignkeys.
16.3.4 Size Estimation for Other Operations
Nextweoutlinehowtoestimatethesizesoftheresultsofotherrelational-algebraop-
erations.
• Projection:Theestimated size(numberofrecordsornumberoftuples) ofapro-
jectionoftheformΠ (r)isV(A,r),sinceprojectioneliminatesduplicates.
A
• Aggregation:Thesizeof γ (r)issimplyV(G,r),sincethereisonetuplein γ (r)
G A G A
foreachdistinctvalueofG.
• Setoperations:Ifthetwoinputstoasetoperationareselectionsonthesamerela-
tion,wecanrewritethesetoperationasdisjunctions,conjunctions,ornegations.
Forexample,σ (r)∪σ (r)canberewrittenasσ (r).Similarly,wecanrewrite
θ θ θ ∨θ
1 2 1 2

--- Page 794 ---

16.3 EstimatingStatisticsofExpressionResults 765
intersectionsasconjunctions,andwecanrewritesetdifferencebyusingnegation,
solongasthetworelationsparticipatinginthesetoperationsareselectionsonthe
samerelation.Wecanthenusetheestimatesforselectionsinvolvingconjunctions,
disjunctions,andnegationinSection16.3.2.
Iftheinputsarenotselectionsonthesamerelation,weestimatethesizesthis
way: The estimated size of r ∪s is the sum of the sizes of r and s. The estimated
sizeofr∩sistheminimumofthesizesofrands.Theestimatedsizeofr−sisthe
same size as r. All three estimates may be inaccurate, but provide upper bounds
onthesizes.
• Outerjoin:Theestimatedsizeofr⟕sisthesizeofr ⋈ splusthesizeofr;thatof
r⟖sissymmetric,whilethatofr⟗sisthesizeofr ⋈ splusthesizesofr and
s.Allthreeestimatesmaybeinaccurate,butprovideupperboundsonthesizes.
16.3.5 Estimation of Number of Distinct Values
The size estimates discussed earlier depend on statistics such as histograms, or at a
minimum,thenumberofdistinctvaluesforanattribute.Whilethesestatisticscanbe
precomputed and stored for relations in the database, we need to compute them for
intermediate results. Note that estimation of the number of sizes and the number of
distinctvaluesofattributesinanintermediateresultE helpsusestimatethesizesand
i
numberofdistinctvaluesofattributesinthenextlevelintermediateresultsthatuseE.
i
Forselections,thenumberofdistinctvaluesofanattribute(orsetofattributes)A
intheresultofaselection,V(A,σ (r)),canbeestimatedintheseways:
θ
• If the selection condition θ forces A to take on a specified value (e.g., A = 3),
V(A,σ (r)) = 1.
θ
• IfθforcesAtotakeononeofaspecifiedsetofvalues(e.g.,(A = 1∨A = 3∨A = 4)),
thenV(A,σ (r))issettothenumberofspecifiedvalues.
θ
• IftheselectionconditionθisoftheformAopv,whereopisacomparisonoperator,
V(A,σ (r))isestimatedtobeV(A,r) ∗ s,wheresistheselectivityoftheselection.
θ
• Inallothercasesofselections,weassumethatthedistributionofAvaluesisinde-
pendentofthedistributionofthevaluesonwhichselectionconditionsarespeci-
fied,andweuseanapproximateestimateofmin(V(A,r),n ).Amoreaccurate
σ θ(r)
estimate can be derived for this case using probability theory, but the preceding
approximationworksfairlywell.
For joins, the number of distinct values of an attribute (or set of attributes) A in
theresultofajoin,V(A,r ⋈ s),canbeestimatedintheseways:

--- Page 795 ---

766 Chapter16 QueryOptimization
• If all attributes in A are from r, V(A,r ⋈ s) is estimated as min(V(A,r),n ),
r⋈s
and similarly if all attributes in A are from s, V(A,r ⋈ s) is estimated to be
min(V(A,s),n ).
r⋈s
• IfAcontainsattributesA1fromrandA2froms,thenV(A,r ⋈ s)isestimatedas:
min(V(A1,r) ∗ V(A2−A1,s),V(A1−A2,r) ∗ V(A2,s),n )
r⋈s
NotethatsomeattributesmaybeinA1aswellasinA2,andA1−A2andA2−A1
denote,respectively,attributesinAthatareonlyfromrandattributesinAthatare
only from s. Again, more accurate estimates can be derived by using probability
theory,buttheaboveapproximationsworkfairlywell.
The estimates of distinct values are straightforward for projections: They are the
sameinΠ (r)asinr.Thesameholdsforgroupingattributesofaggregation.Forresults
A
of sum, count, and average, we can assume, for simplicity, that all aggregate values
are distinct. For min(A) and max(A), the number of distinct values can be estimated
as min(V(A,r),V(G,r)), whereG denotes the grouping attributes. We omitdetailsof
estimatingdistinctvaluesforotheroperations.
16.4 Choice of Evaluation Plans
Generation of expressions is only part of the query-optimization process, since each
operationintheexpressioncanbeimplementedwithdifferentalgorithms.Anevalua-
tion plan defines exactly what algorithm should be used for each operation, and how
theexecutionoftheoperationsshouldbecoordinated.
Given an evaluation plan, we can estimate its cost using statistics estimated by
thetechniquesinSection16.3coupledwithcostestimatesforvariousalgorithmsand
evaluationmethodsdescribedinChapter15.
A cost-based optimizer explores the space of all query-evaluation plans that are
equivalent to the given query, and chooses the one with the least estimated cost. We
have seen how equivalence rules can be used to generate equivalent plans. However,
cost-basedoptimizationwitharbitraryequivalencerulesisfairlycomplicated.Wefirst
coverasimplerversionofcost-basedoptimization,whichinvolvesonlyjoin-orderand
join algorithm selection, in Section 16.4.1. Then, in Section 16.4.2, we briefly sketch
howageneral-purposeoptimizerbasedonequivalencerulescanbebuilt,withoutgoing
intodetails.
Exploringthespaceofallpossibleplansmaybetooexpensiveforcomplexqueries.
Most optimizers include heuristics to reduce the cost of query optimization, at the
potentialriskofnotfindingtheoptimalplan.WestudysomesuchheuristicsinSection
16.4.3.

--- Page 796 ---

16.4 ChoiceofEvaluationPlans 767
16.4.1 Cost-Based Join-Order Selection
ThemostcommontypeofqueryinSQLconsistsofajoinofafewrelations,withjoin
predicatesandselectionsspecifiedinthewhereclause.Inthissectionweconsiderthe
problemofchoosingtheoptimaljoinorderforsuchaquery.
Foracomplexjoinquery,thenumberofdifferentqueryplansthatareequivalent
tothequerycanbelarge.Asanillustration,considertheexpression:
r ⋈ r ⋈ ⋯ ⋈ r
1 2 n
wherethejoinsareexpressedwithoutanyordering.Withn = 3,thereare12different
joinorderings:
r ⋈ (r ⋈ r ) r ⋈ (r ⋈ r ) (r ⋈ r ) ⋈ r (r ⋈ r ) ⋈ r
1 2 3 1 3 2 2 3 1 3 2 1
r ⋈ (r ⋈ r ) r ⋈ (r ⋈ r ) (r ⋈ r ) ⋈ r (r ⋈ r ) ⋈ r
2 1 3 2 3 1 1 3 2 3 1 2
r ⋈ (r ⋈ r ) r ⋈ (r ⋈ r ) (r ⋈ r ) ⋈ r (r ⋈ r ) ⋈ r
3 1 2 3 2 1 1 2 3 2 1 3
In general, with n relations, there are (2(n − 1))!∕(n − 1)! different join orders.
(We leave the computation of this expression for you to do in Exercise 16.12.) For
joinsinvolvingsmallnumbersofrelations,thisnumberisacceptable;forexample,with
n = 5, the number is 1680. However, as n increases, this number rises quickly. With
n = 7,thenumberis665,280;withn = 10,thenumberisgreaterthan17.6billion!
Luckily, it is not necessary to generate all the expressions equivalent to a given
expression.Forexample,supposewewanttofindthebestjoinorderoftheform:
(r ⋈ r ⋈ r ) ⋈ r ⋈ r
1 2 3 4 5
whichrepresentsalljoinorderswherer ,r ,andr arejoinedfirst(insomeorder),and
1 2 3
the result is joined (in some order) with r and r . There are 12 different join orders
4 5
for computing r ⋈ r ⋈ r , and 12 orders for computing the join of this result with
1 2 3
r andr .Thus,thereappeartobe144joinorderstoexamine.However,oncewehave
4 5
foundthebestjoinorderforthesubsetofrelations{r ,r ,r },wecanusethatorderfor
1 2 3
furtherjoinswithr andr ,andwecanignoreallcostlierjoinordersofr ⋈ r ⋈ r .
4 5 1 2 3
Thus,insteadof144choicestoexamine,weneedtoexamineonly12+12choices.
Usingthisidea,wecandevelopadynamic-programmingalgorithmforfindingopti-
maljoin orders. Dynamic-programmingalgorithmsstore resultsof computations and
reusethem,aprocedurethatcanreduceexecutiontimegreatly.
We now consider how to find the optimal join order for a set of n relations S =
{r ,r ,…,r }, where each relation may have selection conditions, and a set of join
1 2 n
conditionsbetweentherelationsr isprovided.Weassume thatrelationshaveunique
i
names.
Arecursiveprocedureimplementingthedynamic-programmingalgorithmappears
inFigure16.7andisinvokedasFindBestPlan(S),whereSisthesetofrelationsabove.
Theprocedureappliesselectionsonindividualrelationsattheearliestpossiblepoint,

--- Page 797 ---

768 Chapter16 QueryOptimization
procedureFindBestPlan(S)
if(bestplan[S].cost ≠ ∞)/*bestplan[S]alreadycomputed*/
returnbestplan[S]
if(S containsonly1relation)
setbestplan[S].planandbestplan[S].cost basedonthebestwayof
accessingS usingselectionconditions(ifany)onS.
elseforeachnon-emptysubsetS1ofS suchthatS1 ≠ S
P1=FindBestPlan(S1)
P2=FindBestPlan(S−S1)
foreachalgorithmAforjoiningtheresultsofP1andP2
//Forindexed-nestedloopsjoin,theouterrelationcouldbeP1orP2.
//Similarlyforhash-join,thebuildrelationcouldbeP1orP2.
//Weassumethealternativesareconsideredasseparatealgorithms.
//WeassumecostofAdoesnotincludecostofreadingtheinputs.
ifalgorithmAisindexednestedloops
LetP andP denotetheouterandinnerinputsofA
o i
ifP hasasinglerelationr,andr hasanindexonthejoin
i i i
attributes
plan=“executeP .plan;joinresultsofP andr usingA”,
o o i
withanyselectionconditiononP performedas
i
partofthejoincondition
cost=P .cost+costofA
o
else/*Cannotuseindexednestedloopsjoin*/
cost=∞
else
plan=“executeP1.plan;executeP2.plan;
joinresultsofP1andP2usingA”
cost=P1.cost+P2.cost+costofA
ifcost< bestplan[S].cost
bestplan[S].cost =cost
bestplan[S].plan=plan
returnbestplan[S]
Figure 16.7 Dynamic-programming algorithmforjoin-orderoptimization.
that is, when the relations are accessed. It is easiest to understand the procedure as-
sumingthat alljoinsare natural joins,although the procedureworks unchanged with
any join condition. With arbitrary join conditions, the join of two subexpressions is
understoodtoincludealljoinconditionsthatrelateattributesfromthetwosubexpres-
sions.

--- Page 798 ---

16.4 ChoiceofEvaluationPlans 769
The procedure stores the evaluation plans it computes in an associative array
bestplan, which is indexed by sets of relations. Each element of the associative array
containstwocomponents:thecostofthebestplanofS,andtheplanitself.Thevalue
of bestplan[S].cost is assumed to be initialized to ∞ if bestplan[S] has not yet been
computed.
Theprocedurefirstchecksifthebestplanforcomputingthejoinofthegivenset
ofrelationsShasbeencomputedalready(andstoredintheassociativearraybestplan);
ifso,itreturnsthealreadycomputedplan.
IfScontainsonlyonerelation,thebestwayofaccessingS(takingselectionsonS,
ifany,intoaccount)isrecordedinbestplan.Thismayinvolveusinganindextoidentify
tuples,andthenfetchingthetuples(oftenreferredtoasanindexscan),orscanningthe
entirerelation(oftenreferredtoasarelationscan).2 Ifthereisanyselectioncondition
onS,otherthanthoseensuredbyanindexscan,aselectionoperationisaddedtothe
plantoensureallselectionsonS aresatisfied.
Otherwise,ifS containsmorethanonerelation,theproceduretrieseverywayof
dividingS intotwodisjointsubsets.Foreachdivision,theprocedurerecursivelyfinds
the best plans for each of the two subsets. It then considers all possible algorithms
forjoiningtheresultsofthetwosubsets.Notethatsinceindexednestedloopsjoincan
potentiallyuseeitherinputP1orP2astheinnerinput,weconsiderthetwoalternatives
as two different algorithms. The choice of build versus probe input also leads us to
considerthetwochoicesforhashjoinastwodifferentalgorithms.
The cost of each alternative is considered, and the least cost option chosen. The
join cost considered should not include the cost of reading the inputs, since we as-
sume that the input is pipelined from the precedingoperators, whichcould be a rela-
tion/indexscan,oraprecedingjoin.Recallthatsomeoperators,suchashashjoin,can
be treated as having suboperators with a blocking (materialized) edge between them,
butwiththeinputandoutputedgesofthejoinbeingpipelined.Thejoincostformulae
that we saw in Chapter 15 can be used with appropriate modifications to ignore the
costofreadingtheinputrelations.Notethatindexednestedloopsjoinistreateddiffer-
entlyfromotherjointechniques:theplanaswellasthecostaredifferentinthiscase,
sincewedonotperformarelation/indexscanoftheinnerinput,andtheindexlookup
costisincludedinthecostofindexednestedloopsjoin.
Theprocedurepicksthecheapestplanfromamongallthealternativesfordividing
S intotwosetsandthealgorithmsforjoiningtheresultsofthetwosets.Thecheapest
plan and its cost are stored in the array bestplan and returned by the procedure. The
time complexity of the procedure can be shown to be O(3n) (see Practice Exercise
16.13).
Theorderinwhichtuplesaregeneratedbythejoinofasetofrelationsisimportant
for finding the best overall join order, since it can affect the cost of further joins. For
2Ifanindexcontainsalltheattributesofarelationthatareusedinaquery,itispossibletoperformanindex-onlyscan,
whichretrievestherequiredattributevaluesfromtheindex,withoutfetchingactualtuples.

--- Page 799 ---

770 Chapter16 QueryOptimization
instance,ifmergejoinisused,apotentiallyexpensivesortoperationisrequiredonthe
input,unlesstheinputisalreadysortedonthejoinattribute.
Aparticularsortorderofthetuplesissaidtobeaninterestingsortorderifitcould
beusefulforalateroperation.Forinstance,generatingtheresultofr ⋈ r ⋈ r sorted
1 2 3
on theattributes commonwithr orr maybe useful, but generatingitsorted on the
4 5
attributes common to only r and r is not useful. Using merge join for computing
1 2
r ⋈ r ⋈ r maybecostlierthanusingsomeotherjointechnique,butitmayprovide
1 2 3
anoutputsortedinaninterestingsortorder.
Hence, it is not sufficient to find the best join order for each subset of the set of
ngivenrelations.Instead,wehavetofindthebestjoinorderforeachsubset,foreach
interesting sort order of the join result for that subset. The bestplan array can now
be indexed by [S,o], where S is a set of relations, and o is an interesting sort order.
The FindBestPlan function can then be modified to take interesting sort orders into
consideration;weleavedetailsasanexerciseforyou(seePracticeExercise16.11).
The number of subsets of n relationsis 2n. The number of interestingsort orders
isgenerallynotlarge.Thus,about2n joinexpressionsneedtobestored.Thedynamic-
programmingalgorithmforfindingthebestjoinordercanbeextendedtohandlesort
orders. Specifically, when considering sort-merge join, the cost of sorting has to be
added if an input (which may be a relation, or the result of a join operation) is not
sortedonthejoinattribute,butisnotaddedifitissorted.
The cost of the extended algorithm depends on the number of interesting orders
foreachsubsetofrelations;sincethisnumberhasbeenfoundtobesmallinpractice,
thecostremainsatO(3n).Withn = 10,thisnumberisaround59,000,whichismuch
betterthanthe17.6billiondifferentjoinorders.Moreimportant,thestoragerequired
ismuchlessthanbefore,sinceweneedtostoreonlyonejoinorderforeachinteresting
sort orderofeachof1024 subsets ofr ,…,r .Althoughbothnumbersstillincrease
1 10
rapidly withn, commonlyoccurringjoins usually have less than 10 relationsand can
behandledeasily.
ThecodeshowninFigure16.7actuallyconsiderseachpossiblewayofdividingS
into two disjoint subsets twice, since each of the two subsets can play the role of S1.
Consideringthedivisiontwicedoesnotaffectcorrectness,butwastestime.Thecode
canbe optimizedasfollows: findthealphabeticallysmallestrelationr inS1, andthe
i
alphabeticallysmallestrelationr inS−S1,andexecutethelooponlyifr < r.Doing
j i j
soensuresthateachdivisionisconsideredonlyonce.
Further,thecodealsoconsidersallpossiblejoinorders,includingthosethatcon-
tain Cartesian products; for example, if two relations r and r do not have any join
1 3
conditionlinkingthetworelations,thecodewillstillconsiderS ={r ,r },whichwill
1 3
result in a Cartesian product. It is possible to take join conditions into account, and
modifythecodetoonlygeneratedivisionsthatdonotresultinCartesianproducts.This
optimizationcansave agreatdealoftimeformanyqueries.See theFurtherReading
section at the end of the chapter for references providing more details on Cartesian-
product-freejoinorderenumeration.

--- Page 800 ---

16.4 ChoiceofEvaluationPlans 771
16.4.2 Cost-Based Optimization with Equivalence Rules
The join-order optimization technique we just saw handles the most common class
of queries, which perform an inner join of a set of relations. However, many queries
use other features, such as aggregation, outer join, and nested queries, which are not
addressedbyjoin-orderselection,butcanbehandledbyusingequivalencerules.
In this section we outline how to create a general-purpose cost-based optimizer
basedonequivalencerules.Equivalencerulescanhelpexplorealternativeswithawide
varietyofoperations,suchasouterjoins,aggregations,andsetoperations,aswehave
seenearlier.Equivalencerulescanbeaddedifrequiredforfurtheroperations,suchas
operatorsthatreturnthetop-Kresultsinsortedorder.
In Section 16.2.4, we saw how an optimizer could systematically generate all ex-
pressionsequivalenttothegivenquery.Theprocedureforgeneratingequivalentexpres-
sionscanbemodifiedtogenerateallpossibleevaluationplansasfollows:Anewclass
ofequivalencerules,calledphysicalequivalencerules,isaddedthatallowsalogicalop-
eration,suchasajoin,tobetransformedtoaphysicaloperation,suchasahashjoin,
oranested-loopsjoin.Byaddingsuchrulestotheoriginalsetofequivalencerules,the
procedure can generate all possible evaluation plans. The cost estimation techniques
wehaveseenearliercanthenbeusedtochoosetheoptimal(i.e.,theleast-cost)plan.
However, the procedure shown in Section 16.2.4 is very expensive, even if we do
not consider generation of evaluation plans. To make the approach work efficiently
requiresthefollowing:
1. A space-efficient representation of expressions that avoids making multiple
copiesofthesamesubexpressionswhenequivalencerulesareapplied.
2. Efficienttechniquesfordetectingduplicatederivationsofthesameexpression.
3. Aformofdynamicprogrammingbasedonmemoization,whichstorestheoptimal
queryevaluationplanforasubexpressionwhenitisoptimizedforthefirsttime;
subsequentrequeststooptimizethesamesubexpressionarehandledbyreturning
thealreadymemorizedplan.
4. Techniques that avoid generating all possible equivalent plans by keeping track
ofthecheapestplangeneratedforanysubexpressionuptoanypointoftime,and
pruning away any plan that is more expensive than the cheapest plan found so
farforthatsubexpression.
The details are more complex than we wish to deal with here. This approach was pi-
oneered by the Volcano research project, and the query optimizer of SQL Server is
basedonthisapproach.Seethebibliographicalnotesforreferencescontainingfurther
information.
16.4.3 Heuristics in Optimization
Adrawbackofcost-basedoptimizationisthecostofoptimizationitself.Althoughthe
costofqueryoptimizationcanbereducedbycleveralgorithms,thenumberofdifferent

--- Page 801 ---

772 Chapter16 QueryOptimization
evaluation plans foraquerycan be verylarge, and findingtheoptimal planfrom this
set requires a lot of computational effort. Hence, optimizers use heuristics to reduce
thecostofoptimization.
An example of a heuristic rule is the following rule for transforming relational-
algebraqueries:
• Performselectionoperationsasearlyaspossible.
A heuristic optimizer would use this rule without finding out whether the cost is re-
ducedbythistransformation.InthefirsttransformationexampleinSection16.2,the
selectionoperationwaspushedintoajoin.
We say that the preceding rule is a heuristic because it usually, but not always,
helpstoreducethecost. Foranexample of whereitcanresultinan increaseincost,
consider an expression σ (r ⋈ s), where the condition θ refers to only attributes in
θ
s.Theselectioncancertainlybeperformedbeforethejoin.However,ifr isextremely
smallcomparedtos,andifthereisanindexonthejoinattributesofs,butnoindexon
the attributes used by θ, then it is probably a bad idea to perform the selection early.
Performingtheselectionearly—thatis,directlyons—wouldrequiredoingascanofall
tuplesins.Itisprobablycheaper,inthiscase,tocomputethejoinbyusingtheindex
andthentorejecttuplesthatfailtheselection.(Thiscaseisspecificallyhandledbythe
dynamicprogrammingalgorithmforjoinorderoptimization.)
Theprojectionoperation,liketheselectionoperation,reducesthesizeofrelations.
Thus,wheneverweneedtogenerate atemporary relation,itisadvantageous toapply
immediatelyanyprojectionsthatarepossible.Thisadvantagesuggestsacompanionto
the“performselectionsearly”heuristic:
• Performprojectionsearly.
Itisusuallybettertoperformselectionsearlierthanprojections,sinceselectionshave
the potential to reduce the sizes of relations greatly, and selections enable the use of
indicestoaccesstuples.Anexamplesimilartotheoneusedfortheselectionheuristic
shouldconvinceyouthatthisheuristicdoesnotalwaysreducethecost.
Optimizers based on join-order enumeration typically use heuristic transforma-
tions to handle constructs other than joins, and applying the cost-based join-order
selection algorithm to subexpressions involving only joins and selections. Details of
such heuristics are for the most part specific to individual optimizers, and we do not
coverthem.
Mostpracticalqueryoptimizershavefurtherheuristicstoreducethecostofopti-
mization. For example, many query optimizers, such as the System R optimizer,3 do
notconsideralljoinorders,butratherrestrictthesearchtoparticularkindsofjoinor-
3SystemRwasoneofthefirstimplementationsofSQL,anditsoptimizerpioneeredtheideaofcost-basedjoin-order
optimization.

--- Page 802 ---

16.4 ChoiceofEvaluationPlans 773
r5
r4
r3 r4 r5
r3
r1 r2
r1 r2
(a) Left-deep join tree (b) Non-left-deep join tree
Figure 16.8 Left-deepjointrees.
ders.TheSystemRoptimizerconsidersonlythosejoinorderswheretherightoperand
ofeachjoinisoneoftheinitialrelationsr ,…,r .Suchjoinordersarecalledleft-deep
1 n
join orders. Left-deepjoin orders are particularlyconvenientfor pipelined evaluation,
since the right operand is a stored relation, and thus only one input to each join is
pipelined.
Figure16.8illustratesthedifferencebetweenleft-deepjointreesandnon-left-deep
jointrees.Thetimeittakestoconsiderallleft-deepjoinordersisO(n!),whichismuch
less than the time to consider all join orders. With the use of dynamic-programming
optimizations, the System R optimizer can find the best join order in time O(n2n).
ContrastthiscostwiththeO(3n)timerequiredtofindthebestoveralljoinorder.The
SystemRoptimizerusesheuristicstopushselectionsandprojectionsdownthequery
tree.
Aheuristicapproachtoreducethecostofjoin-orderselection,whichwasoriginally
usedinsomeversionsofOracle,worksroughlythisway:Forann-wayjoin,itconsiders
n evaluation plans. Each plan uses a left-deepjoin order, starting with adifferentone
ofthe nrelations.Theheuristic constructs thejoinorderforeachofthen evaluation
plansbyrepeatedlyselectingthe“best”relationtojoinnext,onthebasisofaranking
ofthe availableaccesspaths. Eithernested-loop orsort-merge join ischosenforeach
ofthejoins,dependingontheavailableaccesspaths.Finally,theheuristicchoosesone
ofthenevaluationplansinaheuristicmanner,onthebasisofminimizingthenumber
of nested-loop joins that do not have an index available on the inner relation and on
thenumberofsort-mergejoins.
Query-optimization approaches that apply heuristic plan choices for some parts
of the query, with cost-based choice based on generation of alternative access plans
onotherpartsofthequery,havebeenadoptedinseveralsystems.Theapproachused
in System R and in its successor, the Starburst project, is a hierarchical procedure
based on the nested-block concept of SQL. The cost-based optimization techniques
describedhereareusedforeachblockofthequeryseparately.Theoptimizersinseveral

--- Page 803 ---

774 Chapter16 QueryOptimization
databaseproducts,suchasIBMDB2andOracle,arebasedontheaboveapproach,with
extensionstohandleotheroperationssuchasaggregation.ForcompoundSQLqueries
(using the∪, ∩, or − operation), the optimizerprocesses each component separately
andcombinestheevaluationplanstoformtheoverallevaluationplan.
Most optimizers allow a cost budget to be specified for query optimization. The
searchfortheoptimalplanisterminatedwhentheoptimizationcostbudgetisexceeded,
andthebestplanfounduptothatpointisreturned.Thebudgetitselfmaybesetdynam-
ically;forexample,ifacheapplanisfoundforaquery,thebudgetmaybereduced,on
thepremisethatthereisnopointspendingalotoftimeoptimizingthequeryifthebest
plan found so far isalreadyquite cheap. On the otherhand, if the best plan found so
farisexpensive,itmakessensetoinvestmoretimeinoptimization,whichcouldresult
inasignificantreductioninexecutiontime.Tobestexploitthisidea,optimizersusually
first apply cheap heuristics to find a plan and then start full cost-based optimization
withabudgetbasedontheheuristicallychosenplan.
Manyapplicationsexecutethesamequeryrepeatedly,butwithdifferentvaluesfor
theconstants.Forexample,auniversityapplicationmayrepeatedlyexecuteaqueryto
findthecoursesforwhichastudenthasregistered,buteachtimeforadifferentstudent
with a different value for the student ID. As a heuristic, many optimizers optimize
a query once, with whatever values were provided for the constants when the query
was first submitted, and cachethe query plan. Wheneverthe query isexecuted again,
perhaps with new values for constants, the cached query plan is reused (using new
valuesfortheconstants).Theoptimalplanforthenewconstantsmaydifferfromthe
optimalplanfortheinitialvalues,butasaheuristicthecachedplanisreused.4Caching
andreuseofqueryplansisreferredtoasplancaching.
Evenwiththeuseofheuristics,cost-basedqueryoptimizationimposesasubstan-
tial overhead on query processing. However, the added cost of cost-based query op-
timization is usually more than offset by the saving at query-execution time, which is
dominatedbyslowdiskaccesses.Thedifferenceinexecutiontimebetweenagoodplan
andabadonemaybehuge,makingqueryoptimizationessential.Theachievedsaving
ismagnifiedinthoseapplicationsthatrunonaregularbasis,whereaquerycanbeop-
timizedonce,andtheselectedqueryplancanbeusedeachtimethequeryisexecuted.
Therefore, most commercial systems include relatively sophisticated optimizers. The
bibliographicalnotesgivereferencestodescriptionsofthequeryoptimizersofactual
databasesystems.
16.4.4 Optimizing Nested Subqueries
SQL conceptually treats nested subqueries in the where clause as functions that take
parameters and return eithera single value or asetof values (possibly an empty set).
Theparametersarethevariablesfromanouter-levelquerythatareusedinthenested
4Forthestudentregistrationquery,theplanwouldalmostcertainlybethesameforanystudentID.Butaquerythat
tookarangeofstudentIDs,andreturnedregistrationinformationforallstudentIDsinthatrange,wouldprobablyhave
adifferentoptimalplaniftherangewereverysmallthaniftherangewerelarge.

--- Page 804 ---

16.4 ChoiceofEvaluationPlans 775
subquery (these variables are called correlation variables). For instance, suppose we
have the following query, to find the names of all instructors who taught a course in
2019:
selectname
frominstructor
whereexists(select*
fromteaches
whereinstructor.ID=teaches.ID
andteaches.year =2019);
Conceptually,thesubquery canbe viewedasafunction thattakesaparameter(here,
instructor.ID)andreturnsthesetofallcoursestaughtin2019byinstructors(withthe
sameID).
SQLevaluatestheoverallquery(conceptually)bycomputingtheCartesianproduct
of the relations in the outer from clause and then testing the predicates in the where
clause for each tuple in the product. In the preceding example, the predicate tests if
theresultofthesubqueryevaluationisempty.Inpractice,thepredicatesinthewhere
clause that can be used as join predicates, or as selection predicates are evaluated as
part of the selections on relations or to perform joins that avoid Cartesian products.
Predicatesinvolvingnestedsubqueriesinthewhereclauseareevaluatedsubsequently,
sincetheyareusuallyexpensive,byinvokingthesubqueryasafunction.
Thetechniqueofevaluatinganestedsubquerybyinvokingitasafunctioniscalled
correlatedevaluation. Correlatedevaluation isnotveryefficient,sincethesubquery is
separatelyevaluatedforeachtupleintheouterlevelquery.Alargenumberofrandom
diskI/Ooperationsmayresult.
SQLoptimizersthereforeattempttotransformnestedsubqueriesintojoins,where
possible.Efficientjoinalgorithmshelpavoidexpensive randomI/O.Wherethetrans-
formationisnotpossible,theoptimizerkeepsthesubqueriesasseparate expressions,
optimizesthemseparately,andthenevaluatesthembycorrelatedevaluation.
Asanattemptattransforminganestedsubqueryintoajoin,thequeryinthepre-
cedingexamplecanberewritteninrelationalalgebraasajoin:
Π (instructor ⋈ teaches)
name instructor.ID=teaches.ID∧teaches.year=2019
Unfortunately, the above query is not quite correct,since the multisetversions of the
relational algebra operators are used in SQL implementations, and as a result an in-
structorwhoteachesmultiplesectionsin2019willappearmultipletimesintheresult
oftherelationalalgebraquery,althoughthatinstructorwouldappearonlyonceinthe
SQLqueryresult.Usingthesetversionoftherelationalalgebraoperatorswillnothelp
either, since if there are two instructors with the same name who teach in 2019, the
namewouldappearonlyoncewiththesetversionofrelationalalgebra,butwouldap-
peartwiceinthe SQLqueryresult.(We note thatthesetversionof relationalalgebra

--- Page 805 ---

776 Chapter16 QueryOptimization
wouldgivethecorrectresultifthequeryoutputcontainedtheprimarykeyofinstructor,
namelyID.)
ToproperlyreflectSQLsemantics,thenumberofduplicatesofatupleintheresult
shouldnotchangebecauseoftherewriting.Thesemijoinoperatoroftherelationalal-
gebraprovidesasolutiontothisproblem.Themultisetversionofthesemijoinoperator
r⋉ sisdefinedasfollows:ifatupler appearsntimesinr,itappearsntimesinthe
θ i
resultofr⋉ ifthereisatleastonetuples suchthatr ands togethersatisfypredicate
θ j i j
θ; otherwise r doesnot appear in the result. The setversion of the semijoin operator
i
r ⋉ s can be defined as Π (r ⋈ s), where R is the set of attributes in the schema
θ R θ
of r. The multiset version of the semijoin operator outputs the same tuples, but the
numberofduplicatesofeachtupler inthesemijoinresultisthesameasthenumber
i
ofduplicatesofr inr.
i
TheprecedingSQLquerycanbetranslatedintothefollowingequivalentrelational
algebrausingthemultisetsemijoinoperator:
Π (instructor⋉ teaches)
name instructor.ID=teaches.ID∧teaches.year=2019
The above query in the multiset relational algebra gives the same result as the SQL
query,includingthecountsofduplicates.Thequerycanequivalentlybewrittenas:
Π (instructor⋉ (σ (teaches)))
name instructor.ID=teaches.ID teaches.year=2019
ThefollowingSQLqueryusingtheinclauseisequivalenttotheprecedingSQLquery
usingtheexistsclause,andcanbetranslatedtothesamerelationalalgebraexpression
usingsemijoin.
selectname
frominstructor
whereinstructor.IDin(selectteaches.ID
fromteaches
whereteaches.year =2019);
Theanti-semijoinisusefulwithnotexistsqueries.Themultisetanti-semijoinoper-
ator r ⋉ s is defined as follows: if a tuple r appears n times in r, it appears n times
θ i
intheresultofr⋉ siftheredoesnotexistanytuples inssuchthatr ands satisfy
θ j i j
predicate θ; otherwise r does not appear in the result. The anti-semijoin operator is
i
alsoknownastheanti-joinoperator.
ConsidertheSQLquery:
selectname
frominstructor
wherenotexists(select*
fromteaches
whereinstructor.ID=teaches.ID
andteaches.year =2019);

--- Page 806 ---

16.4 ChoiceofEvaluationPlans 777
The preceding query can be translated into the following relational algebra using the
anti-semijoinoperator:
Π (instructor⋉ (σ (teaches)))
name instructor.ID=teaches.ID teaches.year=2019
Ingeneral,aqueryoftheform:
selectA
fromr ,r ,...,r
1 2 n
whereP andexists(select*
1
froms ,s ,...,s
1 2 m
whereP1 andP2);
2 2
where P1 are predicates that only reference the relations s in the subquery, and P2
2 i 2
predicates that also reference the relations r from the outer query, can be translated
i
to:
Π ((σ (r ×r ×…×r ))⋉ σ (s ×s ×…×s ))
A P 1 2 n P2 P1 1 2 m
1 2 2
Ifnotexistswereusedinsteadofexists,thesemijoinshouldbereplacedbyanti-semijoin
in the relational algebra query. If an in clause is used instead of exists, the relational
algebra query can be appropriately modified by adding a corresponding predicate in
thesemijoinpredicate,asourearlierexampleillustrated.
The process of replacing a nested query by a query with a join, semijoin, or anti-
semijoin is called decorrelation. The semijoin and anti-semijoin operators can be effi-
cientlyimplementedusingmodificationsofthejoinalgorithms,asexploredinPractice
Exercise15.10.
Consider the followingquery with aggregation in a scalar subquery, that finds in-
structorswhohavetaughtmorethanonecoursesectionin2019.
selectname
frominstructor
where1<(selectcount(*)
fromteaches
whereinstructor.ID=teaches.ID
andteaches.year =2019);
Theabovequerycanberewrittenusingasemijoinasfollows:
Π (instructor ⋉ ( γ (σ (teaches)))
name (instructor.ID=TID)∧(1<cnt) IDasTID count(∗)ascnt year=2019
Observe that the subquery has a predicate instructor.ID= teaches.ID, and aggregation
without a group by clause. The decorrelated query has the predicate moved into the
semijoincondition,andtheaggregationisnowgroupedbyID.Thepredicate1 <(sub-
query) has turned into a semijoin predicate. Intuitively, the subquery performs a sep-

--- Page 807 ---

778 Chapter16 QueryOptimization
arate count for each instructor.ID; grouping by ID ensures that counts are computed
separatelyforeachID.
Decorrelation is clearly more complicated when the nested subquery uses aggre-
gation,orwhenthenestedsubqueryisusedasascalarsubquery.Infact,decorrelation
is not possible for certain cases of subqueries. For example, a subquery that is used
as a scalar subquery is expected to return only one result; if it returns more than one
result,aruntimeexceptioncanoccur,whichisnotpossiblewithadecorrelatedquery.
Further,whethertodecorrelateornotshouldideallybedoneinacost-basedmanner,
depending on whether decorrelation reduces the cost or not. Some query optimizers
represent nested subqueries using extended relational-algebraconstructs, and express
transformationsofnestedsubqueriestosemijoin,anti-semijoin,andsoforth,asequiv-
alence rules. We do not attempt to give algorithms for the general case, and instead
referyoutorelevantitemsintheonlinebibliographicalnotes.
Optimization of complex nested subqueries is a complicated task, as you can in-
fer from the preceding discussion, and many optimizers do only a limited amount of
decorrelation.Itbettertoavoidusingcomplexnestedsubqueries,wherepossible,since
wecannotbesurethatthequeryoptimizerwillsucceedinconvertingthemtoaform
thatcanbeevaluatedefficiently.
16.5 Materialized Views
Whenaviewisdefined,normallythedatabasestoresonlythequerydefiningtheview.
In contrast, a materialized view is a view whose contents are computed and stored.
Materialized views constitute redundant data, in that their contents can be inferred
from the view definition and the rest of the database contents. However, it is much
cheaperinmanycasestoreadthecontentsofamaterializedviewthantocomputethe
contentsoftheviewbyexecutingthequerydefiningtheview.
Materializedviewsareimportantforimprovingperformanceinsomeapplications.
Considerthisview,whichgivesthetotalsalaryineachdepartment:
createviewdepartmenttotal salary(dept name,total salary)as
selectdept name,sum(salary)
frominstructor
groupbydept name;
Supposethetotalsalaryamountatadepartmentisrequiredfrequently.Computingthe
view requires reading every instructor tuple pertaining to a department and summing
upthesalaryamounts,whichcanbetime-consuming.Incontrast,iftheviewdefinition
of the total salary amount were materialized, the total salary amount could be found
bylookingupasingletupleinthematerializedview.5
5Thedifferencemaynotbeallthatlargeforamedium-sizeduniversity,butinothersettingsthedifferencecanbe
verylarge.Forexample,ifthematerializedviewcomputedtotalsalesofeachproduct,fromasalesrelationwithtens

--- Page 808 ---

16.5 MaterializedViews 779
16.5.1 View Maintenance
Aproblemwithmaterializedviewsisthattheymustbekeptup-to-datewhenthedata
used in the view definition changes. For instance, if the salary value of an instructor
is updated, the materialized view will become inconsistent with the underlying data,
and it must be updated. The task of keeping a materialized view up-to-date with the
underlyingdataisknownasviewmaintenance.
Views can be maintained by manually written code: That is, every piece of code
thatupdatesthesalaryvaluecanbemodifiedtoalsoupdatethetotalsalaryamountfor
thecorrespondingdepartment.However,thisapproachiserrorprone,sinceitiseasy
to miss some places where the salary is updated, and the materialized view will then
nolongermatchtheunderlyingdata.
Another option for maintaining materialized views is to define triggers on insert,
delete, and update of each relation in the view definition. The triggers must modify
thecontentsofthematerializedview,totakeintoaccountthechangethatcausedthe
triggertofire.Asimplisticwayofdoingsoistocompletelyrecomputethematerialized
viewoneveryupdate.
Abetteroptionistomodifyonlytheaffectedpartsofthematerializedview,which
is known as incremental view maintenance. We describe how to perform incremental
viewmaintenanceinSection16.5.2.
Moderndatabasesystemsprovidemoredirectsupportforincrementalviewmain-
tenance.Database-systemprogrammersnolongerneedtodefinetriggersforviewmain-
tenance.Instead,onceaviewisdeclaredtobematerialized,thedatabasesystemcom-
putesthecontentsoftheviewandincrementallyupdatesthecontentswhentheunder-
lyingdatachange.
Most database systems perform immediate view maintenance; thatis, incremental
view maintenance is performed as soon as an update occurs, as part of the updat-
ingtransaction.Somedatabasesystemsalsosupportdeferredviewmaintenance,where
view maintenance is deferred to a later time; for example, updates may be collected
throughout a day, and materialized views may be updated at night. This approach re-
ducestheoverheadonupdatetransactions.However,materializedviewswithdeferred
view maintenance may not be consistent with the underlying relations on which they
aredefined.
16.5.2 Incremental View Maintenance
Tounderstand how tomaintainmaterializedviewsincrementally,westart offbycon-
sideringindividualoperations,andthenweseehowtohandleacompleteexpression.
Thechangestoarelationthatcancauseamaterializedviewtobecomeout-of-date
are inserts, deletes, and updates. To simplify our description,we replace updates to a
tuplebydeletionofthetuplefollowedbyinsertionoftheupdatedtuple.Thus,weneed
ofmillionsoftuples,thedifferencebetweencomputingtheaggregatefromtheunderlyingdataandlookingupthe
materializedviewcanbemanyordersofmagnitude.

--- Page 809 ---

780 Chapter16 QueryOptimization
toconsideronlyinsertsanddeletes.Thechanges(insertsanddeletes)toarelationor
expressionarereferredtoasitsdifferential.
16.5.2.1 JoinOperation
Consider the materialized view v = r ⋈ s. Suppose we modify r by inserting a set of
tuplesdenotedbyi .Iftheoldvalue ofr isdenotedbyrold,andthenewvalueofr by
r
rnew,rnew = rold ∪i .Now,theoldvalueoftheview,vold,isgivenbyrold ⋈ s,andthe
r
newvalue vnew isgivenbyrnew ⋈ s.Wecanrewriternew ⋈ sas(rold ∪i ) ⋈ s,which
r
wecanagainrewriteas(rold ⋈ s)∪(i ⋈ s).Inotherwords:
r
vnew = vold ∪(i ⋈ s)
r
Thus,toupdatethematerializedviewv,wesimplyneedtoaddthetuplesi ⋈ stothe
r
oldcontentsofthematerializedview.Insertstosarehandledinanexactlysymmetric
fashion.
Nowsupposerismodifiedbydeletingasetoftuplesdenotedbyd .Usingthesame
r
reasoningasabove,weget:
vnew = vold −(d ⋈ s)
r
Deletesonsarehandledinanexactlysymmetricfashion.
16.5.2.2 SelectionandProjectionOperations
Consideraviewv = σ (r).Ifwemodifyr byinsertingasetoftuplesi ,thenewvalue
θ r
ofvcanbecomputedas:
vnew = vold ∪σ (i )
θ r
Similarly,ifr ismodifiedbydeletingasetoftuplesd ,thenewvalueofvcanbecom-
r
putedas:
vnew = vold −σ (d )
θ r
Projectionisamoredifficultoperationwithwhichtodeal.Consideramaterialized
viewv =Π (r).SupposetherelationrisontheschemaR = (A,B),andrcontainstwo
A
tuples(a,2)and(a,3).Then,Π (r)hasasingletuple(a).Ifwedeletethetuple(a,2)
A
fromr,wecannotdeletethetuple(a)fromΠ (r):Ifwedidso,theresultwouldbean
A
emptyrelation,whereasin realityΠ (r)still hasasingle tuple (a). The reason isthat
A
thesametuple(a)isderivedintwoways,anddeletingonetuplefromr removesonly
oneofthewaysofderiving(a);theotherisstillpresent.
Thisreasonalsogivesustheintuitionforasolution:Foreachtupleinaprojection
suchasΠ (r),wewillkeepacountofhowmanytimesitwasderived.
A

--- Page 810 ---

16.5 MaterializedViews 781
Whenasetoftuplesd isdeletedfromr,foreachtupletind wedothefollowing:
r r
Lett.Adenotetheprojectionoft on theattribute A.Wefind(t.A)inthematerialized
viewanddecreasethecountstoredwithitby1.Ifthecountbecomes0,(t.A)isdeleted
fromthematerializedview.
Handlinginsertionsisrelativelystraightforward.Whenasetoftuplesi isinserted
r
into r, for each tuple t in i we do the following: If (t.A) is already present in the ma-
r
terialized view, we increase the count stored with it by 1. If not, we add (t.A) to the
materializedview,withthecountsetto1.
16.5.2.3 AggregationOperations
Aggregationoperations proceedsomewhatlikeprojections.Theaggregate operations
inSQLarecount,sum,avg,min,andmax:
• count: Consideramaterializedviewv = γ (r), whichcomputes the count
G count(B)
oftheattributeB,aftergroupingr byattributeG.
Whenasetoftuplesi isinsertedintor,foreachtupletini wedothefollowing:
r r
We look for the group t.G in the materialized view. If it is not present, we add
(t.G,1)tothematerializedview.Ifthegroupt.Gispresent,weadd1tothecount
ofthegroup.
When a set of tuples d is deleted from r, for each tuple t in d we do the
r r
following:Welookforthegroupt.G inthematerializedviewandsubtract1from
thecountforthegroup.Ifthecountbecomes0,wedeletethetupleforthegroup
t.Gfromthematerializedview.
• sum:Consideramaterializedviewv = γ (r).
G sum(B)
Whenasetoftuplesi isinsertedintor,foreachtupletini wedothefollowing:
r r
We look for the group t.G in the materialized view. If it is not present, we add
(t.G,t.B) to the materialized view; in addition, we store a count of 1 associated
with (t.G,t.B), just as we did for projection. If the group t.G is present, we add
thevalueoft.Btotheaggregatevalueforthegroupandadd1tothecountofthe
group.
When a set of tuples d is deleted from r, for each tuple t in d we do the
r r
following: We look for the group t.G in the materialized view and subtract t.B
fromtheaggregatevalueforthegroup.Wealsosubtract1fromthecountforthe
group,andifthecountbecomes0,wedeletethetupleforthegroupt.G fromthe
materializedview.
Without keeping the extra count value, we would not be able to distinguish a
casewherethesumforagroupis0fromthecasewherethelasttupleinagroup
isdeleted.
• avg:Consideramaterializedviewv = γ (r).
G avg(B)
Directlyupdatingtheaverageonaninsertordeleteisnotpossible,sinceitdepends
not only on the old average and the tuple being inserted/deleted, but also on the
numberoftuplesinthegroup.

--- Page 811 ---

782 Chapter16 QueryOptimization
Instead, to handle the case of avg, we maintain the sum and count aggregate
values as described earlier and compute the average as the sum divided by the
count.
• min,max:Consideramaterializedviewv = γ (r).(Thecaseofmaxisexactly
G min(B)
equivalent.)
Handling insertions on r is straightforward, similar to the case of sum. Main-
tainingtheaggregatevaluesminandmaxondeletionsmaybemoreexpensive.For
example,ifthetupletcorrespondingtotheminimumvalueforagroupisdeleted
fromr,wehavetolookattheothertuplesofr thatareinthesamegrouptofind
the new minimum value. It is a good idea to create an ordered index on (G,B)
sinceitwouldhelpustofindthenewminimumvalueforagroupveryefficiently.
16.5.2.4 OtherOperations
The set operation intersection is maintained as follows: Given materialized view v =
r ∩ s, when a tuple is inserted in r we check if it is present in s, and if so we add it
tov.Ifatuple isdeletedfrom r,wedeleteitfrom theintersectionifitispresent.The
othersetoperations,unionandsetdifference,arehandledinasimilarfashion;weleave
detailstoyou.
Outerjoinsarehandledinmuchthesamewayasjoins,butwithsomeextrawork.
In the case of deletionfrom r we have to handle tuples in s thatno longer matchany
tupleinr.Inthecaseofinsertiontor,wehavetohandletuplesinsthatdidnotmatch
anytupleinr.Againweleavedetailstoyou.
16.5.2.5 HandlingExpressions
So far we have seen how to update incrementally the result of a single operation. To
handleanentireexpression,wecanderiveexpressionsforcomputingtheincremental
changetotheresultofeachsubexpression,startingfromthesmallestsubexpressions.
Forexample,supposewewishtoincrementallyupdateamaterializedviewE ⋈ E
1 2
when a set of tuples i is inserted into relation r. Let us assume r is used in E alone.
r 1
Suppose the set of tuples to be inserted into E is given by expression D . Then the
1 1
expressionD ⋈ E givesthesetoftuplestobeinsertedintoE ⋈ E .
1 2 1 2
Seetheonlinebibliographicalnotesforfurtherdetailsonincrementalviewmain-
tenancewithexpressions.
16.5.3 Query Optimization and Materialized Views
Query optimization can be performed by treating materialized views just like regular
relations.However,materializedviewsofferfurtheropportunitiesforoptimization:
• Rewritingqueriestousematerializedviews:
Supposeamaterializedviewv = r ⋈ sisavailable,andausersubmitsaquery
r ⋈ s ⋈ t. Rewritingthe query as v ⋈ t may provide a more efficientquery plan

--- Page 812 ---

16.6 AdvancedTopicsinQueryOptimization 783
thanoptimizingthequeryassubmitted.Thus,itisthejobofthequeryoptimizer
torecognizewhenamaterializedviewcanbeusedtospeedupaquery.
• Replacingauseofamaterializedviewwiththeviewdefinition:
Suppose a materialized view v = r ⋈ s is available, but without any index on
it, and a user submits a query σ (v). Suppose also that s has an index on the
A=10
commonattributeB,andrhasanindexonattributeA.Thebestplanforthisquery
maybetoreplacevwithr ⋈ s,whichcanleadtothequeryplanσ (r) ⋈ s;the
A=10
selectionandjoincanbeperformedefficientlybyusingtheindicesonr.Aands.B,
respectively. In contrast, evaluating the selection directly on v may require a full
scanofv,whichmaybemoreexpensive.
The online bibliographical notes give pointers to research showing how to perform
queryoptimizationefficientlywithmaterializedviews.
16.5.4 Materialized View and Index Selection
Another related optimization problem is that of materialized view selection, namely,
“Whatisthebestsetofviewstomaterialize?”Thisdecisionmustbemadeonthebasis
of the system workload, which is a sequence of queries and updates that reflects the
typicalloadonthesystem.Onesimplecriterionwouldbetoselectasetofmaterialized
viewsthatminimizestheoverallexecutiontimeoftheworkloadofqueriesandupdates,
includingthetimetaken tomaintainthematerializedviews.Database administrators
usually modify this criterion to take into account the importance of different queries
andupdates: Fastresponse maybe requiredforsomequeriesandupdates, butaslow
responsemaybeacceptableforothers.
Indicesarejustlikematerializedviews,inthattheytooarederiveddata,canspeed
upqueries,andmayslowdownupdates.Thus,theproblemofindexselectionisclosely
relatedtothatofmaterializedviewselection,althoughitissimpler.Weexamineindex
andmaterializedviewselectioninmoredetailinSection25.1.4.1andSection25.1.4.2.
Mostdatabasesystemsprovidetoolstohelpthedatabaseadministratorwithindex
andmaterializedviewselection.Thesetoolsexaminethehistoryofqueriesandupdates
andsuggestindicesandviewstobematerialized.TheMicrosoftSQLServerDatabase
Tuning Assistant, the IBM DB2 Design Advisor, and the Oracle SQL Tuning Wizard
areexamplesofsuchtools.
16.6 Advanced Topics in Query Optimization
Thereareanumberofopportunitiesforoptimizingqueries,beyondthosewehaveseen
sofar.Weexamineafewoftheseinthissection.

--- Page 813 ---

784 Chapter16 QueryOptimization
16.6.1 Top-K Optimization
Many queries fetch results sorted on some attributes, and require only the top K re-
sults for some K. Sometimes the bound K is specified explicitly. For example, some
databases support a limit K clause which results in only the top K results being re-
turned by the query. Other databases support alternative ways of specifying similar
limits. In other cases, the query may not specify such a limit, but the optimizer may
allowahinttobespecified,indicatingthatonlythetopK resultsofthequeryarelikely
toberetrieved,evenifthequerygeneratesmoreresults.
When K is small, a query optimization plan that generates the entire set of re-
sults, then sorts and generates the top K, is very inefficient since it discards most of
the intermediate results that it computes. Several techniques have been proposed to
optimizesuchtop-K queries.Oneapproachistousepipelinedplansthatcangenerate
the results in sorted order. Another approach is to estimate what is the highest value
on the sorted attributes that will appear in the top-K output, and introduce selection
predicatesthat eliminatelarger values. If extra tuples beyond the top-K are generated
they arediscarded,and iftoo few tuples are generated then the selectionconditionis
changed and the query is re-executed. See the bibliographical notes for references to
workontop-K optimization.
16.6.2 Join Minimization
Whenqueriesaregeneratedthroughviews,sometimesmorerelationsarejoinedthan
areneededforcomputationofthequery.Forexample,aviewvmayincludethejoinof
instructor anddepartment,butauseoftheviewvmayuseonlyattributesfrominstruc-
tor. The join attribute dept name of instructor is a foreign key referencing department.
Assumingthatinstructor.dept namehasbeendeclarednotnull,thejoinwithdepartment
canbedropped,withnoimpactonthequery.Forundertheaboveassumption,thejoin
withdepartmentdoesnoteliminateanytuplesfrominstructor,nordoesitresultinextra
copiesofanyinstructor tuple.
Droppingarelationfromajoinasaboveisanexampleofjoinminimization.Infact,
joinminimizationcanbeperformedinothersituationsaswell.Seethebibliographical
notesforreferencesonjoinminimization.
16.6.3 Optimization of Updates
Updatequeriesofteninvolvesubqueriesinthesetandwhereclauses,whichmustalso
betakenintoaccountinoptimizingtheupdate.Updatesthatinvolveaselectiononthe
updatedcolumn(e.g.,givea10percentsalaryraisetoallemployeeswhosesalaryis≥
$100,000)mustbehandledcarefully.Iftheupdateisdonewhiletheselectionisbeing
evaluated byan indexscan,an updated tuple maybe reinsertedinthe indexaheadof
thescanandseenagainbythescan;thesameemployeetuplemaythengetincorrectly
updated multiple times (an infinite number of times, in this case). A similarproblem
alsoariseswithupdatesinvolvingsubquerieswhoseresultisaffectedbytheupdate.

--- Page 814 ---

16.6 AdvancedTopicsinQueryOptimization 785
Theproblemofanupdateaffectingtheexecutionofaqueryassociatedwiththeup-
dateisknownastheHalloweenproblem(namedsobecauseitwasfirstrecognizedona
Halloweenday,atIBM).Theproblemcanbeavoidedbyexecutingthequeriesdefining
theupdatefirst,creatingalistofaffectedtuples,andupdatingthetuplesandindicesas
thelaststep. However,breakinguptheexecutionplaninsuchafashionincreasesthe
executioncost.UpdateplanscanbeoptimizedbycheckingiftheHalloweenproblem
can occur, and if it cannot occur, updates can be performed while the query is being
processed, reducing the update overheads. For example, the Halloween problem can-
notoccurifthe update doesnotaffectindexattributes. Even ifitdoes, iftheupdates
decrease the value while the index is scanned in increasingorder, updated tuples will
notbeencounteredagainduringthescan.Insuchcases,theindexcanbeupdatedeven
whilethequeryisbeingexecuted,reducingtheoverallcost.
Update queriesthatresultin a large number of updates canalso be optimizedby
collectingtheupdatesasabatchandthenapplyingthebatchofupdatesseparatelyto
eachaffectedindex.Whenapplyingthebatchofupdatestoanindex,thebatchisfirst
sortedintheindexorderforthatindex;suchsortingcangreatlyreducetheamountof
randomI/Orequiredforupdatingindices.
Suchoptimizationsofupdatesareimplementedinmostdatabasesystems.Seethe
bibliographicalnotesforreferencestosuchoptimization.
16.6.4 Multiquery Optimization and Shared Scans
When a batch of queries are submitted together, a query optimizer can potentially
exploit common subexpressions between the different queries, evaluating them once
and reusing them where required. Complex queries may in fact have subexpressions
repeated in different parts of the query, which can be similarly exploited to reduce
queryevaluationcost.Suchoptimizationisknownasmultiqueryoptimization.
Common subexpression elimination optimizes subexpressions shared by different
expressionsinaprogrambycomputingandstoringtheresultandreusingitwherever
thesubexpressionoccurs.Commonsubexpressioneliminationisastandardoptimiza-
tionappliedonarithmeticexpressionsbyprogramming-languagecompilers.Exploiting
commonsubexpressionsamongevaluationplanschosenforeachofabatchofqueries
isjust asuseful in database queryevaluation,andisimplementedbysomedatabases.
However,multiqueryoptimizationcandoevenbetterinsomecases:Aquerytypically
has more than one evaluation plan, and a judiciously chosen set of query evaluation
plansforthequeriesmayprovideforagreatersharingandlessercostthanthatafforded
bychoosingthelowestcostevaluationplanforeachquery.Moredetailsonmultiquery
optimizationmaybefoundinreferencescitedinthebibliographicalnotes.
Sharingofrelationscansbetweenqueriesisanotherlimitedformofmultiqueryop-
timizationthatisimplementedinsomedatabases.Theshared-scanoptimizationworks
as follows: Instead of reading the relation repeatedly from disk, once for each query
that needs to scan a relation, data are read once from disk, and pipelined to each of

--- Page 815 ---

786 Chapter16 QueryOptimization
thequeries.Theshared-scanoptimizationisparticularlyusefulwhenmultiplequeries
performascanonasinglelargerelation(typicallya“facttable”).
16.6.5 Parametric Query Optimization
Plancaching,whichwesawinSection16.4.3,isusedasaheuristicinmanydatabases.
Recallthatwithplancaching,ifaqueryisinvokedwithsomeconstants,theplancho-
sen by the optimizer is cached and reused if the query is submitted again, even if the
constantsinthequeryaredifferent.Forexample,supposeaquerytakesadepartment
nameasaparameterandretrievesallcoursesofthedepartment.Withplancaching,a
planchosenwhenthequeryisexecutedforthefirsttime,sayfortheMusicdepartment,
isreusedifthequeryisexecutedforanyotherdepartment.
Such reuse of plans by plan caching is reasonable if the optimal query plan is
notsignificantlyaffected bythe exact value of the constants in the query. However, if
theplanisaffectedbythevalueoftheconstants,parametricqueryoptimizationisan
alternative.
Inparametricqueryoptimization,aqueryisoptimizedwithoutbeingprovidedspe-
cificvaluesforitsparameters—forexample,dept nameintheprecedingexample.The
optimizer then outputs several plans, each optimal for a different parameter value. A
plan would be output by the optimizeronly if it isoptimal for some possible value of
theparameters.Thesetofalternativeplansoutputbytheoptimizerarestored.When
aqueryissubmittedwithspecificvaluesforitsparameters,insteadofperformingafull
optimization, the cheapest plan from the set of alternative plans computed earlier is
used.Findingthecheapestsuchplanusuallytakesmuchlesstimethanreoptimization.
Seethebibliographicalnotesforreferencesonparametricqueryoptimization.
16.6.6 Adaptive Query Processing
Aswenotedearlier,queryoptimizationisbasedonestimatesthatareatbestapproxi-
mations.Thus,itispossibleattimesfortheoptimizertochooseaplanthatturnsout
to perform very badly. Adaptive operators that choose the specific operator at execu-
tiontimeprovideapartialsolutiontothisproblem.Forexample,SQLServersupports
an adaptive join algorithm that checks the size of its outer input, and chooses either
nestedloopsjoin,orhashjoindependingonthesizeoftheouterinput.
Many systems also include the ability to monitor the behavior of a plan during
query execution, and adapt the plan accordingly. For example, suppose the statistics
collected by the system during early stages of the plan’s execution (or the execution
ofsubpartsoftheplan)arefoundtodiffersubstantiallyfromtheoptimizersestimates
tosuchanextentthatitisclearthatthechosenplanissuboptimal.Thenanadaptive
system may abort the execution, choose a new query execution plan using the statis-
tics collected during the initial execution, and restart execution using the new plan;
the statistics collectedduringthe execution of the old plan ensure the old plan isnot
selectedagain.Further,thesystemmustavoidrepeatedabortsandrestarts;ideally,the
systemshouldensurethattheoverallcostofqueryevaluationisclosetothatwiththe

--- Page 816 ---

16.7 Summary 787
planthatwouldbechoseniftheoptimizerhadexactstatistics.Thespecificcriteriaand
mechanismsforsuchadaptivequeryprocessingarecomplex,andarereferencedinthe
bibliographicnotesavailableonline.
16.7 Summary
• Givenaquery,therearegenerallyavarietyofmethodsforcomputingtheanswer.
Itistheresponsibilityofthesystemtotransformthequeryasenteredbytheuser
into an equivalent query that can be computed more efficiently. The process of
findingagoodstrategyforprocessingaqueryiscalledqueryoptimization.
• Theevaluationofcomplexqueriesinvolvesmanyaccessestodisk.Sincethetrans-
fer of data from disk is slow relative to the speed of main memory and the CPU
ofthecomputersystem,itisworthwhiletoallocateaconsiderableamountofpro-
cessingtochooseamethodthatminimizesdiskaccesses.
• Thereareanumberofequivalencerulesthatwecanusetotransformanexpression
intoanequivalentone.Weusetheserulestogeneratesystematicallyallexpressions
equivalenttothegivenquery.
• Eachrelational-algebraexpressionrepresentsaparticularsequenceofoperations.
Thefirststepinselectingaquery-processingstrategyistofindarelational-algebra
expression thatis equivalent tothe given expression and isestimated to cost less
toexecute.
• Thestrategythatthedatabasesystemchoosesforevaluatinganoperationdepends
on the size of eachrelation and on the distribution of values withincolumns. So
that they can base the strategy choice on reliable information, database systems
maystorestatisticsforeachrelationr.Thesestatisticsinclude:
° Thenumberoftuplesintherelationr.
° Thesizeofarecord(tuple)ofrelationrinbytes.
° The number of distinct values that appear in the relation r for a particular
attribute.
• Most database systems use histograms to store the number of values for an at-
tribute within each of several ranges of values. Histograms are often computed
usingsampling.
• Thesestatisticsallowustoestimatethesizesoftheresultsofvariousoperations,as
wellasthecostofexecutingtheoperations.Statisticalinformationaboutrelations
isparticularlyusefulwhenseveralindicesareavailabletoassistintheprocessingof
aquery.Thepresenceofthesestructureshasasignificantinfluenceonthechoice
ofaquery-processingstrategy.

--- Page 817 ---

788 Chapter16 QueryOptimization
• Alternativeevaluationplansforeachexpressioncanbegenerated byequivalence
rules, and the cheapest plan across all expressions can be chosen. Several opti-
mizationtechniquesareavailabletoreducethenumberofalternativeexpressions
andplansthatneedtobegenerated.
• Weuseheuristicstoreducethenumberofplansconsidered,andtherebytoreduce
thecostofoptimization.Heuristicrulesfortransformingrelational-algebraqueries
include“Performselectionoperationsasearlyaspossible,”“Performprojections
early,”and“AvoidCartesianproducts.”
• Materialized views can be used to speed up query processing. Incremental view
maintenanceisneededtoefficientlyupdatematerializedviewswhentheunderly-
ing relations are modified. The differential of an operation can be computed by
means of algebraic expressions involving differentials of the inputs of the opera-
tion.Otherissuesrelatedtomaterializedviewsincludehowtooptimizequeriesby
makinguse of availablematerializedviews,and how toselectviewstobe materi-
alized.
• Anumberofadvancedoptimizationtechniqueshavebeenproposed,suchastop-
K optimization,joinminimization,optimizationofupdates,multiqueryoptimiza-
tion,andparametricqueryoptimization.
Review Terms
• Queryoptimization • Histograms
• Transformationofexpressions • Distinctvalueestimation
• Equivalenceofexpressions • Randomsample
• Equivalencerules • Choiceofevaluationplans
° Joincommutativity • Interactionofevaluation
techniques
° Joinassociativity
• Cost-basedoptimization
• Minimalsetofequivalencerules
• Join-orderoptimization
• Enumerationofequivalent
expressions
° Dynamic-programming
• Statisticsestimation algorithm
• Cataloginformation
° Left-deepjoinorder
• Sizeestimation
° Interestingsortorder
° Selection
• Heuristicoptimization
° Selectivity
• Plancaching
° Join
• Access-planselection

--- Page 818 ---

PracticeExercises 789
• Correlatedevaluation ° Deletion
• Decorrelation ° Updates
• Semijoin
• Queryoptimizationwith
• Anti-semijoin
materializedviews
• Materializedviews • Indexselection
• Materializedviewmaintenance • Materializedviewselection
• Top-K optimization
° Recomputation
• Joinminimization
° Incrementalmaintenance • Halloweenproblem
° Insertion • Multiqueryoptimization
Practice Exercises
16.1 Downloadtheuniversitydatabaseschemaandthelargeuniversitydatasetfrom
dbbook.com.Createtheuniversityschemaonyourfavoritedatabase,andload
thelargeuniversitydataset.UsetheexplainfeaturedescribedinNote16.1on
page746toviewtheplanchosenbythedatabase,indifferentcasesasdetailed
below.
a. Write a query with an equality condition on student.name (which does
nothaveanindex),andviewtheplanchosen.
b. Createanindexontheattributestudent.name,andviewtheplanchosen
fortheabovequery.
c. Createsimplequeriesjoiningtworelations,orthreerelations,andview
theplanschosen.
d. Createaquerythatcomputesanaggregatewithgrouping,andviewthe
planchosen.
e. CreateanSQLquerywhosechosenplanusesasemijoinoperation.
f. Create an SQL query that uses a not in clause, with a subquery using
aggregation.Observewhatplanischosen.
g. Createaqueryforwhichthechosenplanusescorrelatedevaluation(the
way correlated evaluation is represented varies by database, but most
databases would show a filter or a project operator with a subplan or
subquery).
h. CreateanSQLupdatequerythatupdatesasinglerowinarelation.View
theplanchosenfortheupdatequery.

--- Page 819 ---

790 Chapter16 QueryOptimization
i. CreateanSQLupdatequerythatupdatesalargenumberofrowsinare-
lation,usingasubquerytocomputethenewvalue.Viewtheplanchosen
fortheupdatequery.
16.2 Show that the following equivalences hold. Explain how you can apply them
toimprovetheefficiencyofcertainqueries:
a. E ⋈ (E −E ) ≡ (E ⋈ E −E ⋈ E ).
1 θ 2 3 1 θ 2 1 θ 3
b. σ ( γ (E)) ≡ γ (σ (E)),whereθusesonlyattributesfromA.
θ A F A F θ
c. σ (E ⟕E ) ≡ σ (E )⟕E ,whereθusesonlyattributesfromE .
θ 1 2 θ 1 2 1
16.3 Foreachofthefollowingpairsofexpressions,giveinstancesofrelationsthat
showtheexpressionsarenotequivalent.
a. Π (r−s)andΠ (r)−Π (s).
A A A
b. σ ( γ (r))and γ (σ (r)).
B<4 A max(B)asB A max(B)asB B<4
c. Intheprecedingexpressions,ifbothoccurrencesofmaxwerereplaced
bymin,wouldtheexpressionsbeequivalent?
d. (r⟖s)⟖tandr⟖(s⟖t)
Inotherwords,thenaturalrightouterjoinisnotassociative.
e. σ (E ⟕E )andE ⟕σ (E ),whereθusesonlyattributesfromE .
θ 1 2 1 θ 2 2
16.4 SQLallowsrelationswithduplicates(Chapter3), andthemultisetversionof
therelationalalgebraisdefinedinNote3.1onpage80,Note3.2onpage97,
andNote3.3onpage108.Checkwhichoftheequivalencerules1through7.b
holdforthemultisetversionoftherelationalalgebra.
16.5 Considertherelationsr (A,B,C),r (C,D,E),andr (E,F),withprimarykeys
1 2 3
A, C, and E, respectively. Assume that r has 1000 tuples, r has 1500 tuples,
1 2
andr has750tuples.Estimatethesizeofr ⋈ r ⋈ r ,andgiveanefficient
3 1 2 3
strategyforcomputingthejoin.
16.6 Consider the relations r (A,B,C), r (C,D,E), and r (E,F) of Practice Exer-
1 2 3
cise 16.5. Assume that there are no primary keys, except the entire schema.
Let V(C,r ) be 900, V(C,r ) be 1100, V(E,r ) be 50, and V(E,r ) be 100.
1 2 2 3
Assumethatr has1000tuples,r has1500tuples,andr has750tuples.Es-
1 2 3
timate the size of r ⋈ r ⋈ r and give an efficient strategy for computing
1 2 3
thejoin.
16.7 Suppose that a B+-tree index on building is available on relation department
andthatnootherindexisavailable.Whatwouldbethebestwaytohandlethe
followingselectionsthatinvolvenegation?
a. σ (department)
¬(building<“Watson”)

--- Page 820 ---

PracticeExercises 791
b. σ (department)
¬(building=“Watson”)
c. σ (department)
¬(building<“Watson”∨budget<50000)
16.8 Considerthequery:
select*
fromr,s
whereupper(r.A)=upper(s.A);
where“upper”isafunctionthatreturnsitsinputargumentwithalllowercase
lettersreplacedbythecorrespondinguppercaseletters.
a. Find out what plan is generated for this query on the database system
youuse.
b. Some database systems would use a (block) nested-loop join for this
query, which can be very inefficient. Briefly explain how hash-join or
merge-joincanbeusedforthisquery.
16.9 Giveconditionsunderwhichthefollowingexpressionsareequivalent:
γ (E ⋈ E ) and ( γ (E )) ⋈ E
A,B agg(C) 1 2 A agg(C) 1 2
whereagg denotes anyaggregation operation. How can the above conditions
berelaxedifaggisoneofminormax?
16.10 Considertheissueofinterestingordersinoptimization.Supposeyouaregiven
a query that computes the natural join of a set of relations S. Given a subset
S1ofS,whataretheinterestingordersofS1?
16.11 ModifytheFindBestPlan(S)functiontocreateafunctionFindBestPlan(S,O),
where O is a desired sort order for S, and which considers interesting sort
orders.Anullorderindicatesthattheorderisnotrelevant.Hints:Analgorithm
Amaygive thedesiredorderO;ifnotasort operation mayneed tobe added
togetthedesiredorder.IfAisamerge-join,FindBestPlanmustbeinvokedon
thetwoinputswiththedesiredordersfortheinputs.
16.12 Showthat,withnrelations,thereare(2(n−1))!∕(n−1)!differentjoinorders.
Hint:Acompletebinarytreeisonewhereeveryinternalnodehasexactlytwo
children.Usethefactthatthenumberofdifferentcompletebinarytreeswith
nleafnodesis: ( )
1 2(n−1)
n (n−1)
Ifyouwish,youcanderivetheformulaforthenumberofcompletebinarytrees
with n nodes from the formula for the number of binary trees with n nodes.
Thenumberofbinarytreeswithnnodesis:
( )
1 2n
n+1 n

--- Page 821 ---

792 Chapter16 QueryOptimization
ThisnumberisknownastheCatalannumber,anditsderivationcanbefound
inanystandardtextbookondatastructuresoralgorithms.
16.13 Showthatthelowest-costjoinordercanbecomputedintimeO(3n).Assume
that you can store and look up information about a set of relations (such as
theoptimaljoinorderfortheset,andthecostofthatjoinorder)inconstant
time.(Ifyoufindthisexercisedifficult,atleastshowtheloosertimeboundof
O(22n).)
16.14 Showthat,ifonlyleft-deepjointreesareconsidered,asintheSystemRopti-
mizer,thetimetakentofindthemostefficientjoinorderisaroundn2n.Assume
thatthereisonlyoneinterestingsortorder.
16.15 ConsiderthebankdatabaseofFigure16.9,wheretheprimarykeysareunder-
lined.ConstructthefollowingSQLqueriesforthisrelationaldatabase.
a. Write a nested query on the relation account to find, for each branch
with name starting with B, all accounts with the maximum balance at
thebranch.
b. Rewrite the preceding query without using a nested subquery; in other
words,decorrelatethequery,butinSQL.
c. Give a relational algebra expression using semijoin equivalent to the
query.
d. Giveaprocedure(similartothatdescribedinSection16.4.4)fordecor-
relatingsuchqueries.
Exercises
16.16 Suppose thataB+-treeindexon(dept name,building)isavailableonrelation
department.Whatwouldbethebestwaytohandlethefollowingselection?
σ (department)
(building<“Watson”)∧(budget<55000)∧(deptname =“Music”)
branch(branch name,branch city,assets)
customer (customer name,customer street,customer city)
loan(loan number,branch name,amount)
borrower (customer name,loan number)
account (account number,branch name,balance)
depositor (customer name,account number)
Figure 16.9 Bankingdatabase.

--- Page 822 ---

Exercises 793
16.17 Show how to derive the following equivalences by a sequence of transforma-
tionsusingtheequivalencerulesinSection16.2.1.
a. σ (E) ≡ σ (σ (σ (E)))
θ ∧θ ∧θ θ θ θ
1 2 3 1 2 3
b. σ (E ⋈ E ) ≡ σ (E ⋈ (σ (E ))), where θ involves only
θ ∧θ 1 θ 2 θ 1 θ θ 2 2
1 2 3 1 3 2
attributesfromE
2
16.18 Considerthetwoexpressionsσ (E ⟕E )andσ (E ⋈ E ).
θ 1 2 θ 1 2
a. Show using an example that the two expressions are not equivalent in
general.
b. Giveasimpleconditiononthepredicateθ,whichifsatisfiedwillensure
thatthetwoexpressionsareequivalent.
16.19 A set of equivalence rules is said to be complete if, whenever two expressions
areequivalent,onecanbederivedfromtheotherbyasequenceofusesofthe
equivalencerules.IsthesetofequivalencerulesthatweconsideredinSection
16.2.1complete?Hint:Considertheequivalenceσ (r) ≡ {}.
3=5
16.20 Explainhowtouseahistogramtoestimatethesizeofaselectionoftheform
σ (r).
A≤v
16.21 Supposetworelationsrandshavehistogramsonattributesr.Aands.A,respec-
tively,butwithdifferentranges.Suggesthowtousethehistogramstoestimate
thesizeofr ⋈ s.Hint:Splittherangesofeachhistogramfurther.
16.22 Considerthequery
selectA,B
from r
wherer.B<some(selectB
from s
wheres.A = r.A)
Showhowtodecorrelatethisqueryusingthemultisetversionofthesemijoin
operation.
16.23 Describehowtoincrementallymaintaintheresultsofthefollowingoperations
onbothinsertionsanddeletions:
a. Unionandsetdifference.
b. Leftouterjoin.
16.24 Giveanexample ofan expression definingamaterializedviewandtwositua-
tions (sets of statistics for the input relations and the differentials) such that
incremental view maintenance is better than recomputation in one situation,
andrecomputationisbetterintheothersituation.

--- Page 823 ---

794 Chapter16 QueryOptimization
16.25 Suppose you want to get answers to r ⋈ s sorted on an attribute of r, and
wantonlythe top K answersforsome relativelysmallK.Give agood wayof
evaluatingthequery:
a. When the join is on a foreign key of r referencing s, where the foreign
keyattributeisdeclaredtobenotnull.
b. Whenthejoinisnotonaforeignkey.
16.26 Consider a relation r(A,B,C), with an index on attribute A. Give an example
ofaquerythatcanbeansweredbyusingtheindexonly,withoutlookingatthe
tuplesintherelation.(Queryplansthatuseonlytheindex,withoutaccessing
theactualrelation,arecalledindex-onlyplans.)
16.27 Suppose you have an update query U. Give a simple sufficient condition on
U thatwillensurethattheHalloweenproblemcannotoccur,regardlessofthe
executionplanchosenortheindicesthatexist.
Further Reading
The seminal work of [Selinger et al. (1979)] describes access-path selection in the
System R optimizer, which was one of the earliest relational-queryoptimizers. Query
processing in Starburst, described in [Haas et al. (1989)], forms the basis for query
optimizationinIBMDB2.
[Graefe and McKenna (1993)] describes Volcano, an equivalence-rule–based
query optimizerthat,alongwithitssuccessor Cascades ([Graefe (1995)]), formsthe
basisofqueryoptimizationinMicrosoftSQLServer.[Moerkotte(2014)] providesex-
tensive textbook coverage of query optimization, including optimizations of the dy-
namicprogrammingalgorithmforjoinorderoptimizationtoavoidconsideringCarte-
sianproducts.AvoidinggenerationofplanswithCartesianproductscanresultinsub-
stantialreductioninoptimizationcostforcommonqueries.
The bibliographic notes for this chapter, available online, provides references to
research on a variety of optimization techniques, including optimization of queries
withaggregates,withouterjoins,nestedsubqueries,top-Kqueries,joinminimization,
optimization of update queries, materialized view maintenance and view matching,
indexandmaterializedviewselection,parametricqueryoptimization,andmultiquery
optimization.
Bibliography
[Graefe(1995)] G.Graefe,“TheCascadesFrameworkforQueryOptimization”,DataEngi-
neeringBulletin,Volume18,Number3(1995),pages19–29.

--- Page 824 ---

FurtherReading 795
[GraefeandMcKenna(1993)] G.GraefeandW.McKenna, “TheVolcano OptimizerGen-
erator”,InProc.oftheInternationalConf.onDataEngineering(1993),pages209–218.
[Haasetal.(1989)] L.M.Haas,J.C.Freytag,G.M.Lohman,andH.Pirahesh,“Extensible
QueryProcessinginStarburst”,InProc.oftheACMSIGMODConf.onManagementofData
(1989),pages377–388.
[Moerkotte(2014)] G.Moerkotte,BuildingQueryCompilers,availableonlineathttp://pi3.
informatik.uni-mannheim.de/∼moer/querycompiler.pdf,retrieved13Dec2018(2014).
[Selingeretal.(1979)] P.G.Selinger,M.M.Astrahan,D.D.Chamberlin,R.A.Lorie,and
T.G.Price,“AccessPathSelectioninaRelationalDatabaseSystem”,InProc.oftheACM
SIGMODConf.onManagementofData(1979),pages23–34.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 826 ---

7
PART
TRANSACTION
MANAGEMENT
Thetermtransactionreferstoacollectionofoperationsthatformasinglelogicalunit
ofwork.Forinstance,transferofmoneyfromoneaccounttoanotherisatransaction
consistingoftwoupdates,onetoeachaccount.
It is important that either all actions of a transaction be executed completely, or,
incaseofsomefailure,partialeffectsofeachincompletetransactionbeundone.This
property is called atomicity. Further, once a transaction is successfully executed, its
effectsmustpersistinthedatabase—asystemfailureshouldnotresultinthedatabase
forgettingaboutatransactionthatsuccessfullycompleted.Thispropertyiscalleddura-
bility.
In a database system where multiple transactions are executing concurrently, if
updatestoshareddataarenotcontrolled,thereispotentialfortransactionstoseein-
consistentintermediatestatescreatedbyupdatesofothertransactions.Suchasituation
canresultinerroneousupdatestodatastoredinthedatabase.Thus,databasesystems
mustprovidemechanismstoisolatetransactionsfromtheeffectsofotherconcurrently
executingtransactions.Thispropertyiscalledisolation.
Chapter 17 describesthe conceptof atransaction in detail,includingthe proper-
tiesofatomicity,durability,isolation,andotherpropertiesprovidedbythetransaction
abstraction. Inparticular,thechaptermakesprecisethenotion ofisolationbymeans
ofaconceptcalledserializability.
Chapter18describesseveralconcurrency-controltechniquesthathelpimplement
theisolation property. Chapter19 describesthe recoverymanagementcomponentof
adatabase,whichimplementstheatomicityanddurabilityproperties.
Takenasawhole,thetransaction-managementcomponentofadatabasesystemal-
lowsapplicationdeveloperstofocusontheimplementationofindividualtransactions,
ignoringtheissuesofconcurrencyandfaulttolerance.
797

--- Page 828 ---

17
CHAPTER
Transactions
Often,acollectionofseveraloperationsonthedatabaseappearstobeasingleunitfrom
thepointofviewofthedatabaseuser.Forexample,atransferoffundsfromachecking
account to a savings account is a single operation from the customer’s standpoint;
within the database system, however, it consists of several operations. It is essential
that all these operations occur, or that, in case of a failure, none occur. It would be
unacceptableifthecheckingaccountweredebitedbutthesavingsaccountnotcredited.
Collections of operations that form a single logical unit of work are called trans-
actions. A database system must ensure proper execution of transactions despite fail-
ures—either the entire transaction executes, or none of it does. Furthermore, it must
manage concurrentexecutionoftransactions inawaythatavoidstheintroductionof
inconsistency. In our funds-transfer example, a transaction computing the customer’s
totalbalancemightseethechecking-accountbalancebeforeitisdebitedbythefunds-
transfertransaction,butseethesavingsbalanceafteritiscredited.Asaresult,itwould
obtainanincorrectresult.
This chapter introduces the basic concepts of transaction processing. Details on
concurrent transaction processing and recovery from failures are in Chapter 18 and
Chapter19,respectively.
17.1 Transaction Concept
Atransactionisaunitofprogramexecutionthataccessesandpossiblyupdatesvarious
dataitems.Usually,atransactionisinitiatedbyauserprogramwritteninahigh-level
data-manipulation language (typically SQL), or programming language (e.g., C++ or
Java),withembeddeddatabaseaccessesinJDBCorODBC.Atransactionisdelimited
bystatements(orfunctioncalls)oftheformbegintransactionandendtransaction.The
transaction consists of all operations executed between the begin transaction and end
transaction.
Thiscollectionofstepsmustappeartotheuserasasingle,indivisibleunit.Since
a transaction is indivisible, it either executes in its entirety or not at all. Thus, if a
799

--- Page 829 ---

800 Chapter17 Transactions
transactionbeginstoexecutebutfailsforwhateverreason,anychangestothedatabase
thatthetransactionmayhavemademustbeundone.Thisrequirementholdsregardless
ofwhetherthetransactionitselffailed(e.g.,ifitdividedbyzero),theoperatingsystem
crashed, or the computer itself stopped operating. As we shall see, ensuring that this
requirement is met is difficult since some changes to the database may still be stored
only in the main-memory variables of the transaction, while others may have been
writtentothedatabaseandstoredondisk.This“all-or-none”propertyisreferredtoas
atomicity.
Furthermore, since a transaction is a single unit, its actions cannot appear to be
separated by other database operations not part of the transaction. While we wish to
present this user-level impression of transactions, we know that reality is quite differ-
ent.EvenasingleSQLstatementinvolvesmanyseparateaccessestothedatabase,and
a transaction may consist of several SQL statements. Therefore, the database system
musttakespecialactionstoensurethattransactionsoperateproperlywithoutinterfer-
encefromconcurrentlyexecutingdatabasestatements.Thispropertyisreferredtoas
isolation.
Evenifthesystemensurescorrectexecutionofatransaction,thisserveslittlepur-
poseifthesystemsubsequentlycrashesand,asaresult,thesystem“forgets”aboutthe
transaction.Thus,atransaction’sactionsmustpersistacrosscrashes.Thispropertyis
referredtoasdurability.
Becauseoftheabovethreeproperties,transactionsareanidealwayofstructuring
interaction with a database. This leads us to impose a requirement on transactions
themselves.Atransactionmustpreservedatabaseconsistency—ifatransactionisrun
atomically in isolation starting from a consistent database, the database must again
beconsistentattheendofthetransaction.Thisconsistencyrequirementgoesbeyond
the data-integrity constraints we have seen earlier (such as primary-key constraints,
referentialintegrity,checkconstraints,andthelike).Rather,transactionsareexpected
to go beyond that to ensure preservation of those application-dependent consistency
constraints that are too complex to state using the SQL constructs for data integrity.
Howthisisdoneistheresponsibilityoftheprogrammerwhocodesatransaction.This
propertyisreferredtoasconsistency.
Torestatetheabovemoreconcisely,werequirethatthedatabasesystemmaintain
thefollowingpropertiesofthetransactions:
• Atomicity. Either all operations of the transaction are reflected properly in the
database,ornoneare.
• Consistency.Executionofatransactioninisolation(i.e.,withnoothertransaction
executingconcurrently)preservestheconsistencyofthedatabase.
• Isolation.Eventhoughmultipletransactionsmayexecuteconcurrently,thesystem
guaranteesthat,foreverypairoftransactionsT andT,itappearstoT thateither
i j i
T finished execution before T started or T started execution after T finished.
j i j i

--- Page 830 ---

17.2 ASimpleTransactionModel 801
Thus,eachtransactionisunawareofothertransactionsexecutingconcurrentlyin
thesystem.
• Durability.Afteratransactioncompletessuccessfully,thechangesithasmadeto
thedatabasepersist,eveniftherearesystemfailures.
ThesepropertiesareoftencalledtheACIDproperties;theacronymisderivedfromthe
firstletterofeachofthefourproperties.
As we shall see later, ensuring the isolation property may have a significant ad-
verse effect on system performance. For this reason, some applications compromise
on the isolation property. We shall study these compromises after first studying the
strictenforcementoftheACIDproperties.
17.2 A Simple Transaction Model
Because SQL isapowerful and complexlanguage, webegin our study oftransactions
with a simple database language that focuses on when data are moved from disk to
main memory and from main memory to disk. In doing this, we ignore SQL insert
and delete operations and defer considering them until Section 18.4. The only actual
operationson thedataarerestrictedinoursimplelanguage toarithmeticoperations.
Later we shall discuss transactions in a realistic, SQL-based context with a richer set
of operations. The data items in our simplified model contain a single data value (a
number in our examples). Each data item is identified by a name (typically a single
letterinourexamples,thatis,A,B,C,etc.).
Weshallillustratethetransactionconceptusingasimplebankapplicationconsist-
ingofseveralaccountsandasetoftransactionsthataccessandupdatethoseaccounts.
Transactionsaccessdatausingtwooperations:
• read(X), which transfers the data item X from the database to a variable, also
called X, in a buffer in main memory belonging to the transaction that executed
thereadoperation.
• write(X), which transfers the value in the variable X in the main-memory buffer
ofthetransactionthatexecutedthewritetothedataitemX inthedatabase.
It is important to know if a change to a data item appears only in main memory
or if it has been written to the database on disk. In a real database system, the write
operationdoesnotnecessarilyresultintheimmediateupdateofthedataonthedisk;
the write operation may be temporarily stored elsewhere and executed on the disk
later.Fornow,however,weshallassumethatthewriteoperationupdatesthedatabase
immediately.WediscussstorageissuesfurtherinSection17.3anddiscusstheissueof
when database data in main memory are written to the database on disk in Chapter
19.

--- Page 831 ---

802 Chapter17 Transactions
LetT beatransactionthattransfers$50fromaccountAtoaccountB.Thistrans-
i
actioncanbedefinedas:
T: read(A);
i
A:=A−50;
write(A);
read(B);
B:=B+50;
write(B).
LetusnowconsidereachoftheACIDproperties.(Foreaseofpresentation,weconsider
theminanorderdifferentfromtheorderA-C-I-D.)
• Consistency: The consistency requirementhere isthat the sum of A and B be un-
changedbytheexecutionofthetransaction.Withouttheconsistencyrequirement,
money could be created or destroyed by the transaction! It can be verified eas-
ily that, if the database is consistent before an execution of the transaction, the
databaseremainsconsistentaftertheexecutionofthetransaction.
Ensuring consistency for an individual transaction is the responsibility of the
application programmer who codes the transaction. This task may be facilitated
byautomatictestingofintegrityconstraints,aswediscussedinSection4.4.
• Atomicity: Suppose that,justbeforetheexecutionoftransaction T,thevaluesof
i
accountsAandBare$1000and$2000,respectively.Nowsupposethat,duringthe
executionoftransactionT,afailureoccursthatpreventsT fromcompletingitsex-
i i
ecutionsuccessfully.Further,supposethatthefailurehappenedafterthewrite(A)
operation but before the write(B) operation. In this case, the values of accounts
AandBreflectedinthedatabaseare$950and$2000.Thesystemdestroyed$50
as a result of this failure. In particular, we note that the sum A + B is no longer
preserved.
Thus, because of the failure, the state of the system no longer reflects a real
state oftheworldthatthe database issupposed tocapture.We termsuch astate
an inconsistent state. We must ensure that such inconsistencies are not visible in
a database system. Note, however, that the system must at some point be in an
inconsistent state. Even if transaction T is executed to completion, there exists
i
a point at which the value of account A is $950 and the value of account B is
$2000, which is clearly an inconsistent state. This state, however, is eventually
replacedbytheconsistentstatewherethevalueofaccountAis$950,andthevalue
of account B is $2050. Thus, if the transaction never started or was guaranteed
to complete, such an inconsistent state would not be visible except during the
execution of the transaction. That is the reason for the atomicity requirement: If
theatomicitypropertyispresent,allactionsofthetransactionarereflectedinthe
database,ornoneare.

--- Page 832 ---

17.2 ASimpleTransactionModel 803
The basic idea behind ensuring atomicity is this: The database system keeps
track (on disk) of the old values of any data on which a transaction performs a
write. This information is written to a file called the log. If the transaction does
notcompleteitsexecution,thedatabasesystemrestorestheoldvaluesfromthelog
tomakeitappearasthoughthetransactionneverexecuted.Wediscusstheseideas
furtherinSection17.4.Ensuringatomicityistheresponsibilityofthedatabasesys-
tem;specifically,itishandledbyacomponentofthedatabasecalledtherecovery
system,whichwedescribeindetailinChapter19.
• Durability:Oncetheexecutionofthetransactioncompletessuccessfully,andthe
userwhoinitiatedthetransactionhasbeennotifiedthatthetransferoffundshas
taken place,itmust be thecase thatnosystem failurecanresultin alossof data
corresponding to this transfer of funds. The durability property guarantees that,
onceatransactioncompletessuccessfully,alltheupdatesthatitcarriedoutonthe
database persist, even if there is a system failure after the transaction completes
execution.
Weassumefornowthatafailureofthecomputersystemmayresultinlossof
data in main memory, but data written to disk are never lost. Protection against
loss of data on disk is discussed in Chapter 19. We can guarantee durability by
ensuringthateither:
1.Theupdatescarriedoutbythetransactionhavebeenwrittentodiskbefore
thetransactioncompletes.
2.Information about the updates carried out by the transaction is written to
disk,andsuchinformationissufficienttoenablethedatabasetoreconstruct
theupdateswhenthedatabasesystemisrestartedafterthefailure.
The recovery system of the database, described in Chapter 19, is responsible for
ensuringdurability,inadditiontoensuringatomicity.
• Isolation: Even if the consistency and atomicity properties are ensured for each
transaction,ifseveraltransactionsareexecutedconcurrently,theiroperationsmay
interleaveinsomeundesirableway,resultinginaninconsistentstate.
Forexample,aswesawearlier,thedatabaseistemporarilyinconsistentwhile
thetransactiontotransferfundsfromAtoBisexecuting,withthedeductedtotal
writtentoAandtheincreasedtotalyettobewrittentoB.Ifasecondconcurrently
runningtransactionreadsAandBatthisintermediatepointandcomputesA+B,
itwillobserveaninconsistentvalue.Furthermore,ifthissecondtransactionthen
performs updates on A and B based on the inconsistent values that it read, the
database may be left in an inconsistent state even after both transactions have
completed.
Awaytoavoidtheproblemofconcurrentlyexecutingtransactionsistoexecute
transactions serially—that is, one after the other. However, concurrent execution
oftransactionsprovidessignificantperformancebenefits,asweshallseeinSection

--- Page 833 ---

804 Chapter17 Transactions
17.5. Othersolutions have thereforebeen developed;they allow multiple transac-
tionstoexecuteconcurrently.
WediscusstheproblemscausedbyconcurrentlyexecutingtransactionsinSec-
tion 17.5. The isolation property of a transaction ensures that the concurrent ex-
ecution of transactions results in a system state that is equivalent to a state that
could have been obtained had these transactions executed one at a time in some
order.WeshalldiscusstheprinciplesofisolationfurtherinSection17.6.Ensuring
theisolationpropertyistheresponsibilityofacomponentofthedatabasesystem
calledtheconcurrency-controlsystem,whichwediscussinChapter18.
17.3 Storage Structure
Tounderstandhowtoensuretheatomicityanddurabilitypropertiesofatransaction,
wemustgainabetterunderstandingofhowthevariousdataitemsinthedatabasemay
bestoredandaccessed.
In Chapter 12, we saw that storage media can be distinguished by their relative
speed,capacity,andresiliencetofailure,andclassifiedasvolatilestorageornon-volatile
storage. We review these terms and introduce another class of storage, called stable
storage.
• Volatile storage. Information residing in volatile storage does not usually survive
system crashes. Examples of such storage are main memory and cache memory.
Accesstovolatilestorageisextremelyfast,bothbecauseofthespeedofthemem-
oryaccessitselfandbecauseitispossibletoaccessanydataiteminvolatilestorage
directly.
• Non-volatile storage. Information residing in non-volatile storage survives system
crashes.Examplesofnon-volatilestorage includesecondarystorage devicessuch
as magnetic disk and flash storage, used for online storage, and tertiary storage
devicessuchasopticalmediaandmagnetictapes,usedforarchivalstorage.Atthe
currentstateoftechnology,non-volatilestorageisslowerthanvolatilestorage,par-
ticularlyforrandomaccess.Bothsecondaryandtertiarystoragedevices,however,
aresusceptibletofailuresthatmayresultinlossofinformation.
• Stable storage. Information residing in stable storage is never lost (never should
be taken with a grain of salt, since theoretically never cannot be guaranteed—for
example,itispossible,althoughextremelyunlikely,thatablackholemayenvelop
the earth and permanently destroy all data!). Although stable storage is theoreti-
callyimpossibletoobtain,itcanbecloselyapproximatedbytechniquesthatmake
datalossextremelyunlikely.Toimplementstablestorage,wereplicatetheinforma-
tion in several non-volatile storage media (usually disk) with independent failure
modes.Updatesmustbedonewithcaretoensurethatafailureduringanupdate
to stable storage does not cause a loss of information. Section 19.2.1 discusses
stable-storageimplementation.

--- Page 834 ---

17.4 TransactionAtomicityandDurability 805
Thedistinctionsamongthevarious storage typescanbe lessclearinpracticethanin
our presentation. For example, certain systems, for example some RAID controllers,
provide battery backup, so that some main memory can survive system crashes and
powerfailures.
For a transaction to be durable, its changes need to be written to stable storage.
Similarly,foratransactiontobeatomic,logrecordsneedtobewrittentostablestorage
before any changes are made to the database on disk. The degree to which a system
ensures durability and atomicity depends on how stable its implementation of stable
storage really is. In some cases, a single copy on disk is considered sufficient, but ap-
plicationswhosedataarehighlyvaluableandwhosetransactionsarehighlyimportant
require multiple copies, or, in other words, a closer approximation of the idealized
conceptofstablestorage.
17.4 Transaction Atomicity and Durability
Aswenotedearlier,atransactionmaynotalwayscompleteitsexecutionsuccessfully.
Such a transaction is termed aborted. If we are to ensure the atomicity property, an
abortedtransactionmusthavenoeffectonthestateofthedatabase.Thus,anychanges
thattheabortedtransactionmadetothedatabasemustbeundone.Oncethechanges
caused by an aborted transaction have been undone, we say that the transaction has
beenrolledback.Itispartoftheresponsibilityoftherecoveryschemetomanagetrans-
actionaborts.Thisisdonetypicallybymaintainingalog.Eachdatabasemodification
madebyatransactionisfirstrecordedinthelog.Werecordtheidentifierofthetrans-
actionperformingthemodification,theidentifierofthedataitembeingmodified,and
both the old value (prior to modification) and the new value (after modification) of
the data item. Only then is the database itself modified. Maintaining a log provides
the possibility of redoing a modification to ensure atomicity and durability as wellas
thepossibilityofundoingamodificationtoensureatomicityincaseofafailureduring
transactionexecution.Detailsoflog-basedrecoveryarediscussedinChapter19.
Atransactionthatcompletesitsexecutionsuccessfullyissaidtobecommitted.A
committedtransactionthathasperformedupdatestransformsthedatabaseintoanew
consistentstate,whichmustpersistevenifthereisasystemfailure.
Onceatransactionhascommitted,wecannotundoitseffectsbyabortingit.The
only way to undo the effectsof acommitted transaction is to execute a compensating
transaction.Forinstance,ifatransactionadded$20toanaccount,thecompensating
transactionwouldsubtract$20fromtheaccount.However,itisnotalwayspossibleto
createsuchacompensatingtransaction.Therefore,theresponsibilityofwritingandex-
ecutingacompensatingtransactionislefttotheuserandisnothandledbythedatabase
system.
We need to be more precise about what we mean by successful completion of a
transaction.Wethereforeestablishasimpleabstracttransactionmodel.Atransaction
mustbeinoneofthefollowingstates:

--- Page 835 ---

806 Chapter17 Transactions
• Active,theinitialstate;thetransactionstaysinthisstatewhileitisexecuting.
• Partiallycommitted,afterthefinalstatementhasbeenexecuted.
• Failed,afterthediscoverythatnormalexecutioncannolongerproceed.
• Aborted, after the transaction has been rolled back and the database has been
restoredtoitsstatepriortothestartofthetransaction.
• Committed,aftersuccessfulcompletion.
The state diagram corresponding to a transaction appears in Figure 17.1. We say
thatatransactionhascommittedonlyifithasenteredthecommittedstate.Similarly,
wesaythatatransaction hasaborted onlyifithasenteredtheaborted state. Atrans-
actionissaidtohaveterminatedifithaseithercommittedoraborted.
Atransactionstartsintheactivestate.Whenitfinishesitsfinalstatement,itenters
thepartiallycommittedstate.Atthispoint,thetransactionhascompleteditsexecution,
but it is still possible that it may have to be aborted, since the actual output may still
betemporarilyresidinginmainmemory,andthusahardwarefailuremayprecludeits
successfulcompletion.
Thedatabasesystem thenwritesoutenoughinformationtodiskthat,eveninthe
eventofafailure,theupdatesperformedbythetransactioncanbere-createdwhenthe
system restarts after the failure. When the last of this information is written out, the
transactionentersthecommittedstate.
Asmentionedearlier,weassumefornowthatfailuresdonotresultinlossofdata
ondisk.Chapter19discussestechniquestodealwithlossofdataondisk.
A transaction enters the failed state after the system determines that the transac-
tion can no longer proceed with its normal execution (e.g., because of hardware or
logical errors). Such a transaction must be rolled back. Then, it enters the aborted
state.Atthispoint,thesystemhastwooptions:
partially
committed
committed
active
failed aborted
Figure 17.1 State diagramofatransaction.

--- Page 836 ---

17.5 TransactionIsolation 807
• Itcanrestartthetransaction,butonlyifthetransactionwasabortedasaresultof
some hardware or software error that was not created through the internal logic
ofthetransaction.Arestartedtransactionisconsideredtobeanewtransaction.
• Itcankillthetransaction.Itusuallydoessobecauseofsomeinternallogicalerror
that can be corrected only by rewriting the application program, or because the
inputwasbad,orbecausethedesireddatawerenotfoundinthedatabase.
Wemustbecautiouswhendealingwithobservableexternalwrites,suchaswrites
to a user’s screen, or sending email. Once such a write has occurred, it cannot be
erased, since it may have been seen external to the database system. Most systems
allow such writes to take place only after the transaction has entered the committed
state.Onewaytoimplementsuchaschemeisforthedatabasesystemtostoreanyvalue
associated with such external writes temporarily in a special relation in the database,
andtoperformtheactualwritesonlyafterthetransactionentersthecommittedstate.If
thesystemshouldfailafterthetransactionhasenteredthecommittedstate,butbefore
it could complete the external writes, the database system will carry out the external
writes(usingthedatainnon-volatilestorage)whenthesystemisrestarted.
Handlingexternalwritescanbemorecomplicatedinsomesituations.Forexample,
supposetheexternalactionisthatofdispensingcashatanautomatedtellermachine,
and the system fails just before the cash is actually dispensed (we assume that cash
can be dispensed atomically). It makes no sense to dispense cash when the system is
restarted,sincetheusermayhaveleftthemachine.Insuchacaseacompensatingtrans-
action,suchasdepositingthecashbackintotheuser’saccount,needstobeexecuted
whenthesystemisrestarted.
As another example, consider a user making a booking over the web. It is possi-
ble that the database system or the application server crashes just after the booking
transactioncommits.Itisalsopossiblethatthenetworkconnectiontotheuserislost
justafterthebookingtransactioncommits.Ineithercase,eventhoughthetransaction
has committed,the external write has not taken place.To handle such situations, the
applicationmustbedesignedsuchthatwhentheuserconnectstothewebapplication
again,shewillbeabletoseewhetherhertransactionhadsucceededornot.
Forcertainapplications,itmaybedesirabletoallowactivetransactionstodisplay
datatousers,particularlyforlong-durationtransactionsthatrunforminutesorhours.
Unfortunately,wecannotallowsuchoutputofobservabledataunlesswearewillingto
compromisetransactionatomicity.
17.5 Transaction Isolation
Transaction-processingsystemsusuallyallowmultipletransactionstorunconcurrently.
Allowing multiple transactions to update data concurrently causes several complica-
tions with consistency of the data, as we saw earlier. Ensuring consistency in spite of

--- Page 837 ---

808 Chapter17 Transactions
Note 17.1 TRENDSINCONCURRENCY
Severalcurrenttrendsinthefieldofcomputingaregivingrisetoanincreaseinthe
amountofconcurrencypossible.Asdatabasesystemsexploitthisconcurrencyto
increaseoverallsystemperformance,therewillnecessarilybeanincreasingnum-
beroftransactionsrunconcurrently.
Earlycomputershad onlyone processor. Therefore,therewas neveranyreal
concurrency in the computer. The only concurrency was apparent concurrency
createdbytheoperatingsystem asitsharedtheprocessoramongseveraldistinct
tasks or processes. Modern computers are likely to have many processors. Each
processorisreferredtoasacore;asingleprocessorchipmaycontainseveralcores,
and several such chips may be connected together in a single system, which all
shareacommonsystemmemory.Further,paralleldatabasesystemsmaycontain
multiplesuchsystems.ParalleldatabasearchitecturesarediscussedinChapter20.
Theparallelismprovidedbymultipleprocessorsandcoresisusedfortwopur-
poses.Oneistoexecutedifferentpartsofasinglelongrunningqueryinparallel,
tospeedupqueryexecution.Theotheristoallowalargenumberofqueries(often
muchsmallerqueries)toexecuteconcurrently,forexampletosupportaverylarge
numberofconcurrentusers.Chapter21throughChapter23describealgorithms
forbuildingparalleldatabasesystems.
concurrent execution of transactions requires extra work; it is far easier to insist that
transactions run serially—that is, one at a time, each starting only after the previous
onehascompleted.However,therearetwogoodreasonsforallowingconcurrency:
• Improvedthroughputandresourceutilization.Atransactionconsistsofmanysteps.
Some involve I/O activity; others involve CPU activity. The CPU and the disks in
a computer system can operate in parallel. Therefore, I/O activity can be done
in parallel with processing at the CPU. The parallelism of the CPU and the I/O
system can therefore be exploited to run multiple transactions in parallel. While
a read or write on behalf of one transaction is in progress on one disk, another
transaction can be running in the CPU, while another disk may be executing a
readorwriteonbehalfofathirdtransaction.Allofthisincreasesthethroughput
of the system—that is, the number of transactions executed in agiven amountof
time. Correspondingly, the processor and disk utilization also increase; in other
words, the processor and disk spend less time idle, or not performing any useful
work.
• Reduced waiting time. There may be a mix of transactions running on a system,
some short and some long. If transactions run serially, a short transaction may
have to wait for a preceding long transaction to complete, which can lead to un-

--- Page 838 ---

17.5 TransactionIsolation 809
predictable delays in running a transaction. If the transactions are operating on
different parts of the database, it is better to let them run concurrently, sharing
theCPUcyclesanddiskaccessesamongthem.Concurrentexecutionreducesthe
unpredictabledelaysinrunningtransactions.Moreover,italsoreducestheaverage
responsetime:theaveragetimeforatransactiontobecompletedafterithasbeen
submitted.
Themotivationforusingconcurrentexecutioninadatabaseisessentiallythesame
asthemotivationforusingmultiprogramminginanoperatingsystem.
When several transactions run concurrently, the isolation property may be vio-
lated,resultingindatabaseconsistencybeingdestroyeddespitethecorrectnessofeach
individual transaction. In this section, we present the concept of schedules to help
identifythoseexecutionsthatareguaranteedtoensuretheisolationpropertyandthus
databaseconsistency.
The database system must control the interaction among the concurrent trans-
actions to prevent them from destroying the consistency of the database. It does
so through a variety of mechanisms called concurrency-control schemes. We study
concurrency-controlschemesinChapter18;fornow,wefocuson theconceptofcor-
rectconcurrentexecution.
Consider again the simplified banking system of Section 17.1, which has several
accounts,andasetoftransactionsthataccessandupdatethoseaccounts.LetT and
1
T betwotransactionsthattransferfundsfromoneaccounttoanother.TransactionT
2 1
transfers$50fromaccountAtoaccountB.Itisdefinedas:
T : read(A);
1
A:=A−50;
write(A);
read(B);
B:=B+50;
write(B).
Transaction T transfers 10 percentof the balance from account A toaccountB. Itis
2
definedas:
T : read(A);
2
temp:=A*0.1;
A:=A−temp;
write(A);
read(B);
B:=B+temp;
write(B).

--- Page 839 ---

810 Chapter17 Transactions
T T
1 2
read(A)
A:=A−50
write(A)
read(B)
B:=B+50
write(B)
commit
read(A)
temp:=A∗0.1
A:=A−temp
write(A)
read(B)
B:=B+temp
write(B)
commit
Figure 17.2 Schedule1—aserialscheduleinwhichT 1 isfollowedbyT 2 .
SupposethecurrentvaluesofaccountsAandBare$1000and$2000,respectively.
Suppose also that the twotransactions are executed one ata time in the order T fol-
1
lowedbyT .ThisexecutionsequenceappearsinFigure17.2.Inthefigure,thesequence
2
ofinstructionstepsisinchronologicalorderfromtoptobottom,withinstructionsof
T appearingintheleftcolumnandinstructionsofT appearingintherightcolumn.
1 2
ThefinalvaluesofaccountsAandB,aftertheexecutioninFigure17.2takesplace,are
$855and$2145,respectively.Thus,thetotalamountofmoneyinaccountsAandB—
thatis,thesumA+B—ispreservedaftertheexecutionofbothtransactions.
Similarly, if the transactions are executed one at a time in the order T followed
2
by T , then the corresponding execution sequence is that of Figure 17.3. Again, as
1
expected,thesumA+Bispreserved,andthefinalvaluesofaccountsAandBare$850
and$2150,respectively.
The execution sequences just described are called schedules. They represent the
chronologicalorderinwhichinstructionsareexecutedinthesystem.Clearly,asched-
ule for a set of transactions must consist of all instructions of those transactions and
theymustpreservetheorderinwhichtheinstructionsappearineachindividualtrans-
action. For example, in transaction T , the instruction write(A) must appear before
1
the instruction read(B), in any valid schedule.Note that we includein our schedules
thecommitoperationtoindicatethatthetransactionhasenteredthecommittedstate.
Inthefollowingdiscussion,weshallrefertothefirstexecutionsequence(T followed
1
by T ) as schedule 1, and to the second execution sequence (T followed by T ) as
2 2 1
schedule2.

--- Page 840 ---

17.5 TransactionIsolation 811
T T
1 2
read(A)
temp:=A∗0.1
A:=A−temp
write(A)
read(B)
B:=B+temp
write(B)
commit
read(A)
A:=A−50
write(A)
read(B)
B:=B+50
write(B)
commit
Figure 17.3 Schedule2—aserialscheduleinwhichT 2 isfollowedbyT 1 .
Theseschedulesareserial:Eachserialscheduleconsistsofasequenceofinstruc-
tions from various transactions, where the instructions belonging to one single trans-
action appear together in that schedule. Recallinga well-known formula from combi-
natorics, we note that, for a set of n transactions, there exist n factorial (n!) different
validserialschedules.
When the database system executes several transactions concurrently, the corre-
spondingschedulenolongerneedstobeserial.Iftwotransactionsarerunningconcur-
rently,theoperatingsystemmayexecuteonetransactionforalittlewhile,thenperform
acontextswitch,executethesecondtransaction forsometime,andthenswitchback
tothefirsttransactionforsometime,andsoon.Withmultipletransactions,theCPU
timeissharedamongallthetransactions.
Severalexecutionsequencesarepossible,sincethevariousinstructionsfromboth
transactions may now be interleaved. In general, it is not possible to predict exactly
how many instructions of a transaction will be executed before the CPU switches to
anothertransaction.1
Returningtoourpreviousexample,supposethatthetwotransactionsareexecuted
concurrently.OnepossiblescheduleappearsinFigure17.4.Afterthisexecutiontakes
place, we arrive at the same state as the one in which the transactions are executed
seriallyintheorderT followedbyT .ThesumA+Bisindeedpreserved.
1 2
1Thenumberofpossibleschedulesforasetofntransactionsisverylarge.Therearen!differentserialschedules.
Consideringallthepossiblewaysthatstepsoftransactionsmightbeinterleaved,thetotalnumberofpossibleschedules
ismuchlargerthann!.

--- Page 841 ---

812 Chapter17 Transactions
T T
1 2
read(A)
A:=A−50
write(A)
read(A)
temp:=A∗0.1
A:=A−temp
write(A)
read(B)
B:=B+50
write(B)
commit
read(B)
B:=B+temp
write(B)
commit
Figure 17.4 Schedule3—aconcurrentscheduleequivalenttoschedule1.
Not all concurrent executions result in a correct state. To illustrate, consider the
scheduleofFigure17.5.Aftertheexecutionofthisschedule,wearriveatastatewhere
thefinalvaluesofaccountsAandBare$950and$2100,respectively.Thisfinalstateis
aninconsistentstate,sincewehavegained$50intheprocessoftheconcurrentexecu-
tion.Indeed,thesumA+Bisnotpreservedbytheexecutionofthetwotransactions.
If control of concurrent execution is left entirely to the operating system, many
possibleschedules,includingonesthatleavethedatabaseinaninconsistentstate,such
as the one just described, are possible. It is the job of the database system to ensure
that any schedule that is executed will leave the database in a consistent state. The
concurrency-controlcomponentofthedatabasesystemcarriesoutthistask.
Wecanensureconsistencyofthedatabaseunderconcurrentexecutionbymaking
sure that any schedule that is executed has the same effect as a schedule that could
haveoccurredwithoutanyconcurrentexecution.Thatis,thescheduleshould,insome
sense,be equivalenttoaserialschedule.Suchschedulesarecalledserializable sched-
ules.
17.6 Serializability
Before we can consider how the concurrency-controlcomponent of the database sys-
temcanensureserializability,weconsiderhowtodeterminewhenascheduleisserial-
izable.Certainly,serialschedulesareserializable,butifstepsofmultipletransactions
areinterleaved,itishardertodeterminewhetherascheduleisserializable.Sincetrans-

--- Page 842 ---

17.6 Serializability 813
T T
1 2
read(A)
A:=A−50
read(A)
temp:=A∗0.1
A:=A−temp
write(A)
read(B)
write(A)
read(B)
B:=B+50
write(B)
commit
B:=B+temp
write(B)
commit
Figure 17.5 Schedule4—aconcurrentscheduleresultinginaninconsistentstate.
actionsareprograms,itisdifficulttodetermineexactlywhatoperationsatransaction
performsandhowoperationsofvarioustransactionsinteract.Forthisreason,weshall
notconsiderthevarioustypesofoperationsthatatransactioncanperformonadata
item, but instead consider only two operations: read and write. We assume that, be-
tweenaread(Q)instructionandawrite(Q)instructiononadataitemQ,atransaction
may perform an arbitrary sequence of operations on the copy of Q that is residingin
the local buffer of the transaction. In this model, the only significant operations of a
transaction,fromaschedulingpointofview,areitsreadandwriteinstructions.Com-
mit operations, though relevant, are not considered until Section 17.7. We therefore
may show only read and write instructions in schedules, as we do for schedule 3 in
Figure17.6.
In thissection,we discuss differentforms of scheduleequivalence but focus on a
particularformcalledconflictserializability.
Let us consider a schedule S in which there are two consecutive instructions, I
and J, of transactions T and T, respectively (i ≠ j). If I and J refer to different data
i j
items,thenwecanswapI andJ withoutaffectingtheresultsofanyinstructioninthe
schedule.However,ifI andJ refertothesamedataitemQ,thentheorderofthetwo
stepsmaymatter.Sincewearedealingwithonlyreadandwriteinstructions,thereare
fourcasesthatweneedtoconsider:
1. I =read(Q),J =read(Q).TheorderofI andJ doesnotmatter,sincethesame
valueofQisreadbyT andT,regardlessoftheorder.
i j

--- Page 843 ---

814 Chapter17 Transactions
T T
1 2
read(A)
write(A)
read(A)
write(A)
read(B)
write(B)
read(B)
write(B)
Figure 17.6 Schedule3—showingonlythereadandwrite instructions.
2. I = read(Q), J = write(Q). IfI comesbefore J, then T does notread the value
i
ofQthatiswrittenbyT ininstructionJ.IfJ comesbeforeI,thenT readsthe
j i
valueofQthatiswrittenbyT.Thus,theorderofI andJ matters.
j
3. I = write(Q), J = read(Q). The order of I and J matters for reasons similar to
thoseofthepreviouscase.
4. I = write(Q), J = write(Q). Since both instructions are write operations, the
order of these instructions does not affect either T or T. However, the value
i j
obtainedbythenextread(Q)instructionofSisaffected,sincetheresultofonly
thelatterofthetwowriteinstructionsispreservedinthedatabase.Ifthereisno
other write(Q) instruction after I and J in S, then the order of I and J directly
affectsthefinalvalueofQinthedatabasestatethatresultsfromscheduleS.
Thus,onlyinthecasewherebothI andJ arereadinstructionsdoestherelativeorder
oftheirexecutionnotmatter.
WesaythatI andJ conflictiftheyareoperationsbydifferenttransactionsonthe
samedataitem,andatleastoneoftheseinstructionsisawriteoperation.
Toillustratetheconceptofconflictinginstructions,weconsiderschedule3inFig-
ure 17.6. The write(A) instruction of T conflicts with the read(A) instruction of T .
1 2
However,thewrite(A)instructionofT doesnotconflictwiththeread(B)instruction
2
ofT becausethetwoinstructionsaccessdifferentdataitems.
1
LetI andJ beconsecutiveinstructionsofascheduleS.IfI andJ areinstructions
of differenttransactionsand I andJ donotconflict,thenwecan swaptheorderof I
andJ toproduceanewscheduleS′.SisequivalenttoS′,sinceallinstructionsappear
inthesameorderinbothschedulesexceptforI andJ,whoseorderdoesnotmatter.
Since the write(A) instruction of T in schedule 3 of Figure 17.6 does not con-
2
flictwiththeread(B)instructionofT ,wecanswaptheseinstructionstogeneratean
1
equivalent schedule, schedule 5, in Figure 17.7. Regardless of the initial system state,
schedules3and5bothproducethesamefinalsystemstate.

--- Page 844 ---

17.6 Serializability 815
T T
1 2
read(A)
write(A)
read(A)
read(B)
write(A)
write(B)
read(B)
write(B)
Figure 17.7 Schedule5—schedule3afterswappingofapairofinstructions.
Wecontinuetoswapnonconflictinginstructions:
• Swaptheread(B)instructionofT withtheread(A)instructionofT .
1 2
• Swapthewrite(B)instructionofT withthewrite(A)instructionofT .
1 2
• Swapthewrite(B)instructionofT withtheread(A)instructionofT .
1 2
The final result of these swaps, schedule 6 of Figure 17.8, is a serial schedule. Note
thatschedule6isexactlythesameasschedule1,butitshowsonlythereadandwrite
instructions. Thus, we have shown that schedule 3 is equivalent to a serial schedule.
Thisequivalenceimpliesthat,regardlessoftheinitialsystemstate,schedule3produces
thesamefinalstateassomeserialschedule.
IfascheduleS canbetransformedintoascheduleS′ byaseriesofswapsofnon-
conflictinginstructions,wesaythatS andS′ areconflictequivalent.2
T T
1 2
read(A)
write(A)
read(B)
write(B)
read(A)
write(A)
read(B)
write(B)
Figure 17.8 Schedule6—aserialschedulethatisequivalenttoschedule3.
2Weusethetermconflictequivalenttodistinguishthewaywehavejustdefinedequivalencefromotherdefinitionsthat
weshalldiscusslateroninthissection.

--- Page 845 ---

816 Chapter17 Transactions
T T
3 4
read(Q)
write(Q)
write(Q)
Figure 17.9 Schedule7.
Notallserialschedulesareconflictequivalenttoeachother.Forexample, sched-
ules1and2arenotconflictequivalent.
Theconceptofconflictequivalenceleadstotheconceptofconflictserializability.
We say that a schedule S is conflict serializable if it is conflict equivalent to a serial
schedule.Thus,schedule3isconflictserializable,sinceitisconflictequivalenttothe
serialschedule1.
Finally, consider schedule 7 of Figure 17.9; it consists of only the significant op-
erations (that is, the read and write) of transactions T and T . This schedule is not
3 4
conflictserializable,sinceitisnotequivalenttoeithertheserialschedule<T ,T >or
3 4
theserialschedule<T ,T >.
4 3
Wenowpresentasimpleandefficientmethodfordeterminingtheconflictserial-
izability of a schedule. Consider a schedule S. We construct a directed graph, called
a precedencegraph, from S. Thisgraph consists of a pair G = (V, E), whereV isa set
of vertices and E is a set of edges. The set of vertices consists of all the transactions
participatinginthe schedule.Thesetof edgesconsists of alledges T → T for which
i j
oneofthreeconditionsholds:
1. T executeswrite(Q)beforeT executesread(Q).
i j
2. T executesread(Q)beforeT executeswrite(Q).
i j
3. T executeswrite(Q)beforeT executeswrite(Q).
i j
IfanedgeT →T existsintheprecedencegraph,then,inanyserialscheduleS′equiv-
i j
alenttoS,T mustappearbeforeT.
i j
For example, the precedence graph for schedule 1 in Figure 17.10a contains the
single edge T → T , since all the instructions of T are executed before the first in-
1 2 1
struction of T is executed. Similarly, Figure 17.10b shows the precedence graph for
2
T T T T
1 2 2 1
(a) (b)
Figure 17.10 Precedencegraphfor(a)schedule1and(b)schedule2.

--- Page 846 ---

17.6 Serializability 817
T T
1 2
Figure 17.11 Precedencegraphforschedule4.
schedule2withthesingle edge T →T ,sinceallthe instructionsof T are executed
2 1 2
beforethefirstinstructionofT isexecuted.
1
Theprecedencegraphforschedule4appearsinFigure17.11.Itcontainstheedge
T →T becauseT executesread(A)beforeT executeswrite(A).Italsocontainsthe
1 2 1 2
edgeT →T becauseT executesread(B)beforeT executeswrite(B).
2 1 2 1
Ifthe precedencegraph for S has acycle,then scheduleS is notconflictserializ-
able.Ifthegraphcontainsnocycles,thenthescheduleS isconflictserializable.
Aserializabilityorderofthetransactionscanbeobtainedbyfindingalinearorder
consistentwiththepartial orderof theprecedencegraph.Thisprocessiscalledtopo-
logicalsorting.Thereare,ingeneral,severalpossiblelinearordersthatcanbeobtained
throughatopologicalsort.Forexample,thegraphofFigure17.12ahasthetwoaccept-
ablelinearorderingsshowninFigure17.12bandFigure17.12c.
Thus,totestforconflictserializability,weneedtoconstructtheprecedencegraph
and to invoke a cycle-detection algorithm. Cycle-detection algorithms can be found
instandard textbooks onalgorithms.Cycle-detectionalgorithms,suchasthosebased
on depth-firstsearch,requireon the order of n2 operations, wheren isthe numberof
verticesinthegraph(thatis,thenumberoftransactions).3
Returningtoourpreviousexamples,notethattheprecedencegraphsforschedules
1and2(Figure17.10)indeeddonotcontaincycles.Theprecedencegraphforsched-
ule4(Figure17.11),ontheotherhand,containsacycle,indicatingthatthisschedule
isnotconflictserializable.
It is possible to have two schedules that produce the same outcome but that are
notconflictequivalent.Forexample,considertransactionT ,whichtransfers$10from
5
account B to account A. Let schedule 8 be as defined in Figure 17.13. We claim that
schedule 8 is not conflict equivalent to the serial schedule <T ,T >, since, in sched-
1 5
ule8,thewrite(B)instructionofT conflictswiththeread(B)instructionofT .This
5 1
createsan edgeT →T in theprecedencegraph. Similarly,wesee thatthe write(A)
5 1
instruction of T conflictswiththe readinstruction of T , creatingan edge T → T .
1 5 1 5
Thisshowsthattheprecedencegraphhasacycleandthatschedule8isnotserializable.
However,thefinalvaluesofaccountsAandBaftertheexecutionofeitherschedule8
ortheserialschedule<T ,T >arethesame—$960and$2040,respectively.
1 5
3Ifinsteadwemeasurecomplexityintermsofthenumberofedges,whichcorrespondstothenumberofactualconflicts
betweenactivetransactions,thendepth-first-basedcycledetectionislinear.

--- Page 847 ---

818 Chapter17 Transactions
T
i
T T
j k
T
m
(a)
T T
i i
T j T k
T T
k j
T T
m m
(b) (c)
Figure 17.12 Illustrationoftopological sorting.
We cansee from thisexample thatthereare less-stringentdefinitionsof schedule
equivalence than conflict equivalence. For the system to determine that schedule 8
producesthesameoutcomeastheserialschedule<T ,T >,itmustanalyzethecom-
1 5
putation performed by T and T , rather than just the read and write operations. In
1 5
general, such analysis is hard to implement and is computationally expensive. In our
example, the final result is the same as that of a serial schedule because of the math-
ematical fact that the increment and decrement operations are commutative. While
this may be easy to see in our simple example, the general case is not so easy since a
transactionmaybeexpressedasacomplexSQLstatement,aJavaprogramwithJDBC
calls,etc.
However, there are other definitions of schedule equivalence based purely on the
read and write operations. One such definition is view equivalence, a definition that
leads to the concept of view serializability. View serializability is not used in practice
duetoitshighdegreeofcomputationalcomplexity.4 Wethereforedeferdiscussionof
4TestingforviewserializabilityhasbeenproventobeNP-complete,whichmeansthatitisvirtuallycertainthatno
efficienttestforviewserializabilityexists.

--- Page 848 ---

17.7 TransactionIsolationandAtomicity 819
T T
1 5
read(A)
A:=A−50
write(A)
read(B)
B:=B−10
write(B)
read(B)
B:=B+50
write(B)
read(A)
A:=A+10
write(A)
Figure 17.13 Schedule8.
viewserializabilitytoChapter18,but,forcompleteness,noteherethattheexampleof
schedule8isnotviewserializable.
17.7 Transaction Isolation and Atomicity
Sofar,wehavestudiedscheduleswhileassumingimplicitlythattherearenotransaction
failures.Wenowaddresstheeffectoftransactionfailuresduringconcurrentexecution.
If a transaction T fails, for whatever reason, we need to undo the effect of this
i
transactiontoensuretheatomicitypropertyofthetransaction.Inasystemthatallows
concurrent execution, the atomicity property requires that any transaction T that is
j
dependent on T (i.e., T has read data written by T) is also aborted. To achieve this,
i j i
weneedtoplacerestrictionsonthetypesofschedulespermittedinthesystem.
Inthefollowingtwosubsections,weaddresstheissueofwhatschedulesareaccept-
able from the viewpointof recoveryfrom transaction failure.We describe in Chapter
18howtoensurethatonlysuchacceptableschedulesaregenerated.
17.7.1 Recoverable Schedules
Consider the partial schedule 9 in Figure 17.14, in which T is a transaction that per-
7
forms only one instruction: read(A). We call this a partial schedule because we have
notincludedacommitorabortoperationforT .NoticethatT commitsimmediately
6 7
after executing the read(A) instruction. Thus, T commits while T is still in the ac-
7 6
tive state. Now suppose that T fails before it commits. T has read the value of data
6 7
itemAwrittenbyT .Therefore,wesaythatT isdependentonT .Becauseofthis,we
6 7 6
mustabortT toensureatomicity.However,T hasalreadycommittedandcannotbe
7 7

--- Page 849 ---

820 Chapter17 Transactions
T T
6 7
read(A)
write(A)
read(A)
commit
read(B)
Figure 17.14 Schedule9,anonrecoverableschedule.
aborted.Thus,wehaveasituationwhereitisimpossibletorecovercorrectlyfromthe
failureofT .
6
Schedule9isanexampleofanonrecoverableschedule.Arecoverablescheduleisone
where,foreachpairoftransactionsT andT suchthatT readsadataitempreviously
i j j
written by T, the commitoperation of T appears before the commitoperation of T.
i i j
For the example of schedule 9 to be recoverable, T would have to delay committing
7
untilafterT commits.
6
17.7.2 Cascadeless Schedules
Even if a schedule is recoverable, to recover correctly from the failure of a transac-
tionT,wemayhavetorollbackseveraltransactions.Suchsituationsoccuriftransac-
i
tions have read data written by T. Asan illustration, considerthe partial scheduleof
i
Figure17.15.TransactionT writesavalueofAthatisreadbytransactionT .Transac-
8 9
tionT writesavalue ofAthatisreadbytransactionT .Suppose that,atthispoint,
9 10
T fails.T mustberolledback.SinceT isdependentonT ,T mustberolledback.
8 8 9 8 9
SinceT isdependentonT ,T mustberolledback.Thisphenomenon,inwhicha
10 9 10
single transaction failureleadstoaseriesof transaction rollbacks, iscalledcascading
rollback.
T T T
8 9 10
read(A)
read(B)
write(A)
read(A)
write(A)
read(A)
abort
Figure 17.15 Schedule10.

--- Page 850 ---

17.8 TransactionIsolationLevels 821
Cascading rollback is undesirable, since it leads to the undoing of a significant
amountofwork.Itisdesirabletorestricttheschedulestothosewherecascadingroll-
backs cannot occur. Such schedulesare calledcascadeless schedules. Formally,a cas-
cadelessscheduleisonewhere,foreachpairoftransactionsT andT suchthatT reads
i j j
adataitempreviouslywrittenbyT,thecommitoperationofT appearsbeforetheread
i i
operationofT.Itiseasytoverifythateverycascadelessscheduleisalsorecoverable.
j
17.8 Transaction Isolation Levels
Serializabilityisausefulconceptbecauseitallowsprogrammerstoignoreissuesrelated
toconcurrencywhentheycodetransactions.Ifeverytransactionhasthepropertythat
it maintains database consistency if executed alone, then serializability ensures that
concurrentexecutionsmaintainconsistency.However,theprotocolsrequiredtoensure
serializabilitymayallowtoolittleconcurrencyforcertainapplications.Inthesecases,
weaker levels of consistency are used. The use of weaker levels of consistency places
additionalburdensonprogrammersforensuringdatabasecorrectness.
The SQL standard also allows a transaction to specify that it may be executed in
such a way that itbecomes nonserializable with respect to other transactions. For in-
stance, a transaction may operate at the isolation level of read uncommitted, which
permitsthetransactiontoreadadataitemevenifitwaswrittenbyatransactionthat
has not been committed. SQL provides such features for the benefit of long transac-
tionswhoseresultsdonotneedtobeprecise.Ifthesetransactionsweretoexecutein
aserializablefashion,theycouldinterferewithothertransactions,causingtheothers’
executiontobedelayed.
TheisolationlevelsspecifiedbytheSQLstandardareasfollows:
• Serializable usually ensures serializable execution. However, as we shall explain
shortly, some database systems implement this isolation level in a manner that
may,incertaincases,allownonserializableexecutions.
• Repeatable read allows only committed datato be read and further requiresthat,
betweentworeadsofadataitembyatransaction,noothertransactionisallowed
toupdateit.However,thetransactionmaynotbeserializablewithrespecttoother
transactions.Forinstance,whenitissearchingfordatasatisfyingsomeconditions,
atransactionmayfindsomeofthedatainsertedbyacommittedtransaction,but
maynotfindotherdatainsertedbythesametransaction.
• Read committed allows only committed data to be read, but does not require re-
peatablereads.Forinstance,betweentworeadsofadataitembythetransaction,
anothertransactionmayhaveupdatedthedataitemandcommitted.
• Read uncommitted allows uncommitted data to be read. It is the lowest isolation
levelallowedbySQL.

--- Page 851 ---

822 Chapter17 Transactions
All the isolation levels above additionally disallow dirty writes, that is, they disallow
writestoadataitemthathasalreadybeenwrittenbyanothertransactionthathasnot
yetcommittedoraborted.
Many database systems run, by default, at the read-committed isolation level. In
SQL,itispossibletosettheisolationlevelexplicitly,ratherthanacceptingthesystem’s
defaultsetting.Forexample,thestatement
settransactionisolationlevelserializable
setstheisolationleveltoserializable;anyoftheotherisolationlevelsmaybespecified
instead. The preceding syntax is supported by Oracle, PostgreSQL, and SQL Server;
Oracleusesthesyntax
altersessionsetisolation level=serializable
while DB2 uses the syntax “change isolation level” with its own abbreviations for iso-
lation levels. Changing of the isolation level must be done as the first statement of a
transaction.
By default,most databases commitindividualstatements as soon asthey areexe-
cuted.Suchautomaticcommitofindividualstatementsmustbeturnedofftoallowmul-
tiplestatementstorunasasingletransaction.Thecommandstarttransactionensures
that subsequent SQL statements, until a subsequent commit or rollback, are executed
asasingletransaction.Asexpected,thecommitoperationcommitstheprecedingSQL
statements, whilerollback rollsbacktheprecedingSQLstatements. (SQLServeruses
begintransactioninplaceof starttransaction,whileOracleandPostgreSQLtreatbegin
asidenticaltostarttransaction.)
APIssuchasJDBCandODBCprovidefunctionstoturnoffautomaticcommit.In
JDBCthesetAutoCommitmethodoftheConnectioninterface(whichwesawearlier
inSection5.1.1.8)canbeusedtoturnautomaticcommitoffbyinvokingsetAutoCom-
mit(false),oronbyinvokingsetAutoCommit(true).Further,inJDBCthemethodset-
TransactionIsolation(int level) of the Connection interface can be invoked with any
oneof
• Connection.TRANSACTION SERIALIZABLE,
• Connection.TRANSACTION REPEATABLE READ,
• Connection.TRANSACTION READ COMMITTED,or
• Connection.TRANSACTION READ UNCOMMITTED
tosetthetransactionisolationlevelcorrespondingly.
An application designermaydecideto accepta weakerisolation levelin order to
improvesystemperformance.AsweshallseeinSection17.9andChapter18,ensuring
serializabilitymayforceatransactiontowaitforothertransactionsor,insomecases,
toabortbecausethetransactioncannolongerbeexecutedaspartofaserializableex-
ecution.Whileitmayseemshortsightedtoriskdatabaseconsistencyforperformance,

--- Page 852 ---

17.9 ImplementationofIsolationLevels 823
this trade-off makes sense if we can be sure that the inconsistency that may occur is
notrelevanttotheapplication.
Therearemanymeansofimplementingisolationlevels.Aslongastheimplemen-
tation ensures serializability, the designer of a database application or a user of an
application does not need to know the details of such implementations, except per-
haps for dealing with performance issues. Unfortunately, even if the isolation level is
set to serializable, some database systems actually implement a weaker level of isola-
tion, which does not rule out every possible nonserializable execution; we revisit this
issue in Section 17.9. If weaker levels of isolation are used, eitherexplicitly or implic-
itly,theapplicationdesignerhastobeawareofsomedetailsoftheimplementation,to
avoidorminimizethechanceofinconsistencyduetolackofserializability.
17.9 Implementation of Isolation Levels
Sofar,wehaveseenwhatpropertiesaschedulemusthaveifitistoleavethedatabase
inaconsistentstateandallowtransactionfailurestobehandledinasafemanner.
Therearevariousconcurrency-controlpoliciesthatwecanusetoensurethat,even
when multiple transactions are executed concurrently, only acceptable schedules are
generated,regardlessofhowtheoperatingsystemtime-sharesresources(suchasCPU
time)amongthetransactions.
Asa trivial example of aconcurrency-controlpolicy, considerthis: A transaction
acquires a lock on the entire database before it starts and releases the lock after it
has committed. While a transaction holds a lock, no other transaction is allowed to
acquirethelock,andallmustthereforewaitforthelocktobereleased.Asaresultof
the locking policy, only one transaction can execute at a time. Therefore, only serial
schedulesaregenerated.Thesearetriviallyserializable,anditiseasytoverifythatthey
arerecoverableandcascadelessaswell.
Aconcurrency-controlpolicysuchasthisoneleadstopoorperformance,sinceit
forcestransactionstowaitforprecedingtransactionstofinishbeforetheycanstart.In
otherwords,itprovidesapoordegreeofconcurrency(indeed,noconcurrencyatall).
AswesawinSection17.5,concurrentexecutionhassubstantialperformancebenefits.
Thegoalofconcurrency-controlpoliciesistoprovideahighdegreeofconcurrency,
whileensuringthatallschedulesthatcanbegeneratedareconflictorviewserializable,
recoverable,andcascadeless.
Hereweprovideanoverviewofhowsomeofmostimportantconcurrency-control
mechanismswork,andwedeferthedetailstoChapter18.
17.9.1 Locking
Insteadoflockingtheentiredatabase,atransactioncouldinsteadlockonlythosedata
itemsthatitaccesses.Undersuchapolicy,thetransactionmustholdlockslongenough
toensureserializability,butforaperiodshortenoughnottoharmperformanceexces-

--- Page 853 ---

824 Chapter17 Transactions
Note 17.2 SERIALIZABILITYINTHEREALWORLD
Serializable schedules are the ideal way to ensure consistency, but in our day-to-
daylives,wedon’timposesuchstringentrequirements.Awebsiteofferinggoods
for sale may list an item as being in stock, yet by the time a user selects the item
and goes through the checkout process, that item might no longer be available.
Viewedfromadatabaseperspective,thiswouldbeanonrepeatableread.
Asanotherexample,considerseatselectionforairtravel.Assumethatatrav-
elerhasalreadybookedanitineraryandnowisselectingseatsforeachflight.Many
airlinewebsitesallowtheusertostepthroughthevariousflightsandchooseaseat,
after whichthe userisasked to confirmthe selection.Itcould be thatothertrav-
elers are selecting seats or changing their seat selections for the same flights at
the same time. The seat availability that the traveler was shown is thus actually
changing, but the traveler is shown a snapshot of the seat availability as of when
thetravelerstartedtheseatselectionprocess.
Eveniftwotravelersareselectingseatsatthesametime,mostlikelytheywill
selectdifferentseats,andifsotherewouldbenorealconflict.However,thetrans-
actionsarenotserializable,sinceeachtravelerhasreaddatathatwassubsequently
updated by the other traveler, leading to a cycle in the precedence graph. If two
travelers performing seat selection concurrently actually selected the same seat,
oneofthemwouldnotbeabletogettheseattheyselected;however,thesituation
couldbeeasilyresolvedbyaskingthetravelertoperformtheselectionagain,with
updatedseatavailabilityinformation.
Itispossibletoenforceserializabilitybyallowingonlyonetravelertodoseat
selectionforaparticularflightatatime.However,doingsocouldcausesignificant
delays as travelers would have to waitfor their flightto become available for seat
selection; in particular a traveler who takes a long time to make a choice could
causeseriousproblemsforothertravelers.Instead,anysuchtransactionistypically
brokenupintoapartthatrequiresuserinteractionandapartthatrunsexclusively
on the database. In the example above, the database transaction would check if
the seats chosenby the userare still available,and ifso update the seatselection
inthedatabase.Serializabilityisensuredonlyforthetransactionsthatrunonthe
database,withoutuserinteraction.
sively.ComplicatingmattersareSQLstatementswherethedataitemsaccesseddepend
on a where clause, which we discuss in Section 17.10. In Chapter 18, we present the
two-phaselockingprotocol,asimple,widelyusedtechniquethatensuresserializability.
Statedsimply,two-phaselockingrequiresatransactiontohavetwophases,onewhere
itacquireslocksbutdoesnotreleaseany,andasecondphasewherethetransactionre-
leaseslocksbutdoesnotacquireany.(Inpractice,locksareusuallyreleasedonlywhen
thetransactioncompletesitsexecutionandhasbeeneithercommittedoraborted.)

--- Page 854 ---

17.9 ImplementationofIsolationLevels 825
Furtherimprovementstolockingresultifwehave twokindsoflocks:sharedand
exclusive.Sharedlocksareusedfordatathatthetransactionreadsandexclusivelocks
areusedforthoseitwrites.Manytransactionscanholdsharedlocksonthesamedata
item at the same time, but a transaction is allowed an exclusive lock on a data item
onlyifnoothertransactionholdsanylock(regardlessofwhethersharedorexclusive)
onthedataitem.Thisuseoftwomodesoflocksalongwithtwo-phaselockingallows
concurrentreadingofdatawhilestillensuringserializability.
17.9.2 Timestamps
Anothercategoryoftechniquesfortheimplementationofisolationassignseachtrans-
actionatimestamp,typicallywhenitbegins.Foreachdataitem,thesystemkeepstwo
timestamps.Thereadtimestampofadataitemholdsthelargest(thatis,themostre-
cent)timestampofthosetransactionsthatreadthedataitem.Thewritetimestampof
adataitemholdsthetimestampofthetransactionthatwrotethecurrentvalueofthe
dataitem.Timestampsareusedtoensurethattransactionsaccesseachdataiteminor-
derofthetransactions’timestampsiftheiraccessesconflict.Whenthisisnotpossible,
offendingtransactionsareabortedandrestartedwithanewtimestamp.
17.9.3 Multiple Versions and Snapshot Isolation
By maintaining more than one version of a data item, it is possible to allow a trans-
actiontoreadanoldversionofadataitemratherthananewerversionwrittenbyan
uncommitted transaction or by a transaction that should come later in the serializa-
tionorder.Thereareavarietyofmultiversionconcurrency-controltechniques.Onein
particular,calledsnapshotisolation,iswidelyusedinpractice.
Insnapshotisolation,wecanimaginethateachtransactionisgivenitsownversion,
orsnapshot,ofthedatabasewhenitbegins.5Itreadsdatafromthisprivateversionand
isthusisolatedfromtheupdatesmadebyothertransactions.Ifthetransactionupdates
the database, that update appears only in its own version, not in the actual database
itself. Information about these updates is saved so that the updates can be applied to
the“real”databaseifthetransactioncommits.
When a transaction T enters the partially committed state, it then proceeds to
thecommittedstate onlyifnootherconcurrenttransactionhasmodifieddatathatT
intendstoupdate.Transactionsthat,asaresult,cannotcommitabortinstead.
Snapshot isolation ensures that attempts to read data never need to wait (unlike
locking).Read-onlytransactionscannotbeaborted;onlythosethatmodifydataruna
slightriskofaborting.Sinceeachtransactionreadsitsownversionorsnapshotofthe
database,readingdatadoesnotcausesubsequentupdateattemptsbyothertransactions
to wait(unlike locking). Since most transactions are read-only(and most others read
moredatathantheyupdate),thisisoftenamajorsourceofperformanceimprovement
ascomparedtolocking.
5Inreality,theentiredatabaseisnotcopied.Multipleversionsarekeptonlyofthosedataitemsthatarechanged.

--- Page 855 ---

826 Chapter17 Transactions
The problem with snapshot isolation is that, paradoxically, it provides too much
isolation.ConsidertwotransactionsT andT′.Inaserializableexecution,eitherT sees
all the updates made by T′ or T′ sees all the updates made by T, because one must
follow the other in the serialization order. Under snapshot isolation, there are cases
whereneithertransactionseestheupdatesoftheother.Thisisasituationthatcannot
occur in a serializable execution. In many (indeed, most) cases, the data accesses by
thetwotransactionsdonotconflictandthereisnoproblem.However,ifT readssome
data item that T′ updates and T′ reads some data item that T updates, it is possible
thatbothtransactionsfailtoreadtheupdatemadebytheother.Theresult,asweshall
seeinChapter18,maybeaninconsistentdatabasestatethat,ofcourse,couldnotbe
obtainedinanyserializableexecution.
Oracle,PostgreSQL,andSQLServeroffertheoptionofsnapshotisolation.Oracle
andPostgreSQLversionspriortoPostgreSQL9.1implementtheserializableisolation
levelusing snapshot isolation.Asaresult,theirimplementationof serializabilitycan,
inexceptionalcircumstances,resultinanonserializableexecutionbeingallowed.SQL
Server instead includes an additional isolation level beyond the standard ones, called
snapshot, to offer the option of snapshot isolation. PostgreSQL versions subsequent
to9.1implementaformofconcurrencycontrolcalledserializablesnapshotisolation,
whichprovidesthebenefitsofsnapshotisolationwhileensuringserializability.
17.10 Transactions as SQL Statements
In Section 4.3, we presented the SQL syntax for specifying the beginning and end of
transactions. Now thatwehave seen some ofthe issuesinensuring theACIDproper-
tiesfortransactions,wearereadytoconsiderhowthosepropertiesareensuredwhen
transactions are specified as a sequence of SQL statements rather than the restricted
modelofsimplereadsandwritesthatweconsidereduptothispoint.
In our simple model, we assumed a set of data items exists. While our simple
modelalloweddata-itemvaluestobechanged,itdidnotallowdataitemstobecreated
or deleted. In SQL, however, insert statements create new data and delete statements
deletedata.Thesetwostatementsare,ineffect,writeoperations,sincetheychangethe
database,buttheirinteractionswiththeactionsofothertransactionsaredifferentfrom
whatwesaw inour simple model.Asan example, considerhow insertion or deletion
wouldconflictwiththefollowingSQLquery,whichfindsallinstructorswhoearnmore
than$90,000:
selectID,name
frominstructor
wheresalary>90000;
Usingoursampleinstructor relation(SectionA.3),wefindthatonlyEinsteinand
Brandtsatisfythecondition.Nowassumethataroundthesametimewearerunningour
query,anotheruserinsertsanewinstructornamed“James”whosesalaryis$100,000.

--- Page 856 ---

17.10 TransactionsasSQLStatements 827
insertintoinstructor values('11111','James','Marketing',100000);
Theresultofourquerydependsonwhetherthisinsertcomesbeforeorafterourquery
is run. In a concurrent execution of these transactions, it is intuitively clear that they
conflict,butthisisaconflictthatmaynotbecapturedbyoursimplemodel.Thissitu-
ationisreferredtoasthephantomphenomenonbecauseaconflictmayexiston“phan-
tom”data.
Our simple model of transactions required that operations operate on a specific
dataitemgivenasanargumenttotheoperation.Inoursimplemodel,wecanlookatthe
readandwritestepstoseewhichdataitemsarereferenced.ButinanSQLstatement,the
specificdataitems(tuples)referencedmaybedeterminedbyawhereclausepredicate.
So the same transaction, if run more than once, might reference different data items
eachtimeitisrunifthevaluesinthedatabasechangebetweenruns.Inourexample,
the'James'tupleisreferencedonlyifourquerycomesaftertheinsertion.LetT denote
thequeryandletT′ denotetheinsert.IfT′ comesfirst,thenthereisanedgeT′ → T
in the precedence graph. However, in the case where the query T comes first, there
is no edge in the precedence graph between T and T′ despite the actual conflict on
phantomdatathatforcesT tobeserializedbeforeT′.
The above-mentioned problem demonstrates that it is not sufficient for concur-
rency control to consider only the tuples that are accessed by a transaction; the in-
formation used to find the tuples that are accessed by the transaction must also be
considered for the purpose of concurrency control. The information used to find tu-
plescouldbeupdatedbyaninsertionordeletion,orinthecaseofanindex,evenbyan
updatetoasearch-keyattribute.Forexample,iflockingisusedforconcurrencycontrol,
thedatastructuresthattrackthetuplesinarelation,aswellasindexstructures,must
beappropriatelylocked.However,suchlockingcanleadtopoorconcurrencyinsome
situations; index-locking protocols that maximize concurrency, while ensuring serial-
izabilityinspiteofinserts,deletes,andpredicatesinqueries,arediscussedinSection
18.4.3.
Letusconsideragainthequery:
selectID,name
frominstructor
wheresalary>90000;
andthefollowingSQLupdate:
updateinstructor
setsalary=salary*0.9
wherename=’Wu’;
We now face an interesting situation in determiningwhetherour queryconflictswith
theupdatestatement.Ifourqueryreadstheentireinstructorrelation,thenitreadsthe

--- Page 857 ---

828 Chapter17 Transactions
tuplewithWu’sdataandconflictswiththeupdate.However,ifanindexwereavailable
thatallowedourquerydirectaccesstothosetupleswithsalary>90000,thenourquery
wouldnothaveaccessedWu’sdataatallbecauseWu’ssalaryisinitially$90,000inour
exampleinstructorrelationandreducesto$81,000aftertheupdate.
However,usingtheaboveapproach,itwouldappearthattheexistenceofaconflict
depends on a low-level query processing decision by the system that is unrelated to a
user-levelviewofthemeaningofthetwoSQLstatements!Analternativeapproachto
concurrency control treats an insert, delete, or update as conflicting with a predicate
onarelation,ifitcouldaffectthesetoftuplesselectedbyapredicate.Inourexample
query above, the predicate is “salary > 90000”, and an update of Wu’s salary from
$90,000toavaluegreaterthan$90,000,oranupdateofEinstein’ssalaryfromavalue
greaterthan$90,000toavaluelessthanorequalto$90,000,wouldconflictwiththis
predicate. Locking based on this idea is called predicate locking; predicate locking is
oftenimplementedusinglocksonindexnodesasweseeinSection18.4.3.
17.11 Summary
• A transaction is a unit of program execution that accesses and possibly updates
various data items. Understanding the concept of a transaction is critical for un-
derstanding and implementing updates of data in a database in such a way that
concurrentexecutionsandfailuresofvariousformsdonotresultinthedatabase
becominginconsistent.
• TransactionsarerequiredtohavetheACIDproperties:atomicity,consistency,iso-
lation,anddurability.
° Atomicityensuresthateitheralltheeffectsofatransactionarereflectedinthe
database, or none are; a failure cannot leave the database in a state where a
transactionispartiallyexecuted.
° Consistency ensures that, if the database is initially consistent, the execution
ofthetransaction(byitself)leavesthedatabaseinaconsistentstate.
° Isolation ensures that concurrently executing transactions are isolated from
one another, so that eachhas the impression that no othertransaction isexe-
cutingconcurrentlywithit.
° Durability ensures that, once atransaction has been committed,that transac-
tion’supdatesdonotgetlost,evenifthereisasystemfailure.
• Concurrent execution of transactions improves throughput of transactions and
systemutilizationandalsoreducesthewaitingtimeoftransactions.
• Thevarioustypesofstorageinacomputerarevolatilestorage,non-volatilestorage,
and stable storage. Data in volatile storage, such as in RAM, are lost when the
computer crashes. Data in non-volatile storage, such as disk, are not lost when

--- Page 858 ---

17.11 Summary 829
thecomputercrashesbutmayoccasionallybelostbecauseoffailuressuchasdisk
crashes.Datainstablestorageareneverlost.
• Stablestoragethatmustbeaccessibleonlineisapproximatedwithmirroreddisks,
orotherformsofRAID,whichprovideredundantdatastorage.Offline,orarchival,
stable storage mayconsist of multipletape copies of data stored in physicallyse-
curelocations.
• Whenseveraltransactionsexecuteconcurrentlyonthedatabase,theconsistency
of data may no longer be preserved. It is therefore necessary for the system to
controltheinteractionamongtheconcurrenttransactions.
° Since a transaction is a unit that preserves consistency, a serial execution of
transactionsguaranteesthatconsistencyispreserved.
° A schedule captures the key actions of transactions that affect concurrent ex-
ecution, such as read and write operations, while abstracting away internal
detailsoftheexecutionofthetransaction.
° We require that any schedule produced by concurrent processing of a set of
transactionswillhaveaneffectequivalenttoascheduleproducedwhenthese
transactionsarerunseriallyinsomeorder.
° Asystemthatguaranteesthispropertyissaidtoensureserializability.
° There are several different notions of equivalence leading to the concepts of
conflictserializabilityandviewserializability.
• Serializabilityof schedules generated by concurrentlyexecuting transactions can
beensuredthroughoneofavarietyofmechanismscalledconcurrency-controlpoli-
cies.
• We can test a given schedule for conflict serializability by constructing a prece-
dence graph for the schedule and by searching for the absence of cycles in the
graph. However, there are more efficient concurrency-control policies for ensur-
ingserializability.
• Schedulesmustberecoverable,tomakesurethatiftransactionaseestheeffects
oftransactionb,andbthenaborts,thenaalsogetsaborted.
• Schedulesshouldpreferablybecascadeless,sothattheabortofatransactiondoes
notresultincascadingabortsofothertransactions.Cascadelessnessisensuredby
allowingtransactionstoonlyreadcommitteddata.
• The concurrency-control management component of the database is responsible
forhandlingtheconcurrency-controlpolicies.Techniquesincludelocking,times-
tampordering,andsnapshotisolation.Chapter18describesconcurrency-control
policies.

--- Page 859 ---

830 Chapter17 Transactions
• Databasesystemsofferisolationlevelsweakerthanserializabilitytoallowlessre-
striction of concurrency and thus improved performance. This introduces a risk
ofinconsistencythatsomeapplicationsfindacceptable.
• EnsuringcorrectconcurrentexecutioninthepresenceofSQLupdate,insert,and
deleteoperationsrequiresadditionalcareduetothephantomphenomenon.
Review Terms
• Transaction • Observableexternalwrites
• ACIDproperties • Concurrentexecutions
° Atomicity • Serialexecution
• Schedules
° Consistency
• Conflictofoperations
° Isolation
• Conflictequivalence
° Durability • Conflictserializability
• Inconsistentstate • Serializabilitytesting
• Storagetypes • Precedencegraph
° Volatilestorage • Serializabilityorder
• Recoverableschedules
° Non-volatilestorage
• Cascadingrollback
° Stablestorage
• Cascadelessschedules
• Concurrency-controlsystem • Isolationlevels
• Recoverysystem
• Transactionstate ° Serializable
° Repeatableread
° Active
° Readcommitted
° Partiallycommitted
° Readuncommitted
° Failed
° Aborted • Dirtywrites
° Committed • Automaticcommit
• Concurrencycontrol
° Terminated
• Locking
• compensatingtransaction
• Timestampordering
• Transaction
• Snapshotisolation
° Restart • Phantomphenomenon
° Kill • Predicatelocking

--- Page 860 ---

PracticeExercises 831
Practice Exercises
17.1 Supposethatthereisadatabasesystemthatneverfails.Isarecoverymanager
requiredforthissystem?
17.2 Considerafilesystemsuchastheoneonyourfavoriteoperatingsystem.
a. What are the steps involved in the creation and deletion of files and in
writingdatatoafile?
b. Explain how the issues of atomicity and durability are relevant to the
creationanddeletionoffilesandtowritingdatatofiles.
17.3 Database-system implementers have paid much more attention to the ACID
propertiesthanhavefile-systemimplementers.Whymightthisbethecase?
17.4 Whatclassorclassesofstoragecanbeusedtoensuredurability?Why?
17.5 Since every conflict-serializable schedule is view serializable, why do we em-
phasizeconflictserializabilityratherthanviewserializability?
17.6 ConsidertheprecedencegraphofFigure17.16.Isthecorrespondingschedule
conflictserializable?Explainyouranswer.
17.7 What is a cascadeless schedule? Why is cascadelessness of schedules desir-
able?Arethereanycircumstancesunderwhichitwouldbedesirabletoallow
noncascadelessschedules?Explainyouranswer.
17.8 Thelost updateanomalyissaidtooccurifatransaction T readsadataitem,
j
thenanothertransactionT writesthedataitem(possiblybasedonaprevious
k
read), after which T writes the data item. The update performed by T has
j k
beenlost,sincetheupdatedonebyT ignoredthevaluewrittenbyT .
j k
T T
1 2
T T
4 3
T
5
Figure 17.16 PrecedencegraphforPracticeExercise17.6.

--- Page 861 ---

832 Chapter17 Transactions
a. Giveanexampleofascheduleshowingthelostupdateanomaly.
b. Giveanexamplescheduletoshowthatthelostupdateanomalyispossi-
blewiththereadcommittedisolationlevel.
c. Explainwhythelostupdateanomalyisnotpossiblewiththerepeatable
readisolationlevel.
17.9 Considera database fora bank wherethe database system uses snapshot iso-
lation.Describeaparticularscenarioinwhichanonserializableexecutionoc-
cursthatwouldpresentaproblemforthebank.
17.10 Consider a database for an airline where the database system uses snapshot
isolation.Describeaparticularscenarioinwhichanonserializableexecution
occurs,buttheairlinemaybewillingtoacceptitinordertogainbetteroverall
performance.
17.11 The definition of a schedule assumes that operations can be totally ordered
bytime.Consideradatabasesystem thatrunson asystem withmultiplepro-
cessors,whereitisnotalwayspossibletoestablishanexactorderingbetween
operations that executed on different processors. However, operations on a
dataitemcanbetotallyordered.
Doesthissituationcauseanyproblemforthedefinitionofconflictserializ-
ability?Explainyouranswer.
Exercises
17.12 ListtheACIDproperties.Explaintheusefulnessofeach.
17.13 Duringitsexecution,atransactionpassesthroughseveralstates,untilitfinally
commitsoraborts.Listallpossiblesequencesofstatesthroughwhichatrans-
actionmaypass.Explainwhyeachstatetransitionmayoccur.
17.14 Explainthedistinctionbetweenthetermsserialscheduleandserializablesched-
ule.
17.15 Considerthefollowingtwotransactions:
T : read(A);
13
read(B);
ifA = 0thenB:=B+1;
write(B).
T : read(B);
14
read(A);
ifB = 0thenA:=A+1;
write(A).

--- Page 862 ---

Exercises 833
LettheconsistencyrequirementbeA = 0 ∨ B = 0,withA = B = 0as
theinitialvalues.
a. Show that every serial execution involving these two transactions pre-
servestheconsistencyofthedatabase.
b. ShowaconcurrentexecutionofT andT thatproducesanonserializ-
13 14
ableschedule.
c. IsthereaconcurrentexecutionofT andT thatproducesaserializable
13 14
schedule?
17.16 Giveanexampleofaserializableschedulewithtwotransactionssuchthatthe
orderinwhichthetransactionscommitisdifferentfromtheserializationorder.
17.17 Whatisarecoverableschedule?Whyisrecoverabilityofschedulesdesirable?
Are there any circumstances under which it would be desirable to allow non-
recoverableschedules?Explainyouranswer.
17.18 Why do database systems support concurrent execution of transactions, de-
spitetheextraeffortneededtoensurethatconcurrentexecutiondoesnotcause
anyproblems?
17.19 Explain why the read-committed isolation level ensures that schedules are
cascade-free.
17.20 For each of the following isolation levels, give an example of a schedule that
respectsthespecifiedlevelofisolationbutisnotserializable:
a. Readuncommitted
b. Readcommitted
c. Repeatableread
17.21 Supposethatinadditiontotheoperationsreadandwrite,weallowanopera-
tionpred read(r,P),whichreadsalltuplesinrelationrthatsatisfypredicate
P.
a. Give an example of a schedule using the pred read operation that ex-
hibitsthephantomphenomenonandisnonserializableasaresult.
b. Give an example of a schedule where one transaction uses the
pred readoperationon relationr andanotherconcurrenttransaction
deletesatuplefromr,butthescheduledoesnotexhibitaphantomcon-
flict. (To do so, you have to give the schema of relation r and show the
attributevaluesofthedeletedtuple.)

--- Page 863 ---

834 Chapter17 Transactions
Further Reading
[Gray and Reuter (1993)] provides detailed textbook coverage of transaction-
processing concepts, techniques, and implementation details, including concurrency
controlandrecoveryissues.[BernsteinandNewcomer(2009)]providestextbookcov-
erageofvariousaspectsoftransactionprocessing.
Theconceptofserializabilitywasformalizedby[Eswaranetal.(1976)]inconnec-
tionwithworkonconcurrencycontrolforSystemR.
References covering specific aspects of transaction processing, such as concur-
rencycontrolandrecovery,arecitedinChapter18andChapter19.
Bibliography
[BernsteinandNewcomer(2009)] P.A.BernsteinandE.Newcomer,PrinciplesofTransaction
Processing,2ndedition,MorganKaufmann(2009).
[Eswaranetal.(1976)] K.P.Eswaran,J.N.Gray,R.A.Lorie,andI.L.Traiger,“TheNotions
of Consistency and Predicate Locks in a Database System”, Communications of the ACM,
Volume19,Number11(1976),pages624–633.
[GrayandReuter(1993)] J.GrayandA.Reuter,TransactionProcessing:ConceptsandTech-
niques,MorganKaufmann(1993).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 864 ---

18
CHAPTER
Concurrency Control
We saw in Chapter 17 that one of the fundamental properties of a transaction is iso-
lation. When several transactions execute concurrently in the database, however, the
isolation property may no longer be preserved. To ensure that it is, the system must
control the interaction among the concurrent transactions; this control is achieved
through one of a variety of mechanisms called concurrency-control schemes. In this
chapter,weconsiderthemanagementofconcurrentlyexecutingtransactions, and we
ignorefailures.InChapter19,weshallseehowthesystemcanrecoverfromfailures.
Asweshallsee,thereareavarietyofconcurrency-controlschemes.Noonescheme
is clearly the best; each one has advantages. In practice, the most frequently used
schemesaretwo-phaselockingandsnapshotisolation.
18.1 Lock-Based Protocols
Onewaytoensureisolationistorequirethatdataitemsbeaccessedinamutuallyexclu-
sivemanner;thatis,whileonetransactionisaccessingadataitem,noothertransaction
canmodifythatdataitem.Themostcommonmethodusedtoimplementthisrequire-
mentistoallowatransactiontoaccessadataitemonlyifitiscurrentlyholdingalock
onthatitem.WeintroducedtheconceptoflockinginSection17.9.
18.1.1 Locks
Therearevariousmodesinwhichadataitemmaybelocked.Inthissection,werestrict
ourattentiontotwomodes:
1. Shared. If a transaction T has obtained a shared-mode lock (denoted by S) on
i
itemQ,thenT canread,butcannotwrite,Q.
i
2. Exclusive.IfatransactionT hasobtainedanexclusive-modelock(denotedbyX)
i
onitemQ,thenT canbothreadandwriteQ.
i
We require that every transaction request a lock in an appropriate mode on data
itemQ,dependingonthetypesofoperationsthatitwillperformonQ.Thetransaction
835

--- Page 865 ---

836 Chapter18 ConcurrencyControl
S X
S true false
X false false
Figure 18.1 Lock-compatibility matrixcomp.
makes the request to the concurrency-control manager. The transaction can proceed
with the operation only after the concurrency-controlmanager grants the lock to the
transaction. The use of these two lock modes allows multiple transactions to read a
dataitembutlimitswriteaccesstojustonetransactionatatime.
Tostatethismoregenerally,givenasetoflockmodes,wecandefineacompatibility
functiononthemasfollows:LetAandBrepresentarbitrarylockmodes.Supposethat
a transaction T requests a lock of mode A on item Q on which transaction T (T
i j i
≠ T) currently holds a lock of mode B. If transaction T can be granted a lock on
j i
Q immediately, in spite of the presence of the mode B lock, then we say mode A is
compatiblewithmodeB.Suchafunctioncanberepresentedconvenientlybyamatrix.
Thecompatibilityrelationbetweenthetwomodesoflockingdiscussedinthissection
appearsinthematrixcompofFigure18.1.Anelementcomp(A,B)ofthematrixhas
thevaluetrueifandonlyifmodeAiscompatiblewithmodeB.
Note that shared mode is compatible with shared mode, but not with exclusive
mode.Atanytime,severalshared-modelockscanbeheldsimultaneously(bydifferent
transactions)onaparticulardataitem.Asubsequentexclusive-modelockrequesthas
towaituntilthecurrentlyheldshared-modelocksarereleased.
A transaction requests a shared lock on data item Q by executing the lock-S(Q)
instruction. Similarly, a transaction requests an exclusive lock through the lock-X(Q)
instruction.AtransactioncanunlockadataitemQbytheunlock(Q)instruction.
Toaccessadataitem,transactionT mustfirstlockthatitem.Ifthedataitemisal-
i
readylockedbyanothertransactioninanincompatiblemode,theconcurrency-control
managerwillnotgrantthelockuntilallincompatiblelocksheldbyothertransactions
havebeenreleased.Thus,T ismadetowaituntilallincompatiblelocksheldbyother
i
transactionshavebeenreleased.
Transaction T may unlock a data item that it had locked at some earlier point.
i
Note that a transaction must hold a lock on a data item as long as it accesses that
item. Moreover, it is not necessarily desirable for a transaction to unlock a data item
immediately after its final access of that data item, since serializability may not be
ensured.
Asanillustration,consideragainthebankingexamplethatweintroducedinChap-
ter17.LetAandBbetwoaccountsthatareaccessedbytransactionsT andT .Trans-
1 2
action T transfers $50 from account B to account A (Figure 18.2). Transaction T
1 2
displaysthetotalamountofmoneyinaccountsAandB—thatis,thesumA+B(Figure
18.3).

--- Page 866 ---

18.1 Lock-BasedProtocols 837
T : lock-X(B);
1
read(B);
B:=B−50;
write(B);
unlock(B);
lock-X(A);
read(A);
A:=A+50;
write(A);
unlock(A).
Figure 18.2 TransactionT 1 .
Suppose that the values of accounts A and B are $100 and $200, respectively. If
thesetwotransactionsareexecutedserially,eitherintheorderT ,T ortheorderT ,
1 2 2
T ,thentransactionT willdisplaythevalue$300.If,however,thesetransactionsare
1 2
executed concurrently,thenschedule1, inFigure18.4,ispossible. Inthiscase,trans-
action T displays $250, which is incorrect. The reason for this mistake is that the
2
transactionT unlockeddataitemBtooearly,asaresultofwhichT sawaninconsis-
1 2
tentstate.
Thescheduleshowstheactionsexecutedbythetransactions,aswellasthepoints
at which the concurrency-control manager grants the locks. The transaction making
a lock request cannot execute its next action until the concurrency-control manager
grants the lock. Hence, the lock must be granted in the interval of time between the
lock-requestoperationandthefollowingactionofthetransaction.Exactlywhenwithin
thisintervalthelockisgrantedisnotimportant;wecansafelyassumethatthelockis
grantedjustbeforethefollowingactionofthetransaction.Weshallthereforedropthe
T : lock-S(A);
2
read(A);
unlock(A);
lock-S(B);
read(B);
unlock(B);
display(A+B).
Figure 18.3 TransactionT 2 .

--- Page 867 ---

838 Chapter18 ConcurrencyControl
T T concurrency-controlmanager
1 2
lock-X(B)
grant-X(B,T )
1
read(B)
B:=B−50
write(B)
unlock(B)
lock-S(A)
grant-S(A,T )
2
read(A)
unlock(A)
lock-S(B)
grant-S(B,T )
2
read(B)
unlock(B)
display(A+B)
lock-X(A)
grant-X(A,T )
1
read(A)
A:=A+50
write(A)
unlock(A)
Figure 18.4 Schedule1.
column depicting the actions of the concurrency-control manager from all schedules
depictedintherestofthechapter.Weletyouinferwhenlocksaregranted.
Suppose nowthatunlockingisdelayedtotheendofthetransaction.Transaction
T correspondstoT withunlockingdelayed(Figure18.5).TransactionT corresponds
3 1 4
toT withunlockingdelayed(Figure18.6).
2
Youshouldverifythatthesequenceofreadsandwritesinschedule1,whichleadto
anincorrecttotalof$250beingdisplayed,isnolongerpossiblewithT andT .Other
3 4
schedulesare possible. T willnot print out an inconsistent result in any of them; we
4
shallseewhylater.
Unfortunately, locking can lead to an undesirable situation. Consider the partial
schedule of Figure 18.7 for T and T . Since T is holding an exclusive-mode lock on
3 4 3
B and T is requesting a shared-mode lock on B, T is waiting for T to unlock B.
4 4 3
Similarly,sinceT isholdingashared-modelockonAandT isrequestinganexclusive-
4 3
mode lock on A, T is waiting for T to unlock A. Thus, we have arrived at a state
3 4
where neither of these transactions can ever proceed with its normal execution. This
situation is called deadlock. When deadlock occurs, the system must roll back one of

--- Page 868 ---

18.1 Lock-BasedProtocols 839
T : lock-X(B);
3
read(B);
B:=B−50;
write(B);
lock-X(A);
read(A);
A:=A+50;
write(A);
unlock(B);
unlock(A).
Figure 18.5 TransactionT 3 (transactionT 1 withunlockingdelayed).
thetwotransactions.Onceatransactionhasbeenrolledback,thedataitemsthatwere
locked by that transaction are unlocked. These data items are then available to the
othertransaction, whichcancontinue with itsexecution.We shall return tothe issue
ofdeadlockhandlinginSection18.2.
Ifwedonotuselocking,orifweunlockdataitemstoosoonafterreadingorwriting
them, we may get inconsistent states. On the other hand, if we do not unlock a data
item before requesting a lock on another data item, deadlocks may occur. There are
waystoavoiddeadlockinsomesituations,asweshallseeinSection18.1.5.However,
ingeneral, deadlocksareanecessaryevilassociated withlocking,ifwewanttoavoid
inconsistentstates.Deadlocksaredefinitelypreferabletoinconsistentstates,sincethey
can be handled by rolling back transactions, whereas inconsistent states may lead to
real-worldproblemsthatcannotbehandledbythedatabasesystem.
Weshallrequirethateachtransactioninthesystem followasetofrules,calleda
locking protocol,indicatingwhen a transaction may lockand unlock eachof the data
items.Lockingprotocolsrestrictthenumberofpossibleschedules.Thesetofallsuch
T : lock-S(A);
4
read(A);
lock-S(B);
read(B);
display(A+B);
unlock(A);
unlock(B).
Figure 18.6 TransactionT 4 (transactionT 2 withunlockingdelayed).

--- Page 869 ---

840 Chapter18 ConcurrencyControl
T T
3 4
lock-X(B)
read(B)
B:=B−50
write(B)
lock-S(A)
read(A)
lock-S(B)
lock-X(A)
Figure 18.7 Schedule2.
schedules is a proper subset of all possible serializable schedules. We shall present
several locking protocols that allow only conflict-serializable schedules, and thereby
ensureisolation.Beforedoingso,weintroducesometerminology.
Let {T , T ,…,T } be a set of transactions participating in a schedule S. We say
0 1 n
thatT precedesT inS,writtenT →T,ifthereexists adataitemQ such thatT has
i j i j i
heldlockmodeAonQ,andT hasheldlockmodeBonQlater,andcomp(A,B)=false.
j
IfT →T,thenthatprecedenceimpliesthatinanyequivalentserialschedule,T must
i j i
appear before T. Observe that this graph is similar to the precedence graph that we
j
used in Section 17.6 to test for conflict serializability. Conflicts between instructions
correspondtononcompatibilityoflockmodes.
We say that a schedule S is legal under a given lockingprotocol if S is a possible
scheduleforasetoftransactionsthatfollowstherulesofthelockingprotocol.Wesay
thatalockingprotocolensuresconflictserializabilityifand onlyifalllegal schedules
areconflictserializable;inotherwords,foralllegalschedulestheassociated→relation
isacyclic.
18.1.2 Granting of Locks
Whenatransactionrequestsalockonadataiteminaparticularmode,andnoother
transaction has a lock on the same data item in a conflicting mode, the lock can be
granted.However,caremustbetakentoavoidthefollowingscenario.Supposeatrans-
actionT hasashared-modelockonadataitem,andanothertransactionT requests
2 1
an exclusive-mode lock on the data item. T has to wait for T to release the shared-
1 2
modelock.Meanwhile,atransactionT mayrequestashared-modelockonthesame
3
data item. The lock request is compatible with the lock granted to T , so T may be
2 3
granted the shared-mode lock. At this point T may release the lock, but still T has
2 1
to wait for T to finish. But again, there may be a new transaction T that requests a
3 4
shared-modelockonthesamedataitem,andisgrantedthelockbeforeT releasesit.
3
Infact,itispossiblethatthereisasequenceoftransactionsthateachrequestsashared-
modelockonthedataitem,andeachtransactionreleasesthelockashortwhileafterit

--- Page 870 ---

18.1 Lock-BasedProtocols 841
isgranted,butT nevergetstheexclusive-modelockonthedataitem.Thetransaction
1
T maynevermakeprogress,andissaidtobestarved.
1
Wecanavoidstarvationoftransactionsbygrantinglocksinthefollowingmanner:
When a transaction T requests a lock on a data item Q in a particular mode M, the
i
concurrency-controlmanagergrantsthelockprovidedthat:
• ThereisnoothertransactionholdingalockonQinamodethatconflictswithM.
• ThereisnoothertransactionthatiswaitingforalockonQandthatmadeitslock
requestbeforeT.
i
Thus,alockrequestwillnevergetblockedbyalockrequestthatismadelater.
18.1.3 The Two-Phase Locking Protocol
Oneprotocolthatensuresserializabilityisthetwo-phaselockingprotocol.Thisprotocol
requiresthateachtransactionissuelockandunlockrequestsintwophases:
1. Growingphase.Atransactionmayobtainlocks,butmaynotreleaseanylock.
2. Shrinking phase. A transaction may release locks, but may not obtain any new
locks.
Initially,atransactionisinthegrowingphase.Thetransactionacquireslocksasneeded.
Oncethetransactionreleasesalock,itenterstheshrinkingphase,anditcanissueno
morelockrequests.
Forexample,transactionsT andT aretwophase.Ontheotherhand,transactions
3 4
T andT arenottwophase.Notethattheunlockinstructionsdonotneedtoappear
1 2
at the end of the transaction. For example, in the case of transaction T , we could
3
move the unlock(B) instruction to just after the lock-X(A) instruction and still retain
thetwo-phaselockingproperty.
We can show that the two-phase locking protocol ensures conflict serializability.
Consideranytransaction.Thepointintheschedulewherethetransactionhasobtained
itsfinallock(theend ofitsgrowingphase) iscalledthelock point ofthetransaction.
Now, transactions can be ordered according to their lock points—this ordering is, in
fact,aserializabilityorderingforthetransactions.Weleavetheproofasanexercisefor
youtodo(seePracticeExercise18.1).
Two-phaselockingdoesnot ensurefreedomfromdeadlock.Observe thattransac-
tionsT andT aretwophase,but,inschedule2(Figure18.7),theyaredeadlocked.
3 4
RecallfromSection17.7.2that,inadditiontobeingserializable,schedulesshould
be cascadeless. Cascading rollback may occur under two-phase locking. As an illus-
tration, consider the partial schedule of Figure 18.8. Each transaction observes the
two-phaselockingprotocol,butthefailureof T aftertheread(A)step ofT leadsto
5 7
cascadingrollbackofT andT .
6 7

--- Page 871 ---

842 Chapter18 ConcurrencyControl
T T T
5 6 7
lock-X(A)
read(A)
lock-S(B)
read(B)
write(A)
unlock(A)
lock-X(A)
read(A)
write(A)
unlock(A)
lock-S(A)
read(A)
Figure 18.8 Partialscheduleundertwo-phaselocking.
Cascadingrollbackscanbeavoidedbyamodificationoftwo-phaselockingcalled
thestricttwo-phaselockingprotocol.Thisprotocolrequiresnotonlythatlockingbetwo
phase, but also that all exclusive-mode locks taken by a transaction be held until that
transactioncommits.Thisrequirementensuresthatanydatawrittenbyanuncommit-
tedtransactionarelockedinexclusivemodeuntilthetransactioncommits,preventing
anyothertransactionfromreadingthedata.
Another variant of two-phase locking is the rigorous two-phase locking protocol,
whichrequiresthatalllocksbehelduntilthetransactioncommits.Wecaneasilyverify
that, with rigorous two-phase locking, transactions can be serialized in the order in
whichtheycommit.
Consider the following two transactions, for which we have shown only some of
thesignificantreadandwriteoperations:
T : read(a );
8 1
read(a );
2
...
read(a );
n
write(a ).
1
T : read(a );
9 1
read(a );
2
display(a + a ).
1 2
If we employ the two-phase locking protocol, then T must lock a in exclusive
8 1
mode. Therefore, any concurrent execution of both transactions amounts to a serial
execution. Notice, however, that T needs an exclusive lock on a only at the end of
8 1

--- Page 872 ---

18.1 Lock-BasedProtocols 843
T T
8 9
lock-S(a )
1
lock-S(a )
1
lock-S(a )
2
lock-S(a )
2
lock-S(a )
3
lock-S(a )
4
unlock(a )
1
unlock(a )
2
lock-S(a )
n
upgrade(a )
1
Figure 18.9 Incompleteschedulewithalockconversion.
itsexecution,whenitwritesa .Thus,ifT couldinitiallylocka insharedmode,and
1 8 1
then could later change the lock to exclusive mode, we could get more concurrency,
sinceT andT couldaccessa anda simultaneously.
8 9 1 2
Thisobservationleadsustoarefinementofthebasictwo-phaselockingprotocol,
inwhichlockconversionsareallowed.Weshallprovideamechanismforupgradinga
sharedlocktoanexclusivelock,anddowngradinganexclusivelocktoasharedlock.We
denote conversion from shared to exclusive modes by upgrade, and from exclusive to
sharedbydowngrade.Lockconversioncannotbeallowedarbitrarily.Rather,upgrading
cantakeplaceinonlythegrowingphase,whereasdowngradingcantakeplaceinonly
theshrinkingphase.
Returningtoourexample,transactionsT andT canrunconcurrentlyunderthe
8 9
refinedtwo-phaselockingprotocol,asshownintheincompletescheduleofFigure18.9,
whereonlysomeofthelockinginstructionsareshown.
NotethatatransactionattemptingtoupgradealockonanitemQmaybeforced
to wait. This enforced wait occurs if Q is currently locked by another transaction in
sharedmode.
Justlikethebasictwo-phaselockingprotocol,two-phaselockingwithlockconver-
sion generates only conflict-serializable schedules, and transactions can be serialized
bytheirlockpoints.Further,ifexclusivelocksarehelduntiltheendofthetransaction,
theschedulesarecascadeless.
For a set of transactions, there may be conflict-serializable schedules that can-
not be obtained through the two-phase locking protocol. However, to obtain conflict-
serializableschedulesthroughnon-two-phaselockingprotocols,weneedeithertohave
additionalinformationaboutthetransactionsortoimposesomestructureorordering
onthesetofdataitemsinthedatabase.Weshallseeexampleswhenweconsiderother
lockingprotocolslaterinthischapter.
Strict two-phase locking and rigorous two-phase locking (with lock conversions)
areusedextensivelyincommercialdatabasesystems.

--- Page 873 ---

844 Chapter18 ConcurrencyControl
Asimplebutwidelyusedschemeautomaticallygeneratestheappropriatelockand
unlockinstructionsforatransaction,onthebasisofreadandwriterequestsfromthe
transaction:
• When atransaction T issuesaread(Q) operation, thesystem issues alock-S(Q)
i
instructionfollowedbytheread(Q)instruction.
• WhenT issuesawrite(Q)operation,thesystemcheckstoseewhetherT already
i i
holds a shared lock on Q. If it does, then the system issues an upgrade(Q) in-
struction, followed by the write(Q) instruction. Otherwise, the system issues a
lock-X(Q)instruction,followedbythewrite(Q)instruction.
• Alllocksobtainedbyatransactionareunlockedafterthattransactioncommitsor
aborts.
18.1.4 Implementation of Locking
A lock manager can be implemented as a process that receives messages from trans-
actionsandsendsmessagesinreply.Thelock-managerprocessrepliestolock-request
messageswithlock-grantmessages, orwithmessagesrequestingrollbackofthetrans-
action (in case of deadlocks). Unlock messages require only an acknowledgment in
response,butmayresultinagrantmessagetoanotherwaitingtransaction.
The lock manager uses this data structure: For each data item that is currently
locked,itmaintainsalinkedlistofrecords,oneforeachrequest,intheorderinwhich
the requests arrived. Ituses a hash table, indexed on the name of a data item, to find
thelinkedlist(ifany)foradataitem;thistableiscalledthelocktable.Eachrecordof
thelinkedlistforadataitemnoteswhichtransactionmadetherequest,andwhatlock
modeitrequested.Therecordalsonotesiftherequesthascurrentlybeengranted.
Figure 18.10 shows an example of a lock table. The table contains locks for five
different data items, I4, I7, I23, I44, and I912. The lock table uses overflow chaining,
so there is a linked list of data items for each entry in the lock table. There is also a
list of transactions that have been granted locks, or are waiting for locks, for each of
thedataitems.Grantedlocksaretherectanglesfilledinadarkershade,whilewaiting
requestsaretherectanglesfilledinalightershade.Wehaveomittedthelockmodeto
keepthefiguresimple.Itcanbeseen,forexample,thatT23hasbeengrantedlockson
I912andI7andiswaitingforalockonI4.
Althoughthefiguredoesnotshowit,thelocktableshouldalsomaintainanindex
ontransactionidentifierssothatitispossibletodetermineefficientlythesetoflocks
heldbyagiventransaction.
Thelockmanagerprocessesrequeststhisway:
• Whenalockrequestmessagearrives,itaddsarecordtotheendofthelinkedlist
forthedataitem,ifthelinkedlistispresent.Otherwiseitcreatesanewlinkedlist,
containingonlytherecordfortherequest.

--- Page 874 ---

18.1 Lock-BasedProtocols 845
I7 I23
T23 T1 T8 T2
I912
T23
I4
T1 T23
I44
granted
waiting
T8
Figure 18.10 Locktable.
Italwaysgrantsalockrequestonadataitemthatisnotcurrentlylocked.But
if the transaction requests a lock on an item on which a lock is currently held,
thelockmanagergrantstherequestonlyifitiscompatiblewiththelocksthatare
currently held, and all earlier requests have been granted already. Otherwise the
requesthastowait.
• Whenthelockmanagerreceivesanunlockmessagefromatransaction,itdeletes
therecordforthatdataiteminthelinkedlistcorrespondingtothattransaction.It
teststherecordthatfollows,ifany,asdescribedinthepreviousparagraph,tosee
ifthatrequestcannowbegranted.Ifitcan,thelockmanagergrantsthatrequest
andprocessestherecordfollowingit,ifany,similarly,andsoon.
• Ifatransactionaborts,thelockmanagerdeletesanywaitingrequestmadebythe
transaction.Oncethedatabasesystem hastakenappropriateactionstoundothe
transaction(seeSection19.3),itreleasesalllocksheldbytheabortedtransaction.

--- Page 875 ---

846 Chapter18 ConcurrencyControl
This algorithm guarantees freedom from starvation for lock requests, since a re-
quest can never be granted while a request received earlier is waiting to be granted.
We study how to detect and handle deadlocks later, in Section 18.2.2. Section 20.3.1
describesanalternativeimplementation—onethatusessharedmemoryinsteadofmes-
sagepassingforlockrequest/grant.
18.1.5 Graph-Based Protocols
AsnotedinSection18.1.3,ifwewishtodevelopprotocolsthatarenottwophase,we
need additional information on how each transaction will access the database. There
are various models that can give us the additional information, each differing in the
amountofinformationprovided.Thesimplestmodelrequiresthatwehavepriorknowl-
edge about the order in which the database items will be accessed. Given such infor-
mation, it is possible to construct locking protocols that are not two phase, but that,
nevertheless,ensureconflictserializability.
To acquire such prior knowledge, we impose a partial ordering → on the set
D = {d , d ,…,d } of all data items. If d → d, then any transaction accessing both
1 2 h i j
d andd mustaccessd beforeaccessingd.Thispartialorderingmaybetheresultof
i j i j
eitherthelogicalorthephysicalorganizationofthedata,oritmaybeimposedsolely
forthepurposeofconcurrencycontrol.
ThepartialorderingimpliesthatthesetDmaynowbeviewedasadirectedacyclic
graph,calledadatabasegraph.Inthissection,forthesakeofsimplicity,wewillrestrict
our attention to only those graphs that are rooted trees. We shall present a simple
protocol, called the tree protocol, which is restricted to employ only exclusive locks.
References to other, more complex, graph-based locking protocols are in the online
bibliographicalnotes.
Inthe tree protocol,theonlylockinstruction allowedislock-X. Each transaction
T canlockadataitematmostonce,andmustobservethefollowingrules:
i
1. ThefirstlockbyT maybeonanydataitem.
i
2. Subsequently,adataitemQcanbelockedbyT onlyiftheparentofQiscurrently
i
lockedbyT.
i
3. Dataitemsmaybeunlockedatanytime.
4. A data item that has been locked and unlocked by T cannot subsequently be
i
relockedbyT.
i
Allschedulesthatarelegalunderthetreeprotocolareconflictserializable.
Toillustratethisprotocol,considerthedatabasegraphofFigure18.11.Thefollow-
ingfourtransactionsfollowthetreeprotocolonthisgraph.Weshowonlythelockand
unlockinstructions:

--- Page 876 ---

18.1 Lock-BasedProtocols 847
A
B C
F
D
E
G H
I
J
Figure 18.11 Tree-structureddatabasegraph.
T : lock-X(B);lock-X(E);lock-X(D);unlock(B);unlock(E);lock-X(G);
10
unlock(D);unlock(G).
T : lock-X(D);lock-X(H);unlock(D);unlock(H).
11
T : lock-X(B);lock-X(E);unlock(E);unlock(B).
12
T : lock-X(D);lock-X(H);unlock(D);unlock(H).
13
One possible schedule in which these four transactions participated appears in
Figure18.12.Notethat,duringitsexecution,transactionT holdslocksontwodisjoint
10
subtrees.
ObservethatthescheduleofFigure18.12isconflictserializable.Itcanbeshown
notonlythatthetreeprotocolensuresconflictserializability,butalsothatthisprotocol
ensuresfreedomfromdeadlock.
The tree protocol in Figure 18.12 does not ensure recoverability and cascadeless-
ness. To ensure recoverability and cascadelessness, the protocol can be modified to
not permit release of exclusive locks until the end of the transaction. Holding exclu-
sivelocksuntiltheendofthetransactionreducesconcurrency.Hereisanalternative
that improves concurrency, but ensures only recoverability: For each data item with
an uncommitted write, we record which transaction performed the last write to the
data item. Whenever a transaction T performs a read of an uncommitted data item,
i
werecordacommitdependency ofT onthetransaction thatperformedthelastwrite
i
tothedataitem.TransactionT isthennotpermittedtocommituntilthecommitofall
i
transactionsonwhichithasacommitdependency.Ifanyofthesetransactionsaborts,
T mustalsobeaborted.
i

--- Page 877 ---

848 Chapter18 ConcurrencyControl
T T T T
10 11 12 13
lock-X(B)
lock-X(D)
lock-X(H)
unlock(D)
lock-X(E)
lock-X(D)
unlock(B)
unlock(E)
lock-X(B)
lock-X(E)
unlock(H)
lock-X(G)
unlock(D)
lock-X(D)
lock-X(H)
unlock(D)
unlock(H)
unlock(E)
unlock(B)
unlock(G)
Figure 18.12 Serializablescheduleunderthetreeprotocol.
The tree-locking protocol has an advantage over the two-phase locking protocol
inthat,unliketwo-phaselocking,itisdeadlock-free,sonorollbacksarerequired.The
tree-lockingprotocolhasanotheradvantageoverthetwo-phaselockingprotocolinthat
unlocking may occur earlier. Earlier unlocking may lead to shorter waiting times and
toanincreaseinconcurrency.
However,theprotocolhasthedisadvantagethat,insomecases,atransactionmay
have to lockdataitemsthatitdoes notaccess. Forexample, atransaction thatneeds
toaccessdataitemsAandJ inthedatabasegraphofFigure18.11mustlocknotonly
A and J, but also data items B, D, and H. This additional lockingresults in increased
locking overhead, the possibility of additional waiting time, and a potential decrease
in concurrency. Further, without prior knowledge of what data items will need to be
locked,transactionswillhavetolocktherootofthetree,andthatcanreduceconcur-
rencygreatly.
For a set of transactions, there may be conflict-serializableschedulesthat cannot
beobtainedthroughthetreeprotocol.Indeed,thereareschedulespossibleunderthe
two-phaselockingprotocolthatarenotpossibleunderthetreeprotocol,andviceversa.
Examplesofsuchschedulesareexploredintheexercises.

--- Page 878 ---

18.2 DeadlockHandling 849
18.2 Deadlock Handling
A system is in a deadlock state if there exists a set of transactions such that every
transactioninthesetiswaitingforanothertransactionintheset.Moreprecisely,there
exists a set of waiting transactions {T , T ,…,T } such that T is waiting for a data
0 1 n 0
item that T holds, and T is waiting for a data item that T holds, and … , and T
1 1 2 n−1
iswaitingforadataitemthatT holds,andT iswaitingforadataitemthatT holds.
n n 0
Noneofthetransactionscanmakeprogressinsuchasituation.
The only remedy to this undesirable situation is for the system to invoke some
drasticaction,suchasrollingbacksomeofthetransactionsinvolvedinthedeadlock.
Rollbackof a transaction may be partial: That is, atransaction may be rolled back to
thepointwhereitobtainedalockwhosereleaseresolvesthedeadlock.
There are two principal methods for dealing with the deadlock problem. We can
useadeadlockpreventionprotocoltoensurethatthesystemwillneverenteradeadlock
state.Alternatively,wecanallowthesystem toenteradeadlockstate,andthentryto
recover by using a deadlock detection and deadlock recovery scheme. As we shall see,
both methods may result in transaction rollback. Prevention is commonly used if the
probability that the system would enter a deadlock state is relatively high; otherwise,
detectionandrecoveryaremoreefficient.
Note that a detection and recovery scheme requires overhead that includes not
onlythe run-time cost of maintainingthe necessaryinformationand ofexecutingthe
detectionalgorithm,butalsothepotentiallossesinherentinrecoveryfromadeadlock.
18.2.1 Deadlock Prevention
Therearetwoapproachestodeadlockprevention.Oneapproachensuresthatnocyclic
waitscanoccurbyorderingtherequestsforlocks,orrequiringalllockstobeacquired
together.Theotherapproachisclosertodeadlockrecovery,anditperformstransaction
rollback instead of waiting for a lock whenever the wait could potentially result in a
deadlock.
Thesimplestschemeunderthefirstapproachrequiresthateachtransactionlocks
allitsdataitemsbeforeitbeginsexecution.Moreover,eitherallarelockedinonestep
or none are locked. There are two main disadvantages to this protocol: (1) it is often
hard topredict,before the transaction begins, whatdata itemsneed to be locked; (2)
data-itemutilizationmaybeverylow,sincemanyofthedataitemsmaybelockedbut
unusedforalongtime.
Another approach for preventing deadlocks is to impose an ordering of all data
items and to require that a transaction lock data items only in a sequence consistent
with the ordering. We have seen one such scheme in the tree protocol, which uses a
partialorderingofdataitems.
Avariationofthisapproachistouseatotalorderofdataitems,inconjunctionwith
two-phase locking. Once a transaction has locked a particular item, it cannot request
locksonitemsthatprecedethatitemintheordering.Thisschemeiseasytoimplement,

--- Page 879 ---

850 Chapter18 ConcurrencyControl
aslongasthesetofdataitemsaccessedbyatransactionisknownwhenthetransaction
startsexecution.Thereisnoneedtochangetheunderlyingconcurrency-controlsystem
iftwo-phaselockingisused:Allthatisneededistoensurethatlocksarerequestedin
therightorder.
The second approach for preventing deadlocks is to use preemption and transac-
tion rollbacks. In preemption, when a transaction T requests a lock that transaction
j
T holds, the lock granted to T may be preempted by rolling back of T, and granting
i i i
of thelocktoT. Tocontrol thepreemption,weassign aunique timestamp, based on
j
acounteroronthesystemclock,toeachtransactionwhenitbegins.Thesystemuses
thesetimestampsonlytodecidewhetheratransactionshouldwaitorrollback.Lock-
ing is still used for concurrency control. If a transaction is rolled back, it retains its
oldtimestampwhenrestarted.Twodifferentdeadlock-preventionschemesusingtimes-
tampshavebeenproposed:
1. Thewait–dieschemeisanonpreemptivetechnique.WhentransactionT requests
i
a data item currentlyheld by T, T is allowed to wait only if it has a timestamp
j i
smallerthanthatofT (i.e.,T isolderthanT).Otherwise,T isrolledback(dies).
j i j i
Forexample,supposethattransactionsT ,T ,andT havetimestamps5,
14 15 16
10,and15,respectively.IfT requestsadataitemheldbyT ,thenT willwait.
14 15 14
IfT requestsadataitemheldbyT ,thenT willberolledback.
16 15 16
2. Thewound–waitschemeisapreemptivetechnique.Itisacounterparttothewait–
diescheme.WhentransactionT requestsadataitemcurrentlyheldbyT,T is
i j i
allowedtowaitonlyifithasatimestamplargerthanthatofT (i.e.,T isyounger
j i
thanT).Otherwise,T isrolledback(T iswounded byT).
j j j i
Returningtoourexample,withtransactionsT ,T ,andT ,ifT requests
14 15 16 14
adataitemheldbyT ,thenthedataitemwillbepreemptedfromT ,andT
15 15 15
willberolledback.IfT requestsadataitemheldbyT ,thenT willwait.
16 15 16
Themajorproblemwithbothoftheseschemesisthatunnecessaryrollbacksmay
occur.
Anothersimpleapproachtodeadlockpreventionisbasedonlocktimeouts.Inthis
approach,atransactionthathasrequestedalockwaitsforatmostaspecifiedamount
oftime.Ifthelockhasnotbeengrantedwithinthattime,thetransactionissaidtotime
out, and it rolls itself back and restarts. If there was in fact a deadlock, one or more
transactionsinvolvedinthedeadlockwilltimeoutandrollback,allowingtheothersto
proceed.Thisschemefallssomewherebetweendeadlockprevention,whereadeadlock
willneveroccur,anddeadlockdetectionandrecovery,whichSection18.2.2discusses.
Thetimeoutschemeisparticularlyeasytoimplement,anditworkswelliftransac-
tionsareshortandiflongwaitsarelikelytobeduetodeadlocks.However,ingeneral
itishardtodecidehowlongatransactionmustwaitbeforetimingout.Toolongawait
results in unnecessary delays once a deadlock has occurred. Too short a wait results
in transaction rollback even when there is no deadlock, leading to wasted resources.

--- Page 880 ---

18.2 DeadlockHandling 851
Starvationisalsoapossibilitywiththisscheme.Hence,thetimeout-basedschemehas
limitedapplicability.
18.2.2 Deadlock Detection and Recovery
If a system does not employ some protocol that ensures deadlock freedom, then a
detection and recovery scheme must be used. An algorithm that examines the state
of the system is invoked periodically to determine whether a deadlock has occurred.
If one has, then the system must attempt to recoverfrom the deadlock. Todo so, the
systemmust:
• Maintain information about the current allocation of data items to transactions,
aswellasanyoutstandingdataitemrequests.
• Provideanalgorithmthatusesthisinformationtodeterminewhetherthesystem
hasenteredadeadlockstate.
• Recoverfromthedeadlockwhenthedetectionalgorithmdeterminesthatadead-
lockexists.
Inthissection,weelaborateontheseissues.
18.2.2.1 DeadlockDetection
Deadlocks can be described precisely in terms of a directed graph called a wait-for
graph. This graph consists of a pair G = (V, E), where V is a set of vertices and E is
a set of edges. The set of vertices consists of all the transactions in the system. Each
elementinthesetEofedgesisanorderedpairT → T.IfT → T isinE,thenthere
i j i j
isadirectededgefromtransactionT toT,implyingthattransactionT iswaitingfor
i j i
transactionT toreleaseadataitemthatitneeds.
j
When transaction T requests a data item currently being held by transaction T,
i j
then the edge T → T is inserted in the wait-for graph. This edge is removed only
i j
whentransactionT isnolongerholdingadataitemneededbytransactionT.
j i
A deadlock exists in the system if and only if the wait-for graph contains a cycle.
Eachtransactioninvolvedinthecycleissaidtobedeadlocked.Todetectdeadlocks,the
system needs to maintain the wait-for graph, and periodically to invoke an algorithm
thatsearchesforacycleinthegraph.
To illustrate these concepts, consider the wait-for graph in Figure 18.13, which
depictsthefollowingsituation:
• TransactionT iswaitingfortransactionsT andT .
17 18 19
• TransactionT iswaitingfortransactionT .
19 18
• TransactionT iswaitingfortransactionT .
18 20

--- Page 881 ---

852 Chapter18 ConcurrencyControl
T T
18 20
T
17
T
19
Figure 18.13 Wait-forgraphwithnocycle.
Sincethegraphhasnocycle,thesystemisnotinadeadlockstate.
SupposenowthattransactionT isrequestinganitemheldbyT .TheedgeT →
20 19 20
T isaddedtothewait-forgraph,resultinginthenewsystemstateinFigure18.14.This
19
time,thegraphcontainsthecycle:
T →T →T →T
18 20 19 18
implyingthattransactionsT ,T ,andT arealldeadlocked.
18 19 20
Consequently, the question arises: When should we invoke the detection algo-
rithm?Theanswerdependsontwofactors:
1. Howoftendoesadeadlockoccur?
2. Howmanytransactionswillbeaffectedbythedeadlock?
Ifdeadlocksoccurfrequently,thenthedetectionalgorithmshouldbeinvokedmore
frequently.Dataitemsallocatedtodeadlockedtransactionswillbeunavailabletoother
transactionsuntilthedeadlockcanbebroken.Inaddition,thenumberofcyclesinthe
graphmayalsogrow.Intheworstcase,wewouldinvokethedetectionalgorithmevery
timearequestforallocationcouldnotbegrantedimmediately.
T T
18 20
T
17
T
19
Figure 18.14 Wait-forgraphwithacycle.

--- Page 882 ---

18.3 MultipleGranularity 853
18.2.2.2 RecoveryfromDeadlock
Whenadetectionalgorithmdeterminesthatadeadlockexists,thesystemmustrecover
fromthedeadlock.Themostcommonsolutionistorollbackoneormoretransactions
tobreakthedeadlock.Threeactionsneedtobetaken:
1. Selectionofavictim.Givenasetofdeadlockedtransactions,wemustdetermine
whichtransaction(ortransactions)torollbacktobreakthedeadlock.Weshould
rollbackthosetransactionsthatwillincurtheminimumcost.Unfortunately,the
termminimumcostisnotapreciseone.Manyfactorsmaydeterminethecostof
arollback,including:
a. How long the transaction has computed, and how much longer the trans-
actionwillcomputebeforeitcompletesitsdesignatedtask.
b. Howmanydataitemsthetransactionhasused.
c. Howmanymoredataitemsthetransactionneedsforittocomplete.
d. Howmanytransactionswillbeinvolvedintherollback.
2. Rollback.Oncewehavedecidedthataparticulartransactionmustberolledback,
wemustdeterminehowfarthistransactionshouldberolledback.
Thesimplestsolutionisatotalrollback:Abortthetransactionandthenrestart
it.However,itismoreeffectivetorollbackthetransactiononlyasfarasnecessary
tobreakthedeadlock.Suchpartialrollback requiresthesystem tomaintainad-
ditionalinformationaboutthestateofalltherunningtransactions.Specifically,
the sequence of lock requests/grants and updates performed by the transaction
needs to be recorded. The deadlock detection mechanism should decide which
lockstheselectedtransactionneedstoreleaseinordertobreakthedeadlock.The
selected transaction must be rolledbackto the point whereitobtained the first
of these locks, undoing all actions it took after that point. The recovery mech-
anism must be capable of performing such partial rollbacks. Furthermore, the
transactionsmustbecapableofresumingexecutionafterapartialrollback.See
theonlinebibliographicalnotesforrelevantreferences.
3. Starvation.Inasystemwheretheselectionofvictimsisbasedprimarilyoncost
factors, it may happen that the same transaction is always picked as a victim.
As a result, this transaction never completes its designated task, thus there is
starvation. We must ensure that a transaction can be picked as a victim only
a (small) finite number of times. The most common solution is to include the
numberofrollbacksinthecostfactor.
18.3 Multiple Granularity
In the concurrency-control schemes described thus far, we have used each individual
dataitemastheunitonwhichsynchronizationisperformed.

--- Page 883 ---

854 Chapter18 ConcurrencyControl
Therearecircumstances,however,whereitwouldbeadvantageoustogroupseveral
dataitems,andtotreatthemasoneindividualsynchronizationunit.Forexample,ifa
transactionT needstoaccessanentirerelation,andalockingprotocolisusedtolock
i
tuples,thenT mustlockeachtupleintherelation.Clearly,acquiringmanysuchlocks
i
istime-consuming;evenworse,thelocktablemaybecomeverylargeandnolongerfit
in memory. Itwould be better if T could issue a single lockrequest tolock the entire
i
relation.Ontheotherhand,iftransactionT needstoaccessonlyafewtuples,itshould
j
notberequiredtolocktheentirerelation,sinceotherwiseconcurrencyislost.
What is needed is a mechanism to allow the system to define multiple levels of
granularity. This is done by allowing data items to be of various sizes and defining a
hierarchy of data granularities, where the small granularities are nested within larger
ones.Suchahierarchycanberepresentedgraphicallyasatree.Notethatthetreethat
wedescribehereissignificantlydifferentfromthatusedbythetreeprotocol(Section
18.1.5).Anonleafnodeofthemultiple-granularitytreerepresentsthedataassociated
withitsdescendants.Inthetreeprotocol,eachnodeisanindependentdataitem.
As an illustration, consider the tree of Figure 18.15, which consists of four levels
of nodes. The highest level represents the entire database. Below it are nodes of type
area;thedatabaseconsistsofexactlytheseareas.Eachareainturnhasnodesoftype
fileasitschildren.Eachareacontainsexactlythosefilesthatareitschildnodes.Nofile
isinmorethanonearea.Finally,eachfilehasnodesoftyperecord.Asbefore,thefile
consistsofexactlythoserecordsthatareitschildnodes,andnorecordcanbepresent
inmorethanonefile.
Eachnodeinthetreecanbelockedindividually.Aswedidinthetwo-phaselocking
protocol, we shall use shared and exclusive lock modes. When a transaction locks a
node,ineithersharedorexclusivemode,thetransactionalsohasimplicitlylockedall
the descendants of that node in the same lock mode. For example, if transaction T
i
getsanexplicitlockonfileF ofFigure18.15,inexclusivemode,thenithasanimplicit
c
DB
A A
1 2
F F F
a b c
. . . . . . . . .
r r r r r r r
a1 a2 an b1 bk c1 cm
Figure 18.15 Granularityhierarchy.

--- Page 884 ---

18.3 MultipleGranularity 855
lockinexclusivemodeonalltherecordsbelongingtothatfile.Itdoesnotneedtolock
theindividualrecordsofF explicitly.
c
SupposethattransactionT wishestolockrecordr offileF .SinceT haslocked
j b b i
6
F explicitly, it follows that r is also locked (implicitly). But, when T issues a lock
b b j
6
requestforr ,r isnotexplicitlylocked!HowdoesthesystemdeterminewhetherT
b b j
6 6
can lock r ? T must traverse the tree from the root to record r . If any node in that
b j b
6 6
pathislockedinanincompatiblemode,thenT mustbedelayed.
j
Suppose now that transaction T wishes to lock the entire database. To do so, it
k
simplymustlocktherootofthehierarchy.Note,however,thatT shouldnotsucceed
k
inlockingtherootnode,sinceT iscurrentlyholdingalockonpartofthetree(specifi-
i
cally,onfileF ).Buthowdoesthesystemdetermineiftherootnodecanbelocked?One
b
possibility is for it to search the entire tree. This solution, however, defeats the whole
purpose of the multiple-granularity lockingscheme.A more efficientway to gain this
knowledgeistointroduceanewclassoflockmodes,calledintention lockmodes.Ifa
nodeislockedinanintentionmode,explicitlockingisdoneatalowerlevelofthetree
(that is, at a finer granularity). Intention locks are put on all the ancestors of a node
before that node is locked explicitly. Thus, a transaction does not need to search the
entire tree to determine whether it can lock a node successfully. A transaction wish-
ing to lock a node—say, Q—must traverse a path in the tree from the root to Q. While
traversingthetree,thetransactionlocksthevariousnodesinanintentionmode.
There is an intention mode associated with shared mode, and there is one with
exclusive mode. If a node is locked in intention-shared (IS) mode, explicit locking is
being done at a lower level of the tree, but with only shared-mode locks. Similarly, if
a node is locked in intention-exclusive (IX) mode, then explicit locking is being done
atalowerlevel,withexclusive-modeorshared-modelocks.Finally,ifanodeislocked
insharedandintention-exclusive(SIX)mode,thesubtreerootedbythatnodeislocked
explicitlyinsharedmode,andthatexplicitlockingisbeingdoneatalowerlevelwith
exclusive-mode locks. The compatibility function for these lock modes is shown in
Figure18.16.
IS IX S SIX X
IS true true true true false
IX true true false false false
S true false true false false
SIX true false false false false
X false false false false false
Figure 18.16 Compatibilitymatrix.

--- Page 885 ---

856 Chapter18 ConcurrencyControl
Themultiple-granularitylockingprotocolusestheselockmodestoensureserializ-
ability.ItrequiresthatatransactionT thatattemptstolockanodeQmustfollowthese
i
rules:
• TransactionT mustobservethelock-compatibilityfunctionofFigure18.16.
i
• TransactionT mustlocktherootofthetreefirstandcanlockitinanymode.
i
• TransactionT canlockanodeQinSorISmodeonlyifT currentlyhastheparent
i i
ofQlockedineitherIXorISmode.
• TransactionT canlockanodeQinX,SIX,orIXmodeonlyifT currentlyhasthe
i i
parentofQlockedineitherIXorSIXmode.
• Transaction T can lock a node only if T has not previously unlocked any node
i i
(i.e.,T istwophase).
i
• Transaction T can unlock anode Q onlyif T currentlyhas none of the children
i i
ofQlocked.
Observe that the multiple-granularity protocol requires that locks be acquired in top-
down (root-to-leaf) order, whereas locks must be released in bottom-up (leaf-to-root)
order.Deadlockispossibleinthemultiple-granularityprotocol,asitisinthetwo-phase
lockingprotocol.
Asanillustrationoftheprotocol,considerthetreeofFigure18.15andthesetrans-
actions:
• Suppose that transaction T reads record r in file F . Then, T needs to lock
21 a a 21
2
thedatabase,areaA ,andF inISmode(andinthatorder),andfinallytolockr
1 a a
2
inSmode.
• SupposethattransactionT modifiesrecordr infileF .Then,T needstolock
22 a a 22
9
thedatabase,areaA ,andfileF (andinthatorder)inIXmode,andfinallytolock
1 a
r inXmode.
a
9
• Suppose that transaction T reads all the records in file F . Then, T needs to
23 a 23
lock the database and area A (and in that order) in IS mode, and finally to lock
1
F inSmode.
a
• Suppose thattransactionT readstheentiredatabase.Itcandosoafterlocking
24
thedatabaseinSmode.
WenotethattransactionsT ,T ,andT canaccessthedatabaseconcurrently.Trans-
21 23 24
actionT canexecuteconcurrentlywithT ,butnotwitheitherT orT .
22 21 23 24
Thisprotocolenhancesconcurrencyand reduceslockoverhead.Itisparticularly
usefulinapplicationsthatincludeamixof:
• Shorttransactionsthataccessonlyafewdataitems.
• Longtransactionsthatproducereportsfromanentirefileorsetoffiles.

--- Page 886 ---

18.4 InsertOperations,DeleteOperations,andPredicateReads 857
The number of locks that an SQL query may need to acquire can usually be esti-
matedbasedontherelationscanoperationsperformedbyaquery.Arelationscan,for
example,wouldacquirealockatarelationlevel,whileanindexscanthatisexpectedto
fetchonlyafewrecordsmayacquireanintentionlockattherelationlevelandregular
locksatthetuplelevel.Incasetheatransactionacquiresalargenumberoftuplelocks,
thelocktablemaybecomeoverfull.Todealwiththissituation,thelockmanagermay
performlockescalation,replacingmanylowerlevellocksbyasinglehigherlevellock;
inourexample,asinglerelationlockcouldreplacealargenumberoftuplelocks.
18.4 Insert Operations, Delete Operations, and Predicate Reads
Untilnow,wehaverestrictedourattentiontoreadandwriteoperations.Thisrestric-
tionlimitstransactionstodataitemsalreadyinthedatabase.Sometransactionsrequire
notonlyaccesstoexistingdataitems,butalsotheabilitytocreatenewdataitems.Oth-
ers require the ability to delete data items. To examine how such transactions affect
concurrencycontrol,weintroducetheseadditionaloperations:
• delete(Q)deletesdataitemQfromthedatabase.
• insert(Q)insertsanewdataitemQintothedatabaseandassignsQaninitialvalue.
AnattemptbyatransactionT toperformaread(Q)operationafterQhasbeendeleted
i
results in a logical error in T. Likewise, an attempt by a transaction T to perform a
i i
read(Q)operationbeforeQhasbeeninsertedresultsinalogicalerrorinT.Itisalso
i
alogicalerrortoattempttodeleteanonexistentdataitem.
18.4.1 Deletion
Tounderstandhowthepresenceofdeleteinstructionsaffectsconcurrencycontrol,we
must decide when a delete instruction conflicts with another instruction. Let I and
i
I be instructions of T and T, respectively, that appear in schedule S in consecutive
j i j
order.LetI =delete(Q).WeconsiderseveralinstructionsI.
i j
• I =read(Q).I andI conflict.IfI comesbeforeI,T willhavealogicalerror.If
j i j i j j
I comesbeforeI,T canexecutethereadoperationsuccessfully.
j i j
• I =write(Q).I andI conflict.IfI comesbeforeI,T willhavealogicalerror.If
j i j i j j
I comesbeforeI,T canexecutethewriteoperationsuccessfully.
j i j
• I =delete(Q).I andI conflict.IfI comesbeforeI,T willhavealogicalerror.If
j i j i j j
I comesbeforeI,T willhavealogicalerror.
j i i
• I = insert(Q). I and I conflict. Suppose that data item Q did not exist prior to
j i j
theexecutionofI andI.Then,ifI comesbeforeI,alogicalerrorresultsforT.
i j i j i

--- Page 887 ---

858 Chapter18 ConcurrencyControl
If I comes before I, then no logical error results. Likewise, if Q existed prior to
j i
theexecutionofI andI,thenalogicalerrorresultsifI comesbeforeI,butnot
i j j i
otherwise.
Wecanconcludethefollowing:
• Underthetwo-phaselockingprotocol,anexclusivelockisrequiredonadataitem
beforethatitemcanbedeleted.
• Underthetimestamp-orderingprotocol,atest similartothatforawritemust be
performed.SupposethattransactionT issuesdelete(Q).
i
° If TS(T) < R-timestamp(Q), then the value of Q that T was to delete has al-
i i
ready been read by a transaction T with TS(T) > TS(T). Hence, the delete
j j i
operationisrejected,andT isrolledback.
i
° If TS(T) < W-timestamp(Q), then a transaction T withTS(T) > TS(T) has
i j j i
writtenQ.Hence,thisdeleteoperationisrejected,andT isrolledback.
i
° Otherwise,thedeleteisexecuted.
18.4.2 Insertion
Wehavealreadyseenthataninsert(Q)operationconflictswithadelete(Q)operation.
Similarly, insert(Q) conflicts with a read(Q) operation or a write(Q) operation; no
readorwritecanbeperformedonadataitembeforeitexists.
Sinceaninsert(Q)assignsavaluetodataitemQ,aninsertistreatedsimilarlytoa
writeforconcurrency-controlpurposes:
• Underthetwo-phaselockingprotocol,ifT performsaninsert(Q)operation,T is
i i
givenanexclusivelockonthenewlycreateddataitemQ.
• Underthetimestamp-orderingprotocol,ifT performsaninsert(Q)operation,the
i
valuesR-timestamp(Q)andW-timestamp(Q)aresettoTS(T).
i
18.4.3 Predicate Reads and The Phantom Phenomenon
Consider transaction T that executes the following SQL query on the university
30
database:
selectcount(*)
frominstructor
wheredept name='Physics';
TransactionT requiresaccesstoalltuplesoftheinstructorrelationpertainingtothe
30
Physicsdepartment.

--- Page 888 ---

18.4 InsertOperations,DeleteOperations,andPredicateReads 859
LetT beatransactionthatexecutesthefollowingSQLinsertion:
31
insertintoinstructor
values(11111,'Feynman','Physics',94000);
Let S be a schedule involving T and T . We expect there to be potential for a
30 31
conflictforthefollowingreasons:
• IfT usesthetuplenewlyinsertedbyT incomputingcount(*), thenT reads
30 31 30
a value written by T . Thus, in a serial schedule equivalent to S, T must come
31 31
beforeT .
30
• IfT doesnotusethetuplenewlyinsertedbyT incomputingcount(*),thenin
30 31
aserialscheduleequivalenttoS,T mustcomebeforeT .
30 31
Thesecondofthesetwocasesiscurious.T andT donotaccessanytupleincom-
30 31
mon, yet they conflict with each other! In effect, T and T conflict on a phantom
30 31
tuple.Ifconcurrencycontrolisperformedatthetuplegranularity,thisconflictwould
goundetected.Asaresult,thesystemcouldfailtopreventanonserializableschedule.
Thisproblemisaninstanceofthephantomphenomenon.
Phantomphenomenacanoccurnotjustwithinserts,butalsowithupdates.Con-
sider the situation we saw in Section 17.10, where a transaction T used an index to
i
find only tuples with dept name = “Physics”, and as a result did not read any tuples
with other department names. If another transaction T updates one of these tuples,
j
changingitsdepartmentnametoPhysics,aproblemsimilartotheaboveproblemoc-
curs:eventhoughT andT havenotaccessedanytuplesincommon,theydoconflict
i j
witheachother.Thisproblemtooisaninstanceofthephantomphenomenon.Ingen-
eral, the phantom phenomenon is rooted in predicate reads that conflict with inserts
orupdatesthatresultinnew/updatedtuplesthatsatisfythepredicate.
WecanpreventtheseproblemsbyallowingtransactionT topreventothertrans-
30
actionsfromcreatingnewtuplesintheinstructorrelationwithdept name=“Physics”,
andfromupdatingthedepartmentnameofanexistinginstructor tupletoPhysics.
Tofindallinstructortupleswithdept name=“Physics”,T mustsearcheitherthe
30
whole instructor relation, or at least an index on the relation. Up to now, we have as-
sumedimplicitlythattheonlydataitemsaccessedbyatransactionaretuples.However,
T is an example of a transaction that reads information about what tuples are in a
30
relation,andT isanexampleofatransactionthatupdatesthatinformation.
31
Clearly,itisnotsufficientmerelytolockthetuplesthatareaccessed;theinforma-
tionusedtofindthetuplesthatareaccessedbythetransactionmustalsobelocked.
Locking of information used to find tuples can be implemented by associating a
data item with the relation; the data item represents the information used to find the
tuplesintherelation.Transactions,suchasT ,thatreadtheinformationaboutwhat
30
tuples are in a relation would then have to lock the data item corresponding to the

--- Page 889 ---

860 Chapter18 ConcurrencyControl
relationinsharedmode.Transactions,suchasT ,thatupdatetheinformationabout
31
whattuplesareinarelationwouldhavetolockthedataiteminexclusivemode.Thus,
T and T would conflict on a real data item, rather than on a phantom. Similarly,
30 31
transactionsthatuseanindextoretrievetuplesmustlocktheindexitself.
Donotconfusethelockingofanentirerelation,asinmultiple-granularitylocking,
withthelockingofthedataitemcorrespondingtotherelation.Bylockingthedataitem,
a transaction only preventsothertransactions from updating information about what
tuplesareintherelation.Lockingisstillrequiredontuples.Atransactionthatdirectly
accessesatuplecanbegrantedalockonthetuplesevenwhenanothertransactionhas
anexclusivelockonthedataitemcorrespondingtotherelationitself.
The major disadvantage of locking a data item corresponding to the relation, or
lockinganentireindex,isthelowdegreeofconcurrency—twotransactionsthatinsert
differenttuplesintoarelationarepreventedfromexecutingconcurrently.
Abettersolutionisanindex-lockingtechniquethatavoidslockingthewholeindex.
Anytransactionthatinsertsatupleintoarelationmust insertinformationintoevery
indexmaintainedontherelation.Weeliminatethephantomphenomenonbyimposing
alockingprotocolforindices.ForsimplicityweshallconsideronlyB+-treeindices.
As we saw in Chapter 14, every search-key value is associated with an index leaf
node. A query will usually use one or more indices to access a relation. An insert
must insert the new tuple in all indices on the relation. In our example, we assume
thatthereisanindexoninstructor forattributedept name.Then,T mustmodifythe
31
leaf containing the key “Physics”. If T reads the same leaf node to locate all tuples
30
pertainingtothePhysicsdepartment,thenT andT conflictonthatleafnode.
30 31
The index-locking protocoltakes advantage of the availability of indiceson a rela-
tion,byturninginstancesofthephantomphenomenonintoconflictsonlocksonindex
leafnodes.Theprotocoloperatesasfollows:
• Everyrelationmusthaveatleastoneindex.
• AtransactionT canaccesstuplesofarelationonlyafterfirstfindingthemthrough
i
one or more of the indices on the relation. For the purpose of the index-locking
protocol, a relation scan is treated as a scan through all the leaves of one of the
indices.
• A transaction T that performs a lookup (whether a range lookup or a point
i
lookup)mustacquireasharedlockonalltheindexleafnodesthatitaccesses.
• AtransactionT maynotinsert,delete,orupdateatuplet inarelationr without
i i
updatingallindicesonr.Thetransactionmustobtainexclusivelocksonallindex
leaf nodes that are affected by the insertion, deletion, or update. For insertion
and deletion, the leaf nodes affected are those that contain (after insertion) or
contained(beforedeletion)thesearch-keyvalueofthetuple.Forupdates,theleaf
nodesaffectedarethosethat(beforethemodification)containedtheoldvalueof
the search key, and nodes that (after the modification) contain the new value of
thesearchkey.

--- Page 890 ---

18.5 Timestamp-BasedProtocols 861
• Locksareobtainedontuplesasusual.
• Therulesofthetwo-phaselockingprotocolmustbeobserved.
Notethattheindex-lockingprotocoldoesnotaddressconcurrencycontroloninter-
nalnodesofanindex;techniquesforconcurrencycontrolonindices,whichminimize
lockconflicts,arepresentedinSection18.10.2.
Locking an index leaf node prevents any update to the node, even if the update
did not actually conflict with the predicate. A variant called key-value locking, which
minimizes such false lock conflicts, is presented in Section 18.10.2 as part of index
concurrencycontrol.
AsnotedinSection17.10,itwouldappearthattheexistenceofaconflictbetween
transactions depends on a low-level query-processing decision by the system that is
unrelated to a user-level view of the meaning of the two transactions. An alternative
approachtoconcurrencycontrolacquiressharedlocksonpredicatesinaquery,such
asthepredicate“salary>90000”ontheinstructor relation.Insertsanddeletesofthe
relationmustthenbecheckedtoseeiftheysatisfythepredicate;iftheydo,thereisa
lockconflict,forcingtheinsertordeletetowaittillthepredicatelockisreleased.For
updates,boththeinitialvalueandthefinalvalueofthetuplemustbecheckedagainst
thepredicate.Suchconflictinginserts,deletes,andupdatesaffectthesetoftuplesse-
lected by the predicate, and they cannot be allowed to execute concurrently with the
query that acquired the (shared) predicate lock. We call this protocol predicate lock-
ing;1 predicatelockingisnotusedinpracticesinceitismoreexpensivetoimplement
thantheindex-lockingprotocolanddoesnotgivesignificantadditionalbenefits.
18.5 Timestamp-Based Protocols
Thelockingprotocolsthatwehavedescribedthusfardeterminetheorderbetweenev-
erypairofconflictingtransactionsatexecutiontimebythefirstlockthatbothmembers
ofthepairrequestthatinvolvesincompatiblemodes.Anothermethodfordetermining
the serializability order is to select an ordering among transactions in advance. The
mostcommonmethodfordoingsoistouseatimestamp-orderingscheme.
18.5.1 Timestamps
WitheachtransactionT inthesystem,weassociateauniquefixedtimestamp,denoted
i
by TS(T). This timestamp is assigned by the database system before the transaction
i
T startsexecution.IfatransactionT hasbeenassignedtimestampTS(T),andanew
i i i
transactionT entersthesystem,thenTS(T)<TS(T).Therearetwosimplemethods
j i j
forimplementingthisscheme:
1Thetermpredicatelockingwasusedforaversionoftheprotocolthatusedsharedandexclusivelocksonpredicates,
andwasthusmorecomplicated.Theversionwepresenthere,withonlysharedlocksonpredicates,isalsoreferredto
asprecisionlocking.

--- Page 891 ---

862 Chapter18 ConcurrencyControl
1. Usethevalueofthesystemclockasthetimestamp;thatis,atransaction’stime-
stampisequaltothevalueoftheclockwhenthetransactionentersthesystem.
2. Use a logical counter that is incremented after a new timestamp has been as-
signed; that is, a transaction’s timestamp is equal to the value of the counter
whenthetransactionentersthesystem.
The timestamps of the transactions determine the serializability order. Thus, if
TS(T)<TS(T),thenthesystemmustensurethattheproducedscheduleisequivalent
i j
toaserialscheduleinwhichtransactionT appearsbeforetransactionT.
i j
To implement this scheme, we associate with each data item Q two timestamp
values:
1. W-timestamp(Q)denotesthelargesttimestampofanytransactionthatexecuted
write(Q)successfully.
2. R-timestamp(Q) denotes the largest timestamp of any transaction that executed
read(Q)successfully.
These timestamps are updated whenever a new read(Q) or write(Q) instruction is
executed.
18.5.2 The Timestamp-Ordering Protocol
Thetimestamp-orderingprotocolensuresthatanyconflictingreadandwriteoperations
areexecutedintimestamporder.Thisprotocoloperatesasfollows:
• SupposethattransactionT issuesread(Q).
i
° IfTS(T)<W-timestamp(Q),thenT needstoreadavalueofQthatwasalready
i i
overwritten.Hence,thereadoperationisrejected,andT isrolledback.
i
° If TS(T) ≥ W-timestamp(Q), then the read operation is executed, and R-
i
timestamp(Q)issettothemaximumofR-timestamp(Q)andTS(T).
i
• SupposethattransactionT issueswrite(Q).
i
° If TS(T) < R-timestamp(Q), then the value of Q that T is producing was
i i
neededpreviously,andthesystemassumedthatthatvaluewouldneverbepro-
duced.Hence,thesystemrejectsthewriteoperationandrollsT back.
i
° If TS(T) < W-timestamp(Q), then T isattempting to write an obsolete value
i i
ofQ.Hence,thesystemrejectsthiswriteoperationandrollsT back.
i
° Otherwise, the system executes the write operation and sets W-time-
stamp(Q)toTS(T).
i

--- Page 892 ---

18.5 Timestamp-BasedProtocols 863
IfatransactionT isrolledbackbytheconcurrency-controlschemeasresultofissuance
i
ofeitherareadorwriteoperation,thesystemassignsitanewtimestampandrestarts
it.
To illustrate this protocol, we consider transactions T and T . Transaction T
25 26 25
displaysthecontentsofaccountsAandB:
T : read(B);
25
read(A);
display(A+B).
TransactionT transfers$50fromaccountBtoaccountA,andthendisplaysthecon-
26
tentsofboth:
T : read(B);
26
B:=B−50;
write(B);
read(A);
A:=A+50;
write(A);
display(A+B).
Inpresentingschedulesunderthetimestampprotocol,weshallassumethatatransac-
tionisassignedatimestampimmediatelybeforeitsfirstinstruction.Thus,inschedule
3ofFigure18.17,TS(T )<TS(T ),andthescheduleispossibleunderthetimestamp
25 26
protocol.
Wenotethattheprecedingexecutioncanalsobeproducedbythetwo-phaselock-
ingprotocol.Thereare,however,schedulesthatarepossibleunderthetwo-phaselock-
ing protocol, but are not possible under the timestamp protocol, and vice versa (see
Exercise18.27).
The timestamp-ordering protocol ensures conflict serializability. This is because
conflictingoperationsareprocessedintimestamporder.
Theprotocolensuresfreedomfromdeadlock,sincenotransactioneverwaits.How-
ever, there is a possibility of starvation of long transactions if a sequence of conflict-
ing short transactions causes repeated restarting of the long transaction. If a transac-
tionissufferingfromrepeatedrestarts,conflictingtransactionsneedtobetemporarily
blockedtoenablethetransactiontofinish.
The protocol can generate schedulesthat are not recoverable. However, it can be
extendedtomaketheschedulesrecoverable,inoneofseveralways:
• Recoverability and cascadelessness can be ensured by performing all writes to-
gether at the end of the transaction. The writes must be atomic in the following
sense:Whilethewritesareinprogress,notransactionispermittedtoaccessany
ofthedataitemsthathavebeenwritten.

--- Page 893 ---

864 Chapter18 ConcurrencyControl
T T
25 26
read(B)
read(B)
B:=B−50
write(B)
read(A)
read(A)
display(A+B)
A:=A+50
write(A)
display(A+B)
Figure 18.17 Schedule3.
• Recoverabilityandcascadelessnesscanalsobeguaranteedbyusingalimitedform
oflocking,wherebyreadsof uncommitteditemsarepostponed untilthe transac-
tionthatupdatedtheitemcommits(seeExercise18.28).
• Recoverabilityalonecanbeensuredbytrackinguncommittedwritesandallowing
atransaction T tocommitonly afterthe commitof any transaction thatwrote a
i
valuethatT read.Commitdependencies,outlinedinSection18.1.5,canbeused
i
forthispurpose.
Ifthetimestamp-orderingprotocolisappliedonlytotuples,theprotocolwouldbe
vulnerabletothephantomproblemsthatwesawinSection17.10andSection18.4.3.
To avoid this problem, the timestamp-ordering protocol could be applied to all
data that is read by a transaction, including relation metadata and index data. In the
contextoflocking-basedconcurrencycontrol,theindex-lockingprotocol,describedin
Section18.4.3,isamoreefficientalternativeforavoidingthephantomproblem;recall
thattheindex-lockingprotocolobtainslocksonindexnodes,inadditiontoobtaining
locks on tuples. The timestamp-ordering protocol can be similarly modified to treat
each index node as a data item, with associated read and write timestamps, and to
apply the timestamp-ordering tests on these dataitems, too. Thisextended version of
thetimestamp-orderingprotocolavoidsphantomproblemsandensuresserializability
evenwithpredicatereads.
18.5.3 Thomas’ Write Rule
Wenowpresentamodificationtothetimestamp-orderingprotocolthatallowsgreater
potentialconcurrencythandoestheprotocolofSection18.5.2.Letusconsidersched-
ule4ofFigure18.18andapplythetimestamp-orderingprotocol.SinceT startsbefore
27
T ,weshallassumethatTS(T )<TS(T ).Theread(Q)operationofT succeeds,
28 27 28 27
as does the write(Q) operation of T . When T attempts its write(Q) operation,
28 27

--- Page 894 ---

18.5 Timestamp-BasedProtocols 865
T T
27 28
read(Q)
write(Q)
write(Q)
Figure 18.18 Schedule4.
wefindthatTS(T )<W-timestamp(Q),sinceW-timestamp(Q)=TS(T ).Thus,the
27 28
write(Q)byT isrejectedandtransactionT mustberolledback.
27 27
Although the rollback of T is required by the timestamp-ordering protocol, it
27
is unnecessary. Since T has already written Q, the value that T is attempting to
28 27
writeisonethatwillneverneedtoberead.AnytransactionT withTS(T)<TS(T )
i i 28
that attempts a read(Q) will be rolled back, since TS(T) < W-timestamp(Q). Any
i
transaction T with TS(T) > TS(T ) must read the value of Q written by T , rather
j j 28 28
thanthevaluethatT isattemptingtowrite.
27
Thisobservationleadstoamodifiedversionofthetimestamp-orderingprotocolin
whichobsoletewriteoperationscanbeignoredundercertaincircumstances.Thepro-
tocolrulesforreadoperationsremainunchanged.Theprotocolrulesforwriteopera-
tions, however, are slightly differentfrom the timestamp-ordering protocol of Section
18.5.2.
Themodificationtothetimestamp-orderingprotocol,calledThomas’writerule,is
this:SupposethattransactionT issueswrite(Q).
i
1. IfTS(T)<R-timestamp(Q), thenthevalueofQthatT isproducingwasprevi-
i i
ouslyneeded,andithadbeenassumedthatthevaluewouldneverbeproduced.
Hence,thesystemrejectsthewriteoperationandrollsT back.
i
2. IfTS(T)<W-timestamp(Q),thenT isattemptingtowriteanobsoletevalueof
i i
Q.Hence,thiswriteoperationcanbeignored.
3. Otherwise,thesystemexecutesthewriteoperationandsetsW-timestamp(Q)to
TS(T).
i
The difference between these rules and those of Section 18.5.2 lies in the sec-
ond rule. The timestamp-ordering protocol requires that T be rolled back if T issues
i i
write(Q)andTS(T)<W-timestamp(Q). However,here,inthosecaseswhereTS(T)
i i
≥R-timestamp(Q),weignoretheobsoletewrite.
Byignoringthewrite,Thomas’writeruleallowsschedulesthatarenotconflictseri-
alizablebutareneverthelesscorrect.Thosenon-conflict-serializableschedulesallowed
satisfythedefinitionofviewserializableschedules(seeNote18.1onpage867).Thomas’
writerulemakesuseofviewserializabilityby,ineffect,deletingobsoletewriteopera-
tionsfromthetransactionsthatissuethem.Thismodificationoftransactionsmakesit
possibletogenerate serializableschedulesthatwouldnotbepossibleundertheother

--- Page 895 ---

866 Chapter18 ConcurrencyControl
protocolspresentedinthischapter.Forexample,schedule4ofFigure18.18isnotcon-
flictserializableand,thus,isnotpossibleunderthetwo-phaselockingprotocol,thetree
protocol,orthetimestamp-orderingprotocol.UnderThomas’writerule,thewrite(Q)
operationofT wouldbeignored.Theresultisaschedulethatisviewequivalenttothe
27
serialschedule<T ,T >.
27 28
18.6 Validation-Based Protocols
Incaseswhereamajorityoftransactionsareread-onlytransactions,therateofconflicts
amongtransactionsmaybelow.Thus,manyofthesetransactions,ifexecutedwithout
thesupervisionofaconcurrency-controlscheme,wouldneverthelessleavethesystem
inaconsistentstate. Aconcurrency-controlschemeimposesoverheadof codeexecu-
tion and possible delay of transactions. It may be better to use an alternative scheme
thatimposeslessoverhead.Adifficultyinreducingtheoverheadisthatwedonotknow
in advance which transactions will be involved in a conflict. To gain that knowledge,
weneedaschemefor monitoringthesystem.
The validation protocol requires that each transaction T executes in two or three
i
different phases in its lifetime, depending on whether it is a read-only or an update
transaction.Thephasesare,inorder:
1. Read phase. During this phase, the system executes transaction T. It reads the
i
values of the various data items and stores them in variables local to T. It per-
i
formsall writeoperations on temporary localvariables, withoutupdates ofthe
actualdatabase.
2. Validation phase.Thevalidationtest(describedbelow)isappliedtotransaction
T.ThisdetermineswhetherT isallowedtoproceedtothewritephasewithout
i i
causingaviolationofserializability.Ifatransactionfailsthevalidationtest,the
systemabortsthetransaction.
3. Writephase.IfthevalidationtestsucceedsfortransactionT,thetemporarylocal
i
variablesthatholdtheresultsofanywriteoperationsperformedbyT arecopied
i
tothedatabase.Read-onlytransactionsomitthisphase.
Eachtransactionmustgothroughthephasesintheordershown.However,phasesof
concurrentlyexecutingtransactionscanbeinterleaved.
Toperformthevalidationtest,weneedtoknowwhenthevariousphasesoftrans-
actionstookplace.Weshall,therefore,associatethreedifferenttimestampswitheach
transactionT:
i
1. StartTS(T),thetimewhenT starteditsexecution.
i i
2. ValidationTS(T),thetimewhenT finisheditsreadphaseandstarteditsvalida-
i i
tionphase.
3. FinishTS(T),thetimewhenT finisheditswritephase.
i i

--- Page 896 ---

18.6 Validation-BasedProtocols 867
Note 18.1 VIEWSERIALIZABILITY
Thereisanotherformofequivalencethatislessstringentthanconflictequivalence,
butthat,likeconflictequivalence,isbasedononlythereadandwriteoperations
oftransactions.
Consider two schedules S and S′, where the same set of transactions partic-
ipates in both schedules. The schedules S and S′ are said to be view equivalent if
threeconditionsaremet:
1. ForeachdataitemQ,iftransactionT readstheinitialvalueofQinschedule
i
S,thentransactionT must,inscheduleS′,alsoreadtheinitialvalueofQ.
i
2. ForeachdataitemQ,iftransactionT executesread(Q)inscheduleS,andif
i
thatvaluewasproducedbyawrite(Q)operationexecutedbytransactionT,
j
thentheread(Q)operationoftransactionT must,inscheduleS′,alsoread
i
the value of Q that was produced by the same write(Q) operation of trans-
actionT.
j
3. For each data item Q, the transaction (if any) that performs the final
write(Q)operationinscheduleSmustperformthefinalwrite(Q)insched-
uleS′.
Conditions 1 and 2 ensure that each transaction reads the same values in both
schedules and, therefore, performs the same computation. Condition 3, coupled
withconditions1and2,ensuresthatbothschedulesresultinthesamefinalsystem
state.
Theconceptofviewequivalenceleadstotheconceptofviewserializability.We
saythatascheduleSisviewserializableifitisviewequivalenttoaserialschedule.
As an illustration, suppose that we augment schedule 4 with transaction T
29
andobtainthefollowingviewserializable(schedule5):
T T T
27 28 29
read (Q)
write (Q)
write (Q)
write (Q)
Indeed,schedule5isviewequivalenttotheserialschedule<T ,T ,T >,since
27 28 29
theoneread(Q)instructionreadstheinitialvalueofQinbothschedulesandT
29
performsthefinalwriteofQinbothschedules.
Everyconflict-serializablescheduleisalsoviewserializable,butthereareview-
serializable schedules that are not conflict serializable. Indeed, schedule 5 is not
conflict serializable, since every pair of consecutive instructions conflicts, and,
thus,noswappingofinstructionsispossible.

--- Page 897 ---

868 Chapter18 ConcurrencyControl
Note 18.1 VIEWSERIALIZABILITY(Cont.)
Observe that, in schedule 5, transactions T and T perform write(Q) op-
28 29
erations without having performed a read(Q) operation. Writes of this sort are
calledblindwrites.Blindwritesappearinanyview-serializableschedulethatisnot
conflictserializable.
Wedeterminetheserializabilityorderbythetimestamp-orderingtechnique,using
thevalueofthetimestampValidationTS(T).Thus,thevalueTS(T)=ValidationTS(T)
i i i
and, if TS(T) < TS(T ), then any produced schedule must be equivalent to a serial
j k
scheduleinwhichtransactionT appearsbeforetransactionT .
j k
The validation test for transaction T requires that, for all transactions T with
i k
TS(T )<TS(T),oneofthefollowingtwoconditionsmusthold:
k i
1. FinishTS(T ) < StartTS(T). Since T completes its execution before T started,
k i k i
theserializabilityorderisindeedmaintained.
2. ThesetofdataitemswrittenbyT doesnotintersectwiththesetofdataitems
k
readbyT,andT completesitswritephasebeforeT startsitsvalidationphase
i k i
(StartTS(T)<FinishTS(T )<ValidationTS(T)).Thisconditionensuresthatthe
i k i
writesofT andT donotoverlap. Sincethe writesofT donotaffectthe read
k i k
ofT,andsinceT cannotaffectthereadofT ,theserializabilityorderisindeed
i i k
maintained.
Asanillustration,consideragaintransactionsT andT .Suppose thatTS(T )
25 26 25
<TS(T ).Then,thevalidationphasesucceedsintheschedule6inFigure18.19.Note
26
thatthewritestotheactualvariablesareperformedonlyafterthevalidationphaseof
T .Thus,T readstheoldvaluesofBandA,andthisscheduleisserializable.
26 25
Thevalidationschemeautomaticallyguardsagainstcascadingrollbacks,sincethe
actual writes take place only after the transaction issuing the write has committed.
However,thereisapossibilityofstarvationoflongtransactions,duetoasequenceof
conflicting short transactions that cause repeated restarts of the long transaction. To
avoid starvation, conflicting transactions must be temporarily blocked to enable the
longtransactiontofinish.
Note also that the validation conditions result in a transaction T only being val-
idated again the set of transactions T that finished after T started, and, further, are
i
serialized before T. Transactions that finished before T started can be ignored in the
validation tests. Transactions T that are serialized after T (that is, they have Valida-
i
tionTS(T)>ValidationTS(T))canalsobeignored;whensuchatransactionT isvali-
i i
dated,itwouldbevalidatedagainstT ifT finishedafterT started.
i

--- Page 898 ---

18.7 MultiversionSchemes 869
T T
25 26
read(B)
read(B)
B:=B−50
read(A)
A:=A+50
read(A)
<validate>
display(A+B)
<validate>
write(B)
write(A)
Figure 18.19 Schedule6,ascheduleproducedbyusingvalidation.
This validation scheme is called the optimistic concurrency-control scheme since
transactionsexecuteoptimistically,assumingtheywillbe abletofinishexecutionand
validateattheend.Incontrast,lockingandtimestamporderingarepessimisticinthat
they force a wait or a rollback whenever a conflict is detected, even though there is a
chancethattheschedulemaybeconflictserializable.
It is possible to use TS(T) = StartTS(T) instead of ValidationTS(T) without af-
i i i
fecting serializability. However, doing so may result in a transaction T entering the
i
validationphasebeforeatransactionT thathasTS(T)<TS(T).Then,thevalidation
j j i
of T would have to wait for T to complete, so its read and write sets are completely
i j
known.UsingValidationTS avoidsthisproblem.
18.7 Multiversion Schemes
Theconcurrency-controlschemesdiscussedthusfarensureserializabilitybyeitherde-
layinganoperationorabortingthetransactionthatissuedtheoperation.Forexample,
a read operation may be delayed because the appropriate value has not been written
yet; or it may be rejected (that is, the issuing transaction must be aborted) because
thevaluethatitwassupposedtoreadhasalreadybeenoverwritten.Thesedifficulties
couldbeavoidedifoldcopiesofeachdataitemwerekeptinasystem.
In multiversion concurrency-control schemes, each write(Q) operation creates a
new version of Q. When a transaction issues a read(Q) operation, the concurrency-
controlmanagerselectsone of theversionsof Q tobe read.The concurrency-control
scheme must ensure that the version to be read is selected in a manner that ensures
serializability.Itisalsocrucial,forperformancereasons,thatatransactionbeableto
determineeasilyandquicklywhichversionofthedataitemshouldberead.

--- Page 899 ---

870 Chapter18 ConcurrencyControl
18.7.1 Multiversion Timestamp Ordering
The timestamp-ordering protocol can be extended to a multiversion protocol. With
each transaction T in the system, we associate a unique static timestamp, denoted
i
by TS(T). The database system assigns this timestamp before the transaction starts
i
execution,asdescribedinSection18.5.
With each data item Q, a sequence of versions <Q , Q ,…,Q > is associated.
1 2 m
EachversionQ containsthreedatafields:
k
1. ContentisthevalueofversionQ .
k
2. W-timestamp(Q )isthetimestampofthetransactionthatcreatedversionQ .
k k
3. R-timestamp(Q )isthelargesttimestampofanytransactionthatsuccessfullyread
k
versionQ .
k
Atransaction—say,T—createsanewversionQ ofdataitemQbyissuingawrite(Q)
i k
operation. The content field of the version holds the value written by T. The system
i
initializes the W-timestamp and R-timestamp to TS(T). It updates the R-timestamp
i
valueofQ wheneveratransactionT readsthecontentofQ andR-timestamp(Q )<
k j k k
TS(T).
j
The multiversion timestamp-ordering scheme presented next ensures serializabil-
ity. The scheme operates as follows: Suppose that transaction T issues a read(Q) or
i
write(Q)operation.LetQ denotetheversionofQwhosewritetimestampisthelargest
k
writetimestamplessthanorequaltoTS(T).
i
1. IftransactionT issuesaread(Q), thenthe value returnedisthecontentofver-
i
sionQ .
k
2. If transaction T issues write(Q), and if TS(T) < R-timestamp(Q ), then
i i k
the system rolls back transaction T. On the other hand, if TS(T) = W-
i i
timestamp(Q ), the system overwrites the contents of Q ; otherwise (if TS(T)
k k i
>R-timestamp(Q )),itcreatesanewversionofQ.
k
The justification for rule 1 is clear. A transaction reads the most recent version
thatcomesbeforeitintime.Thesecondruleforcesatransactiontoabortifitis“too
late”indoingawrite.Moreprecisely,ifT attemptstowriteaversionthatsomeother
i
transactionwouldhaveread,thenwecannotallowthatwritetosucceed.
ThevalidintervalofaversionQ ofQ withW-timestampt isdefinedasfollows:if
i
Q is the latest version of Q, the interval is [t,∞]; otherwise let the next version of Q
i
have timestamp s; then the valid interval is [t,s). You can easily verify that reads by
atransaction withtimestamp t return the contentof the version whose validinterval
i
containst.
i
Versions that are no longer needed are removed according to the following rule:
Supposethattherearetwoversions,Q andQ,ofadataitem,andthatbothversions
k j

--- Page 900 ---

18.7 MultiversionSchemes 871
have a W-timestamp less than the timestamp of the oldest transaction in the system.
Then,theolderofthetwoversionsQ andQ willnotbeusedagain,andcanbedeleted.
k j
Themultiversiontimestamp-orderingschemehasthedesirablepropertythataread
requestneverfailsandisnevermadetowait.Intypicaldatabasesystems,wherereading
isamorefrequentoperationthaniswriting,thisadvantagemaybeofmajorpractical
significance.
Thescheme,however,suffersfromtwoundesirableproperties.First,thereadingof
adataitemalsorequirestheupdatingoftheR-timestampfield,resultingintwopotential
diskaccesses,ratherthanone.Second,theconflictsbetweentransactionsareresolved
throughrollbacks,ratherthanthroughwaits.Thisalternativemaybeexpensive.Section
18.7.2describesanalgorithmtoalleviatethisproblem.
This multiversion timestamp-ordering scheme does not ensure recoverability and
cascadelessness. It can be extended in the same manner as the basic timestamp-
orderingschemetomakeitrecoverableandcascadeless.
18.7.2 Multiversion Two-Phase Locking
Themultiversiontwo-phaselockingprotocolattemptstocombinetheadvantagesofmul-
tiversionconcurrencycontrolwiththeadvantagesoftwo-phaselocking.Thisprotocol
differentiatesbetweenread-onlytransactionsandupdatetransactions.
Updatetransactionsperformrigoroustwo-phaselocking;thatis,theyholdalllocks
uptotheendofthetransaction.Thus,theycanbeserializedaccordingtotheircommit
order.Eachversionofadataitemhasasingletimestamp.Thetimestampinthiscase
is not a real clock-based timestamp, but rather is a counter, which we will call the ts-
counter,thatisincrementedduringcommitprocessing.
The database system assigns read-only transactions a timestamp by reading the
current value of ts-counter before they start execution; they follow the multiversion
timestamp-orderingprotocolforperformingreads.Thus,whenaread-onlytransaction
T issuesaread(Q),thevaluereturnedisthecontentsoftheversionwhosetimestamp
i
isthelargesttimestamplessthanorequaltoTS(T).
i
When an update transaction reads an item, it gets a shared lock on the item and
reads the latest version of that item. When an update transaction wants to write an
item, it first gets an exclusive lock on the item and then creates a new version of the
data item. The write is performed on the new version, and the timestamp of the new
versionisinitiallysettoavalue∞,avaluegreaterthanthatofanypossibletimestamp.
When the update transaction T completes its actions, it carries out commit pro-
i
cessing;onlyoneupdatetransactionisallowedtoperformcommitprocessingatatime.
First,T setsthetimestamponeveryversionithascreatedto1morethanthevalueof
i
ts-counter;then,T incrementsts-counterby1,andcommits.
i
Read-only transactions see the old value of ts-counter until T has successfully
i
committed.As a result, read-onlytransactions thatstart after T commitswillsee the
i
values updated by T, whereas those that start before T commits will see the value
i i
before the updates by T. In either case, read-only transactions never need to wait for
i

--- Page 901 ---

872 Chapter18 ConcurrencyControl
Note 18.2 MULTIVERSIONINGANDDATABASEIMPLEMENTATION
Consideradatabasesystemthatimplementsaprimarykeyconstraintbyensuring
thatonlyonetupleexistsforanyvalue oftheprimarykeyattribute. Thecreation
ofasecondversionoftherecordwiththesameprimarykeywouldappeartobea
violationoftheprimarykeyconstraint.However,itislogicallynotaviolation,since
the two versions do not coexist at any time in the database. Therefore, primary
constraintenforcementmustbemodifiedtoallowmultiplerecordswiththesame
primarykey,aslongastheyaredifferentversionsofthesamerecord.
Next, consider the issue of deletion of tuples. This can be implemented by
creating a new version of the tuple, with timestamps created as usual, but with a
special marker denoting that the tuple has been deleted. Transactions that read
suchatuplesimplyskipit,sinceithasbeendeleted.
Further, consider the issue of enforcing foreign-key dependencies. Consider
the case of a relation r whose attribute r.B is a foreign-key referencing attribute
s.B of relation s. In general, deletion of a tuple t in s or update of a primary key
s
attributeoftuplet inscausesaforeign-keyviolationifthereisanrtuplet suchthat
s r
t .B = t .B. Withmultiversioning,ifthetimestamp of thetransaction performing
r s
thedeletion/updateists,thecorrespondingconditionforviolationistheexistence
i
ofsuchatupleversiont ,withtheadditionalconditionthatthevalidintervaloft
r r
containsts.
i
Finally,considerthecaseofanindexonattributer.Bofrelationr.Ifthereare
multipleversionsofarecordt withthesamevalueforB,theindexcouldpointto
i
thelatestversionoftherecord,andthelatestversioncouldhavepointerstoearlier
versions. However, if an update was made to attribute t.B, the index would need
i
tocontainseparateentriesfordifferentversionsofrecordt;oneentryfortheold
i
value oft.B andanotherforthenewvalue of t.B.When oldversionsofarecord
i i
aredeleted,anyentryintheindexfortheoldversionmustalsobedeleted.
locks.Multiversiontwo-phaselockingalsoensuresthatschedulesarerecoverableand
cascadeless.
Versions are deleted in a manner like that of multiversion timestamp ordering.
Supposetherearetwoversions,Q andQ,ofadataitem,andthatbothversionshave
k j
atimestamplessthanorequaltothetimestampoftheoldestread-onlytransactionin
thesystem.Then,theolderofthetwoversionsQ andQ willnotbeusedagainandit
k j
canbedeleted.
18.8 Snapshot Isolation
Snapshot isolation is a particular type of concurrency-control scheme that has
gained wide acceptance in commercial and open-source systems, including Oracle,

--- Page 902 ---

18.8 SnapshotIsolation 873
PostgreSQL,andSQLServer.WeintroducedsnapshotisolationinSection17.9.3.Here,
wetakeamoredetailedlookintohowitworks.
Conceptually,snapshotisolationinvolvesgivingatransactiona“snapshot”ofthe
database at the time when it begins its execution. It then operates on that snapshot
in complete isolation from concurrent transactions. The data values in the snapshot
consist only of values written by committed transactions. This isolation is ideal for
read-onlytransactionssincetheyneverwaitandareneverabortedbytheconcurrency
manager.
Transactionsthatupdatethedatabasepotentiallyhaveconflictswithothertransac-
tionsthatupdatethedatabase.Updatesperformedbyatransactionmustbevalidated
beforethetransactionisallowedtocommit.Wedescribehowvalidationisperformed,
later in thissection.Updates are keptin the transaction’sprivate workspace until the
transactionisvalidated,atwhichpointtheupdatesarewrittentothedatabase.
WhenatransactionT isallowedtocommit,thetransitionofT tothecommitted
stateandthewritingofalloftheupdatesmadebyT tothedatabasemustbeconcep-
tually done as an atomic action so that any snapshot created for another transaction
eitherincludesallupdatesbytransactionT ornoneofthem.
18.8.1 Multiversioning in Snapshot Isolation
To implement snapshot isolation, transactions are given two timestamps. The first
timestamp,StartTS(T),isthetimeatwhichtransactionT started.Thesecondtimes-
i i
tamp,CommitTS(T)isthetimewhenthetransactionT requestedvalidation.
i i
Note that timestamps can be wall clock time, as long as no two transactions are
given the same timestamp, but they are usually assigned from a counter that is incre-
mentedeverytimeatransactionentersitsvalidationphase.
Snapshotisolationisbasedonmultiversioning,andeachtransactionthatupdates
adataitemcreatesaversionofthedataitem.Versionshaveonlyonetimestamp,which
is the write timestamp, indicating when the version was created. The timestamp of a
versioncreatedbytransactionT issettoCommitTS(T).(Sinceupdatestothedatabase
i i
are also only made after validation of the transaction T, CommitTS(T) is available
i i
whenaversioniscreated.)2
WhenatransactionT readsadataitem,thelatestversionofthedataitemwhose
i
timestamp is ≤ StartTS(T) is returned to T. Thus, T does not see the updates of
i i i
any transactions that committed after T started, while it does see the updates of all
i
transactionsthatcommitbeforeitstarted.Asaresult,T effectivelyseesasnapshotof
i
thedatabaseasofthetimeitstarted.3
2Manyimplementationscreateversionsevenbeforethetransactionstartsvalidation;sincetheversiontimestampis
notavailableatthispoint,thetimestampissettoinfinityinitially,andisupdatedtothecorrectvalueatthetimeof
validation.Furtheroptimizationsareusedinactualimplementations,butweignorethemforsimplicity.
3Toefficientlyfindthecorrectversionofadataitemforagiventimestamp,manyimplementationsstorenotonly
thetimestampwhenaversionwascreated,butalsothetimestampwhenthenextversionwascreated,whichcan
beconsideredaninvalidationtimestampforthatversion;theversionisvalidbetweenthecreationandinvalidation
timestamps.Thecurrentversionofadataitemhastheinvalidationtimestampsettoinfinity.

--- Page 903 ---

874 Chapter18 ConcurrencyControl
18.8.2 Validation Steps for Update Transactions
Decidingwhetherornottoallowanupdatetransactiontocommitrequiressomecare.
Potentially, two transactions running concurrently might both update the same data
item. Since these two transactions operate in isolation using their own private snap-
shots, neither transaction sees the update made by the other. If both transactions are
allowed to write to the database, the first update written will be overwritten by the
second. The result is a lost update. This must be prevented. There are two variants of
snapshotisolation,bothofwhichpreventlostupdates. Theyarecalledfirstcommitter
winsandfirstupdaterwins.Bothapproachesarebasedontestingthetransactionagainst
concurrenttransactions.
AtransactionT issaidtobeconcurrentwithagiventransactionT ifitwasactive
j i
orpartiallycommittedatanypointfromthestartofT uptothepointwhenvalidation
ofT started.Formally,T isconcurrentwithT ifeither
i j i
StartTS(T) ≤StartTS(T) ≤CommitTS(T),or
j i j
StartTS(T) ≤StartTS(T) ≤CommitTS(T).
i j i
Under first committer wins, when a transaction T starts validation, the following
i
actionsareperformedaspartofvalidation,afteritsCommitTSisassigned.(Weassume
for simplicity that only one transaction performs validation at a time, although real
implementationsdosupportconcurrentvalidation.)
• A test is made to see if any transaction that was concurrent with T has already
writtenanupdatetothedatabaseforsomedataitemthatT intendstowrite.
ThiscanbedonebycheckingforeachdataitemdthatT intendstowrite,whether
i
thereisaversionofthedataitemd whosetimestampisbetweenStartTS(T)and
i
CommitTS(T).4
i
• Ifanysuchdataitemisfound,thenT aborts.
i
• If no such data item is found, then T commits and its updates are written to the
database.
Thisapproachiscalled“firstcommitterwins”becauseiftransactionsconflict,thefirst
one to be tested using theabove rule succeedsin writingitsupdates, whilethe subse-
quentonesareforcedtoabort.Detailsofhowtoimplementthesetestsareaddressed
inExercise18.15.
Underfirstupdaterwins,thesystemusesalockingmechanismthatappliesonlyto
updates (reads are unaffected by this, since they do not obtain locks). When a trans-
action T attempts to update a data item, it requests a write lock on that data item. If
i
thelockisnotheldbyaconcurrenttransaction,thefollowingstepsaretakenafterthe
lockisacquired:
• Iftheitemhasbeenupdatedbyanyconcurrenttransaction,thenT aborts.
i
4Therearealternativeimplementations,basedonkeepingtrackofreadandwritesetsfortransactions.

--- Page 904 ---

18.8 SnapshotIsolation 875
• OtherwiseT mayproceedwithitsexecution,includingpossiblycommitting.
i
If, however, some other concurrent transaction T already holds a write lock on that
j
dataitem,thenT cannotproceed,andthefollowingrulesarefollowed:
i
• T waitsuntilT abortsorcommits.
i j
° IfT aborts,thenthelockisreleasedandT canobtainthelock.Afterthelock
j i
isacquired,thecheckforanupdate byaconcurrenttransactionisperformed
asdescribedearlier:T abortsifaconcurrenttransactionhadupdatedthedata
i
item,anditproceedswithitsexecutionotherwise.
° IfT commits,thenT mustabort.
j i
Locksarereleasedwhenthetransactioncommitsoraborts.
Thisapproachiscalled“firstupdaterwins”becauseiftransactionsconflict,thefirst
one toobtain the lockistheone thatispermittedtocommitandperform itsupdate.
Thosethatattempttheupdatelaterabortunlessthefirstupdatersubsequentlyaborts
forsomeotherreason.(AsanalternativetowaitingtoseeifthefirstupdaterT aborts,
j
asubsequentupdaterT canbeabortedassoonasitfindsthatthewritelockitwishes
i
toobtainisheldbyT.)
j
18.8.3 Serializability Issues and Solutions
Snapshotisolationisattractiveinpracticebecausetransactionsthatreadalotofdata
(typically for data analysis) do not interfere with shorter update transactions (typi-
cally used for transaction processing). With two-phase locking, such long read-only
transactions wouldblockupdate transactionsfor longperiodsof time,whichisoften
unacceptable.
Itisworthnotingthatintegrityconstraintsthatareenforcedbythedatabase,such
as primary-key and foreign-key constraints, cannot be checked on a snapshot; other-
wiseitwouldbepossiblefortwoconcurrenttransactionstoinserttwotupleswiththe
same primary key value, or for a transaction to insert a foreign key value that is con-
currentlydeletedfromthereferencedtable.Thisproblemishandledbycheckingthese
constraints on the current state of the database, rather than on the snapshot, as part
ofvalidationatthetimeofcommit.
Evenwiththeabovefix,thereisstillaseriousproblemwiththesnapshotisolation
schemeaswehavepresenteditandasitisimplementedinpractice:snapshotisolation
doesnotensureserializability!
Nextwegiveexamples ofpossible nonserializableexecutionsundersnapshotiso-
lation. We then outline the serializable snapshot isolation technique that is supported
bysomedatabases,whichextendsthesnapshotisolationtechniquetoensureserializ-
ability. Snapshot isolation implementations that do not support serializable snapshot
isolation often support SQL extensions that allow the programmer to ensure serializ-
abilityevenwithsnapshotisolation;westudytheseextensionsattheendofthesection.

--- Page 905 ---

876 Chapter18 ConcurrencyControl
T T
i j
read(A)
read(B)
read(A)
read(B)
A=B
B=A
write(A)
write(B)
Figure 18.20 Nonserializablescheduleundersnapshotisolation.
• Consider the transaction schedule shown in Figure 18.20. Two concurrenttrans-
actionsT andT bothreaddataitemsAandB.T setsA = BandwritesA,whileT
i j i j
setsB = AandwritesB.SinceT andT areconcurrent,undersnapshotisolation
i j
neither transaction sees the update by the other in its snapshot. But, since they
updatedifferentdataitems,bothareallowedtocommitregardlessofwhetherthe
systemusesthefirst-update-winspolicyorthefirst-committer-winspolicy.
However, the execution is not serializable, since it results in swapping of the
valuesofAandB,whereasanyserializableschedulewouldsetbothAandBtothe
samevalue:eithertheinitialvalueofAortheinitialvalueofB,dependingonthe
orderofT andT.
i j
It can be easily seen that the precedence graph has a cycle. There is an edge
intheprecedencegraphfromT toT becauseT readsthevalueofAthatexisted
i j i
before T writes A. There is also an edge in the precedence graph from T to T
j j i
because T reads the value of B that existed before T writes B. Since there is a
j i
cycleintheprecedencegraph,theresultisanonserializableschedule.
Thissituation,whereeachofapairoftransactionshasreadadataitemthatis
written by the other, but the set of data items written by the two transactions do
nothaveanydataitemincommon,isreferredtoaswriteskew.
• Asanotherexampleofwriteskew,considerabankingscenario.Supposethatthe
bankenforcestheintegrityconstraintthatthesumofthebalancesinthechecking
andthesavingsaccountofacustomermustnotbenegative.Supposethechecking
andsavingsbalancesforacustomerare$100and$200,respectively.Supposethat
transactionT withdraws$200fromthecheckingaccount,afterverifyingthein-
36
tegrityconstraintbyreadingbothbalances.Supposethatconcurrentlytransaction
T withdraws $200 from the savings account, again after verifying the integrity
37
constraint. Since each of the transactions checks the integrity constraint on its
own snapshot, if they run concurrently each will believe that the sum of the bal-
ances after the withdrawal is $100, and therefore its withdrawal does not violate

--- Page 906 ---

18.8 SnapshotIsolation 877
theconstraint.Sincethetwotransactionsupdatedifferentdataitems,theydonot
haveanyupdateconflict,andundersnapshotisolationbothofthemcancommit.
Unfortunately,inthefinalstateafterbothT andT havecommitted,thesum
36 37
of the balances is $100, violating the integrity constraint. Such a violation could
neverhaveoccurredinanyserialexecutionofT andT .
36 37
• Manyfinancialapplicationscreateconsecutivesequencenumbers,forexampleto
number bills, by taking the maximum current bill number and adding 1 to the
value to get a new bill number. If two such transactions run concurrently, each
would see the same set of bills in its snapshot, and each would create a new bill
with the same number. Both transactions pass the validation tests for snapshot
isolation,sincetheydonotupdateanytupleincommon.However,theexecution
is not serializable; the resultant database state cannot be obtained by any serial
executionofthetwotransactions.Creatingtwobillswiththesamenumbercould
haveseriouslegalimplications.
Theaboveproblemisinfactanexampleofthephantomphenomenon,which
wesawin Section18.4.3,sincetheinsertperformedbyeachtransactionconflicts
withthereadperformedbytheothertransactiontofindthemaximumbillnumber,
buttheconflictisnotdetectedbysnapshotisolation.5
Theproblemslisted above seemtoindicatethatthesnapshot isolationtechnique
isvulnerable tomanyserializabilityproblemsand should neverbe used. However,se-
rializabilityproblemsarerelativelyrarefortworeasons:
1. The fact that the database must check integrity constraints at the time of com-
mit, and not on a snapshot, helps avoid inconsistenciesin many situations. For
example,inthefinancialapplicationexamplethatwesawearlier,thebillnumber
would likely have been declared as a primary key. The database system would
detect the primary key violation outside the snapshot and roll back one of the
twotransactions.
It was shown that primary key constraints ensured that all transactions in a
popular transaction processing benchmark, TPC-C, were free from nonserializ-
abilityproblems,whenexecutedundersnapshotisolation.Thiswasviewedasan
indicationthatsuchproblemsarerare.However,theydooccuroccasionally,and
whentheyoccurtheymustbedealtwith.6
2. Inmanyapplicationsthatarevulnerabletoserializabilityproblems,suchasskew
writes,onsomedataitems,thetransactionsconflictonotherdataitems,ensuring
5TheSQLstandardusesthetermphantomproblemtorefertononrepeatablepredicatereads,leadingsometoclaimthat
snapshotisolationavoidsthephantomproblem;however,suchaclaimisnotvalidunderourdefinitionofphantom
conflict.
6Forexample,theproblemofduplicatebillnumbersactuallyoccurredseveraltimesinafinancialapplicationinI.I.T.
Bombay,where(forreasonstoocomplextodiscusshere)thebillnumberwasnotaprimarykey,anditwasdetected
byfinancialauditors.

--- Page 907 ---

878 Chapter18 ConcurrencyControl
suchtransactionscannotexecuteconcurrently;asaresult,theexecutionofsuch
transactionsundersnapshotisolationremainsserializable.
Nonserializable may nevertheless occur with snapshot isolation. The impact of
nonserializableexecutionduetosnapshotisolationisnotverysevereformanyapplica-
tions.Forexample,considerauniversityapplicationthatimplementsenrollmentlimits
foracoursebycountingthecurrentenrollmentbeforeallowingregistration.Snapshot
isolationcouldallowtheclassenrollmentlimittobeexceeded.However,thismayhap-
penveryrarely,andifitdoes,havingoneextrastudentinaclassisusuallynotamajor
problem.Thefactthatsnapshotisolationallowslongreadtransactionstoexecutewith-
outblockingupdatersisalargeenoughbenefitformanysuchapplicationstolivewith
occasionalglitches.
Nonserializability may not be acceptable for many other applications, such as fi-
nancialapplications.Thereareseveralpossiblesolutions.
• Amodifiedformofsnapshotisolation,calledserializablesnapshotisolation,can
beusedifitissupportedbythedatabasesystem.Thistechniqueextendsthesnap-
shotisolationtechniqueinawaythatensuresserializability.
• Some systems allow different transactions to run under different isolation levels,
whichcanbeusedtoavoidtheserializabilityproblemsmentionedabove.
• SomesystemsthatsupportsnapshotisolationprovideawayforSQLprogrammers
tocreateartificialconflicts,usingaforupdateclauseinSQL,whichcanbeusedto
ensureserializability.
Webrieflyoutlineeachofthesesolutionsbelow.
Sinceversion9.1,PostgreSQLimplementsatechniquecalledserializablesnapshot
isolation, which ensures serializability; in addition, PostgreSQL versions from 9.1 on-
wardsincludeanindex-locking-basedtechniquetoprovideprotectionagainstphantom
problems.
Theintuitionbehindtheserializablesnapshotisolation(SSI)protocolisasfollows:
Suppose we track all conflicts (i.e., write-write, read-write, and write-read conflicts)
between transactions. Recall from Section 17.6 that we can construct a transaction
precedence graph which has a directed edge from T to T if transactions T and T
1 2 1 2
haveconflictingoperationsonatuple,withT ’sactionprecedingT ’saction.Aswesaw
1 2
inSection17.6,onewaytoensureserializabilityistolookforcyclesinthetransaction
precedencegraphandrollbacktransactionsifacycleisfound.
Thekeyreasonforlossofserializabilitywithsnapshotisolationisthatread-write
conflicts,whereatransactionT writesaversionofanobject,andatransactionT sub-
1 2
sequentlyreadsanearlierversionoftheobject,arenottrackedbysnapshotisolation.
Thisconflictcanberepresentedbyaread-writeconflictedgefromT toT .
2 1
Ithasbeenshownthatinallcaseswheresnapshotisolationallowsnonserializable
schedules, there must be a transaction that has both an incoming read-write conflict

--- Page 908 ---

18.8 SnapshotIsolation 879
edgeandanoutgoingread-writeconflictedge(allothercasesofcyclesintheconflict
grapharecaughtbythesnapshotisolationrules).Thus,serializablesnapshotisolation
implementations track all read-write conflicts between concurrent transactions to de-
tectifatransactionhasbothanincomingandanoutgoingread-writeconflictedge.If
suchasituationisdetected,oneofthetransactionsinvolvedintheread-writeconflicts
isrolledback.Thischeckissignificantlycheaperthantrackingallconflictsandlooking
forcycles,althoughitmayresultinsomeunnecessaryrollbacks.
ItisalsoworthmentioningthatthetechniqueusedbyPostgreSQLtopreventphan-
tomsusesindexlocking,butthelocksarenotheldinatwo-phasemanner.Instead,they
areusedtodetectpotentialconflictsbetweenconcurrenttransactionsandmustbere-
tained for some time even after a transaction commits, to allow checks against other
concurrent transactions. The index-locking technique used by PostgreSQL also does
notresultinanydeadlocks.
SQLServerofferstheoptionofallowingsometransactionstorunundersnapshot
isolation, while allowing others to run under the serializable isolation level. Running
long read-only transactions under the snapshot isolation level while running update
transactionsundertheserializableisolationlevelensuresthattheread-onlytransaction
doesnotblockupdaters,whilealsoensuringthattheaboveanomaliescannotoccur.
In Oracle versions till at least Oracle 12c (to the best of our knowledge), and in
PostgreSQL versions prior to 9.1, the serializable isolation level actually implements
snapshot isolation. As a result, even with the isolation level set to serializable, it is
possiblethatthedatabasepermitssomeschedulesthatarenotserializable.
Ifanapplicationhastorunundersnapshotisolation,onseveralofthesedatabases
an application developer can guard against certain snapshot anomalies by appending
aforupdateclausetotheSQLselectqueryasillustratedbelow:
select*
frominstructor
whereID=22222
forupdate;
Adding the for update clause causes the system to treat data that are read as if they
had been updated for purposes of concurrency control. In our first example of write
skewshowninFigure18.20,iftheforupdateclausewereappendedtotheselectqueries
thatreadthevaluesofAandB,onlyoneofthetwoconcurrenttransactionswouldbe
allowedtocommitsinceitappearsthatbothtransactionshaveupdatedbothAandB.
Formalmethodsexist(seetheonlinebibliographicalnotes)todeterminewhether
a given mixof transactions runs the risk of nonserializable execution under snapshot
isolationandtodecideonwhatconflictstointroduce(usingtheforupdateclause,for
example)toensureserializability.Suchmethodscanworkonlyifweknowinadvance
whattransactionsarebeingexecuted.Insomeapplications,alltransactionsarefroma
predeterminedsetoftransactions,makingthisanalysispossible.However,iftheappli-
cationallowsunrestricted,adhoctransactions,thennosuchanalysisispossible.

--- Page 909 ---

880 Chapter18 ConcurrencyControl
18.9 Weak Levels of Consistency in Practice
In Section 17.8, we discussed the isolation levels specified by the SQL standard: seri-
alizable, repeatable read, read committed, and read uncommitted. In this section, we
first briefly outline some olderterminology relatingto consistency levelsweakerthan
serializabilityandrelateittotheSQLstandardlevels.Wethendiscusstheissueofcon-
currencycontrolfortransactionsthatinvolveuserinteraction,anissuethatwebriefly
discussedinSection17.8.
18.9.1 Degree-Two Consistency
Thepurposeofdegree-twoconsistencyistoavoidcascadingabortswithoutnecessarily
ensuringserializability.Thelockingprotocolfordegree-twoconsistencyusesthesame
twolockmodesthatweusedforthetwo-phaselockingprotocol:shared(S)andexclu-
sive (X). A transaction must hold the appropriate lock mode when it accesses a data
item,buttwo-phasebehaviorisnotrequired.
In contrast to the situation in two-phase locking, S-locks may be released at any
time, and locks may be acquired at any time. Exclusive locks, however, cannot be re-
leaseduntilthetransactioneithercommitsoraborts. Serializabilityisnotensuredby
thisprotocol.Indeed,atransactionmayreadthesamedataitemtwiceandobtaindif-
ferentresults. InFigure18.21, T readsthevalue ofQ before thatvalue iswritten by
32
T ,andagainafteritiswrittenbyT .
33 33
Readsarenotrepeatable,butsinceexclusivelocksarehelduntiltransactioncom-
mit, no transaction can read an uncommitted value. Thus, degree-two consistency is
oneparticularimplementationoftheread-committedisolationlevel.
Itisinterestingtonotethatwithdegree-twoconsistency,atransactionthatisscan-
ning an index may potentially see two versions of a record that was updated while
the scan was in progress and may also potentially see neither version! For example,
T T
32 33
lock-S(Q)
read(Q)
unlock(Q)
lock-X(Q)
read(Q)
write(Q)
unlock(Q)
lock-S(Q)
read(Q)
unlock(Q)
Figure 18.21 Nonserializableschedulewithdegree-twoconsistency.

--- Page 910 ---

18.9 WeakLevelsofConsistencyinPractice 881
consider a relation r(A,B,C), with primary key A, with an index on attribute B. Now
consider a query that is scanning the relation r using the index on attribute B, using
degree-two consistency. Suppose there is a concurrent update to a tuple t ∈ r that
1
updatesattributet .Bfromv tov .Suchanupdaterequiresdeletionofanentrycorre-
1 1 2
spondingtovaluev fromtheindexandinsertionofanewentrycorrespondingtov .
1 2
Now,thescanofrcouldpossiblyscantheindexnodecorrespondingtov aftertheold
1
tuple isdeleted there but visitthe index node correspondingto v before the updated
2
tuple is inserted in that node. Then, the scan would completely miss the tuple, even
thoughitshouldhaveseeneithertheoldvalueorthenewvalueoft .Further,ascan
1
usingdegree-twoconsistencycouldpossiblyvisitthenodecorrespondingtov before
1
thedelete,andthenodecorrespondingtov aftertheinsert,andtherebyseetwover-
2
sionsoft , onefrom before theupdate andone fromafter theupdate. (Thisproblem
1
wouldnotariseifthescanandtheupdatebothusedtwo-phaselocking.)
18.9.2 Cursor Stability
Cursorstabilityisaformofdegree-twoconsistencydesignedforprogramsthatiterate
overtuplesofarelationbyusingcursors.Insteadoflockingtheentirerelation,cursor
stabilityensuresthat:
• The tuple that is currently being processed by the iteration is locked in shared
mode.Oncethetupleisprocessed,thelockonthetuplecanbereleased.
• Anymodifiedtuplesarelockedinexclusivemodeuntilthetransactioncommits.
Theserulesensurethatdegree-twoconsistencyisobtained.Butlockingisnotdone
in a two-phase manner, and serializability is not guaranteed. Cursor stability is used
in practice on heavily accessed relations as a means of increasing concurrency and
improving system performance. Applications that use cursor stability must be coded
in a way that ensures database consistency despite the possibility of nonserializable
schedules. Thus, the use of cursor stability is limited to specialized situations with
simpleconsistencyconstraints.
When supported by the database, snapshot isolation is a better alternative to
degree-twoconsistencyaswellascursorstability,sinceitoffersasimilarorevenbetter
levelofconcurrencywhilereducingtheriskofnonserializableexecutions.
18.9.3 Concurrency Control Across User Interactions
Concurrency-control protocols usually consider transactions that do not involve user
interaction. Consider the airline seat selection example from Section 17.8, which in-
volveduserinteraction.Supposewetreatallthestepsfromwhentheseatavailabilityis
initiallyshowntotheuser,untiltheseatselectionisconfirmed,asasingletransaction.
If two-phase locking is used, the entire set of seats on a flight would be locked in
sharedmodeuntiltheuserhascompletedtheseatselection,andnoothertransaction
would be able to update the seat allocation information in this period. Such locking

--- Page 911 ---

882 Chapter18 ConcurrencyControl
wouldbeaverybadideasinceausermaytakealongtimetomakeaselection,oreven
just abandon the transaction without explicitly cancellingit. Timestamp protocols or
validation could be used instead, which avoid the problem of locking, but both these
protocolswouldabortthetransactionforauserAifanyotheruserBhasupdatedthe
seat allocation information, even if the seat selected by B does not conflict with the
seat selected by user A. Snapshot isolation is a good option in this situation, since it
wouldnotabort thetransaction of user A aslongasB didnotselectthesameseatas
A.
However,snapshotisolationrequiresthedatabasetorememberinformationabout
updates performed by a transaction even after it has committed, as long as any other
concurrenttransactionisstillactive,whichcanbeproblematicforlong-durationtrans-
actions.
Another option is to split a transaction that involves user interaction into two or
more transactions, such that no transaction spans a user interaction. If our seat se-
lection transaction is split thus, the first transaction would read the seat availability,
whilethesecondtransactionwouldcompletetheallocationoftheselectedseat.Ifthe
second transaction is written carelessly, it could assign the selected seat to the user,
without checking if the seat was meanwhile assigned to some other user, resulting in
a lost-update problem. To avoid the problem, as we outlined in Section 17.8, the sec-
ondtransactionshouldperformtheseatallocationonlyiftheseatwasnotmeanwhile
assignedtosomeotheruser.
Theaboveideahasbeengeneralizedinanalternativeconcurrencycontrolscheme,
whichusesversionnumbersstoredintuplestoavoidlostupdates.Theschemaofeach
relationisalteredbyaddinganextraversion number attribute,whichisinitializedto0
when thetuple iscreated.When a transaction reads(forthe firsttime)atuple thatit
intendstoupdate,itrememberstheversionnumberofthattuple.Thereadisperformed
asastand-alonetransactiononthedatabase,andhenceanylocksthatmaybeobtained
arereleasedimmediately.Updatesaredonelocallyandcopiedtothedatabaseaspart
ofcommitprocessing,usingthefollowingstepswhichareexecutedatomically(i.e.,as
partofasingledatabasetransaction):
• Foreachupdatedtuple,thetransactionchecksifthecurrentversionnumberisthe
sameastheversionnumberofthetuplewhenitwasfirstreadbythetransaction.
1.If the version numbers match, the update is performed on the tuple in the
database,anditsversionnumberisincrementedby1.
2.Iftheversionnumbersdonotmatch,thetransactionisaborted,rollingback
alltheupdatesitperformed.
• Iftheversionnumberchecksucceedsforallupdatedtuples,thetransactioncom-
mits. It is worth noting that a timestamp could be used instead of the version
numberwithoutimpactingtheschemeinanyway.

--- Page 912 ---

18.10 AdvancedTopicsinConcurrencyControl 883
Observetheclosesimilaritybetweentheprecedingschemeandsnapshotisolation.
Theversionnumbercheckimplementsthefirst-committer-winsruleused insnapshot
isolation, and it can be used even if the transaction was active for a very long time.
However,unlikesnapshotisolation,thereadsperformedbyatransactionmaynotcor-
respondtoasnapshotofthedatabase;andunlikethevalidation-basedprotocol,reads
performedbythetransactionarenotvalidated.
Werefertotheaboveschemeasoptimisticconcurrencycontrolwithoutreadvalida-
tion. Optimistic concurrencycontrol without read validation provides a weak level of
serializability,anditdoesnotensureserializability.Avariantofthisschemeusesver-
sionnumberstovalidatereadsatthetimeofcommit,inadditiontovalidatingwrites,
to ensure that the tuples read by the transaction were not updated subsequent to the
initial read; this scheme is equivalent to the optimistic concurrency-control scheme
whichwesawearlier.
This scheme has been widely used by application developers to handle transac-
tions that involve user interaction. An attractive feature of the scheme is that it can
be implemented easily on top of a database system. The validation and update steps
performed as part of commit processing are then executed as a single transaction in
thedatabase,usingtheconcurrency-controlschemeofthedatabasetoensureatomic-
ityforcommitprocessing.TheschemeisalsousedbytheHibernate object-relational
mapping system (Section 9.6.2), and other object-relational mapping systems, where
itisreferredtoasoptimisticconcurrencycontrol(eventhoughreadsarenotvalidated
bydefault).Hibernate andotherobject-relationalmappingsystems thereforeperform
theversionnumbercheckstransparentlyaspartofcommitprocessing.(Transactions
thatinvolveuserinteractionarecalledconversationsinHibernatetodifferentiatethem
from regular transactions; validation using version numbers is particularly useful for
suchtransactions.)
Application developers must, however, be aware of the potential for non-
serializableexecution,andtheymustrestricttheirusageoftheschemetoapplications
wherenon-serializabilitydoesnotcauseseriousproblems.
18.10 Advanced Topics in Concurrency Control
Instead of using two-phase locking, special-purpose concurrency control techniques
canbeusedforindexstructures,resultinginimprovedconcurrency.Whenusingmain-
memory databases, conversely, index concurrencycontrol can be simplified.Further,
concurrencycontrolactionsoftenbecomebottlenecksinmain-memorydatabases,and
techniquessuchaslatch-freedatastructureshavebeendesignedtoreduceconcurrency
controloverheads.Insteadofdetectingconflictsatthelevelofreadsandwrites,itispos-
sible toconsideroperations, such as incrementof acounter, asbasic operations, and
performconcurrencycontrolonthebasisofconflictsbetweenoperations.Certainap-
plicationsrequireguaranteesontransactioncompletiontime.Specializedconcurrency
controltechniqueshavebeendevelopedforsuchapplications.

--- Page 913 ---

884 Chapter18 ConcurrencyControl
18.10.1 Online Index Creation
Whenwearedealingwithlargevolumesofdata(rangingintheterabytes),operations
such as creating an index can take a long time—perhaps hours or even days. When
theoperation finishes,theindexcontentsmustbeconsistentwiththecontentsofthe
relation,andallfurtherupdatestotherelationmustmaintaintheindex.
One way of ensuring thatthe data and the index are consistent isto block all up-
datestotherelationwhiletheindexiscreated,forexamplebygettingasharedlockon
therelation.Aftertheindexiscreated,andtherelationmetadataareupdatedtoreflect
the existence of the index locks can be released. Subsequent update transactions will
findtheindex,andcarryoutindexmaintenanceaspartofthetransaction.
However, the above approach would make the system unavailable for updates to
therelationforaverylongtime,whichisunacceptable.Instead,mostdatabasesystems
supportonlineindexcreation,whichallowsrelationupdatestooccurevenastheindex
isbeingcreated.Onlineindexcreationcanbecarriedoutasfollows:
1. Indexcreationgetsasnapshotoftherelationandusesittocreatetheindex;mean-
while,thesystem logsallupdatestotherelationthathappenafterthesnapshot
iscreated.
2. Whentheindexonthesnapshotdataiscomplete,itisnotyetreadyforuse,since
subsequentupdatesaremissing.Atthispoint,thelogofupdatestotherelationis
usedtoupdatetheindex.Butwhiletheindexupdateisbeingcarriedout,further
updatesmaybehappeningontherelation.
3. The index update then obtains a shared lock on the relation to prevent further
updates and applies all remainingupdates to the index. Atthis point, the index
is consistent with the contents of the relation. The relation metadata are then
updated to indicate the existence of the new index. Subsequently all locks are
released.
Anytransactionthatexecutesafterthiswillseetheexistenceoftheindex;ifthe
transactionupdatestherelation,itwillalsoupdatetheindex.
Creation of materialized views that are maintained immediately, as part of the
transactionthatupdatesanyoftherelationsusedintheview,canalsobenefitfromon-
line construction techniques that are similar to online index construction. The query
defining the view is executed on a snapshot of the participating relations, and subse-
quentupdatesarelogged.Theupdatesareappliedtothematerializedview,withafinal
phaseoflockingandcatchingupsimilartothecaseofonlineindexcreation.
Schemachangessuchasaddingordeletingattributesorconstraintscanalsohave
asignificantimpactifrelationsarelockedwhiletheschemachangeisimplementedon
alltuples.
• For adding or deleting attributes, a version number can be kept with each tuple,
andtuplescanbeupdatedinthebackground,orwhenevertheyareaccessed;the
versionnumberisusedtodetermineiftheschemachangehasalreadybeenapplied

--- Page 914 ---

18.10 AdvancedTopicsinConcurrencyControl 885
tothetuple,andtheschemachangeisappliedtothetupleifithasnotalreadybeen
applied.
• Adding of constraints requires that existing data must be checked to ensure that
theconstraintissatisfied.Forexample,addingaprimaryoruniquekeyconstraint
onanattributeIDrequirescheckingofexistingtuplestoensurethatnotwotuples
have the same IDvalue. Online additionof such constraints is done in amanner
similar to online index construction, by checking the constraints on a relation
snapshot,whilekeepingalogofupdatesthatoccurafterthesnapshot.Theupdates
inthelogmustthenbecheckedtoensurethattheydonotviolatetheconstraint.In
afinalcatch-upphase,theconstraintischeckedonanyremainingupdatesinthe
logandaddedtotherelationmetadatawhileholdingasharedlockontherelation.
18.10.2 Concurrency in Index Structures
Itispossibletotreataccesstoindexstructureslikeanyotherdatabasestructureandto
applytheconcurrency-controltechniquesdiscussedearlier.However,sinceindicesare
accessedfrequently,theywouldbecomeapointofgreatlockcontention,leadingtoa
lowdegreeofconcurrency.Luckily,indicesdonothavetobetreatedlikeotherdatabase
structures; it is desirable to release index locks early, in a non-two-phase manner, to
maximize concurrency. In fact, it is perfectly acceptable for a transaction to perform
a lookup on an index twice and to find that the structure of the index has changed
in between, as long as the index lookup returns the correct set of tuples. Informally,
it is acceptable to have nonserializable concurrent access to an index, as long as the
accuracyoftheindexismaintained;weformalizethisnotionnext.
Operation serializability for index operations is defined as follows: A concurrent
execution of index operations on an index is said to be serializable if there is a se-
rialization order of the operations that is consistent with the results that each index
operation intheconcurrentexecutionsees,aswellaswiththefinalstate oftheindex
afteralltheoperationshavebeenexecuted.Indexconcurrencycontroltechniquesmust
ensurethatanyconcurrentexecutionofindexoperationsisserializable.
We outline two techniques for managing concurrent access to B+-trees as well as
anindex-concurrencycontroltechniquetopreventthephantomphenomenon.Theon-
linebibliographicalnotesreferenceothertechniquesforB+-treesaswellastechniques
forotherindexstructures.Thetechniquesthatwepresentforconcurrencycontrolon
B+-trees are based on locking, but neither two-phase locking nor the tree protocol is
employed.Thealgorithmsforlookup,insertion,anddeletionarethoseusedinChapter
14,withonlyminormodifications.
Thefirsttechniqueiscalledthecrabbingprotocol:
• Whensearchingforakeyvalue,thecrabbingprotocolfirstlockstherootnodein
sharedmode.Whentraversingdownthetree,itacquiresasharedlockonthechild
nodetobetraversedfurther.Afteracquiringthelockonthechildnode,itreleases
thelockontheparentnode.Itrepeatsthisprocessuntilitreachesaleafnode.

--- Page 915 ---

886 Chapter18 ConcurrencyControl
• Wheninsertingordeletingakeyvalue,thecrabbingprotocoltakestheseactions:
° It follows the same protocol as for searching until it reaches the desired leaf
node.Uptothispoint,itobtains(andreleases)onlysharedlocks.
° Itlockstheleafnodeinexclusivemodeandinsertsordeletesthekeyvalue.
° If it needs to split a node or coalesce it with its siblings, or redistribute key
valuesbetweensiblings,thecrabbingprotocollockstheparentofthenodein
exclusive mode. After performing these actions, it releases the locks on the
nodeandsiblings.
If the parent requires splitting, coalescing, or redistribution of key values,
theprotocolretainsthelockontheparent,andsplitting,coalescing,orredistri-
bution propagates further inthe samemanner.Otherwise,itreleasesthe lock
ontheparent.
The protocol gets its name from the way in whichcrabs advance by moving side-
ways, moving the legs on one side, then the legs on the other, and so on alternately.
Theprogressoflockingwhiletheprotocolbothgoesdownthetreeandgoesbackup
(incaseofsplits,coalescing,orredistribution)proceedsinasimilarcrab-likemanner.
Onceaparticularoperationreleasesalockonanode,otheroperationscanaccess
thatnode.Thereisapossibilityofdeadlocksbetweensearchoperationscomingdown
the tree, and splits, coalescing, or redistribution propagating up the tree. The system
caneasilyhandlesuchdeadlocksbyrestartingthesearchoperationfromtheroot,after
releasingthelocksheldbytheoperation.
Locksthatareheldforashortduration,insteadofbeingheldinatwo-phaseman-
ner,areoftenreferredtoaslatches.Latchesareusedinternallyindatabasestoachieve
mutualexclusiononshareddatastructures.Intheabovecase,locksareheldinaway
that does not ensure mutual exclusion during an insert or delete operation, yet the
resultantexecutionofindexoperationsisserializable.
Thesecondtechniqueachievesevenmoreconcurrency,avoidingevenholdingthe
lock on one node while acquiring the lock on another node; thereby, deadlocks are
avoided, and concurrencyisincreased.Thistechnique uses a modifiedversion of B+-
treescalledB-linktrees;B-linktreesrequirethateverynode(includinginternalnodes,
not just the leaves) maintain a pointer to its right sibling. This pointer is required be-
causealookupthatoccurswhileanodeisbeingsplitmayhavetosearchnotonlythat
nodebutalsothatnode’sright.
Unlike the crabbing protocol, the B-link-tree locking protocol holds locks on only
one internal node at a time. The protocol releases the lock on the current internal
node before requesting a lock on a child node (when traversing downwards), or on a
parentnode(whiletraversingupwardsduringasplitormerge).Doingsocanresultin
anomalies:for example, betweenthe time thelockon anode isreleased and the lock
on a parent is requested, a concurrent insert or delete on a sibling may cause a split
ormergeontheparent,andtheoriginalparentnodemaynolongerbeaparentofthe

--- Page 916 ---

18.10 AdvancedTopicsinConcurrencyControl 887
childnodewhenitislocked.Theprotocoldetectsandhandlessuchsituations,ensuring
operation serializability while avoiding deadlocks between operations and increasing
concurrencycomparedtothecrabbingprotocol.
Thephantomphenomenon,whereconflictsbetweenapredicatereadandaninsert
or update are not detected, can allow nonserializable executions to occur. The index-
lockingtechnique,whichwesawinSection18.4.3,preventsthephantomphenomenon
bylockingindexleafnodesinatwo-phasemanner.Instead oflockinganentireindex
leafnode,someindexconcurrency-controlschemesusekey-valuelockingonindividual
keyvalues,allowingotherkeyvaluestobeinsertedordeletedfromthesameleaf.Key-
valuelockingthusprovidesincreasedconcurrency.
Usingkey-value lockingna¨ıvely,however,would allowthephantom phenomenon
tooccur;topreventthephantomphenomenon,thenext-keylockingtechniqueisused.
In this technique, every index lookup must lock not only the keys found within the
range(orthesinglekey,incaseofapointlookup)butalsothenext-keyvalue—thatis,
thekeyvaluejustgreaterthanthelastkeyvaluethatwaswithintherange.Also,every
insertmustlocknotonlythevaluethatisinserted,butalsothenext-keyvalue.Thus,if
atransaction attemptstoinsertavalue thatwaswithintherange of theindexlookup
of another transaction, the two transactions would conflict on the key value next to
theinsertedkeyvalue.Similarly,deletesmustalsolockthenext-keyvaluetothevalue
being deletedto ensure thatconflictswith subsequent range lookups of other queries
aredetected.
18.10.3 Concurrency Control in Main-Memory Databases
Withdatastoredon harddisk,thecostofI/Ooperationsoften dominatesthecostof
transactionprocessing.WhendiskI/Oisthebottleneckcostinasystem,thereislittle
benefit from optimizing other smaller costs, such as the cost of concurrency control.
However,inamain-memorydatabase,withdiskI/Onolongerthebottleneck,systems
benefitfromreducingothercosts,suchasqueryprocessingcosts,aswesawinSection
15.8;wenowconsiderhowtoreducethecostofconcurrencycontrolinmain-memory
databases.
As we saw in Section 18.10.2, concurrency-control techniques for operations on
disk-basedindexstructuresacquirelocksonindividualnodes,toincreasethepotential
forconcurrentaccesstotheindex.However,suchlockingcomesattheincreasedcost
of acquiringthelocks. In a main-memorydatabase, where dataare inmemory, index
operations take very little time for execution. Thus, it may be acceptable to perform
locking at a coarse granularity: for example, the entire index could be locked using a
singlelatch(i.e.,shortdurationlock),theoperationperformed,andthelatchreleased.
The reduced overhead of locking has been found to make up for the slightly reduced
concurrency,andtoimproveoverallperformance.
There is another way to improve performance with in-memory indices, using
atomic instructions to carry out index updates without acquiring any latches at all.

--- Page 917 ---

888 Chapter18 ConcurrencyControl
insert(value,head){
node=newnode
node−>value=value
node−>next=head
head =node
}
Figure 18.22 Insertioncodethatisunsafewithconcurrentinserts.
Data structures implementations that support concurrent operations without requir-
inglatchesarecalledlatch-freedatastructureimplementations.
Consider a linked list, where each node has a value value and a next pointer, and
theheadofthelinkedlistisstoredinthevariablehead.Thefunctioninsert()shownin
Figure18.22 wouldworkcorrectlytoinsertanode atthe head ofthe list,ifthereare
noconcurrentinvocationsofthecodeforthesamelist.7
However, iftwoprocessesexecute theinsert() function concurrentlyon the same
list, it is possible that both of them would read the same value of variable head, and
then both would update the variable after that. The final result would contain one of
thetwonodesbeinginserted,whiletheothernodebeinginsertedwouldbelost.
Onewayofpreventingsuchaproblemistogetanexclusivelatch(shorttermlock)
onthelinkedlist,performtheinsert()function,andthenreleasethelatch.Theinsert()
functioncanbemodifiedtoacquireandreleasealatchonthelist.
An alternative implementation, which is faster in practice, is to use an atomic
compare-and-swap() instruction, abbreviated to CAS, which works as follows: The in-
structionCAS(var,oldval,newval)takesthreearguments:avariablevarandtwovalues,
oldval andnewval.Theinstructiondoesthefollowingatomically:checkifthevalueof
var is equal to oldval, and if so, set var to newval, and return success. If the value is
not equal, it returns failure. The instruction is supported by most modern processor
architectures,anditexecutesveryquickly.
Thefunctioninsert latchfree(),showninFigure18.23isamodificationofinsert()
that works correctlyeven with concurrent inserts on the same list, without obtaining
any latches.With thiscode, iftwoprocesses concurrentlyread the old value of head,
andthenbothexecutetheCASinstruction,oneofthemwillfindtheCASinstruction
returning success, while the other one will find it returning failure since the value of
head changes between the time it is read and when the CAS instruction is executed.
Therepeatloopthenretriestheinsertusingthenewvalueofhead,untilitsucceeds.
Function delete latchfree(), shown in Figure 18.23, similarly implements deletion
from the head of the list using the compare and swap instruction, without requiring
latches. (In this case, the list is used as a stack, since deletion occurs at the head of
7Weassumeallparametersarepassedbyreference.

--- Page 918 ---

18.10 AdvancedTopicsinConcurrencyControl 889
insert latchfree(head,value){
node=newnode
node−>value=value
repeat
oldhead =head
node−>next=oldhead
result=CAS(head,oldhead,node)
until(result==success)
}
delete latchfree(head){
/*Thisfunctionisnotquitesafe;seeexplanationintext.*/
repeat
oldhead =head
newhead =oldhead−>next
result=CAS(head,oldhead,newhead)
until(result==success)
}
Figure 18.23 Latch-free insertionanddeletiononalist.
thelist.)However,ithasaproblem:itdoesnotworkcorrectlyinsomerarecases.The
problemcanoccurwhenaprocessP1isperformingadelete,withnoden1atthehead
ofthelist,andconcurrentlyasecondprocessP2deletesthefirsttwoelements,n1and
n2, and then reinserts n1 at the head of the list, with some other element, say n3 as
the next element. If P1 read n1 before P2 deleted it, but performs the CAS after P2
has reinserted n1, the CAS operation of P1 will succeed, but set the head of the list
to point to n2, which has been deleted, leaving the list in an inconsistent state. This
problemisknownastheABAproblem.
One solution is to keep a counter along with each pointer, which is incremented
every time the pointer is updated. The CAS instruction is applied on the (pointer,
counter)pair;mostCASimplementationson64bitprocessorssupportsuchadouble
compare-and-swapon128bits.TheABAproblemcanthenbeavoidedsincealthough
thereinsertofn1wouldresultintheheadpointington1,thecounterwouldbediffer-
ent, resultingin the CAS operation of P1 failing. See the online solutions to Practice
Exercise18.16formoredetailsoftheABAproblemandtheabovesolution.Withsuch
amodification,bothinserts anddeletescanbe executed concurrentlywithoutacquir-
inglatches.Thereareothersolutionsthatdonotrequireadoublecompare-and-swap,
butaremorecomplicated.
Deletionfromthetailofthelist(toimplementaqueue)aswellasmorecomplex
datastructuressuchashashindicesandsearchtreescanalsobeimplementedinalatch-

--- Page 919 ---

890 Chapter18 ConcurrencyControl
free manner. It is best to use latch-free data structure implementations (more often
referred to as lock-freedata structure implementations)that are provided by standard
libraries, such as the Boost library for C++, or the ConcurrentLinkedQueue class in
Java; do not build your own, since you may introduce bugs due to “race conditions”
betweenconcurrentaccesses,thatcanbeveryhardtodetectordebug.
Sincetoday’smultiprocessorCPUshavealargenumberofcores,latch-freeimple-
mentations have been found to significantly outperform implementations that obtain
latches,inthecontextofin-memoryindicesandotherin-memorydatastructures
18.10.4 Long-Duration Transactions
The transaction concept developed initiallyin the context of data-processing applica-
tions, in which most transactions are noninteractive and of short duration. Serious
problems arise when this concept is applied to database systems that involve human
interaction.Suchtransactionshavethesekeyproperties:
• Longduration.Onceahumaninteractswithanactivetransaction,thattransaction
becomes a long-duration transaction from the perspective of the computer, since
human response time is slow relative to computer speed. Furthermore, in design
applications,thehumanactivitymayinvolvehours,days,oranevenlongerperiod.
Thus,transactionsmaybeoflongdurationinhumanterms,aswellasinmachine
terms.
• Exposure of uncommitted data. Data generated and displayed to a user by along-
duration transaction are uncommitted, since the transaction may abort. Thus,
users—and, as a result, other transactions—may be forced to read uncommitted
data. If several users are cooperating on a project, user transactions may need to
exchangedatapriortotransactioncommit.
• Subtasks. An interactive transaction may consist of a set of subtasks initiated by
the user. The user may wish to abort a subtask without necessarily causing the
entiretransactiontoabort.
• Recoverability. It is unacceptable to abort a long-duration interactive transaction
becauseofasystemcrash.Theactivetransactionmustberecoveredtoastatethat
existedshortlybeforethecrashsothatrelativelylittlehumanworkislost.
• Performance.Goodperformanceinaninteractivetransactionsystemisdefinedas
fastresponsetime.Thisdefinitionisincontrasttothatinanoninteractivesystem,
inwhichhighthroughput(numberoftransactionspersecond)isthegoal.Systems
withhighthroughputmakeefficientuseofsystemresources.However,inthecase
ofinteractivetransactions,themostcostlyresourceistheuser.Iftheefficiencyand
satisfactionof theuserare tobe optimized,response timeshould be fast (from a
humanperspective).Inthosecaseswhereatasktakesalongtime,responsetime

--- Page 920 ---

18.10 AdvancedTopicsinConcurrencyControl 891
T T
1 2
read(A)
A:=A−50
write(A)
read(B)
B:=B−10
write(B)
read(B)
B:=B+50
write(B)
read(A)
A:=A+10
write(A)
Figure 18.24 Anon-conflict-serializable schedule.
should be predictable(i.e.,thevariance inresponse timesshould be low)sothat
userscanmanagetheirtimewell.
Snapshot isolation, described in Section 18.8, can provide a partial solution to
these issues, as can the optimistic concurrency control without read validation protocol
described in Section 18.9.3. The latter protocol was in fact designed specifically to
deal with long-duration transactions that involve user interaction. Although it does
notguaranteeserializability,optimisticconcurrencycontrolwithoutreadvalidationis
quitewidelyused.
However, when transactions are of long duration, conflicting updates are more
likely,resultinginadditionalwaitsoraborts.Theseconsiderationsarethebasisforthe
alternativeconceptsofcorrectnessofconcurrentexecutionsandtransactionrecovery
thatweconsiderintheremainderofthissection.
18.10.5 Concurrency Control with Operations
Consider a bank database consisting of two accounts A and B, with the consistency
requirementthatthe sum A + B be preserved. Consider the schedule of Figure18.24.
Althoughthescheduleisnotconflictserializable,itneverthelesspreservesthesumof
A+B.Italsoillustratestwoimportantpointsabouttheconceptofcorrectnesswithout
serializability.
1. Correctnessdependsonthespecificconsistencyconstraintsforthedatabase.
2. Correctnessdependsonthepropertiesofoperationsperformedbyeachtransac-
tion.

--- Page 921 ---

892 Chapter18 ConcurrencyControl
While two-phase locking ensures serializability, it can result in poor concurrency
in case a large number of transactions conflict on a particular data item. Timestamp
andvalidationprotocolsalsohavesimilarproblemsinthiscase.
Concurrencycanbeincreasedbytreatingsomeoperationsbesidesreadandwrite
as fundamental low-level operations and to extend concurrency control to deal with
them.
Consider the case of materialized view maintenance, which we saw in Section
16.5.1. Suppose there is a relation sales(date, custID, itemID, amount), and a materi-
alized view daily sales total(date, total amount), that records total sales on each day.
Every sales transaction must update the materialized view as part of the transaction
if immediateview maintenance is used. With a high volume of sales, and everytrans-
actionupdatingthesamerecordinthedaily sales total relation,thedegreeofconcur-
rencywillbequitelowiftwo-phaselockingisusedonthematerializedview.
Abetterwaytoperformconcurrencycontrolforthematerializedviewisasfollows:
Observe that each transaction increments a record in the daily sales total relation by
somevaluebutdoesnotneedtoseethevalue.Itwouldmakesensetohaveanoperation
increment(v,n),thataddsavaluentoavariablevwithoutmakingthevalueofvvisible
tothetransaction;weshallseeshortlyhowthisisimplemented.Inoursalesexample,
atransactionthatinsertsasalestuplewithamountninvokestheincrementoperation
with the first argument being the total amount value of the appropriate tuple in the
materializedviewdaily sales total,andthesecondargumentbeingthevaluen.
Theincrementoperationdoesnotlockthevariableinatwo-phasemanner;how-
ever, individual operations should be executed serially on the variable. Thus, if two
increment operations are initiated concurrently on the same variable, one must fin-
ish before the otherisallowedto start. Thiscan be ensured by acquiringan exclusive
latch(lock)onthevariablevbeforestartingtheoperationandreleasingthelatchafter
theoperationhasfinisheditsupdates.Incrementoperationscanalsobeimplemented
usingcompare-and-swapoperations,withoutgettinglatches.
Twotransactionsthatinvoketheincrementoperationshouldbeallowedtoexecute
concurrently to avoid concurrency control bottlenecks. In fact, increment operations
executed by two transactions do not conflict with each other, since the final result is
the same regardless of the order in whichthe operations wereexecuted. If one of the
transactions rolls back, the increment(v,n) operation must be rolled back by execut-
ing an operation increment(v,−n), which adds a negative of the original value; this
operationisreferredtoasacompensatingoperation.
However,ifatransactionT wishestoreadthematerializedview,itclearlyconflicts
withanyconcurrenttransactionthathasperformedanincrementoperation;thevalue
thatT readsdependsonwhethertheothertransactionisserializedbeforeorafterT.
Wecandefinealockingprotocoltohandletheprecedingsituationbydefiningan
incrementlock.Theincrementlockiscompatiblewithitselfbutisnotcompatiblewith
shared and exclusive locks. Figure 18.25 shows a lock-compatibility matrix for three
lockmodes:sharemode,exclusivemode,andincrementmode.

--- Page 922 ---

18.10 AdvancedTopicsinConcurrencyControl 893
S X I
S true false false
X false false false
I false false true
Figure 18.25 Lock-compatibility matrixwithincrementlockmode.
As another example of special-purpose concurrency control for operations, con-
sider an insert operation on a B+-tree index which releases locks early, as we saw in
Section 18.10.2. In this case, there is no special lock mode, but holding locks on leaf
nodesinatwo-phasemanner(orusingnext-keylocking)aswesawinSection18.10.2
ensuresserializability.TheinsertoperationmayhavemodifiedseveralnodesoftheB+-
tree index. Other transactions may have read and updated these nodes further while
processing other operations. To roll back the insertion, we would have to delete the
recordinsertedbyT;deletionisthecompensatingactionforinsertion.Theresultisa
i
correct,consistentB+-tree,butnotnecessarilyonewithexactlythesamestructureas
theonewehadbeforeT started.
i
Whileoperationlockingcanbedoneinawaythatensuresserializability,insome
cases it may even be used in a way that does not guarantee serializability, but where
violationsmaybeacceptable.Considerthecaseofconcerttickets,whereeverytransac-
tionneedstoaccessandupdatethetotalticketsales.Wecanhaveanoperationincre-
ment conditional(v,n)whichincrementsvbyn,providedtheresultantvaluewouldbe
≥ 0;theoperationreturnsastatusofsuccessincasetheresultantvalueis≥ 0andre-
turnsfailureotherwise.ConsideratransactionT executedtopurchasetickets.Tobook
i
threetickets,wherevariableavail ticketsindicatesthenumberofavailabletickets,the
transaction can execute increment conditional(avail tickets, −3). A return value of
success indicates that there were enough tickets available, and decrements the avail-
abletickets,whilefailureindicatesinsufficientavailabilityoftickets.
Ifthevariableavail ticketsislockedinatwo-phasemanner,concurrencywouldbe
verypoor,withcustomersbeingforcedtowaitforbookingswhileanearliertransaction
commits, even when there are many tickets available. Concurrency can be greatly in-
creasedbyexecutingtheincrement conditionaloperation,withoutholdinganylocks
on avail tickets in a two-phase manner; instead, an exclusive lock is obtained on the
variable,theoperationisperformed,andthelockisthenreleased.
Thetransaction T alsoneedstocarryoutothersteps, suchascollectingthepay-
i
ment; if one of the subsequent steps, such as payment, fails, the incrementoperation
must be rolled back by executing a compensating operation; if the original operation
added−ntoavail tickets,thecompensatingoperationadds+ntoavail tickets.
It may appear that two increment conditional operations are compatible with
each other, similar to the increment operation that we saw earlier. But that is not

--- Page 923 ---

894 Chapter18 ConcurrencyControl
thecase.Considertwoconcurrenttransactionstopurchaseasingleticket,andassume
thatthereisonlyoneticketleft.Theorderinwhichtheoperationsareexecutedhasan
obvious impact on which one succeeds and which one fails. Nevertheless, many real-
worldapplicationsallowoperationsthatholdshort-termlockswhiletheyexecuteand
release them at the end of the operation to increase concurrency, even at the cost of
lossofserializabilityinsomesituations.
18.10.6 Real-Time Transaction Systems
Incertainapplications,theconstraintsincludedeadlinesbywhichataskmustbecom-
pleted. Examples of such applications includeplant management, traffic control,and
scheduling. When deadlines are included, correctness of an execution is no longer
solelyanissueofdatabaseconsistency.Rather,weareconcernedwithhowmanydead-
linesaremissed,andbyhowmuchtimetheyaremissed.Deadlinesarecharacterized
asfollows:
• Harddeadline.Seriousproblems,suchassystemcrash,mayoccurifataskisnot
completedbyitsdeadline.
• Firmdeadline.Thetaskhaszerovalueifitiscompletedafterthedeadline.
• Softdeadlines.Thetaskhasdiminishingvalueifitiscompletedafterthedeadline,
withthevalueapproachingzeroasthedegreeoflatenessincreases.
Systemswithdeadlinesarecalledreal-timesystems.
Transaction management in real-time systems must take deadlines into account.
Iftheconcurrency-controlprotocoldeterminesthatatransactionT mustwait,itmay
i
causeT tomissthedeadline.Insuchcases,itmaybepreferabletopre-emptthetrans-
i
action holding the lock, and to allow T to proceed. Pre-emption must be used with
i
care, however, because the time lost by the pre-empted transaction (due to rollback
andrestart)maycausethepre-emptedtransactiontomissitsdeadline.Unfortunately,
itisdifficulttodeterminewhetherrollbackorwaitingispreferableinagivensituation.
Due to the unpredictable nature of delays when reading data from disk, main-
memorydatabasesareoftenusedifreal-timeconstraintshavetobemet.However,even
ifdataareresidentinmainmemory,variancesinexecutiontimearisefromlockwaits,
transactionaborts,andsoon.Researchershavedevotedconsiderableefforttoconcur-
rencycontrolforreal-timedatabases.Theyhaveextendedlockingprotocolstoprovide
higher priority for transactions with early deadlines. They have found that optimistic
concurrencyprotocolsperformwellinreal-timedatabases;thatis,theseprotocolsre-
sult in fewer missed deadlines than even the extended locking protocols. The online
bibliographicalnotesprovidereferencestoresearchintheareaofreal-timedatabases.
18.11 Summary
• When several transactions execute concurrently in the database, the consistency
ofdatamaynolongerbepreserved.Itisnecessaryforthesystemtocontrolthein-

--- Page 924 ---

18.11 Summary 895
teractionamongtheconcurrenttransactions,andthiscontrolisachievedthrough
oneofavarietyofmechanismscalledconcurrency-control schemes.
• To ensure serializability, we can use various concurrency-control schemes. All
these schemes either delay an operation or abort the transaction that issued the
operation. The most common ones are locking protocols, timestamp-ordering
schemes,validationtechniques,andmultiversionschemes.
• A locking protocol is a set of rules that state when a transaction may lock and
unlockeachofthedataitemsinthedatabase.
• Thetwo-phaselockingprotocolallowsatransactiontolockanewdataitemonly
ifthattransactionhasnotyetunlockedanydataitem.Theprotocolensuresserial-
izability,butnotdeadlockfreedom.Intheabsenceofinformationconcerningthe
mannerinwhichdataitemsare accessed,the two-phase lockingprotocol isboth
necessaryandsufficientforensuringserializability.
• The strict two-phase locking protocol permits release of exclusive locks only at
the end of transaction, in order to ensure recoverability and cascadelessness of
theresultingschedules.Therigoroustwo-phaselockingprotocolreleasesalllocks
onlyattheendofthetransaction.
• Various locking protocols do not guard against deadlocks. One way to prevent
deadlock is to use an ordering of data items and to request locks in a sequence
consistentwiththeordering.
• Anotherwaytopreventdeadlockistouse preemptionandtransactionrollbacks.
Tocontrolthepreemption,weassignauniquetimestamptoeachtransaction.The
system usesthesetimestampstodecidewhetheratransactionshouldwaitorroll
back.Thewound–waitschemeisapreemptivescheme.
• Ifdeadlocksarenotprevented,thesystemmustdealwiththembyusingadeadlock
detectionand recoveryscheme.Todoso,thesystem constructsawait-forgraph.
A system is in a deadlock state if and only if the wait-for graph contains a cycle.
When the deadlock detection algorithm determines that a deadlock exists, the
systemrollsbackoneormoretransactionstobreakthedeadlock.
• There are circumstances where it would be advantageous to group several data
items and to treat them as one aggregate data item for purposes of working, re-
sultinginmultiplelevelsofgranularity.Weallowdataitemsofvarioussizes,and
wedefineahierarchyofdataitemswherethesmallitemsarenestedwithinlarger
ones. Such a hierarchy can be represented graphically as a tree. In such multi-
granularitylockingprotocols,locksareacquiredinroot-to-leaforder;theyarere-
leased in leaf-to-root order. Intention lock modes are used at higher levels to get
betterconcurrency,withoutaffectingserializability.

--- Page 925 ---

896 Chapter18 ConcurrencyControl
• A timestamp-ordering scheme ensures serializability by selecting an ordering in
advancebetweeneverypairoftransactions.Auniquefixedtimestampisassociated
witheachtransactioninthesystem.Thetimestampsofthetransactionsdetermine
theserializabilityorder.Thus,ifthetimestampoftransactionT issmallerthanthe
i
timestampoftransactionT,thentheschemeensuresthattheproducedschedule
j
isequivalenttoaserialscheduleinwhichtransactionT appearsbeforetransaction
i
T.Itdoessobyrollingbackatransactionwheneversuchanorderisviolated.
j
• Avalidationschemeisanappropriateconcurrency-controlmethodincaseswhere
amajorityoftransactionsareread-onlytransactions,andthustherateofconflicts
amongthesetransactionsislow.Auniquefixedtimestampisassociatedwitheach
transactioninthesystem.Theserializabilityorderisdeterminedbythetimestamp
ofthetransaction.Atransactioninthisschemeisneverdelayed.Itmust,however,
passavalidationtesttocomplete.Ifitdoesnotpassthevalidationtest,thesystem
rollsitbacktoitsinitialstate.
• Amultiversionconcurrency-controlschemeisbasedonthecreationofanewver-
sionofadataitemforeachtransactionthatwritesthatitem.Whenareadopera-
tionisissued,thesystemselectsoneoftheversionstoberead.Theconcurrency-
control scheme ensures that the version to be read is selected in a manner that
ensuresserializabilitybyusingtimestamps.Areadoperationalwayssucceeds.
° Inmultiversiontimestampordering,awriteoperationmayresultintherollback
ofthetransaction.
° In multiversion two-phase locking, write operations may result in a lock wait
or,possibly,indeadlock.
• Snapshotisolationisamultiversionconcurrency-controlprotocolbasedonvalida-
tion, which,unlike multiversion two-phase locking, does not require transactions
to be declared as read-only or update. Snapshot isolation does not guarantee se-
rializabilitybutisneverthelesssupported bymanydatabasesystems. Serializable
snapshotisolationisanextensionofsnapshotisolationwhichguaranteesserializ-
ability.
• Adeleteoperationmaybeperformedonlyifthetransactiondeletingthetuplehas
anexclusivelockonthetupletobedeleted.Atransactionthatinsertsanewtuple
intothedatabaseisgivenanexclusivelockonthetuple.
• Insertionscanleadtothephantom phenomenon, inwhichan insertionlogically
conflicts with a query even though the two transactions may access no tuple in
common. Such conflict cannot be detected if locking is done only on tuples ac-
cessedbythetransactions.Lockingisrequiredonthedatausedtofindthetuples
intherelation.Theindex-lockingtechniquesolvesthisproblembyrequiringlocks
oncertainindexnodes.Theselocksensurethatallconflictingtransactionsconflict
onarealdataitem,ratherthanonaphantom.

--- Page 926 ---

ReviewTerms 897
• Weak levels of consistency are used in some applications where consistency
of query results is not critical, and using serializability would result in queries
adversely affecting transaction processing. Degree-two consistency is one such
weaker level of consistency; cursor stability is a special case of degree-two con-
sistencyandiswidelyused.
• Concurrencycontrolisachallengingtaskfortransactionsthatspanuserinterac-
tions.Applicationsoftenimplementaschemebasedonvalidationofwritesusing
versionnumbersstoredintuples;thisschemeprovidesaweaklevelofserializabil-
ity and can be implemented at the application level without modificationsto the
database.
• Special concurrency-control techniques can be developed for special data struc-
tures. Often, special techniques are applied in B+-trees to allow greater concur-
rency. These techniques allow nonserializable access to the B+-tree, but they en-
sure that the B+-tree structure is correct, and they ensure that accesses to the
database itself are serializable. Latch-free data structures are used to implement
high-performanceindicesandotherdatastructuresinmain-memorydatabases.
Review Terms
• Concurrencycontrol ° Stricttwo-phaselocking
• Locktypes ° Rigoroustwo-phaselocking
° Shared-mode(S)lock • Lockconversion
° Exclusive-mode(X)lock
° Upgrade
• Lock ° Downgrade
° Compatibility • Graph-basedprotocols
° Request
° Treeprotocol
° Wait
° Commitdependency
° Grant
• Deadlockhandling
• Deadlock
° Prevention
• Starvation
° Detection
• Lockingprotocol
• Legalschedule ° Recovery
• Two-phaselockingprotocol • Deadlockprevention
° Growingphase ° Orderedlocking
° Shrinkingphase ° Preemptionoflocks
° Lockpoint ° Wait–diescheme

--- Page 927 ---

898 Chapter18 ConcurrencyControl
° Wound–waitscheme ° Writephase
° Timeout-basedschemes ° Validationtest
• Deadlockdetection • Multiversiontimestampordering
° Wait-forgraph • Multiversiontwo-phaselocking
• Deadlockrecovery ° Read-onlytransactions
° Totalrollback ° Updatetransactions
° Partialrollback • Snapshotisolation
• Multiplegranularity ° Lostupdate
° Explicitlocks ° Firstcommitterwins
° Implicitlocks ° Firstupdaterwins
° Intentionlocks ° Writeskew
• Intentionlockmodes ° Selectforupdate
° Intention-shared(IS) • Insertanddeleteoperations
• Phantomphenomenon
° Intention-exclusive(IX)
• Index-lockingprotocol
° Sharedandintention-
• Predicatelocking
exclusive(SIX)
• Weaklevelsofconsistency
• Multiple-granularitylocking
° Degree-twoconsistency
protocol
• Timestamp ° Cursorstability
° Systemclock • Optimisticconcurrencycontrolwith-
outreadvalidation
° Logicalcounter
• Conversations
° W-timestamp(Q) • Concurrencyinindices
° R-timestamp(Q)
° Crabbingprotocol
• Timestamp-orderingprotocol
° B-linktrees
° Thomas’writerule
° B-link-treelockingprotocol
• Validation-basedprotocols
° Next-keylocking
° Readphase • Latch-freedatastructures
° Validationphase • Compare-and-swap(CAS)instruction

--- Page 928 ---

PracticeExercises 899
Practice Exercises
18.1 Show that the two-phase locking protocol ensures conflict serializability and
thattransactionscanbeserializedaccordingtotheirlockpoints.
18.2 Considerthefollowingtwotransactions:
T : read(A);
34
read(B);
ifA = 0thenB:=B+1;
write(B).
T : read(B);
35
read(A);
ifB = 0thenA:=A+1;
write(A).
AddlockandunlockinstructionstotransactionsT andT sothattheyob-
31 32
servethetwo-phaselockingprotocol.Cantheexecutionofthesetransactions
resultinadeadlock?
18.3 Whatbenefit doesrigorous two-phase lockingprovide?How doesitcompare
withotherformsoftwo-phaselocking?
18.4 Consider a database organized in the form of a rooted tree. Suppose that we
insert a dummy vertex between each pair of vertices. Show that, if we follow
thetreeprotocolonthenewtree,wegetbetterconcurrencythanifwefollow
thetreeprotocolontheoriginaltree.
18.5 Showbyexamplethatthereareschedulespossibleunderthetreeprotocolthat
arenotpossibleunderthetwo-phaselockingprotocol,andviceversa.
18.6 Locking is not done explicitly in persistent programming languages. Rather,
objects(orthecorrespondingpages)mustbelockedwhentheobjectsareac-
cessed.Mostmodernoperatingsystemsallowtheusertosetaccessprotections
(no access, read, write) on pages, and memory access that violate the access
protectionsresultinaprotectionviolation(seetheUnixmprotectcommand,
forexample).Describehowtheaccess-protectionmechanismcanbeusedfor
page-levellockinginapersistentprogramminglanguage.
18.7 Consider a database system that includes an atomic increment operation, in
additiontothereadandwriteoperations. LetVbethevalueofdataitemX.
Theoperation
increment(X)byC

--- Page 929 ---

900 Chapter18 ConcurrencyControl
sets the value of X to V + C in an atomicstep. The value of X is notavailable
tothetransactionunlessthelatterexecutesaread(X).
Assumethatincrementoperationslocktheiteminincrementmodeusingthe
compatibilitymatrixinFigure18.25.
a. Showthat,ifalltransactionslockthedatathattheyaccessinthecorre-
spondingmode,thentwo-phaselockingensuresserializability.
b. Show that the inclusion of increment mode locks allows for increased
concurrency.
18.8 Intimestampordering,W-timestamp(Q)denotesthelargesttimestampofany
transactionthatexecutedwrite(Q)successfully.Supposethat,instead,wede-
finedittobethetimestampofthemostrecenttransactiontoexecutewrite(Q)
successfully.Wouldthischangeinwordingmakeanydifference?Explainyour
answer.
18.9 Use of multiple-granularity locking may require more or fewer locks than an
equivalentsystemwithasinglelockgranularity.Provideexamplesofbothsit-
uations,andcomparetherelativeamountofconcurrencyallowed.
18.10 Foreachofthefollowingprotocols,describeaspectsofpracticalapplications
thatwouldleadyoutosuggestusingtheprotocol,andaspectsthatwouldsug-
gestnotusingtheprotocol:
• Two-phaselocking
• Two-phaselockingwithmultiple-granularitylocking.
• Thetreeprotocol
• Timestampordering
• Validation
• Multiversiontimestampordering
• Multiversiontwo-phaselocking
18.11 Explain why the following technique for transaction execution may provide
better performance than just using strict two-phase locking: First execute the
transaction without acquiring any locks and without performing any writes
tothedatabaseasinthevalidation-basedtechniques,butunlikethevalidation
techniquesdonotperformeithervalidationorwritesonthedatabase.Instead,
rerunthetransactionusingstricttwo-phaselocking.(Hint:Considerwaitsfor
diskI/O.)
18.12 Consider the timestamp-ordering protocol, and two transactions, one that
writestwodataitemspandq,andanotherthatreadsthesametwodataitems.

--- Page 930 ---

PracticeExercises 901
Give a schedule whereby the timestamp test for a write operation fails and
causes the first transaction to be restarted, in turn causing a cascading abort
oftheothertransaction.Showhowthiscouldresultinstarvationofbothtrans-
actions.(Suchasituation,wheretwoormoreprocessescarryoutactions,but
are unable to complete their task because of interaction with the other pro-
cesses,iscalledalivelock.)
18.13 Deviseatimestamp-basedprotocolthatavoidsthephantomphenomenon.
18.14 SupposethatweusethetreeprotocolofSection18.1.5tomanageconcurrent
accesstoaB+-tree.Sinceasplitmayoccuronaninsertthataffectstheroot,it
appearsthataninsertoperationcannotreleaseanylocksuntilithascompleted
theentireoperation.Underwhatcircumstancesisitpossibletoreleasealock
earlier?
18.15 Thesnapshotisolationprotocolusesavalidationstepwhich,beforeperform-
ingawriteofadataitembytransactionT,checksifatransactionconcurrent
withT hasalreadywrittenthedataitem.
a. Astraightforwardimplementationusesastarttimestampandacommit
timestampforeachtransaction,inadditiontoanupdateset,that,isthe
set of data items updated by the transaction. Explain how to perform
validation for the first-committer-wins scheme by using the transaction
timestampsalongwiththeupdatesets.Youmayassumethatvalidation
andothercommitprocessingstepsareexecutedserially,thatis,forone
transactionatatime,
b. Explainhowthevalidationstepcanbeimplementedaspartofcommit
processing for the first-committer-winsscheme, using a modificationof
the above scheme, where instead of using update sets, each data item
has a write timestamp associated with it. Again, you may assume that
validationandothercommitprocessingstepsareexecutedserially.
c. Thefirst-updater-winsschemecanbeimplementedusingtimestampsas
describedabove,exceptthatvalidationisdoneimmediatelyafteracquir-
inganexclusivelock,insteadofbeingdoneatcommittime.
i. Explainhowtoassignwritetimestampstodataitemstoimplement
thefirst-updater-winsscheme.
ii. Showthatasaresultoflocking,ifthevalidationisrepeatedatcom-
mittimetheresultwouldnotchange.
iii. Explainwhythereisnoneedtoperformvalidationandothercommit
processingstepsseriallyinthiscase.
18.16 Consider functions insert latchfree() and delete latchfree(), shown in Figure
18.23.

--- Page 931 ---

902 Chapter18 ConcurrencyControl
a. ExplainhowtheABAproblemcanoccurifadeletednodeisreinserted.
b. Supposethatadjacenttohead westoreacountercnt.Alsosupposethat
DCAS((head,cnt),(oldhead,oldcnt),(newhead,newcnt))atomicallyper-
formsacompare-and-swaponthe128bitvalue(head,cnt).Modifythein-
sert latchfree()anddelete latchfree()tousetheDCASoperationtoavoid
theABAproblem.
c. Since most processors use only 48 bits of a 64 bit address to actually
addressmemory,explainhowtheother16bitscanbeusedtoimplement
acounter,incasetheDCASoperationisnotsupported.
Exercises
18.17 What benefit does strict two-phase locking provide? What disadvantages re-
sult?
18.18 Most implementationsof database systems use strict two-phase locking. Sug-
gestthreereasonsforthepopularityofthisprotocol.
18.19 Consideravariantofthetreeprotocolcalledtheforestprotocol.Thedatabase
is organized as a forest of rooted trees. Each transaction T must follow the
i
followingrules:
• Thefirstlockineachtreemaybeonanydataitem.
• The second, and all subsequent, locks in a tree may be requested only if
theparentoftherequestednodeiscurrentlylocked.
• Dataitemsmaybeunlockedatanytime.
• AdataitemmaynotberelockedbyT afterithasbeenunlockedbyT.
i i
Showthattheforestprotocoldoesnotensureserializability.
18.20 Under what conditions is it less expensive to avoid deadlock than to allow
deadlockstooccurandthentodetectthem?
18.21 Ifdeadlockisavoidedbydeadlock-avoidanceschemes,isstarvationstillpossi-
ble?Explainyouranswer.
18.22 In multiple-granularity locking, what is the difference between implicit and
explicitlocking?
18.23 AlthoughSIXmodeisusefulinmultiple-granularitylocking,anexclusiveand
intention-shared(XIS)modeisofnouse.Whyisituseless?
18.24 Themultiple-granularityprotocolrulesspecifythatatransactionT canlocka
i
nodeQinSorISmodeonlyifT currentlyhastheparentofQlockedineither
i

--- Page 932 ---

Exercises 903
IX or IS mode. Given that SIX and S locks are stronger than IX or IS locks,
whydoestheprotocolnotallowlockinganodeinSor ISmodeiftheparent
islockedineitherSIXorSmode?
18.25 Supposethelockhierarchyforadatabaseconsistsofdatabase,relations,and
tuples.
a. Ifatransactionneedstoreadalotoftuplesfromarelationr,whatlocks
shoulditacquire?
b. Now suppose the transaction wants to update a few of the tuples in r
afterreadingalotoftuples.Whatlocksshoulditacquire?
c. Ifatrun-timethetransactionfindsthatitneedstoactuallyupdateavery
largenumberoftuples(afteracquiringlocksassumingonlyafewtuples
would be updated). What problems would this cause to the lock table,
andwhatcouldthedatabasedotoavoidtheproblem?
18.26 When a transaction is rolled-back under timestamp ordering, it is assigned a
newtimestamp.Whycanitnotsimplykeepitsoldtimestamp?
18.27 Show that there are schedules that are possible under the two-phase locking
protocolbutnotpossibleunderthetimestampprotocol,andviceversa.
18.28 Underamodifiedversionofthetimestampprotocol,werequirethatacommit
bit be tested to see whether a read request must wait. Explain how the com-
mit bit can prevent cascading abort. Why is this test not necessary for write
requests?
18.29 As discussed in Exercise 18.15, snapshot isolation can be implemented using
aform of timestampvalidation. However,unlike the multiversion timestamp-
orderingscheme,whichguaranteesserializability,snapshotisolationdoesnot
guaranteeserializability.Explainthekeydifferencebetweentheprotocolsthat
resultsinthisdifference.
18.30 Outline the key similarities and differencesbetween the timestamp-based im-
plementation of the first-committer-wins version of snapshot isolation, de-
scribedinExercise18.15,andtheoptimistic-concurrencycontrol-without-read-
validationscheme,describedinSection18.9.3.
18.31 Considerarelationr(A,B,C)andatransactionT thatdoesthefollowing:find
themaximumAvalueinr,andinsertanewtupleinrwhoseAvalueis1+the
maximumAvalue.AssumethatanindexisusedtofindthemaximumAvalue.
a. Suppose that the transaction locks each tuple it reads in S mode, and
thetupleitcreatesinXmode,andperformsnootherlocking.Nowsup-
posetwoinstancesofT arerunconcurrently.Explainhowtheresultant
executioncouldbenon-serializable.

--- Page 933 ---

904 Chapter18 ConcurrencyControl
b. Now suppose thatr.A isdeclaredasaprimarykey. Can theabove non-
serializableexecutionoccurinthiscase?Explainwhyorwhynot.
18.32 Explain the phantom phenomenon. Why may this phenomenon lead to an
incorrectconcurrentexecutiondespitetheuseofthetwo-phaselockingproto-
col?
18.33 Explainthereasonfortheuseofdegree-twoconsistency.Whatdisadvantages
doesthisapproachhave?
18.34 Giveexampleschedulestoshowthatwithkey-valuelocking,iflookup,insert,
ordeletedoesnotlockthenext-keyvalue,thephantomphenomenoncouldgo
undetected.
18.35 Manytransactionsupdateacommonitem(e.g.,thecashbalanceatabranch)
andprivateitems(e.g.,individualaccountbalances).Explainhowyoucanin-
creaseconcurrency(andthroughput)byorderingtheoperationsofthetrans-
action.
18.36 Consider the following locking protocol: All items are numbered, and once
an item is unlocked, only higher-numbered items may be locked. Locks may
be releasedatany time.OnlyX-locks areused. Show by an example thatthis
protocoldoesnotguaranteeserializability.
Further Reading
[Gray and Reuter (1993)] provides detailed textbook coverage of transaction-
processingconcepts,includingconcurrency-controlconceptsandimplementationde-
tails.[BernsteinandNewcomer(2009)]providestextbookcoverageofvariousaspects
oftransactionprocessingincludingconcurrencycontrol.
The two-phase locking protocol was introduced by [Eswaran et al. (1976)]. The
locking protocol for multiple-granularity data items is from [Gray et al. (1975)]. The
timestamp-based concurrency-control scheme is from [Reed (1983)]. The validation
concurrency-controlschemeisfrom[KungandRobinson(1981)].Multiversiontimes-
tamp order was introduced in [Reed (1983)]. A multiversion tree-locking algorithm
appearsin[Silberschatz(1982)].
Degree-twoconsistencywasintroducedin[Grayetal.(1975)]. Thelevelsofcon-
sistency—or isolation—offeredin SQLare explained and critiquedin [Berenson etal.
(1995)];thesnapshotisolationtechniquewasalsointroducedinthesamepaper.Seri-
alizablesnapshot-isolationwasintroducedby[Cahilletal.(2009)];[PortsandGrittner
(2012)]describestheimplementationofserializablesnapshotisolationinPostgreSQL.
ConcurrencyinB+-treeswasstudiedby[BayerandSchkolnick(1977)]and[John-
son andShasha(1993)]. ThecrabbingandB-linktreetechniqueswereintroducedby
[KungandLehman(1980)]and[LehmanandYao(1981)].Thetechniqueofkey-value
lockingusedinARIESprovidesforveryhighconcurrencyonB+-treeaccessandisde-

--- Page 934 ---

FurtherReading 905
scribed in [Mohan (1990)] and [Mohan and Narang (1992)]. [Faerber et al. (2017)]
provide a survey of main-memory databases, including coverage of concurrency con-
trol in main-memory databases. The ABA problem with latch-free data structures as
wellassolutionsfortheproblemarediscussedin[Dechevetal.(2010)].
Bibliography
[BayerandSchkolnick(1977)] R.BayerandM.Schkolnick,“ConcurrencyofOperatingon
B-trees”,ActaInformatica,Volume9,Number1(1977),pages1–21.
[Berensonetal.(1995)] H. Berenson, P. Bernstein, J. Gray, J. Melton, E. O’Neil, and
P.O’Neil,“ACritiqueofANSISQLIsolationLevels”,InProc.oftheACMSIGMODConf.
onManagementofData(1995),pages1–10.
[BernsteinandNewcomer(2009)] P.A.BernsteinandE.Newcomer,PrinciplesofTransaction
Processing,2ndedition,MorganKaufmann(2009).
[Cahilletal.(2009)] M. J. Cahill, U. Ro¨hm, and A. D. Fekete, “Serializable isolation for
snapshotdatabases”,ACMTransactionsonDatabaseSystems,Volume34,Number4(2009),
pages20:1–20:42.
[Dechevetal.(2010)] D.Dechev,P.Pirkelbauer,andB.Stroustrup,“UnderstandingandEf-
fectively Preventing the ABA Problem in Descriptor-Based Lock-Free Designs”, In IEEE
Int’lSymp.onObject/Component/Service-OrientedReal-TimeDistributedComputing,(ISORC)
(2010),pages185–192.
[Eswaranetal.(1976)] K.P.Eswaran,J.N.Gray,R.A.Lorie,andI.L.Traiger,“TheNotions
of Consistency and Predicate Locks in a Database System”, Communications of the ACM,
Volume19,Number11(1976),pages624–633.
[Faerberetal.(2017)] F.Faerber,A.Kemper,P.-A.Larson,J.Levandoski,T.Neumann,and
A.Pavlo,“MainMemoryDatabaseSystems”,FoundationsandTrendsinDatabases,Volume
8,Number1-2(2017),pages1–130.
[GrayandReuter(1993)] J.GrayandA.Reuter,TransactionProcessing:ConceptsandTech-
niques,MorganKaufmann(1993).
[Grayetal.(1975)] J.Gray,R.A.Lorie,andG.R.Putzolu,“GranularityofLocksandDe-
greesofConsistencyinaSharedDataBase”,InProc.oftheInternationalConf.onVeryLarge
Databases(1975),pages428–451.
[JohnsonandShasha(1993)] T.JohnsonandD.Shasha,“ThePerformanceofConcurrent
B-TreeAlgorithms”,ACMTransactionsonDatabaseSystems,Volume18,Number1(1993),
pages51–101.
[KungandLehman(1980)] H.T.KungandP.L.Lehman,“ConcurrentManipulationofBi-
nary Search Trees”, ACM Transactions on Database Systems, Volume 5, Number 3 (1980),
pages339–353.

--- Page 935 ---

906 Chapter18 ConcurrencyControl
[KungandRobinson(1981)] H.T.KungandJ.T.Robinson,“OptimisticConcurrencyCon-
trol”,ACMTransactionsonDatabaseSystems,Volume6,Number2(1981),pages312–326.
[LehmanandYao(1981)] P. L. Lehman and S. B. Yao, “Efficient Locking for Concurrent
OperationsonB-trees”,ACMTransactionsonDatabaseSystems,Volume6,Number4(1981),
pages650–670.
[Mohan(1990)] C.Mohan,“ARIES/KVL:AKey-ValueLockingMethodforConcurrency
ControlofMultiactionTransactionsOperationsonB-Treeindexes”,InProc.oftheInterna-
tionalConf.onVeryLargeDatabases(1990),pages392–405.
[MohanandNarang(1992)] C. Mohan and I. Narang, “Efficient Locking and Caching of
DataintheMultisystemSharedDisksTransactionEnvironment”,InProc.oftheInternational
Conf.onExtendingDatabaseTechnology(1992),pages453–468.
[PortsandGrittner(2012)] D.R.K.PortsandK.Grittner,“SerializableSnapshotIsolation
inPostgreSQL”,ProceedingsoftheVLDBEndowment,Volume5,Number12(2012),pages
1850–1861.
[Reed(1983)] D. Reed, “Implementing Atomic Actions on Decentralized Data”, Transac-
tionsonComputerSystems,Volume1,Number1(1983),pages3–23.
[Silberschatz(1982)] A.Silberschatz,“AMulti-VersionConcurrencyControlSchemeWith
NoRollbacks”,InProc.oftheACMSymposiumonPrinciplesofDistributedComputing(1982),
pages216–223.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 936 ---

19
CHAPTER
Recovery System
Acomputersystem,likeanyotherdevice,issubjecttofailurefromavarietyofcauses:
disk crash, power outage, software error, a fire in the machine room, even sabotage.
In any failure, information may be lost. Therefore, the database system must take ac-
tionsinadvancetoensurethattheatomicityanddurabilitypropertiesoftransactions,
introducedinChapter17,arepreserved.Anintegralpartofadatabasesystemisare-
coveryschemethatcanrestore thedatabase totheconsistentstate thatexisted before
thefailure.
The recovery scheme must also support high availability, that is, the database
should be usable for a very high percentage of time. To support high availability in
thefaceofmachinefailure(asalsoplannedmachineshutdownsforhardware/software
upgrades and maintenance), the recovery scheme must support the ability to keep a
backup copy of the database synchronized with the current contents of the primary
copyofthedatabase.Ifthemachinewiththeprimarycopyfails,transactionprocess-
ingcancontinueonthebackupcopy.
19.1 Failure Classification
Therearevarioustypesoffailurethatmayoccurinasystem,eachofwhichneedstobe
dealt with in a different manner. In this chapter, we shall consider only the following
typesoffailure:
• Transaction failure.Therearetwotypesoferrorsthatmaycauseatransaction to
fail:
° Logicalerror.Thetransactioncannolongercontinuewithitsnormalexecution
becauseofsomeinternalcondition,suchasbadinput,datanotfound,overflow,
orresourcelimitexceeded.
° System error.Thesystem hasenteredanundesirable state (e.g.,deadlock),as
aresultofwhichatransactioncannotcontinuewithitsnormalexecution.The
transaction,however,canbereexecutedatalatertime.
907

--- Page 937 ---

908 Chapter19 RecoverySystem
• Systemcrash.Thereisahardwaremalfunction,orabuginthedatabasesoftware
ortheoperatingsystem,thatcausesthelossofthecontentofvolatilestorageand
bringstransactionprocessingtoahalt.Thecontentofnon-volatilestorageremains
intactandisnotcorrupted.
Theassumptionthathardwareerrorsandbugsinthesoftwarebringthesystem
to a halt, but do not corrupt the non-volatile storage contents, is known as the
fail-stopassumption.Well-designedsystemshavenumerousinternalchecks,atthe
hardware and the software level, that bring the system to a halt when there is an
error.Hence,thefail-stopassumptionisareasonableone.
• Diskfailure.Adiskblocklosesitscontentasaresultofeitheraheadcrashorfail-
ureduringadata-transferoperation.Copiesofthedataonotherdisks,orarchival
backups on tertiary media, such as DVD or tapes, are used to recover from the
failure.
Todeterminehowthesystemshouldrecoverfromfailures,weneedtoidentifythe
failuremodesofthosedevicesusedforstoringdata.Next,wemustconsiderhowthese
failure modes affect the contents of the database. We can then propose algorithms
toensuredatabase consistencyandtransactionatomicitydespite failures.Thesealgo-
rithms,knownasrecoveryalgorithms,havetwoparts:
1. Actionstakenduringnormaltransactionprocessingtoensurethatenoughinfor-
mationexiststoallowrecoveryfromfailures.
2. Actions taken after a failure to recover the database contents to a state that en-
suresdatabaseconsistency,transactionatomicity,anddurability.
19.2 Storage
As we saw in Chapter 13, the various data items in the database may be stored and
accessed in a number of differentstorage media. In Section 17.3, we saw that storage
mediacanbedistinguishedbytheirrelativespeed,capacity,andresilienceagainstfail-
ure.Weidentifiedthreecategoriesofstorage:
1. Volatilestorage
2. Non-Volatilestorage
3. Stablestorage
Stable storage or, more accurately, an approximation thereof, plays a critical role in
recoveryalgorithms.

--- Page 938 ---

19.2 Storage 909
19.2.1 Stable-Storage Implementation
To implement stable storage, we need to replicate the needed information in several
non-volatilestoragemedia(usuallydisk)withindependentfailuremodesandtoupdate
theinformationinacontrolledmannertoensurethatfailureduringdatatransferdoes
notdamagetheneededinformation.
Recall(fromChapter12)thatRAIDsystemsguaranteethatthefailureofasingle
disk(evenduringdatatransfer)willnotresultinlossofdata.Thesimplestandfastest
formofRAIDisthemirroreddisk,whichkeepstwocopiesofeachblockonseparate
disks.OtherformsofRAIDofferlowercosts,butattheexpenseoflowerperformance.
RAIDsystems,however,cannotguardagainstdatalossduetodisasterssuchasfires
orflooding.Manysystemsstorearchivalbackupsoftapesoff-sitetoguardagainstsuch
disasters.However,sincetapescannotbecarriedoff-sitecontinually,updatessincethe
mostrecenttimethattapeswerecarriedoff-sitecouldbelostinsuchadisaster.More
secure systems keep a copy of each block of stable storage at a remote site, writingit
out over a computer network, in addition to storing the block on a local disk system.
Since the blocks are output to a remote system as and when they are output to local
storage,onceanoutputoperationiscomplete,theoutputisnotlost,evenintheevent
of a disaster such as a fire or flood. We study such remote backup systems in Section
19.7.
In the remainder of this section, we discuss how storage media can be protected
fromfailureduringdatatransfer.Blocktransferbetweenmemoryanddiskstoragecan
resultin:
• Successfulcompletion.Thetransferredinformationarrivedsafelyatitsdestination.
• Partialfailure.Afailureoccurredinthemidstoftransfer,andthedestinationblock
hasincorrectinformation.
• Total failure. The failure occurred sufficiently early during the transfer that the
destinationblockremainsintact.
Werequirethat,ifadata-transferfailureoccurs,thesystemdetectsitandinvokesa
recoveryproceduretorestoretheblocktoaconsistentstate.Todoso,thesystemmust
maintain two physical blocks for each logical database block; in the case of mirrored
disks, both blocks are at the same location; in the case of remote backup, one of the
blocks islocal,whereasthe otherisataremotesite. An output operation isexecuted
asfollows:
1. Writetheinformationontothefirstphysicalblock.
2. Whenthefirstwritecompletessuccessfully,writethesameinformationontothe
secondphysicalblock.
3. Theoutputiscompletedonlyafterthesecondwritecompletessuccessfully.

--- Page 939 ---

910 Chapter19 RecoverySystem
Ifthesystemfailswhileblocksarebeingwritten,itispossiblethatthetwocopies
ofablockcouldbeinconsistentwitheachother.Duringrecovery,foreachblock,the
system would need to examine two copies of the blocks. If both are the same and no
detectableerror exists, then nofurther actionsarenecessary.(Recallthaterrorsina
diskblock,suchasapartialwritetotheblock,aredetectedbystoringachecksumwith
each block.) If the system detects an error in one block, then it replaces its content
with the content of the other block. If both blocks contain no detectable error, but
theydifferincontent,thenthesystemcaneitherreplacethecontentofthefirstblock
withthevalueofthesecond,orreplacethecontentofthesecondblockwiththevalue
of the first. Either way, the recovery procedure ensures that a write to stable storage
eithersucceedscompletely(i.e.,updatesallcopies)orresultsinnochange.
Therequirementofcomparingeverycorrespondingpairofblocksduringrecovery
isexpensivetomeet.Wecanreducethecostgreatlybykeepingtrackofblockwritesthat
are in progress, using a small amount of non-volatile RAM. On recovery, only blocks
forwhichwriteswereinprogressneedtobecompared.
The protocolsforwritingoutablocktoaremote site aresimilartotheprotocols
for writing blocks to a mirrored disk system, which we examined in Chapter 12, and
particularlyinPracticeExercise12.6.
Wecanextendthisprocedureeasilytoallowtheuseofanarbitrarilylargenumber
of copies of each block of stable storage. Although a large number of copies reduces
theprobabilityofafailuretoevenlowerthantwocopiesdo,itisusuallyreasonableto
simulatestablestoragewithonlytwocopies.
19.2.2 Data Access
As we saw in Chapter 12, the database system resides permanently on non-volatile
storage (usually disks), and only parts of the database are in memory at any time.
(In main-memory databases, the entire database resides in memory, but a copy still
residesonnon-volatilestoragesodatacansurvivethelossofmain-memorycontents.)
Thedatabaseispartitionedintofixed-lengthstorageunitscalledblocks.Blocksarethe
units of data transfer to and from disk and may contain several data items. We shall
assume that no data item spans two or more blocks. This assumption is realistic for
mostdata-processingapplications,suchasabankorauniversity.
Transactionsinputinformationfromthediskintomainmemoryandthenoutput
theinformationbackontothedisk.Theinputandoutputoperationsaredoneinblock
units.Theblocksresidingonthediskarereferredtoasphysicalblocks;theblocksresid-
ingtemporarilyinmainmemoryarereferredtoasbufferblocks.Theareaofmemory
whereblocksresidetemporarilyiscalledthediskbuffer.
Blockmovementsbetweendiskandmainmemoryareinitiatedthroughthefollow-
ingtwooperations:
1. input(B)transfersthephysicalblockBtomainmemory.

--- Page 940 ---

19.2 Storage 911
2. output(B) transfers the buffer block B to the disk and replaces the appropriate
physicalblockthere.
Figure19.1illustratesthisscheme.
Conceptually,eachtransactionT hasaprivateworkareainwhichcopiesofdata
i
items accessed and updated by T are kept. The system creates this work area when
i
thetransactionisinitiated;thesystemremovesitwhenthetransactioneithercommits
or aborts. Each data item X kept in the work area of transaction T is denoted by x.
i i
TransactionT interactswiththedatabasesystem bytransferringdatatoandfromits
i
workareatothesystembuffer.Wetransferdatabythesetwooperations:
1. read(X)assignsthevalueofdataitemXtothelocalvariablex.Itexecutesthis
i
operationasfollows:
a. IfblockB onwhichXresidesisnotinmainmemory,itissuesinput(B ).
X X
b. Itassignstox thevalueofXfromthebufferblock.
i
2. write(X)assignsthevalueoflocalvariablex todataitemXinthebufferblock.
i
Itexecutesthisoperationasfollows:
a. IfblockB onwhichX residesisnotinmainmemory,itissuesinput(B ).
X X
b. Itassignsthevalueofx toXinbufferB .
i X
Notethatbothoperationsmayrequirethetransferofablockfromdisktomainmem-
ory.Theydonot,however,specificallyrequirethetransferofablockfrommainmem-
orytodisk.
Abufferblockiseventuallywrittenouttothediskeitherbecausethebufferman-
agerneedsthememoryspaceforotherpurposesorbecausethedatabasesystemwishes
input(A)
A
output(B)
B B
disk
mainmemory
Figure 19.1 Blockstorageoperations.

--- Page 941 ---

912 Chapter19 RecoverySystem
toreflectthechangetoBonthedisk.Weshallsaythatthedatabasesystem performs
aforce-outputofbufferBifitissuesanoutput(B).
WhenatransactionneedstoaccessadataitemXforthefirsttime,itmustexecute
read(X).ThetransactionthenperformsallupdatestoXonx.Atanypointduringits
i
executionatransactionmayexecutewrite(X)toreflectthechangetoXinthedatabase
itself;write(X)mustcertainlybedoneafterthefinalwritetox.
i
Theoutput(B )operationforthebufferblockB onwhichX residesdoesnotneed
X X
to take effectimmediatelyafter write(X)is executed,since the blockB may contain
X
other data items that are still being accessed. Thus, the actual output may take place
later.Noticethat,ifthesystem crashesafterthewrite(X)operationwasexecutedbut
beforeoutput(B )wasexecuted,thenewvalueofXisneverwrittentodiskand,thus,
X
is lost. As we shall see shortly, the database system executes extra actions to ensure
thatupdatesperformedbycommittedtransactionsarenotlostevenifthereisasystem
crash.
19.3 Recovery and Atomicity
Consider again our simplified banking system and a transaction T that transfers $50
i
from account A to account B, with initial values of A and B being $1000 and $2000,
respectively.SupposethatasystemcrashhasoccurredduringtheexecutionofT,after
i
output(B ) has taken place, but before output(B ) was executed, where B and B
A B A B
denote the buffer blocks on which A and B reside. Since the memory contents were
lost,wedonotknowthefateofthetransaction.
Whenthesystemrestarts,thevalueofAwouldbe$950,whilethatofBwouldbe
$2000,whichisclearlyinconsistentwiththeatomicityrequirementfortransactionT.
i
Unfortunately,thereisnowaytofindoutbyexaminingthedatabasestatewhatblocks
hadbeenoutputandwhathadnotbeforethecrash.Itispossiblethatthetransaction
completed,updatingthedatabaseonstablestoragefromaninitialstatewiththevalues
ofAandB being$1000and$1950;itisalsopossiblethatthetransactiondidnotaffect
the stable storage at all, and the values of A and B were $950 and $2000 initially; or
thattheupdatedBwasoutputbutnottheupdatedA;orthattheupdatedAwasoutput
buttheupdatedBwasnot.
Our goal is to perform either all or no database modifications made by T. How-
i
ever, if T performed multiple database modifications, several output operations may
i
berequired,andafailuremayoccuraftersomeofthesemodificationshavebeenmade,
butbeforeallofthemaremade.
To achieve our goal of atomicity, we must first output to stable storage informa-
tion describing the modifications, without modifying the database itself. As we shall
see, this information can help us ensure that all modificationsperformed by commit-
ted transactions are reflected in the database (perhaps during the course of recovery
actions after a crash). We also need to store information about the old value of any
item updated by a modification in case the transaction performing the modification

--- Page 942 ---

19.3 RecoveryandAtomicity 913
fails(aborts).Thisinformationcanhelpusundothemodificationsmadebythefailed
transaction.
Themostcommonlyused techniqueforrecoveryisbased onlogrecords,and we
studylog-basedrecoveryindetailinthischapter.Analternative,calledshadowcopying,
isusedbytexteditorsbutisnotusedindatabasesystems;thisapproachissummarized
inNote19.1onpage914.
19.3.1 Log Records
Themostwidelyusedstructureforrecordingdatabasemodificationsisthelog.Thelog
isasequenceoflogrecords,recordingalltheupdateactivitiesinthedatabase.
Thereareseveraltypesoflogrecords.Anupdatelogrecorddescribesasingledata-
basewrite.Ithasthesefields:
• Transaction identifier, which is the unique identifier of the transaction that per-
formedthewriteoperation.
• Data-item identifier, which is the unique identifier of the data item written. Typi-
cally, it is the location on disk of the data item, consisting of the block identifier
oftheblockonwhichthedataitemresidesandanoffsetwithintheblock.
• Oldvalue,whichisthevalueofthedataitempriortothewrite.
• Newvalue,whichisthevaluethatthedataitemwillhaveafterthewrite.
Werepresentanupdatelogrecordas<T, X, V , V >,indicatingthattransactionT
i j 1 2 i
hasperformedawriteondataitemX.X hadvalueV beforethewriteandhasvalue
j j 1
V after the write. Other special log records exist to record significant events during
2
transactionprocessing,suchasthestartofatransactionandthecommitorabortofa
transaction.Amongthetypesoflogrecordsare:
• <T start>.TransactionT hasstarted.
i i
• <T commit>.TransactionT hascommitted.
i i
• <T abort>.TransactionT hasaborted.
i i
Weshallintroduceseveralothertypesoflogrecordslater.
Wheneveratransactionperformsawrite,itisessentialthatthelogrecordforthat
write be created and added to the log, before the database is modified. Once a log
recordexists,wecanoutputthemodificationtothedatabaseifthatisdesirable.Also,
wehavetheabilitytoundoamodificationthathasalreadybeenoutputtothedatabase.
Weundoitbyusingtheold-valuefieldinlogrecords.
Forlogrecordstobeusefulforrecoveryfromsystemanddiskfailures,thelogmust
resideinstablestorage.Fornow,weassumethateverylogrecordiswrittentotheend

--- Page 943 ---

914 Chapter19 RecoverySystem
Note 19.1 SHADOWCOPIESANDSHADOWPAGING
In the shadow-copy scheme, a transaction that wants to update the database first
createsacompletecopyofthedatabase.Allupdatesaredoneonthenewdatabase
copy, leaving the original copy, the shadow copy, untouched. If at any point the
transaction has to be aborted, the system merely deletes the new copy. The old
copy of the database has not been affected. The current copy of the database is
identifiedbyapointer,calleddb-pointer,whichisstoredondisk.
Ifthetransactionpartiallycommits(i.e.,executesitsfinalstatement)itiscom-
mitted asfollows: First,the operating system isasked to make sure thatallpages
ofthenewcopyofthedatabasehavebeenwrittenouttodisk.(Unixsystems use
the fsynccommandfor thispurpose.) Afterthe operating system has written all
the pages to disk, the database system updates the pointer db-pointer to point to
thenewcopyofthedatabase;thenewcopythenbecomesthecurrentcopyofthe
database.Theoldcopyofthedatabaseisthendeleted.Thetransactionissaidto
havebeencommittedatthepointwheretheupdateddb-pointeriswrittentodisk.
Theimplementationactuallydependsonthewritetodb-pointerbeingatomic;
thatis,eitherallitsbytesarewrittenornoneofitsbytesarewritten.Disksystems
provideatomicupdatestoentireblocks,oratleasttoadisksector.Inotherwords,
thedisksystemguaranteesthatitwillupdatedb-pointeratomically,aslongaswe
make sure that db-pointer lies entirely in a single sector, which we can ensure by
storingdb-pointeratthebeginningofablock.
Shadow-copy schemes are commonly used by text editors (saving the file is
equivalentto transaction commit,whilequittingwithoutsavingthe file isequiva-
lent to transaction abort). Shadow copying can be used for small databases, but
copyingalargedatabasewouldbeextremelyexpensive.Avariantofshadowcopy-
ing,calledshadow paging,reducescopyingasfollows: the schemeuses apage ta-
blecontainingpointerstoallpages;thepagetableitselfandallupdatedpagesare
copied to a new location. Any page which is not updated by a transaction is not
copied, but instead the new page table just stores a pointer to the original page.
When a transaction commits,itatomicallyupdates the pointer to the page table,
whichactsasdb-pointertopointtothenewcopy.
Shadowpagingunfortunatelydoesnotworkwellwithconcurrenttransactions
andisnotwidelyusedindatabases.
ofthelogonstablestorageassoonasitiscreated.InSection19.5,weshallseewhen
it is safe to relax this requirement so as to reduce the overhead imposed by logging.
Observe that the log contains a complete record of all database activity. As a result,
thevolumeofdatastoredinthelogmaybecomeunreasonablylarge.InSection19.3.6,
weshallshowwhenitissafetoeraseloginformation.

--- Page 944 ---

19.3 RecoveryandAtomicity 915
19.3.2 Database Modification
Aswenotedearlier,atransactioncreatesalogrecordpriortomodifyingthedatabase.
Thelogrecordsallowthe system toundo changesmadeby atransaction inthe event
thatthetransactionmustbeaborted;theyallowthesystemalsotoredochangesmade
byatransactionifthetransactionhascommittedbutthesystemcrashedbeforethose
changescouldbestoredinthedatabaseondisk.Inorderforustounderstandtherole
of these log records in recovery, we need to consider the steps a transaction takes in
modifyingadataitem:
1. The transaction performs some computations in its own private part of main
memory.
2. Thetransactionmodifiesthedatablockinthediskbufferinmainmemoryhold-
ingthedataitem.
3. Thedatabasesystemexecutestheoutputoperationthatwritesthedatablockto
disk.
Wesayatransactionmodifiesthedatabaseifitperformsanupdateonadiskbuffer,
or on the disk itself; updates to the private part of main memory do not count as
databasemodifications.Ifatransactiondoesnotmodifythedatabaseuntilithascom-
mitted, it is said to use the deferred-modification technique. If database modifications
occurwhilethetransactionisstillactive,thetransaction issaidtouse theimmediate-
modificationtechnique.Deferredmodificationhastheoverheadthattransactionsneed
to make local copies of all updated data items; further, if a transaction reads a data
itemthatithasupdated,itmustreadthevaluefromitslocalcopy.
Therecoveryalgorithmswedescribeinthischaptersupportimmediatemodifica-
tion.Asdescribed,theyworkcorrectlyevenwithdeferredmodification,buttheycanbe
optimizedto reduceoverhead when used withdeferred modification;we leave details
asanexercise.
Arecoveryalgorithmmusttakeintoaccountavarietyoffactors,including:
• The possibility that a transaction may have committed although some of its
database modifications exist only in the disk buffer in main memory and not in
thedatabaseondisk.
• The possibility that a transaction may have modified the database while in the
activestateand,asaresultofasubsequentfailure,mayneedtoabort.
Because all database modifications must be preceded by the creation of a log
record, the system has available both the old value prior to the modification of the
data item and the new value that is to be written for the data item. This allows the
systemtoperformundoandredooperationsasappropriate.

--- Page 945 ---

916 Chapter19 RecoverySystem
• Theundooperationusingalogrecordsetsthedataitemspecifiedinthelogrecord
totheoldvaluecontainedinthelogrecord.
• Theredooperationusingalogrecordsetsthedataitemspecifiedinthelogrecord
tothenewvaluecontainedinthelogrecord.
19.3.3 Concurrency Control and Recovery
If the concurrency control scheme allows a data item X that has been modified by a
transaction T to be further modified by another transaction T before T commits,
1 2 1
then undoing the effects of T by restoring the old value of X (before T updated X)
1 1
wouldalsoundotheeffectsofT .Toavoidsuchsituations,recoveryalgorithmsusually
2
requirethatifadataitemhasbeenmodifiedbyatransaction,noothertransactioncan
modifythedataitemuntilthefirsttransactioncommitsoraborts.
This requirement can be ensured by acquiring an exclusive lock on any updated
dataitemandholdingthelockuntilthetransactioncommits;inotherwords,byusing
stricttwo-phaselocking.Snapshotisolationandvalidation-basedconcurrency-control
techniquesalsoacquireexclusive locksondataitemsatthetimeofvalidation,before
modifying the data items, and hold the locks until the transaction is committed; as a
resulttheaboverequirementissatisfiedevenbytheseconcurrencycontrolprotocols.
We discuss in Section 19.8 how the above requirement can be relaxed in certain
cases.
When either snapshot isolation or validation is used for concurrency control,
database updates of a transaction are (conceptually) deferred until the transaction is
partiallycommitted;thedeferred-modificationtechniqueisanaturalfitwiththesecon-
currency control schemes. However, it is worth noting that some implementations of
snapshot isolation use immediate modification but provide a logical snapshot on de-
mand:whenatransactionneedstoreadanitemthataconcurrenttransactionhasup-
dated,acopyofthe(alreadyupdated)itemismade,andupdatesmadebyconcurrent
transactionsarerolledbackonthecopyoftheitem.Similarly,immediatemodification
of the database is a natural fit with two-phase locking, but deferred modification can
alsobeusedwithtwo-phaselocking.
<T
0
start>
<T
0
, A, 1000, 950>
<T
0
, B, 2000, 2050>
<T
0
commit>
<T
1
start>
<T
1
, C, 700, 600>
<T
1
commit>
Figure 19.2 PortionofthesystemlogcorrespondingtoT 0 andT 1 .

--- Page 946 ---

19.3 RecoveryandAtomicity 917
19.3.4 Transaction Commit
We say that a transaction has committed when its commit log record, which is the
last log record of the transaction, has been output to stable storage; at that point all
earlier log records have already been output to stable storage. Thus, there is enough
informationinthelogtoensurethatevenifthereisasystemcrash,theupdatesofthe
transactioncanberedone.Ifasystemcrashoccursbeforealogrecord<T commit>
i
is output to stable storage, transaction T will be rolled back. Thus, the output of the
i
block containing the commit log record is the single atomic action that results in a
transactiongettingcommitted.1
With most log-based recovery techniques, including the ones we describe in this
chapter,blockscontainingthedataitemsmodifiedbyatransactiondonothavetobe
output to stable storage when the transaction commits but can be output some time
later.WediscussthisissuefurtherinSection19.5.2.
19.3.5 Using the Log to Redo and Undo Transactions
Wenowprovideanoverviewofhowthelogcanbeusedtorecoverfromasystemcrash
and to roll back transactions during normal operation. However, we postpone details
oftheproceduresforfailurerecoveryandrollbacktoSection19.4.
Consideroursimplifiedbankingsystem.LetT beatransactionthattransfers$50
0
fromaccountAtoaccountB:
T : read(A);
0
A:=A−50;
write(A);
read(B);
B:=B+50;
write(B).
LetT beatransactionthatwithdraws$100fromaccountC:
1
T : read(C);
1
C:=C−100;
write(C).
Theportionofthelogcontainingtherelevantinformationconcerningthesetwotrans-
actionsappearsinFigure19.2.
Figure 19.3 shows one possible order in which the actual outputs took place in
boththedatabasesystemandthelogasaresultoftheexecutionofT andT .2
0 1
1Theoutputofablockcanbemadeatomicbytechniquesfordealingwithdata-transferfailure,asdescribedinSection
19.2.1.
2Noticethatthisordercouldnotbeobtainedusingthedeferred-modificationtechnique,becausethedatabaseismod-
ifiedbyT beforeitcommits,andlikewiseforT .
0 1

--- Page 947 ---

918 Chapter19 RecoverySystem
Log Database
<T
0
start>
<T
0
, A, 1000, 950>
<T
0
, B, 2000, 2050>
A = 950
B = 2050
<T
0
commit>
<T
1
start>
<T
1
, C, 700, 600>
C = 600
<T
1
commit>
Figure 19.3 State ofsystemloganddatabasecorrespondingtoT 0 andT 1 .
Usingthelog,thesystemcanhandleanyfailurethatdoesnotresultinthelossof
informationinnon-volatilestorage.Therecoveryschemeusestworecoveryprocedures.
Boththeseproceduresmakeuseofthelogtofindthesetofdataitemsupdatedbyeach
transactionT andtheirrespectiveoldandnewvalues.
i
• redo(T).TheproceduresetsthevalueofalldataitemsupdatedbytransactionT
i i
to the new values. The order in which updates are carried out by redo is impor-
tant;whenrecoveringfromasystemcrash,ifupdatestoaparticulardataitemare
appliedinanorderdifferentfromtheorderinwhichtheywereappliedoriginally,
thefinalstateofthatdataitemwillhaveawrongvalue.Mostrecoveryalgorithms,
includingtheonewedescribeinSection19.4,donotperformredoofeachtrans-
actionseparately;insteadtheyperformasinglescanofthelog,duringwhichredo
actionsareperformedforeachlogrecordasitisencountered.Thisapproachen-
surestheorderofupdatesispreserved,anditismoreefficientsincethelogneeds
tobereadonlyonceoverall,insteadofoncepertransaction.
• undo(T).Theprocedurerestoresthevalueofalldataitemsupdatedbytransaction
i
T totheoldvalues.IntherecoveryschemethatwedescribeinSection19.4:
i
° The undo operation not only restores the data items to their old value, but
also writes log records to record the updates performed as part of the undo
process.Theselogrecordsarespecial redo-only logrecords,sincetheydonot
need to contain the old value of the updated data item; note that when such
logrecordsareusedduringundo,the“oldvalue”isactuallythevalue written
bythetransactionthatisbeingrolledback,andthe“newvalue”istheoriginal
valuethatisbeingrestoredbytheundooperation.
As with the redo procedure, the order in which undo operations are per-
formedisimportant;againwepostponedetailstoSection19.4.

--- Page 948 ---

19.3 RecoveryandAtomicity 919
° WhentheundooperationfortransactionT completes,itwritesa<T abort>
i i
logrecord,indicatingthattheundohascompleted.
As we shall see in Section 19.4, the undo(T) procedure is executed only
i
onceforatransaction,ifthetransactionisrolledbackduringnormalprocess-
ing or if on recovering from a system crash, neither a commit nor an abort
recordisfoundfortransactionT.Asaresult,everytransactionwilleventually
i
haveeitheracommitoranabortrecordinthelog.
Afterasystemcrashhasoccurred,thesystemconsultsthelogtodeterminewhich
transactionsneedtoberedoneandwhichneedtobeundonesoastoensureatomicity.
• Transaction T needs to be undone if the log contains the record <T start> but
i i
doesnotcontaineithertherecord<T commit>ortherecord<T abort>.
i i
• Transaction T needs to be redone if the log contains the record <T start> and
i i
eithertherecord<T commit>ortherecord<T abort>.Itmayseemstrangeto
i i
redoT iftherecord<T abort>isinthelog.Toseewhythisworks,notethatif<T
i i i
abort>is in the log, so are the redo-only recordswritten by the undo operation.
Thus, the end result will be to undo T’s modifications in this case. This slight
i
redundancy simplifies the recovery algorithm and enables faster overall recovery
time.
As an illustration, return to our banking example, with transaction T and T ex-
0 1
ecuted one after the other in the order T followed by T . Suppose that the system
0 1
crashesbeforethecompletionofthetransactions.Weshallconsiderthreecases.The
stateofthelogsforeachofthesecasesappearsinFigure19.4.
First,letusassumethatthecrashoccursjustafterthelogrecordforthestep:
write(B)
of transaction T has been written to stable storage (Figure 19.4a). When the system
0
comes back up, it finds the record <T start> in the log, but no corresponding <T
0 0
commit>or<T abort>record.Thus,transactionT mustbeundone,soanundo(T )
0 0 0
isperformed.Asaresult,thevaluesinaccountsAandB(onthedisk)arerestoredto
$1000and$2000,respectively.
Next,letusassumethatthecrashcomesjustafterthelogrecordforthestep:
write(C)
of transaction T has been written to stable storage (Figure 19.4b). When the system
1
comesbackup, tworecoveryactionsneedtobetaken. Theoperation undo(T )must
1
be performed, since the record <T start> appears in the log, but there is no record
1
<T commit>or<T abort>.Theoperationredo(T )mustbeperformed,sincethe
1 1 0
logcontainsboththerecord<T start>andtherecord<T commit>.Attheendof
0 0

--- Page 949 ---

920 Chapter19 RecoverySystem
<T
0
start> <T
0
start> <T
0
start>
<T
0
, A, 1000, 950> <T
0
, A, 1000, 950> <T
0
, A, 1000, 950>
<T
0
, B, 2000, 2050> <T
0
, B, 2000, 2050> <T
0
, B , 2000, 2050>
<T
0
commit> <T
0
commit>
<T
1
start> <T
1
start>
<T
1
, C , 700, 600> <T
1
, C , 700, 600>
<T
1
commit>
(a) (b) (c)
Figure 19.4 Thesamelog,shownatthreedifferenttimes.
theentirerecoveryprocedure,thevaluesofaccountsA,B,andCare$950,$2050,and
$700,respectively.
Finally,letusassumethatthecrashoccursjustafterthelogrecord:
<T commit>
1
has been written to stable storage (Figure 19.4c). When the system comes back up,
both T and T need to be redone, since the records <T start> and <T commit>
0 1 0 0
appear in the log, as do the records<T start>and <T commit>. After the system
1 1
performstherecoveryproceduresredo(T )andredo(T ),thevaluesinaccountsA,B,
0 1
andCare$950,$2050,and$600,respectively.
19.3.6 Checkpoints
Whenasystemcrashoccurs,wemustconsultthelogtodeterminethosetransactions
that need to be redone and those that need to be undone. In principle, we need to
search the entire log to determine this information. There are two major difficulties
withthisapproach:
1. Thesearchprocessistime-consuming.
2. Mostofthetransactionsthat,accordingtoouralgorithm,needtoberedonehave
alreadywrittentheirupdatesintothedatabase.Althoughredoingthemwillcause
noharm,itwillneverthelesscauserecoverytotakelonger.
Toreducethesetypesofoverhead,weintroducecheckpoints.
We describe below a simple checkpoint scheme that (a) does not permit any up-
dates to be performed while the checkpointoperation is in progress, and (b) outputs
allmodifiedbufferblockstodiskwhenthecheckpointisperformed.Wediscusslater
how to modify the checkpointingand recovery procedures to provide more flexibility
byrelaxingboththeserequirements.
Acheckpointisperformedasfollows:

--- Page 950 ---

19.3 RecoveryandAtomicity 921
1. Outputontostablestoragealllogrecordscurrentlyresidinginmainmemory.
2. Outputtothediskallmodifiedbufferblocks.
3. Outputontostablestoragealogrecordoftheform<checkpointL>,whereLis
alistoftransactionsactiveatthetimeofthecheckpoint.
Transactions are not allowed to perform any update actions, such as writing to a
bufferblockorwritingalogrecord,whileacheckpointisinprogress.Wediscusshow
thisrequirementcanbeenforcedinSection19.5.2.
Thepresenceofa<checkpointL>recordinthelogallowsthesystemtostream-
lineitsrecoveryprocedure.ConsideratransactionT thatcompletedpriortothecheck-
i
point. For such a transaction, the <T commit> record (or < T abort> record) ap-
i i
pears in the log before the <checkpoint> record. Any database modifications made
byT musthavebeenwrittentothedatabaseeitherpriortothecheckpointoraspart
i
of the checkpoint itself. Thus, at recovery time, there is no need to perform a redo
operationonT.
i
After a system crash has occurred, the system examines the log to find the last
<checkpoint L> record (this can be done by searching the log backward, from the
endofthelog,untilthefirst<checkpointL>recordisfound).
TheredoorundooperationsneedtobeappliedonlytotransactionsinL,andto
alltransactionsthatstartedexecutionafterthe<checkpointL>recordwaswrittento
thelog.LetusdenotethissetoftransactionsasT.
• For all transactions T in T that have no <T commit> record or <T abort>
k k k
recordinthelog,executeundo(T ).
k
• ForalltransactionsT inTsuchthateithertherecord<T commit>ortherecord
k k
<T abort>appearsinthelog,executeredo(T ).
k k
Note that we need only examine the part of the log starting with the last checkpoint
logrecordtofindthesetoftransactionsT andtofindoutwhetheracommitorabort
recordoccursinthelogforeachtransactioninT.
Asanillustration,considerthesetoftransactions{T ,T ,…,T }.Supposethat
0 1 100
the most recent checkpoint took place during the execution of transaction T and
67
T ,whileT andalltransactionswithsubscriptslowerthan67completedbeforethe
69 68
checkpoint. Thus, only transactions T , T ,…,T need to be considered during
67 69 100
therecoveryscheme.Eachofthemneedstoberedoneifithascompleted(i.e.,either
committedoraborted);otherwise,itwasincompleteandneedstobeundone.
ConsiderthesetoftransactionsLinacheckpointlogrecord.Foreachtransaction
T in L, log records of the transaction that occur prior to the checkpoint log record
i
may be needed to undo the transaction, in case it does not commit. However, all log
recordspriortotheearliestofthe<T start>logrecords,amongtransactionsT inL,
i i

--- Page 951 ---

922 Chapter19 RecoverySystem
are not needed once the checkpoint has completed. These log records can be erased
wheneverthedatabasesystemneedstoreclaimthespaceoccupiedbytheserecords.
Therequirementthattransactionsmustnotperformanyupdatestobufferblocks
or to the log during checkpointing can be bothersome, since transaction processing
hastohaltwhileacheckpointisinprogress.Afuzzycheckpointisacheckpointwhere
transactions are allowed to perform updates even while buffer blocks are being writ-
ten out. Section 19.5.4 describes fuzzy-checkpointing schemes. Later in Section 19.9
we describe a checkpointscheme that is not only fuzzy, but does not even require all
modifiedbufferblockstobeoutputtodiskatthetimeofthecheckpoint.
19.4 Recovery Algorithm
Until now, in discussing recovery, we have identified transactions that need to be re-
doneandthosethatneedtobeundone,butwehavenotgivenaprecisealgorithmfor
performingtheseactions.Wearenowreadytopresentthefullrecoveryalgorithmusing
logrecordsforrecoveryfromtransactionfailureandacombinationofthemostrecent
checkpointandlogrecordstorecoverfromasystemcrash.
The recovery algorithm described in this section requires that a data item that
has been updated by an uncommitted transaction cannot be modified by any other
transaction,untilthefirsttransactionhaseithercommittedoraborted.Recallthatthis
restrictionwasdiscussedinSection19.3.3.
19.4.1 Transaction Rollback
Firstconsidertransactionrollbackduringnormaloperation (i.e.,notduringrecovery
fromasystemcrash).RollbackofatransactionT isperformedasfollows:
i
1. The log is scanned backward, and for each log record of T of the form
i
<T, X, V , V >thatisfound:
i j 1 2
a. ThevalueV iswrittentodataitemX,and
1 j
b. A special redo-only log record <T, X, V > is written to the log, where
i j 1
V is the value being restored to data item X during the rollback. These
1 j
log records are sometimes called compensation log records. Such records
donotneedundoinformation,sinceweneverneedtoundosuchanundo
operation.Weshallexplainlaterhowtheyareused.
2. Oncethelogrecord<T start>isfound,thebackwardscanisstopped,andalog
i
record<T abort>iswrittentothelog.
i
Observethateveryupdateactionperformedbythetransactionoronbehalfofthe
transaction,includingactionstakentorestoredataitemstotheiroldvalue,havenow
beenrecordedinthelog.InSection19.4.2weshallseewhythisisagoodidea.

--- Page 952 ---

19.4 RecoveryAlgorithm 923
19.4.2 Recovery After a System Crash
Recoveryactions,whenthedatabasesystemisrestartedafteracrash,takeplaceintwo
phases:
1. Intheredophase,thesystemreplaysupdatesofall transactionsbyscanningthe
log forward from the last checkpoint. The log records that are replayed include
logrecordsfortransactionsthatwererolledbackbeforesystemcrash,andthose
thathadnotcommittedwhenthesystemcrashoccurred.
Thisphasealsodeterminesalltransactionsthatwereincompleteatthetimeof
thecrash,andmustthereforeberolledback.Suchincompletetransactionswould
eitherhavebeenactiveatthetimeofthecheckpoint,andthuswouldappearinthe
transactionlistinthecheckpointrecord,orwouldhavestartedlater;further,such
incomplete transactions would have neither a <T abort> nor a <T commit>
i i
recordinthelog.
Thespecificstepstakenwhilescanningthelogareasfollows:
a. Thelistoftransactionstoberolledback,undo-list,isinitiallysettothelist
Linthe<checkpointL>logrecord.
b. Whenever a normal log record of the form <T, X, V , V >, or a redo-
i j 1 2
onlylogrecordoftheform<T, X, V >isencountered,theoperation is
i j 2
redone;thatis,thevalueV iswrittentodataitemX.
2 j
c. Whenever a log record of the form <T start> is found, T is added to
i i
undo-list.
d. Wheneveralogrecordoftheform<T abort>or<T commit>isfound,
i i
T isremovedfromundo-list.
i
At the end of the redo phase, undo-list contains the list of all transactions that
are incomplete, that is, they neither committed nor completed rollback before
thecrash.
2. In the undo phase, the system rolls back all transactions in the undo-list. It per-
formsrollbackbyscanningthelogbackwardfromtheend.
a. Wheneveritfindsalogrecordbelongingtoatransactionintheundo-list,it
performsundoactionsjustasifthelogrecordhadbeenfoundduringthe
rollbackofafailedtransaction.
b. Whenthesystemfindsa<T start>logrecordforatransactionT inundo-
i i
list,itwritesa<T abort>logrecordtothelogandremovesT fromundo-
i i
list.
c. Theundophaseterminatesonceundo-listbecomesempty,thatis,thesys-
temhasfound<T start>logrecordsforalltransactionsthatwereinitially
i
inundo-list.

--- Page 953 ---

924 Chapter19 RecoverySystem
Aftertheundophaseofrecoveryterminates,normaltransactionprocessingcan
resume.
Observethattheredophasereplayseverylogrecordsincethemostrecentcheck-
pointrecord.Inotherwords,thisphaseofrestartrecoveryrepeatsalltheupdateactions
thatwereexecutedafterthecheckpoint,andwhoselogrecordsreachedthestablelog.
Theactionsincludeactionsofincompletetransactionsandtheactionscarriedoutto
rollbackfailedtransactions.Theactionsarerepeatedinthesameorderinwhichthey
wereoriginallycarriedout;hence,thisprocessiscalledrepeatinghistory.Althoughit
mayappearwasteful,repeatinghistoryevenforfailedtransactionssimplifiesrecovery
schemes.
Figure19.5shows an example ofactionslogged duringnormaloperation and ac-
tionsperformedduringfailurerecovery.Inthelogshowninthefigure,transactionT
1
hadcommitted,andtransactionT hadbeencompletelyrolledback,beforethesystem
0
crashed. Observe how the value of data item B is restored during the rollback of T .
0
Observe also the checkpointrecord, with the list of active transactions containingT
0
andT .
1
When recovering from a crash, in the redo phase, the system performs a redo of
alloperationsafterthelastcheckpointrecord.Inthisphase,thelistundo-listinitially
containsT andT ;T isremovedfirstwhenitscommitlogrecordisfound,whileT
0 1 1 2
is added when its start log record is found. Transaction T is removed from undo-list
0
whenitsabortlogrecordisfound,leavingonlyT inundo-list.Theundophasescans
2
the log backwards from the end, and when it finds a log record of T updating A, the
2
old value of A is restored, and a redo-only log record is written to the log. When the
Start log records
Beginning of log
found for all
older <T 0 start> transactions in
<T , B, 2000, 2050>
0 undo list
<T start> T rollback
1 0 Redo Pass
<checkpoint {T , T }> (during normal
0 1
operation)
<T, C, 700, 600>
1 begins
<T commit>
1
<T start>
E a n t d c r o a f s l h o ! g <T 2 2 , A, 500, 400> T c 0 o r m ol p lb le a t c e k
<T , B, 2000>
0
<T 0 abort> T 2 is incomplete
Log records at crash Undo list: T Undo Pass
2
added during <T 2 , A, 500>
recovery <T abort> T rolled back
2 2
in undo pass
newer
Figure 19.5 Exampleofloggedactionsandactionsduringrecovery.

--- Page 954 ---

19.4 RecoveryAlgorithm 925
start record for T isfound, anabort recordisadded forT . Sinceundo-listcontains
2 2
nomoretransactions,theundophaseterminates,completingrecovery.
19.4.3 Optimizing Commit Processing
Committingatransactionrequiresthatitslogrecordshavebeenforcedtodisk.Ifasep-
aratelogflushisdoneforeachtransaction,eachcommitincursasignificantlogwrite
overhead. The rate of transaction commit can be increased using the group-commit
technique. With this technique, instead of attempting to force the log as soon as a
transaction completes, the system waits until several transactions have completed, or
a certain period of time has passed since a transaction completed execution. It then
commitsthegroupoftransactionsthatarewaiting,together.Blockswrittentothelog
on stable storage would contain records of several transactions. By careful choice of
groupsizeandmaximumwaitingtime,thesystemcanensurethatblocksarefullwhen
they are written to stable storage without making transactions wait excessively. This
techniqueresults,onaverage,infeweroutputoperationspercommittedtransaction.
If logging is done to hard disk, writing a block of data can take about 5 to 10
milliseconds.Asaresult,withoutgroupcommit,atmost100to200transactionscan
becommittedpersecond.Ifrecordsof10transactionsfitinadiskblock,groupcommit
willallow1000to2000transactionstobecommittedpersecond.
Ifloggingisdonetoflash,writingablockcantakeabout100microseconds,allow-
ing10,000transactionstobecommittedpersecondwithoutgroupcommit.Ifrecords
of10transactionsfitinadiskblock,groupcommitwillallow100,000transactionsto
becommittedpersecondonflash.Afurtherbenefitofgroupcommitwithflashisthat
itminimizesthenumberoftimesthesamepageiswritten,whichinturnminimizesthe
numberoferaseoperations,whichcanbeexpensive.(Recallthatflashstoragesystems
remap logical pages to a pre-erased physical page, avoiding delay at the time a page
is written, but the erase operation must be performed eventually as part of garbage
collectionofoldversionsofpages.)
Although group commit reduces the overhead imposed by logging, it results in a
slightdelayincommitoftransactionsthatperformupdates.Whentherateofcommits
islow,thedelaymaynotbeworththebenefit,butwithhighratesoftransactioncommit,
theoveralldelayincommitisactuallyreducedbyusinggroupcommit.
Inadditiontooptimizationsdoneatthedatabase,programmerscanalsotakesome
steps to improve transaction commitperformance. Forexample, consideran applica-
tionthatloadsdataintoadatabase.Iftheapplicationperformseachinsertasaseparate
transaction,thenumberofinsertsthatcanbeperformedpersecondislimitedbythe
numberofblockswritesthatcanbeperformedpersecond.Iftheapplicationwaitsfor
oneinserttofinishbeforestartingthenextone,groupcommitdoesnotofferanybene-
fitsandinfactmayslowthesystemdown.However,insuchacase,performancecanbe
significantlyimprovedbyperformingabatchofinsertsasasingletransaction.Thelog
records corresponding to multiple inserts are then written together in one page. The
numberofinsertsthatcanbeperformedpersecondthenincreasescorrespondingly.

--- Page 955 ---

926 Chapter19 RecoverySystem
19.5 Buffer Management
Inthissection,weconsiderseveralsubtledetailsthatareessentialtotheimplementa-
tionofacrash-recoveryschemethatensuresdataconsistencyandimposesaminimal
amountofoverheadoninteractionswiththedatabase.
19.5.1 Log-Record Buffering
Sofar,wehaveassumedthateverylogrecordisoutputtostablestorageatthetimeit
is created. This assumption imposes a high overhead on system execution for several
reasons: Typically, output to stable storage is in units of blocks. In most cases, a log
recordismuchsmallerthanablock.Thus,theoutputofeachlogrecordtranslatestoa
muchlargeroutputatthephysicallevel.Furthermore,aswesawinSection19.2.1,the
outputofablocktostablestoragemayinvolveseveraloutputoperationsatthephysical
level.
Thecostofoutputtingablocktostablestorageissufficientlyhighthatitisdesirable
to output multiple log records at once. To do so, we write log records to a log buffer
in main memory, where they stay temporarily until they are output to stable storage.
Multiplelogrecordscanbegatheredinthelogbufferandoutputtostablestorageina
singleoutputoperation.Theorderoflogrecordsinthestablestoragemustbeexactly
thesameastheorderinwhichtheywerewrittentothelogbuffer.
Asaresultoflogbuffering,alogrecordmayresideinonlymainmemory(volatile
storage) for a considerable time before it is output to stable storage. Since such log
recordsarelostifthesystemcrashes,wemustimposeadditionalrequirementsonthe
recoverytechniquestoensuretransactionatomicity:
• TransactionT entersthecommitstateafterthe<T commit>logrecordhasbeen
i i
outputtostablestorage.
• Beforethe<T commit>logrecordcanbeoutputtostablestorage,alllogrecords
i
pertainingtotransactionT musthavebeenoutputtostablestorage.
i
• Before a block of data in main memory can be output to the database (in non-
volatile storage), all log records pertaining to data in that block must have been
outputtostablestorage.
This rule is called the write-ahead logging (WAL) rule. (Strictly speaking, the
WALrulerequiresonlythattheundoinformationintheloghasbeenoutputtosta-
blestorage,anditpermitstheredoinformationtobewrittenlater.Thedifference
isrelevantinsystemswhereundoinformationandredoinformationarestoredin
separatelogrecords.)
The three rules state situations in which certain log records must have been output
to stable storage. There isnoproblem resultingfrom the output of logrecordsearlier
than necessary. Thus, when the system finds it necessary to output a log record to

--- Page 956 ---

19.5 BufferManagement 927
stablestorage,itoutputsanentireblockoflogrecords,ifthereareenoughlogrecords
inmainmemorytofillablock.Ifthereareinsufficientlogrecordstofilltheblock,all
logrecordsinmainmemoryarecombinedintoapartiallyfullblockandareoutputto
stablestorage.
Writingthebufferedlogtodiskissometimesreferredtoasalogforce.
19.5.2 Database Buffering
In Section 19.2.2, we described the use of a two-level storage hierarchy. The system
storesthedatabase innon-volatilestorage (disk),andbringsblocksofdataintomain
memory as needed. Since main memory is typically much smaller than the entire
database, itmay be necessary tooverwrite ablock B in mainmemorywhen another
1
blockB needstobebroughtintomemory.IfB hasbeenmodified,B mustbeoutput
2 1 1
priortotheinputofB .AsdiscussedinSection13.5.1thisstoragehierarchyissimilar
2
tothestandardoperating-systemconceptofvirtualmemory.
Onemightexpectthattransactionswouldforce-outputallmodifiedblockstodisk
whentheycommit.Suchapolicyiscalledtheforcepolicy.Thealternative,theno-force
policy, allows a transaction to commit even if it has modified some blocks that have
notyetbeenwrittenbacktodisk.Alltherecoveryalgorithmsdescribedinthischapter
workcorrectlyevenwiththeno-forcepolicy.Theno-forcepolicyallowsfastercommit
oftransactions;moreoveritallowsmultipleupdatestoaccumulateonablockbeforeit
isoutputtostablestorage, whichcanreducethenumberofoutputoperationsgreatly
forfrequentlyupdatedblocks.Asaresult,thestandardapproachtakenbymostsystems
istheno-forcepolicy.
Similarly,onemightexpectthatblocksmodifiedbyatransactionthatisstillactive
shouldnotbewrittentodisk.Thispolicyiscalledtheno-stealpolicy.Thealternative,
thestealpolicy,allowsthesystemtowritemodifiedblockstodiskevenifthetransac-
tionsthatmadethosemodificationshavenotallcommitted.Aslongasthewrite-ahead
loggingrule isfollowed,alltherecoveryalgorithmswestudy inthechapterworkcor-
rectlyevenwiththestealpolicy.Further,theno-stealpolicydoesnotworkwithtrans-
actions that perform a large number of updates, since the buffer may get filled with
updatedpagesthatcannotbeevictedtodisk,andthetransactioncannotthenproceed.
Asaresult,thestandardapproachtakenbymostsystemsisthestealpolicy.
Toillustratetheneedforthewrite-aheadloggingrequirement,considerourbanking
examplewithtransactionsT andT .Supposethatthestateofthelogis:
0 1
<T start>
0
<T , A, 1000, 950>
0
andthattransactionT issuesaread(B).AssumethattheblockonwhichBresidesis
0
notinmainmemoryandthatmainmemoryisfull.SupposethattheblockonwhichA
residesischosentobeoutputtodisk.Ifthesystemoutputsthisblocktodiskandthena
crashoccurs,thevaluesinthedatabaseforaccountsA,B,andCare$950,$2000,and

--- Page 957 ---

928 Chapter19 RecoverySystem
$700, respectively. This database state is inconsistent. However, because of the WAL
requirements,thelogrecord:
<T , A, 1000, 950>
0
must be output tostable storage prior tooutput of the blockon whichA resides.The
systemcanusethelogrecordduringrecoverytobringthedatabasebacktoaconsistent
state.
When a block B is to be output to disk, all log records pertaining to data in B
1 1
must be output to stable storage before B is output. It is important that no writes to
1
the block B be in progress while the block is being output, since such a write could
1
violatethewrite-aheadloggingrule.Wecanensurethattherearenowritesinprogress
byusingaspecialmeansoflocking:
• Beforeatransactionperformsawriteonadataitem,itacquiresanexclusivelock
ontheblockinwhichthedataitemresides.Thelockisreleasedimmediatelyafter
theupdatehasbeenperformed.
• Thefollowingsequenceofactionsistakenwhenablockistobeoutput:
° Obtainanexclusivelockontheblock,toensurethatnotransactionisperform-
ingawriteontheblock.
° OutputlogrecordstostablestorageuntilalllogrecordspertainingtoblockB
1
havebeenoutput.
° OutputblockB todisk.
1
° Releasethelockoncetheblockoutputhascompleted.
Locksonbufferblocksareunrelatedtolocksusedforconcurrencycontroloftrans-
actions,andreleasingtheminanon-two-phasemannerdoesnothaveanyimplications
on transaction serializability. These locks, and other similar locks that are held for a
shortduration,areoftenreferredtoaslatches.
Locks on buffer blocks can also be used to ensure that buffer blocks are not up-
dated, and log records are not generated, while a checkpoint is in progress. This re-
striction may be enforced by acquiring exclusive locks on all buffer blocks, as well as
anexclusivelockonthelog,beforethecheckpointoperationisperformed.Theselocks
canbereleasedassoonasthecheckpointoperationhascompleted.
Databasesystemsusuallyhaveaprocessthatcontinuallycyclesthroughthebuffer
blocks,outputtingmodifiedbufferblocksbacktodisk.Theabovelockingprotocolmust
ofcoursebefollowedwhentheblocksareoutput.Asaresultofcontinuousoutputof
modifiedblocks,thenumberofdirtyblocksinthebuffer,thatis,blocksthathavebeen
modifiedinthebufferbuthavenotbeensubsequentlyoutput,isminimized.Thus,the
number of blocks that have to be output during a checkpoint is minimized; further,

--- Page 958 ---

19.5 BufferManagement 929
when a block needs to be evicted from the buffer, it is likely that there will be a non-
dirtyblockavailableforeviction,allowingtheinputtoproceedimmediatelyinsteadof
waitingforanoutputtocomplete.
19.5.3 Operating System Role in Buffer Management
Wecanmanagethedatabasebufferbyusingoneoftwoapproaches:
1. The database system reserves part of main memory to serve as a buffer that it,
rather than the operating system, manages. The database system manages data-
blocktransferinaccordancewiththerequirementsinSection19.5.2.
Thisapproachhasthedrawbackoflimitingflexibilityintheuseofmainmem-
ory.Thebuffermustbekeptsmallenoughthatotherapplicationshavesufficient
main memory available for their needs. However, even when the other applica-
tionsarenotrunning,thedatabasewillnotbeabletomakeuseofalltheavailable
memory.Likewise,non-databaseapplicationsmaynotusethatpartofmainmem-
ory reserved for the database buffer, even if some of the pages in the database
bufferarenotbeingused.
2. The database system implements its buffer within the virtual memory provided
by the operating system. Since the operating system knows about the memory
requirements of all processes in the system, ideally it should be in charge of
decidingwhat buffer blocks must be force-output to disk, and when. But, to en-
surethewrite-aheadloggingrequirementsinSection19.5.1,theoperatingsystem
should notwrite outthedatabase bufferpages itself,butinstead should request
the database system to force-output the buffer blocks. The database system in
turn would force-output the buffer blocks to the database, after writingrelevant
logrecordstostablestorage.
Unfortunately, almost all current-generation operating systems retain com-
pletecontrolofvirtualmemory.Theoperatingsystemreservesspaceondiskfor
storingvirtual-memorypagesthatarenotcurrentlyinmainmemory;thisspace
is called swap space. If the operating system decides to output a block B , that
x
block is output to the swap space on disk, and there is no way for the database
systemtogetcontroloftheoutputofbufferblocks.
Therefore, if the database buffer is in virtual memory, transfers between
databasefilesandthebufferinvirtualmemorymustbemanagedbythedatabase
system,whichenforcesthewrite-aheadloggingrequirementsthatwediscussed.
Thisapproachmayresultinextraoutputofdatatodisk.IfablockB isoutput
x
by the operating system, that block is not output to the database. Instead, it is
output to the swap space for the operating system’s virtual memory. When the
databasesystemneedstooutputB ,theoperatingsystemmayneedfirsttoinput
x
B fromitsswapspace.Thus,insteadofasingleoutputofB ,theremaybetwo
x x
outputsofB (onebytheoperatingsystem,andonebythedatabasesystem)and
x
oneextrainputofB .
x

--- Page 959 ---

930 Chapter19 RecoverySystem
Althoughbothapproachessufferfromsomedrawbacks,oneortheothermustbe
chosenunlesstheoperatingsystemisdesignedtosupporttherequirementsofdatabase
logging.
19.5.4 Fuzzy Checkpointing
ThecheckpointingtechniquedescribedinSection19.3.6requiresthatallupdatestothe
databasebetemporarilysuspendedwhilethecheckpointisinprogress.Ifthenumber
of pages in the buffer islarge, acheckpointmay take alongtime tofinish, whichcan
resultinanunacceptableinterruptioninprocessingoftransactions.
Toavoidsuchinterruptions,thecheckpointingtechniquecanbemodifiedtopermit
updatestostartoncethecheckpointrecordhasbeenwritten,butbeforethemodified
bufferblocksarewrittentodisk.Thecheckpointthusgeneratedisafuzzycheckpoint.
Sincepagesareoutputtodiskonlyafterthecheckpointrecordhasbeenwritten,it
ispossiblethatthesystemcouldcrashbeforeallpagesarewritten.Thus,acheckpoint
ondiskmaybeincomplete.Onewaytodealwithincompletecheckpointsisthis:The
locationinthelogofthecheckpointrecordofthelastcompletedcheckpointisstoredin
afixedposition,last-checkpoint,ondisk.Thesystemdoesnotupdatethisinformation
whenitwritesthecheckpointrecord.Instead,beforeitwritesthecheckpointrecord,
itcreatesalistofallmodifiedbufferblocks.Thelast-checkpointinformationisupdated
onlyafterallbufferblocksinthelistofmodifiedbufferblockshavebeenoutputtodisk.
Evenwithfuzzycheckpointing,abufferblockmustnotbeupdatedwhileitisbeing
output to disk, although other buffer blocks may be updated concurrently. The write-
ahead log protocol must be followed so that (undo) log records pertaining to a block
areonstablestoragebeforetheblockisoutput.
19.6 Failure with Loss of Non-Volatile Storage
Untilnow,wehaveconsideredonlythecasewhereafailureresultsinthelossofinfor-
mationresidinginvolatilestoragewhilethecontentofthenon-volatilestorageremains
intact. Although failures in which the content of non-volatile storage is lost are rare,
weneverthelessneedtobepreparedtodealwiththistypeoffailure.Inthissection,we
discuss only disk storage. Our discussions apply as well to other non-volatile storage
types.
Thebasic schemeistodump theentirecontentsofthedatabase tostable storage
periodically—say, once per day. For example, we may dump the database to one or
more magnetic tapes. If a failure occurs that results in the loss of physical database
blocks, the system uses the most recent dump in restoring the database to a previous
consistentstate.Oncethisrestorationhasbeenaccomplished,thesystemusesthelog
tobringthedatabasesystemtothemostrecentconsistentstate.
One approach to database dumping requires that no transaction may be active
duringthedumpprocedure,anditusesaproceduresimilartocheckpointing:

--- Page 960 ---

19.7 HighAvailabilityUsingRemoteBackupSystems 931
1. Outputalllogrecordscurrentlyresidinginmainmemoryontostablestorage.
2. Outputallbufferblocksontothedisk.
3. Copythecontentsofthedatabasetostablestorage.
4. Outputalogrecord<dump>ontothestablestorage.
Steps1,2,and4correspondtothethreestepsusedforcheckpointsinSection19.3.6.
To recover from the loss of non-volatile storage, the system restores the database
to disk by using the most recent dump. Then, it consults the log and redoes all the
actionssincethemostrecentdumpoccurred.Noticethatnoundooperationsneedto
beexecuted.
Incaseofapartialfailureofnon-volatilestorage,suchasthefailureofasingleblock
orafewblocks,onlythoseblocksneedtoberestored,andredoactionsperformedonly
forthoseblocks.
Adumpofthedatabasecontentsisalsoreferredtoasanarchivaldump,sincewe
canarchivethedumpsandusethemlatertoexamineoldstatesofthedatabase.Dumps
ofadatabaseandcheckpointingofbuffersaresimilar.
Most database systems also support an SQL dump, which writes out SQL DDL
statementsandSQLinsertstatementstoafile,whichcanthenbereexecutedtore-create
thedatabase.Suchdumpsareusefulwhenmigratingdatatoadifferentinstanceofthe
database,ortoadifferentversionofthedatabasesoftware,sincethephysicallocations
andlayoutmaybedifferentintheotherdatabaseinstanceordatabasesoftwareversion.
Thesimpledumpproceduredescribedhereiscostlyforthefollowingtworeasons.
First,theentiredatabasemustbecopiedtostablestorage,resultinginconsiderabledata
transfer. Second, since transaction processing is halted during the dump procedure,
CPU cycles are wasted. Fuzzy dump schemes have been developed that allow transac-
tionstobeactivewhilethedumpisinprogress.Theyaresimilartofuzzy-checkpointing
schemes;seethebibliographicalnotesformoredetails.
19.7 High Availability Using Remote Backup Systems
Traditional transaction-processing systems are centralized or client–server systems.
Suchsystemsarevulnerabletoenvironmentaldisasterssuchasfire,flooding,orearth-
quakes.Today’sapplicationsneedtransaction-processingsystemsthatcanfunctionin
spite of system failures or environmental disasters. Such systems must provide high
availability;thatis,thetimeforwhichthesystemisunusablemustbeextremelyshort.
Wecanachievehighavailabilitybyperformingtransactionprocessingatonesite,
calledtheprimarysite,andhavingaremotebackupsitewhereallthedatafromthepri-
marysitearereplicated.Theremotebackupsiteissometimesalsocalledthesecondary
site. The remote site must be kept synchronized with the primary site as updates are
performedattheprimary.Weachievesynchronizationbysendingalllogrecordsfrom
theprimarysitetotheremotebackupsite.Theremotebackupsitemustbephysically

--- Page 961 ---

932 Chapter19 RecoverySystem
primary network backup
log
records
Figure 19.6 Architecture ofremotebackupsystem.
separatedfromtheprimary—forexample,wecanlocateitinadifferentstate—sothata
disastersuchasafire,floodoranearthquakeattheprimarydoesnotalsodamagethe
remotebackupsite.3 Figure19.6showsthearchitectureofaremotebackupsystem.
When the primary site fails, the remote backup site takes over processing. First,
however,itperformsrecovery,usingits(perhapsoutdated) copyofthedatafromthe
primary and the log records received from the primary. In effect, the remote backup
siteisperformingrecoveryactionsthatwouldhavebeenperformedattheprimarysite
whenthelatterrecovered.Standardrecoveryalgorithms,withminormodifications,can
beusedforrecoveryattheremotebackupsite.Oncerecoveryhasbeenperformed,the
remotebackupsitestartsprocessingtransactions.
Availability is greatly increased over a single-site system, since the system can re-
coverevenifalldataattheprimarysitearelost.
Severalissuesmustbeaddressedindesigningaremotebackupsystem:
• Detection of failure. Itis important for the remote backup system to detectwhen
theprimaryhasfailed.Failureofcommunicationlinescanfooltheremotebackup
intobelievingthattheprimaryhasfailed.Toavoidthisproblem,wemaintainsev-
eralcommunicationlinkswithindependentmodesoffailurebetweentheprimary
and the remote backup. For example, several independent network connections,
includingperhapsamodemconnectionoveratelephoneline,maybeused.These
connections may be backed up via manual intervention by operators, who can
communicateoverthetelephonesystem.
• Transferofcontrol.Whentheprimaryfails,thebackupsitetakesoverprocessing
andbecomesthenewprimary.Thedecisiontotransfercontrolcanbedoneman-
uallyorcanbeautomatedusingsoftwareprovidedbydatabasesystemvendors.
Queriesmustnowbesenttothenewprimary.Todosoautomatically,manysys-
temsassigntheIPaddressoftheoldprimarytothenewprimary.Existingdatabase
connectionswillfail,butwhenanapplicationtriestoreopenaconnectionitgets
connectedtothenewprimary.Somesystemsinsteaduseahighavailabilityproxy
3Sinceearthquakescancausedamageoverawidearea,thebackupisgenerallyrequiredtobeinadifferentseismic
zone.

--- Page 962 ---

19.7 HighAvailabilityUsingRemoteBackupSystems 933
machine.Applicationclientsdonotconnecttothedatabasedirectly,butconnect
throughtheproxy.Theproxytransparentlyroutesapplicationrequeststothecur-
rent primary. (There can be more than one machine acting as proxy at the same
time,todealwithasituationwhereaproxymachinefails;requestscanberouted
throughanyactiveproxymachine.)
When the original primary site recovers, it can either play the role of remote
backup or it can take over the role of primary site again. In either case, the old
primarymustreceivealogofupdatescarriedoutbythebackupsitewhiletheold
primarywasdown.Theoldprimarymustcatchupwiththeupdatesinthelogby
applying them locally. The old primary can then act as a remote backup site. If
controlmustbetransferredback,thenewprimary(whichistheoldbackupsite)
canpretendtohavefailed,resultingintheoldprimarytakingover.
• Time to recover. If the log at the remote backup grows large, recovery will take a
long time. The remote backup site can periodically process the redo log records
that it has received and can perform a checkpointso that earlierparts of the log
canbedeleted.Thedelaybeforetheremotebackuptakesovercanbesignificantly
reducedasaresult.
Ahot-spareconfigurationcanmaketakeoverbythebackupsitealmostinstanta-
neous.Inthisconfiguration,theremotebackupsitecontinuallyprocessesredolog
records as they arrive, applying the updates locally. As soon as the failure of the
primaryisdetected,thebackupsitecompletesrecoverybyrollingbackincomplete
transactions;itisthenreadytoprocessnewtransactions.
• Timetocommit.Toensurethattheupdatesofacommittedtransactionaredurable,
a transaction must not be declared committed until its log records have reached
the backup site. This delay can result in a longer wait to commit a transaction,
and some systems therefore permit lower degrees of durability. The degrees of
durabilitycanbeclassifiedasfollows:
° One-safe.Atransactioncommitsassoonasitscommitlogrecordiswrittento
stablestorageattheprimarysite.
The problem withthisschemeisthatthe updates of acommittedtransac-
tion may nothave madeitto thebackup site when the backup site takes over
processing. Thus, the updates may appear to be lost. When the primary site
recovers,thelostupdatescannotbemergedindirectly,sincetheupdatesmay
conflict with later updates performed at the backup site. Thus, human inter-
ventionmayberequiredtobringthedatabasetoaconsistentstate.
° Two-very-safe.Atransactioncommitsassoonasitscommitlogrecordiswritten
tostablestorageattheprimaryandthebackupsite.
Theproblemwiththisschemeisthattransactionprocessingcannotproceed
if either the primary or the backup site is down. Thus, availability is actually
less than in the single-site case, although the probability of data loss is much
less.

--- Page 963 ---

934 Chapter19 RecoverySystem
° Two-safe.Thisschemeisthesameastwo-very-safeifbothprimaryandbackup
sitesareactive.Ifonlytheprimaryisactive,thetransactionisallowedtocom-
mitassoonasitscommitlogrecordiswrittentostablestorageattheprimary
site.
Thisschemeprovidesbetteravailabilitythandoestwo-very-safe,whileavoid-
ingtheproblemoflosttransactionsfacedbytheone-safescheme.Itresultsin
aslowercommitthantheone-safescheme,butthebenefitsgenerallyoutweigh
thecost.
Most database systems today provide support for replication to a backup copy,
alongwithsupportforhotsparesandquickswitchoverfromtheprimarytothebackup.
Manydatabasesystemsalsoallowreplicationtomorethanonebackup;suchafeature
canbeusedtoprovidealocalbackuptodealwithmachinefailures,alongwitharemote
backuptodealwithdisasters.
Although update transactions cannot be executed at a backup server, many
database systems allow read-only queries to be executed at backup servers. The load
attheprimarycanbereducedbyexecutingatleastsomeoftheread-onlytransactions
at the backup. Snapshot-isolation can be used at the backup server to give readers a
transactionconsistentviewofthedata,whileensuringthatupdatesareneverblocked
frombeingappliedatthebackup.
Remotebackupisalsosupported attheleveloffilesystems, typicallybynetwork
file system or NAS implementations, as well as at the disk level, typically by storage
areanetwork(SAN)implementations.Remotebackupsarekeptsynchronizedwiththe
primarybyensuringthatallblockwritesperformedattheprimaryarealsoreplicated
at the backup. File-system level and disk level backups can be used to replicate the
database data as well as log files. If the primary fails, the backup system can recover
using its replica of the data and log files. However, to ensure that recovery will work
correctly at the backup site, the file system level replication must be done in a way
that ensures that the write-ahead logging (WAL) rule continues to hold. To do so, if
the database forces a block to disk and then performs some other update actions at
the primary, the block must also be forced to disk at the backup, before subsequent
updatesareperformedatthebackupsystem.
An alternative way of achieving high availability is to use a distributed database,
withdatareplicatedatmorethanonesite.Transactionsarethenrequiredtoupdateall
replicas of any data item that they update. We study distributed databases, including
replication,inChapter23.Whenproperlyimplemented,distributeddatabasescanpro-
vide a higher level of availability than remote backup systems, but are more complex
andexpensivetoimplementandmaintain.
End-users typically interact with applications, rather than directly with database.
Toensureavailabilityofanapplication,aswellastosupporthandlingofalargenumber
ofrequestspersecond,applicationsmayrunonmultipleapplicationservers.Requests
from clients are load-balanced across the servers. The load-balancer ensures that all
requests from a particular clientare sent to a single application server, as long as the

--- Page 964 ---

19.8 EarlyLockReleaseandLogicalUndoOperations 935
applicationserverisfunctional.Ifanapplicationserverfails,clientrequestsarerouted
to other application servers, so users can continue to use the application. Although
usersmaynoticeasmallinterruption,applicationserverscanensurethatauserisnot
forcedtologinagain,bysharingsessioninformationacrossapplicationservers.
19.8 Early Lock Release and Logical Undo Operations
Anyindexusedinprocessingatransaction,suchasaB+-tree,canbetreatedasnormal
data, but to increase concurrency, we can use the B+-tree concurrency-control algo-
rithmdescribedinSection18.10.2toallowlockstobereleasedearly,inanon-two-phase
manner. As a result of early lock release, it is possible that a value in a B+-tree node
is updated by one transaction T , which inserts an entry (V1,R1), and subsequently
1
byanothertransaction T ,whichinsertsanentry(V2,R2) inthe samenode,moving
2
theentry(V1,R1)evenbeforeT completesexecution.4Atthispoint,wecannotundo
1
transactionT byreplacingthecontentsofthenodewiththeoldvaluepriortoT per-
1 1
formingitsinsert,sincethatwouldalsoundotheinsertperformedbyT ;transaction
2
T maystillcommit(ormayhavealreadycommitted).Inthisexample,theonlywayto
2
undotheeffectofinsertionof(V1,R1)istoexecuteacorrespondingdeleteoperation.
Intherestofthissection,weseehowtoextendtherecoveryalgorithmofSection
19.4tosupportearlylockrelease.
19.8.1 Logical Operations
Theinsertionanddeletionoperationsareexamplesofaclassofoperationsthatrequire
logical undo operations since they release locks early; we call such operations logical
operations.Suchearlylockreleaseisimportantnotonlyforindices,butalsoforoper-
ationsonothersystem datastructuresthatareaccessedandupdated veryfrequently;
examplesincludedatastructuresthattracktheblockscontainingrecordsofarelation,
thefreespaceinablock,andthefreeblocksinadatabase.Iflockswerenotreleased
earlyafterperformingoperations on such datastructures, transactions wouldtend to
runserially,affectingsystemperformance.
The theory of conflict serializability has been extended to operations, based on
what operations conflict with what other operations. For example, two insert opera-
tions on a B+-tree do not conflict if they insert different key values, even if they both
update overlapping areas of the same index page. However, insert and delete opera-
tionsconflictwithotherinsertanddeleteoperations, aswellaswithreadoperations,
if they use the same key value. See the bibliographical notes for references to more
informationonthistopic.
Operationsacquirelower-levellockswhiletheyexecutebutreleasethemwhenthey
complete; the corresponding transaction must however retain a higher-level lock in a
4Recallthatanentryconsistsofakeyvalueandarecordidentifier,orakeyvalueandarecordinthecaseoftheleaf
levelofaB+-treefileorganization.

--- Page 965 ---

936 Chapter19 RecoverySystem
two-phase manner to prevent concurrent transactions from executing conflicting ac-
tions. For example, while an insert operation is being performed on a B+-tree page,
a short-term lock is obtained on the page, allowing entries in the page to be shifted
duringtheinsert;theshort-termlockisreleasedassoonasthepagehasbeenupdated.
Such earlylockrelease allows a second insert to execute on the same page. However,
each transaction must obtain a lock on the key values being inserted or deleted and
retainitinatwo-phase manner,topreventaconcurrenttransaction from executinga
conflictingread,insert,ordeleteoperationonthesamekeyvalue.
Oncethelower-levellockisreleased,theoperationcannotbeundonebyusingthe
oldvaluesofupdateddataitemsandmustinsteadbeundonebyexecutingacompen-
sating operation; such an operation is called a logical undo operation. It is important
thatthelower-levellocksacquiredduringanoperationaresufficienttoperformasub-
sequentlogicalundooftheoperation,forreasonsexplainedlaterinSection19.8.4.
19.8.2 Logical Undo Log Records
To allow logical undo of operations, before an operation is performed to modify an
index, the transaction creates a log record <T,O, operation-begin>, where O is a
i j j
unique identifier for the operation instance.5 While the system is executing the oper-
ation, it creates update log records in the normal fashion for all updates performed
by the operation. Thus, the usual old-value and new-value information is written out
as usual for each update performed by the operation; the old-value information is re-
quiredincasethetransactionneedstoberolledbackbeforetheoperationcompletes.
Whentheoperationfinishes,itwritesanoperation-endlogrecordoftheform<T,O,
i j
operation-end,U>,wheretheU denotesundoinformation.
Forexample,iftheoperationinsertedanentryinaB+-tree,theundoinformation
U would indicatethat adeletionoperation isto be performed and would identifythe
B+-treeandwhatentrytodeletefromthetree.Suchloggingofinformationaboutop-
erationsiscalledlogicallogging.Incontrast,loggingofold-valueandnew-valueinfor-
mationiscalledphysicallogging,andthecorrespondinglogrecordsarecalledphysical
logrecords.
Notethatintheabovescheme,logicalloggingisusedonlyforundo,notforredo;
redooperationsareperformedexclusivelyusingphysicallogrecord.Thisisbecausethe
stateofthedatabaseafterasystemfailuremayreflectsomeupdatesofanoperationand
nototheroperations,dependingonwhatbufferblockshadbeenwrittentodiskbefore
the failure. Data structures such as B+-trees would not be in a consistent state, and
neitherlogicalredonorlogicalundooperationscanbeperformedonaninconsistent
data structure. To perform logical redo or undo, the database state on disk must be
operationconsistent,thatis,itshouldnothavepartialeffectsofanyoperation.However,
asweshallsee,thephysicalredoprocessingintheredophaseoftherecoveryscheme,
along with undo processing using physical log records, ensures that the parts of the
5Thepositioninthelogoftheoperation-beginlogrecordcanbeusedastheuniqueidentifier.

--- Page 966 ---

19.8 EarlyLockReleaseandLogicalUndoOperations 937
database accessed by a logical undo operation are in an operation consistent state
beforethelogicalundooperationisperformed.
Anoperationissaidtobeidempotentifexecutingitseveraltimesinarowgivesthe
same result as executing it once. Operations such as inserting an entry into a B+-tree
maynotbeidempotent,andtherecoveryalgorithmmustthereforemakesurethatan
operationthathasalreadybeenperformedisnotperformedagain.Ontheotherhand,
aphysicallogrecordisidempotent,sincethecorrespondingdataitemwouldhavethe
samevalueregardlessofwhethertheloggedupdateisexecutedoneormultipletimes.
19.8.3 Transaction Rollback with Logical Undo
When rolling back a transaction T, the log is scanned backwards, and log records
i
correspondingtoT areprocessedasfollows:
i
1. Physicallogrecordsencounteredduringthescanarehandledasdescribedearlier,
exceptthosethatareskippedasdescribedshortly.Incompletelogicaloperations
areundoneusingthephysicallogrecordsgeneratedbytheoperation.
2. Completed logical operations, identified by operation-end records, are rolled
backdifferently.Wheneverthesystemfindsalogrecord<T,O,operation-end,
i j
U>,ittakesspecialactions:
a. It rolls back the operation by using the undo information U in the log
record.Itlogstheupdatesperformedduringtherollbackoftheoperation
justlikeupdatesperformedwhentheoperationwasfirstexecuted.
Attheendoftheoperationrollback,insteadofgeneratingalogrecord
<T,O, operation-end, U>, the database system generates a log record
i j
<T,O,operation-abort>.
i j
b. Asthebackwardscanofthelogcontinues,thesystemskipsalllogrecords
of transaction T until it finds the log record <T,O, operation-begin>.
i i j
After it finds the operation-begin log record, it processes log records of
transactionT inthenormalmanneragain.
i
Observe that the system logs physical undo information for the updates per-
formed during rollback, instead of using redo-only compensation log records.
Thisisbecauseacrashmayoccurwhilealogicalundoisinprogress,andonre-
coverythesystemhastocompletethelogicalundo;todoso,restartrecoverywill
undothepartialeffectsoftheearlierundo,usingthephysicalundoinformation,
andthenperformthelogicalundoagain.
Observealsothatskippingoverphysicallogrecordswhentheoperation-end
logrecordisfoundduringrollbackensuresthattheoldvaluesinthephysicallog
recordarenotusedforrollbackoncetheoperationcompletes.

--- Page 967 ---

938 Chapter19 RecoverySystem
3. Ifthesystemfindsarecord<T,O,operation-abort>,itskipsallprecedingre-
i j
cords(includingtheoperation-endrecordforO)untilitfindstherecord<T,O,
j i j
operation-begin>.
An operation-abort log record would be found only if a transaction that is
being rolled back had been partially rolled back earlier. Recall that logical op-
erations may not be idempotent, and hence a logical undo operation must not
be performed multiple times. These preceding log records must be skipped to
prevent multiple rollback of the same operation in case there had been a crash
duringanearlierrollbackandthetransactionhadalreadybeenpartlyrolledback.
4. Asbefore,whenthe<T start>logrecordhasbeen found,thetransaction roll-
i
backiscomplete,andthesystemaddsarecord<T abort>tothelog.
i
If a failure occurs whilea logical operation is in progress, the operation-endlog
recordfortheoperationwillnotbefoundwhenthetransactionisrolledback.However,
foreveryupdateperformedbytheoperation,undoinformation—intheformoftheold
value in the physical log records—is available in the log. The physical log records will
beusedtorollbacktheincompleteoperation.
Nowsupposeanoperationundowasinprogresswhenthesystemcrashoccurred,
which could happen if a transaction was being rolled back when the crash occurred.
If T aborts before
0
operation O ends, undo of
1
update to C will be physical
Beginning of log T has completed operation O
0 1
<T start> on C, releases lower-level
0
<T , B, 2000, 2050> lock; physical undo cannot be
0
<T , O, operation-begin> done anymore, logical undo
0 1
<T , C, 700, 600> will add 100 to C
0
<T , O, operation-end, (C, +100)>
0 1 T can update C since T has
<T start> 1 0
1 released lower-level lock on C
<T , O , operation-begin>
0 2
T
0 <T, C, 600, 400>
decides 1 T 1 releases lower-level lock
<T, O , operation-end, (C, +200)>
to abort 1 2 on C
Logical undo of O adds 100
<T , C, 400, 500> 1
0
on C
<T , O, operation-abort>
0 1
<T 0 , B, 2000> O 1 undo complete
<T , abort>
0
<T, commit>
1
Figure 19.7 Transactionrollbackwithlogical undooperations.

--- Page 968 ---

19.8 EarlyLockReleaseandLogicalUndoOperations 939
Thenthephysicallogrecordswrittenduringoperationundowouldbefound,andthe
partial operation undo would itself be undone using these physical log records. Con-
tinuinginthebackwardscanofthelog,theoriginaloperation’soperation-endrecord
would then be found, and the operation undo would be executed again. Rolling back
the partial effects of the earlier undo operation using the physical log records brings
the database to a consistent state, allowingthe logicalundo operation to be executed
again.
Figure19.7showsanexampleofaloggeneratedbytwotransactions,whichaddor
subtractavaluefromadataitem.EarlylockreleaseonthedataitemC bytransaction
T after operation O completes allows transaction T to update the data item using
0 1 1
O ,evenbeforeT completes,butnecessitateslogicalundo.Thelogicalundooperation
2 0
needstoaddorsubtractavaluefromthedataiteminsteadofrestoringanoldvalueto
thedataitem.
Theannotationsonthefigureindicatethatbeforeanoperationcompletes,rollback
canperformphysicalundo;aftertheoperationcompletesandreleaseslower-levellocks,
theundomustbeperformedbysubtractingoraddingavalue,insteadofrestoringthe
oldvalue.Intheexampleinthefigure,T rollsbackoperationO byadding100toC;
0 1
ontheotherhand,fordataitemB,whichwasnotsubjecttoearlylockrelease,undois
performedphysically.ObservethatT ,whichhadperformedanupdateonC,commits,
1
and its update O , which added 200 to C and was performed before the undo of O ,
2 1
haspersistedeventhoughO hasbeenundone.
1
Figure19.8showsanexampleofrecoveryfromacrashwithlogicalundologging.
In this example, operation T was active and executing operation O at the time of
1 4
checkpoint.Intheredopass,theactionsofO thatareafterthecheckpointlogrecord
4
areredone.Atthetimeofcrash,operationO wasbeingexecutedbyT ,buttheoper-
5 2
ationwasnotcomplete.Theundo-listcontainsT andT attheendoftheredopass.
1 2
During the undo pass, the undo of operation O is carried out using the old value in
5
thephysicallogrecord,settingC to400;thisoperationisloggedusingaredo-onlylog
record. The start record of T is encountered next, resulting in the addition of <T
2 2
abort>tothelogandremovalofT fromundo-list.
2
Thenextlogrecordencounteredistheoperation-endrecordofO ;logicalundo
4
is performed for this operation by adding 300 to C, which is logged physically, and
an operation-abort log record is added for O . The physical log records that were
4
part of O are skipped until the operation-begin log record for O is encountered.
4 4
Inthisexample,therearenootherinterveninglogrecords,butingeneral logrecords
fromothertransactionsmaybefoundbeforewereachtheoperation-beginlogrecord;
suchlogrecordsshouldofcoursenotbeskipped(unlesstheyarepartofacompleted
operation for the corresponding transaction and the algorithm skips those records).
After the operation-begin log record is found for O , a physical log record is found
4
forT ,whichisrolledbackphysically.FinallythestartlogrecordforT isfound;this
1 1
resultsin< T abort>beingaddedtothelogandT beingdeletedfromundo-list.At
1 1
thispointundo-listisempty,andtheundophaseiscomplete.

--- Page 969 ---

940 Chapter19 RecoverySystem
Start log records
Beginning of log
found for all
<T start> transactions in
0
<T , B, 2000, 2050> undo list
0
<T commit>
0
<T start>
1
<T, B, 2050, 2100>
1
<T, O , operation-begin>
1 4
<checkpoint {T}> Redo Pass
1
<T, C, 700, 400>
1
<T, O , operation-end (C, +300)>
1 4
<T start>
End of 2
<T , O , operation-begin>
log at 2 5
<T , C, 400, 300>
crash! 2
Undo list: T, T Undo Pass
1 2
<T , C, 400>
2 Update of C was part of O , undone
5
<T abort>
2 physically during recovery since
Records
added <T 1 , C, 400, 700> O 5 did not complete
<T, O , operation-abort>
during 1 4
<T, B, 2050>
recovery 1 Logical undo of O adds 300 to C
4
<T abort>
1
Figure 19.8 Failurerecoveryactionswithlogicalundooperations.
19.8.4 Concurrency Issues in Logical Undo
Asmentionedearlier,itisimportantthatthelower-levellocksacquiredduringan op-
erationaresufficienttoperformasubsequentlogicalundooftheoperation;otherwise
concurrent operations that execute during normal processing may cause problems in
theundophase.Forexample,supposethelogicalundoofoperationO oftransaction
1
T canconflictatthedataitemlevelwithaconcurrentoperationO oftransactionT ,
1 2 2
andO completeswhileO doesnot.Assumealsothatneithertransactionhadcommit-
1 2
tedwhenthesystemcrashed.ThephysicalupdatelogrecordsofO mayappearbefore
2
and after the operation-endrecord forO , and duringrecoveryupdates done during
1
the logical undo of O may get fully or partially overwritten by old values during the
1
physicalundoofO .ThisproblemcannotoccurifO hadobtainedallthelower-level
2 1
locksrequiredforthelogicalundoofO ,sincethentherecannotbesuchaconcurrent
1
O .
2
If both the original operation and its logical undo operation access a single page
(suchoperationsarecalledphysiologicaloperationsandarediscussedinSection19.9),
thelockingrequirementaboveismeteasily.Otherwisethedetailsofthespecificopera-
tionneedtobeconsideredwhendecidingonwhatlower-levellocksneedtobeobtained.
Forexample,updateoperationsonaB+-treecouldobtainashort-termlockontheroot,

--- Page 970 ---

19.9 ARIES 941
toensurethatoperationsexecuteserially.Seethebibliographicalnotesforreferences
on B+-tree concurrencycontrol and recovery exploitinglogical undo logging. See the
bibliographical notes also for references to an alternative approach, called multilevel
recovery,whichrelaxesthislockingrequirement.
19.9 ARIES
The state of the art in recovery methods is best illustrated by the ARIES recovery
method.TherecoverytechniquethatwedescribedinSection19.4,alongwiththelog-
icalundologgingtechniquesdescribedinSection19.8,aremodeledafter ARIES,but
theyhavebeensimplifiedsignificantlytobringoutkeyconceptsandmakethemeasier
tounderstand.Incontrast,ARIESusesanumberoftechniquestoreducethetimetaken
forrecoveryandtoreducetheoverheadofcheckpointing.Inparticular,ARIESisable
toavoidredoingmanyloggedoperationsthathavealreadybeenappliedandtoreduce
the amount of information logged. The price paid is greater complexity; the benefits
areworththeprice.
The four major differencesbetween ARIES and the recovery algorithm presented
earlierarethatARIES:
1. Uses a log sequence number (LSN) to identify log records and stores LSNs in
databasepagestoidentifywhichoperationshavebeenappliedtoadatabasepage.
2. Supports physiological redo operations, which are physical in that the affected
pageisphysicallyidentifiedbutcanbelogicalwithinthepage.
Forinstance,thedeletionofarecordfromapagemayresultinmanyother
records in the page being shifted, if a slotted page structure (Section 13.2.2) is
used.Withphysicalredologging,allbytesofthepageaffectedbytheshiftingof
records must be logged. With physiological logging, the deletion operation can
belogged,resultinginamuchsmallerlogrecord.Redoofthedeletionoperation
woulddeletetherecordandshiftotherrecordsasrequired.
3. Usesadirtypagetabletominimizeunnecessaryredosduringrecovery.Asmen-
tionedearlier,dirtypagesarethosethathavebeenupdatedinmemory,andthe
diskversionisnotup-to-date.
4. Uses a fuzzy-checkpointing scheme that records only information about dirty
pagesandassociatedinformationanddoesnotevenrequirewritingofdirtypages
todisk.Itflushesdirtypagesinthebackground,continuously,insteadofwriting
themduringcheckpoints.
Intherestofthissection,weprovideanoverviewofARIES.Thebibliographicalnotes
listsomereferencesthatprovideacompletedescriptionofARIES.

--- Page 971 ---

942 Chapter19 RecoverySystem
19.9.1 Data Structures
Each log record in ARIES has a log sequence number (LSN) that uniquely identifies
the record. The number is conceptuallyjust a logicalidentifierwhose value isgreater
for log records that occur later in the log. In practice, the LSN is generated in such a
waythatitcanalsobe used tolocate thelogrecordon disk. Typically,ARIES splitsa
log into multiple log files, each of which has a file number. When a log file grows to
somelimit,ARIESappendsfurtherlogrecordstoanewlogfile;thenewlogfilehasa
file number that is higher by 1 than the previous log file. The LSN then consists of a
filenumberandanoffsetwithinthefile.
Each page also maintains an identifier called the PageLSN. Whenever an update
operation (whether physical or physiological) occurs on a page, the operation stores
the LSN of its log record in the PageLSN field of the page. During the redo phase of
recovery,anylogrecordswithLSNlessthanorequaltothePageLSNofapageshould
not be executed on the page, since their actions are already reflected on the page. In
combinationwithaschemeforrecordingPageLSNsaspartofcheckpointing,whichwe
present later, ARIES can avoid even reading many pages for which logged operations
arealreadyreflectedondisk.Thereby,recoverytimeisreducedsignificantly.
ThePageLSNisessentialforensuringidempotenceinthepresenceofphysiological
redooperations,sincereapplyingaphysiologicalredothathasalreadybeenappliedto
apagecouldcauseincorrectchangestoapage.
Pages should not be flushed to disk while an update is in progress, since physio-
logicaloperationscannotberedoneonthepartiallyupdatedstateofthepageondisk.
Therefore, ARIES uses latches on buffer pages to prevent them from being written to
diskwhiletheyarebeingupdated.Itreleasesthebufferpagelatchonlyaftertheupdate
iscompletedandthelogrecordfortheupdatehasbeenwrittentothelog.
EachlogrecordalsocontainstheLSNofthepreviouslogrecordofthesametrans-
action.Thisvalue,storedinthePrevLSNfield,permitslogrecordsofatransactionto
be fetched backward, without reading the whole log. There are special redo-only log
recordsgeneratedduringtransactionrollback,calledcompensationlogrecords(CLRs)
inARIES.Theseservethesamepurposeastheredo-onlylogrecordsinourearlierre-
coveryscheme.Inaddition,CLRsservetheroleoftheoperation-abortlogrecordsin
ourscheme.TheCLRshaveanextra field,calledtheUndoNextLSN,thatrecordsthe
LSNofthelogthatneedstobeundonenext,whenthetransactionisbeingrolledback.
Thisfieldserves the same purpose asthe operation identifierin theoperation-abort
log record in our earlier recovery scheme, which helps to skip over log records that
havealreadybeenrolledback.
TheDirtyPageTablecontainsalistofpagesthathavebeenupdatedinthedatabase
buffer.Foreachpage,itstoresthePageLSNandafieldcalledtheRecLSN,whichhelps
identifylogrecordsthathavebeenappliedalreadytotheversionofthepage ondisk.
WhenapageisinsertedintotheDirtyPageTable(whenitisfirstmodifiedinthebuffer
pool),thevalueofRecLSNissettothecurrentendoflog.Wheneverthepageisflushed
todisk,thepageisremovedfromtheDirtyPageTable.

--- Page 972 ---

19.9 ARIES 943
A checkpoint log record contains the DirtyPageTable and a list of active transac-
tions.Foreachtransaction,thecheckpointlogrecordalsonotesLastLSN,theLSNof
the last log record written by the transaction. A fixed position on disk also notes the
LSNofthelast(complete)checkpointlogrecord.
Figure19.9illustratessomeofthedatastructuresusedinARIES.Thelogrecords
shown in the figure are prefixed by their LSN; these may not be explicitly stored, but
inferredfromthepositioninthelog,inanactualimplementation.Thedataitemiden-
tifierinalogrecordisshownintwoparts,forexample,4894.1; thefirstidentifiesthe
page,andthesecondpartidentifiesarecordwithinthepage(weassumeaslottedpage
recordorganizationwithinapage).Notethatthelogisshownwiththenewestrecords
ontop,sinceolderlogrecords,whichareondisk,areshownlowerinthefigure.
Eachpage(whetherinthebufferorondisk)hasanassociatedPageLSNfield.You
canverifythattheLSNforthelastlogrecordthatupdatedpage4894is7567.Bycom-
paringPageLSNsforthepagesinthebufferwiththePageLSNsforthecorresponding
pages in stable storage, you can observe that the DirtyPageTable contains entries for
allpagesinthebufferthathavebeenmodifiedsincetheywerefetchedfromstablestor-
age. The RecLSN entry in the DirtyPageTable reflects the LSN at the end of the log
PageID PageLSN RecLSN
7567 2345
4894 7567 7564
7200 7565 7565
Page 4894 Page 9923 Dirty Page Table
7565
7567: <T ,4894.1, 40, 60>
145
7566: <T , commit>
Page 7200 143
Database Buffer Log Buffer (PrevLSN and UndoNextLSN
fields not shown)
Stable data Stable log
4566 4404
7565: <T ,7200.2, 60, 80>
143
7564: <T ,4894.1, 20, 40>
Page 4894 Page 7200 145
7563: <T begin>
145
2345
Page 9923
Figure 19.9 DatastructuresusedinARIES.

--- Page 973 ---

944 Chapter19 RecoverySystem
whenthepagewasaddedtoDirtyPageTableandwouldbegreaterthanorequaltothe
PageLSNforthatpageonstablestorage.
19.9.2 Recovery Algorithm
ARIESrecoversfromasystemcrashinthreepasses.
• Analysispass:Thispassdetermineswhichtransactionstoundo,whichpageswere
dirtyatthetimeofthecrash,andtheLSNfromwhichtheredopassshouldstart.
• Redo pass: This pass starts from a position determined during analysis and per-
formsaredo,repeatinghistory,tobringthedatabasetoastateitwasinbeforethe
crash.
• Undo pass: This pass rolls back all transactions that were incomplete at the time
ofcrash.
19.9.2.1 AnalysisPass
TheanalysispassfindsthelastcompletecheckpointlogrecordandreadsintheDirty-
PageTablefromthisrecord.ItthensetsRedoLSNtotheminimumoftheRecLSNsof
thepagesintheDirtyPageTable.Iftherearenodirtypages,itsetsRedoLSNtotheLSN
ofthecheckpointlogrecord.TheredopassstartsitsscanofthelogfromRedoLSN.All
thelogrecordsearlierthanthispointhavealreadybeenappliedtothedatabasepages
ondisk.Theanalysispassinitiallysetsthelistoftransactionstobeundone,undo-list,
to the list of transactions in the checkpoint log record. The analysis pass also reads
fromthecheckpointlogrecordtheLSNsofthelastlogrecordforeachtransactionin
undo-list.
The analysis pass continues scanning forward from the checkpoint. Whenever it
findsalogrecordforatransactionnotintheundo-list,itaddsthetransactiontoundo-
list. Whenever it finds a transaction end log record, it deletes the transaction from
undo-list.Alltransactionsleftinundo-listattheendofanalysishavetoberolledback
later, in the undo pass. The analysis pass also keeps track of the last record of each
transactioninundo-list,whichisusedintheundopass.
The analysis pass also updates DirtyPageTable whenever it finds a log record for
an update on apage. Ifthepage isnotinDirtyPageTable, theanalysis pass addsitto
DirtyPageTableandsetstheRecLSNofthepagetotheLSNofthelogrecord.
19.9.2.2 RedoPass
Theredopassrepeatshistorybyreplayingeveryactionthatisnotalreadyreflectedin
the page on disk. The redo pass scans the log forward from RedoLSN. Whenever it
findsanupdatelogrecord,ittakesthisaction:

--- Page 974 ---

19.9 ARIES 945
• Ifthepage isnotinDirtyPageTableoriftheLSNoftheupdate logrecordisless
thanthe RecLSNofthe page inDirtyPageTable, thentheredopassskips thelog
record.
• Otherwisetheredopassfetchesthepagefromdisk,andifthePageLSNislessthan
theLSNofthelogrecord,itredoesthelogrecord.
Note that if either of the tests is negative, then the effects of the log record have
alreadyappearedonthepage;otherwisetheeffectsofthelogrecordarenotreflectedon
the page. Since ARIES allows non-idempotent physiological log records, a log record
should not be redone if its effect is already reflected on the page. If the first test is
negative,itisnotevennecessarytofetchthepagefromdisktocheckitsPageLSN.
19.9.2.3 UndoPassandTransactionRollback
Theundopassisrelativelystraightforward. Itperformsasinglebackward scanofthe
log,undoingalltransactionsinundo-list.Theundopassexaminesonlylogrecordsof
transactionsinundo-list;thelastLSNrecordedduringtheanalysispassisusedtofind
thelastlogrecordforeachtransactioninundo-list.
Whenever an update log record is found, it is used to perform an undo (whether
for transaction rollback during normal processing, or during the restart undo pass).
The undo pass generates a CLR containing the undo action performed (which must
be physiological). It sets the UndoNextLSN of the CLR to the PrevLSN value of the
updatelogrecord.
IfaCLRisfound,itsUndoNextLSNvalueindicatestheLSNofthenextlogrecord
to be undone for that transaction; later log records for that transaction have already
beenrolledback.ForlogrecordsotherthanCLRs,thePrevLSNfieldofthelogrecord
indicates the LSN of the next log record to be undone for that transaction. The next
log record to be processed at each stop in the undo pass is the maximum, across all
transactionsinundo-list,ofnextlogrecordLSN.
Figure 19.10 illustrates the recovery actions performed by ARIES on an example
log.Weassumethatthelastcompletedcheckpointpointerondiskpointstothecheck-
pointlogrecordwithLSN7568.ThePrevLSNvaluesinthelogrecordsareshownusing
arrowsinthefigure,whiletheUndoNextLSNvalueisshownusingadashedarrowfor
theonecompensationlogrecord,withLSN7565,inthefigure.Theanalysispasswould
startfromLSN7568,andwhenitiscomplete,RedoLSNwouldbe7564.Thus,theredo
pass must start at the log record with LSN 7564. Note that this LSN is less than the
LSNofthecheckpointlogrecord,sincetheARIEScheckpointingalgorithmdoesnot
flushmodifiedpagestostablestorage.TheDirtyPageTableattheendofanalysiswould
includepages4894,7200fromthecheckpointlogrecord,and2390whichisupdated
bythelogrecordwithLSN7570.Attheendoftheanalysispass,thelistoftransactions
tobeundoneconsistsofonlyT inthisexample.
145
TheredopassfortheprecedingexamplestartsfromLSN7564andperformsredo
of log records whose pages appear in DirtyPageTable. The undo pass needs to undo

--- Page 975 ---

946 Chapter19 RecoverySystem
newer PrevLSN
End of log at crash pointers
7571: <T commit>
146
7570: <T , 2390.4, 50, 90>
146
7569: <T begin>
146
7568: checkpoint
Txn lastLSN
T145 7567
PageID PageLSN RecLSN
4894 7567 7564
Undo
7200 7565 7565
pass
7567: <T ,4894.1, 40, 60> Analysis
145
pass
7566: <T commit>
143 CLR
7565: <T ,7200.2, 60>
143
7564: <T 145 ,4894.1, 20, 40> Redo
pass
7563: <T begin>
145
older 7562: <T , 7200.2, 60, 80> UndoNextLSN
143
Figure 19.10 RecoveryactionsinARIES.
only transaction T , and hence it starts from its LastLSN value 7567 and continues
145
backwardsuntiltherecord<T start>isfoundatLSN7563.
145
19.9.3 Other Features
AmongotherkeyfeaturesthatARIESprovidesare:
• Nestedtopactions:ARIESallowstheloggingofoperationsthatshouldnotbeun-
doneevenifatransactiongetsrolledback;forexample,ifatransactionallocatesa
pagetoarelation,evenifthetransactionisrolledback,thepageallocationshould
notbeundonesinceothertransactionsmayhavestoredrecordsinthepage.Such
operations that should not be undone are called nested top actions. Such opera-
tions can be modeled as operations whose undo action does nothing. In ARIES,
suchoperationsareimplementedbycreatingadummyCLRwhoseUndoNextLSN
issetsuchthattransaction rollbackskipsthelogrecordsgenerated bytheopera-
tion.
• Recovery independence: Some pages can be recovered independently from others
sothattheycanbeusedevenwhileotherpagesarebeingrecovered.Ifsomepages

--- Page 976 ---

19.10 RecoveryinMain-MemoryDatabases 947
of a disk fail, they can be recovered without stopping transaction processing on
otherpages.
• Savepoints:Transactionscanrecordsavepointsandcanberolledbackpartiallyup
toasavepoint.Thiscanbe quiteuseful fordeadlockhandling,sincetransactions
can be rolled back up to a point that permits release of required locks and then
restartedfromthatpoint.
Programmerscanalsousesavepointstoundoatransactionpartially,andthen
continueexecution;thisapproachcanbeuseful tohandlecertainkindsoferrors
detectedduringthetransactionexecution.
• Fine-grained locking: The ARIES recovery algorithm can be used with index
concurrency-controlalgorithmsthatpermittuple-levellockingonindices,instead
ofpage-levellocking,whichimprovesconcurrencysignificantly.
• Recoveryoptimizations:TheDirtyPageTablecanbeusedtoprefetchpagesduring
redo, instead of fetching a page only when the system finds a log record to be
appliedtothepage.Out-of-orderredoisalsopossible:Redocanbepostponedona
pagebeingfetchedfromdiskandperformedwhenthepageisfetched.Meanwhile,
otherlogrecordscancontinuetobeprocessed.
In summary, the ARIES algorithm is a state-of-the-art recovery algorithm, incor-
porating a variety of optimizations designed to improve concurrency, reduce logging
overhead,andreducerecoverytime.
19.10 Recovery in Main-Memory Databases
Main-memory databases support fast querying and updates, since main memory sup-
ports very fast random access. However, the contents of main memory are lost on
system failure,aswellasonsystem shutdown. Thus,datamustbe additionallystored
on persistentorstable storage toallowrecoveryof datawhenthe system comesback
up.
Traditional recovery algorithms can be used with main-memory databases. Log
recordsforupdateshavetobeoutputtostablestorage.Onrecovery,thedatabasehas
to be reloaded from disk and log records applied to restore the database state. Data
blocks that have been modified by committed transactions still have to be written to
disk, and checkpointshave to be performed, so that the amount of log that has to be
replayedatrecoverytimeisreduced.
However,someoptimizationsarepossiblewithmain-memorydatabases.
• Withmain-memorydatabases,indicescanberebuiltveryquicklyaftertheunder-
lying relation is brought into memory and recovery has been performed on the
relation. Thus, many systems do not perform any redo logging actions for index
updates.Undologgingtosupporttransactionabortisstillrequired,butsuchundo

--- Page 977 ---

948 Chapter19 RecoverySystem
Note 19.2 NON-VOLATILERAM
Some newly launched non-volatile storage systems support direct access to indi-
vidualwords,insteadofrequiringthatanentirepagemustbereadorwritten.Such
non-volatileRAM systems, also called storage class memory (SCM), support very
fastrandomaccess,withlatencyandbandwidthcomparabletoRAMaccess.The
contentsofsuchnon-volatileRAMsurvivepowerfailures,likeflash,butofferdirect
access,likeRAM.Intermsofcapacityandcostpermegabyte,currentgeneration
non-volatilestorageliesbetweenRAMandflashstorage.
Recovery techniques have been specialized to deal with NVRAM storage. In
particular, redo logging can be avoided, although undo logging may be used to
dealwithtransactionaborts.IssuessuchasatomicupdatestoNVRAMhavetobe
takenintoconsiderationwhendesigningsuchrecoverytechniques.
log records can be kept in memory, and they need not be written to the log on
stablestorage.
• Severalmain-memorydatabasesreduceloggingoverheadbyperformingonlyredo
logging. Checkpoints are taken periodically, either ensuring that uncommitted
data are not written to disk or avoiding in-place updates of records by creating
multiple versions of records. Recovery consists of reloading the checkpoint and
thenperformingredooperations.(Recordversionscreatedbyuncommittedtrans-
actionsmustbegarbagecollectedeventually.)
• Fastrecoveryiscrucialformain-memorydatabases,sincetheentiredatabasehas
to be loaded and recovery actions performed before any transaction processing
canbedone.
Several main-memory databases therefore perform recovery in parallel using
multiplecores,tominimizerecoverytime.Todoso,dataandlogrecordsmaybe
partitioned,withlogrecordsofapartitionaffectingonlydatainthecorresponding
data partition. Each core is then responsible for performing recovery operations
foraparticularpartition, and itcanperform recoveryoperations inparallel with
othercores.
19.11 Summary
• A computer system, like any other mechanical or electrical device, is subject to
failure. There are a variety of causes of such failure, including disk crash, power
failure, and software errors. In each of these cases, information concerning the
databasesystemislost.

--- Page 978 ---

19.11 Summary 949
• Inadditiontosystemfailures,transactionsmayalsofailforvariousreasons,such
asviolationofintegrityconstraintsordeadlocks.
• An integral part of a database system is a recovery scheme that is responsible
forthedetectionoffailuresandfortherestoration ofthedatabase toastate that
existedbeforetheoccurrenceofthefailure.
• Thevarioustypesofstorageinacomputerarevolatilestorage,non-volatilestorage,
and stable storage. Data in volatile storage, such as in RAM, are lost when the
computer crashes. Data in non-volatile storage, such as disk, are not lost when
thecomputercrashesbutmayoccasionallybelostbecauseoffailuressuchasdisk
crashes.Datainstablestorageareneverlost.
• Stablestoragethatmustbeaccessibleonlineisapproximatedwithmirroreddisks,
orotherformsofRAID,whichprovideredundantdatastorage.Offline,orarchival,
stable storage may consist of multiple tape copies of data stored in a physically
securelocation.
• In case of failure, the state of the database system may no longer be consistent;
that is, it may not reflect a state of the world that the database is supposed to
capture.Topreserveconsistency,werequirethateachtransactionbeatomic.Itis
the responsibility of the recovery scheme to ensure the atomicity and durability
property.
• In log-based schemes, all updates are recorded on a log, which must be kept in
stable storage. A transaction is considered to have committed when its last log
record, which is the commit log record for the transaction, has been output to
stablestorage.
• Logrecordscontainoldvaluesandnewvaluesforallupdateddataitems.Thenew
valuesareusedincasetheupdatesneedtoberedoneafterasystemcrash.Theold
valuesareusedtorollbacktheupdatesofthetransactionifthetransactionaborts
duringnormaloperation, aswellastorollbacktheupdates ofthetransactionin
casethesystemcrashedbeforethetransactioncommitted.
• Inthedeferred-modificationsscheme,duringtheexecutionofatransaction,allthe
writeoperationsaredeferreduntilthetransactionhasbeencommitted,atwhich
timethesystemusestheinformationonthelogassociatedwiththetransactionin
executingthedeferredwrites.Withdeferredmodification,logrecordsdonotneed
tocontainoldvaluesofupdateddataitems.
• Toreducetheoverheadofsearchingthelogandredoingtransactions,wecanuse
checkpointingtechniques.
• Modern recovery algorithms are based on the concept of repeating history,
wherebyallactionstakenduringnormaloperation(sincethelastcompletedcheck-
point) are replayed during the redo pass of recovery. Repeating history restores

--- Page 979 ---

950 Chapter19 RecoverySystem
the system state to what it was at the time the last log record was output to sta-
blestorage beforethesystem crashed.Undoisthenperformedfromthisstate by
executing an undo pass that processes log records of incomplete transactions in
reverseorder.
• Undoofanincompletetransactionwritesoutspecialredo-onlylogrecordsandan
abortlogrecord.Afterthat,thetransactioncanbeconsideredtohavecompleted,
anditwillnotbeundoneagain.
• Transactionprocessingisbasedonastoragemodelinwhichmainmemoryholds
alogbuffer,adatabasebuffer,andasystembuffer.Thesystembufferholdspages
ofsystemobjectcodeandlocalworkareasoftransactions.
• Efficientimplementationofarecoveryschemerequiresthatthenumberofwrites
to the database and to stable storage be minimized. Log records may be kept in
volatilelogbufferinitially,buttheymustbewrittentostablestoragewhenoneof
thefollowingconditionsoccurs:
° Before the <T commit> log record may be output to stable storage, all log
i
recordspertainingtotransactionT musthavebeenoutputtostablestorage.
i
° Beforeablockofdatainmainmemoryisoutputtothedatabase(innon-volatile
storage),alllogrecordspertainingtodatainthatblockmusthavebeenoutput
tostablestorage.
• Remotebackupsystemsprovideahighdegreeofavailability,allowingtransaction
processing to continue even if the primary site is destroyed by a fire, flood, or
earthquake. Data and log records from a primary site are continually backed up
toaremotebackupsite.Iftheprimarysitefails,theremotebackupsitetakesover
transactionprocessing,afterexecutingcertainrecoveryactions.
• Modern recovery techniques support high-concurrency locking techniques, such
as those used for B+-tree concurrency control. These techniques allow early re-
leaseoflower-levellocksobtainedbyoperationssuchasinsertsordeletes,which
allows other such operations to be performed by other transactions. After lower-
level locks are released, physical undo is not possible, and instead logical undo,
such as a deletion to undo an insertion, is required. Transactions retain higher-
level locks that ensure that concurrent transactions cannot perform actions that
couldmakelogicalundoofanoperationimpossible.
• To recover from failures that result in the loss of non-volatile storage, we must
dump the entire contents of the database onto stable storage periodically—say,
onceperday.Ifafailureoccursthatresultsinthelossofphysicaldatabaseblocks,
we use the most recent dump in restoring the database to a previous consistent
state. Once this restoration has been accomplished, we use the log to bring the
databasesystemtothemostrecentconsistentstate.

--- Page 980 ---

ReviewTerms 951
• TheARIESrecoveryschemeisastate-of-the-artschemethatsupportsanumberof
features to provide greaterconcurrency,reduce loggingoverheads, and minimize
recovery time. It is also based on repeating history, and it allows logical undo
operations.Theschemeflushespagesonacontinuousbasisanddoesnotneedto
flush allpages atthetimeofacheckpoint.Ituses logsequence numbers(LSNs)
toimplementavarietyofoptimizationsthatreducethetimetakenforrecovery.
Review Terms
• Recoveryscheme • Uncommittedmodifications
• Failureclassification • Checkpoints
• Recoveryalgorithm
° Transactionfailure
• Restartrecovery
° Logicalerror
• Transactionrollback
° Systemerror • Physicalundo
° Systemcrash • Physicallogging
° Data-transferfailure • Transactionrollback
• Restartrecovery
• Fail-stopassumption
• Redophase
• Diskfailure
• Undophase
• Storagetypes
• Repeatinghistory
° Volatilestorage
• Buffermanagement
° Non-Volatilestorage • Log-recordbuffering
° Stablestorage • Write-aheadlogging(WAL)
• Blocks • Logforce
• Databasebuffering
° Physicalblocks
• Latches
° Bufferblocks • Operatingsystemandbuffer
• Diskbuffer management
• Force-output • Fuzzycheckpointing
• Log-basedrecovery • Highavailability
• Log • Remotebackupsystems
• Logrecords
° Primarysite
• Updatelogrecord
° Remotebackupsite
• Deferredmodification
• Immediatemodification ° Secondarysite

--- Page 981 ---

952 Chapter19 RecoverySystem
• Detectionoffailure • Fuzzydump
• Transferofcontrol • ARIES
• Timetorecover ° Logsequencenumber(LSN)
• Hot-spareconfiguration
° PageLSN
• Timetocommit
° Physiologicalredo
° One-safe
° Compensationlogrecord
° Two-very-safe (CLR)
° Two-safe ° DirtyPageTable
• Earlylockrelease ° Checkpointlogrecord
• Logicaloperations
° Analysispass
• Logicallogging
° Redopass
• Logicalundo
• Lossofnon-volatilestorage ° Undopass
• Archivaldump
Practice Exercises
19.1 Explainwhylogrecordsfortransactionsontheundo-listmustbeprocessedin
reverseorder,whereasredoisperformedinaforwarddirection.
19.2 Explain the purpose of the checkpointmechanism.How often should check-
pointsbeperformed?Howdoesthefrequencyofcheckpointsaffect:
• Systemperformancewhennofailureoccurs?
• Thetimeittakestorecoverfromasystemcrash?
• Thetimeittakestorecoverfromamedia(disk)failure?
19.3 Somedatabasesystemsallowtheadministratortochoosebetweentwoforms
of logging: normal logging, used to recover from system crashes, and archival
logging, used to recover from media (disk) failure. When can a log record be
deleted,ineachofthesecases,usingtherecoveryalgorithmofSection19.4?
19.4 DescribehowtomodifytherecoveryalgorithmofSection19.4toimplement
savepoints and to perform rollback to a savepoint. (Savepoints are described
inSection19.9.3.)
19.5 Supposethedeferredmodificationtechniqueisusedinadatabase.
a. Istheoldvaluepartofanupdatelogrecordrequiredanymore?Whyor
whynot?

--- Page 982 ---

PracticeExercises 953
b. If old values are not stored in update log records, transaction undo is
clearly not feasible. How would the redo phase of recovery have to be
modifiedasaresult?
c. Deferred modification can be implemented by keeping updated data
itemsinlocalmemoryoftransactionsandreadingdataitemsthathave
notbeenupdateddirectlyfromthedatabasebuffer.Suggesthowtoeffi-
cientlyimplementa dataitem read, ensuringthat atransaction sees its
ownupdates.
d. Whatproblemwouldarisewiththeabovetechniqueiftransactionsper-
formalargenumberofupdates?
19.6 Theshadow-pagingschemerequiresthepagetabletobecopied.Supposethe
pagetableisrepresentedasaB+-tree.
a. Suggest how toshare asmany nodes aspossible between the new copy
and the shadow copy of the B+-tree, assuming that updates are made
onlytoleafentries,withnoinsertionsordeletions.
b. Even with the above optimization, logging is much cheaper than a
shadow copy scheme, for transactions that perform small updates. Ex-
plainwhy.
19.7 Suppose we (incorrectly) modify the recovery algorithm of Section 19.4 to
note log actions taken during transaction rollback. When recovering from a
systemcrash,transactionsthatwererolledbackearlierwouldthenbeincluded
inundo-listandrolledbackagain.Giveanexampletoshowhowactionstaken
duringtheundophaseofrecoverycouldresultinanincorrectdatabasestate.
(Hint: Consider a data item updated by an aborted transaction and then up-
datedbyatransactionthatcommits.)
19.8 Diskspaceallocatedtoafileasaresultofatransactionshouldnotbereleased
even if the transaction is rolled back. Explain why, and explain how ARIES
ensuresthatsuchactionsarenotrolledback.
19.9 Suppose a transaction deletes a record, and the free space generated thus is
allocatedtoarecordinsertedbyanothertransaction,evenbeforethefirsttrans-
actioncommits.
a. Whatproblemcanoccurifthefirsttransactionneedstoberolledback?
b. Would this problem be an issue if page-level locking is used instead of
tuple-levellocking?
c. Suggest how tosolve thisproblem whilesupporting tuple-levellocking,
by logging post-commit actions in special log records, and executing

--- Page 983 ---

954 Chapter19 RecoverySystem
them after commit. Make sure your scheme ensures that such actions
areperformedexactlyonce.
19.10 Explain the reasons why recovery of interactive transactions is more difficult
todealwiththanisrecoveryofbatchtransactions.Isthereasimplewaytodeal
with this difficulty? (Hint: Consider an automatic teller machine transaction
inwhichcashiswithdrawn.)
19.11 Sometimes a transaction has to be undone after it has committed because it
waserroneouslyexecuted—forexample,becauseoferroneousinputbyabank
teller.
a. Giveanexampletoshowthatusingthenormaltransactionundomech-
anismtoundosuchatransactioncouldleadtoaninconsistentstate.
b. Onewaytohandlethissituationistobringthewholedatabasetoastate
priortothecommitoftheerroneoustransaction(calledpoint-in-timere-
covery).Transactionsthatcommittedlaterhavetheireffectsrolledback
withthisscheme.
Suggest a modification to the recovery algorithm of Section 19.4 to
implementpoint-in-timerecoveryusingdatabasedumps.
c. Later nonerroneous transactions can be reexecuted logically, if the up-
dates are available in the form of SQL but cannot be reexecuted using
theirlogrecords.Why?
19.12 The recovery techniques that we described assume that blocks are written
atomicallytodisk.However,ablockmaybepartiallywrittenwhenpowerfails,
withsomesectorswritten,andothersnotyetwritten.
a. Whatproblemscanpartialblockwritescause?
b. Partial block writes can be detected using techniques similar to those
usedtovalidatesectorreads.Explainhow.
c. Explain how RAID 1 can be used to recover from a partially written
block,restoringtheblocktoeitheritsoldvalueortoitsnewvalue.
19.13 TheOracledatabasesystemusesundologrecordstoprovideasnapshotview
ofthedatabase undersnapshotisolation.Thesnapshotviewseenbytransac-
tionT reflectsupdatesofalltransactionsthathadcommittedwhenT started
i i
andtheupdatesofT;updatesofallothertransactionsarenotvisibletoT.
i i
Describe a scheme for buffer handling whereby transactions are given a
snapshot view of pages in the buffer. Include details of how to use the log to
generate the snapshot view. You can assume that operations as well as their
undoactionsaffectonlyonepage.

--- Page 984 ---

Exercises 955
Exercises
19.14 Explain the difference between the three storage types—volatile, nonvolatile,
andstable—intermsofI/Ocost.
19.15 Stablestoragecannotbeimplemented.
a. Explainwhyitcannotbe.
b. Explainhowdatabasesystemsdealwiththisproblem.
19.16 Explain how the database may become inconsistent if some log records per-
tainingtoablockarenotoutputtostablestoragebeforetheblockisoutputto
disk.
19.17 Outlinethedrawbacksoftheno-stealandforcebuffermanagementpolicies.
19.18 Supposetwo-phaselockingisused,butexclusivelocksarereleasedearly,that
is,lockingisnotdoneinastricttwo-phasemanner.Giveanexampletoshow
whytransactionrollbackcanresultinawrongfinalstate,whenusingthelog-
basedrecoveryalgorithm.
19.19 Physiological redo logging can reduce logging overheads significantly, espe-
ciallywithaslottedpagerecordorganization.Explainwhy.
19.20 Explainwhylogicalundologgingisusedwidely,whereaslogicalredologging
(otherthanphysiologicalredologging)israrelyused.
19.21 Consider the log in Figure 19.5. Suppose there is a crash just before the log
record<T abort>iswrittenout.Explainwhatwouldhappenduringrecovery.
0
19.22 Suppose thereisatransactionthathasbeenrunningforaverylongtimebut
hasperformedveryfewupdates.
a. Whateffectwouldthetransactionhaveonrecoverytimewiththerecov-
eryalgorithmofSection19.4,andwiththeARIESrecoveryalgorithm?
b. Whateffectwouldthetransactionhaveondeletionofoldlogrecords?
19.23 ConsidertheloginFigure19.7.Supposethereisacrashduringrecovery,just
beforetheoperationabortlogrecordiswrittenforoperationO .Explainwhat
1
willhappenwhenthesystemrecoversagain.
19.24 Compare log-based recovery with the shadow-copy scheme in terms of their
overheadsforthecasewhendataarebeingaddedtonewlyallocateddiskpages
(in other words, there is no old value to be restored in case the transaction
aborts).
19.25 IntheARIESrecoveryalgorithm:

--- Page 985 ---

956 Chapter19 RecoverySystem
a. If at the beginning of the analysis pass, a page is not in the checkpoint
dirtypagetable,willweneedtoapplyanyredorecordstoit?Why?
b. WhatisRecLSN,andhowisitusedtominimizeunnecessaryredos?
19.26 Explainthedifferencebetweenasystemcrashanda“disaster.”
19.27 For each of the following requirements, identify the best choice of degree of
durabilityinaremotebackupsystem:
a. Datalossmustbeavoided,butsomelossofavailabilitymaybetolerated.
b. Transaction commit must be accomplished quickly, even at the cost of
lossofsomecommittedtransactionsinadisaster.
c. Ahighdegreeofavailabilityanddurabilityisrequired,butalongerrun-
ningtimeforthetransactioncommitprotocolisacceptable.
Further Reading
[GrayandReuter(1993)]isanexcellenttextbooksourceofinformationaboutrecov-
ery,includinginterestingimplementationandhistoricaldetails.[BernsteinandGood-
man (1981)] is an early textbook source of information on concurrency control and
recovery. [Faerber et al. (2017)] provide an overview of main-memory databases, in-
cludingrecoverytechniques.
An overview of the recovery scheme of System R is presented by [Gray (1978)]
(which also includes extensive coverage of concurrency control and other aspects of
System R), and [Gray et al. (1981)]. A comprehensive presentation of the principles
ofrecoveryisofferedby[HaerderandReuter(1983)].TheARIESrecoverymethodis
describedin[Mohanetal.(1992)].Manydatabasessupporthigh-availabilityfeatures;
moredetailsmaybefoundintheironlinemanuals.
Bibliography
[Bayeretal.(1978)] R.Bayer,R.M.Graham,andG.Seegmuller,editors,OperatingSystems:
AnAdvancedCourse,volume60ofLectureNotesinComputerScience,SpringerVerlag(1978).
[BernsteinandGoodman(1981)] P.A.BernsteinandN.Goodman,“ConcurrencyControl
inDistributedDatabaseSystems”,ACMComputingSurveys,Volume13,Number2(1981),
pages185–221.
[Faerberetal.(2017)] F.Faerber,A.Kemper,P.-A.Larson,J.Levandoski,T.Neumann,and
A.Pavlo,“MainMemoryDatabaseSystems”,FoundationsandTrendsinDatabases,Volume
8,Number1-2(2017),pages1–130.
[Gray(1978)] J. Gray. “Notes on Data Base Operating System”, In [Bayer et al. (1978)],
pages393–481.SpringerVerlag(1978).

--- Page 986 ---

FurtherReading 957
[GrayandReuter(1993)] J.GrayandA.Reuter,TransactionProcessing:ConceptsandTech-
niques,MorganKaufmann(1993).
[Grayetal.(1981)] J.Gray,P.R.McJones,andM.Blasgen,“TheRecoveryManagerofthe
SystemRDatabaseManager”,ACMComputingSurveys,Volume13,Number2(1981),pages
223–242.
[HaerderandReuter(1983)] T.HaerderandA.Reuter,“PrinciplesofTransaction-Oriented
DatabaseRecovery”,ACMComputingSurveys,Volume15,Number4(1983),pages287–318.
[Mohanetal.(1992)] C. Mohan, D. Haderle, B. Lindsay, H. Pirahesh, and P. Schwarz,
“ARIES:ATransactionRecoveryMethodSupportingFine-GranularityLockingandPartial
RollbacksUsingWrite-AheadLogging”,ACMTransactionsonDatabaseSystems,Volume17,
Number1(1992),pages94–162.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 988 ---

8
PART
PARALLEL AND
DISTRIBUTED DATABASES
Database systems can be centralized, where one server machine executes operations
on the database. Database systems can also be designed to exploit parallel computer
architectures.Distributeddatabasesspanmultiplegeographicallyseparatedmachines.
Chapter 20 first outlines the architectures of database systems running on server
systems,whichareusedincentralizedandclient–serverarchitectures.Thechapterthen
outlines parallel computer architectures,and parallel database architectures designed
for differenttypes of parallel computers. Finally,the chapteroutlines architectural is-
suesinbuildingadistributeddatabasesystem.
Chapter21discussestechniquesfordatastorage andindexinginparallelanddis-
tributed database systems. These include data partitioning and replication.Key-value
stores, which offer some but not all features of a full database system, are discussed
alongwiththeirbenefitsanddrawbacks.
Chapter 22 discusses algorithms for query processing in parallel and distributed
database systems. This chapter focuses on query processing in decision-support sys-
tems.Suchsystemsneedtoexecutequeriesonverylargeamountsofdata,andparallel
processingofthequeryacrossmultiplenodesiscriticalforprocessingquerieswithin
acceptable response times. The chapter covers parallel sort and join, pipelining, the
implementationofMapReducesystems,andparallelstreamprocessing.
Chapter 23 discusses how to carry out transaction processing in parallel and dis-
tributeddatabasesystems.Inadditiontosupportingconcurrencycontrolandrecovery,
thesystemmustdealwithissuespertainingtoreplicationofdataandwithfailuresthat
involvesome,butnotall,nodes.Thechaptercoversatomiccommitprotocolsandcon-
sensus protocols designed for distributed databases, distributed concurrency control,
replicaconsistency,andtrade-offsofconsistencyforthesakeofperformanceandavail-
ability.
959

--- Page 990 ---

20
CHAPTER
Database-System Architectures
Thearchitectureofadatabasesystemisgreatlyinfluencedbytheunderlyingcomputer
systemonwhichitruns,inparticularbysuchaspectsasprocessorandmemoryarchi-
tecture,andnetworking,aswellasbyrequirementsofparallelismanddistribution.In
thischapter,weprovideahigh-levelviewofdatabasearchitectures,withafocusonhow
theyareinfluencedbytheunderlyinghardware,aswellasbyrequirementsofparallel
anddistributedprocessing.
20.1 Overview
Theearliestdatabaseswerebuilttorunonasinglephysicalmachinesupportingmulti-
tasking;suchcentralizeddatabasesystemsarestillwidelyused.Anenterprise-scaleap-
plicationthatrunsonacentralizeddatabasesystemtodaymayhavefromtenstothou-
sandsofusersanddatabasesizesrangingfrommegabytestohundredsofgigabytes.
Paralleldatabasesystemsweredeveloped,startinginthelate1980stoexecutetasks
in parallel on a large number of machines. These were developed to handle high-end
enterpriseapplicationswhoserequirementsintermsoftransactionprocessingperfor-
mance,timetoprocessdecisionsupportqueries,andstoragecapacitycouldnotbemet
bycentralizeddatabases.Thesedatabasesweredesignedtoruninparallelonhundreds
ofmachines.Today,thegrowthofparalleldatabasesisdrivennotjustbyenterpriseap-
plications,butevenmoresobyweb-scaleapplications,whichmayhavemillionstoeven
hundredsofmillionsofusersandmayneedtodealwithmanypetabytesofdata.
Paralleldatastoragesystemsaredesignedprimarilytostoreandretrievedatabased
onkeys. Unlikeparalleldatabases,datastorage systems typicallyprovideverylimited
supportfortransactions,andtheylacksupportfordeclarativequerying.Ontheother
hand, such systems can be run in parallel on very large numbers of machines (thou-
sandstotensofthousands),ascalethatmostparalleldatabasescannothandle.
Further, data are often generated and stored on different database systems, and
there is a need to execute queries and update transactions across multiple databases.
Thisneedledtothedevelopmentofdistributeddatabasesystems.Techniquesdeveloped
forfaulttoleranceinthecontextofdistributed databasestodayalsoplayakeyrolein
961

--- Page 991 ---

962 Chapter20 Database-SystemArchitectures
ensuring the extremely high reliability and availability of massively parallel database
anddatastoragesystems.
We study the architecture of database systems in this chapter, starting with the
traditionalcentralizedarchitecturesandcoveringparallelanddistributeddatabasear-
chitectures. We cover issues of parallel and distributed data storage and indexing in
Chapter21.Chapter22coversissuesofparallelanddistributedqueryprocessing,while
Chapter23coversissuesofparallelanddistributedtransactionprocessing.
20.2 Centralized Database Systems
Centralized database systems are those that run on a single computer system. Such
database systems span a range from single-user database systems running on mobile
devices or personal computers to high-performance database systems running on a
serverwithmultipleCPUcoresanddisksandalargeamountofmainmemorythatcan
beaccessedbyanyoftheCPUcores.Centralizeddatabasesystemsarewidelyusedfor
enterprise-scaleapplications.
Wedistinguish twoways inwhichcomputersareused:assingle-usersystems and
asmultiusersystems.Smartphonesandpersonalcomputersfallintothefirstcategory.
Atypicalsingle-user systemisasystem usedbyasingleperson,usuallywithonlyone
processor (usually with multiple cores), and one or two disks.1 A typical multiuser
system,ontheotherhand,hasmultipledisks,alargeamountofmemory,andmultiple
processors.Suchsystemsservealargenumberofuserswhoareconnectedtothesystem
remotely,andtheyarecalledserversystems.
Databasesystemsdesignedforsingle-usersystemsusuallydonotprovidemanyof
the facilities that a multiuser database provides. In particular, they may support very
simple concurrency control schemes, since highly concurrent access to the database
isveryunlikely.Provisionsforcrash recoveryinsuchsystems mayalsobe eithervery
basic (e.g., making a copy of data before updating it), or even absent in some cases.
Such systems may not support SQL and may instead provide an API for data access.
Such database systems are referred to as embedded databases, since they are usually
designedtobelinkedtoasingleapplicationprogramandareaccessibleonlyfromthat
application.
Incontrast,multiuserdatabasesystemssupportthefulltransactionalfeaturesthat
we have studied earlier.Suchdatabases areusually designed asservers, whichservice
requestsreceivedfromapplicationprograms;therequestscouldbeintheformofSQL
queries, or they could be requests for retrieving, storing, or updating data specified
usinganAPI.
Mostgeneral-purposecomputersystemsinusetodayhaveafewmulticoreproces-
sors(typicallyonetofour),witheachmulticoreprocessorhavingafewcores(typically
1Recallthatweusethetermdisktorefertoharddisksaswellassolid-statedrives.

--- Page 992 ---

20.3 ServerSystemArchitectures 963
4to8).Mainmemoryissharedacrossalltheprocessors.Parallelismwithsuchasmall
numberofcores,andwithsharedmemory,isreferredtoascoarse-grainedparallelism.
Operating systems that run on single-processor systems support multitasking, al-
lowingmultipleprocessestorun on thesameprocessorinatime-sharedmanner.Ac-
tions of different processes may thus be interleaved. Databases designed for single-
processor machines have long been designed to allow multiple processes or threads
to access shared database structures concurrently. Thus, many of the issues in han-
dling multiple processes running truly in parallel, such as concurrent access to data,
arealreadyaddressedbydatabasesdesignedforsingle-processormachines.Asaresult,
databasesystemsdesignedfortime-sharedsingle-processormachinescouldbeadapted
relativelyeasilytorunoncoarse-grainedparallelsystems.
Databases running on coarse-grained parallel machines traditionally did not at-
tempt to partition a single query among the processors; instead, they ran each query
on a single processor, allowing multiple queries to run concurrently. Thus, such sys-
temssupportahigherthroughput;thatis,theyallowagreaternumberoftransactions
to run per second, although individual transactions do not run any faster. In recent
years, with even mobile phones supporting multiple cores, such systems are evolving
tosupportparallelprocessingofindividualqueries.
Incontrast,machineswithfine-grainedparallelismhavealargenumberofproces-
sors,anddatabasesystemsrunningonsuchmachinesattempttoparallelizesingletasks
(queries,forexample)submittedbyusers.
Parallelismhasemergedasacriticalissueinthedesignofsoftwaresystemsingen-
eral,andinparticularinthedesignofdatabasesystems.Asaresult,paralleldatabase
systems,whichoncewerespecializedsystemsrunningonspeciallydesignedhardware,
are increasingly becoming the norm. We study the architecture of parallel database
systemsinSection20.4.
20.3 Server System Architectures
Serversystemscanbebroadlycategorizedastransactionserversanddataservers.
• Transaction-server systems, also called query-server systems, provide an interface
towhichclientscansendrequeststoperformanaction,inresponsetowhichthey
executetheactionandsendbackresultstotheclient.Usually,clientmachinesship
transactionstotheserversystems,wherethosetransactionsareexecuted,andre-
sultsareshippedbacktoclientsthatareinchargeofdisplayingthedata.Requests
maybespecifiedthroughtheuseofSQLorthroughaspecializedapplicationpro-
graminterface.
• Data-server systems allow clients to interact with the servers by making requests
to read or update data, in units such as files, pages, or objects. For example, file
servers provide afile-system interfacewhere clientscan create,update, read,and

--- Page 993 ---

964 Chapter20 Database-SystemArchitectures
deletefiles.Dataserversfordatabasesystemsoffermuchmorefunctionality;they
supportunitsofdata—suchaspages,tuples,orobjects—thataresmallerthanafile.
Theyprovideindexingfacilitiesfordata,andtheyprovidetransactionfacilitiesso
thatthe data are neverleftin an inconsistent state ifaclientmachineor process
fails.
Ofthese,thetransaction-serverarchitectureisbyfarthemorewidelyusedarchitecture,
although parallel data servers are widelyused to handle traffic at web scale. We shall
elaborateonthetransaction-serveranddata-serverarchitecturesinSection20.3.1and
Section20.3.2.
20.3.1 Transaction-Server Architecture
Atypicaltransaction-serversystemtodayconsistsofmultipleprocessesaccessingdata
in shared memory, as in Figure 20.1. The processes that form part of the database
systeminclude:
user user user
process process process
ODBC JDBC
server server server
process process process
process
buffer pool monitor
shared process
memory
query plan cache
lock
manager
log buffer lock table
process
database
log writer checkpoint writer
process process process
log disks data disks
Figure 20.1 Sharedmemoryandprocessstructure.

--- Page 994 ---

20.3 ServerSystemArchitectures 965
• Serverprocesses:Theseareprocessesthatreceiveuserqueries(transactions),exe-
cutethem,andsendtheresultsback.Thequeriesmaybesubmittedtotheserver
processesfromauserinterface,orfromauserprocessrunningembeddedSQL,or
viaJDBC,ODBC,orsimilarprotocols.Somedatabasesystemsuseaseparatepro-
cessforeachusersession,andafewuseasingledatabaseprocessforalluserses-
sions,butwithmultiplethreadssothatmultiplequeriescanexecuteconcurrently.
(Athreadissimilartoaprocess,butmultiplethreadsexecuteaspartofthesame
process, and all threads within a process run in the same virtual-memory space.
Multiple threads withina process can execute concurrently.)Many database sys-
temsuseahybridarchitecture,withmultipleprocesses,eachonerunningmultiple
threads.
• Lockmanagerprocess:Thisprocessimplementslockmanagerfunctionality,which
includeslockgrant,lockrelease,anddeadlockdetection.
• Database writer process: There are one or more processes that output modified
bufferblocksbacktodiskonacontinuousbasis.
• Logwriterprocess:Thisprocessoutputslogrecordsfromthelogrecordbufferto
stablestorage.Serverprocessessimplyaddlogrecordstothelogrecordbufferin
sharedmemory, andifalogforce isrequired,theyrequest thelogwriterprocess
tooutputlogrecords(recallthatalogforcecausesthelogcontentsinmemoryto
beoutputtostablestorage).
• Checkpointprocess:Thisprocessperformsperiodiccheckpoints.
• Processmonitorprocess:Thisprocessmonitorsotherprocesses,andifanyofthem
fails, it takes recovery actions for the process, such as aborting any transaction
beingexecutedbythefailedprocessandthenrestartingtheprocess.
Thesharedmemorycontainsallshareddata,suchas:
• Bufferpool.
• Locktable.
• Logbuffer,containinglogrecordswaitingtobeoutputtothelogonstablestorage.
• Cachedqueryplans,whichcanbereusedifthesamequeryissubmittedagain.
Alldatabaseprocessescanaccessthedatainsharedmemory.Sincemultipleprocesses
may read or perform updates on data structures in shared memory, there must be a
mechanismtoensuremutualexclusion,thatis,toensurethatadatastructureismodi-
fiedbyatmostoneprocessatatime,andnoprocessisreadingadatastructurewhile
itisbeingwrittenbyotherprocesses.
Such mutual exclusion can be implemented by means of operating system func-
tions called semaphores. Alternative implementations, with less overhead, use one of

--- Page 995 ---

966 Chapter20 Database-SystemArchitectures
Note 20.1 ATOMICINSTRUCTIONS
1. The instruction test-and-set (M) performs the following two actions atomi-
cally:(i)test,thatis,readthevalueofmemorylocationM,andthen(ii)set
itto1;thetest-and-setinstructionreturnsthevaluethatitreadinstep(i).
SupposeamemorylocationM representinganexclusivelockisinitially
setto0.Aprocessthatwishestogetthelockexecutesthetest-and-set(M).
IfitistheonlyprocessexecutingtheinstructiononM,thevaluethatisread
and returned would be 0, indicating to the process that it has acquired the
lock, and M would be set to 1. When the process is done using the lock, it
releasesthelockbysettingM backto0.
Ifasecondprocessexecutestest-and-set(M)beforethelockisreleased,
the value returned would be 1, indicating that some other process already
has the lock. The process could repeat the execution of test-and-set on M
periodically, until it gets a return value of 0, indicating that it has acquired
thelockafteritwasreleasedbyanotherprocess.
Now,iftwoprocessesexecutetest-and-set(M)concurrently,oneofthem
wouldseeareturnvalueof0,whiletheotherwouldseeareturnvalueof1;
thisisbecausethereadoperationandthesetoperationareexecutedtogether,
atomically.Thefirstprocesstoreadthevaluewouldalsosetitto1,andthe
secondprocesswouldfindthatM isalreadysetto1.Thus,onlyoneprocess
acquiresthelock,ensuringmutualexecution.
2. The compare-and-swap instruction is another atomic instruction similar to
thetest-and-setinstruction,butittakesthefollowingoperands:(M,V ,V ),
o n
whereM isamemorylocation,andvalueV andV aretwovalues(referred
o n
toastheoldandnewvalues).Theinstructiondoesthefollowingatomically:
it compares the value at M with V , and if it matches, it updates the value
o
toV andreturnssuccess.Ifthevaluesdonotmatch,itdoesnotupdateM,
n
anditreturnsfailure.
Similar to the case of test-and-set, we have a memory location M repre-
senting a lock, which is initially set to 0. A process that wants to acquire
thelockexecutescompare-and-swap(M,0,id)whereid canbeanynonzero
value and is typically the process identifier. If no process has the lock, the
compare-and-swapoperationreturnssuccess,afterstoringtheprocessiden-
tifierinM;otherwise,theoperationreturnsfailure.
A benefit of compare-and-swap over the test-and-set implementation is
thatitiseasytofindoutwhichprocesshasacquiredthelockbyjustreading
thecontentofM,iftheprocessidentifierisusedasV .
n

--- Page 996 ---

20.3 ServerSystemArchitectures 967
theatomicinstructions,test-and-set,orcompare-and-swap,whicharesupportedbythe
computer hardware. See Note 20.1 on page 966 for details of these instructions. All
multiprocessorsystemstodaysupporteitherthetest-and-setorthecompare-and-swap
atomic instructions. Further details on these instructions may be found in operating
systemstextbooks.
Notethattheatomicinstructionscanbeusedformutualexclusion,whichisequiv-
alent to supporting exclusive locks, but they do not directly support shared locks.
Thus,theycannotbeuseddirectlytoimplementgeneral-purposelockingindatabases.
Atomicinstructionsare,however,usedtoimplementshort-durationlocks,alsoknown
aslatches,whichareusedformutualexclusionindatabases.
To avoid the overhead of message passing, in many database systems, server pro-
cessesimplementlockingbydirectlyupdatingthelocktable(whichisinsharedmem-
ory) instead of sending lock request messages to a lock manager process. (The lock
tableisshowninFigure18.10.)
Sincemultipleserverprocessesmayaccessthelocktableinsharedmemorycon-
currently,processesmust ensure mutualexclusion on accesstothelocktable. Thisis
typicallydonebyacquiringamutex(alsoreferredtoasalatch)onthelocktable,using
the test-and-set or compare-and-swap instructions on amemory location representing
alockonthelocktable.
A transaction that wants to acquire a lock by directly updating the lock table in
sharedmemoryexecutesthefollowingsteps.
1. Acquireamutex(latch)onthelocktable.
2. Checkiftherequestedlockcanbeallocated,usingtheprocedurewesawinSec-
tion18.1.4.Ifitcan,update thelocktabletoindicatethelockisallocated.Oth-
erwise,updatethelocktabletoindicatethatthelockrequestisinthequeuefor
thatlock.
3. Releasethemutexonthelocktable.
Ifalockcannotbeobtainedimmediatelybecauseofalockconflict,thetransaction
mayperiodicallyreadthelocktabletocheckifthelockhasbeenallocatedtoitdueto
alockrelease,whichisdescribednext.
Lockreleaseisdoneasfollows:
1. Acquireamutexonthelocktable
2. Removetheentryinthelocktableforthelockbeingreleased.
3. If there are any other lock requests pending for the data item that can now be
allocatedtothelock,thelocktableisupdatedtomarkthoserequestsasallocated.
The rules on which lock requests may be granted are as described in Section
18.1.4.
4. Releasethemutexonthelocktable.

--- Page 997 ---

968 Chapter20 Database-SystemArchitectures
To avoid repeated checks on the lock table (an example of the phenomenon of
busy waiting), operating system semaphores can be used by the lock request code to
waitforalockgrantnotification.Thelockreleasecodemustthenusethesemaphore
mechanismtonotifywaitingtransactionsthattheirlockshavebeengranted.
Even if the system handleslock requests through shared memory, it still uses the
lockmanagerprocessfordeadlockdetection.
20.3.2 Data Servers and Data Storage Systems
Data-server systems were originally developed to support data access from object-
oriented databases; object-oriented databases allow programmers to use a program-
minglanguagethatallowscreation,retrieval,andupdateofpersistentobjects.
Many of the target applications of object-oriented databases, such as computer-
aided design (CAD) systems, required extensive computation on the retrieved data.
Forexample,theCADsystemmaystoreamodelofacomputerchiporabuilding,and
it may perform computations such as simulations on the retrieved model,which may
beexpensiveintermsofCPUtime.
If all the computation were done at the server, the server would be overloaded.
Instead,insuchanenvironment,itmakessensetostoredataonaseparatedataserver
machine, fetch data to client machines when needed, perform all processing at the
client machines, and then to store new or updated data back on the data server ma-
chine. Thus, the processing power of client machines can be used to carry out the
computation, whiletheserver needsonlytostore andfetchdata, withoutperforming
anycomputation.
Morerecently,anumberofparalleldatastoragesystemshavebeendevelopedfor
handlingveryhighvolumesofdataandtransactions.Suchsystemsdonotnecessarily
supportSQL,butinsteadprovideAPIsforstoring,retrieving,andupdatingdataitems.
Dataitemsstoredinsuchsystemstheycouldbetuples,orcouldbeobjectsrepresented
informatssuchasJSONorXML,ortheycouldevenbefilesordocuments.
Weusethetermdataitemtorefertotuples,objects,files,anddocuments.Wealso
usethetermsdataserver anddatastoragesysteminterchangeably.
Dataserverssupportcommunicationofentiredataitems;inthecaseofverylarge
data items, they may also support communication of only specified parts of the data
item, for instance, specified blocks, instead of requiring that the entire data item be
fetchedorstored.
Data servers in earliergenerations of storage systems supported a conceptcalled
pageshipping,wheretheunitofcommunicationisadatabasepagethatmaypotentially
containmultipledataitems.Pageshippingisnotusedtoday,sincestoragesystemsdo
notexposetheunderlyingstoragelayouttoclients.
20.3.3 Caching at Clients
The time cost of communication between a client application and a server (whether
a transaction server, or a data server) is high compared to that of a local memory

--- Page 998 ---

20.3 ServerSystemArchitectures 969
reference(milliseconds,versuslessthan100nanoseconds).Thetimetosendamessage
overanetwork,andgetaresponseback,calledthenetworkround-triptime,ornetwork
latency, can be nearly a millisecond even if the data server is in the same location as
theclient.
Asaresult,applicationsrunningattheclientsadoptseveraloptimizationstrategies
toreducetheeffectsofnetworklatency.Thesamestrategiescanalsobeusefulinpar-
alleldatabasesystems,wheresomeofthedatarequiredforprocessingaquerymaybe
storedonadifferentmachinefromwhereitisconsumed.Theoptimizationstrategies
includethefollowing:
• Prefetching. If the unit of communication is a single small item, the overhead of
message passing is high compared to the amount of datatransmitted. In particu-
lar, network latency can cause significant delays if a transaction makes repeated
requestsfordataitemsacrossanetwork.
Thus, when an item is requested, it may make sense to also send other items
that are likely to be used in the near future. Fetching items even before they are
requestediscalledprefetching.
• Data caching. Datathat are shipped to aclienton behalf of atransaction can be
cached at the clientwithin the scope of a single transaction. Data can be cached
evenafterthetransactioncompletes,allowingsuccessivetransactionsatthesame
clienttomakeuseofthecacheddata.
However,cachecoherencyisanissue:Evenifatransactionfindscacheddata,it
mustmakesurethatthosedataareuptodate,sincetheymayhavebeenupdated,
orevendeleted,byadifferentclientaftertheywerecached.Thus,amessagemust
still be exchanged with the server to check validity of the data and to acquire a
lockonthedata,unlesstheapplicationiswillingtolivewithpotentiallystaledata.
Further,newtuplesmayhavebeeninsertedafteratransactioncachesdata,which
may not be in the cache. The transaction may have to contact the server to find
suchtuples.
• Lock caching. If the usage of data is mostly partitioned among the clients, with
clients rarely requesting data that are also requested by other clients, locks can
also be cached at the client machine. Suppose that a client finds a data item in
the cache, and that it also finds the lock required for an access to the data item
inthe cache.Then, theaccesscan proceedwithoutanycommunicationwiththe
server. However, the server must keep track of cached locks; if a client requests
a lock from the server, the server must call back all conflictinglocks on the data
itemfromanyotherclientmachinesthathavecachedthelocks.Thetaskbecomes
morecomplicatedwhenmachinefailuresaretakenintoaccount.
• Adaptive lock granularity. If a transaction requires locks on multiple data items,
discovered in the course of a transaction, and each lock acquisition requires a
round trip to a data server, the transaction may waste a good deal of time on

--- Page 999 ---

970 Chapter20 Database-SystemArchitectures
justlockacquisition.Insuchasituation,multi-granularitylockingcanbeusedto
avoidmultiplerequests.Forexample,ifmultipledataitemsarestoredinapage,a
singlepage lock(whichisatacoarsergranularity)canavoidtheneedtoacquire
multipledata-itemlocks(whichareatafinergranularity).Thisstrategyworkswell
ifthereisverylittlelockcontention,butwithhighercontention,acquiringacoarse
granularitylockcanaffectconcurrencysignificantly.
Lockde-escalation,isawayofadaptivelydecreasingthelockgranularityifthere
is higher contention. Lock de-escalation is initiated by the data server sending a
request to the client to de-escalate a lock, and the client responds by acquiring
finer-granularitylocksandthenreleasingthecoarser-granularitylock.
Whenswitchingtoafinergranularity,ifsomeofthelockswereforcacheddata
itemsthatarenotcurrentlylockedbyanytransactionataclient,thedataitemcan
beremovedfromthecacheinsteadofacquiringafiner-granularitylockonit.
20.4 Parallel Systems
Parallel systems improve processing and I/O speeds by using a large number of com-
puters in parallel. Parallel machines are becoming increasingly common, making the
studyofparalleldatabasesystemscorrespondinglymoreimportant.
Inparallelprocessing,manyoperationsareperformedsimultaneously,asopposed
to serial processing, in which the computational steps are performed sequentially. A
coarse-grainparallelmachineconsistsofasmallnumberofpowerfulprocessors;amas-
sivelyparallelorfine-grainparallelmachineusesthousandsofsmallerprocessors.Vir-
tuallyallhigh-endservermachinestodayoffersomedegreeofcoarse-grainparallelism,
withuptotwoorfourprocessorseachofwhichmayhave20to40cores.
Massively parallel computers can be distinguished from the coarse-grain parallel
machinesbythemuchlargerdegreeofparallelismthattheysupport.Itisnotpractical
tosharememorybetweenalargenumberofprocessors.Asaresult,massivelyparallel
computersaretypicallybuiltusingalargenumberofcomputers,eachofwhichhasits
own memory, and often, its own set of disks. Each such computer is referred to as a
nodeinthesystem.
Parallelsystemsatthescaleofhundredstothousandsofnodesormorearehoused
inadatacenter,whichisafacilitythathousesalargenumberofservers.Datacenters
providehigh-speednetworkconnectivitywithinthedatacenter,aswellastotheoutside
world. The numbers and sizes of data centers have grown tremendously in the last
decade,andmoderndatacentersmayhaveseveralhundredthousandservers.
20.4.1 Motivation for Parallel Databases
The transaction requirements of organizations have grown with the increasing use of
computers.Moreover,thegrowthoftheWorldWideWebhascreatedmanysiteswith
millions of viewers, and the increasing amounts of data collected from these viewers
hasproducedextremelylargedatabasesatmanycompanies.

--- Page 1000 ---

20.4 ParallelSystems 971
Thedrivingforcebehindparalleldatabasesystemsisthedemandsofapplications
that have to query extremelylarge databases (of the order of petabytes—that is, 1000
terabytes,orequivalently,1015bytes)orthathavetoprocessanextremelylargenumber
of transactions per second (of the order of thousands of transactions per second).
Centralized and client–server database systems are not powerful enough to handle
suchapplications.
Web-scale applications today often require hundreds to thousands of nodes (and
insomecases,tensofthousandsofnodes)tohandlethevastnumberofusersonthe
web.
Organizations are using these increasingly large volumes of data—such as data
about what items people buy, what web links users click on, and when people make
telephone calls—to plan their activities and pricing. Queries used for such purposes
arecalleddecision-supportqueries,andthedatarequirementsforsuchqueriesmayrun
intoterabytes. Single-nodesystems arenotcapableofhandlingsuchlarge volumesof
dataattherequiredrates.
Theset-orientednatureofdatabasequeriesnaturallylendsitselftoparallelization.
Anumberofcommercialandresearchsystemshavedemonstratedthepowerandscal-
abilityofparallelqueryprocessing.
Asthecostofcomputingsystemshasreducedsignificantlyovertheyears,parallel
machineshavebecomecommonandrelativelyinexpensive.Individualcomputershave
themselvesbecomeparallelmachinesusingmulticorearchitectures.Paralleldatabases
arethusquiteaffordableevenforsmallorganizations.
Parallel database systems which can support hundreds of nodes have been avail-
able commercially for several decades, but the number of such products has seen a
significantincreasesincethemid2000s.Open-sourceplatformsforparalleldatastor-
age such as the Hadoop File System (HDFS), and HBase, and for query processing,
suchasHadoopMap-ReduceandHive(amongmanyothers),havealsoseenextensive
adoption.
Itisworthnotingthatapplicationprogramsaretypicallybuiltsuchthattheycan
be executed in parallel on a number of application servers, which communicate over
a network with a database server, which may itself be a parallel system. The parallel
architecturesdescribedinthissectioncanbeusednotonlyfordatastorageandquery
processinginthedatabasebutalsoforparallelprocessingofapplicationprograms.
20.4.2 Measures of Performance for Parallel Systems
Therearetwomainmeasuresofperformanceofadatabasesystem:(1)throughput,the
numberoftasksthatcanbecompletedinagiventimeinterval,and(2)responsetime,
the amount of time ittakes to complete a single task from the time itissubmitted. A
systemthatprocessesalargenumberofsmalltransactionscanimprovethroughputby
processing many transactions in parallel. A system that processes large transactions
canimproveresponsetimeaswellasthroughputbyperformingsubtasksofeachtrans-
actioninparallel.

--- Page 1001 ---

972 Chapter20 Database-SystemArchitectures
linear speedup
sublinear speedup
resources
deeps
Figure 20.2 Speedupwithincreasingresources.
Parallel processing within a computer system allows database-system activitiesto
bespeededup,allowingfasterresponsetotransactions,aswellasmoretransactionsto
beexecutedpersecond.Queriescanbeprocessedinawaythatexploitstheparallelism
offeredbytheunderlyingcomputersystem.
Twoimportantissuesinstudyingparallelismarespeedupandscaleup.Runninga
given task in less time by increasing the degree of parallelism is called speedup. Han-
dlinglargertasksbyincreasingthedegreeofparallelismiscalledscaleup.
Consideradatabaseapplicationrunningonaparallelsystemwithacertainnum-
ber of processors and disks. Now suppose that we increase the size of the system by
increasingthenumberofprocessors,disks,andothercomponentsofthesystem.The
goal istoprocessthe task intimeinverselyproportional tothe numberof processors
and disks allocated. Suppose that the execution time of a task on the larger machine
isT ,andthattheexecutiontimeofthesametaskonthesmallermachineisT .The
L S
speedupduetoparallelismisdefinedasT ∕T .Theparallelsystem issaidtodemon-
S L
strate linear speedup if the speedup is N when the larger system has N times the re-
sources(processors,disk,andsoon)ofthesmallersystem.Ifthespeedupislessthan
N, the system is said to demonstrate sublinear speedup. Figure 20.2 illustrates linear
andsublinearspeedup.2
Scaleup relates to the ability to process larger tasks in the same amount of time
by providing more resources. Let Q be a task, and let Q be a task that is N times
N
bigger than Q. Suppose that the execution time of task Q on a given machine M is
S
T ,andtheexecutiontimeoftaskQ onaparallelmachineM thatisN timeslarger
S N L
than M is T . The scaleup is then defined as T ∕T . The parallel system M is said
S L S L L
to demonstrate linear scaleup on task Q if T = T . If T > T , the system is said
L S L S
2Insomecases,aparallelsystemmayprovidesuperlinearspeedup,thatis,anN timeslargersystemmayprovide
speedupgreaterthanN.Thiscouldhappen,forexample,becausedatathatdidnotfitinthemainmemoryofasmaller
systemdofitinthemainmemoryofalargersystem,avoidingdiskI/O.Similarly,datamayfitinthecacheofalarger
system,reducingmemoryaccessescomparedtoasmallersystem,whichcouldleadtosuperlinearspeedup.

--- Page 1002 ---

20.4 ParallelSystems 973
linear scaleup
T
S
T
L
sublinear scaleup
problem size
Figure 20.3 Scaleupwithincreasingproblemsizeandresources.
todemonstrate sublinear scaleup.Figure20.3illustrates linearandsublinearscaleups
(where the resources increase in proportion to problem size). There are two kinds of
scaleupthatarerelevantinparalleldatabasesystems,dependingonhowthesizeofthe
taskismeasured:
• In batch scaleup, the size of the database increases, and the tasks are large jobs
whoseruntimedependsonthesizeofthedatabase.Anexampleofsuchataskis
a scan of a relation whose size is proportional to the size of the database. Thus,
the size of the database is the measure of the size of the problem. Batch scaleup
also applies in scientific applications, such as executing a weather simulation at
an N-times finer resolution,3 or performing the simulation for an N-times longer
periodoftime.
• Intransactionscaleup,therateatwhichtransactionsaresubmittedtothedatabase
increases,andthesizeofthedatabaseincreasesproportionallytothetransaction
rate. This kind of scaleup is what is relevant in transaction-processing systems
where the transactions are small updates—for example, a deposit or withdrawal
fromanaccount—andtransactionratesgrowasmoreaccountsarecreated.Such
transactionprocessingisespeciallywelladaptedforparallelexecution,sincetrans-
actionscanrunconcurrentlyandindependentlyonseparatenodes,andeachtrans-
actiontakesroughlythesameamountoftime,evenifthedatabasegrows.
Scaleup is usually the more important metric for measuring the efficiencyof par-
alleldatabase systems. Thegoal ofparallelismindatabase systems isusually tomake
surethatthedatabasesystemcancontinuetoperformatanacceptablespeed,evenas
the size of the database and the number of transactions increases. Increasing the ca-
3Forexample,aweathersimulationthatdividestheatmosphereinaparticularregionintocubesofside200meters
mayneedtobemodifiedtouseafinerresolution,withcubesofside100meters;thenumberofcubeswouldthusbe
scaledupbyafactorof8.

--- Page 1003 ---

974 Chapter20 Database-SystemArchitectures
pacityofthesystembyincreasingtheparallelismprovidesasmootherpathforgrowth
foranenterprisethandoesreplacingacentralizedsystemwithafastermachine(even
assumingthatsuchamachineexists). However,wemust alsolookatabsolute perfor-
mance numbers when using scaleup measures; a machine that scales up linearly may
performworsethanamachinethatscaleslessthanlinearly,simplybecausethelatter
machineismuchfastertostartoffwith.
Anumberoffactorsworkagainstefficientparalleloperationandcandiminishboth
speedupandscaleup.
• Sequentialcomputation.Manytaskshavesomecomponentsthatcanbenefitfrom
parallel processing, and some components that have to be executed sequentially.
ConsiderataskthattakestimeT torunsequentially.Supposethefractionofthe
totalexecutiontimethatcanbenefitfromparallelizationisp,andthatpartisexe-
cutedbynnodesinparallel.Thenthetotaltimetakenwouldbe(1−p)T+(p∕n)T,
andthespeedupwouldbe 1 .(ThisformulaisreferredtoasAmdahl’slaw.)
(1−p)+(p∕n)
Ifthefractionpis,say 9,thenthemaximumspeeduppossible,evenwithverylarge
10
n,wouldbe10.
Now consider scaleup, where the problem size increases. If the time taken
by the sequential part of a task increases along with the problem size, scaleup
will be similarly limited. Suppose fraction p of the execution time of a problem
benefitsfromincreasingresources,whilefraction(1−p)issequentialanddoesnot
benefit from increasingresources. Then the scaleup with n timesmore resources
on a problem that is n times larger will be 1 . (This formula is referred to
n(1−p)+p
as Gustafson’s law.) However, if the time taken by the sequential part does not
increasewithproblemsize,itsimpactonscaleupwillbelessastheproblemsizes.
Start-upcosts.Thereisastart-upcostassociatedwithinitiatingasingleprocess.
Inaparalleloperationconsistingofthousandsofprocesses,thestart-uptimemay
overshadowtheactualprocessingtime,affectingspeedupadversely.
• Interference. Since processes executing in a parallel system often access shared
resources, a slowdown may result from the interference of each new process as it
competes withexisting processes for commonlyheld resources, such asa system
bus,orshareddisks,orevenlocks.Bothspeedupandscaleupareaffectedbythis
phenomenon.
• Skew.Bybreakingdownasingletaskintoanumberofparallelsteps,wereducethe
size of the average step. Nonetheless, the service time for the single slowest step
willdeterminetheservicetimeforthetaskasawhole.Itisoftendifficulttodivide
a task into exactly equal-sized parts, and the way that the sizes are distributed is
thereforeskewed.Forexample,ifataskofsize100isdividedinto10parts,andthe
divisionisskewed,theremaybesometasksofsizelessthan10andsometasksof
sizemorethan10;ifevenonetaskhappenstobeofsize20,thespeedupobtained
byrunningthetasksinparallelisonly5,insteadof10aswewouldhavehoped.

--- Page 1004 ---

20.4 ParallelSystems 975
(a) bus (b) ring
(c) mesh (d) hypercube
core
switches
. . . aggregation
switches
. . . top-of-rack
switches
. . .
(e) tree-like topology
Figure 20.4 Interconnection networks.
20.4.3 Interconnection Networks
Parallel systems consist of aset of components (processors, memory, and disks) that
can communicate with each other via an interconnection network. Figure 20.4 shows
severalcommonlyusedtypesofinterconnectionnetworks:
• Bus.Allthe system components cansenddataon andreceivedatafromasingle
communication bus. This type of interconnection is shown in Figure 20.4a. Bus
interconnects were used in earlier days to connect multiple nodes in a network,
but they are no longer used for this task. However, bus interconnections are still
used for connecting multiple CPUs and memory units within a single node, and
they work well for small numbers of processors. However, they do not scale well

--- Page 1005 ---

976 Chapter20 Database-SystemArchitectures
with increasing parallelism, since the bus can handle communication from only
onecomponentatatime;withincreasingnumbersofCPUsandmemorybanksin
anode,otherinterconnectionmechanismssuchasringormeshinterconnections
arenowusedevenwithinasinglenode.
• Ring. The components are nodes arranged in a ring (circle), and each node is
connectedtoitstwoadjacentnodesinthering,asshowninFigure20.4b.Unlike
abus,eachlinkcantransmitdataconcurrentlywithotherlinksinthering,leading
tobetterscalability.However,totransmitdatafromonenodetoanothernodeon
the ring may require a large number of hops; specifically, up to n∕2 hops may
beneededonaringwithnnodes,assumingcommunicationcanbedoneineither
directiononthering.Furthermore,thetransmissiondelayincreasesifthenumber
ofnodesintheringisincreased.
• Mesh.Thecomponentsarenodesinagrid,andeachcomponentconnectstoallits
adjacentcomponentsinthegrid.Inatwo-dimensionalmesh,eachnodeconnects
to(upto)fouradjacentnodes,whileinathree-dimensionalmesh,eachnodecon-
nectsto (up to) six adjacentnodes. Figure20.4c shows a two-dimensionalmesh.
Nodesthatarenotdirectlyconnectedcancommunicatewithoneanotherbyrout-
ingmessagesviaasequenceofintermediatenodesthataredirectlyconnectedto
one another. The number of communication links grows as the number of com-
ponentsgrows,andthecommunicationcapacityofameshthereforescalesbetter
withincreasingparallelism.
Meshinterconnectsareusedtoconnectmultiplecoresinaprocessor,orpro-
cessors in a single server, to each other; eachprocessor core has directaccess to
abankofmemoryconnectedtotheprocessorcore,butthesystem transparently
fetchesdatafrom othermemorybanks by sendingmessages over the mesh inter-
connects.
However, mesh interconnects are no longer used for interconnecting nodes,
sincethenumberofhopsrequiredtotransmitdataincreasessignificantlywiththe
numberofnodes(thenumberofhopsrequiredtotransmitdatafromonenodeto
anothernodeinameshisproportionalintheworstcasetothesquarerootofthe
number of nodes). Parallel systems today have very large numbers of nodes, and
meshinterconnectswouldthusbeimpracticallyslow.
• Hypercube. The components are numbered in binary, and a component is con-
nected to another if the binary representations of their numbers differ in exactly
onebit.Thus,eachofthencomponentsisconnectedtolog(n)othercomponents.
Figure20.4dshowsahypercubewitheightnodes.Inahypercubeinterconnection,
a message from a component can reach any other component by going through
at√most log(n) links. In contrast, in a mesh architecture a comp√onent may be
2( n − 1) links away from some of the other components (or n links away,
ifthemeshinterconnectionwrapsaroundattheedgesofthegrid).Thuscommu-
nicationdelaysinahypercubearesignificantlylowerthaninamesh.

--- Page 1006 ---

20.4 ParallelSystems 977
Hypercubes have been used to interconnect nodes in massively parallel com-
putersinearlierdays,buttheyarenolongercommonlyused.
• Tree-like.Serversystemsinadatacenteraretypicallymountedinracks,witheach
rackholdinguptoabout40nodes.Multipleracksareusedtobuildsystemswith
largernumbersofnodes.Akeyissueishowtointerconnectsuchnodes.
To connect nodes within a rack, there is typically a network switch mounted
atthetopoftherack;48portswitchesarecommonlyused,soasingleswitchcan
beusedtoconnectalltheserversinarack.Current-generationnetworkswitches
typicallysupportabandwidthof1to10gigabitspersecond(Gbps)simultaneously
from/to each of the servers connected to the switch, although more expensive
networkinterconnectswith40to100Gbpsbandwidthsareavailable.
Multipletop-of-rackswitches(alsoreferredtoasedgeswitches)caninturnbe
connected to another switch, called an aggregation switch, allowing interconnec-
tionbetweenracks.Iftherearealargenumberofracks,theracksmaybedivided
intogroups,withoneaggregationswitchconnectingagroupofracks,andallthe
aggregationswitchesinturnconnectedtoacoreswitch.Suchanarchitectureisa
treetopology withthreetiers.Thecoreswitchatthetopofthetreealsoprovides
connectivitytooutsidenetworks.
Aproblemwiththisbasictreestructure,whichisfrequentlyusedinlocal-area
networks within organizations, is that the available bandwidth between racks is
often notsufficientifmultiplemachinesinaracktrytocommunicatesignificant
amounts of data with machines from other racks. Typically, the interconnects of
the aggregation switches support higher bandwidths of 10 to 40 Gbps, although
interconnectsof100Gbpsareavailable.Interconnectsofevenhighercapacitycan
be created by using multiple interconnects in parallel. However, even such high-
speedlinkscanbesaturatedifalargeenoughnumberofserversinarackattempt
tocommunicateattheirfullconnectionbandwidthtoserversinotherracks.
To avoid the bandwidth bottleneck of a tree structure, data centers typically
connecteachtop-of-rack(edge)switchtomultipleaggregationswitches.Eachag-
gregation switch in turn is linked to a number of core switches at the next layer.
Suchaninterconnectiontopologyiscalledatree-liketopology;Figure20.4eshows
a tree-liketopology with threetiers. The tree-liketopology is also referred to as a
fat-tree topology, although originallythe fat-tree topology referred to a tree topol-
ogy where edges higher in the tree have a higher bandwidth than edges lower in
thetree.
Thebenefitofthetree-likearchitectureisthateachtop-of-rackswitchcanroute
its messages through any of the aggregation switches that it is connected to, in-
creasingthe inter-rackbandwidthgreatlyas comparedto thetree topology. Simi-
larly, each aggregation switch can communicate with another aggregation switch
viaanyofthecoreswitchesthatitisconnectedto,increasingthebandwidthavail-
able between the aggregation switches. Further, even if an aggregation or edge
switchfails, there are alternative paths through otherswitches.With appropriate

--- Page 1007 ---

978 Chapter20 Database-SystemArchitectures
routing algorithms, the network can continue functioning even if a switch fails,
makingthenetworkfault-tolerant,atleasttofailuresofoneorafewswitches.
A tree-like architecture with three tiers can handle a cluster of tens of thou-
sands of machines. Although a tree-like topology improves the inter-rack band-
width greatly compared to a tree topology, parallel processing applications, in-
cluding parallel storage and parallel database systems, perform best if they are
designedinawaythatreducesinter-racktraffic.
Thetree-liketopologyandvariantsofitarewidelyusedindatacenterstoday.
The complex interconnection networks in a data center are referred to as a data
centerfabric.
Whilenetworktopologiesareveryimportantforscalability,akeytonetworkper-
formance is network technology used for individual links. The popular technologies
include:
• Ethernet: The dominant technology for network connections today is the Ether-
nettechnology.Ethernetstandards have evolved over time,and the predominant
versionsusedtodayare1-gigabitEthernetand10-gigabitEthernet,whichsupport
bandwidthsof1and10gigabitspersecondrespectively.Forty-gigabitEthernetand
100-gigabitEthernettechnologiesarealsoavailableatahighercostandareseeing
increasing usage. Ethernet protocols can be used over cheaper copper cables for
shortdistances,andoveropticalfiberforlongerdistances.
• Fiberchannel:TheFiberChannelProtocolstandard wasdesignedforhigh-speed
interconnectionbetweenstorage systemsandcomputers,anditispredominantly
usedtoimplementstorageareanetworks(describedinSection20.4.6).Thediffer-
entversionsofthestandardhavesupported increasingbandwidthovertheyears,
with16gigabitspersecondavailableasof2011,and32and128gigabitspersecond
supportedfrom2016.
• Infiniband:TheInfinibandstandardwasdesignedforinterconnectionswithadata
center; it was specifically designed for high-performance computing applications
whichneednotjustveryhighbandwidth,butalsoverylowlatency.TheInfiniband
standard has evolved, with linkspeeds of 8-gigabits per second available by 2007
and24-gigabits persecondavailableby2014. Multiplelinkscanbe aggregated to
giveabandwidthof120to290-gigabitspersecond.
Thelatencyassociatedwithmessagedeliveryisasimportantasbandwidthfor
manyapplications.AkeybenefitofInfinibandisthatitsupportslatenciesaslow
as0.7to0.5microseconds.Incontrast,Ethernetlatenciescanbeuptohundreds
of microseconds in an unoptimized local-area network, while latency-optimized
Ethernetimplementationsstillhavelatenciesofseveralmicroseconds.
Oneoftheimportanttechniquesusedtoreducelatencyistoallowapplicationsto
sendandreceivemessagesbydirectlyinterfacingwiththehardware,bypassingtheoper-
atingsystem.Withthestandardimplementationsofthenetworkingstack,applications

--- Page 1008 ---

20.4 ParallelSystems 979
P M P
M
P M PP
P M PP
P M PP
P M P
(a) shared memory (b) shared disk
M P
P M P P P
M M M
M P P P P
P P P
P M
P P P
M P
P P P
(c) shared nothing (d) hierarchical
Figure 20.5 Paralleldatabasearchitectures.
send messages to the operating system, which in turn interfaces with the hardware,
which in turn delivers the message to the other computer, where again the hardware
interfaceswiththeoperatingsystem,whichtheninterfaceswiththeapplicationtode-
liver the message. Support for direct access to the network interface, bypassing the
operatingsystem,reducesthecommunicationlatencysignificantly.
Another approach to reducing latency is to use remote direct memory access
(RDMA), a technology which allows a process on one node to directly read or write
tomemoryon anothernode, withoutexplicitmessage passing. Hardware support en-
sures that RDMA can transfer data at very high rates with very low latency. RDMA
implementations can use Infiniband, Ethernet, or other networking technologies for
physicalcommunicationbetweennodes.
20.4.4 Parallel Database Architectures
Thereare several architectural modelsfor parallelmachines.Amongthe most promi-
nent ones are those in Figure 20.5 (in the figure, M denotes memory, P denotes a
processor,anddisksareshownascylinders):
• Sharedmemory.Alltheprocessorsshareacommonmemory(Figure20.5a).

--- Page 1009 ---

980 Chapter20 Database-SystemArchitectures
• Shared disk. A set of nodes that share a common set of disks; each node has its
own processor and memory (Figure 20.5b). Shared-disk systems are sometimes
calledclusters.
• Sharednothing.Asetofnodesthatshareneitheracommonmemorynorcommon
disk(Figure20.5c).
• Hierarchical. This model is a hybrid of the preceding three architectures (Figure
20.5d).Thismodelisthemostwidelyusedmodeltoday.
InSection20.4.5throughSection20.4.8,weelaborateoneachofthesemodels.
NotethattheinterconnectionnetworksareshowninanabstractmannerinFigure
20.5.Donotinterprettheinterconnectionnetworksshowninthefiguresasnecessarily
beingabus;infactotherinterconnectionnetworksareusedinpractice.Forexample,
mesh networks are used within a processor, and tree-like networks are often used to
interconnectnodes.
20.4.5 Shared Memory
In a shared-memory architecture, the processors have access to a common memory,
typicallythroughaninterconnectionnetwork.Disksarealsosharedbytheprocessors.
Thebenefitofsharedmemoryisextremelyefficientcommunicationbetweenprocesses
—data in shared memory can be accessed by any process without being moved with
software.Aprocesscansendmessagestootherprocessesmuchfasterbyusingmemory
writes(whichusuallytakelessthanamicrosecond)thanbysendingamessagethrough
acommunicationmechanism.
Multicoreprocessorswith4to8coresarenowcommonnotjustindesktopcom-
puters, but even in mobile phones. High-end processing systems such as Intel’s Xeon
processorhaveupto28coresperCPU,withupto8CPUsonaboard,whiletheXeon
Phicoprocessorsystemscontainaround72cores,asof2018,andthesenumbershave
beenincreasingsteadily.Thereasonfortheincreasingnumberofcoresisthatthesizes
offeaturessuchaslogicgatesinintegratedcircuitshasbeendecreasingsteadily,allow-
ing more gates to be packed in a single chip. The number of transistors that can be
accommodatedonagivenareaofsiliconhasbeendoublingapproximatelyevery11/2
to2years.4
Since the number of gates required for a processor core has not increased corre-
spondingly,itmakessensetohavemultipleprocessorsonasinglechip.Tomaintaina
distinctionbetweenon-chipmultiprocessorsandtraditionalprocessors,thetermcore
isusedforanon-chipprocessor.Thus,wesaythatamachinehasamulticoreprocessor.
4GordonMoore,cofounderofIntel,predictedsuchanexponentialgrowthinthenumberoftransistorsbackinthe
1960s;hispredictionispopularlyknownasMoore’slaw,eventhough,technically,itisnotalaw,butratheranobserva-
tionandaprediction.Inearlierdecades,processorspeedsalsoincreasedalongwiththedecreaseinthefeaturesizes,
butthattrendendedinthemid-2000ssinceprocessorclockfrequenciesbeyondafewgigahertzcouldnotbeattained
withoutunreasonableincreaseinpowerconsumptionandheatgeneration.Moores’slawissometimeserroneously
interpretedtohavepredictedexponentialincreasesinprocessorspeeds.

--- Page 1010 ---

20.4 ParallelSystems 981
All the cores on a single processor typically access a shared memory. Further, a
system can have multiple processors which can share memory. Another effect of the
increasingnumberofgateshasbeenthesteadyincreaseinthesizeofmainmemoryas
wellasadecreaseincost,per-byte,ofmainmemory.
Giventheavailabilityofmulticoreprocessorsatalowcost,aswellastheconcur-
rentavailabilityofverylargeamountsofmemoryatalowcost,shared-memoryparallel
processinghasbecomeincreasinglyimportantinrecentyears.
20.4.5.1 Shared-MemoryArchitectures
In earlier generation architectures, processors were connected to memory via a bus,
withallprocessorcoresandmemorybankssharingasinglebus.Adownsideofshared-
memory accessed via a common bus is that the bus or the interconnection network
becomes a bottleneck, since it is shared by all processors. Adding more processors
doesnothelpafterapoint,sincetheprocessorswillspendmostoftheirtimewaiting
fortheirturnonthebustoaccessmemory.
Asaresult,modernshared-memoryarchitecturesassociatememorydirectlywith
processors;eachprocessorhaslocallyconnectedmemory,whichcanbeaccessedvery
quickly;however,eachprocessorcanalsoaccessmemoryassociatedwithotherproces-
sors; afast interprocessorcommunicationnetworkensuresthatdataarefetchedwith
relatively low overhead. Since there is a difference in memory access speed depend-
ing on which part of memory is accessed, such an architecture is often referred to as
non-uniformmemoryarchitecture(NUMA).
Figure 20.6 shows a conceptual architecture of a modern shared-memory system
withmultipleprocessors;notethateachprocessorhasabankofmemorydirectlycon-
nectedtoit,andtheprocessorsarelinkedbyafastinterconnectsystem;processorsare
alsoconnectedtoI/Ocontrollerswhichinterfacewithexternalstorage.
I/O
Controller
CPU CPU
CPU CPU
I/O
Controller
yromeM
yromeM
rellortnoC
rellortnoC
Controller
Controller
Memory
Memory
Memory Memory
Figure 20.6 Architecture ofamodernshared-memorysystem.

--- Page 1011 ---

982 Chapter20 Database-SystemArchitectures
Becauseshared-memoryarchitecturesrequirespecializedhigh-speedinterconnects
between cores and between processors, the number of cores/processors that can be
interconnectedinashared-memorysystemisrelativelysmall.Asaresult,thescalability
ofshared-memoryparallelismislimitedtoatmostafewhundredcores.
Processor architectures include cache memory, since access to cache memory is
muchfasterthanaccesstomainmemory(cachecanbeaccessedinafewnanoseconds
comparedtonearlyahundrednanosecondsformainmemory).Largecachememory
isparticularlyimportantinshared-memoryarchitectures,sincealargecachecanhelp
minimizethenumberofaccessestosharedmemory.
Ifaninstructionneedstoaccessadataitemthatisnotincache,itmustbefetched
from main memory.Because main memoryismuchslowerthan processors, a signifi-
cantamountofpotentialprocessingspeedmaybelostwhileacorewaitsfordatafrom
mainmemory.Thesewaitsarereferredtoascachemisses.
Manyprocessorarchitecturessupportafeaturecalledhyper-threading,orhardware
threads,whereasinglephysical coreappears astwoormorelogicalcoresorthreads.
Differentprocessescouldbemappedtodifferentlogicalcores.Onlyoneofthelogical
corescorrespondingtoasinglephysicalcorecanactuallyexecuteatanytime.Butthe
motivationforlogicalcoresisthatifthecoderunningononelogicalcoreblocksona
cachemiss,waitingfordatatobefetchedfrommemory,thehardwareofthephysical
corecanstartexecutionofoneoftheotherlogicalcoresinsteadofidlingwhilewaiting
fordatatobefetchedfrommemory.
Atypicalmulticoreprocessorhasmultiplelevelsofcache,withtheL1cachebeing
fastesttoaccess,butalsothesmallest;lowercachelevelssuchasL2andL3areslower
(although still much faster than main memory) but considerably larger than the L1
cache. Lower cache levels are usually shared between multiple cores on a single pro-
cessor.InthecachearchitectureshowninFigure20.7,theL1andL2cachesarelocal
toeachofthe4cores,whiletheL3cacheissharedbyallcoresoftheprocessor.data
are read into, or written from, cache in units of a cache line, which typically consists
of64consecutivebytes.
Core 0 Core 1 Core 2 Core 3
L1 Cache L1 Cache L1 Cache L1 Cache
L2 Cache L2 Cache L2 Cache L2 Cache
Shared L3 Cache
Figure 20.7 Multilevelcache system.

--- Page 1012 ---

20.4 ParallelSystems 983
20.4.5.2 CacheCoherency
Cachecoherencyisanissuewhenevertherearemultiplecoresorprocessors,eachwith
its own cache. An update done on one core may not be seen by another core, if the
localcacheonthesecondcorecontainsanoldvalueoftheaffectedmemorylocation.
Thus,wheneveranupdateoccurstoamemorylocation,copiesofthecontentofthat
memorylocationthatarecachedonothercachesmustbeinvalidated.
Suchinvalidationisdonelazilyinmanyprocessorarchitectures;thatis,theremay
be some time lag between a write to a cache and the dispatch of invalidation mes-
sagestoothercaches;inadditiontheremaybeafurtherlaginprocessinginvalidation
messages that are received at a cache. (Requiring immediate invalidation to be done
alwayscancauseasignificantperformancepenalty,andthusitisnotdoneincurrent-
generationsystems.)Thus,itisquitepossibleforawritetohappenononeprocessor,
andasubsequentreadonanotherprocessormaynotseetheupdatedvalue.
Suchalackofcachecoherencycancauseproblemsifaprocessexpectstoseean
updatedmemorylocationbutdoesnot.Modernprocessorsthereforesupportmemory
barrierinstructions,whichensurecertainorderingsbetweenload/storeoperationsbe-
fore the barrier and those after the barrier. For example, the store barrier instruction
(sfence) on the x86 architecture forces the processor to wait until invalidation mes-
sagesaresenttoallcachesforallupdatesdonepriortotheinstruction,beforeanyfur-
therload/storeoperationsareissued.Similarly,theloadbarrierinstruction(lfence)en-
suresallreceivedinvalidationmessageshavebeenappliedbeforeanyfurtherload/store
operationsareissued.Themfenceinstructiondoesbothofthesetasks.
Memorybarrierinstructionsmustbeusedwithinterprocesssynchronizationpro-
tocolstoensurethattheprotocolsexecute correctly.Withouttheuse ofmemorybar-
riers, if the caches are not “strongly” coherent, the following scenario can happen.
Consider a situation where a process P1 updates memory location A first, then loca-
tionB; aconcurrentprocess P2runningonadifferentcoreorprocessorreadsB first
andthenreadsA.Withacoherentcache,ifP2seestheupdatedvalueofB,itmustalso
see the updated value of A. However, in the absence of cache coherence, the writes
may be propagated out of order, and P2 may thus see the updated value of B but the
old value of A. While many architectures disallow out-of-order propagation of writes,
thereareothersubtle errorsthatcanoccurduetolackofcachecoherency.However,
executingsfenceinstructionsaftereachofthesewritesandlfencebeforeeachofthe
readswillalwaysensurethatreadsseeacachecoherentstate.Asaresult,intheabove
example,theupdatedvalueofBwillbeseenonlyiftheupdatedvalueofAisseen.
It is worth noting that programs do not need to include any extra code to deal
withcachecoherency,aslongastheyacquirelocksbeforeaccessingdata,andrelease
locksonlyafterperformingupdates,sincelockacquireandreleasefunctionstypically
includetherequiredmemorybarrierinstructions.Specifically,ansfenceinstructionis
executedaspartofthelockreleasecode,beforethedataitemisactuallyunlocked.Sim-
ilarlyanlfenceisexecutedrightafterlockingadataitem,aspartofthelockacquisition

--- Page 1013 ---

984 Chapter20 Database-SystemArchitectures
function, and is thus executed before the item is read. Thus, the reader is guaranteed
toseethemostrecentvaluewrittentothedataitem.
Synchronization primitives supported in a variety of languages also internallyex-
ecutememorybarrierinstructions;asaresult,programmerswhousetheseprimitives
neednotbeconcernedaboutlackofcachecoherency.
It is also interesting to note that many processor architectures use a form of
hardware-level shared and exclusive locking of memory locations to ensure cache co-
herency. A widely used protocol, called the MESI protocol, can be understood as fol-
lows:Lockingisdoneatthelevelofcachelines,containingmultiplememorylocations,
insteadofsupportinglocksonindividualmemorylocations,sincecachelinesarethe
unitsofcacheaccess.Lockingisimplementedinthehardware,ratherthaninsoftware,
toprovidetherequiredhighperformance.
TheMESIprotocolkeepstrackofthestateofeachcacheline,whichcanbeModi-
fied(updatedafterexclusivelocking),Exclusivelocked(lockedbutnotyetmodified,or
alreadywrittenbacktomemory),Sharelocked,orInvalid.Areadofamemorylocation
automaticallyacquiresasharedlockonthecachelinecontainingthatlocation,while
a memory write gets an exclusive lock on the cache line before performing the write.
Incontrasttodatabaselocks,memorylockrequestsdonotwait;insteadtheyimmedi-
atelyrevokeconflictinglocks.Thus,anexclusivelockrequestautomaticallyinvalidates
allcachedcopiesofthecachelineandrevokesallsharedlocksonthecacheline.Sym-
metrically, a shared lock request causes any existing exclusive lock to be revoked and
thenfetchesthelatestcopyofthememorylocationintocache.
Inprinciple,itispossibletoensure“strong”cachecoherencywithsuchalocking-
basedcachecoherenceprotocol,makingmemorybarrierinstructionsredundant.How-
ever,manyimplementationsincludesomeoptimizationsthatspeedupprocessing,such
as allowing delayed delivery of invalidation messages, at the cost of not guaranteeing
cache coherence. As a result, memory barrier instructions are required on many pro-
cessorarchitecturestoensurecachecoherency.
20.4.6 Shared Disk
Intheshared-diskmodel,eachnodehasitsownprocessorsandmemory,butallnodes
canaccessalldisksdirectlyviaaninterconnectionnetwork.Therearetwoadvantages
ofthisarchitectureoverashared-memoryarchitecture.First,ashared-disksystemcan
scaletoalargernumberofprocessorsthanashared-memorysystem.Second,itoffers
acheapwaytoprovideadegreeoffaulttolerance:Ifanodefails,theothernodescan
take over its tasks, since the database is resident on disks that are accessible from all
nodes.
WecanmakethedisksubsystemitselffaulttolerantbyusingaRAIDarchitecture,
asdescribedinChapter12,allowingthesystemtofunctionevenifindividualdisksfail.
ThepresenceofalargenumberofstoragedevicesinaRAIDsystemalsoprovidessome
degreeofI/Oparallelism.

--- Page 1014 ---

20.4 ParallelSystems 985
node
node storage array
storage area
node
network
node storage array
node
Figure 20.8 Storage-areanetwork.
A storage-area network (SAN) is a high-speed local-areanetwork designed to con-
nectlargebanksofstoragedevices(disks)tonodesthatusethedata(seeFigure20.8).
Thestoragedevicesphysicallyconsistofanarrayofmultipledisksbutprovideaview
of a logical disk, or set of disks, that hidesthe detailsof the underlyingdisks. For ex-
ample,alogicaldiskmaybe muchlargerthan anyofthephysicaldisks, and alogical
disk’ssizecanbeincreasedbyaddingmorephysical disks.Theprocessingnodescan
accessdisksasiftheyarelocaldisks,eventhoughtheyarephysicallyseparate.
Storage-area networks are usually built with redundancy, such as multiple paths
betweennodes,soifacomponentsuchasalinkoraconnectiontothenetworkfails,
thenetworkcontinuestofunction.
Storage-areanetworksarewellsuitedforbuildingshared-disksystems.Theshared-
diskarchitecturewithstorage-areanetworkshasfoundacceptanceinapplicationsthat
donotneedaveryhighdegreeofparallelismbutdorequirehighavailability.
Compared to shared-memory systems, shared-disk systems can scale to a larger
numberofprocessors,butcommunicationacrossnodesisslower(uptoafewmillisec-
onds in the absence of special-purpose hardware for communication), since it has to
gothroughacommunicationnetwork.
Onelimitationofshared-disksystemsisthatthebandwidthofthenetworkconnec-
tion to storage in a shared-disk system is usually less than the bandwidth available to
accesslocalstorage.Thus,storageaccesscanbecomeabottleneck,limitingscalability.
20.4.7 Shared Nothing
In a shared-nothing system, each node consists of a processor, memory, and one or
moredisks.Thenodescommunicatebyahigh-speedinterconnectionnetwork.Anode

--- Page 1015 ---

986 Chapter20 Database-SystemArchitectures
functions as the server for the data on the disk or disks that the node owns. Since
localdiskreferencesareservicedbylocaldisksateachnode,theshared-nothingmodel
overcomesthedisadvantageofrequiringallI/Otogothroughasingleinterconnection
network.
Moreover, the interconnection networks for shared-nothing systems, such as the
tree-like interconnection network, are usually designed to be scalable, so their trans-
mission capacity increases as more nodes are added. Consequently, shared-nothing
architecturesaremorescalableandcaneasilysupportaverylargenumberofnodes.
The main drawbacks of shared-nothing systems are the costs of communication
andofnonlocaldiskaccess,whicharehigherthaninashared-memoryorshared-disk
architecturesincesendingdatainvolvessoftwareinteractionatbothends.
Due to theirhighscalability,shared-nothingarchitecturesarewidelyused to deal
with very large data volumes, supporting scalability to thousands of nodes, or in ex-
tremecases,eventotensofthousandsofnodes.
20.4.8 Hierarchical
The hierarchical architecture combines the characteristics of shared-memory, shared-
disk, and shared-nothing architectures. At the top level, the system consists of nodes
thatare connectedby an interconnectionnetworkand donotshare disks ormemory
withoneanother.Thus,thetoplevelisashared-nothingarchitecture.Eachnodeofthe
systemcouldactuallybeashared-memorysystemwithafewprocessors.Alternatively,
eachnodecouldbeashared-disksystem,andeachofthesystemssharingasetofdisks
could be a shared-memory system. Thus, a system could be built as a hierarchy, with
shared-memory architecture with a few processors at the base, and a shared-nothing
architecture at the top, with possibly a shared-disk architecture in the middle. Figure
20.5d illustrates a hierarchical architecture with shared-memory nodes connected to-
getherinashared-nothingarchitecture.
Paralleldatabasesystemstodaytypicallyrunonahierarchicalarchitecture,where
eachnodesupportsshared-memoryparallelism,withmultiplenodesinterconnectedin
ashared-nothingmanner.
20.5 Distributed Systems
Inadistributeddatabasesystem,thedatabaseisstoredonnodeslocatedatgeographi-
callyseparatedsites.Thenodesinadistributedsystemcommunicatewithoneanother
throughvariouscommunicationmedia,suchashigh-speedprivatenetworksorthein-
ternet.Theydonotsharemainmemoryordisks.Thegeneralstructureofadistributed
systemappearsinFigure20.9.
The main differences between shared-nothing parallel databases and distributed
databasesincludethefollowing:

--- Page 1016 ---

20.5 DistributedSystems 987
site A site C
network
communication
via network
site B
Figure 20.9 Adistributedsystem.
• Distributeddatabaseshavesitesthataregeographicallyseparated.Asaresult,the
networkconnectionshavelowerbandwidth,higherlatency,andgreaterprobability
offailures,ascomparedtonetworkswithinasingledatacenter.
Systems built on distributed databases therefore need to be aware of network la-
tency, and failures, as well as of physical data location. We discuss these issues
laterinthissection.Inparticular,itisoftendesirabletokeepacopyofthedataat
adatacenterclosetotheenduser.
• Paralleldatabasesystemsaddresstheproblemofnodefailure.However,somefail-
ures, particularly those due to earthquakes, fires, or other natural disasters, may
affectanentiredatacenter,causingfailureofalargenumberofnodes.Distributed
database systems need to continue working even in the event of failure of an en-
tiredatacenter,toensurehighavailability.Thisrequiresreplicationofdataacross
geographically separated data centers, to ensure that a common natural disaster
does not affect all the data centers. Replication and other techniques to ensure
high availability are similar in both parallel and distributed databases, although
implementationdetailsmaydiffer.
• Distributed databases may be separately administered, with each site retaining
some degree of autonomy of operation. Such databases are often the result of
the integration of existing databases to allow queries and transactions to cross
database boundaries. However, distributed databases that are built for providing
geographic distribution, versus those built by integrating existing databases, may
becentrallyadministered.
• Nodes in a distributed database tend to vary more in size and function, whereas
paralleldatabasestendtohavenodesthatareofsimilarcapacity.

--- Page 1017 ---

988 Chapter20 Database-SystemArchitectures
• In a distributed database system, we differentiatebetween local and global trans-
actions. A local transaction is one that accesses data only from nodes where the
transaction was initiated. A global transaction, on the other hand, is one that ei-
ther accesses data in a node different from the one at which the transaction was
initiated,oraccessesdatainseveraldifferentnodes.
Web-scaleapplicationstodayrunondatamanagementsystemsthatcombinesup-
portforparallelismanddistribution.Parallelismisusedwithinadatacentertohandle
high loads, while distribution across data centers is used to ensure high availability
even in the event of natural disasters. At the lower end of functionality, such systems
may be distributed data storage systems that support only limited functionality such
as storage and retrievalof data by key, and they may notsupport schemas, query lan-
guages, or transactions; all such higher-level functionality has to be managed by the
applications.Atthehigherendoffunctionality,therearedistributeddatabasesystems
that support schemas, query language, and transactions. However, one characteristic
ofsuchsystemsisthattheyarecentrallyadministered.
In contrast, distributed databases that are built by integrating existing database
systemshavesomewhatdifferentcharacteristics.
• Sharingdata.Themajoradvantageinbuildingadistributeddatabasesystemisthe
provisionofanenvironmentwhereusersatonesitemaybeabletoaccessthedata
residingatothersites.Forinstance,inadistributeduniversitysystem,whereeach
campusstoresdatarelatedtothatcampus,itispossibleforauserinonecampus
toaccessdatainanothercampus.Withoutthiscapability,thetransferofstudent
recordsfromonecampustoanothercampuswouldhavetorelyonsomeexternal
mechanism.
• Autonomy. The primary advantage of sharing data by means of data distribution
is that each site can retain a degree of control over data that are stored locally.
Inacentralizedsystem,thedatabaseadministratorofthecentralsitecontrolsthe
database.Inadistributedsystem,thereisaglobaldatabaseadministratorrespon-
siblefortheentiresystem.Apartoftheseresponsibilitiesisdelegatedtothelocal
database administrator for each site. Depending on the design of the distributed
databasesystem,eachadministratormayhaveadifferentdegreeoflocalautonomy.
In a homogeneous distributed database system, nodes share a common global
schema (although some relations may be stored only at some nodes), all nodes run
thesamedistributeddatabase-managementsoftware,andthenodesactivelycooperate
inprocessingtransactionsandqueries.
However, in many cases a distributed database has to be constructed by linking
togethermultiplealready-existingdatabasesystems,eachwithitsownschemaandpos-
siblyrunning differentdatabase-management software. Thesites maynot be awareof
oneanother,andtheymayprovideonlylimitedfacilitiesforcooperationinqueryand
transactionprocessing.Suchsystemsaresometimescalledfederateddatabasesystems
orheterogeneousdistributeddatabasesystems.

--- Page 1018 ---

20.6 TransactionProcessinginParallelandDistributedSystems 989
Nodesinadistributeddatabasecommunicateoverwide-areanetworks(WAN).Al-
thoughwide-areanetworkshavebandwidthmuchgreaterthanlocal-areanetworks,the
bandwidthisusuallysharedbymultipleusers/applicationsandisexpensiverelativeto
local-area network bandwidth. Thus, applications that communicate across wide-area
networksusuallyhavealowerbandwidth.
Communication in a WAN must also contend with significant latency: a message
maytakeuptoafewhundredmillisecondstobedeliveredacrosstheworld,bothdue
tospeed-of-lightdelays,andduetoqueuingdelaysatanumberofroutersinthepathof
the message. Latency in a wide-area setting is a fundamental problem that cannot be
reduced beyond a point. Thus, applications whose data and computing resources are
distributedgeographicallyhavetobecarefullydesignedtoensurethatlatencydoesnot
affectsystemperformanceexcessively.
Wide-areanetworksalsohavetocontendwithnetwork-linkfailures,aproblemthat
isrelativelyrareinlocal-areanetworks.Inparticular,network-linkfailuresmayresultin
twositesthatarebothalivehavingnowaytocommunicatewitheachother,asituation
referredtoasanetworkpartition.5Intheeventofapartition,itmaynotbepossiblefor
auseroranapplicationtoaccessrequireddata.Thus,networkpartitioningaffectsthe
availability of a system. Tradeoffs between availability and consistency of data in the
eventofnetworkpartitionsarediscussedinSection23.4.
20.6 Transaction Processing in Parallel and Distributed Systems
Atomicity of transactions is an important issue in building a parallel and distributed
database system. If a transaction runs across two nodes, unless the system designers
arecareful,itmaycommitatonenodeandabortatanother,leadingtoaninconsistent
state.Transactioncommitprotocolsensuresuchasituationcannotarise.Thetwo-phase
commitprotocol(2PC)isthemostwidelyusedoftheseprotocols.
The2PCprotocolisdescribedindetailinSection23.2.1,butthekeyideasareas
follows: The basic idea behind 2PC is for each node to execute the transaction until
itentersthepartiallycommittedstate,andthenleavethecommitdecisiontoasingle
coordinatornode;thetransactionissaidtobeinthereadystateatanodeatthispoint.
Thecoordinatordecidestocommitthetransactiononlyifthetransactionreachesthe
ready state at every node where it executed; otherwise (e.g., if the transaction aborts
atany node), the coordinatordecidesto abort the transaction. Every node wherethe
transactionexecutedmustfollowthedecisionofthecoordinator.Ifanodefailswhen
a transaction is in ready state, when the node recovers from failure it should be in a
position to either commit or abort the transaction, depending on the decision of the
coordinator.
5Donotconfusethetermnetworkpartitioningwiththetermdatapartitioning;datapartitioningreferstodividingupof
dataitemsintopartitions,whichmaybestoredatdifferentnodes.

--- Page 1019 ---

990 Chapter20 Database-SystemArchitectures
Concurrency control is another issue in parallel and distributed databases. Since
a transaction may accessdata itemsat several nodes, transaction managers at several
nodes may need to coordinate to implement concurrency control. If locking is used,
locking can be performed locally at the nodes containing accessed data items, but
there is also a possibility of deadlock involving transactions originating at multiple
nodes. Therefore deadlock detection needs to be carried out across multiple nodes.
Failures are more common in distributed systems since not only may computers fail,
but communication links may also fail. Replication of data items, whichis the key to
thecontinuedfunctioningofdistributeddatabaseswhenfailuresoccur,furthercompli-
catesconcurrencycontrol.Wedescribeconcurrency-controltechniquesfordistributed
databasesinSection23.3(whichdescribestechniquesbasedonlocking)andSection
23.3.4(whichdescribestechniquesbasedontimestamps).
Thestandardtransactionmodels,basedonmultipleactionscarriedoutbyasingle
programunit,areofteninappropriateforcarryingouttasksthatcrosstheboundaries
of databases that cannot or will not cooperate to implement protocols such as 2PC.
Alternativeapproaches,basedonpersistentmessagingforcommunication,aregenerally
usedforsuchtasks;persistentmessagingisdiscussedinSection23.2.3.
Whenthetaskstobecarriedoutarecomplex,involvingmultipledatabasesand/or
multipleinteractionswithhumans,coordinationofthetasksandensuringtransaction
propertiesforthetasksbecomemorecomplicated.Workflowmanagement systemsare
systemsdesignedtohelpwithcarryingoutsuchtasks.
20.7 Cloud-Based Services
Traditionally,enterprises purchased and ran servers thatexecute the database as well
as the applications. There is a high cost to maintaining servers, including setting up
server room infrastructure dealing with all kinds of failures such as air conditioning
and power failures, not to mention failures of CPUs, disks, and other components of
theservers.Further,ifthereisasuddenincreaseindemand,itisverydifficulttoadd
infrastructure to service the demand, and if demand falls, the infrastructure may lie
idle.
In contrast, in the cloud computing model, applications of an enterprise are ex-
ecuted on an infrastructure that is managed by another company, typically at a data
centerthathostsalargenumberofmachinesusedbymanydifferententerprises/users.
The service provider may provide not just hardware, but also support platforms such
asdatabases,andapplicationsoftware.
A variety of vendors offer cloud services; these include major vendors such as
Amazon, Microsoft, IBM, and Google, and a number of smaller vendors. One of the
pioneers of cloud services, Amazon, originally built a large computing infrastructure
purely for its internal use; then, seeing a business opportunity, it offered computing
infrastructure as a service to other users. Cloud services became very popular within
justafewyears.

--- Page 1020 ---

20.7 Cloud-BasedServices 991
Cloud Clients
Web browsers, mobile apps, ...
internet
Software-as-a-Service
Enterprise applications, email,
shared documents, ...
Platform-as-a-Service
Data storage, Database,
Application server, ...
Infrastructure-as-a-Service
Containers
Virtual Machines
Servers Storage
Figure 20.10 Cloudservicemodels.
20.7.1 Cloud Service Models
There are several ways in which cloud computing can be utilized, which are summa-
rized in Figure 20.10. These include infrastructure-as-a-service, platform-as-a-service,
andsoftware-as-a-servicemodels.
• In the infrastructure-as-a-service model, an enterprise rents computing facilities;
for example, an enterprise may rent one or more physical machines, along with
diskstoragespace.
Morefrequently,cloudcomputingprovidersprovideanabstractionofavirtual
machine (VM), which appears to the user to be a real machine. These machines
arenot“real”machines,butratheraresimulatedby softwarethatallowsasingle

--- Page 1021 ---

992 Chapter20 Database-SystemArchitectures
realcomputer tosimulate several independentcomputers. Containersare alower
cost alternative to VMs and are described later in thissection. Multiple VMs can
run on a single server machine, and multiple containers can run on a single VM
orserver.
By running a very large data center with many machines, cloud-service
providers can exploit economies of scale and deliver computing power at much
lowercostthananenterprisecandousingitsowninfrastructure.
Anothermajoradvantageofcloudcomputingisthatthecloud-serviceprovider
usuallyhasalargenumberofmachines,withsparecapacity,andthusanenterprise
canrentmore(virtual)machinesasneededtomeetdemandandreleasethemat
times of light load. The ability to expand or contract capacity at short notice is
oftenreferredtoaselasticity.
The above benefits of on-demand elastic provisioning of server systems have
ledtothewidespreadadoptionofinfrastructure-as-serviceplatforms,especiallyby
companiesthatanticipaterapidgrowthintheircomputingusage.However,dueto
thepotentialsecurityrisksofstoringdataoutsidetheenterprise,theuseofcloud
computingisstilllimitedinhigh-securityenterpriseneeds,suchasbanking.
In the infrastructure-as-service model, the client enterprise runs its own soft-
ware, including database systems, on virtual machines provided by the cloud-
serviceprovider;theclienthastoinstallthedatabasesystemanddealwithmain-
tenanceissuessuchasbackupandrestore.
• Intheplatform-as-a-servicemodel,theserviceprovidernotonlyprovidescomput-
inginfrastructure,butitalsodeploysandmanagesplatforms,suchasdatastorage,
databases,andapplicationservers,thatareusedbyapplicationsoftware.Theclient
has to install and maintain application software, such as enterprise resource plan-
ning(ERP)systems,whichrunonsuchplatform-providedservicesasapplication
servers,databaseservices,ordatastorageservices.
° Cloud-baseddatastorageplatformsprovideaservicethatapplicationscanuse
tostoreandretrievedata.Theserviceprovidertakescareofprovisioningsuffi-
cientamountofstorageandcomputingpowertosupporttheloadonthedata
storageplatform.Suchstoragesystemscouldsupportfiles,whicharetypically
large,ranginginsizefromafewmegabytestothousandsofmegabytes,support-
ing millions of such files. Or such storage systems could support data items,
whicharetypicallysmall,rangingfromhundredsofbytestoafewmegabytes,
but supporting billions of such data items. Such distributed file systems and
datastoragesystemsarediscussedinSection21.6andSection21.7.Database
applications using cloud-based storage may run on the same cloud (i.e., the
samesetofmachines),oronanothercloud.
Oneofthemainattractionsofcloud-basedstorageisthatitcanbeusedby
paying a fee without worrying about purchasing, maintaining, and managing
the computer systems on which such a service runs. Further, if there is an

--- Page 1022 ---

20.7 Cloud-BasedServices 993
increase in demand, the number of servers on which the service runs can be
increasedbypayingalargerfee,withouthavingtoactuallypurchaseanddeploy
moreservers.Theserviceproviderwouldofcoursehavetodeployextraservers,
buttheybenefitfromeconomiesofscale;thecostofdeployment,andespecially
the time to deployment, are greatlyreduced compared to what they would be
iftheend-usersdiditontheirown.
Thefeesforcloud-baseddatastoragearetypicallybasedontheamountof
datastored,andamountofdatainputto,andtheamountofdataoutputfrom,
thedatastoragesystem.
° Database-as-a-service platforms provide a database that can be accessed and
queriedbyclients.Unlikestorageservices,database-as-a-serviceplatformspro-
vide database functionality such as querying using SQL or other query lan-
guages,whichdatastoragesystemsdonotprovide.Earlyofferingsofdatabase-
as-a-service only supported databases that run on a single node, although the
nodeitselfcanhaveasubstantialnumberofprocessors,memory,andstorage.
More recently,parallel database systems are being offered as a service on the
cloud.
• In the software-as-a-service model, the service provider provides the application
softwareasaservice.Theclientdoesnotneedtodealwithissuessuchassoftware
installationorupgrades;thesetasksarelefttotheserviceprovider.Theclientcan
directlyuseinterfacesprovidedbythesoftware-as-a-serviceprovider,suchasweb
interfaces,ormobileappinterfacesthatprovideafrontend,withtheapplication
softwareactingasthebackend.
Theconceptofvirtualmachineswasdevelopedinthe1960stoallowanexpensive
mainframe computer to be shared concurrently by users running different operating
systems.Althoughcomputersarenowmuchcheaper,thereisstillacostassociatedwith
supplying electrical power to the computers and maintaining them; virtual machines
allow this cost to be shared by multiple concurrent users. Virtual machines also ease
the task of moving services to new machines: a virtual machine can be shut down
on one physical server and restarted on another physical server with very little delay
or downtime. This feature is particularly important for quick recovery in the event of
hardwarefailureorupgrade.
Although multiple virtual machines can run on a single real machine, each VM
hasahighoverhead,sinceitrunsanentireoperatingsysteminternally.Whenasingle
organization wishes to run a number of services, if it creates a separate VM for each
service,theoverheadcanbeveryhigh.Ifmultipleapplicationsarerunononemachine
(orVM),twoproblemsoftenarise:(1)applicationsconflictonnetworkportsbyeach
tryingtolistentothesamenetworkport,and(2)applicationsrequiredifferentversions
ofsharedlibraries,causingconflicts.
Containers solve both these problems; applicationsrun in a container,whichhas
itsownIPaddressanditsownsetofsharedlibraries.Eachapplicationcanconsistof

--- Page 1023 ---

994 Chapter20 Database-SystemArchitectures
App App
App App App App
Libraries Libraries
Libraries Libraries
App App
OS Kernel OS Kernel App App
Libraries
Libraries Libraries
OS Kernel Hypervisor
OS Kernel
a) Multiple applications on a b) Each application running on c) Each application running in
single machine its own VM, with multiple VMs its own container, with multiple
running in a machine containers running in a machine
Figure 20.11 Applicationdeploymentalternatives.
multipleprocesses,allrunningwithinthesamecontainer.Thecostofusingcontainers
to run applications is much less than the alternative of running each application in
itsownVM,sincemanycontainerscansharethesameoperatingsystemkernel.Each
containerappearstohaveitsownfilesystem, butthefilesareallstoredinacommon
underlyingfilesystem acrossallcontainers.Processeswithinacontainercaninteract
with each other through the file system as well as interprocess communication, but
theycaninteractwithprocessesfromothercontainersonlyvianetworkconnections.
Figure20.11depictsthedifferentdeploymentalternativesforasetofapplications.
Figure 20.11a shows the alternative of multiple applications running in a single ma-
chine,sharinglibrariesand operating-system kernel.Figure20.11b shows the alterna-
tiveofrunningeachapplicationinitsownVM,withmultipleVMsrunningonasingle
machine. The different VMs running on a single real machine are managed by a soft-
ware layer called the hypervisor. Figure 20.11c shows the alternative of using contain-
ers,witheachcontainerhavingitsownlibraries,andmultiplecontainersrunningona
singlemachine.Sincecontainershaveloweroverheads,asinglemachinecansupport
morecontainersthanVMs.
Containers provide low-cost support for elasticity, since more containers can be
deployedveryquicklyonexistingvirtualmachines,insteadofstartingupfreshvirtual
machines.
Manyapplicationstodayarebuiltasacollectionofmultipleservices,eachofwhich
runs as a separate process, offering a network API; that is, the functions provided by
theserviceareinvokedbycreatinganetworkconnectiontotheprocessandsendinga
service requestover thenetworkconnection.Such an applicationarchitecture,which
buildsanapplicationasacollectionofsmallservices,iscalledamicroservicesarchitec-
ture.Containersfitthemicroservicesarchitectureverywell,sincetheyprovideavery
lowoverheadmechanismtoexecuteprocessessupportingeachservice.

--- Page 1024 ---

20.8 Summary 995
Dockerisaverywidelyusedcontainerplatform,whileKubernetesisaverypopular
platform that providesnot only containers,but alsoa microservicesplatform. Kuber-
netes allows applications to specify declaratively their container needs, and it auto-
maticallydeploysandlinksmultiplecontainerstoexecutetheapplication.Itcanalso
manage a number of pods, which allow multiple containers to share storage (file sys-
tem)andnetwork(IPaddress)whileallowingcontainerstoretaintheirowncopiesof
shared libraries.Furthermore,itcan manage elasticitybycontrollingthe deployment
ofadditionalcontainerswhenrequired.Kubernetescansupportapplicationscalability
byload-balancingAPIrequestsacrossacollectionofcontainersthatallrun copiesof
the same application. Users of the API do not need to know what IP addresses (each
correspondingtoacontainer)theserviceisrunningon,andtheycaninsteadconnect
toasingleIPaddress.TheloadbalancerdistributestherequestsfromthecommonIP
addresstoasetofcontainers(eachwithitsownIPaddress)runningtheservice.
20.7.2 Benefits and Limitations of Cloud Services
Many enterprises are finding the model of cloud computing and services beneficial.
Thecloud modelsaves cliententerprisesthe needtomaintainalarge system-support
staffandallowsnewenterprisestobeginoperationwithouthavingtomakealarge,up-
frontcapitalinvestmentincomputingsystems.Further,astheneedsoftheenterprise
grow, more resources (computing and storage) can be added as required; the cloud-
computing vendor generally has very large clusters of computers, making it easy for
thevendortoallocateresourcesondemand.
Users of cloud computing must be willing to accept that their data are held by
anotherorganization.Thismaypresentavarietyofrisksintermsofsecurityandlegal
liability. If the cloud vendor suffers a security breach, client data may be divulged,
causing the client to face legal challenges from its customers. Yet the client has no
direct control over cloud-vendor security. These issues become more complex if the
cloud vendor chooses to store data (or replicasof data) in a foreign country. Various
legaljurisdictionsdifferintheirprivacylaws.So,forexample,ifaGermancompany’s
dataarereplicatedonaserverinNewYork,thentheprivacylawsoftheUnitedStates
mayapplyinsteadoforinadditiontothoseofGermanyortheEuropeanUnion.The
cloud vendor might be required to release client data to the U.S. government even
though the client never knew that its data would be stored in a location under U.S.
jurisdiction. Specific cloud vendors offer their clients varying degrees of control over
howtheirdataaredistributedgeographicallyandreplicated.
Despite the drawbacks, the benefits of cloud services are great enough that there
isarapidlygrowingmarketforsuchservices.
20.8 Summary
• Centralizeddatabasesystemsrunentirelyonasinglecomputer.Databasesystems
designedformultiusersystemsneedtosupportthefullsetoftransactionfeatures.

--- Page 1025 ---

996 Chapter20 Database-SystemArchitectures
Suchsystemsareusuallydesignedasserversthatacceptrequestsfromapplications
viaSQLortheirownAPIs.
• Parallelism with a small number of cores is referred to as coarse-grained paral-
lelism.Parallelismwithalargenumberofprocessorsisreferredtoasfine-grained
parallelism.
• Transactionservershavemultipleprocesses,possiblyrunningonmultipleproces-
sors. So that these processes have access to common data, such as the database
buffer, systems store such data in shared memory. In addition to processes that
handle queries, there are system processes that carry out tasks such as lock and
logmanagementandcheckpointing.
• Access to shared memory is controlled by a mutual-exclusion mechanism based
onmachine-levelatomicinstructions(test-and-setorcompare-and-swap).
• Data-server systems supply raw data to clients. Such systems strive to minimize
communication between clients and servers by caching data and locks at the
clients.Paralleldatabasesystemsusesimilaroptimizations.
• Parallel database systems consist of multiple processors and multiple disks con-
nectedbyafastinterconnectionnetwork.Speedupmeasureshowmuchwecanin-
creaseprocessingspeedbyincreasingparallelismforasingletransaction.Scaleup
measureshowwellwecanhandleanincreasednumberoftransactionsbyincreas-
ingparallelism.Interference,skew,andstart-upcostsactasbarrierstogettingideal
speedupandscaleup.
• The components of a parallel system are connected via several possible types of
interconnectionnetworks:bus,ring,mesh,hypercube,oratree-liketopology.
• Parallel database architectures include the shared-memory, shared-disk, shared-
nothing, and hierarchical architectures. These architectures have different trade-
offsofscalabilityversuscommunicationspeed.
• Modern shared-memory architectures associate some memory with each proces-
sor,resultinginanon-uniformmemoryarchitecture(NUMA).Sinceeachproces-
sor has its own cache, there is a problem of ensuring cache coherency, that is,
consistencyofdataacrossthecachesofmultipleprocessors.
• Storage-areanetworksareaspecialtypeoflocal-areanetworkdesignedtoprovide
fastinterconnectionbetweenlargebanksofstoragedevicesandmultiplecomput-
ers.
• Adistributeddatabasesystemisacollectionofpartiallyindependentdatabasesys-
temsthat(ideally)shareacommonschemaandcoordinateprocessingoftransac-
tionsthataccessnonlocaldata.

--- Page 1026 ---

ReviewTerms 997
• Cloud services may be provided at a variety of levels: The infrastructure-as-a-
servicemodelprovidesclientswithavirtualmachineonwhichclientsinstalltheir
own software. The platform-as-a-service model provides data-storage, database,
andapplicationserversinadditiontovirtualmachines,buttheclientneedstoin-
stallandmaintainapplicationsoftware.Thesoftware-as-a-servicemodelprovides
thatapplicationsoftwareplustheunderlyingplatform.
• Organizations using cloud services have to consider a wide variety of technical,
economic, and legal issues in order to ensure the privacy and security of data
andadequateperformancedespitethelikelihoodofdatabeingstoredataremote
location.
Review Terms
• CentralizedDatabaseSystems ° Datacenter
° Single-usersystem • Decision-supportqueries
° Multiusersystem • Measureofperformance
° Serversystems ° Throughput
° Embeddeddatabases ° Responsetime
° Servers ° Linearspeedup
° Coarse-grainedparallelism ° Sublinearspeedup
° Fine-grainedparallelism ° Linearscaleup
• ServerSystemArchitectures ° Sublinearscaleup
° Transaction-server • Sequentialcomputation
• Amdahl’slaw
° Query-server
• Start-upcosts
° Data-serversystems
• Interconnectionnetwork
° Serverprocesses
° Bus
• Mutualexclusion
• Atomicinstructions ° Ring
• Datacaching ° Mesh
• ParallelSystems ° Hypercube
° Coarse-grainparallelmachine ° Tree-like
° Massivelyparallelmachine ° Edgeswitches
° Fine-grainparallelmachine • Aggregationswitch

--- Page 1027 ---

998 Chapter20 Database-SystemArchitectures
• Ethernet • Shared-disk
• Fiberchannel • Faulttolerance
• Infiniband • Storage-areanetwork(SAN)
• Remote direct memory access • Distributeddatabasesystem
(RDMA) • Localautonomy
• ParallelDatabaseArchitectures • Homogeneousdistributeddatabase
• Federateddatabasesystems
° Sharedmemory
• Heterogeneous distributed database
° Shareddisk systems
° Clusters • Latency
° Sharednothing • Networkpartition
• Availability
° Hierarchical
• Cloudcomputing
• Moore’slaw • Infrastructure-as-a-service
• NUMA • Platform-as-a-service
• Cachemisses • Cloud-baseddatastorage
• Hyper-threading • Database-as-a-service
• Hardwarethreads • Software-as-a-service
• Cache • Microservicesarchitecture
Practice Exercises
20.1 Isamultiusersystemnecessarilyaparallelsystem?Whyorwhynot?
20.2 Atomicinstructionssuchascompare-and-swapandtest-and-setalsoexecutea
memoryfenceaspartoftheinstructiononmanyarchitectures.Explainwhat
isthemotivationforexecutingthememoryfence,fromtheviewpointofdata
in shared memory that is protected by a mutex implemented by the atomic
instruction.Alsoexplainwhataprocessshoulddobeforereleasingamutex.
20.3 Instead of storing shared structures in shared memory, an alternative archi-
tecture would be to store them in the local memory of a special process and
accesstheshareddatabyinterprocesscommunicationwiththeprocess.What
wouldbethedrawbackofsuchanarchitecture?
20.4 Explain the distinction between a latch and a lock as used for transactional
concurrencycontrol.
20.5 Suppose atransactioniswritteninCwithembeddedSQL,andabout80per-
centofthetimeisspentintheSQLcode,withtheremaining20percentspent

--- Page 1028 ---

Exercises 999
in C code. How much speedup can one hope to attain if parallelism is used
onlyfortheSQLcode?Explain.
20.6 Consider a pair of processes in a shared memory system such that process
A updates a data structure, and then sets a flag to indicate that the update is
completed. Process B monitors the flag, and starts processing the data struc-
tureonlyafteritfindstheflagisset.
Explain the problems that could arise in a memory architecture where
writesmaybereordered,andexplainhowthesfenceandlfenceinstructions
canbeusedtoensuretheproblemdoesnotoccur.
20.7 Inashared-memoryarchitecture,whymightthetimetoaccessamemorylo-
cationvarydependingonthememorylocationbeingaccessed?
20.8 Most operating systems for parallel machines (i) allocate memory in a local
memory area when a process requests memory, and (ii) avoid moving a pro-
cessfromonecoretoanother.Whyaretheseoptimizationsimportantwitha
NUMAarchitecture?
20.9 Some database operations such as joins can see a significant difference in
speed when data (e.g., one of the relations involved in a join) fits in mem-
ory as compared to the situation where the data do not fit in memory. Show
how this fact can explain the phenomenon of superlinear speedup, where an
application sees aspeedup greaterthan the amount of resources allocated to
it.
20.10 What is the key distinction between homogeneous and federated distributed
databasesystems?
20.11 Why might a client choose to subscribe only to the basic infrastructure-as-a-
servicemodelratherthantotheservicesofferedbyothercloudservicemod-
els?
20.12 Whydocloud-computingservicessupporttraditionaldatabasesystemsbestby
using a virtual machine, instead of running directly on the service provider’s
actualmachine,assumingthatdataisonexternalstorage?
Exercises
20.13 Considerabankthathasacollectionofsites,eachrunningadatabasesystem.
Supposetheonlywaythedatabasesinteractisbyelectronictransferofmoney
betweenthemselves,usingpersistentmessaging.Wouldsuchasystemqualify
asadistributeddatabase?Why?
20.14 Assume that a growing enterprise has outgrown its current computer system
andispurchasinganewparallelcomputer.Ifthegrowthhasresultedinmany
moretransactionsperunittime,butthelengthofindividualtransactionshas

--- Page 1029 ---

1000 Chapter20 Database-SystemArchitectures
notchanged,whatmeasureismostrelevant—speedup,batchscaleup,ortrans-
actionscaleup?Why?
20.15 Databasesystemsaretypicallyimplementedasasetofprocesses(orthreads)
accessingsharedmemory.
a. Howisaccesstotheshared-memoryareacontrolled?
b. Istwo-phaselockingappropriateforserializingaccesstothedatastruc-
turesinsharedmemory?Explainyouranswer.
20.16 Isitwisetoallowauserprocesstoaccesstheshared-memoryareaofadatabase
system?Explainyouranswer.
20.17 What are the factors that can work against linear scale up in a transaction
processingsystem?Whichofthefactorsarelikelytobethemostimportantin
each of the following architectures: shared-memory, shared disk, and shared
nothing?
20.18 Memorysystemstodayaredividedintomultiplemodules,eachofwhichcan
be serving a separate request at a given time, in contrast to earlier architec-
tures where there was a single interface to memory. What impact has such a
memoryarchitecturehaveonthenumberofprocessorsthatcanbesupported
inashared-memorysystem?
20.19 Assumewehavedataitemsd ,d ,…,d witheachd protectedbyalockstored
1 2 n i
inmemorylocationM.
i
a. Describe the implementation of lock-X(d) and unlock(d) via the use
i i
ofthetest-and-setinstruction.
b. Describe the implementation of lock-X(d) and unlock(d) via the use
i i
ofthecompare-and-swapinstruction.
20.20 In a shared-nothing system data access from a remote node can be done by
remote procedure calls, or by sending messages. But remote direct memory
access (RDMA) provides a much faster mechanism for such data access. Ex-
plainwhy.
20.21 Supposethatamajordatabasevendoroffersitsdatabasesystem(e.g.,Oracle,
SQL Server DB2) as a cloud service. Where would this fit among the cloud-
servicemodels?Why?
20.22 If an enterprise uses its own ERP application on a cloud service under the
platform-as-a-service model, what restrictions would there be on when that
enterprisemayupgradetheERPsystemtoanewversion?

--- Page 1030 ---

FurtherReading 1001
Further Reading
[Hennessyetal.(2017)]providesanexcellentintroductiontotheareaofcomputerar-
chitecture,includingthetopicsofshared-memoryarchitecturesandcachecoherency,
parallelcomputingarchitectures,andcloudcomputing,whichwecoveredinthischap-
ter. [Gray and Reuter (1993)] provides the classic textbook description of transac-
tion processing, including the architecture of client–server and distributed systems.
[Ozsu and Valduriez (2010)] provides textbook coverage of distributed database sys-
tems.[AbtsandFelderman(2012)]providesanoverviewofdatacenternetworking.
Bibliography
[AbtsandFelderman(2012)] D.AbtsandB.Felderman,“AGuidedTourofDatacenterNet-
working”,CommunicationsoftheACM,Volume55,Number6(2012),pages44–51.
[GrayandReuter(1993)] J.GrayandA.Reuter,TransactionProcessing:ConceptsandTech-
niques,MorganKaufmann(1993).
[Hennessyetal.(2017)] J.L.Hennessy,D.A.Patterson,andD.Goldberg,ComputerArchi-
tecture:AQuantitativeApproach,6thedition,MorganKaufmann(2017).
[OzsuandValduriez(2010)] T.OzsuandP.Valduriez,PrinciplesofDistributedDatabaseSys-
tems,3ndedition,PrenticeHall(2010).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 1032 ---

21
CHAPTER
Parallel and Distributed Storage
AswediscussedinChapter20,parallelismisusedtoprovidespeedup,wherequeries
areexecutedfasterbecausemoreresources,suchasprocessorsanddisks,areprovided.
Parallelism is also used to provide scaleup, where increasing workloads are handled
withoutincreasedresponsetime,viaanincreaseinthedegreeofparallelism.
In this chapter, we discuss techniques for data storage and indexing in parallel
databasesystems.
21.1 Overview
Wefirstdescribe,inSection21.2andSection21.3,howtopartitiondataamongstmulti-
plenodes.Wethendiscuss,inSection21.4,replicationofdataandparallelindexing(in
Section21.5).Ourdescriptionfocusesonshared-nothingparalleldatabasesystems,but
thetechniqueswedescribearealsoapplicabletodistributed databasesystems, where
dataarestoredinageographicallydistributedmanner.
File systems that run on a large number of nodes, called distributed file systems,
are a widely used way to store data in a parallel system. We discuss distributed file
systemsinSection21.6.
Inrecentyearsparalleldatastorageandindexingtechniqueshavebeenextensively
used for storage of nonrelational data, including unstructured text data, and semi-
structureddatainXML,JSON,orotherformats.Suchdataareoftenstoredinparallel
key-valuestores,whichstore dataitemswithanassociatedkey.Thetechniqueswede-
scribeforparallelstorageofrelationaldatacanalsobeusedforkey-valuestoreswhich
are discussed in Section 21.7. We use the term data storage system to refer to both
key-valuestores,andthedatastorageandaccesslayerofparalleldatabasesystems.
QueryprocessinginparallelanddistributeddatabasesisdiscussedinChapter22,
while and transaction processing in parallel and distributed databases is discussed in
Chapter23.
1003

--- Page 1033 ---

1004 Chapter21 ParallelandDistributedStorage
21.2 Data Partitioning
Initssimplestform,I/Oparallelismreferstoreducingthetimerequiredtoretrievedata
fromdiskbypartitioningthedataovermultipledisks.1
At the lowest level, RAID systems allow blocks to be partitioned across multiple
disks,allowingthemtobeaccessedinparallel.Blocksareusuallyallocatedtodifferent
disks in a round-robin fashion, as we saw in Section 12.5. For example, if there are
n disks numbered 0 to n −1, round-robin allocation assigns block i to disk i mod n.
However, the block-level partitioning techniques supported by RAID systems do not
offer any control in terms of which tuples of a relation are stored on which disk or
node.Therefore,paralleldatabasesystemstypicallydonotuseblock-levelpartitioning
andinsteadperformpartitioningattheleveloftuples.
Insystemswithmultiplenodes(computers),eachwithmultipledisks,partitioning
canpotentiallybespecifiedtothelevelofindividualdisks.However,paralleldatabase
systemstypicallyfocusonpartitioningdataacrossnodesandleaveittotheoperating
systemoneachnodetodecideonassigningblockstodiskswithinthenode.
Inaparallelstoragesystem,thetuplesofarelationarepartitioned(divided)among
manynodes,sothateachtupleresidesononenode;suchpartitioningisreferredtoas
horizontalpartitioning.Severalpartitioningstrategieshavebeenproposedforhorizon-
talpartitioning,whichwestudynext.
Wenotethatverticalpartitioning,discussedinSection13.6inthecontextofcolum-
narstorage,isorthogonaltohorizontalpartitioning.(Asanexampleofverticalparti-
tioning,arelationr(A,B,C,D)whereAisaprimarykey,maybeverticallypartitioned
intor(A,B)andr(A,C,D),ifmanyqueriesrequireBvalues,whileC andDvaluesare
large in size and not required for many queries.) Once tuples are horizontally parti-
tioned,theymaybestoredinaverticallypartitionedmannerateachnode.
Wealsonotethatseveraldatabasevendorsusethetermpartitioningtodenotethe
partitioningoftuplesofarelationrintomultiplephysicalrelationsr ,r ,…,r ,where
1 2 n
allthephysicalrelationsr arestoredinasinglenode.Therelationr isnotstored,but
i
treatedasaviewdefinedbythequeryr ∪r ∪…∪r .Suchintra-nodepartitioningofa
1 2 n
relationistypicallyusedtoensurethatfrequentlyaccessedtuplesarestoredseparately
from infrequentlyaccessed tuplesand isdifferentfromhorizontal partitioningacross
nodes.Intra-nodepartitioningisdescribedinmoredetailinSection25.1.4.3.
Intherestofthischapter,aswellasinsubsequent chapters,weusethetermpar-
titioning torefertohorizontalpartitioningacrossmultiplenodes.
21.2.1 Partitioning Strategies
Wepresentthreebasicdata-partitioningstrategies forpartitioningtuples.Assumethat
therearennodes,N ,N ,…,N ,acrosswhichthedataaretobepartitioned.
1 1 n
1Asinearlierchapters,weusethetermdisktorefertopersistentstoragedevices,suchasmagneticharddisksand
solid-statedrives.

--- Page 1034 ---

21.2 DataPartitioning 1005
Range partitioning Range associated
vector Node with the node
Node 1 [–∞, 15)
15
Node 2 [15, 40)
40
75 Node 3 [40, 75)
Node 4 [ 75, +∞]
Figure 21.1 Exampleofrangepartitioningvector.
• Round-robin.Thisstrategy scanstherelationin anyorder andsends theith tuple
fetchedduringthescantonodenumber N .Theround-robinscheme
((i−1)mod n)+1
ensuresanevendistributionoftuplesacrossnodes;thatis,eachnodehasapprox-
imatelythesamenumberoftuplesastheothers.
• Hash partitioning. This declustering strategy designates one or more attributes
from the given relation’s schema as the partitioning attributes. A hash function
ischosenwhoserangeis{1,2,…,n}.Eachtupleoftheoriginalrelationishashed
onthepartitioningattributes.Ifthehashfunctionreturnsi,thenthetupleisplaced
onnodeN.2
i
• Range partitioning. This strategy distributes tuples by assigning contiguous
attribute-value ranges to each node. It chooses a partitioning attribute, A, and a
partitioningvector[v ,v ,…,v ],suchthat,ifi < j,thenv < v.Therelationis
1 2 n−1 i j
partitionedasfollows:Consideratupletsuchthatt[A] = x.Ifx < v ,thentgoes
1
on node N . If x ≥ v , then t goes on node N . If v ≤ x < v , then t goes on
1 n−1 n i i+1
nodeN .
i+1
Figure21.1showsanexampleofarangepartitioningvector.Intheexampleinthe
figure, values less than 15 are mapped to Node 1. Values in the range [15,40), i.e.,
values≥ 15but< 40.aremappedtoNode2;Valuesintherange[40,75), i.e.,values
≥40but<75,aremappedtoNode3,whilevalues> 75aremappedtoNode4.
Wenowconsiderhowpartitioningismaintainedwhenarelationisupdated.
1. Whenatupleisinsertedintoarelation,itissenttotheappropriatenodebased
onthepartitioningstrategy.
2Hash-functiondesignisdiscussedinSection24.5.1.1.

--- Page 1035 ---

1006 Chapter21 ParallelandDistributedStorage
2. Ifatupleisdeleted,itslocationisfirstfoundbasedonthevalueofitspartitioning
attribute(forround-robin,allpartitionsaresearched).Thetupleisthendeleted
fromwhereveritislocated.
3. Ifatupleisupdated,itslocationisnotaffectedifeitherround-robinpartitioning
isusedoriftheupdatedoesnotaffectapartitioningattribute.
However,ifrangepartitioningorhashpartitioningisused,andtheupdateaffects
apartitioningattribute,thelocationofthetuplemaybeaffected.Inthiscase:
a. Theoriginaltupleisdeletedfromtheoriginallocation,and
b. The updated tuple is inserted and sent to the appropriate node based on
thepartitioningstrategyused.
21.2.2 Comparison of Partitioning Techniques
Oncearelationhasbeenpartitionedamongseveralnodes,wecanretrieveitinparallel,
using all the nodes. Similarly, when a relation is being partitioned, it can be written
to multiple nodes in parallel. Thus, the transfer rates for reading or writing an entire
relationaremuchfasterwithI/Oparallelismthanwithoutit.However,readinganentire
relation,or scanning a relation, isonly one kind of accesstodata. Accessto datacan
beclassifiedasfollows:
1. Scanningtheentirerelation.
2. Locatingatupleassociatively(e.g.,employee name=“Campbell”);thesequeries,
calledpointqueries,seektuplesthathaveaspecifiedvalueforaspecificattribute.
3. Locatingalltuplesforwhichthevalueofagivenattributelieswithinaspecified
range(e.g.,10000 < salary < 20000);thesequeriesarecalledrangequeries.
The different partitioning techniques support these types of access at different levels
ofefficiency:
• Round-robin. The scheme is ideally suited for applications that wish to read the
entire relation sequentially for each query. With this scheme, both point queries
and range queries are complicated to process, since each of the n nodes must be
usedforthesearch.
• Hashpartitioning.Thisschemeisbestsuitedforpointqueriesbasedontheparti-
tioningattribute.Forexample,ifarelationispartitionedonthetelephone number
attribute, then we can answer the query “Find the record of the employee with
telephone number=555-3333” byapplyingthepartitioninghash function to555-
3333 and then searching that node. Directing a query to a single node saves the
start-upcostofinitiatingaqueryonmultiplenodesandleavestheothernodesfree
toprocessotherqueries.

--- Page 1036 ---

21.3 DealingwithSkewinPartitioning 1007
Hash partitioning is also useful for sequential scans of the entire relation. If
thehashfunctionisagoodrandomizingfunction,andthepartitioningattributes
form a key of the relation, then the number of tuples in each of the nodes is ap-
proximatelythe same,withoutmuchvariance.Hence,thetimetaken toscan the
relationisapproximately1∕nofthetimerequiredtoscantherelationinasingle
nodesystem.
The scheme, however, is not well suited for point queries on nonpartition-
ingattributes.Hash-basedpartitioningisalsonotwellsuitedforansweringrange
queries,since,typically,hashfunctionsdonotpreserveproximitywithinarange.
Therefore,allthenodesneedtobescannedforrangequeriestobeanswered.
• Range partitioning.Thisschemeiswellsuited forpointandrange querieson the
partitioningattribute.Forpointqueries,wecanconsultthepartitioningvectorto
locatethenodewherethetupleresides.Forrangequeries,weconsultthepartition-
ingvectortofindtherangeofnodesonwhichthetuplesmayreside.Inbothcases,
thesearchnarrowstoexactlythosenodesthatmighthaveanytuplesofinterest.
Anadvantageofthisfeatureisthat,ifthereareonlyafewtuplesinthequeried
range, then the query is typically sent to one node, as opposed to all the nodes.
Sinceothernodescanbeusedtoanswerotherqueries,rangepartitioningresults
inhigherthroughputwhilemaintaininggoodresponsetime.Ontheotherhand,if
therearemanytuplesinthequeriedrange(astherearewhenthequeriedrangeis
a larger fraction of the domain of the relation), many tuples have to be retrieved
fromafewnodes,resultinginanI/Obottleneck(hotspot)atthosenodes.Inthis
exampleofexecutionskew,allprocessingoccursinone—oronlyafew—partitions.
In contrast, hash partitioning and round-robin partitioning would engage all the
nodes for such queries, giving a faster response time for approximately the same
throughput.
The type of partitioning also affects other relational operations, such as joins, as
weshallseeinSection22.3andSection22.4.1.
Thus, the choice of partitioning technique also depends on the operations that
need to be executed. In general, hash partitioning or range partitioning are preferred
toround-robinpartitioning.
Partitioningisimportantforlargerelations.Largedatabasesthatbenefitfrompar-
allel storage often have some small relations. Partitioning is not a good idea for such
small relations, since each node would end up with just a few tuples. Partitioning is
worthwhile only if each node would contain at least a few disk blocks worth of data.
Smallrelationsarebestleftunpartitioned,whilemedium-sizedrelationscouldbepar-
titionedacrosssomeofthenodes,ratherthanacrossallthenodes,inalargesystem.
21.3 Dealing with Skew in Partitioning
When a relationispartitioned (by atechnique otherthan round-robin), theremay be
a skew in the distribution of tuples, with a high percentage of tuples placed in some

--- Page 1037 ---

1008 Chapter21 ParallelandDistributedStorage
partitions and fewer tuples in other partitions. Such an imbalance in the distribution
of data is called data distribution skew. Data distribution skew may be caused by one
oftwofactors.
• Attribute-valueskew,whichreferstothefactthatsomevaluesappearintheparti-
tioningattributesofmanytuples.Allthetupleswiththesamevaluefortheparti-
tioningattributeendupinthesamepartition,resultinginskew.
• Partition skew, which refers to the fact that there may be load imbalance in the
partitioning,evenwhenthereisnoattributeskew.
Attribute-valueskewcanresultinskewedpartitioningregardlessofwhetherrange
partitioningorhashpartitioningisused.Ifthepartitionvectorisnotchosencarefully,
range partitioning may result in partition skew. Partition skew is less likely with hash
partitioningifagoodhashfunctionischosen.
As Section 20.4.2 noted, even a small skew can result in a significantdecrease in
performance.Skewbecomesanincreasingproblemwithahigherdegreeofparallelism.
For example, if a relation of 1000 tuples is divided into 10 parts, and the division is
skewed,thentheremaybesomepartitionsofsizelessthan100andsomepartitionsof
size more than 100; if even one partition happens tobe of size 200, the speedup that
wewould obtain byaccessingthepartitions inparallelisonly5,instead ofthe10 for
whichwewouldhavehoped.Ifthesamerelationhastobepartitionedinto100parts,
apartitionwillhave10tuplesonanaverage.Ifevenonepartitionhas40tuples(which
ispossible,giventhelargenumberofpartitions)thespeedupthatwewouldobtainby
accessingtheminparallelwouldbe25,ratherthan100. Thus,weseethatthelossof
speedupduetoskewincreaseswithparallelism.
Inadditiontoskewinthedistributionoftuples,theremaybeexecutionskeweven
ifthereisnoskewinthedistributionoftuples,ifqueriestendtoaccesssomepartitions
moreoftenthanothers.Forexample,supposearelationispartitionedbythetimestamp
ofthetuples,andmostqueriesrefertorecenttuples;then,evenifallpartitionscontain
thesame numberoftuples,thepartition containingrecenttupleswouldexperiencea
significantlyhigherload.
Intherestofthissection,weconsiderseveralapproachestohandlingskew.
21.3.1 Balanced Range-Partitioning Vectors
Data distribution skew in range partitioning can be avoided by choosing a balanced
range-partitioningvector,whichevenlydistributestuplesacrossallnodes.
A balanced range-partitioning vector can be constructed by sorting, as follows:
Therelationisfirstsortedonthepartitioningattributes.Therelationisthenscannedin
sortedorder.Afterevery1∕noftherelationhasbeenread,thevalueofthepartitioning
attributeofthenexttupleisaddedtothepartitionvector.Here,ndenotesthenumber
ofpartitionstobeconstructed.

--- Page 1038 ---

21.3 DealingwithSkewinPartitioning 1009
ThemaindisadvantageofthismethodistheextraI/Ooverheadincurredindoing
theinitialsort.TheI/Ooverheadforconstructingbalancedrange-partitioningvectors
canbereducedbyusingaprecomputedfrequencytable,orhistogram,oftheattribute
valuesforeachattributeofeachrelation.Figure21.2showsanexampleofahistogram
for an integer-valued attribute that takes values in the range 1 to 25. It is straightfor-
wardtoconstructabalancedrange-partitioningfunctiongivenahistogramonthepar-
titioningattributes. Ahistogram takesuponlyalittlespace,sohistogramson several
differentattributescanbestoredinthesystem catalog.Ifthehistogramisnotstored,
it can be computed approximately by sampling the relation, using only tuples from a
randomlychosensubsetofthediskblocksoftherelation.Usingarandomsampleal-
lowsthehistogramtobe constructed inmuchlesstimethanitwouldtaketosortthe
relation.
The preceding approach for creating range-partitioning vectors addresses data-
distribution skew; extensions to handle execution skew are left as an exercise for the
reader(Exercise21.3).
A drawback of the above approach is that it is static: the partitioning is decided
at some point and is not automatically updated as tuples are inserted, deleted, or up-
dated.Thepartitioningvectorscanberecomputed,andthedatarepartitioned,when-
ever the system detects skew in data distribution. However, the cost of repartitioning
can be quite large, and doing it periodically would introduce a high load which can
affectnormalprocessing.Dynamictechniquesforavoidingskew,whichcanadaptina
continuousandlessdisruptivefashion,arediscussedinSection21.3.2andinSection
21.3.3.
21.3.2 Virtual Node Partitioning
Anotherapproachtominimizingtheeffectofskewistousevirtualnodes.Inthevirtual
nodesapproach,wepretendthereareseveraltimesasmanyvirtualnodesasthenumber
value
ycneuqerf
50
40
30
20
10
1–5 6–10 11–15 16–20 21–25
Figure 21.2 Exampleofhistogram.

--- Page 1039 ---

1010 Chapter21 ParallelandDistributedStorage
ofrealnodes.Anyofthepartitioningtechniquesdescribedearliercanbeused,butto
maptuplesandworktovirtualnodesinsteadoftorealnodes.3
Virtualnodes,inturn,aremappedtorealnodes.Onewaytomapvirtualnodesto
real nodes is round-robin allocation; thus, if there are n real nodes numbered 1 to n,
virtual node i is mapped to real node ((i−1)modn)+1. The idea is that even if one
range had many more tuples than the others because of skew, these tuples would get
split across multiple virtual nodes ranges. Round-robin allocation of virtual nodes to
realnodeswoulddistributetheextraworkamongmultiplerealnodes,sothatonenode
doesnothavetobearalltheburden.
Amoresophisticatedwayofdoingthemappingisbytrackingthenumberoftuples
in each virtual node, and the load (e.g., the number of accesses per second) on each
virtual node. Virtual nodes are then mapped to real nodes in a way that balances the
numberofstoredtuplesaswellastheloadacrosstherealnodes.Thus,data-distribution
skewandexecutionskewcanbeminimized.
The system must then record this mapping and use it to route accesses to the
correctrealnode.Ifvirtualnodesarenumberedbyconsecutiveintegers,thismapping
canbestoredasanarrayvirtual to real map[],withmentries,wheretherearemvirtual
nodes; the ith element of this array stores the real node to which virtual node i is
mapped.
Yetanotherbenefitofthevirtualnodeapproachisthatitallowselasticityofstorage,
thatis,astheloadonthesystemincreasesitispossibletoaddmoreresources(nodes)
tothesystemtohandletheload.Whenanewnodeisadded,someofthevirtualnodes
aremigratedtothenewrealnode,whichcanbedonewithoutaffectinganyoftheother
virtualnodes.Iftheamountofdatamappedtoeachvirtualnodeissmall,themigration
of a virtual node from one node to another can be done relatively fast, minimizing
disruption.
21.3.3 Dynamic Repartitioning
While the virtual-node approach can reduce skew with range partitioning as well as
hashpartitioning,itdoesnotworkverywellifthedatadistributionchangesovertime,
resulting in some virtual nodes having a very large number of tuples, or a very high
execution load. For example, if partitioning was done by timestamps of records, the
last timestamprange would getan increasingnumber ofrecords, asmore recordsare
inserted, while other ranges would not get any new records. Thus, even if the initial
partitioningisbalanced,itcouldbecomeincreasinglyskewedovertime.
Skewcanbedealtwithbyrecomputingthepartitioningschemeentirely.However,
repartitioning the data based on the new partitioning scheme would, in general, be a
veryexpensiveoperation.Intheprecedingexample,wewouldendupmovingasignifi-
cantnumberofrecordsfromeachpartitiontoapartitionthatprecedesitintimestamp
3Thevirtualnodeapproachisalsocalledthevirtualprocessorapproach,atermusedinearliereditionsofthisbook;
sincethetermvirtualprocessorisnowcommonlyusedinadifferentsenseinthecontextofvirtualmachines,wenow
usethetermvirtualnode.

--- Page 1040 ---

21.3 DealingwithSkewinPartitioning 1011
order. When dealing with large amounts of data, such repartitioning would be unrea-
sonablyexpensive.
Dynamic repartitioning can be done in an efficient manner by instead exploiting
thevirtualnodescheme.Thebasicideaistosplitavirtualnodeintotwovirtualnodes
whenithastoomanytuples,ortoomuchload;theideaisverysimilartoaB+-treenode
being split into two nodes when it is overfull. One of the newly created virtual nodes
canthenbemigratedtoadifferentnodetorebalancethedatastoredateachnode,or
theloadateachnode.
Considering the preceding example, if the virtual node corresponding to a range
oftimestamps2017-01-01 toMaxDateweretobecomeoverfull,thepartitioncouldbe
splitintotwopartitions.Forexample,ifhalfthetuplesinthisrange havetimestamps
lessthan2018-01-01,onepartitionwouldhavetimestampsfrom2017-01-01tolessthan
2018-01-01,andtheotherwouldhavetupleswithtimestampsfrom2018-01-01toMax-
Date. To rebalance the number of tuples in a real node, we would just need to move
oneofthevirtualnodestoanewrealnode.
Dynamic repartitioning in this way is very widely used in parallel databases and
paralleldatastorage systems today. In datastorage systems, the term table referstoa
collection of data items. Tables are partitioned into multiple tablets. The number of
tablets into which a table is divided is much larger than the number of real nodes in
thesystem;thustabletscorrespondtovirtualnodes.
Thesystemneedstomaintainapartitiontable,whichprovidesamappingfromthe
partitioningkeyrangestoatabletidentifier,aswellastherealnodeonwhichthetablet
datareside.Figure21.3showsanexampleofapartitiontable,wherethepartitionkey
is a date. Tablet0 stores records with key value < 2012-01-01. Tablet1 stores records
withkeyvalues≥2012-01-01,but<2013-01-01.Tablet2storesrecordswithkeyvalues
≥2013-01-01,but<2014-01-01,andsoon.Finally,Tablet6storesvalues≥2017-01-01.
Readrequestsmustspecifyavalue forthepartitioningattribute, whichisused to
identifythetabletwhichcouldcontainarecordwiththatkeyvalue;arequestthatdoes
not specify a value for the partitioning attribute would have to be sent to all tablets.
Areadrequestisprocessedbyusingthepartitioningkeyvalue v toidentifythetablet
Value TabletID NodeID
2012-01-01 Tablet0 Node0
2013-01-01 Tablet1 Node1
2014-01-01 Tablet2 Node2
2015-01-01 Tablet3 Node2
2016-01-01 Tablet4 Node0
2017-01-01 Tablet5 Node1
MaxDate Tablet6 Node1
Figure 21.3 Exampleofapartitiontable.

--- Page 1041 ---

1012 Chapter21 ParallelandDistributedStorage
whose range of keys contains v, and then sending the request to the real node where
thetabletresides.Therequestcanbehandledefficientlyatthatnodebymaintaining,
foreachtablet,anindexonthepartitioningkeyattribute.
Write, insert, and delete requests are processed similarly, by routing the requests
tothecorrecttabletandrealnode,usingthemechanismdescribedaboveforreads.
The above scheme allows tablets to be split if they become too big; the key range
correspondingtothetabletissplitintotwo,withanewlycreatedtabletgettinghalfthe
keyrange.Recordswhosekeyrangeismappedtothenewtabletarethenmovedfrom
theoriginaltablettothenewtablet.Thepartitiontable isupdated toreflectthesplit,
sorequestsarethencorrectlydirectedtotheappropriatetablet.
Ifarealnodegetsoverloaded,eitherduetoalargenumberofrequestsorduetotoo
muchdataatthenode,someofthetabletsfromthenodecanbemovedtoadifferent
realnodethathasalowerload.Tabletscanalsobemovedsimilarlyincaseoneofthe
realnodeshasalargeamountofdata,whileanotherrealnodehaslessdata.Finally,if
a new real node joinsa system, some tables can be moved from existing nodes to the
new node. Whenever a tablet is moved to a different real node, the partition table is
updated;subsequentrequestswillthenbesenttothecorrectrealnode.
Figure 21.4 shows the partition table from Figure 21.3 after Tablet6, which had
values≥2017-01-01,hasbeensplitintotwo:Tablet6nowhasvalues≥2017-01-01,but
<2018-01-01,whilethenewtablet,Tablet7,hasvalues≥2018-01-01.Suchasplitcould
be caused by a large number of inserts into Tablet6, making it very large; the split
rebalancesthesizesofthetablets.
Note also that Tablet1, which was in Node1, has now been moved to Node0 in
Figure21.4.SuchatabletmovecouldbebecauseNode1isoverloadedduetoexcessive
data,orduetoahighnumberofrequests.
Mostparalleldatastoragesystemsstorethepartitiontableatamasternode.How-
ever, tosupport alarge number of requests eachsecond,the partition table isusually
replicated, either to all client nodes that access data or to multiple routers. Routers
accept read/write requests from clients and forward the requests to the appropriate
Value TabletID NodeID
2012-01-01 Tablet0 Node0
2013-01-01 Tablet1 Node0
2014-01-01 Tablet2 Node2
2015-01-01 Tablet3 Node2
2016-01-01 Tablet4 Node0
2017-01-01 Tablet5 Node1
2018-01-01 Tablet6 Node1
MaxDate Tablet7 Node1
Figure 21.4 Examplepartitiontableaftertabletsplitandtabletmove.

--- Page 1042 ---

21.4 Replication 1013
real node containing the tablet/virtual nodes based on the key values specified in the
request.
Analternativefullydistributedapproachissupportedbyahashbasedpartitioning
schemecalledconsistenthashing.Intheconsistenthashingapproach,keysarehashed
toalargespace,suchas32bitintegers.Further,node(orvirtualnode)identifiersare
alsohashedtothesamespace.Akeyk couldbelogicallymappedtothenoden whose
i j
hash value h(n) is the highest value among all nodes satisfying h(n) < h(k). But to
j j i
ensurethateverykeyisassignedtoanode,hashvaluesaretreatedaslyingonacycle
similartothefaceofaclock,wherethemaximumhashvaluemaxhashisimmediately
followed by 0. Then, key k is then logicallymapped to the node n whose hash value
i j
h(n) is the closest among all nodes, when we move anti-clockwise in the circle from
j
h(k).
i
Distributed hash tables based on this idea have been developed where there is no
needforeitheramasternodeorarouter;insteadeachparticipatingnodekeepstrack
of a few otherpeer nodes, and routingis implemented in acooperative manner. New
nodes can join the system, and integrate themselves by following specified protocols
in a completely peer-to-peer manner, without the need for a master. See the Further
Readingsectionattheendofthechapterforreferencesprovidingfurtherdetails.
21.4 Replication
Withalargenumberofnodes,theprobabilitythatatleastonenodewillmalfunctionin
aparallelsystemissignificantlygreaterthaninasingle-nodesystem.Apoorlydesigned
parallelsystemwillstopfunctioningifanynodefails.Assumingthattheprobabilityof
failureofasinglenodeissmall,theprobabilityoffailureofthesystemgoesuplinearly
withthenumberofnodes.Forexample,ifasinglenodewouldfailonceevery5years,
asystemwith100nodeswouldhaveafailureevery18days.
Parallel data storage systems must, therefore, be resilientto failure of nodes. Not
onlyshoulddatanotbelostintheeventofanodefailure,butalso,thesystemshould
continuetobeavailable,thatis,continuetofunction,evenduringsuchafailure.
To ensure tuples are not lost on node failure, tuples are replicated across at least
two nodes, and often three nodes. If a node fails, the tuples that it stored can still be
accessedfromtheothernodeswherethetuplesarereplicated.4
Tracking the replicas at the level of individual tuples would result in significant
overheadintermsofstorage andqueryprocessing.Instead, replicationisdoneatthe
levelofpartitions(tablets,nodes,orvirtualnodes).Thatis,eachpartitionisreplicated;
thelocationsofthepartitionreplicasarerecordedaspartofthepartitiontable.
Figure21.5showsapartitiontablewithreplicationoftablets.Eachtabletisrepli-
catedintwonodes.
4Cachingalsoresultsinreplicationofdata,butwiththeaimofspeedingupaccess.Sincedatamaybeevictedfrom
cacheatanytime,cachingdoesnotensureavailabilityintheeventoffailure.

--- Page 1043 ---

1014 Chapter21 ParallelandDistributedStorage
Value TabletID NodeID
2012-01-01 Tablet0 Node0,Node1
2013-01-01 Tablet1 Node0,Node2
2014-01-01 Tablet2 Node2,Node0
2015-01-01 Tablet3 Node2,Node1
2016-01-01 Tablet4 Node0,Node1
2017-01-01 Tablet5 Node1,Node0
2018-01-01 Tablet6 Node1,Node2
MaxDate Tablet7 Node1,Node2
Figure 21.5 PartitiontableofFigure21.4withreplication.
Thedatabasesystemkeepstrackoffailednodes;requestsfordatastoredatafailed
node are automatically routed to the backup nodes that store a replica of the data.
Issues ofhow tohandlethe casewhereone ormorereplicasarestored atacurrently
failednodeareaddressedbrieflyinSection21.4.2,andinmoredetaillater,inSection
23.4.
21.4.1 Location of Replicas
Replicationtotwonodesprovidesprotectionfromdataloss/unavailabilityintheevent
ofsinglenodefailure,whilereplicationtothreenodesprovidesprotectioneveninthe
event of two node failures. If all nodes where a partition is replicated fail, obviously
thereisnowaytopreventdataloss/unavailability.Systemsthatuselow-costcommodity
machines for data storage typically use three-way replication, while systems that use
morereliablemachinestypicallyusetwo-wayreplication.
Therearemultiplepossiblefailuremodesinaparallelsystem.Asinglenodecould
fail due to some internal fault. Further, itispossible forall the nodes ina rackto fail
ifthereissomeproblemwiththeracksuchas,forexample,failureofpowersupplyto
theentirerack,orfailureofthenetworkswitchesinarack,makingallthenodesinthe
rack inaccessible. Further, there is a possibility of failure of an entire data center, for
example,duetofire,flooding,oralarge-scalepowerfailure.
Thelocationofthenodeswherethereplicasofapartitionarestoredmust,there-
fore,bechosencarefully,tomaximizetheprobabilityofatleastonecopybeingacces-
sibleevenduringafailure.Suchreplicationcanbewithinadatacenteroracrossdata
centers.
• Replication within a data center:Since single node failuresarethe most common
failuremode,partitionsareoftenreplicatedtoanothernode.
With the tree-like interconnection topology commonly used in data center net-
works (described in Section 20.4.3) network bandwidth within a rack is much

--- Page 1044 ---

21.4 Replication 1015
higher than the network bandwidth between racks. As a result, replication to an-
othernodewithinthesamerackasthefirstnodereducesnetworkdemandonthe
networkbetweenracks.Buttodealwiththepossibilityofarackfailure,partitions
arealsoreplicatedtoanodeonadifferentrack.
• Replication across data centers: To deal with the possibility of failure of an en-
tire data center, partitions may also be replicated at one or more geographically
separateddatacenters.Geographicseparationisimportanttodealwithdisasters
suchasearthquakesorstormsthatmayshutdownalldatacentersinageographic
region.
For many web applications, round-trip delays across a long-distance network
can affect performance significantly, a problem that is increasing with the use
ofAjaxapplicationsthatrequiremultipleroundsof communicationbetweenthe
browserandtheapplication.Todealwiththisproblem,usersareconnectedwith
applicationserversthatareclosesttothemgeographically,anddatareplicationis
done in such a way that one of the replicas is in the same data center as (or at
least,geographicallycloseto)theapplicationserver.
Suppose allthepartitionsatanodeN arereplicatedatasinglenodeN ,andN
1 2 1
fails.Then,nodeN willhavetohandlealltherequeststhatwouldoriginallyhavegone
2
toN ,aswellasrequestsroutedtonodeN .Asaresult,nodeN wouldhavetoperform
1 2 2
twice as much work as other nodes in the system, resulting in execution skew during
failureofnodeN .
1
To avoid this problem, the replicas of partitions residing at a node, say N , are
1
spreadacrossmultipleothernodes.Forexample,considerasystemwith10nodesand
two-wayreplication.SupposenodeN hadoneofthereplicasofpartitionsp through
1 1
p .Then,theotherreplicaofpartitionsp couldbestoredonN ,ofp onN ,andso
9 1 2 2 3
ontop onN .ThenintheeventoffailureofN ,nodesN throughN wouldshare
9 10 1 2 10
theextraworkequally,insteadofburdeningasinglenodewithalltheextrawork.
21.4.2 Updates and Consistency of Replicas
Since each partition is replicated, updates made to tuples in a partition must be per-
formed on all the replicas of the partition. For data that is never updated after it has
beencreated,readscanbeperformedatanyofthereplicas,sinceallofthemwillhave
the same value. If a storage system ensures that all replicas are exclusive-locked and
updatedatomically(using,forexample,thetwo-phasecommitprotocolwhichwewill
seeinSection23.2.1),readsofatuplecanbeperformed(afterobtainingasharedlock)
atanyofthereplicasandwillseethemostrecentversionofthetuple.
Ifdataareupdated,andreplicasarenotupdatedatomically,differentreplicasmay
temporarilyhavedifferentvalues.Thus,areadmayseeadifferentvaluedependingon
whichreplicaitaccesses.Mostapplicationsrequirethatreadrequestsforatuplemust

--- Page 1045 ---

1016 Chapter21 ParallelandDistributedStorage
receivethemostrecentversionofthetuple;updatesthatarebasedonreadinganolder
versioncouldresultinalostupdateproblem.
One way of ensuring that reads get the latest value is to treat one of the replicas
ofeachpartitionasamasterreplica.Allupdatesaresenttothemasterreplicaandare
then propagated to other replicas. Reads are also sent to the master replica, so that
readsgetthelatestversionofanydataitemevenifupdateshavenotyetbeenapplied
totheotherreplicas.
Ifamasterreplicafails,anewmasterisassignedforthatpartition.Itisimportant
toensurethateveryupdateoperationperformedbytheoldmasterhasalsobeenseen
by the new master. Further, the old master may have updated some of the replicas,
butnotall,beforeitfailed;thenewmastermustcompletethetaskofupdatingallthe
replicas.WediscussdetailsinSection23.6.2.
Itisimportanttoknowwhichnodeisthe(current)masterforeachpartition.This
informationcanbestoredalongwiththepartitiontable.Specifically,thepartitiontable
mustrecord,inadditiontotherangeofkeyvaluesassignedtothatpartition,wherethe
replicasofthepartitionarestored,andfurtherwhichreplicaiscurrentlythemaster.
Threesolutionsarecommonlyusedtoupdatereplicas.
• The two-phase commit (2PC) protocol, which ensures that multiple updates per-
formedby atransaction are applied atomicallyacrossmultiple sites, isdescribed
inSection23.2.Thisprotocolcanbeused withreplicastoensurethatanupdate
isperformedatomicallyonallreplicasofatuple.
Weassumefornowthatallreplicasareavailableandcanbeupdated.Issuesof
howtoallowtwo-phasecommittocontinueexecutioninthepresenceoffailures,
whensomereplicasmaynotbereachable,arediscussedinSection23.4.
• Persistentmessagingsystems,describedinSection23.2.3,whichguaranteethata
message is delivered once it is sent. Persistent messaging systems can be used to
update replicas as follows: An update to a tuple is registered as a persistent mes-
sage,senttoallreplicasofthetuple.Oncethemessageisrecorded,thepersistent
messagingsystemensuresitwillbedeliveredtoallreplicas.Thus,allreplicaswill
gettheupdate,eventually;thepropertyisknownaseventualconsistencyofreplicas.
However,theremaybeadelayinmessagedelivery,andduringthattimesome
replicasmayhaveappliedanupdatewhileothershavenot.Toensurethatreadsget
aconsistentversion,readsareperformedonlyatamasterreplica,whereupdates
aremadefirst.(Ifthesitewithamasterreplicaofatuplehasfailed,anotherreplica
cantakeoverasthemasterreplicaafterensuringallpendingpersistentmessages
withupdateshavebeenapplied.)DetailsarepresentedinSection23.6.2.
• Protocolscalledconsensusprotocols,thatallowupdatesofreplicastoproceedeven
in the face of failures, when some replicas may not be reachable, can be used to
manage update of replicas. Unlike the preceding protocols, consensus protocols
canworkevenwithoutadesignatedmasterreplica.Westudyconsensusprotocols
inSection23.8.

--- Page 1046 ---

21.5 ParallelIndexing 1017
21.5 Parallel Indexing
Indicesinaparalleldatastoragesystemcanbedividedintotwokinds:localandglobal
indices. In the following discussion, when virtual node partitioning is used, the term
nodeshouldbeunderstoodtomeanvirtualnode(orequivalently,tablet).
• Alocalindexisanindexbuiltontuplesstoredinaparticularnode;typically,such
anindexwouldbebuiltonallthepartitionsofagivenrelation.Theindexcontents
arestoredonthesamenodeasthedata.
• Aglobalindexisanindexbuiltondatastoredacrossmultiplenodes;aglobalindex
canbeused toefficientlyfindmatchingtuples,regardlessofwherethetuplesare
stored.
Whilethecontentsofaglobalindexcouldbestoredatasinglecentrallocation,
suchaschemewouldresultinpoorscalability;asaresult,thecontentsofaglobal
indexshouldpartitionedacrossmultiplenodes.
A global primary index on a relation is a global index on the attributes on which
thetuplesoftherelationarepartitioned.AglobalindexonpartitioningattributeK is
constructedbymerelycreatinglocalindicesonK oneachpartition.
Aquerythatisintendedtoretrievetupleswithaspecifickeyvaluek1forK canbe
answered by first finding whichpartition could hold the key value k1, and then using
thelocalindexinthatpartitiontofindtherequiredtuples.
Forexample,supposethestudentrelationispartitionedontheattributeID,anda
globalindexistobeconstructedontheattributeID.Allthatisrequiredistoconstruct
alocalindexonIDoneachpartition.Figure21.6(a)showsaglobalprimaryindexon
the student relation, on attribute ID; the local indices are not shown explicitly in the
figure.
AquerythatisintendedtoretrievetupleswithaspecificvalueforID,say557,can
beansweredbyfirstusingthepartitioningfunctiononIDtofirstfindwhichpartition
could contain the specifiedID value 557; the query is then sent to the corresponding
node,whichusesthelocalindexonIDtolocatetherequiredtuples.
NotethatIDistheprimarykeyfortherelationstudent;however,theabovescheme
would work even if the partitioning attribute were not the primary key. The scheme
can be extended to handle range queries, provided the partitioning function is itself
based on ranges of values; a partitioning scheme based on hashing cannot support
rangequeries.
Aglobalsecondaryindexonarelationisaglobalindexwhoseindexattributesdo
notmatchtheattributesonwhichthetuplesarepartitioned.
Suppose the partitioning attributes are K , while the index attributes are K, with
p i
K ≠ K.OneapproachforansweringaselectionqueryonattributesK isasfollows:If
p i i
alocalindexiscreatedonK oneachpartitionoftherelation,thequeryissenttoeach
i

--- Page 1047 ---

1018 Chapter21 ParallelandDistributedStorage
Tablet 1 Tablet 6
001 Zhang Comp. Sci. 102 766 Aoi
123 Shankar Comp. Sci. 32 987 Bourakis
199 Brandt History 80 199 Brandt
765 Brown
Partition Table Tablet 2 Partition Table
231 Chavez Finance 110
445 Peltier Physics 56 Tablet 7
231 456 Levy Physics 46 231 Chavez Chavez
456 Levy
543 Tablet 3 445 Peltier
543 Williams Comp. Sci. 54 557 Sanchez Shankar
557 Sanchez Music 38
765 705 Snow Physics 0
Tablet 8
Tablet 4 123 Shankar
765 Brown Comp. Sci. 58 705 Snow
766 Aoi Elec. Eng. 6 989 Tanaka
987 Bourakis Elec. Eng. 98 543 Williams
989 Tanaka Biology 120 001 Zhang
(a) Primary index on ID (b) Secondary index on name
Figure 21.6 Globalprimaryandsecondaryindicesonstudent relation
partition,andthelocalindexisusedtofindmatchingtuples.Suchanapproachusing
localindicesisveryinefficientifthenumberofpartitionsislarge,sinceeverypartition
hastobequeried,evenifonlyoneorafewpartitionscontainmatchingtuples.
Wenowillustrateanefficientschemeforconstructingaglobalsecondaryindexby
usinganexample.Consideragainthestudent relationpartitionedontheattribute ID,
and suppose a global index is to be constructed on the attribute name. A simple way
to construct such an index is to create a set of (name, ID) tuples, with one tuple per
studenttuple;letuscallthissetoftuplesindex name.Now,theindex nametuplesare
partitionedontheattributename.Alocalindexonnameisthenconstructedoneach
partition of index name.In addition,aglobal indexiscreatedon theID, whichisthe
partitioningattribute. Figure21.6(b) shows a secondaryindexon the student relation
onattributename;localindicesarenotexplicitlyshowninthefigure.
Now,aquerythatneedstoretrievestudentswithagivennamecanbehandledby
firstexaminingthepartitionfunctionofindex nametofindwhichpartitioncouldstore
index nametupleswiththegivenname;thequeryisthensenttothatpartition,which
usesthelocalindexonnametofindthecorrespondingIDvalue.Next,theglobalindex
ontheIDvalueisusedtofindtherequiredtuple.
Note that in the example above, the partitioning attribute ID does not have du-
plicates; hence it suffices to add only the index key name and the attribute ID to the
index name relation. Otherwise, further attributes would have to be added to ensure
tuplescanbeuniquelyidentified,asdescribednext.
In general, given a relation r, which is partitioned on a set of attributes K , if we
p
wishtocreateaglobalsecondaryindexonasetofattributesK,wecreateanewrelation
i
rs,containingthefollowingattributes:
i

--- Page 1048 ---

21.6 DistributedFileSystems 1019
1. K,andK
i p
2. If the partitioning attributes K have duplicates, we would have to add further
p
attributesK ,suchthatK ∪K isakeyfortherelationbeingindexed.
u p u
The relation rs is partitioned on K, and a local index is created on K. In addition, a
i i i
localindexonattributes(K ,K )iscreatedoneachpartitionofrelationr.
p u
Wenowconsiderhowtouseaglobalsecondaryindextoansweraquery.Consider
aquerythatspecifiesaparticularvaluevforK.Thequeryisprocessedasfollows:
i
1. Therelevantpartitionofrsforthevaluevisfoundusingthepartitioningfunction
i
onK.
i
2. UsethelocalindexonK attheabovepartitiontofindtuplesofrs thathavethe
i i
specifiedvaluevforK.
i
3. ThetuplesintheprecedingresultarepartitionedbasedontheK valueandsent
p
tothecorrespondingnodes.
4. At each node, the tuples received from the preceding step are used along with
thelocalindexonr onattributesK ∪K ,tofindmatchingr tuples.
p u
Note that relation rs is basically a materialized view defined as rs = Π (r).
i i K i ,K p ,K u
Wheneverrismodifiedbyinserts,deletions,orupdatestotuples,thematerializedview
rs mustbecorrespondinglyupdated.
i
Notealsothatupdatestoatupleofratsomenodemayresultinupdatestotuples
ofrsatothernodes.Forexample,inFigure21.6,ifthenameofID001isupdatedfrom
i
ZhangtoYang,thetuple(Zhang,001)atTablet8willbeupdatedto(Yang,001);since
both Zhang and Yang belong in the same partition of the secondary index, no other
partition isaffected.On the otherhand, ifthe name is updated from Zhangto Bolin,
thetuple(Zhang,001)willbedeletedfromTablet8andanewentry(Bolin,001)added
toTablet6.
Performingtheaboveupdatestothesecondaryindexaspartofthesametransac-
tionthatupdatesthebaserelationrequiresupdatestobecommittedatomicallyacross
multiple nodes. Two-phase commit, discussed in Section 23.2, can be used for this
task.AlternativesbasedonpersistentmessagingcanalsobeusedasdescribedinSec-
tion 23.2.3, provided it is acceptable for the secondary index to be somewhat out of
date.
21.6 Distributed File Systems
Adistributedfilesystemstoresfilesacrossalargecollectionofmachineswhilegivinga
single-file-systemviewtoclients.Aswithanyfilesystem,thereisasystemoffilenames
anddirectories,whichclientscanusetoidentifyandaccessfiles.Clientsdonotneed
tobotheraboutwherethefilesarestored.

--- Page 1049 ---

1020 Chapter21 ParallelandDistributedStorage
Thegoaloffirst-generationdistributedfilesystemswastoallowclientmachinesto
accessfilesstoredononeormorefileservers.Incontrast,later-generationdistributed
file systems, whichwe focus on, address distribution of file blocks across a very large
numberofnodes.Suchdistributedfilesystemscanstoreverylargeamountsofdataand
support very large numbers of concurrent clients. A landmark system in this context
wastheGoogleFileSystem(GFS),developedintheearly2000s,whichsawwidespread
usewithinGoogle.Theopen-sourceHadoopFileSystem(HDFS)isbasedontheGFS
architectureandisnowverywidelyused.
Distributedfilesystemsaregenerallydesignedtoefficientlystorelargefileswhose
sizes range from tens of megabytes to hundreds of gigabytes or more. However, they
aredesignedtostoremoderatenumbersofsuchfiles,oftheorderofmillions;theyare
typicallynotdesignedtostoresbillionsofdifferentfiles.Incontrast,theparalleldata
storagesystemswehaveseenearlieraredesignedtostoreverylargenumbers(billions
ormore)ofdataitems,whosesizecanrangefromsmall(tensofbytes)tomedium(a
fewmegabytes).
Asinparalleldatastoragesystems,thedatainadistributedfilesystemarestored
across a number of nodes. Since files can be much larger than data items in a data
storagesystem,filesarebrokenupintomultipleblocks.Theblocksofasinglefilecan
be partitioned across multiple machines. Further, each file block is replicated across
multiple(typicallythree)machines,sothatamachinefailuredoesnotresultinthefile
becominginaccessible.
Filesystemstypicallysupporttwokindsofmetadata:
1. Adirectorysystem,whichallowsahierarchicalorganizationoffilesintodirecto-
riesandsubdirectories,and
2. A mapping from a file name to the sequence of identifiers of blocks that store
theactualdataineachfile.
In the case of a centralized file system, the block identifiers help locate blocks in a
storage device such as a disk. In the case of a distributed file system, in addition to
providingablockidentifier,thefilesystemmustprovidethelocation(nodeidentifier)
where the block is stored; in fact, due to replication, the file system provides a set of
nodeidentifiersalongwitheachblockidentifier.
Intherestofthissection,wedescribetheorganizationoftheHadoopFileSystem
(HDFS),whichisshowninFigure21.7;thearchitectureofHDFSisderivedfromthat
of the Google File System (GFS). The nodes (machines) which store data blocks in
HDFS are called datanodes. Blocks have an associated ID, and datanodes map the
blockIDtoalocationintheirlocalfilesystemwheretheblockisstored.
The file system metadata too can be partitioned across many nodes, but unless
carefullyarchitected,thiscouldleadtobadperformance.GFSandHDFStookasim-
plerandmorepragmaticapproachofstoringthefilesystemmetadataatasinglenode,
calledthenamenodeinHDFS.

--- Page 1050 ---

21.6 DistributedFileSystems 1021
NameNode
Metadata (name, replicas, ...)
Metadata Ops
BackupNode
Metadata (name, replicas, ...)
Client
Block Read
DataNodes
Blocks
Client
Block Write
Replication
Rack 1 Rack 2
Figure 21.7 HadoopDistributedFileSystem(HDFS)architecture
Sinceallmetadatareadshavetogotothenamenode,ifadiskaccesswererequired
to satisfy a metadata read, the number of requests that could be satisfied per second
wouldbeverysmall.Toensureacceptableperformance,HDFSnamenodescachethe
entiremetadatainmemory;thesizeofmemorythenbecomesalimitingfactorinthe
numberoffilesandblocksthatthefilesystemcanmanage.Toreducethememorysize,
HDFS uses very large block sizes (typically 64 MB) to reduce the number of blocks
that the namenode must track for each file. Despite this, the limited amount of main
memoryonmostmachinesconstrainsnamenodestosupportonlyalimitednumberof

--- Page 1051 ---

1022 Chapter21 ParallelandDistributedStorage
files (of the order of millions). However, with main-memory sizes of many gigabytes,
and block sizes of tens of megabytes, an HDFS system can comfortably handle many
petabytesofdata.
Inany system withalarge numberof datanodes,datanode failuresare afrequent
occurrence.Todealwithdatanodefailures,datablocksmustbereplicatedtomultiple
datanodes.Ifadatanodefails,theblockcanstillbereadfromoneoftheotherdatan-
odesthatstoresareplicaoftheblock.Replicationtothreedatanodesiswidelyusedto
providehighavailability,withoutpayingtoohighastorageoverhead.
We now consider how a file open and read request is satisfied with HDFS. First,
the clientcontacts the namenode, with the name of the file. The namenode finds the
list of IDs of blocks containingthe file data and returnsto the clientthe list of block
IDs,alongwiththesetofnodesthatcontainreplicasofeachoftheblocks.Theclient
thencontactsanyoneofthereplicasforeachblockofthefile,sendingittheIDofthe
block,toretrievetheblock.Incasethatparticularreplicadoesnotrespond,theclient
cancontactanyoftheotherreplicas.
To satisfy a write request, the clientfirst contacts the namenode, which allocates
blocks,anddecideswhichdatanodesshouldstorereplicasofeachblock.Themetadata
are recorded at the namenode and sent back to the client. The client then writes the
blocktoallthereplicas.Asanoptimizationtoreducenetworktraffic,HDFSimplemen-
tationsmaychoosetostoretworeplicasinthesamerack;inthatcase,theblockwriteis
performedtoonereplica,whichthencopiesthedatatothesecondreplicaonthesame
rack.Whenallthereplicashaveprocessedthewriteofablock,anacknowledgmentis
senttotheclient.
Replication introduces the problem of consistency of data across the replicas in
case the file is updated. As an example, suppose one of the replicas of a data block
is updated, but due to system failure, another replica does not get updated; then the
systemcouldendupwithinconsistentstatesacrossthereplicas.Andwhatvalueisread
woulddependonwhichreplicaisaccessed,whichisnotanacceptablesituation.
While data storage systems in general need to deal with consistency, using tech-
niquesthatwestudy inChapter23,some distributed filesystems suchasHDFStake
a different approach: namely, not allowing updates. In other words, a file can be ap-
pended to, but data that are written cannot be updated. As each block of the file is
written, the block is copied to the replicas. The file cannot be read until it is closed,
that is, all data have been written to the file, and the blocks have been written suc-
cessfullyatalltheirreplicas.Themodelofwritingdatatoafileissometimesreferred
to as write-once-read-many access model. Others such as GFS allow updates and de-
tect certain inconsistent states caused by failures while writing to replicas; however,
transactional(atomic)updatesarenotsupported.
The restriction that files cannot be updated, but can only be appended to, is not
aproblemformanyapplicationsofadistributedfilesystem.Applicationsthatrequire
updatesshoulduseadata-storagesystem thatsupportsupdatesinsteadofusingadis-
tributedfilesystem.

--- Page 1052 ---

21.7 ParallelKey-ValueStores 1023
21.7 Parallel Key-Value Stores
ManyWebapplicationsneedtostoreverylargenumbers(manybillions)ofrelatively
smallrecords(ofsizerangingfromafewkilobytestoafewmegabytes).Storagewould
have to be distributed across thousands of nodes. Storing such records as files in a
distributed file system is infeasible, since file systems are not designed to store such
large numbers of small files. Ideally, a massively parallel relational database should
be used to store such data. But the parallel relational databases available in the early
2000swerenotdesignedtoworkatamassivescale;nordidtheysupporttheabilityto
easilyaddmorenodestothesystemwithoutcausingsignificantdisruptiontoongoing
activities.
Anumberofparallelkey-valuestoragesystemsweredevelopedtomeettheneedsof
suchwebapplications.Akey-valuestoreprovidesawaytostoreorupdateadataitem
(value) with an associated key and to retrieve the data item with a given key. Some
key-value storestreatthedataitemsasuninterpretedsequencesofbytes,whileothers
allowaschematobeassociatedwiththedataitem.Ifthesystemsupportsdefinitionof
aschemafordataitems,itispossibleforthesystemtocreateandmaintainsecondary
indicesonspecifiedattributesofdataitems.
Key-valuestoressupporttwoverybasicfunctionsontables:put(table,key,value),
usedtostorevalues, withanassociatedkey, inatable,andget(table, key),whichre-
trievesthestoredvalueassociatedwiththespecifiedkey.Inaddition,theymaysupport
otherfunctions,suchasrangequeriesonkeyvalues,usingget(table, key1, key2).
Further,manykey-valuestoressupportsomeformofflexibleschema.
• Some allow column namesto be specified as part of aschemadefinition,similar
torelationaldatastores.
• Othersallowcolumnstobeaddedto,ordeletedfrom,individualtuples;suchkey-
valuestoresaresometimesreferredtoaswide-columnstores.Suchkey-valuestores
supportfunctionssuchasput(table,key,columname,value),tostoreavaluein
aspecificcolumnofarowidentifiedbythekey(creatingthecolumnifitdoesnot
already exist), and get(table, key, columname), which retrieves the value for a
specificcolumnofaspecificrowidentifiedbythekey.Further,delete(table,key,
columname)deletesaspecificcolumnfromarow.
• Yet other key-value stores allow the value stored with a key to have a complex
structure, typically based on JSON; they are sometimes referred to as document
stores.
Theabilitytospecifya(partial)schemaofthestoredvalueallowsthekey-value store
to evaluate selection predicates at the data store; some stores also use the schema to
supportsecondaryindices.
Weusethetermkey-valuestoretoincludealltheabove typesofdatastores;how-
ever, some people use the term key-value store to refer more specifically to those that

--- Page 1053 ---

1024 Chapter21 ParallelandDistributedStorage
do not support any form of schema and treat the value as an uninterpreted sequence
ofbytes.
Parallelkey-valuestorestypicallysupportelasticity,wherebythenumberofnodes
can be increased or decreased incrementally, depending on demand. As nodes are
added,tabletscanbemovedtothenewnodes.Toreducethenumberofnodes,tablets
canbemovedawayfromsomenodes,whichcanthenberemovedfromthesystem.
Widelyusedparallelkey-valuestoresthatsupportflexiblecolumns(alsoknownas
wide-column stores) include Bigtable from Google, Apache HBase, Apache Cassan-
dra (originally developed at Facebook), and Microsoft Azure Table Storage from Mi-
crosoft,amongothers.Key-valuestoresthatsupportaschemaincludeMegastoreand
SpannerfromGoogle,andSherpa/PNUTSfromYahoo!.Key-valuestoresthatsupport
semi-structureddata(alsoknownasdocument-stores)includeCouchbase,DynamoDB
from Amazon, and MongoDB, among others. Redis and Memcached are parallel in-
memorykey-valuestoreswhicharewidelyusedforcachingdata.
Key-valuestoresarenotfull-fledgeddatabases, sincetheydonotprovidemanyof
thefeaturesthatareviewedasstandardondatabasesystems today.Featuresthatkey-
value stores typically do not support include declarative querying (using SQL or any
other declarative query language), support for transactions, and support for efficient
retrieval of records based on selections on nonkey attributes (traditional databases
support suchretrievalusingsecondaryindices).Infact,theytypicallydonotsupport
primary-keyconstraintsforattributesotherthanthekey,anddonotsupportforeign-key
constraints.
21.7.1 Data Representation
Asanexampleofdatamanagementneedsofwebapplications,considertheprofileof
auser,whichneedstobeaccessibletoanumberofdifferentapplicationsthatarerun
byanorganization.Theprofilecontainsavarietyofattributes,andtherearefrequent
additionstotheattributesstoredintheprofile.Someattributesmaycontaincomplex
data.Asimplerelationalrepresentationisoftennotsufficientforsuchcomplexdata.
Many key-value stores support the JavaScript Object Notation (JSON) representa-
tion, which has found increasing acceptance for representing complex data (JSON is
covered in Section 8.1.2). The JSON representation provides flexibility in the set of
attributes that a record contains, as well as the types of these attributes. Yet others,
suchasBigtable,definetheirowndatamodelforcomplexdata,includingsupportfor
recordswithaverylargenumberofoptionalcolumns.
InBigtable,arecordisnotstoredasasinglevaluebutisinsteadsplitintocompo-
nentattributesthatarestoredseparately.Thus,thekeyforanattributevalueconceptu-
ally consists of (record-identifier,attribute-name). Each attribute value isjust astring
as far as Bigtable is concerned. To fetch all attributes of a record, a range query, or
morepreciselyaprefix-matchqueryconsistingofjusttherecordidentifier,isused.The
get()functionreturnstheattributenamesalongwiththevalues.Forefficientretrieval

--- Page 1054 ---

21.7 ParallelKey-ValueStores 1025
of all attributes of a record, the storage system stores entries sorted by the key, so all
attributevaluesofaparticularrecordareclusteredtogether.
In fact, the record identifier can itself be structured hierarchically, although to
Bigtable itself the record identifier is just a string. For example, an application that
storespagesretrievedfromawebcrawlcouldmapaURLoftheform:
www.cs.yale.edu/people/silberschatz.html
totherecordidentifier:
edu.yale.cs.www/people/silberschatz.html
sothatpagesareclusteredinausefulorder.
Data-storagesystemsoftenallowmultipleversionsofdataitemstobestored.Ver-
sionsareoften identifiedbytimestamp,but theymaybe alternativelyidentifiedbyan
integer value that is incremented whenever a new version of a data item is created.
Readscanspecifytherequiredversionofadataitem,ortheycanpicktheversionwith
the highest version number. In Bigtable, for example, a key actually consists of three
parts:(record-identifier,attribute-name,timestamp).
Some key-value stores support columnar storage of rows, with each column of a
rowstoredseparately,withtherowkeyandthecolumnvaluestoredforeachrow.Such
a representation allows a scan to efficiently retrieve a specified column of all rows,
without having to retrieve other columns from storage. In contrast, if rows are stored
in the usual manner, with all column values stored with the row, a sequential scan of
thestoragewouldfetchcolumnsthatarenotrequired,reducingperformance.
Further,somekey-valuestoressupportthenotionofacolumnfamily,whichgroups
setsofcolumnsintoacolumnfamily.Foragivenrow,allthecolumnsinaspecificcol-
umn family are stored together, but columns from other column families are stored
separately. If a set of columns are often retrieved together, storing them as a column
familymayallowmoreefficientretrieval,ascomparedtoeithercolumnarstoragewhere
thesearestoredandretrievedseparately,orarowstorage,whichcouldresultinretriev-
ingunneededcolumnsfromstorage.
21.7.2 Storing and Retrieving Data
In this section, we use the term tablet to refer to partitions, as discussed in Section
21.3.3.Wealsousethetermtabletservertorefertothenodethatactsastheserverfor
a particular tablet; all requests related to a tablet are sent to the tablet server for that
tablet.5.Thetabletserverwouldbeoneofthenodesthathasareplicaofthetabletand
playstheroleofmasterreplicaasdiscussedinSection21.4.1.6
5HBaseusesthetermsregionandregionserverinplaceofthetermstabletandtabletserver
6InBigTableandHBase,replicationishandledbytheunderlyingdistributedfilesystem;tabletdataarestoredinfiles,
andoneofthenodescontainingareplicaofthetabletfilesischosenasthetabletserver.

--- Page 1055 ---

1026 Chapter21 ParallelandDistributedStorage
Weusethetermmastertorefertoasitethatstoresamastercopyofthepartition
information, including, for each tablet, the key ranges for the tablet, the sites storing
the replicas of the tablet, and the current tablet server for that tablet.7 The master is
also responsible for tracking the health of tablet servers; in case a tablet server node
fails,themasterassignsoneoftheothernodesthatcontainsareplicaofthetabletto
actasthenewtabletserverforthattablet.Themasterisalsoresponsibleforreassigning
tabletstobalancetheloadinthesystemifsomenodeisoverloadedorifanewnodeis
addedtothesystem.
Foreachrequestcomingintothesystem,thetabletcorrespondingtothekeymust
be identified, and the request routed to the tablet server. If a single master site were
responsibleforthistask,itwouldgetoverloaded.Instead,theroutingtaskisparallelized
inoneoftwoways:
• Byreplicatingthepartitioninformationtotheclientsites;thekey-valuestoreAPI
usedbyclientslooksupthepartitioninformationcopystoredattheclienttode-
cidewheretoroutearequest.ThisapproachisusedinBigtableandHBase.
• Byreplicatingthepartitioninformationtoasetofroutersites,whichrouterequests
tothesitewiththeappropriatetablet.Requestscanbesenttoanyoneoftherouter
sites,whichforwardtherequesttothecorrecttabletmaster.Thisapproachisused,
forexample,inthePNUTSsystem.
Sincetheremaybeagapbetweenactuallysplittingormovingatabletandupdating
thepartitioninformationatarouter(orclient),thepartition informationmaybeout
of date when the routing decision is made. When the request reaches the identified
tablet master node, the node detects that the tablet has been split, or that the site no
longerstoresa(master)replicaofthetablet.Insuchacase,therequestisreturnedto
the router with an indication that the routing was incorrect; the router then retrieves
up-to-datetabletmappinginformationfromthemasterandreroutestherequesttothe
correctdestination.
Figure 21.8 depicts the architecture of a cloud data-storage system, based loosely
onthePNUTSarchitecture.Othersystemsprovidesimilarfunctionality,althoughtheir
architecturemayvary.Forexample,Bigtable/HBasedonothaveseparaterouters;the
partitioning and tablet-server mapping information is stored in the Google File Sys-
tem/HDFS,andclientsreadtheinformationfromthefilesystemanddecidewhereto
sendtheirrequests.
21.7.2.1 GeographicallyDistributedStorage
Severalkey-valuestoressupportreplicationofdatatogeographicallydistributedloca-
tions;someofthesealsosupportpartitioningofdataacrossgeographicallydistributed
locations,allowingdifferentpartitionstobereplicatedindifferentsetsoflocations.
7ThetermtabletcontrollerisusedbyPNUTStorefertothemastersite.

--- Page 1056 ---

21.7 ParallelKey-ValueStores 1027
Requests Requests Requests Master copy of
partition table/
tablet mapping
Tablet
Routers
controller
Tablets
Tablet servers
Figure 21.8 Architecture ofaclouddatastoragesystem.
One of the key motivations for geographic distribution is fault tolerance, which
allows the system to continue functioning even if an entire data center fails due to a
disastersuchasafireoranearthquake;infact,earthquakescouldcausealldatacenters
inaregiontofail.Asecondkeymotivationistoallowacopyofthedatatoresideata
geographicregionclosetotheuser;requiringdatatobefetchedfromacrosstheworld
couldresultinlatenciesofhundredsofmilliseconds.
A key performance issue with geographical replication of data is that the latency
acrossgeographicalregionsismuchhigherthanthelatencywithinadatacenter.Some
key-value stores neverthelesssupport geographically distributed replication,requiring
transactions to wait for confirmation of updates from remote locations. Other key-
valuestoressupportasynchronousreplicationofupdatestoremotelocations,allowing
a transaction to commit without waiting for confirmation of updates from a remote
location.Thereis,however,ariskoflossofupdatesincaseoffailurebeforetheupdates
are replicated.Some key-value stores allow the application to choose whetherto wait
forconfirmationfromremotelocationsortocommitassoonasupdatesareperformed
locally.
Key-value stores that support geographic replication include Apache Cassandra,
Megastore and Spanner from Google, Windows Azure storage from Microsoft, and
PNUTS/SherpafromYahoo!,amongothers.

--- Page 1057 ---

1028 Chapter21 ParallelandDistributedStorage
21.7.2.2 IndexStructure
The records in each tablet in a key-value store are indexed on the key; range queries
canbeefficientlysupportedbystoringrecordsclusteredonthekey.AB+-treefileorga-
nizationisagoodoption,sinceitsupportsindexingwithclusteredstorageofrecords.
Thewidelyusedkey-valuestoresBigTableandHBasearebuiltontopofdistributed
filesystemsinwhichfilesareimmutable;thatis,filescannotbeupdatedoncetheyare
created.ThusB+-treeindicesorfileorganizationcannotbestoredinimmutablefiles,
sinceB+-treesrequireupdates,whichcannotbedoneonanimmutablefile.
Instead, the BigTable and HBase systems use the stepped-merge variant of the log
structured merge tree (LSM tree), which we saw in Section 14.8.1, and is described in
moredetailinSection24.2.TheLSMtreedoesnotperformupdatesonexistingtrees,
butinsteadcreatesnewtreeseitherusingnewdataorbymergingexistingtrees.Thus,
itisanidealfitforuse ontopofdistributedfilesystems thatonlysupport immutable
files. Asan extra benefit, the LSMtreesupports clustered storage of records,and can
support very high insert and update rates, which has been found very useful in many
applications of key-value stores. Several key-value stores, such as Apache Cassandra
andtheWiredTigerstoragestructureusedbyMongoDB,usetheLSMtreestructure.
21.7.3 Support for Transactions
Most key-value stores offer limited support for transactions. For example, key-value
storestypicallysupportatomicupdatesonasingledataitemandensurethatupdates
onthedataitemareserialized,thatis,runoneaftertheother.Serializabilityatthelevel
ofindividualoperationsisthustriviallysatisfied,sincetheoperationsarerunserially.
Notethatserializabilityattheleveloftransactionsisnotguaranteedbyserialexecution
ofupdatesonindividualdataitems,sinceatransactionmayaccessmorethanonedata
item.
Somekey-valuestores,suchasGoogle’sMegaStoreandSpanner,providefullsup-
port for ACID transactions across multiple nodes. However, most key-value stores do
notsupporttransactionsacrossmultipledataitems.
Some key-value stores provide a test-and-set operation that can help applications
implementlimitedformsofconcurrencycontrol,asweseenext.
21.7.3.1 ConcurrencyControl
Somekey-valuestores,suchastheMegastoreandSpannersystemsfromGoogle,sup-
port concurrency control via locking. Issues in distributed concurrency control are
discussed in Chapter 23. Spanner also supports versioning and database snapshots
based on timestamps. Details of the multiversion concurrency control technique im-
plementedinSpannerarediscussedinSection23.5.1.
However,mostoftheotherkey-valuestores,suchasBigtable,PNUTS/Sherpa,and
MongoDB,supportatomicoperationsonsingledataitems(whichmayhavemultiple
columns,ormaybeJSONdocumentsinMongoDB).

--- Page 1058 ---

21.7 ParallelKey-ValueStores 1029
Some key-value stores, suchas HBase andPNUTS,providean atomictest-and-set
function,whichallowsanupdatetoadataitemtobeconditionalonthecurrentversion
ofthedataitembeingthesameasaspecifiedversionnumber;thecheck(test)andthe
update(set)areperformedatomically.Thisfeaturecanbeusedtoimplementalimited
formofvalidation-basedconcurrencycontrol,asdiscussedinSection23.3.7.
Somedatastoressupportatomicincrementoperationsondataitemsandatomic
execution of stored procedures. For example, HBase supports the incrementColum-
nValue() operation, which atomically reads and increments a column value, and a
checkAndPut() which atomically checks a condition on a data item and updates it
only if the check succeeds. HBase also supports atomic execution of stored proce-
dures, which are called “coprocessors” in HBase terminology. These procedures run
onasingledataitemandareexecutedatomically.
21.7.3.2 AtomicCommit
BigTable, HBase, and PNUTS support atomic commit of multiple updates to a single
row;however,noneofthesesystemssupportsatomicupdatesacrossdifferentrows.
Asone ofthe resultsof theabove limitation,none of these systems supports sec-
ondaryindices;updates toadataitemwould requireupdates tothe secondaryindex,
whichcannotbedoneatomically.
Some systems, such as PNUTS, support secondary indices or materialized views
withdeferredupdates;updatestoadataitemresultinupdatestothesecondaryindex
or materialized view being added to a messaging service to be delivered to the node
where the update needs to be applied. These updates are guaranteed to be delivered
andappliedsubsequently;however,untiltheyareapplied,thesecondaryindexmaybe
inconsistentwiththeunderlyingdata.Viewmaintenanceisalsosupported byPNUTS
in the same deferred fashion. There is no transactional guarantee on the updates of
suchsecondaryindicesormaterializedviews,andonlyabest-effortguaranteeinterms
ofwhentheupdatesreachtheirdestination.Consistencyissueswithdeferredmainte-
nancearediscussedinSection23.6.3.
In contrast, the Megastore and Spanner systems developed by Google support
atomic commit for transactions spanning multiple data items, which can be spread
acrossmultiplenodes.Thesesystemsusetwo-phasecommit(discussedinSection23.2)
toensureatomiccommitacrossmultiplenodes.
21.7.3.3 DealingwithFailures
Ifatabletservernodefails,anothernodethathasacopyofthetabletshouldbeassigned
thetaskofservingthetablet.Themasternodeisresponsiblefordetectingnodefailures
andreassigningtabletservers.
Whenanewnodetakesoverastabletserver,itmustrecoverthestateofthetablet.
Toensurethatupdatestothetabletsurvivenodefailures,updatestoatabletarelogged,
and thelogisitselfreplicated.When asite fails,thetablets atthesite are assigned to

--- Page 1059 ---

1030 Chapter21 ParallelandDistributedStorage
other sites; the new master site of each tablet is responsible for performing recovery
actions using the log to bring its copy of the tablet to an up-to-date state, after which
updatesandreadscanbeperformedonthetablet.
In Bigtable, as an example, mapping information is stored in an index structure,
andtheindex,aswellastheactualtabletdata,arestoredinthefilesystem.Tabletdata
updatesarenotflushedimmediately,butlogdataare.Thefilesystemensuresthatthe
filesystem dataarereplicatedandwillbeavailableeveninthefaceoffailureofafew
nodes in the cluster. Thus, when a tablet is reassigned, the new server for that tablet
hasaccesstoup-to-datelogdata.
Yahoo!’sSherpa/PNUTSsystem,ontheotherhand,explicitlyreplicatestabletsto
multiple nodes in a cluster and uses a persistent messaging system to implement the
log.Thepersistentmessagingsystem replicateslogrecordsatmultiplesitestoensure
availability in the event of a failure. When a new node takes over as the tablet server,
it must apply any pending log records that were generated by the earlier tablet server
beforetakingoverasthetabletserver.
To ensure availability in the face of failures, data must be replicated. As noted in
Section 21.4.2, a key issue with replication is the task of keeping the replicas consis-
tentwitheachother.Differentsystems implementatomicupdate ofreplicasindiffer-
entfashions.GoogleBigTableandApacheHBaseusereplicationfeaturesprovidedby
an underlying file system (GFS for BigTable, and HDFS for HBase), instead of im-
plementing replication on their own. Interestingly, neither GFS nor HDFS supports
atomicupdatesofallreplicasofafile;insteadtheysupportappendstofiles,whichare
copiedtoallreplicasofthefileblocks.Anappendissuccessfulonlywhenithasbeen
applied to all replicas. System failures can result in appends that are applied to only
somereplicas;suchincompleteappendsaredetectedusingsequencenumbersandare
cleanedupwhentheyaredetected.
Some systems such as PNUTS use a persistent messaging service to log updates;
the messaging service guarantees that updates will be delivered to all replicas. Other
systems, such as Google’s Megastore and Spanner, use a technique calleddistributed
consensus to implement consistent replication, as we discuss in Section 23.8. Such
systemsrequireamajorityofreplicastobeavailabletoperformanupdate.Othersys-
tems,suchasApacheCassandraandMongoDB,allowtheusercontroloverhowmany
replicasmust be available to perform an update. Setting the value low could result in
conflicting updates, which must be resolved later. We discuss these issues in Section
23.6.
21.7.4 Managing Without Declarative Queries
Key-value stores do not provide any query processing facility, such as SQL language
support, or even lower-level primitives such as joins. Many applications that use key-
value stores can manage without query language support. The primary mode of data
accessinsuchapplicationsistostoredatawithanassociatedkeyandtoretrievedata

--- Page 1060 ---

21.7 ParallelKey-ValueStores 1031
with that key. In the user profile example, the key for user-profile data would be the
user’sidentifier.
There are applications that require joins but implement the joins either in appli-
cation codeorby aform of viewmaterialization.Forexample, inasocial-networking
application,eachusershouldbeshownnewpostsfromallherfriends,whichconcep-
tuallyrequiresajoin.
One approach to computing the join is to implement it in the application code,
by first finding the set of friends of a given user, and then querying the data object
representingeachfriend,tofindtheirrecentposts.
An alternative approach is as follows: Whenever a user makes a post, for each
friendoftheuseramessageissentto,thedataobjectrepresentingthatfriendandthe
data associated with the friend are updated with a summary of the new post. When
that user checks for updates, all required data are available in one place and can be
retrievedquickly.
Bothapproachescanbeusedwithoutanyunderlyingsupport forjoins.Thereare
trade-offs between the two alternatives such as higher cost at query time for the first
alternativeversushigherstoragecostandhighercostatthetimeofwritesforthesecond
alternative.
21.7.5 Performance Optimizations
Whenusingadatastoragesystem,thephysicallocationofdataaredecidedbythestor-
agesystemandhiddenfromtheclient.Whenstoringmultiplerelationsthatneedtobe
joined,partitioningeachindependentlymaybesuboptimalintermsofcommunication
cost.Forexample,ifthejoinoftworelationsiscomputedfrequently,itmaybebestif
theyarepartitionedinexactlythesameway,ontheirjoinattributes.Aswewillseein
Section22.7.4,doingsowouldallowthejointobecomputedinparallelateachstorage
site,withoutdatatransfer.
Tosupport such scenarios, some datastorage systems allow the schemadesigner
tospecifythattuplesofonerelationshouldbestoredinthesamepartitionsastuples
of another relation that they reference, typically using a foreign key. A typical use of
thisfunctionalityistostorealltuplesrelatedtoaparticularentitytogetherinthesame
partition;thesetofsuchtuplesiscalledanentitygroup.
Further, many data storage systems, such as HBase, support stored functions or
stored procedures. Stored functions/procedures allow clients to invoke a function on
a tuple (or an entity group) and instead of the tuples being fetched and executed lo-
cally, the function is executed at the partition where the tuple is stored. Stored func-
tions/procedures are particularly useful if the stored tuples are large, while the func-
tion/procedureresultsaresmall,reducingdatatransfer.
Manydatastoragesystemsprovidefeaturessuchassupportforautomaticallydelet-
ing old versions of data items after some period of time, or even deleting data items
thatareolderthansomespecifiedperiod.

--- Page 1061 ---

1032 Chapter21 ParallelandDistributedStorage
21.8 Summary
• Parallel databases have gained significant commercial acceptance in the past 20
years.
• Datastorageandindexingaretwoimportantaspectsofparalleldatabasesystems.
• Data partitioning involves the distribution of data among multiple nodes. In I/O
parallelism,relationsarepartitionedamongavailablediskssothattheycanbere-
trievedfaster.Threecommonlyusedpartitioningtechniquesareround-robinpar-
titioning,hashpartitioning,andrangepartitioning.
• Skew is a major problem, especially with increasing degrees of parallelism. Bal-
anced partitioning vectors, using histograms, and virtual node partitioning are
amongthetechniquesusedtoreduceskew.
• Parallel data storage systems must be resilientto failure of nodes. To ensure that
data are not lost on node failure, tuples are replicated across at least two nodes,
andoftenthreenodes.Ifanodefails,thetuplesthatitstoredcanstillbeaccessed
fromtheothernodeswherethetuplesarereplicated.
• Indicesinaparallel datastorage system can be dividedintotwokinds: localand
global. A local index is an index built on tuples stored in a particular node; The
indexcontentsarestoredonthesamenodeasthedata.Aglobalindexisanindex
builtondatastoredacrossmultiplenodes.
• A distributed file system stores files across a large collection of machines, while
givingasingle-file-systemviewtoclients.Aswithanyfilesystem,thereisasystem
of file names and directories, which clients can use to identify and access files.
Clientsdonotneedtobotheraboutwherethefilesarestored.
• Web applications need to store very large numbers (many billions) of relatively
smallrecords(ofsizerangingfromafewkilobytestoafewmegabytes).Anumber
of parallel key-value storage systems were developed to meet the needs of such
webapplications.Akey-value storeprovidesawaytostore orupdate adataitem
(value)withanassociatedkey,andtoretrievethedataitemwithagivenkey.
Review Terms
• Key-valuestores • Partitioningstrategies
• Datastoragesystem ° Round-robin
• I/Oparallelism
° Hashpartitioning
• Datapartitioning
° Rangepartitioning
• Horizontalpartitioning
• Partitioningvector

--- Page 1062 ---

PracticeExercises 1033
• Pointqueries • Routers
• Rangequeries • Consistenthashing
• Skew • Distributedhashtables
° Executionskew • Replication
° Datadistributionskew ° Replicationwithinadatacenter
° Attribute-valueskew ° Replicationacrossdatacenter
° Partitionskew ° Masterreplicas
° Executionskew ° Consistencyofreplicas
• Handlingofskew • Eventualconsistency
° Balancedrange-partitioning • Globalprimaryindex
vector
• Globalsecondaryindex
° Histogram • Distributedfilesystem
° Virtualnodes • Write-once-read-manyaccessmodel
• Elasticityofstorage • Key-valuestore
• Table • Wide-columnstores
• Tablets • Documentstores
• Partitiontable • Columnfamily
• Masternode • Tabletserver
Practice Exercises
21.1 In a range selection on a range-partitioned attribute, it is possible that only
onediskmayneedtobeaccessed.Describethebenefitsanddrawbacksofthis
property.
21.2 Recall that histograms are used for constructing load-balanced range parti-
tions.
a. Supposeyouhaveahistogramwherevaluesarebetween1and100,and
arepartitionedinto10ranges,1–10,11–20,…,91–100,withfrequen-
cies15,5,20,10,10,5,5,20,5,and5,respectively.Giveaload-balanced
rangepartitioningfunctiontodividethevaluesintofivepartitions.
b. Writeanalgorithmforcomputingabalancedrangepartitionwithppar-
titions,givenahistogramoffrequencydistributionscontainingnranges.
21.3 Histograms are traditionally constructed on the values of a specific attribute
(orsetofattributes)ofarelation.Suchhistogramsaregoodforavoidingdata

--- Page 1063 ---

1034 Chapter21 ParallelandDistributedStorage
distributionskewbutarenotveryusefulforavoidingexecutionskew.Explain
why.
Nowsuppose you haveaworkloadofqueriesthatperformpointlookups.
Explainhowyoucanusethequeriesintheworkloadtocomeupwithaparti-
tioningschemethatavoidsexecutionskew.
21.4 Replication:
a. Give two reasons for replicating data across geographically distributed
datacenters.
b. Centralized databases support replication using log records. How is
the replication in centralized databases different from that in paral-
lel/distributeddatabases?
21.5 Parallelindices:
a. Secondary indices in a centralized database store the record identifier.
A global secondary index too could potentially store a partition num-
berholdingtherecord,andarecordidentifierwithinthepartition.Why
wouldthisbeabadidea?
b. Globalsecondaryindicesareimplementedinawaysimilartolocalsec-
ondary indices that are used when records are stored in a B+-tree file
organization.Explainthesimilaritiesbetweenthetwoscenariosthatre-
sultinasimilarimplementationofthesecondaryindices.
21.6 Parallel database systems store replicas of each data item (or partition) on
morethanonenode.
a. Whyisitagoodideatodistributethecopiesofthedataitemsallocated
to a node across multiple other nodes, instead of storing all the copies
inthesamenode(orsetofnodes).
b. What are the benefits and drawbacks of using RAID storage instead of
storinganextracopyofeachdataitem?
21.7 Partitioningandreplication.
a. Explain why range-partitioning gives better control on tablet sizes than
hashpartitioning.ListananalogybetweenthiscaseandthecaseofB+-
treeindicesversushashindices.
b. Somesystemsfirstperformhashingonthekey,andthenuserangepar-
titioningonthehashvalues.Whatcouldbeamotivationforthischoice,
and what are its drawbacks as compared to performing range partition
directiononthekey?
c. It is possible to horizontally partition data, and then perform vertical
partitioning locallyat each node. It is also possible to do the converse,

--- Page 1064 ---

PracticeExercises 1035
whereverticalpartitioningisdonefirst,andtheneachpartitionisthen
horizontallypartitionedindependently.Whatarearethebenefitsofthe
firstoptionoverthesecondone?
21.8 In order to send a request to the master replica of a data item, a node must
knowwhichreplicaisthemasterforthatdataitem.
a. Suppose that between the time the node identifies which node is the
masterreplicaforadataitem,andthetimetherequestreachestheiden-
tifiednode,themastershiphaschanged,andadifferentnodeisnowthe
master.Howcansuchasituationbedealtwith?
b. Whilethemasterreplicacouldbechosenonaper-partitionbasis,some
systems support a per-record master replica, where the records of a par-
tition (or tablet) are replicated at some set of nodes, but each record’s
masterreplicacanbeonanyofthenodesfromwithinthissetofnodes,
independentofthe masterreplicaofotherrecords.Listtwobenefitsof
keepingtrackofmasteronaper-recordbasis.
c. Suggest how to keep track of the master replica for each record, when
therearealargenumberofrecords.
Exercises
21.9 For each of the three partitioning techniques, namely, round-robin, hash par-
titioning, and range partitioning, give an example of a query for which that
partitioningtechniquewouldprovidethefastestresponse.
21.10 Whatfactorscouldresultinskew when arelationispartitioned on one of its
attributesby:
a. Hashpartitioning?
b. Rangepartitioning?
Ineachcase,whatcanbedonetoreducetheskew?
21.11 Whatisthemotivationforstoringrelatedrecordstogetherinakey-valuestore?
Explaintheideausingthenotionofanentitygroup.
21.12 Whyisiteasierfora distributed filesystem such as GFS or HDFSto support
replicationthanitisforakey-valuestore?
21.13 Joinscanbeexpensiveinakey-valuestore,anddifficulttoexpressifthesystem
does not support SQL or a similar declarative query language. What can an
application developer do to efficiently get results of join or aggregate queries
insuchasetting?

--- Page 1065 ---

1036 Chapter21 ParallelandDistributedStorage
Tools
A wide variety of open-source Big Data tools are available, in addition to some com-
mercial tools. In addition, a number of these tools are available on cloud platforms.
GoogleFileSystem(GFS)wasanearlygenerationparallelfilesystem. ApacheHDFS
(hadoop.apache.org) is a widely used distributed file system implementation mod-
eledafterGFS.HDFSbyitselfdoesnotdefineanyinternalformatforfiles,butHadoop
implementations today support several optimized file formats such as Sequence files
(which allow binary data), Avro (which supports semi-structured schemas) and Par-
quet and Orc (which support columnar data representation). Hosted cloud storage
systems include the Amazon S3 storage system (aws.amazon.com/s3) and Google
CloudStorage(cloud.google.com/storage).
Google’s Bigtable was an early generation parallel data storage system, ar-
chitected as a layer on top of GFS. Amazon’s Dynamo is an early generation
parallel key-value store which is based on the idea of consistent hashing, de-
veloped initially for peer-to-peer data storage. Both are available hosted on the
cloud as Google Bigtable (cloud.google.com/bigtable) and Amazon DynamoDB
(aws.amazon.com/dynamodb). Google Spanner (cloud.google.com/spanner) is
a hosted storage system that provides extensive transactional support. Apache
HBase (hbase.apache.org) is a widely used open-source data storage sys-
tem which is based on Bigtable and is implemented as a layer on top of
HDFS. Apache Cassandra (cassandra.apache.org) which was developed at Face-
book, Voldemort (www.project-voldemort.com) developed at LinkedIn, MongoDB
(www.mongodb.com), CouchDB(couchdb.apache.org)and Riak(basho.com) are
all open-source key-value stores. MongoDB and CouchDB use the JSON format for
storing data. Aerospike (www.aerospike.com) is an open-source data storage system
optimized for Flash storage. There are many other open-source parallel data storage
systemsavailabletoday.
CommercialparalleldatabasesystemsincludeTeradata,TeradataAsterData,IBM
Netezza,andPivotalGreenplum.IBMNetezza,PivotalGreenplum,andTeradataAster
Data all use PostgreSQL as the underlying database, running independently on each
node; each of these systems builds a layer on top, to partition data, and parallelize
queryprocessingacrossthenodes.
Further Reading
Inthelate1970sandearly1980s,astherelationalmodelgainedreasonablysoundfoot-
ing,peoplerecognizedthatrelationaloperatorsarehighlyparallelizableandhavegood
dataflowproperties.Severalresearchprojects,includingGAMMA([DeWitt(1990)]),
XPRS([Stonebraker etal.(1988)]), andVolcano([Graefe (1990)]) werelaunchedto
investigatethepracticalityofparallelstorageofdataandparallelexecutionofqueries.
Teradatawasoneofthefirstcommercialshared-nothingparalleldatabasesystems
designed for decision support systems, and it continues to have a large market share.

--- Page 1066 ---

FurtherReading 1037
Teradatasupports partitioningand replicationofdatatodeal withnode failures.The
RedBrickWarehousewasanotherearlyparalleldatabasesystemdesignedfordecision
support(RedBrickwasboughtbyInformix,andlaterIBM).
InformationontheGooglefilesystemcanbefoundin[Ghemawatetal.(2003)],
while the Google Bigtable system is described in [Chang et al. (2008)]. The Yahoo!
PNUTS system is described in [Cooper et al. (2008)], while Google Megastore and
Google Spanner are described in [Baker et al. (2011)] and [Corbett et al. (2013)] re-
spectively. Consistent hashing is described in [Karger et al. (1997)], while Dynamo,
whichisbasedonconsistenthashing,isdescribedin[DeCandiaetal.(2007)].
Bibliography
[Bakeretal.(2011)] J.Baker,C.Bond,J.C.Corbett, J.J.Furman, A.Khorlin, J.Larson,
J.-M.Leon,Y.Li,A.Lloyd,andV.Yushprakh,“Megastore:ProvidingScalable,HighlyAvail-
able Storage for Interactive Services”, In Proceedings of the Conference on Innovative Data
systemResearch(CIDR)(2011),pages223–234.
[Changetal.(2008)] F.Chang,J.Dean,S.Ghemawat,W.C.Hsieh,D.A.Wallach,M.Bur-
rows,T.Chandra,A.Fikes,andR.E.Gruber,“Bigtable:ADistributedStorageSystemfor
StructuredData”,ACMTrans.Comput.Syst.,Volume26,Number2(2008).
[Cooperetal.(2008)] B.F.Cooper,R.Ramakrishnan,U.Srivastava,A.Silberstein,P.Bo-
hannon, H.-A. Jacobsen, N. Puz, D. Weaver, and R. Yerneni, “PNUTS: Yahoo!’s Hosted
DataServingPlatform”,ProceedingsoftheVLDBEndowment,Volume1,Number2(2008),
pages1277–1288.
[Corbettetal.(2013)] J. C. Corbett et al., “Spanner: Google’s Globally Distributed
Database”,ACMTrans.onComputerSystems,Volume31,Number3(2013).
[DeCandiaetal.(2007)] G.DeCandia,D.Hastorun,M.Jampani,G.Kakulapati,A.Laksh-
man,A.Pilchin,S.Sivasubramanian,P.Vosshall,andW.Vogels,“Dynamo:AmazonsHighly
Available Key-value Store”, In Proc. of the ACM Symposium on Operating System Principles
(2007),pages205–220.
[DeWitt(1990)] D. DeWitt, “The Gamma Database Machine Project”, IEEE Transactions
onKnowledgeandDataEngineering,Volume2,Number1(1990),pages44–62.
[Ghemawatetal.(2003)] S.Ghemawat,H.Gobioff,andS.-T.Leung,“TheGoogleFileSys-
tem”,Proc.oftheACMSymposiumonOperatingSystemPrinciples(2003).
[Graefe(1990)] G.Graefe,“EncapsulationofParallelismintheVolcanoQueryProcessing
System”,InProc.oftheACMSIGMODConf.onManagementofData(1990),pages102–111.
[Kargeretal.(1997)] D. Karger, E. Lehman, T. Leighton, R. Panigrahy, M. Levine, and
D.Lewin,“ConsistentHashingandRandomTrees:DistributedCachingProtocolsforRe-
lieving Hot Spots on the World Wide Web”, In Proc. of the ACM Symposium on Theory of
Computing(1997),pages654–663.

--- Page 1067 ---

1038 Chapter21 ParallelandDistributedStorage
[Stonebrakeretal.(1988)] M. Stonebraker, R.H. Katz, D.A. Patterson, andJ. K. Ouster-
hout, “The Design of XPRS”, In Proc. of the International Conf. on Very Large Databases
(1988),pages318–330.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 1068 ---

22
CHAPTER
Parallel and Distributed Query
Processing
In this chapter, we discuss algorithms for query processing in parallel database sys-
tems.Weassumethatthequeriesarereadonly,andourfocusisonqueryprocessingin
decisionsupportsystems.Suchsystemsneedtoexecutequeriesonverylargeamounts
of data, and parallel processing of the query across multiple nodes is critical for pro-
cessingquerieswithinacceptableresponsetimes.
Ourfocusintheearlypartsofthischapterisonrelationalqueryprocessing.How-
ever,laterinthechapter,weexamineissuesinparallelprocessingofqueriesexpressed
inmodelsotherthantherelationalmodel.
Transactionprocessingsystemsexecutelargenumbersofqueriesthatperformup-
dates, but each query affects only a small number of tuples. Parallel execution is key
tohandlelargetransactionprocessingloads;however,thistopiciscoveredinChapter
23.
22.1 Overview
Parallel processing can be exploited in two distinct ways in a database system. One
approach is interquery parallelism, which refers to the execution of multiple queries
in parallel witheachother, acrossmultiple nodes. The second approach isintraquery
parallelism,whichreferstotheprocessingofdifferentpartsoftheexecutionofasingle
query,inparallelacrossmultiplenodes.
Interqueryparallelismisessentialfortransactionprocessingsystems.Transaction
throughputcanbeincreasedbythisformofparallelism.However,theresponsetimes
ofindividualtransactionsarenofasterthantheywouldbeifthetransactionswererun
inisolation.Thus,theprimaryuseofinterqueryparallelismistoscaleupatransaction-
processingsystemtosupportalargernumberoftransactionspersecond.Transaction
processingsystemsareconsideredinChapter23.
Incontrast,intraqueryparallelismisessentialforspeedinguplong-runningqueries,
anditisthefocusofthischapter.
1039

--- Page 1069 ---

1040 Chapter22 ParallelandDistributedQueryProcessing
Execution of a single query involves execution of multiple operations, such as se-
lects,joins, oraggregate operations. The key toexploitinglarge-scaleparallelismisto
processeachoperationinparallel,acrossmultiplenodes.Suchparallelismisreferredto
asintraoperationparallelism.Sincethenumberoftuplesinarelationcanbelarge,the
degreeofintraoperationparallelismisalsopotentiallyverylarge;thus,intraoperation
parallelismisnaturalinadatabasesystem.
Toillustratetheparallelevaluationofaquery,consideraquerythatrequiresarela-
tiontobesorted.Supposethattherelationhasbeenpartitionedacrossmultipledisks
by range partitioning on some attribute, and the sort is requested on the partitioning
attribute.Thesortoperationcanbeimplementedbysortingeachpartitioninparallel,
then concatenatingthesorted partitions togetthefinalsorted relation.Thus, wecan
parallelizeaquerybyparallelizingindividualoperations.
Thereisanothersource ofparallelism inevaluatingaquery: Theoperator treefor
a query can contain multiple operations. We can parallelize the evaluation of the op-
eratortreebyevaluatinginparallelsomeoftheoperationsthatdonotdependonone
another. Further, as Chapter 15 mentions, we may be able to pipeline the output of
one operation to another operation. The two operations can be executed in parallel
on separate nodes, one generating output that is consumed by the other, even as it is
generated. Both these formsofparallelismare examples of interoperation parallelism,
whichallowsdifferentoperatorsofaquerytobeexecutedinparallel.
In summary, the execution of a single query can be parallelized in two different
ways:
• Intraoperation parallelism, which we consider in detail in the next few sections,
where we study parallel implementations of common relational operations such
assort,join,aggregateandotheroperations.
• Interoperationparallelism,whichweconsiderindetailinSection22.5.1.
Thetwoformsofparallelismarecomplementaryandcanbeusedsimultaneously
onaquery.Sincethenumberofoperationsinatypicalqueryissmall,comparedtothe
numberoftuplesprocessedbyeachoperation,intraoperationparallelismcanscalebet-
terwithincreasingparallelism.However,interoperationparallelismisalsoimportant,
especiallyinsharedmemorysystemswithmultiplecores.
To simplify the presentation of the algorithms, we assume a shared nothing ar-
chitecture with n nodes, N ,N ,…,N . Each node may have one or more disks, but
1 2 n
typically the number of such disks is small. We do not address how to partition the
databetweenthedisksatanode;RAIDorganizationscanbeusedwiththesedisksto
exploitparallelismatthestoragelevel,ratherthanatthequeryprocessinglevel.
The choice of algorithms for parallelizing query evaluation depends on the ma-
chinearchitecture.Ratherthanpresentalgorithmsforeacharchitectureseparately,we
useashared-nothingarchitectureinourdescription.Thus,weexplicitlydescribewhen
datahavetobetransferredfromonenodetoanother.

--- Page 1070 ---

22.2 ParallelSort 1041
Wecansimulatethismodeleasilybyusingtheotherarchitectures,sincetransferof
datacanbedoneviasharedmemoryinashared-memoryarchitecture,andviashared
disksinashared-diskarchitecture.Hence,algorithmsforshared-nothingarchitectures
can be used on the other architectures too. In Section 22.6, we discuss how some of
thealgorithmscanbefurtheroptimizedforshared-memorysystems.
Current-generation parallel systems are typically based on a hybrid architecture,
whereeachcomputerhasmultiplecoreswithasharedmemory,andtherearemultiple
computers organized in a shared-nothing fashion. For the purpose of our discussion,
with such an architecture, each core can be considered a node in a shared-nothing
system. Optimizations to exploit the fact that some of the cores share memory with
othercorescanbeperformedasdiscussedinSection22.6.
22.2 Parallel Sort
Supposethatwewishtosortarelationr thatresidesonnnodesN ,N ,…,N .Ifthe
1 2 n
relationhasbeenrange-partitionedontheattributesonwhichitistobesorted,wecan
sorteachpartitionseparatelyandconcatenatetheresultstogetthefullsortedrelation.
Since the tuples are partitioned on n nodes, the time required for reading the entire
relationisreducedbyafactorofnbytheparallelaccess.
If relation r has been partitioned in any other way, we can sort it in one of two
ways:
1. Wecanrange-partitionr onthesortattributes,andthensorteachpartitionsep-
arately.
2. Wecanuseaparallelversionoftheexternalsort-mergealgorithm.
22.2.1 Range-Partitioning Sort
Range-partitioning sort, shown pictorially in Figure 22.1a, works in two steps: first
range-partitioning the relation, then sorting each partition separately. When we sort
byrange-partitioningtherelation,itisnotnecessarytorange-partitiontherelationon
thesamesetofnodesasthoseonwhichthatrelationisstored.Supposethatwechoose
nodesN ,N ,…,N tosorttherelation.Therearetwostepsinvolvedinthisoperation:
1 2 m
1. Redistributethetuplesintherelation,usingarange-partitionstrategy,sothatall
tuples thatliewithintheith range are senttonoden,whichstoresthe relation
i
temporarilyonitslocaldisk.
Toimplementrangepartitioning,inparalleleverynodereadsthetuplesfrom
itsdiskandsendseachtupletoitsdestinationnodebasedonthepartitionfunc-
tion.EachnodeN ,N ,…,N alsoreceivestuplesbelongingtoitspartitionand
1 2 m
storesthemlocally.ThissteprequiresdiskI/Oandnetworkcommunication.

--- Page 1071 ---

1042 Chapter22 ParallelandDistributedQueryProcessing
r r‘ Local Sort r Local Sort Merge r‘
1 1 1 1
r r‘ Local Sort r Local Sort Merge r‘
2 2 2 2
r r‘ Local Sort r Local Sort Merge r‘
3 3 3 3
r n r m ‘ Local Sort r n Local Sort Merge r m ‘
1. Range Partition 2. Local Sort 1. Local Sort 2. Range Partition and Merge
(a) Range Partitioning Sort (b) Parallel External Sort-Merge
Figure 22.1 Parallelsortingalgorithms.
2. Each of the nodes sorts its partition of the relation locally, without interaction
withtheothernodes.Eachnodeexecutesthesameoperation—namely,sorting—
onadifferentdataset.(Executionofthesameoperationinparallelondifferent
setsofdataarecalleddataparallelism.)
Thefinalmergeoperationistrivial,becausetherangepartitioninginthefirst
phaseensuresthat,for1 ≤ i < j ≤ m,thekeyvaluesinnodeN arealllessthan
i
thekeyvaluesinN.
j
Wemustdorangepartitioningwithabalancedrange-partitionvectorsothateach
partitionwillhaveapproximatelythesamenumberoftuples.Wesawhowtocreatesuch
partition vectors in Section 21.3.1. Virtual node partitioning, as discussed in Section
21.3.2, can also be used to reduce skew. Recall that there are several times as many
virtual nodes as real nodes, and virtual node partitioning creates a partition for each
virtual node. Virtual nodes are then mapped to real nodes; doing so in a round-robin
fashiontendstospreadsvirtualnodesacrossrealnodesinawaythatreducesthedegree
ofskewatrealnodes.
22.2.2 Parallel External Sort-Merge
Parallelexternalsort-merge,shownpictoriallyinFigure22.1b,isanalternativetorange
partitioning sort. Suppose that a relation has already been partitioned among nodes
N ,N ,…,N (it does not matter how the relation has been partitioned). Parallel ex-
1 2 n
ternalsort-mergethenworksthisway:
1. EachnodeN sortsthedataavailableatN.
i i
2. The system then merges the sorted runs on each node to get the final sorted
output.

--- Page 1072 ---

22.3 ParallelJoin 1043
The merging of the sorted runs in step 2 can be parallelized by this sequence of
actions:
1. Thesystemrange-partitionsthesortedpartitionsateachnodeN (allbythesame
i
partition vector) across the nodes N ,N ,…,N . It sends the tuples in sorted
1 2 m
order,soeachnodereceivesthetuplesassortedstreams.
2. EachnodeN performsamergeonthestreamsoftuplesastheyarereceivedto
i
getasinglesortedrun.
3. ThesystemconcatenatesthesortedrunsonnodesN ,N ,…,N togetthefinal
1 2 m
result.
Asdescribed,thissequenceofactionsresultsinaninterestingformofexecutionskew,
sinceatfirsteverynodesendsalltuplesofpartition1toN ,theneverynodesendsall
1
tuplesofpartition2toN ,andsoon.Thus,whilesendinghappensinparallel,receiving
2
tuplesbecomessequential:FirstonlyN receivestuples,thenonlyN receivestuples,
1 2
and so on. To avoid this problem, the sorted sequence of tuples S from any node i
i,j
destined to any other node j is broken up into multiple blocks. Each node N sends
i
thefirstblockoftuplesfromS nodeN,foreachj;itthensendsthesecondblockof
i,j j
tuplestoeachnodeN,andsoon,untilallblockshavebeensent.Asaresult,allnodes
j
receive data in parallel. (Note that tuples are sent in blocks, rather than individually,
toreducenetworkoverheads.)
22.3 Parallel Join
Paralleljoinalgorithmsattempttodividethetuplesoftheinputrelationsoverseveral
nodes.Eachnodethencomputespartofthejoinlocally.Then,thesystemcollectsthe
results from each node to produce the final result. How exactly to divide the tuples
dependsonthejoinalgorithm,asweseenext.
22.3.1 Partitioned Join
For certain kinds of joins, it is possible to partition the two input relations across the
nodes and to compute the join locally at each node. The partitioned join technique
canbeusedforinnerjoins,wherethejoinconditionisanequi-join(e.g.,r ⋈ s);
r.A=s.B
the relations r and s are partitioned by the same partitioning function on their join
attributes. Theideaofpartitioningisexactlythesame asthatbehindthepartitioning
step of hash join. Partitioned join can also be used for outer joins, as we shall see
shortly.
Suppose that we are using m nodes to perform the join, and that the relations to
be joined are r and s. Partitioned join then works this way: The system partitions the
relations r and s each into m partitions, denoted r ,r ,…,r and s ,s ,…,s . In a
1 2 m 1 2 m
partitionedjoin,however,therearetwodifferentwaysofpartitioningr ands:

--- Page 1073 ---

1044 Chapter22 ParallelandDistributedQueryProcessing
• Rangepartitioningonthejoinattributes.
• Hashpartitioningonthejoinattributes.
In either case, the same partitioning function must be used for both relations. For
rangepartitioning,thesamepartitionvectormustbeusedforbothrelations.Forhash
partitioning,thesamehashfunctionmustbeusedonbothrelations.Figure22.2depicts
thepartitioninginapartitionedparalleljoin.
Thepartitionedjoinalgorithmfirstpartitionsoneoftherelationsbyscanningits
tuplesandsendingthemtotheappropriate nodebasedon thepartition functionand
thejoinattributevaluesofeachtuple.Specifically,eachnodeN readsinthetuplesof
i
one of the relations, say r, from local disk, computes for each tuple t the partition r
j
to which t belongs, and sends the tuple t to node N. Each node also simultaneously
j
receivestuplesthataresenttoitandstoresthemonitslocaldisk(thiscanbedoneby
havingseparatethreadsforsendingandreceivingdata).Theprocessisrepeatedforall
tuplesfromtheotherrelation,s.
Oncebothrelationsarepartitioned,wecanuseanyjointechniquelocallyateach
node N to compute the join of r and s. Thus, we can use partitioning to parallelize
i i i
anyjointechnique.
Partitioned join can be used not only for inner joins, but also for all three forms
of outer join (left, right and full outer join). Each node computes the corresponding
outerjoinlocally,afterpartitioningisdoneonthejoinattributes.Further,sincenatural
joincanbeexpressedasanequijoinfollowedbyaprojection,naturaljoinscanalsobe
computedusingpartitionedjoin.
Ifoneorbothoftherelationsrandsarealreadypartitionedonthejoinattributes
(by either hash partitioning or range partitioning), the work needed for partitioning
is reduced greatly. If the relations are not partitioned or are partitioned on attributes
otherthanthejoinattributes,thenthetuplesneedtoberepartitioned.
r r΄ s΄ s
1 1 1 1
r r΄ s΄ s
2 2 2 2
r r΄ s΄ s
3 3 3 3
r r΄ s΄ s
n m m n
Step 1: Partition r S tep 2: Partition s
Step 3: Each node N computes r΄ s΄
i i i
Figure 22.2 Partitionedparalleljoin.

--- Page 1074 ---

22.3 ParallelJoin 1045
WenowconsiderissuesspecifictothejointechniqueusedlocallyateachnodeN.
i
The local join operation can be optimizedby performing some initial steps on tuples
as they arrive at a node, instead of first storing the tuples to disk and then reading
them back to perform these initial steps. These optimizations, which we describe be-
low,arealsousedinnonparallelqueryprocessing,whenresultsofanearlieroperation
arepipelinedintoasubsequentoperation;thus,theyarenotspecifictoparallelquery
processing.
• Ifweusehashjoinlocally,theresultantparalleljointechniqueiscalledpartitioned
parallelhashjoin.
Recall that hash join first partitions both input relations into smaller pieces
suchthateachpartitionofthesmallerrelation(thebuildrelation)fitsintomem-
ory. Thus, to implement hash join, the partitions r and s received by node N
i i i
mustberepartitionedusingahashfunction,sayh1().Ifthepartitioningofrands
acrossthenodeswasdonebyusingahashfunctionh0(),thesystemmustensure
thath1() isdifferentfrom h0(). Let the resultant partitions at node N be r and
i i,j
s forj = 1…n,wheren denotesthenumberoflocalpartitionsatnodeN.
i,j i i i
Notethatthetuplescanberepartitionedbasedonthehashfunctionusedfor
the local hash join as they arrive and written out to the appropriate partitions,
avoidingtheneedtowritethetuplestodiskandreadthembackin.
Recall also that hash join then loads each partition of the build relation into
memory,buildsanin-memoryindexonthejoinattributes,andfinallyprobesthe
in-memoryindexusingeachtupleoftheotherrelation,calledtheproberelation.
Assume that relation s is chosen as the build relation. Then each partition s is
i,j
loaded in memory, with an index built on the join attributes, and the index is
probedwitheachtupleofr .
i,j
Hybridhashjoin(describedinSection15.5.5.5)canbeusedincasetheparti-
tionsofoneoftherelationsaresmallenoughthatasignificantpartofthepartition
fitsinmemoryateachnode.Inthiscase,thesmallerrelation,says,whichisused
asthebuildrelation,shouldbepartitionedfirst,followedbythelargerrelation,say
r,whichisusedastheproberelation.Recallthatwithhybridhashjoin,thetuples
inthepartitions ofthebuildrelationsareretainedinmemory,andanin-memory
0
index is built on these tuples. When the probe relation tuples arrive at the node,
theyarealsorepartitioned;tuplesinther partitionareuseddirectlytoprobethe
0
indexonthes tuples,insteadofbeingwrittenouttodiskandreadbackin.
0
• If we use merge join locally, the resultant technique is called partitioned parallel
mergejoin.Eachofthepartitionss andr mustbesorted,andmergedlocally,at
i i
nodeN.
i
Thefirststepofsorting,namely,rungeneration,candirectlyconsumeincom-
ingtuplestogenerateruns,avoidingawritetodiskbeforerungeneration.
• Ifweusenested-loopsorindexednested-loopsjoinlocally,theresultanttechnique
iscalledpartitionedparallelnested-loop join orpartitionedparallel indexednested-

--- Page 1075 ---

1046 Chapter22 ParallelandDistributedQueryProcessing
loops join. Each node N performs a nested-loops (or indexed nested-loops) join
i
ons andr.
i i
22.3.2 Fragment-and-Replicate Join
Partitioningisnotapplicabletoalltypesofjoins.Forinstance,ifthejoinconditionis
aninequality,suchasr ⋈ s,itispossiblethatalltuplesinr joinwithsometuple
r.a<s.b
in s (and vice versa). Thus, there may be no nontrivial way of partitioning r and s so
thattuplesinpartitionr joinwithonlytuplesinpartitions.
i i
We can parallelize such joins by using a technique called fragment-and-replicate.
We first consider a special case of fragment-and-replicate—asymmetric fragment-and-
replicatejoin—whichworksasfollows:
1. Thesystempartitionsoneoftherelations—say,r.Anypartitioningtechniquecan
beusedonr,includinground-robinpartitioning.
2. Thesystemreplicatestheotherrelation,s,acrossallthenodes.
3. NodeN thenlocallycomputesthejoinofr withallofs,usinganyjointechnique.
i i
Theasymmetricfragment-and-replicateschemeappearsinFigure22.3a.Ifrisalready
stored by partitioning, there is no need to partition it further in step 1. All that is
requiredistoreplicatesacrossallnodes.
Theasymmetricfragment-and-replicatejointechniqueisalsoreferredtoasbroad-
cast join. It is a very useful technique, even for equi-joins, if one of the relations, say
s, is small, and the other relation, say r, is large, since replicating the small relation s
acrossallnodesmaybecheaperthanrepartitioningthelargerelationr.
Thegeneralcaseoffragment-and-replicatejoin(alsocalledthesymmetricfragment-
and-replicate join appears in Figure 22.3b; it works this way: The system partitions
relationrintonpartitions,r ,r ,…,r ,andpartitionssintompartitions,s ,s ,…,s .
1 2 n 1 2 m
Asbefore,anypartitioningtechniquemaybeusedonr andons.Thevaluesofmand
n do not need to be equal, but they must be chosen so that there are at least m ∗ n
nodes.Asymmetricfragment-and-replicateissimplyaspecialcaseofgeneralfragment-
and-replicate, where m = 1. Fragment-and-replicate reduces the sizes of the relations
ateachnode,comparedtoasymmetricfragment-and-replicate.
LetthenodesbeN ,N ,…,N ,N ,…,N .NodeN computesthejoinof
1,1 1,2 1,m 2,1 n,m i,j
r withs.ToensurethateachnodeN getsalltuplesofr ands,thesystemreplicates
i j i,j i j
r to nodes N ,N ,…,N (which form a row in Figure 22.3b), and replicates s to
i i,1 i,2 i,m i
nodes N ,N ,…,N (which form a column in Figure 22.3b). Any join technique
1,i 2,i n,i
canbeusedateachnodeN .
i,j
Fragment-and-replicate works with any join condition, since every tuple in r can
betestedwitheverytupleins.Thus,itcanbeusedwherepartitioningcannotbeused.
However,notethateachtupleinrisreplicatedmtimes,andeachtupleinsisreplicated
ntimes.

--- Page 1076 ---

22.3 ParallelJoin 1047
s
s s s s . . . s
1 2 3 4 m
r N r N N N N .
1 1 1 1,1 1,2 1,3 1,4
r N r N N N .
2 2 2 2,1 2,2 2,3
r s
r N r r N N .
2 3 3 3,1 3,2
r N r .
3 4 4
. . .
. . .
. . . .
. . . . .
N
r
n
n,m
(a) Asymmetric (b) Fragment and replicate
fragment and replicate
Figure 22.3 Fragment-and-replicate schemes.
Fragment-and-replicate join has a higher cost than partitioning, since it involves
replication of both relations, and is therefore used only if the join does not involve
equi-join conditions.Asymmetric fragment-and-replicate, on the otherhand, is useful
evenforequi-joinconditions,ifoneoftherelationsissmall,asdiscussedearlier.
Notethatasymmetricfragment-and-replicatejoincanbeusedtocomputetheleft
outer join operation r⟕ s if s is replicated, by simply computing the left outer join
θ
locallyateachnode.Thereisnorestrictiononthejoinconditionθ.
However,r⟕ scannotbecomputedlocallyifsisfragmentedandr isreplicated,
θ
since an r tuple may have no matchingtuple in partition s, but may have a matching
i
tupleinpartitions,j ≠ i.Thus,adecisiononwhetherornottooutputthertuplewith
j
null values for s attributes cannot be made locally at node N. For the same reason,
i
asymmetric fragment-and-replicate cannot be used to compute the full outer join op-
eration, and symmetric fragment-and-replicate cannot be used to compute any of the
outerjoinoperations.
22.3.3 Handling Skew in Parallel Joins
Skewpresentsaspecialproblemforparalleljointechniques.Ifoneofthenodeshasa
muchheavierloadthanothernodes,theparalleljoinoperationwilltakemuchlonger
tofinish,withmanyidlenodeswaitingfortheheavilyloadednodetofinishitstask.

--- Page 1077 ---

1048 Chapter22 ParallelandDistributedQueryProcessing
Whenpartitioningdataforstorage,tominimizeskewinstorageweuseabalanced
partitioning vector that ensures all nodes get the same number of tuples. Forparallel
joins,weneedtoinsteadbalancetheexecutiontimeofjoinoperationsacrossallnodes.
Hash partitioningusinganygood hash function usuallyworksquite wellatbalancing
the load across nodes, unless some join attribute values occur very frequently. Range
partitioning,ontheotherhand,ismorevulnerabletojoinskew,unlesstherangesare
carefullychosentobalancetheload.1
Virtual-nodepartitioningwith,say,round-robindistributionofvirtualnodestoreal
nodes,canhelpinreducingskewatthelevelofrealnodesevenifthereisskewatthe
level of virtual nodes, since the skewed virtual nodes tend toget spread over multiple
realnodes.
Theprecedingtechniquesareexamplesofjoinskewavoidance.Virtual-nodeparti-
tioning,inparticular,isveryeffectiveatskewavoidanceinmostcases.
However, there are cases with high skew, for example where some join attribute
values are very frequent in both input relations, leading to a large join result size. In
suchcases,therecouldbesignificantjoinskew,evenwithvirtual-nodepartitioning.
Dynamic handlingofjoinskewisanalternativetoskewavoidance.Adynamicap-
proachcanbeusedtodetectandhandleskewinsuchsituations.Virtualnodepartition-
ingisused,andthesystemthenmonitorsthejoinprogressateachrealnode.Eachreal
nodeschedulesonevirtualnodeatatime.Supposethatsomerealnodehascompleted
join processing for all virtual nodes assigned to it, and is thus idle, while some other
realnodehasmultiplevirtual nodeswaitingtobe processed.Then,theidlenodecan
getacopyofthedatacorrespondingtooneofthevirtualnodesatthebusynodeand
processthe joinforthatvirtual node.Thisprocesscanbe repeated wheneverthereis
anidlerealnode,aslongassomerealnodehasvirtualnodeswaitingtobeprocessed.
Thistechniqueisanexampleofworkstealing,whereaprocessorthatisidletakes
workthatisinthequeueofanotherprocessorthatisbusy.Workstealingisinexpensive
in a shared-memory system, since all data can be accessed quickly from the shared
memory, as discussed further in Section 22.6. In a shared-nothing environment, data
movementmayberequiredtomoveataskfromoneprocessortoanother,butitisoften
worthpayingtheoverheadtoreducethecompletiontimeofatask.
22.4 Other Operations
Inthissection,wediscussparallelprocessingofotherrelationaloperations,aswellas
parallelprocessingintheMapReduceframework.
1Costestimationshouldbedoneusinghistogramsonjoinattributes.Aheuristicapproximationistoestimatethejoin
costateachnodeN asthesumofthesizesofr ands,andchooserangepartitioningvectorstobalancethesumof
i i i
thesizes.

--- Page 1078 ---

22.4 OtherOperations 1049
22.4.1 Other Relational Operations
Theevaluationofotherrelationaloperationsalsocanbeparallelized:
• Selection.Lettheselectionbeσ (r).Considerfirstthecasewhereθisoftheform
θ
a = v, where a is an attribute and v is a value. If the relation r is partitioned on
i i
a,theselectionproceedsatasinglenode.Ifθisoftheforml ≤ a ≤ u—thatis,
i i
θisarangeselection—andtherelationhasbeenrange-partitionedona,thenthe
i
selectionproceedsateachnodewhosepartitionoverlapswiththespecifiedrange
ofvalues.Inallothercases,theselectionproceedsinparallelatallthenodes.
• Duplicateelimination.Duplicatescanbeeliminatedbysorting;eitheroftheparal-
lelsorttechniquescanbeused,optimizedtoeliminateduplicatesassoonasthey
appearduringsorting.We canalsoparallelizeduplicate eliminationbypartition-
ing the tuples (by either range or hash partitioning) and eliminating duplicates
locallyateachnode.
• Projection. Projection without duplicate elimination can be performed as tuples
are read in from disk in parallel. If duplicates are to be eliminated, either of the
techniquesjustdescribedcanbeused.
• Aggregation.Consideranaggregationoperation.Wecanparallelizetheoperation
by partitioning the relation on the grouping attributes, and then computing the
aggregatevalueslocallyateachnode.Eitherhashpartitioningorrangepartitioning
can be used. If the relation is already partitioned on the grouping attributes, the
firststepcanbeskipped.
We can reduce the cost of transferring tuples during partitioning by partly
computing aggregate values before partitioning, at least for the commonly used
aggregatefunctions.Consideranaggregationoperation onarelationr,usingthe
sum aggregate function on attribute B, with grouping on attribute A. The system
can perform the sum aggregation at each node N on those r tuples stored at N.
i i
This computation results in tuples with partial sums at each node; the result at
N has one tuple for each A value present in r tuples stored at N, with the sum
i i
of the B values of those tuples. The system then partitions the result of the local
aggregation on the grouping attribute A and performs the aggregation again (on
tupleswiththepartialsums)ateachnodeN togetthefinalresult.
i
As a result of this optimization, which is called partial aggregation, fewer tuples
needtobesenttoothernodesduringpartitioning.Thisideacanbeextendedeasily
totheminandmaxaggregatefunctions.Extensionstothecountandavgaggregate
functionsareleftforyoutodoinExercise22.2.
Skewhandlingforaggregationiseasierthanskewhandlingforjoins,sincethecost
of aggregation is directly proportional to the input size. Usually, all that needs to be
doneistouse agoodhashfunctiontoensurethegroup-byattribute valuesareevenly
distributed amongst the participating nodes. However, in some extreme cases, a few

--- Page 1079 ---

1050 Chapter22 ParallelandDistributedQueryProcessing
valuesoccurveryfrequentlyinthegroup-byattributes,andhashingcanleadtouneven
distributionofvalues.Whenapplicable,partialaggregationisveryeffectiveinavoiding
skewinsuchsituations.However,whenpartialaggregationisnotapplicable,skewcan
occurwithaggregation.
Dynamicdetectionandhandlingofsuchskewcanbedoneinsomesuchcases:in
caseanodeisfoundtobeoverloaded,someofthekeyvaluesthatarenotyetprocessed
bythenodecanbereassignedtoanothernode,tobalancetheload.Suchreassignment
is greatly simplified if virtual-node partitioning is used; in that case, if a real node is
found to be overloaded,some virtual nodes assigned to the overloaded real node, but
notyetprocessed,areidentified,andreassignedtootherrealnodes.
Moreinformationonskewhandlingforjoinandotheroperatorsmaybefoundin
theFurtherReadingsectionattheendofthechapter.
22.4.2 Map and Reduce Operations
RecalltheMapReduceparadigm,describedinSection10.3,whichisdesignedtoease
thewritingofparalleldataprocessingprograms.
Recall that the map() function provided by the programmer is invoked on each
inputrecordandemitszeroormoreoutputdataitems,whicharethenpassedontothe
reduce()function.Eachdataitemoutputbyamap()functionconsistsofarecord(key,
value); we shall call the key as the intermediate key. In general, a map() function can
emitmultiplesuchrecordsandsincetherearemanyinputrecords,therearepotentially
manyoutputrecordsoverall.
TheMapReducesystemtakesalltherecordsemittedbythemap()functions,and
groups them such that all records with a particular intermediate key are gathered to-
gether. The reduce() function provided by the programmer is then invoked for each
intermediatekeyanditeratesoveracollectionofallvaluesassociatedwiththatkey.
Notethatthemapfunctioncanbethoughtofasageneralizationoftheprojectop-
eration:bothprocessasinglerecordatatime,butforagiveninputrecordtheproject
operationgeneratesasingleoutputrecord,whereasthemapfunctioncanoutputmul-
tiplerecords(including,asaspecialcase,0records).Unliketheprojectoperation,the
output of a map function is usually intended to become the input of a reduce func-
tion;hence,theoutputofamapfunctionhasanassociatedkeythatservesasagroup
by attribute. Recall that the reduce function takes as input a collection of values and
outputs a result; with most of the reduce functions commonly in use, the result is an
aggregate computed on theinputvalues, and thereducefunction isthen essentiallya
user-definedaggregationfunction.
MapReduce systems are designed for parallel processing of data. A key require-
ment for parallel processing is the ability to parallelize file input and output across
multiple machines; otherwise, the single machine storing the data will become a bot-
tleneck.Parallelizationoffileinputandoutputcanbedonebyusingadistributedfile
system,suchastheHadoopFileSystem(HDFS),discussedinSection21.6,orbyusing
aparallel/distributedstoragesystem,discussedinSection21.7.Recallthatinsuchsys-

--- Page 1080 ---

22.4 OtherOperations 1051
User
Program
copy copy copy
Master
assign assign
map reduce
Part 1 Map 1 Reduce 1 File 1
Part 2
Part 3 Map 2 Reduce 1 write File 2
Part 4
local
write
Part p
read Map n Remote Reduce m File m
Read, Sort
Input file Intermediate Output files
partitions files
Figure 22.4 ParallelprocessingofMapReducejob.
tems,dataarereplicated(copied)acrossseveral(typically3)machines,sothatevenif
afewofthemachinesfail,thedataareavailablefromothermachinesthathavecopies
ofthedatainthefailedmachine.
Conceptually, the map and reduce operations are parallelized in the same way
that the relational operations project and aggregation are parallelized. Each node in
the system hasanumberof concurrentlyexecutingworkers, whichareprocesses that
executemapandreducefunctions.Thenumberofworkersononemachineisoftenset
tomatchthenumberofprocessorcoresonthemachine.
ParallelprocessingofMapReducejobsisshownschematicallyinFigure22.4.As
showninthefigure,MapReducesystems splittheinputdataintomultiplepieces;the
jobofprocessingonesuchpieceiscalledatask.Splittingcanbedoneinunitsoffiles,
and large files can be split into multiple parts. Tasks correspond to virtual nodes in
our terminology, while workers correspond to real nodes. Note that with a multicore
processor(asisstandardtoday),MapReducesystemstypicallyallocateoneworkerper
core.
MapReducesystemsalsohaveascheduler,whichassignstaskstoworkers.2When-
ever a worker completes a task, it is assigned a new task, until all tasks have been
assigned.
Akeystepbetweenthemapandreduceoperationsistherepartitioningofrecords
output by the map step; these records are repartitioned based on their intermediate
(reduce)key,suchthatallrecordswithaparticularkeyareassignedtothesamereducer
task.Thiscouldbedoneeitherbyrange-partitioningonthereducekeyorbycomputing
ahashfunctiononthereducekey.Ineithercase,therecordsaredividedintomultiple
2Theschedulerisrunonadedicatednodecalledthemasternode;thenodesthatperformmap()andreduce()tasks
arecalledslavenodesintheHadoopMapReduceterminology.

--- Page 1081 ---

1052 Chapter22 ParallelandDistributedQueryProcessing
partitions, each of which is called a reduce task. A scheduler assigns reduce tasks to
workers.
Thisstep isidenticaltothe repartitioningdone forparallelizingthe relationalag-
gregationoperation,withrecordspartitionedintoanumberofvirtualnodesbasedon
theirgroup-bykey.
To process the records in a particular reduce task, the records are sorted (or
grouped) by the reduce key, so that all records with the same reduce-key value are
brought together, and then the reduce() is executed on each group of reduce-key val-
ues.
Thereducetasksareexecutedinparallelbytheworkers.Whenaworkercompletes
areducetask,anothertaskisassignedtoit,untilallreducetaskshavebeencompleted.
Areducetaskmayhavemultipledifferentreducekeyvalues,butaparticularcalltothe
reduce() function is for a single reduce key; thus, the reduce() function is called for
eachkeyinthereducetask.
Tasks correspond to virtual nodes in the virtual-node partitioning scheme. There
are far more tasks than there are nodes, and tasks are divided among the nodes. As
discussed in Section 22.3.3, virtual-node partitioning reduces skew. Also note that as
discussed in Section 22.4.1, skew can be reduced by partial aggregation, whichcorre-
spondstocombinersintheMapReduceframework.
Further,MapReduceimplementationstypicallyalsocarryoutdynamicdetection
andhandlingofskew,asdiscussedinSection22.4.1.
Most MapReduce implementations include techniques to ensure that processing
canbecontinuedevenifsomenodesfailduringqueryexecution.Detailsarediscussed
furtherinSection22.5.4.
22.5 Parallel Evaluation of Query Plans
AsdiscussedinSection22.1,therearetwotypesofparallelism:intraoperationandin-
teroperation.Untilnowinthischapter,wehavefocusedonintraoperationparallelism.
Inthissection,weconsiderexecutionplansforqueriescontainingmultipleoperations.
We first consider how to exploit interoperator parallelism. We then consider a
modelofparallelqueryexecutionwhichbreaksparallelqueryprocessingintotwotypes
ofsteps:partitioningofdatausingtheexchangeoperator,andexecutionofoperations
on purely local data, without any data exchange. This model is surprisingly powerful
andiswidelyusedinparalleldatabaseimplementations.
22.5.1 Interoperation Parallelism
Therearetwoformsofinteroperationparallelism:pipelinedparallelismandindepen-
dentparallelism.Wefirstdescribetheseformsofparallelism,assumingeachoperator
runsonasinglenodewithoutintraoperationparallelism.

--- Page 1082 ---

22.5 ParallelEvaluationofQueryPlans 1053
We then describe a modelfor parallel execution based on the exchange operator,
in Section22.5.2. Finally,in Section22.5.3, we describehow acomplete plan can be
executed,combiningalltheformsofparallelism.
22.5.1.1 PipelinedParallelism
Recall from Section 15.7.2 that in pipelining, the output tuples of one operation, A,
are consumed by a second operation, B, even before the first operation has produced
the entire set of tuples in its output. The major advantage of pipelined execution in a
sequential evaluation is that we can carry out a sequence of such operations without
writinganyoftheintermediateresultstodisk.
Parallel systems use pipelining primarily for the same reason that sequential sys-
tems do. However, pipelines are a source of parallelism as well, since it is possible to
run operationsAandB simultaneouslyondifferentnodes(ordifferentcoresofasin-
gle node),sothatB consumestuplesin parallelwithA producingthem.Thisformof
parallelismiscalledpipelinedparallelism.
Pipelinedparallelismisusefulwithasmallnumberofnodes,butitdoesnotscale
upwell.First,pipelinechainsgenerallydonotattainsufficientlengthtoprovideahigh
degree of parallelism. Second, it is not possible to pipeline relational operators that
do not produce output until all inputs have been accessed, such as the set-difference
operation. Third, only marginal speedup is obtained for the frequent cases in which
oneoperator’sexecutioncostismuchhigherthanarethoseoftheothers.
All things considered, when the degree of parallelism is high, pipelining is a less
importantsourceofparallelismthanpartitioning.Therealreasonforusingpipelining
withparallel query processingisthesame reason thatpipeliningisused with sequen-
tialqueryprocessing:namely,thatpipelinedexecutionscanavoidwritingintermediate
resultstodisk.
PipeliningincentralizeddatabaseswasdiscussedinSection15.7.2;asmentioned
there, pipelining can be done using a demand-driven, or pull, model of computation,
or using a producer-driven, or push, model of computation. The pull model is widely
usedincentralizeddatabasesystems.
However, the push model is greatly preferred in parallel database systems, since,
unlikethepullmodel,thepushmodelallowsboththeproducerandconsumertoexe-
cuteinparallel.
Unlike the pull model, the push model requires a buffer that can hold multiple
tuples,betweentheproducerandconsumer;withoutsuchabuffer,theproducerwould
stallassoonasitgeneratesonetuple.Figure22.5showsaproducerandconsumerwith
a buffer in-between. If the producer and consumer are on the same node, as shown
in Figure 22.5a, the buffer can be in shared memory. However, if the producer and
consumer are in different nodes, as shown in Figure 22.5b, there will be two buffers:
one at the producer node to collect tuples as they are produced, and another at the
consumernodetocollectthemastheyaresentacrossthenetwork.

--- Page 1083 ---

1054 Chapter22 ParallelandDistributedQueryProcessing
producer consumer
buffer
(a) Producer-consumer in shared memory
consumer
buffer
network
producer
buffer
(b) Producer-consumer across a network
Figure 22.5 Producerandconsumerwithbuffer.
When sending tuples across a network, it makes sense to collect multiple tuples
and send them as a single batch, rather than send tuples one at a time, since there is
usuallyaverysignificantoverheadpermessage.Batchinggreatlyreducesthisoverhead.
If the producer and consumer are on the same node and can communicate via a
sharedmemorybuffer,mutualexclusionneedstobeensuredwheninsertingtuplesinto,
or fetching tuples from, the buffer. Mutual exclusion protocols have some overhead,
whichcanbereducedbyinserting/retrievingabatchoftuplesatatime,insteadofone
tupleatatime.
Notethatwiththepullmodel,eithertheproducerortheconsumer,butnotboth,
canbeexecutingatagiventime;whilethisavoidsthecontentiononthesharedbuffer
thatariseswiththeuseofthepushmodel,italsopreventstheproducerandconsumer
fromrunningconcurrently.
22.5.1.2 IndependentParallelism
Operationsinaqueryexpressionthatdonotdependononeanothercanbeexecuted
inparallel.Thisformofparallelismiscalledindependentparallelism.
Considerthejoinr ⋈ r ⋈ r ⋈ r .Onepossibleplanistocomputeintermedi-
1 2 3 4
ateresultt ← r ⋈ r inparallelwithintermediateresultt ← r ⋈ r .Neitherof
1 1 2 2 3 4
thesecomputationsdependsoneachother,andhencetheycanbeparallelizedbyinde-
pendentparallelism.Inotherwords,theexecutionofthesetwojoinscanbescheduled
inparallel.

--- Page 1084 ---

22.5 ParallelEvaluationofQueryPlans 1055
Whenthesetwocomputationscomplete,wecancompute:
t ⋈ t
1 2
Note thatcomputation of the above join dependson the resultsof the firsttwojoins,
henceitcannotbedoneusingindependentparallelism.
Likepipelinedparallelism,independentparallelismdoesnotprovideahighdegree
ofparallelismandislessusefulinahighlyparallelsystem,althoughitisusefulwitha
lowerdegreeofparallelism.
22.5.2 The Exchange Operator Model
The Volcano parallel database popularized a model of parallelization called the
exchange-operator model.Theexchangeoperationrepartitionsdatainaspecifiedway;
datainterchangebetweennodesisdoneonlybytheexchangeoperator.Allotheroper-
ationsworkonlocaldata,justastheywouldinacentralizeddatabasesystem;thedata
maybeavailablelocallyeitherbecauseitisalreadypresent,orbecauseoftheexecution
ofaprecedingexchangeoperator.
The exchange operator has two components: a scheme for partitioning outgoing
data,appliedateachsourcenode,andaschemeformergingincomingdata,appliedat
eachdestinationnode.TheoperatorisshownpictoriallyinFigure22.6,withtheparti-
tioningschemedenotedas“Partition,”andthemergingschemedenotedas“Merge.”
Theexchangeoperatorcanpartitiondatainoneofseveralways:
1. Byhashpartitioningonaspecifiedsetofattributes.
2. Byrangepartitioningonaspecifiedsetofattributes.
3. Byreplicatingtheinputdataatallnodes,referredtoasbroadcasting.
4. Bysendingalldatatoasinglenode.
r Partition Merge r‘
1 1
r
Partition Merge
r‘
2 2
r Partition Merge r‘
3 3
r n Partition Merge r m ‘
Figure 22.6 The exchange operatorusedforrepartitioning.

--- Page 1085 ---

1056 Chapter22 ParallelandDistributedQueryProcessing
Broadcasting data to all nodes is required for operations such as the asymmetric
fragment-and-replicate join. Sending all data to a single node is usually done as a fi-
nalstepofparallelqueryprocessing,togetpartitionedresultstogetheratasinglesite.
Notealsothattheinputtotheexchangeoperatorcanbeatasinglesite(referredto
asunpartitioned),oralreadypartitionedacrossmultiplesites.Repartitioningofalready
partitioned data results in each destination node receiving data from multiple source
nodes,asshowninFigure22.6.
Eachdestinationnodemergesthedataitemsreceivedfromthesourcenodes.This
mergestepcanstoredataintheorderreceived(whichmaybenondeterministic,since
it depends on the speeds of the machines and unpredictable network delays); such
mergingiscalledrandommerge.
Ontheotherhand,iftheinputdatafromeachsourceissorted,themergestepcan
exploit the sort order by performing an ordered merge. Suppose, for example, nodes
N ,…,N first sort a relation locally, and then repartition the sorted relation using
1 m
rangepartitioning.Eachnodeperformsanorderedmergeoperationonthetuplesthat
itreceives,togenerateasortedoutputlocally.
Thus,theexchangeoperatorperformsthepartitioningofdataatthesourcenodes,
aswellthemergingofdataatthedestinationnodes.
Alltheparalleloperatorimplementationswehaveseensofarcanbemodeledasa
sequenceofexchangeoperations,andlocaloperators,ateachnode,thatarecompletely
unawareofparallelism.
• Range partitioning sort: can be implemented by an exchange operation that per-
forms range partitioning, with random merge at the destination nodes, followed
byalocalsortoperationateachdestinationnode.
• Parallel external sort-merge: can be implemented by local sorting at the source
nodes,followedbyanexchangeoperationthatperformsrangepartitioning,along
withorderedmerging.
• Partitionedjoin:canbeimplementedbyanexchangeoperationthatperformsthe
desiredpartitioning,followedbylocaljoinateachnode.
• Asymmetricfragment-and-replicatejoin:canbeimplementedbyanexchangeop-
erationthatperformsbroadcast“partitioning”ofthesmallerrelation,followedby
alocaljoinateachnode.
• Symmetricfragment-and-replicatejoin:canbeimplementedbyanexchangeoper-
ation that partitions, and partially broadcasts each partition, followed by a local
joinateachnode.
• Aggregation: can be implemented by an exchange operation that performs hash-
partitioningonthegroupingattributes,followedbyalocalaggregationoperation
at each node. The partial-aggregation optimization simply requires an extra local
aggregationoperationateachnode,beforetheexchangeoperation.

--- Page 1086 ---

22.5 ParallelEvaluationofQueryPlans 1057
Otherrelationaloperationscanbeimplementedsimilarly,byasequenceoflocaloper-
ationsrunninginparallelateachnode,interspersedwithexchangeoperations.
Asnotedearlier,parallelexecutionwheredataarepartitioned,andoperationsare
executedlocallyateachnode,isreferredtoasdataparallelism.Theuseoftheexchange
operatormodeltoimplementdataparallelexecutionhasthemajorbenefitofallowing
existing database query engines to be used at each of the local nodes, without any
significantcodechanges.Asaresult,theexchange-operatormodelofparallelexecution
iswidelyusedinparalleldatabasesystems.
There are, however, some operator implementations that can benefit from being
awareoftheparallelnatureofthesystemtheyarerunningon.Forexample,anindexed
nested-loops join where the inner relation is indexed on a parallel data-store would
requireremoteaccessforeachindexlookup;theindexlookupoperationisthusaware
oftheparallelnatureoftheunderlyingsystem.Similarly,inashared-memorysystemit
maymakesensetohaveahashtableorindexinshared-memory,whichisaccessedby
multipleprocessors(thisapproachisdiscussedbrieflyinSection22.6);theoperations
runningoneachprocessorarethenawareoftheparallelnatureofthesystem.
As we discussed in Section 22.5.1.1, while the demand-driven (or pull) iterator
model for pipelined execution of operators is widely used in centralized database en-
gines,thepushmodelispreferredforparallelexecutionofoperatorsinapipeline.
The exchange operator canbe used toimplementthepush model betweennodes
inaparallelsystem,whileallowingexistingimplementationsoflocaloperatorstorun
using the pull model. To do so, at each source node of an exchange operator, the op-
eratorcanpullmultipletuplesfromitsinputandcreateabatchoftuplesdestinedfor
eachdestinationnode.Theinputmaybecomputedbyalocaloperation,whoseimple-
mentationcanusethedemand-driveniteratormodel.
Theexchangeoperatorthensendsbatchesoftuplestothedestinationnodes,where
theyaremergedandkeptinabuffer.Thelocaloperationscanthenconsumethetuples
inademand-drivenmanner.
22.5.3 Putting It All Together
Figure 22.7 shows a query, along with a sequential and two alternative parallel query
execution plans. The query, shown in Figure 22.7a, computes a join of two relations,
r and s, and then computes an aggregate on the join result. Assume for concreteness
thatthequeryis γ (r ⋈ s).
r.C,s.D sum(s.E) r.A=s.B
Thesequentialplan,shown inFigure22.7b,usesahashjoin(denotedas“HJ”in
the figure), which executes in three separate stages. The first stage partitions the first
input(r)locallyonr.A;thesecondstagepartitionsthesecondinput(s)locallyons.B;
andthethirdstagecomputesthejoinofeachofthecorrespondingpartitionsofrands.
Theaggregateiscomputedusingin-memoryhash-aggregation,denotedbytheoperator
HA; we assume that the number of groups is small enough that the hash table fits in
memory.

--- Page 1087 ---

1058 Chapter22 ParallelandDistributedQueryProcessing
r r Loc.
Part.
γ HJ HA
Loc.
Part.
s s
(a) Logical Query (b) Sequential Plan
r
Loc.
E
1 Part.
HJ E HA E Result
3 4
Loc.
E
s 2 Part.
E 1 : partition on r.A E 2 : partition on s.B
E 3 : partition on (r.C,s.D) E 4 : collect results
(c) Parallel Plan
r
Loc.
E
1 Part.
HJ HA E HA E Result
1 3 2 4
Loc.
E
s 2 Part.
E
1
: partition on r.A E
2
: partition on s.B
E
3
: partition on (r.C,s.D) E
4
: collect results
(d) Parallel Plan with Partial Aggregation
Figure 22.7 Parallelqueryexecutionplans.
Thedashedboxesinthefigureshowwhichstepsruninapipelinedfashion.Inthe
sequential plan,thereadoftherelationr ispipelinedtothefirstpartitioningstage of
the sequential hash join; similarly, the read of relations s is pipelined to the second
partitioningstageofthehashjoin.Thethirdstageofthehashjoinpipelinesitsoutput
tuplestothehashaggregationoperator.
The parallel query evaluation plan, shown in Figure 22.7c, starts with r and s al-
readypartitioned,butnotontherequiredjoinattributes.3Theplan,therefore,usesthe
exchangeoperationE torepartitionrusingattributer.A;similarly,exchangeoperator
1
E repartitionssusings.B.Eachnodethenuseshashjoinlocallytocomputethejoin
2
3Notethemultipleboxesindicatingarelationisstoredinmultiplenodes;similarly,multiplecirclesindicatethatan
operationisexecutedinparallelonmultiplenodes.

--- Page 1088 ---

22.5 ParallelEvaluationofQueryPlans 1059
ofitspartitionofr ands.Notethatthesepartitionsarenotassumedtofitinmemory,
so they must be further partitioned by the first two stages of hash join; this local par-
titioning step is denoted as “Loc. Part.” in the figure. The dashed boxes indicate that
theoutputoftheexchangeoperatorcanbepipelinedtothelocalpartitioningstep.As
in the sequential plan, there are two pipelined stages, one each for r and s. Note that
exchange of tuples across nodes is done only by the exchange operator, and all other
edgesdenotetupleflowswithineachnode.
Subsequently, the hash join algorithm is executed in parallel at all participating
nodes, and its output pipelined to the exchange operator E . This exchange operator
3
repartitions its input on the pair of attributes (r.C,s.D), which are the grouping at-
tributesofthesubsequentaggregation.Atthereceivingendoftheexchangeoperator,
tuplesarepipelinedtothehashaggregationoperator.Notethattheabovestepsallrun
togetherasasinglepipelinedstage,eventhoughthereisanexchangeoperatoraspart
of the stage. Note that the local operators computing hash join and hash aggregate
neednotbeawareoftheparallelexecution.
The results of the aggregates are then collected together at a central location by
thefinalexchangeoperatorE ,tocreatethefinalresultrelation.
4
Figure 22.7d shows an alternative plan that performs partial aggregation on the
resultsofthehashjoin,beforepartitioningtheresults.Thepartialaggregationiscom-
putedlocallyateachnodebytheoperatorHA .Sincenotupleisoutputbythepartial
1
aggregationoperatoruntilallitsinputisconsumed,thepipelinedstage containsonly
thelocalhashjoinandhashaggregationoperators.Thesubsequentexchangeoperator
E whichpartitionsitsinputon(r.C,s.D)ispartofasubsequentpipelinedstagealong
3
with the hash aggregation operation HA which computes the final aggregate values.
2
Asbefore,theexchangeoperatorE collectstheresultsatacentralizedlocation.
4
Theaboveexampleshowshowpipelinedexecutioncanbeperformedacrossnodes,
aswellaswithinnodes,andfurtherhowitcanbedonealongwithintra-operatorparallel
execution. The example also shows that some pipelined stages depend on the output
of earlier pipelined stages; therefore their execution can start only after the previous
stepfinishes.Ontheotherhand,theinitialexchangeandpartitioningofrandsoccur
inpipelinedstagesthatareindependentofeachother;suchindependentstagescanbe
scheduledconcurrently,thatis,atthesametime,ifdesired.
Toexecute a parallel plan such as the one in our example, the differentpipelined
stages have to be scheduled for execution, in an order that ensures inter-stage depen-
denciesaremet.Whenexecutingaparticularstage,thesystemmustdecidehowmany
nodes an operation should be executed on. These decisions are usually made as part
oftheschedulingphase,beforequeryexecutionstarts.
22.5.4 Fault Tolerance in Query Plans
Parallel processing of queries across a moderate number of nodes, for example, hun-
dredsof nodes, can be done withoutworryingabout fault tolerance.Ifafault occurs,
thequeryisrerun,afterremovinganyfailednodesfromthesystem(replicationofdata

--- Page 1089 ---

1060 Chapter22 ParallelandDistributedQueryProcessing
at the storage layer ensures that data continues to be available even in the event of a
failure).However,thissimplesolutiondoesnotworkwellwhenoperatingatthescale
ofthousandsortensofthousandsofnodes:ifaqueryrunsforseveralhours,thereisa
significantchancethat therewillbe a failure whilethe query isbeing executed. Ifthe
queryisrestarted,thereisasignificantchanceofanotherfailurewhileitisexecuting,
whichisobviouslyanundesirablesituation.
Todealwiththisproblem,thequeryprocessingsystemshouldideallyjustbeable
toredotheactionsofafailednode,withoutredoingtherestofthecomputation.
ImplementationsofMapReduce thataredesignedtoworkatamassivelyparallel
scalecanbemadefaulttolerantasfollows:
1. Eachmapoperationexecutedateachnodewritesitsoutputtolocalfiles.
2. Thenextoperation,whichisareduceoperation,executesateachnode;theop-
eration execution at a node reads data from the files stored at multiple nodes,
collects the data, and starts processing the data only after it has got all its re-
quireddata.
3. Thereduceoperationwritesitsoutputtoadistributedfilesystem(ordistributed
storage system) that replicates data, so that the data would be available even in
theeventofafailure.
Letusnowexaminethereasonwhythingsaredoneasabove.First,ifaparticular
mapnodefails,theworkdoneatthatnodecanberedoneatabackupnode;thework
done at other map nodes is not affected. Work is not carried out by reduce nodes
until all the requireddatahas been fetched;the failure of amap node just meansthe
reducenodesfetchdatafromthebackupmapnodes.Thereiscertainlyadelaywhile
thebackupnodedoesitswork,butthereisnoneedtorepeattheentirecomputation.
Further, once a reduce node has finished its work, its output goes to replicated
storage to ensure it is not lost even if a data storage node fails. This means that if a
reducenodefailsbeforeitcompletesitswork,itwillhavetobereexecutedatabackup
node;otherreducenodesarenotaffected.Onceareducenodehasfinisheditswork,
thereisnoneedtoreexecuteit.
Note that it is possible to store the output of a map node in a replicated storage
system.However,thisincreasestheexecutioncostsignificantly,andhencemapoutput
isstoredinlocalstorage,evenattheriskofhavingtoreexecutetheworkdonebyamap
nodeincaseitfailsbeforeallthereducenodeshavefetchedthedatathattheyrequire
fromthatmapnode.
It is also worth noting that sometimesnodes do not completely fail, but run very
slowly;suchnodesarecalledstragglernodes.Evenasinglestragglernodecandelayall
thenodesinthenextstep(ifthereisafollowingstep),ordelaytaskcompletion(ifitisin
thelaststep).Stragglernodescanbedealtwithbytreatingthemsimilartofailednodes,
andreexecutingtheirtasksonothernodes(theoriginaltaskonthestragglernodecan
also be allowed to continue, in case it finishes first). Such reexecution to deal with

--- Page 1090 ---

22.6 QueryProcessingonShared-MemoryArchitectures 1061
stragglers has been found to significantly improve time to completion of MapReduce
tasks.
Whiletheabove schemeforfaulttoleranceisquite effective,thereisanoverhead
that must be noted: a reduce stage cannot perform any work until the previous map
stagehasfinished;4 andifmultiplemapandreducestepsareexecuted,thenextmap
stage cannot perform any work until the preceding reduce stage has finished. In par-
ticular, this means that pipelining of data between stages cannot be supported; data
are always materialized before it is sent to the next stage. Materialization carries a
significantoverhead,whichcanslowdowncomputation.
Apache Spark uses an abstraction called Resilient Distributed Datasets (RDDs) to
implement fault tolerance. As we have seen in Section 10.4.2, RDDs can be viewed
as collections, and Spark supports algebraic operations that take RDDs as input, and
generateRDDsasoutput.SparkkeepstrackoftheoperationsusedtocreateanRDD.
IncaseoffailuresthatresultinlossofanRDD,theoperationsusedtocreatetheRDD
can be reexecuted to regenerate the RDD. However, this may be time-consuming, so
Sparkalsosupportsreplicationtoreducethechanceofdataloss,aswellasstoringof
localcopiesofdatawhenashuffle(exchange)stepisexecuted,toallowreexecutionto
berestrictedtocomputationthatwasperformedonfailednodes.
Therehasbeenagooddealofresearchonhowtoallowpipeliningofdata,whilenot
requiringqueryexecutiontorestartfromthebeginningincaseofasinglefailure.Such
schemestypicallyrequirenodestotrackwhatdatatheyhavereceivedfromeachsource
node.Intheeventofasourcenodefailure,theworkofthesourcenodeisredoneona
backupnode,whichcanresultinsometuplesthatwerereceivedearlierbeingreceived
again. Tracking the data received earlier is important to ensure duplicate tuples are
detected and eliminated by the receiving node. The above ideas can also be used to
implementfaulttoleranceforotheralgebraicoperations,suchasjoins.Inparticular,if
weusetheexchangeoperatorwithdataparallelism,faulttolerancecanbeimplemented
asanextensionoftheexchangeoperator.
References to more information on fault tolerant pipelining based on extensions
of the exchange operator, as well as on fault tolerance schemes used in MapReduce
and in Apache Spark, may be found in the Further Readingsection at the end of the
chapter.
22.6 Query Processing on Shared-Memory Architectures
Parallel algorithms designed for shared-nothing architectures can be used in shared-
memory architectures. Each processor can be treated as having its own partition of
memory, and we can ignore the fact that the processors have a common shared-
4Onceamapnodefinishesitstasks,redistributionofresultsfromthatnodetothereducenodescanstartevenif
othermapnodesarestillactive;buttheactualcomputationatthereducenodecannotstartuntilallmaptaskshave
completedandallmapresultsredistributed.

--- Page 1091 ---

1062 Chapter22 ParallelandDistributedQueryProcessing
memory.However,executioncanbeoptimizedsignificantlybyexploitingthefastaccess
toshared-memoryfromanyoftheprocessors.
Before we study optimizations that exploit shared-memory, we note that while
many large-scale systems can execute on a single shared-memory system, the largest-
scale systems today are typically implemented using a hierarchical architecture, with
a shared-nothing architecture at the outer level, but with each node having a shared-
memory architecture locally, as discussed in Section 20.4.8. The techniques we have
studiedsofarforstoring,indexing,andqueryingdatainshared-nothingarchitectures
areusedtodivideupstorage,indexing,andqueryprocessingtasksamongthedifferent
nodesinthesystem.Eachnodeisashared-memoryparallelsystem,whichusesparallel
query processingtechniquesto execute the query processingtasks assigned to it.The
optimizationswedescribeinthissectioncanthusbeusedlocally,ateachnode.
Parallelprocessinginasharedmemorysystemistypicallydonebyusingthreads,
rather than separate processes. A thread is an execution stream that shares its entire
memory5 with other threads. Multiple threads can be started up, and the operating
systemschedulesthreadsonavailableprocessors.
We list below some optimizations that can be applied when parallel algorithms
thatwesawearlierareexecutedinasharedmemorysystem.
1. If we use asymmetric fragment-and-replicate join, the smaller relation need not
be replicated to each processor. Instead, only one copy needs to be stored in
sharedmemory,whichcanbeaccessedbyalltheprocessors.Thisoptimizationis
particularlyusefuliftherearealargenumberofprocessorsintheshared-memory
system.
2. Skew is a significant problem in parallel systems, and it becomes worse as the
number of processors grows. Handing off work from an overloaded node to an
underloaded node is expensive in a shared-nothing system since it involves net-
worktraffic.Incontrast,inasharedmemorysystem,dataassignedtoaprocessor
canbeeasilyaccessedfromanotherprocessor.
Toaddressskew inashared-memorysystem, agood optionistouse virtual-
nodepartitioning,whichallowsworktoberedistributedinordertobalanceload.
Such redistribution could be done when a processor is found to be overloaded.
Alternatively, whenever a processor finds that it has finished processing all the
virtual nodes assigned to it, it can find other processors that still have virtual
nodes left to be processed, and take over some of those tasks; as mentioned in
Section22.3.3,thisapproachiscalledworkstealing.Notethatsuchanapproach
toavoidingskewwouldbemuchmoreexpensiveinashared-nothingenvironment
since a significant amount of data movement would be involved, unlike in the
shared-memorycase.
5Technically,inoperating-systemterminology,itsaddressspace.

--- Page 1092 ---

22.6 QueryProcessingonShared-MemoryArchitectures 1063
3. Hashjoincanbeexecutedintwodistinctways.
a. The first option is to partition both relations to each processor and then
computethejoinsofthepartitions,inamannersimilartoshared-nothing
hash join. Each partition must be small enough that the hash index on a
build-relationpartitionfitsinthepartofsharedmemoryallocatedtoeach
processor.
b. Thesecondoptionistopartitiontherelationsintofewerpieces,suchthat
thehashindexonabuild-relationpartitionfitsintocommonsharedmem-
ory,ratherthanafractionofthesharedmemory.Theconstructionofthe
in-memory index, as well as probing of the index, must now be done in
parallelbyalltheprocessors.
Parallelizingtheprobephaseisrelativelyeasy,sinceeachprocessorcan
workonsomepartitionoftheproberelation.Infactitmakessensetouse
thevirtualnodeapproachandpartitiontheproberelationintomanysmall
pieces(sometimescalled“morsels”),andhaveprocessorsprocessamorsel
atatime.Whenaprocessorisdonewithamorsel,itfindsanunprocessed
morselandworksonit,untiltherearenomorselslefttobeprocessed.
Parallelizing the construction of the shared hash index is more com-
plicated, since multiple processors may attempt to update the same part
of the hash index. Using locks is an option, but there are overheads due
to locking. Techniques based on lock-free data structures can be used to
constructthehashindexinparallel.
Referencestomoredetailsonhowtoparallelizejoinimplementationsinsharedmem-
orymaybefoundintheFurtherReadingsectionattheendofthechapter.
Algorithms designed for shared-memory systems must take into account the fact
thatintoday’sprocessors,memoryisdividedintomultiplememorybanks, witheach
bank directly linked to some processor. The cost of accessing memory from a given
processor is less if the memory is directly linked to the processor, and is more if it is
linked to a different processor. Such memory systems are said to have a Non-Uniform
MemoryAccessorNUMAarchitecture.
Togetthebestperformance,algorithmsmustbeNUMA-aware;thatis,theymustbe
designedtoensurethatdataaccessedbyathreadrunningonaparticularprocessoris,
asfaraspossible,storedinmemorylocaltothatprocessor.Operatingsystemssupport
thistaskintwoways:
1. Each thread is scheduled, as far as possible, on the same processor core, every
timeitisexecuted.
2. When a thread requests memory from the operating system memory manager,
theoperatingsystemallocatesmemorythatislocaltothatprocessorcore.
Note that the techniques for making the best use of shared memory are comple-
mentary to techniques that make the best use of processor caches, including cache-

--- Page 1093 ---

1064 Chapter22 ParallelandDistributedQueryProcessing
consciousindexstructures(whichwesawinSection14.4.7)andcache-consciousalgo-
rithmsforprocessingrelationaloperators.
But in addition, since each processor core has its own cache, it is possible for a
cachetohavean oldvaluethatwassubsequentlyupdated onanotherprocessorcore.
Thus, query processingalgorithmsthatupdate shared datastructures should be care-
fultoensurethattherearenobugsduetotheuseofoutdatedvalues,andduetorace
conditions on updating the same memory location from two processor cores. Lock-
ing and fence instructions to ensure cache consistency (Section 20.4.5) are used in
combinationtoimplementupdatestoshareddatastructures.
Theformofparallelismwehavestudiedsofarallowseachprocessortoexecuteits
owncodeindependentlyofotherprocessors.However,someparallelsystemssupport
a different form of parallelism, called Single Instruction Multiple Data (SIMD). With
SIMD parallelism, the same instruction is executed on each of multiple data items,
which are typically elements of an array. SIMD architectures became widely used in
graphicsprocessingunits(GPUs),whichwereinitiallyusedforspeedingupprocessing
of computer graphics tasks. However, more recently, GPU chips have been used for
parallelizing a variety of other tasks, one of which is parallel processing of relational
operations using the SIMD support provided by GPUs. Intel’s Xeon Phi coprocessor
supportsnotonlymultiplecoresinasinglechip,butalsoseveralSIMDinstructionsthat
can operate in parallel on multiple words. There has been agood deal of research on
howtoprocessrelationaloperationsinparallelonsuchSIMDarchitectures;references
to more information on this topic may be found in the bibliographic notes for this
chapter,availableonline.
22.7 Query Optimization for Parallel Execution
Query optimizers for parallel query evaluation are more complicated than query op-
timizers for sequential query evaluation. First, the space of plan alternatives can be
muchlargerthanthatforsequentialplans.Inparticular,inaparallelsetting,weneed
totakeintoaccountthedifferentpossiblewaysofpartitioningtheinputsandinterme-
diateresults,sincedifferentpartitioningschemescanleadtodifferentqueryexecution
costs,whichisnotanissueforasequentialplan.
Second,thecostmodelsaremorecomplicated,sincethecostofpartitioningmust
be taken into account, and issues such as skew and resource contention must be ad-
dressed.
22.7.1 Parallel Query Plan Space
Aswe have seen in Section 15.1, a sequential query plan can be expressed as an alge-
braicexpressiontree,whereeachnodeisaphysicaloperator,suchasasortoperator,
ahashjoinoperator,amerge-joinoperator,etc.Suchaplanmaybefurtherannotated
withinstructionsonwhatoperationsaretobepipelinedandwhatintermediateresults
aretobematerialized,aswesawinSection15.7.

--- Page 1094 ---

22.7 QueryOptimizationforParallelExecution 1065
Inadditiontotheabove,aparallelqueryplanmustspecify
• Howtoparallelizeeachoperation,includingdecidingwhatalgorithmtouse,and
how to partition the inputs and intermediate results. Exchange operators can be
usedtopartitioninputsaswellasintermediateresultsandfinalresults.
• Howtheplanistobescheduled;specifically:
° Howmanynodestouseforeachoperation.
° Whatoperationstopipelinewithinthesamenode,oracrossdifferentnodes.
° Whatoperationstoexecutesequentially,oneaftertheother.
° Whatoperationstoexecuteindependentlyinparallel.
Asanexample ofthepartitioningdecision,ajoinr ⋈ scanbe paral-
r.A=s.A∧r.B=s.B
lelizedbypartitioningr and son the attributes r.A and s.Aalone,or on theattributes
r.Bands.Balone,oron(r.A,r.B)and(s.A,s.B).Thelastoptionislikelytobethebest
ifweconsideronlythisjoin,sinceitminimizesthechancesofskewwhichcanariseif
thecardinalitiesofr.A,r.B,s.Aors.Barelow.
Butconsidernow thequery γ (r ⋈ s). Ifwe performthe join
r.A sum(s.C) r.A=s.A∧r.B=s.B
bypartitioningon(r.A,r.B)(and(s.A,s.B)),wewouldthenneedtorepartitionthejoin
result by r.A to compute the aggregate. On the other hand, if we performed the join
bypartitioningon r andson r.Aands.Arespectively,boththe joinandthe aggregate
canbecomputedwithoutanyrepartitioning,whichcouldreducethecost.Thisoption
is particularly likely to be a good option if r.A and s.A have high cardinality and few
duplicates,sincethechanceofskewislessinthiscase.
Thus,theoptimizerhastoconsideralargerspaceofalternatives,takingpartition-
ingintoaccount.Referenceswithmoredetailsabouthowtoimplementqueryoptimiza-
tionforparallelqueryprocessingsystems,takingpartitioningalternativesintoaccount,
maybefoundintheFurtherReadingsectionattheendofthechapter.
22.7.2 Cost of Parallel Query Evaluation
The cost of a sequential query plan is typically estimated based on the total resource
consumptionoftheplan,addinguptheCPUandI/Ocostsoftheoperatorsinaquery
plan.Theresourceconsumptioncostmodelcanalsobeusedinaparallelsystem,addi-
tionallytakingintoaccountthenetworkcost,andaddingitalongwiththeothercosts.
As discussed in Section 15.2, even in a sequential system, the resource consumption
cost model does not guarantee minimization of the execution time of an individual
query.Thereareothercostmodelsthatarebetteratmodelingthetimetocompletea
query; however,theresource consumption costmodelhasthebenefitofreducingthe
costofqueryoptimization,andisthuswidelyused.Wereturntotheissueofothercost
modelslaterinthesection.

--- Page 1095 ---

1066 Chapter22 ParallelandDistributedQueryProcessing
We now study how the cost of a parallel query plan can be estimated based on
theresourceconsumptionmodel.Ifaqueryplanisdataparallel,theneachoperation,
otherthantheexchangeoperation,runslocally;thecostofsuchoperationscanbeesti-
matedusingtechniqueswehaveseenearlierinChapter15,ifweassumethattheinput
relationsareuniformlypartitionedacrossnnodes,witheachnodereceiving1∕nthof
theoverallinput.
Thecostoftheexchangeoperationcanbeestimatedbasedonthenetworktopol-
ogy,theamountofdatatransferred,andthenetworkbandwidth;asbeforeitisassumed
that each node is equally loaded during the exchange operation. The cost of a query
plan under the resource-consumption model can then be found by adding up the costs
oftheindividualoperations.
However,inaparallelsystem,twoplanswiththesameresourceconsumptionmay
have significantly different time to completion. A response-time cost model is a cost
modelthatattemptstobetterestimatethetimetocompletionofaquery.Ifaparticular
operationisabletoperformI/OoperationsinparallelwithCPUexecution,theresponse
time would be better modeled as max(CPU cost, I/O cost), rather than the resource
consumptioncostmodelof(CPUcost+I/Ocost).Similarly,iftwooperationso and
1
o areinapipelineonasinglenode,andtheirCPUandI/Ocostsarec ,io andc ,io
2 1 1 2 2
respectively,thentheirresponsetimecostwouldbemax(c +c ,io +io ).Similarly,
1 2 1 2
ifoperationso ando areexecutedsequentially,thentheirresponse timecostwould
1 2
bemax(c ,io )+max(c ,io ).
1 1 2 2
When executing operations in parallel across multiple nodes, the response time
costmodelwouldhavetotakeintoaccount:
• Start-upcostsforinitiatinganoperationatmultiplenodes.
• Skewinthedistributionofworkamongthenodes,withsomenodesgettingalarger
number of tuples than others, and thus taking longer to complete. It is the time
to completion of the slowest node that determinesthe time to completion of the
operation.
Thus,anyskewinthedistributionoftheworkacrossnodesgreatlyaffectsperformance.
Estimatingthetimetocompletionoftheslowestnodedue toskewisnotaneasy
task since it is highly data dependent. However, statistics such as number of distinct
valuesofpartitioningattributes,histogramsonthedistributionofvaluesofpartitioning
attributes,andcountsofmostfrequentvaluescanbeusedtoestimatethepotentialfor
skew.Partitioningalgorithmsthatcandetectandminimizetheeffectofskew,suchas
thosediscussedinSection21.3,areimportanttominimizeskew.
22.7.3 Choosing a Parallel Query Plan
Thenumberofparallelevaluationplansfromwhichtochooseismuchlargerthanthe
number of sequential evaluation plans. Optimization of parallel queries by consider-
ing all alternatives is therefore much more expensive than optimization of sequential

--- Page 1096 ---

22.7 QueryOptimizationforParallelExecution 1067
queries.Hence,weusuallyadoptheuristicapproachestoreducethenumberofparallel
executionplansthatwehavetoconsider.Wedescribetwopopularapproacheshere.
1. Asimpleapproachistochoosethemostefficientsequentialevaluationplan,and
then to choose the optimal way to parallelize the operations in that evaluation
plan.Whenchoosingasequentialplan,theoptimizermayuseabasicsequential
cost model; or it may use a simple cost model that takes some aspects of paral-
lel execution into account but does not consider issues such as partitioning or
scheduling.Thisoptionallowsanexistingsequentialqueryoptimizertobeused
withminimalchangesforthefirststep.
Next,theoptimizerdecideshowtocreateanoptimalparallelplancorrespond-
ing to the chosen sequential plan. At this point, choices of what partitioning
techniques to use and how to schedule operators can be made in a cost-based
manner.
Thechosensequentialplanmaynotbeoptimalintheparallelcontext,since
the exact cost formulae for parallel execution were not used when choosing it;
nevertheless,theapproachworksreasonablywellinmanycases.
2. Amoreprincipledapproachistofindthebestplan,assumingthateachoperation
isexecutedinparallelacrossallthenodes(operationswithverysmallinputsmay
be executed on fewer nodes). Scheduling of independent operations in parallel
ondifferentnodesisnotconsideredatthisstage.
Partitioning of inputs and intermediate results is taken into consideration
whenestimatingthecostofaqueryplan.Existingtechniquesforqueryoptimiza-
tion have been extended by considering partitioning as a physical property, in
additiontophysicalpropertiessuchassortordersthatarealreadytakenintoac-
count when choosing a sequential query plan. Just as sort operators are added
to a query plan to get a desired sort order, exchange operators are added to get
the desired partitioning property. The cost model used in practice is typically
a resource consumption model, which we saw earlier. Although response-time
costmodelsofferbetterestimatesofqueryexecutiontime,thecostofqueryopti-
mizationishigherwhenusingaresponse-timecostmodelcomparedtothecost
ofoptimizationwhenusingaresource-consumptioncostmodel.Referencespro-
viding more information on the response-time cost model may be found in the
FurtherReadingsectionattheendofthechapter.
Yetanother dimension of optimization isthe design of physical-storage organiza-
tion to speed up queries. For example, a relation can be stored partitioned on any of
several different attributes, and it may even be replicated and replicas can be stored
partitioned on different attributes. For example, a relation r(A,B,C) could be stored
partitionedonA,andareplicacouldbepartitionedonB.Thequeryoptimizerchooses
the replica that is best suited for the query. The optimal physical organization differs

--- Page 1097 ---

1068 Chapter22 ParallelandDistributedQueryProcessing
fordifferentqueries.Thedatabaseadministratormustchooseaphysicalorganization
thatappearstobegoodfortheexpectedmixofdatabasequeries.
22.7.4 Colocation of Data
Even with parallel data storage and parallel processing of operations, the execution
timeofsomequeriescanbetooslowfortheneedsofsomeapplications.Inparticular,
queriesthataccesssmallamountsofdatastoredatmultiplenodesmayrunquiteslowly
whenexecutedinparallel,ascomparedtotheexecutionofthesamequeryonasingle
node,ifallthedatawereavailableatthatnode.Therearemanyapplicationsthatneed
suchqueriestoreturnanswerswithverylowlatency.
Animportanttechniquetospeedupsuchqueriesistocolocatedatathataquery
accessesinasinglenode.Forexample,supposeanapplicationneedstoaccessstudent
information, along with information about courses taken by the student. Then, the
studentrelationmaybepartitionedontheID,andthetakesrelationalsopartitionedin
exactlythesamemanneronID.Tuplesinthecourserelation,whichisasmallrelation,
maybereplicatedtoallnodes.Withsuchapartitioning,anyqueryinvolvingthesethree
relationsthatretrievesdataforasingleIDcanbeansweredlocallyatasinglenode.The
query processing engine just detects which node is responsible for that ID and sends
thequerytothatnode,whereitisexecutedlocally.
Colocation of tuples from different relations is supported by many data storage
systems.Ifthedatastoragesystemdoesnotnativelysupportcolocation,analternative
istocreateanobjectcontainingrelatedtuplesthatshareakey(e.g.,studentandtakes
recordscorrespondingtoaparticularID),andstoreitinthedatastoragesystem with
theassociatedkey(ID,inourexample).
Thecolocationtechnique,however,doesnotworkdirectlyifdifferentqueriesneed
a relationpartitioned in differentways. Forexample, ifthe goal istofind all students
whohavetakenaparticularcoursesection,thetakesrelationneedstobepartitionedon
the section information (course id, year, semester, sec id) instead of being partitioned
onID.
A simple technique to handle this situation is to allow multiple copies of a rela-
tion,partitionedondifferentattributes.Thesecopiescanbemodeledasindicesonthe
relation, partitioned on different attributes; when tuples in the relation are updated,
so are the copies, to keep them consistent. In our example, one copy of takes can be
partitionedonIDtobecolocatedwiththestudentpartitions,whileanothercopyispar-
titionedon(course id,year,semester,sec id)tobecolocatedwiththesectionrelation.
Colocationhelpsoptimizequeriesthatcomputejoinsbetweentworelations;itcan
extendtothreeormorerelationsifeithertheremainingrelationsarereplicated,orifall
relationsshareacommonsetofjoinattributes.Inthelattercase,alltuplesthatwould
jointogethercanbecolocatedbypartitioningonthecommonjoinattributes.Ineither
case, the join can be computed locally at a single node, if the query only wants the
resultsforaspecificvalueofthejoinattribute,aswesawearlier.However,notalljoin

--- Page 1098 ---

22.7 QueryOptimizationforParallelExecution 1069
queriesareamenabletoevaluation atasinglenode byusingcolocation.Materialized
views,whichwediscussnext,offeramoregeneralalternative.
22.7.5 Parallel Maintenance of Materialized Views
Materializedviews,whichwesawinSection4.2.3forspeedingupqueriesincentralized
databases, can also be used to speed up queries in parallel databases. Materialized
viewsneedtobemaintainedwhenthedatabaseisupdated,aswesawinSection16.5.
Materialized views in a parallel database can have a very large amount of data, and
must,therefore,bestoredpartitionedacrossmultiplenodes.
Asinthecentralizedcase,materializedviewsinaparalleldatabasespeedupquery
answering at the cost of the overhead of view maintenance at the time of processing
updates.
Weconsiderfirstaverysimplecaseofmaterializedviews.Itisoftenusefultostore
anextracopyofarelation,partitionedondifferentattributes,tospeedupansweringof
somequeries.Sucharepartitioningcanbeconsideredaverysimplecaseofamaterial-
izedview;viewmaintenanceforsuchaviewisstraightforward, justrequiringupdates
tobesenttotheappropriatepartition.
Indicescan be consideredaformofmaterializedviews.Recallfrom Section21.5
how parallel indices are maintained. Consider the case of maintenance of a parallel
secondaryindexonanattributeBofarelationr(A,B,C),withprimarykeyA.Thesec-
ondaryindexwouldbesortedonattributeBandwouldincludeuniquekeyA;assumeit
alsoincludesattributeC.SupposenowthatattributeBofatuple(a1,b1,c1)isupdated
from b1 to b2. This update results in two updates to the secondary index: delete the
indexentrywithkey(b1,a1,c1),andaddanentry(b2,a1,c1).Sincethesecondaryin-
dexisitselfpartitioned,thesetwoupdatesneedtobesenttotheappropriatepartition,
basedontheuniquekeyattributes(B,A).
In some cases, materialized view maintenance can be done by partitioning fol-
lowedbylocalviewmaintenance.Consideraviewthatgroups takestuplesby(course
id,year,semester,sec id),andthencountsthenumberofstudentswhohavetakenthat
coursesection.Suchamaterializedviewwouldbestoredpartitionedonthegrouping
attributes(course id,year,semester,sec id).Itcanbecomputedbymaintainingacopy
ofthetakesrelationpartitionedon(course id,year,semester,sec id),andmaterializing
theaggregateslocallyateachnode.Whenthereisanupdate,sayaninsertordeleteto
the takes relation, that update must be propagated to the appropriate node based on
thepartitioningchosenabove.Thematerializedaggregatecanbemaintainedlocallyat
eachnode,asupdatesarereceivedforthesetoflocaltuplesofthetakesrelation.
Formorecomplexviews,materializedviewmaintenancecannotbedonebyasingle
stepofpartitioningandlocalviewmaintenance.Weconsideramoregeneralapproach
next.
First,consideranoperatoro,whoseresultismaterialized,andanupdate(insertor
delete)tooneoftheinputrelationsofothatrequiresmaintenanceofthematerialized
resultofo.Suppose theexecutionofoperator oisparallelizedusingtheexchange op-

--- Page 1099 ---

1070 Chapter22 ParallelandDistributedQueryProcessing
eratormodel(Section22.5.2)wheretheinputsarepartitioned,andthenoperatorsare
executed at each node on data made available locally by (re)partitioning. To support
materializedviewmaintenanceoftheresultofo,wematerializetheoutputofoateach
node and additionally materialize (store) the input partitions sent to the node when
thematerializedviewresultisinitiallycomputed.
Now,whenthereisanupdate(insertordelete)toaninputtoo,wesendtheupdate
totheappropriatenodeusingthesamepartitionfunctionusedduringtheinitialcom-
putationofo.Consideranodethathasreceivedsuchanupdate.Now,themaintenance
ofthelocallymaterializedresultatthenodecanbedoneusingstandard(nonparallel)
viewmaintenancetechniquesusingonlylocallyavailabledata.
Note thatas we saw in Section 22.5.2, avariety of operations can be parallelized
usingtheexchangeoperatormodel,andhencetheprecedingschemeprovidesaparallel
viewmaintenancetechniqueforallsuchoperators.
Next, consider a query with multiple operators. Such a query can be parallelized
usingtheexchange operatormodel.Theexchange operatorsrepartitiondatabetween
nodes,andeachnodecomputing(possiblymultiple)operationsusingdatamadeavail-
ablelocallybytheexchangeoperators,aswesawinSection22.5.2.
Wecanmaterializetheinputsandresultsateachnode.Now,whenthereisachange
toaninputatanode,weusestandardviewmaintenancetechniqueslocallytofindthe
changetothematerializedresult,sayv,atthatnode.Ifthatresultvisthefinaloutputof
thequery,wearedone.Otherwise,theremustbeanexchangeoperatoraboveit;weuse
theexchangeoperatortoroutetheupdates(insertsordelete)tovtothenextoperator.
That operator in turn computes the change to its result, and propagates it further if
required,untilwegettotherootoftheoriginalmaterializedview.
Theissueofconsistencyofmaterializedviewsinthefaceofconcurrentupdatesto
theunderlyingrelationsisaddressedinSection23.6.3.
22.8 Parallel Processing of Streaming Data
WesawseveralapplicationsofstreamingdatainSection10.5.Manyofthestreaming
data applications that we saw in that section, such as network monitoring or stock
market applications, have very high rates of tuple arrival. Incoming tuples cannot be
processed by a single computer, and parallel processing is essential for such systems.
Streaming data systems apply a variety of operations on incoming data. We now see
howsomeoftheseoperationscanbeexecutedinparallel.
Parallelismisessentialatallstagesofqueryprocessing,startingwiththeentryof
tuplesfromthesources.Thus,aparallelstreamprocessingsystem needstosupporta
largenumberofentrypointsfordata.
For example, a system that is monitoring queries posed on a search engine such
as Google or Bing search has to keep up with a very high rate of queries. Search en-
gines have a large number of machines across which user queries are distributed and
executed.Eachofthesemachinesbecomesasourceforthequerystream.Thestream

--- Page 1100 ---

22.8 ParallelProcessingofStreamingData 1071
processingsystemmusthavemultipleentrypointsforthedata,whichreceivedatafrom
theoriginalsourcesandroutethemwithinthestreamprocessingsystem.
Processingof data must be done by routingtuples from producersto consumers.
WediscussroutingoftuplesinSection22.8.1.Parallelprocessingofstreamoperations
isdiscussedinSection22.8.2,whilefaulttoleranceisdiscussedinSection22.8.3.
Itisalsoworthnotingthatmanyapplicationsthatperformreal-timeanalyticson
streaming data also need to store the data and analyze it in other ways subsequently.
Thus, many systems duplicate incoming data streams, sending one copy to a storage
systemforsubsequentanalysisandsendingtheothercopytoastreamingdatasystem;
such an architecture is called the lambda architecture: the Greek symbol λ is used to
pictoriallydenotethatincomingdataareforkedintotwocopies,senttotwodifferent
systems.
Whilethelambdaarchitectureallowsstreamingsystemstobebuiltquickly,italso
resultsinduplicationofeffort:programmersneedtowritecodetostoreandquerythe
data in the format/language supported by a database, as well as to query the data in
the language supported by a streaming data system. More recently, there have been
effortstoperformstreamprocessingaswellasqueryprocessingonstoreddatawithin
thesamesystemtoavoidthisduplication.
22.8.1 Routing of Tuples
Sinceprocessingofdatatypicallyinvolvesmultipleoperators,routingofdatatooper-
atorsisanimportanttask.Wefirstconsiderthelogicalstructureofsuchrouting,and
addressthephysicalstructure,whichtakesparallelprocessingintoaccount,later.
Thelogicalroutingoftuplesisdonebycreatingadirectedacyclicgraph(DAG)with
operatorsasnodes.Edgesbetweennodesdefinetheflowoftuples.Eachtupleoutputby
anoperatorissentalongalltheout-edgesoftheoperator,totheconsumingoperators.
Each operator receives tuples from all its in-edges. Figure 22.8a depicts the logical
Data
Op Op
Source Data
Data
Op Source Data
Sink
Data Sink
Source Data
Op Data Source
Sink Publish-Subscribe Data
Data System Sink
Source Data Data
Op Op Source
Sink
Data Data
Source Data Sink
Source
Op Op
(a) DAG representation of streaming data flow (b) Publish-subscribe representation of streaming data flow
Figure 22.8 RoutingofstreamsusingDAGandpublish-subscriberepresentations.

--- Page 1101 ---

1072 Chapter22 ParallelandDistributedQueryProcessing
routing of stream tuples through a DAG structure. Operation nodes are denoted as
“Op”nodesinthefigure.Theentrypointstothestreamprocessingsystemarethedata
source nodes of the DAG; these nodes consume tuples from the stream sources and
injectthemintothestreamprocessingsystem.Theexitpointsofthestreamprocessing
systemaredatasinknodes;tuplesexitingthesystemthroughadatasinkmaybestored
inadatastoreorfilesystemormaybeoutputinsomeothermanner.
One way of implementing a stream processing system is by specifying the graph
as part of the system configuration, which is read when the system starts processing
tuples and is then used to route tuples. The Apache Storm stream processing system
is an example of a system that uses a configuration file to define the graph, which is
calledatopologyintheStormsystem.(DatasourcenodesarecalledspoutsintheStorm
system,whileoperatornodesarecalledbolts,andedgesconnectthesenodes.)
An alternative way of creating such a routing graph is by using publish-subscribe
systems. A publish-subscribe system allows publication of documents or other forms
of data, with an associated topic. Subscribers correspondingly subscribe to specified
topics.Wheneveradocumentispublishedtoaparticulartopic,acopyofthedocument
issenttoallsubscriberswhohavesubscribedtothattopic.Publish-subscribesystems
arealsoreferredtoaspub-subsystemsforshort.
Whenapublish-subscribesystemisusedforroutingtuplesinastreamprocessing
system, tuples are considered documents, and each tuple is tagged with a topic. The
entrypointstothesystemconceptually“publish”tuples,eachwithanassociatedtopic.
Operatorssubscribetooneormoretopics;thesystemroutesalltupleswithaspecific
topictoallsubscribersofthattopic.Operatorscanalsopublishtheiroutputsbackto
thepublish-subscribesystem,withanassociatedtopic.
Amajorbenefitofthepublish-subscribe approachisthatoperatorscanbe added
tothesystem,orremovedfromit,withrelativeease.Figure22.8bdepictstheroutingof
tuplesusingapublish-subscriberepresentation.Eachdatasourceisassignedaunique
topic name; the output of each operator is also assigned a unique topic name. Each
operatorsubscribestothetopicsofitsinputsandpublishestothetopicscorresponding
toitsoutput.Datasourcespublishtotheirassociatedtopic,whiledatasinkssubscribe
tothetopicsoftheoperatorswhoseoutputgoestothesink.
The Apache Kafka system uses the publish-subscribe model to manage routing
of tuples in streams. In the Kafka system, tuples published for a topic are retained
foraspecifiedperiodoftime(calledtheretentionperiod),evenifthereiscurrentlyno
subscriberforthetopic.Subscribersusuallyprocesstuplesattheearliestpossibletime,
butincaseprocessingisdelayedortemporarilystoppedduetofailures,thetuplesare
stillavailableforprocessinguntiltheretentiontimeexpires.
Manystreamingdatasystems,suchasGoogle’sMillwheel,andtheMuppetstream
processing system, use the term stream in place of the term topic. In such systems,
streamsareassignednames;operators canpublish tuplestoastream,orsubscribe to
astream,basedonthename.
Wenowconsiderthephysicalroutingoftuples.Regardlessofthemodelusedabove,
eachlogicaloperatormusthavemultiplephysicalinstancesrunninginparallelondif-

--- Page 1102 ---

22.8 ParallelProcessingofStreamingData 1073
ferentnodes.Incomingtuplesforalogicaloperatormustberoutedtotheappropriate
physicalinstance(s)oftheoperator.Apartitioningfunctionisusedtodeterminewhich
tuplegoestowhichinstanceoftheoperator.
In the context of a publish-subscribe system, each topic can be thought of as a
separate logical operator that accepts tuples and passes them on to all subscribers of
thetopic.Sincetheremaybeaverylargenumberoftuplesforagiventopic,theymust
be processed in parallel across multiple nodes in a parallel publish-subscribe system.
In the Kafka system, for example, a topic is divided into multiple partitions, called
a topic-partition; each tuple for that topic is sent to only one of the topic-partitions.
Kafkaallowsapartitionkeytobeattachedtoeachtuple,andensuresthattupleswith
thesamekeyaredeliveredtothesamepartition.
Toallowprocessingbyconsumers,Kafkaallowsconsumeroperatorsregisterwith
aspecified“consumergroup.”Theconsumergroupcorrespondstoalogicaloperator,
whiletheindividualconsumerscorrespondtophysicalinstancesofthelogicaloperator
thatruninparallel.Eachtupleofatopicissenttoonlyoneconsumerintheconsumer
group.Moreprecisely,alltuplesinaparticulartopic-partitionaresenttoasinglecon-
sumerinaconsumergroup;however,tuplesfrommultiplepartitionsmaybesenttothe
sameconsumer,leadingtoamany-to-onerelationshipfrompartitionstoconsumers.
Kafka is used in many streaming data processing implementations for routing
tuples. Kafka Streams provides a client library supporting algebraic operations on
streams,whichcanbeusedtobuildstreamingapplicationsontopoftheKafkapublish-
subscribesystem.
22.8.2 Parallel Processing of Stream Operations
Forstandardrelationaloperations,thetechniquesthatwehaveseenforparallelevalu-
ationoftheoperationscanbeusedwithstreamingdata.
Someofthese,suchasselectionandprojectionoperations,canbedoneinparallel
ondifferenttuples.Others,suchasgrouping,havetobringalltuplesofagrouptogether
toonemachine.6 Whengroupingisdonewithaggregation,optimizationssuchaspre-
aggregationcanbeusedtoreducethedatatransferred,butinformationaboutthetuples
inagroupmuststillbedeliveredtoasinglemachine.
Windowingisanimportantoperationinstreamingdatasystems.RecallfromSec-
tion 10.5.2.1 that incoming data are divided into windows, typically based on times-
tamps (windows can also be defined based on the number of tuples). Windowing is
oftencombinedwithgrouping/aggregation,withaggregatescomputedongroupsoftu-
pleswithinawindow.Theuseofwindowsensuresthatoncethesystemcandetermine
that new tuples will no longer belong to a particular window, aggregates for that win-
dowcanbeoutput.Forexample,supposeawindowisbasedontime,saywitheach5
minutesdefiningawindow;once the system determinesthatfuture tupleswillhave a
6Whengroupingiscombinedwithwindowing(Section10.5.2.1),agroupcontainsalltuplesinawindowthathavethe
samevaluesfortheirgroupingattributes.

--- Page 1103 ---

1074 Chapter22 ParallelandDistributedQueryProcessing
timestamplargerthantheendofaparticularwindow,aggregatesonthatwindowcan
beoutput.Unlikegrouping,windowscanoverlapeachother.
When windowingand grouping are used together to compute aggregates, if there
are overlapping windows, it is best to partition on just the grouping attributes. Oth-
erwise, tuples which belong to multiple windows would have to be sent to multiple
windows,anoverheadthatisavoidedbypartitioningononlythegroupingattributes.
Manystreamingsystemsallowuserstocreatetheirownoperators.Itisimportant
to be able to parallelize user-defined operators by allowing multiple instances of the
operatortorunconcurrently.Suchsystems typicallyrequireeachtupletohaveanas-
sociatedkey,andalltupleswithaparticularkeyaresenttoaparticularinstanceofthe
operator.Tupleswithdifferentkeyscanbesenttodifferentoperatorinstances,allowing
parallelprocessing.
Stream operations often need to store state. For example, a windowing operator
may need to retain all tuples that it has seen in a particular window, as long as the
windowisactive.Or,itmayneedtostoreaggregatescomputedatsomeresolution(say
per minute) to later compute coarser resolution aggregates (say per hour). There are
many other reasons for operators to store state. User-defined operators often define
stateinternaltotheoperator(localvariables),whichneedstobestored.
Such state may be stored locally, at each node where a copy of the operator is
executed.Alternatively,itmaybestoredcentrallyinaparalleldata-storagesystem.The
store-locally alternative has a lower cost but a higher risk of losing state information
onfailure,ascomparedtostoringstateinaparalleldata-storagesystem.Thisaspectis
discussedfurtherinSection22.8.3.
22.8.3 Fault Tolerance with Streaming Data
Faulttolerancewhenqueryingstoreddatacanbeachievedbyreexecutingthequery,or
partsofthequery,aswehaveseeninSection22.5.4.However,suchanapproachtofault
tolerance does not work well in a streaming setting for multiple reasons. First, many
streaming data applications are latency sensitive, and delays in delivering results due
to restarts are not desirable. Second, streaming systems provide a continuous stream
of outputs. In the event of a failure, reexecuting the entire system or parts of it could
potentiallyleadtoduplicatecopiesofoutputtuples,whichisnotacceptableformany
applications.
Thus,streamingdatasystemsneedtoprovideguaranteesaboutdeliveryofoutput
tuples,whichcanbeoneof:at-leastonce,at-mostonce,andexactly-once.Theat-least-
oncesemanticsguaranteesthateachtupleisoutputatleastonce,butallowsduplicate
deliveryduringrecoveryfromfailures.Theat-most-oncesemanticsguaranteesthateach
tuple is delivered at most once, without duplicates, but some tuples may be lost in
the event of a failure. The exactly-once semantics guarantees that each tuple will be
deliveredexactlyonce,regardlessoffailures.Thisisthemodelthatmostapplications
require, although some applications may not care about duplicates and may accept
at-least-oncesemantics.

--- Page 1104 ---

22.8 ParallelProcessingofStreamingData 1075
To ensure such semantics, streaming systems must track what tuples have been
processed at each operator and what tuples have been output. Duplicates can be de-
tectedbycomparingagainsttuplesoutputearlierandremoved.(Thiscanbedoneonly
if the system guarantees the absence of duplicates during normal processing, since
otherwisethesemanticsofthestreamingquerymaybeaffectedbyremovalofgenuine
duplicates.)
Onewaytoimplementfaulttoleranceistosupportitinthesubsystemthatroutes
tuples between operators. For example, in Kafka, tuples are published to topics, and
eachtopic-partitioncanbestoredintwoormorenodessothatevenifoneofthenodes
fails, the other one is available. Further, the tuples are stored on disk in each of the
nodessothattheyarenotlostonpowerfailureorsystemrestart.Thus,thestreaming
datasystemcanusethisunderlyingfaulttoleranceandhighavailabilitymechanismto
implementfault-toleranceandhighavailabilityatahigherlevelofthesystem.
Insuchasystem,ifanoperatorwasexecutingonafailednode,itcanberestarted
onanothernode.Thesystemmustalso(atleastperiodically)recorduptowhatpoint
eachinputstreamhadbeenconsumedbytheoperator.Theoperatormustberestarted
andeachinputstreamreplayedfromapointsuchthattheoperatorcancorrectlyoutput
all tuples that it had not already output before the failure. This is relatively easy for
operatorswithoutanystate;operatorswithoutanystateneedtodoextraworktorestore
thestatethatexistedbeforefailure.Forexample,awindowoperatorneedstostartfrom
a point in the stream corresponding to the start of a window and replay tuples from
thatpoint.
If the window is very large, restarting from a very old point in the stream would
be very inefficient. Instead, the operator may checkpoint its state periodically, along
withpointsintheinputstreamuptowhichprocessinghasbeendone.Intheeventof
afailure,thelatestcheckpointmayberestored,andonlyinputstreamtuplesthatwere
processedsincethelastcheckpointneedtobereplayed.
The same approach can be for other operators that have state information; the
statecanbecheckpointedperiodically,andreplaystartsfromthelastcheckpoint.The
checkpointed state may be stored locally; however, this means that until the node re-
covers, stream processing cannot proceed. As an alternative, the state may be stored
inadistributedfilesystemorinaparalleldata-storagesystem.Suchsystemsreplicate
datatoensurehighavailabilityevenintheeventoffailures.Thus,ifanodehasfailed,
itsfunctionscanberestartedonadifferentnode,startingwiththelastcheckpoint,and
replayingthestreamcontents.
If the underlying system does not implement fault tolerance, operators can im-
plement their own fault-tolerance mechanisms to avoid tuple loss. For example, each
operatormaystorealltuplesthatithasoutput;atuplecanbediscardedonlyafterthe
operatorknowsthatnoconsumerwillneedthetuple,evenintheeventofafailure.
Further, streaming systems must often guarantee low latency, even in the event
of failures.Todo so, some streamingsystems have replicasof each operator, running
concurrently. If one replica fails, the output can be fetched from the other replica.
The system must make sure that duplicate tuples from the replicas are not output to

--- Page 1105 ---

1076 Chapter22 ParallelandDistributedQueryProcessing
consumers.Insuchsystems,onecopyofanoperatoristreatedasaprimarycopy,and
the other copy as a hot-spare replica (recall that we discussed hot-spares in Section
19.7).
Whatwehavedescribedaboveisahigh-levelviewofhowstreamingdatasystems
implementfaulttolerance.Referencestomoreinformationonhowtoimplementfault
toleranceinstreamingsystemsmaybefoundintheFurtherReadingsectionattheend
ofthechapter.
22.9 Distributed Query Processing
Theneedfordistributedqueryprocessingoriginallyarosewhenorganizationsneeded
toexecutequeriesacrossmultipledatabasesthatwereoftengeographicallydistributed.
However,todaythesameneedarisesbecauseorganizationshavedatastoredinmultiple
different databases and data storage systems, and they need to execute queries that
accessmultiplesofthesedatabasesanddatastoragesystems.
22.9.1 Data Integration from Multiple Data Sources
Differentpartsofanenterprisemayusedifferentdatabases,eitherbecauseofalegacy
ofhowtheywereautomated,orbecauseofmergersofcompanies.Migratinganentire
organizationtoacommonsystemmaybeanexpensiveandtime-consumingoperation.
Analternativeistokeepdatainindividualdatabases,buttoprovideuserswithalogical
viewofintegrateddata.Thelocaldatabasesystemsmayemploydifferentlogicalmod-
els, different data-definition and data-manipulation languages, and may differ in their
concurrency-control and transaction-management mechanisms. Some of the sources
of data may not be full-fledged database systems but may instead be data storage sys-
tems, or even just files in a file system. Yet another possibility is that the data source
may be on the cloud and accessed as awebservice. Queries may need accessto data
storedacrossmultipledatabasesanddatasources.
Manipulationofinformationlocatedinmultipledatabasesandotherdatasources
requires an additional software layer on top of existing database systems. This layer
createstheillusionoflogicaldatabaseintegrationwithoutrequiringphysicaldatabase
integrationandissometimescalledafederateddatabasesystem.
Databaseintegrationcanbedoneinseveraldifferentways:
• The federated database approach creates a common schema, called a global
schema, for data from all the databases/data sources; each database has its own
local schema. The task of creating a unified global schema from multiple local
schemasisreferredtoasschemaintegration.
Userscanissuequeriesagainsttheglobalschema.Aqueryonaglobalschema
must be translated into queries on the local schemas at each of the sites where
thequeryhastobeexecuted.Thequeryresultshavetobetranslatedbackintothe
globalschemaandcombinedtogetthefinalresult.

--- Page 1106 ---

22.9 DistributedQueryProcessing 1077
Ingeneral,updatestothecommonschemaalsoneedtobemappedtoupdates
totheindividualdatabases;systemsthatsupportacommonschemaandqueries,
butnotupdates,againsttheschemaaresometimesreferredtoasmediatorsystems.
• Thedatavirtualizationapproachallowsapplicationstoaccessdatafrommultiple
databases/data sources, but it does not try to enforce a common schema. Users
havetobeawareofthedifferentschemasusedindifferentdatabases,buttheydo
notneedtoworryaboutwhichdataarestoredonwhichdatabasesystem,orabout
howtocombineinformationfrommultipledatabases.
• Theexternaldataapproachallowsdatabaseadministratorstoprovideschemain-
formationaboutdatathatarestoredinotherdatabases,alongwithotherinforma-
tion,suchasconnectionandauthorizationinformationneededtoaccessthedata.
Datastoredinexternalsourcesthatcanbeaccessedfromadatabasearereferred
to as external data. Foreign tables are views defined in a database whose actual
data are stored in an external data source. Such tables can be read as well as up-
dated,dependingon whatoperations the external datasource supports. Updates
on foreign tables, if supported, must be translated into updates on the external
datasource.
Unlike the earlier-mentioned approaches, the goal here is not to create a full-
fledged distributed database, but merely to facilitate access to data from other
data sources. The SQL Management of External Data (SQL MED) component
oftheSQLstandard definesstandards foraccessingexternal datasourcesfrom a
database.
If a data source is a database that supports SQL, its data can be easily accessed
using ODBC or JDBC connections. Data in parallel data storage systems that do not
supportSQL,suchasHBase,canbeaccessedusingtheAPImethodsthattheyprovide.
Awrapperprovidesaviewofdatastoredatadatasource,inadesiredschema.For
example,ifthesystemhasaglobalschema,andthelocaldatabaseschemaisdifferent
fromtheglobalschema,awrappercanprovideaviewofthedataintheglobalschema.
Wrapperscanevenbeusedtoprovidearelationalviewofnonrelationaldatasources,
suchaswebservices,flatfiles(e.g.,weblogs),anddirectorysystems.
Wrappers can also translate queries on the global schema into queries on the lo-
cal schema, and translate results back into the global schema. Wrappers may be pro-
videdbyindividualsites,theymaybewrittenaspartofthefederateddatabasesystem.
Many relational databases today support wrappers that provide a relational view of
datastoredinfilesystems;suchwrappersarespecifictothetypeofdatastoredinthe
files.
Ifthegoalofdataintegrationissolelytorundecisionsupportqueries,dataware-
houses, which we saw in Section 11.2, are a widely used alternative to database inte-
gration. Data warehouses import data from multiple sources into a single (possibly
parallel) system, with a centralized schema. Data are typically imported periodically,

--- Page 1107 ---

1078 Chapter22 ParallelandDistributedQueryProcessing
forexample,onceinadayoronceinafewhours,althoughcontinuousimportisalso
increasingly used. Raw data imported from the data sources are typically processed
andcleanedbeforebeingstoredinthedatawarehouse.
However,withthescaleatwhichdataaregeneratedbysomeapplications,creating
andmaintainingsuchawarehousecanbeexpensive.Furthermore,queriescannotac-
cessthemostrecentdata,sincethereisadelaybetweenupdatesonthesourcedatabase
andimportoftheupdatestothedatawarehouse.Ontheotherhand,queryprocessing
canbedonemoreefficientlyinadatawarehouse;further,queriesatadatawarehouse
do not affect the performance of other queries and transactions at the data source.
Whethertouseadatawarehousearchitecture,ortodirectlyaccessdatafromthedata
sourcesinresponsetoindividualqueries,isadecisionthateachenterprisehastomake
basedonitsneeds.
The term data lake is used to refer to an architecture where data are stored in
multiple data storage systems and in different formats, including in file systems, but
can be queried from a single system. Data lakes are viewed as an alternative to data
warehouses,sincetheydonotrequireup-frontefforttopreprocessdata,althoughthey
dorequiremoreeffortwhencreatingqueries.
22.9.2 Schema and Data Integration
The first task in providing a unified view of data lies in creating a unified conceptual
schema,ataskthatisreferredtoasschemaintegration.Eachlocalsystemprovidesits
own conceptual schema. The database system must integrate these separate schemas
into one common schema. Schemaintegration is a complicated task, mainlybecause
ofthesemanticheterogeneity.Thesameattributenamesmayappearindifferentlocal
databasesbutwithdifferentmeanings.
Schemaintegrationrequiresthecreationofaglobalschema,whichprovidesauni-
fiedviewofdataindifferentdatabases.Schemaintegrationalsorequiresawaytodefine
how data are mapped from the local schema representation at each database, to the
global schema. Thisstep can be done by definingviewsat each site which,transform
data from the local schema to the global schema. Data in the global schema is then
treated as the union of the global views at the individualsite. This approach is called
theglobal-as-view(GAV)approach.
Consideranexamplewithtwositeswhichstorestudentinformationintwodiffer-
entways:
• Site s1 which uses the relation student1(ID, name, dept name), and the relation
studentCreds(ID,tot cred).
• Site s2 which uses the relation student2(ID, name, tot cred), and the relation stu-
dentDept(ID,dept name).
Lettheglobalschemachosenbestudent(ID,name,dept name,tot cred).

--- Page 1108 ---

22.9 DistributedQueryProcessing 1079
Then,theglobalschemaviewatsites1wouldbedefinedastheview:
createviewstudent s1(ID,name,dept name,tot cred)as
selectID,name,dept name,tot cred
fromstudent1,studentCreds
wherestudent1.ID=studentCreds.ID;
Whiletheglobalschemaviewatsites2wouldbedefinedastheview:
createviewstudent s2(ID,name,dept name,tot cred)as
selectID,name,dept name,tot cred
fromstudent2,studentDept
wherestudent2.ID=studentDept.ID;
Finally, the global schema student would be defined as the union of student s1 and
student s2.
Note that with the above view definition, a query on the global schema relation
student can be easily translated into queries on the local schemarelationsat the sites
s1 and s2. It is harder to translate updates on the global schema into updates on the
localschema,sincetheremaynotbeauniquewaytodosoasdiscussedinSection4.2.
There are more complex mapping schemes that are designed to deal with dupli-
cation of information across sites and to allow translation of updates on the global
schema into updates on the local schema. The local-as-view (LAV) approach, which
defineslocaldataineachsiteasaviewonaconceptualunifiedglobalrelation,isone
suchapproach.
Considerforexampleasituationwherethestudentrelationispartitionedbetween
twositesbasedonthedept nameattribute,withallstudentsinthe“Comp.Sci.”depart-
ment at site s3 and all students in other departments in site s4. This can be specified
using the local-as-view approach by defining the relations student s3 and student s4,
which are actually stored at the sites s3 and s4, as equivalent to views defined on the
globalrelationstudent.
createviewstudent s3as
select∗
fromstudent
wherestudent.deptname='Comp.Sci.';
and
createviewstudent s4as
select∗
fromstudent
wherestudent.deptname! ='Comp.Sci.';

--- Page 1109 ---

1080 Chapter22 ParallelandDistributedQueryProcessing
Withthisextrainformation,thequeryoptimizercanfigureoutthataquerythatseeks
toretrievestudentsintheComp.Sci.departmentneedonlybeexecutedatsites3and
neednotbeexecutedatsites4.Moreinformationonschemaintegrationmaybefound
inthebibliographicnotesforthischapter,availableonline.
The second task in providing a unified view of data from multiple sources lies in
dealing with differences in data types and values. For example, the data types used
in one system may not be supported by other systems, and translation between types
may not be simple. Even for identical data types, problems may arise from the phys-
ical representation of data: One system may use 8-bit ASCII, while another may use
16-bitUnicode;floating-pointrepresentationsmaydiffer;integersmaybe represented
in big-endian or little-endian form. At the semantic level, an integer value for length
maybe inchesinone system and millimetersinanother;whenintegratingthedata,a
singlerepresentationmustbeused,andvaluesconvertedtothechosenrepresentation.
Mappingbetweentypescanbedoneaspartoftheviewdefinitionsthattranslatedata
betweenthelocalschemasandtheglobalschema.
Adeeperproblemisthatthesameconceptualentitymayhavedifferentnamesin
different systems. For example, a system based in the United States may refer to the
city“Cologne,”whereasoneinGermanyreferstoitas“K¨oln.”Oneapproachtodeal
with this problem is to have a globally unique naming system, and map values to the
uniquenamesaspartoftheviewdefinitionsusedforschemamappings.Forexample,
theInternationalStandardsOrganizationhasauniquecodeforcountrynames,andfor
states/provinceswithinthecountries.TheGeoNamesdatabase(www.geonames.org)
provides unique names for several million locations such as cities, geographical fea-
tures,roads,buildings,andsoforth.
When such standard naming systems are not available, some systems allow the
specification of name equivalences; for example, such a system could allow a user to
say that “Cologne” is the same as “K¨oln”. This approach is used in the Linked Data
project, which supports the integration of a very large number of databases that use
theRDFrepresentationofdata(theRDFrepresentationisdescribedinSection8.1.4).
However,queryingismorecomplicatedinsuchascenario.
Inourdescriptionoftheviewdefinitionsabove,weassumedthatdataarestoredin
localdatabases,andtheviewdefinitionsareusedtoprovideaglobalviewofthedata,
withoutactuallymaterializingthedataintheglobalschema.However,suchviewscan
alsobeusedtomaterializethedataintheglobalschema,whichcanthenbestoredin
adatawarehouse.Inthelattercase,updatesonunderlyingdatamustbepropagatedto
thedatawarehouse.
22.9.3 Query Processing Across Multiple Data Sources
A naive way to execute a query that accesses data from multiple data sources is to
fetchallrequireddatatoonedatabase,whichthenexecutesthequery.Butsuppose,for
example,thatthequeryhasaselectionconditionthatissatisfiedbyonlyoneorafew
recordsoutofalargerelation.Ifthedatasourceallowstheselectiontobeperformedat

--- Page 1110 ---

22.9 DistributedQueryProcessing 1081
thedatasource,itmakesnosensetoretrievetheentirerelation;instead,theselection
operationshouldbeperformedatthedatasource,whileotheroperations,ifany,may
beperformedatthedatabasewherethequerywasissued.
Ingeneral,differentdatasourcesmaysupportdifferentquerycapabilities.Forex-
ample,ifthesourceisadatastoragesystem,itmaysupportselectionsonkeyattributes
only.Webdatasourcesmayrestrictwhichfieldsselectionsareallowedonandmayad-
ditionallyrequirethatselectionsbepresentoncertainfields.Ontheotherhand,ifthe
source is a database that supports SQL, operations such as join or aggregation could
beperformedatthesourceandonlytheresultbroughtovertothedatabasethatissues
the query. In general, queries may have to be broken up and performed partly at the
datasourceandpartlyatthesiteissuingthequery.
The cost of processing a query that accesses multiple data sources depends on
the local execution costs, as well as on the data transfer cost. If the network is a low
bandwidth wide-area network, particular attention must be paid to minimizing data
transfer.
Inthissection,westudyissuesindistributedqueryprocessingandoptimization.
22.9.3.1 JoinLocationsandJoinOrdering
Considerthefollowingrelational-algebraexpression:
r ⋈ r ⋈ r
1 2 3
Assumethatr isstoredatsiteS ,r atS ,andr atS .LetS denotethesiteatwhich
1 1 2 2 3 3 I
the query was issued. The system needs to produce the result at site S . Among the
I
possiblestrategiesforprocessingthisqueryarethese:
• Ship copies of all three relations to site S . Using the techniques of Chapter 16,
I
chooseastrategyforprocessingtheentirequerylocallyatsiteS .
I
• Shipacopyofther relationtositeS ,andcomputetemp =r ⋈ r atS .Ship
1 2 1 1 2 2
temp fromS toS ,andcomputetemp =temp ⋈ r atS .Shiptheresulttemp
1 2 3 2 1 3 3 2
toS .
I
• Devisestrategiessimilartothepreviousone,withtherolesofS ,S ,S exchanged.
1 2 3
Thereareseveralotherpossiblestrategies.
Noonestrategyisalwaysthebestone.Amongthefactorsthatmustbeconsidered
arethevolumeofdatabeingshipped,thecostoftransmittingablockofdatabetweena
pairofsites,andtherelativespeedofprocessingateachsite.Considerthefirststrategy.
Suppose indicespresent at S and S are useful for computing the join. If we ship all
2 3
three relations to S , we would need to either re-create these indices at S or use a
I I
different, possibly more expensive, join strategy. Re-creation of indices entails extra
processing overhead and extra disk accesses. There are many variants of the second
strategy,whichprocessjoinsindifferentorders.

--- Page 1111 ---

1082 Chapter22 ParallelandDistributedQueryProcessing
Thecostofeachofthestrategiesdependsonthesizesoftheintermediateresults,
the network transmission costs, and the costs of processing at each node. The query
optimizerneedstochoosethebeststrategy,basedoncostestimates.
22.9.3.2 SemijoinStrategy
Supposethatwewishtoevaluatetheexpressionr ⋈ r ,wherer andr arestoredat
1 2 1 2
sitesS andS ,respectively.Lettheschemasofr andr beR andR .Suppose that
1 2 1 2 1 2
wewish toobtain the resultatS . Iftherearemany tuplesof r thatdonotjoin with
1 2
anytupleofr ,thenshippingr toS entailsshippingtuplesthatfailtocontributeto
1 2 1
the result. We want to remove such tuples before shipping data to S , particularly if
1
networkcostsarehigh.
Apossiblestrategytoaccomplishallthisis:
1. Computetemp ←Π (r )atS .
1 R ∩R 1 1
1 2
2. Shiptemp fromS toS .
1 1 2
3. Computetemp ←r ⋈temp atS .
2 2 1 2
4. Shiptemp fromS toS .
2 2 1
5. Computer ⋈temp atS .Theresultingrelationisthesameasr ⋈ r .
1 2 1 1 2
Beforeconsideringtheefficiencyofthisstrategy,letusverifythatthestrategycomputes
thecorrectanswer.Instep 3,temp hastheresultofr ⋈ Π (r ).Instep 5,we
2 2 R ∩R 1
1 2
compute:
r ⋈ r ⋈ Π (r )
1 2 R ∩R 1
1 2
Sincejoinisassociativeandcommutative,wecanrewritethisexpressionas:
(r ⋈ Π (r )) ⋈ r
1 R ∩R 1 2
1 2
Since r ⋈ Π (r ) = r , the expression is, indeed, equal to r ⋈ r , the
1 (R ∩R ) 1 1 1 2
1 2
expressionwearetryingtoevaluate.
This strategy is called a semijoin strategy, after the semijoin operator of the rela-
tional algebra, denoted ⋉, whichwe saw in Section 16.4.4. The natural semijoin of r
1
withr ,denotedr ⋉r ,isdefinedas:
2 1 2
r ⋉r ≝ Π (r ⋈ r )
1 2 R 1 2
1
Thus, r ⋉ r selects those tuples of relation r that contributed to r ⋈ r . In step
1 2 1 1 2
3, temp = r ⋉r . The semijoin operation is easily extended to theta-joins. The theta
2 2 1
semijoinofr withr ,denotedr ⋉ r ,isdefinedas:
1 2 1 θ 2
r ⋉ r ≝ Π (r ⋈ r )
1 θ 2 R 1 θ 2
1

--- Page 1112 ---

22.9 DistributedQueryProcessing 1083
Forjoins of several relations, the semijoin strategy can be extended to a series of
semijoinsteps.Itisthejobofthequeryoptimizertochoosethebeststrategybasedon
costestimates.
Thisstrategyisparticularlyadvantageouswhenrelativelyfewtuplesofr contribute
2
tothejoin. Thissituation islikelytooccurifr isthe resultof arelational-algebraex-
1
pressioninvolvingselection.Insuchacase,temp ,thatis,r ⋉r ,mayhavesignificantly
2 2 1
fewer tuples than r . The cost savings of the strategy result from having to ship only
2
r ⋉r ,ratherthanallofr ,toS .
2 1 2 1
Some additional cost is incurred in shipping temp , that is Π (r ) to S . If a
1 R ∩R 1 2
1 2
sufficientlysmallfractionoftuplesinr contributetothejoin,theoverheadofshipping
2
temp willbe dominated bythe savingsofshipping onlyafraction ofthe tuples inr .
1 2
Theoverheadofsendingtemp tuplesfroms tos canbereducedasfollows.Forthe
1 1 2
purposeofoptimizationofjoinprocessing,thesemijoinoperationcanbeimplemented
in a mannerthat overapproximates the true semijoin result. That is, the result should
containallthetuplesintheactualsemijoinresult,butitmaycontainafewextratuples.
Theextratupleswillgeteliminatedlaterbythejoinoperation.
Anefficientoverapproximationofthesemijoinresultcanbecomputedbyusinga
probabilisticdatastructurecalledaBloomfilter,whichusesbitmaps.Bloomfiltersare
described in more detail in Section 24.1. To implement r ⋉r , a Bloom filter with a
2 1
bitmapbofsizem,initializedwithallbitssetto0isused.Thejoinattributesofeach
tuple ofr arehashed toavalue intherange 0…(m−1), andthe correspondingbit
1
of bissetto1.The bitmapb,whichismuch smallerthanthe relationr ,can now be
1
sent to the site containingr . There, the same hash function is computed on the join
2
attributes of each tuple of r . If the corresponding bit is set to 1 in b, that r tuple is
2 2
accepted(addedtotheresultrelation),andotherwiseitisrejected.
Notethatitispossiblefordifferentjoinattributevalues,sayv andv tohavethe
1 2
samehashvalue;evenifr hasatuplewithvaluev ,butdoesnothaveanytuplewith
1 1
value v , the result of the above procedure may include r tuples whose join attribute
2 2
valueisv .Suchasituationisreferredtoasafalsepositive.However,ifv ispresentin
2 1
r ,thetechniquewillneverrejectatupleinr thathasjoinattributevaluev ,whichis
1 2 1
importantforcorrectness.
The result relation computed above, which is a superset of or equal to r ⋉r , is
2 1
senttosites .Thejoinr ⋈ resultisthencomputedatsites togettherequiredjoin
1 1 1
result.Falsepositivesmayresultinextratuplesinresultthatarenotpresentinr ⋉r ,
2 1
butsuchtupleswouldbeeliminatedbythejoin.
To keep the probability of false positives low, the number of bits in the Bloom
filterisusuallysettoafewtimestheestimatednumberofdistinctjoinattributevalues.
Further,itispossibletousekindependenthashfunctions,forsomek > 1,toidentify
k bit positions for a given value, and set all of them to 1 when creating the bitmap.
Whenqueryingitwithagivenvalue,thesamek hashfunctionsareusedtoidentifyk
bitlocations,andthevalueisdeterminedtobeabsentifevenoneofthekbitshasa0
value. Forexample, if the bitmap has 10n bits, where n is the number of distinct join

--- Page 1113 ---

1084 Chapter22 ParallelandDistributedQueryProcessing
attribute values, and k = 7 hash functions are used, the false positive rate would be
about1%.
22.9.3.3 DistributedQueryOptimization
Severalextensionsneedtobemadetoexistingqueryoptimizationtechniquesinorder
tooptimizedistributedqueryplans.
The first extension is to record the location of data as a physical property of the
data;recallthatoptimizersalreadydealwithotherphysicalpropertiessuchasthesort
order of results. Just as the sort operation is used to create different sort orders, an
exchangeoperationisusedtotransferdatabetweendifferentsites.
Thesecondextensionistotrackwhereanoperatorisexecuted;optimizersalready
considerdifferentalgorithms,suchashashjoinormergejoin,foragivenlogicaloper-
ator,inthiscase,thejoinoperator.Theoptimizerisextendedtoadditionallyconsider
alternativesitesforexecutionofeachalgorithm.Notethattoexecuteanoperatorata
givensite,itsinputsmustsatisfythephysicalpropertyofbeinglocatedatthatsite.
Thethirdextensionistoconsidersemijoinoperationstoreducedatatransfercosts.
Semijoinoperationscanbeintroducedaslogicaltransformationrules;however,ifdone
naively,thesearchspaceincreasesgreatly,makingthisapproachinfeasible.Optimiza-
tioncostcanbereducedbyrestricting,asaheuristic,semijoinstobeappliedonlyon
databasetables,andneveronintermediatejoinresults.
A fourth extension is to use schema information to restrict the set of nodes at
whichaquery needstobe executed. Recallfrom Section 22.9.2thatthe local-as-view
approachcanbeusedtospecifythatarelationispartitionedinaparticularway.Inthe
examplewesawthere,sites3containsallstudenttupleswithdept namebeingComp.
Sci., while s4 contains all the other student tuples. Suppose a query has a selection
“dept name='Comp. Sci.'” on student; then, the optimizer should recognize that there
isnoneedtoinvolvesites4whenexecutingthisquery.
Asanotherexample,ifthestudentdataatsites5isareplicaofthedataatsites3,
thentheoptimizercanchoosetoexecutethequeryateitherofthesites,dependingon
whichischeaper;thereisnoneedtoexecutethequeryatbothsites.
22.9.4 Distributed Directory Systems
A directory is a listing of information about some class of objects such as persons.
Directories can be used to find information about a specific object, or in the reverse
directiontofindobjectsthatmeetacertainrequirement.Severaldirectoryaccessproto-
colshavebeendevelopedtoprovideastandardizedwayofaccessingdatainadirectory.
AverywidelyuseddistributeddirectorysystemistheinternetDomainNameSer-
vice (DNS) system, which provides a standardized way to map domain names (such
asdb-book.comorwww.cs.yale.edu,totheIPaddressesofthemachines.(Although
users see only the domain names, the underlying network routes messages based on
IPaddresses,andhenceawaytoconvertdomainnamestoIPaddressesiscriticalfor

--- Page 1114 ---

22.9 DistributedQueryProcessing 1085
thefunctioningoftheinternet.)TheLightweightDirectoryAccessProtocol(LDAP)is
anotherverywidelyusedprotocoldesignedforstoringorganizationaldata.
Data stored in directories can be represented in the relational model, stored in a
relationaldatabase,andaccessedthroughstandardprotocolssuchasJDBCorODBC.
Thequestionthenis,whycomeupwithaspecializedprotocolforaccessingdirectory
information?Thereareseveralreasons.
• First, directory access protocols are simplified protocols that cater to a limited
typeofaccesstodata.Theyevolvedinparallelwiththedatabaseaccessprotocol
standards.
• Second,directorysystemsweredesignedtosupportahierarchicalnamingsystem
for objects, similar to file system directory names. Such a naming system is im-
portant in many applications. For example, all computers whose names end in
yale.edubelongtoYale,whilethose whosenamesendiniitb.ac.inbelongtoIIT
Bombay.Withintheyale.edudomain,therearesubdomainssuchascs.yale.edu,
whichcorresponds to the CS department in Yale,and math.yale.eduwhichcor-
respondstotheMathdepartmentatYale.
• Third, and most important from a distributed systems perspective, the data in a
distributeddirectorysystemarestoredandcontrolledinadistributed,hierarchical,
manner.
For example, a DNS server at Yale would store information about names of
computers at Yale, along with associated information such as their IP addresses.
Similarly,DNSserversatLehighandIITBombaywouldstore informationabout
computers in their respective domains. The DNS servers store information in a
hierarchicalfashion;forexample,theinformationprovidedbytheYaleDNSserver
maybestoredinadistributedfashionacrosssubdomainsatYale,suchastheCS
andMathDNSservers.
Distributeddirectorysystemsautomaticallyforwardqueriessubmittedatasite
tothesitewheretherequiredinformationisactuallystored,togiveaunifiedview
ofdatatousersandapplications.
Further,distributeddirectoryimplementationstypicallysupportreplicationto
ensuretheavailabilityofdataevenifsomenodeshavefailed.
Anotherexampleofusage ofdirectorysystems isfororganizationdata.Suchsys-
temsstoreinformationaboutemployees,suchastheemployeeidentifier,name,email,
organizationunit(suchasdepartment),roomnumber,phonenumber,and(encrypted)
passwordofeachemployee.Theschemaofsuchorganizationaldataarestandardized
aspartoftheLightweightDirectoryAccessProtocol(LDAP).Directorysystemsbased
ontheLDAPprotocolarewidelyusedtoauthenticateusers,usingtheencryptedpass-
words stored for each user. (More information about the LDAP data representation
maybefoundinSection25.5.)

--- Page 1115 ---

1086 Chapter22 ParallelandDistributedQueryProcessing
Althoughdistributeddatastorageacrossorganizationalunitswasimportantatone
time, such directory systems are often centralized these days. In fact, several direc-
toryimplementationsuserelationaldatabasestostoredata,insteadofcreatingspecial-
purposestoragesystems.However,thefactthatthedatarepresentationandprotocolto
accessthedataarestandardizedhasmeantthattheseprotocolscontinuetobewidely
used.
22.10 Summary
• Current generation parallel systems are typically based on a hybrid architecture,
where each computer has multiple cores with a shared memory, and there are
multiplecomputersorganizedinashared-nothingfashion.
• Parallelprocessinginadatabasesystemcanbeexploitedintwodistinctways.
° Interqueryparallelism—theexecutionofmultiplequeriesinparallelwitheach
other,acrossmultiplenodes.
° Intraquery parallelism—theprocessingofdifferentparts oftheexecution ofa
singlequery,inparallelacrossmultiplenodes.
• Interqueryparallelismisessentialfortransaction-processingsystems, whileintra-
queryparallelismisessentialforspeedinguplong-runningqueries.
• Execution of a single query involves execution of multiple relational operations.
Thekeytoexploitinglarge-scaleparallelismistoprocesseachoperationinparallel,
acrossmultiplenodes(referredtoasintraoperationparallelism).
• Theoperationsthatarethemostamenabletoparallelismare:sort,selection,du-
plicateelimination,projection,andaggregation.
• Range-partitioning sort works in two steps: first range-partitioning the relation,
thensortingeachpartitionseparately.
• Parallel external sort-merge works in two steps: first, each node N sorts the data
i
availableatnodeN,thenthesystem mergesthesorted runson eachnodetoget
i
thefinalsortedoutput.
• Paralleljoinalgorithmsdividethetuplesoftheinputrelationsoverseveralnodes.
Each node then computes part of the join locally. Then the system collects the
resultsfromeachnodetoproducethefinalresult.
• Skew is a major problem, especially with increasing degrees of parallelism. Bal-
anced partitioning vectors, using histograms, and virtual node partitioning are
amongthetechniquesusedtoreduceskew.

--- Page 1116 ---

22.10 Summary 1087
• TheMapReduceparadigmisdesignedtoeasethewritingofparalleldataprocess-
ing programs using imperative programming languages that may not be express-
ible using SQL. Fault-tolerant implementations of the MapReduce paradigm are
importantforavarietyofverylargescaledataprocessingtasks.Extensionsofthe
MapReduce model based on algebraic operations is increasingly important. The
Hive SQL system uses a MapReduce system as its underlying execution engine,
compilingSQLqueriestoMapReducecode.
• There are two forms of interoperation parallelism: pipelined parallelism and in-
dependentparallelism.Pipelinedparallelismisusuallyimplementedusingapush
model,withbuffersbetweenoperations.
• The exchange operation repartitions data in a specified way. Parallel query plans
canbecreatedinsuchawaythatdatainterchangebetweennodesisdoneonlyby
theexchange operator, whileallotheroperations workon localdata,just asthey
wouldinacentralizeddatabasesystem.
• Intheeventoffailure,parallelqueryexecutionplanscouldberestarted.However,
inverylargesystems wherethereisasignificantchanceoffailureduringtheexe-
cutionofaquery,faulttolerancetechniquesareimportanttoensurethatqueries
completeexecutionwithoutrestarting,despitefailures.
• Parallel algorithms designed for shared-nothing architectures can be used in
shared-memoryarchitectures.Eachprocessorcanbetreatedashavingitsownpar-
titionofmemory,andwecanignorethefactthattheprocessorshaveacommon
shared memory. However, execution can be optimized significantly by exploiting
thefastaccesstosharedmemoryfromanyoftheprocessors.
• Query optimization for parallel execution can be done using the traditional re-
sourceconsumptioncostmodel,orusingtheresponsetimecostmodel.Partition-
ingoftablesmustbetakenintoaccountwhenchoosingaplan,tominimizedata
exchangewhichisoftenasignificantfactorinqueryexecutioncost.Materialized
viewscanbeimportantinparallelenvironmentssincetheycansignificantlyreduce
queryexecutioncost.
• Therearemanystreamingdataapplicationstodaythatrequirehighperformance
processing, which can only be achieved by parallel processing of streaming data.
Incomingtuples and results of operations need to be routed to other operations.
The publish-subscribe model, implemented for example in Apache Kafka, has
proven quite useful for such routing. Fault-tolerant processing of streaming data
with exactly-once semantics for processing tuples is important in many applica-
tions.Persistenceprovidedbypublish-subscribesystemshelpsinthisregard.
• Integrationofschemaanddatafrommultipledatabasesisneededformanydata
processingtasks.Theexternaldataapproachallowsexternaldatatobequeriesin
adatabaseasifitislocallyresident.Theglobal-as-viewandlocal-as-viewarchitec-

--- Page 1117 ---

1088 Chapter22 ParallelandDistributedQueryProcessing
turesallowsrewritingofqueriesfromaglobalschematoindividuallocalschemas.
ThesemijoinstrategyusingBloomfilterscanbeuseful toreducedatamovement
forjoinsinadistributeddatabase.Distributeddirectorysystemsareatypeofdis-
tributeddatabasedesignedfordistributedstorageandqueryingofdirectories.
Review Terms
• Interqueryparallelism • Independentparallelism
• Intraqueryparallelism • Exchangeoperator
° Intraoperationparallelism • Unpartitioned
° Interoperationparallelism • Randommerge
• Range-partitioningsort • Orderedmerge
• Dataparallelism • Parallelqueryexecutionplan
• Parallelexternalsort-merge • Queryprocessinginsharedmemory
• Partitionedjoin • Thread
• Partitionedparallelhashjoin • Single Instruction Multiple Data
(SIMD)
• Partitionedparallelmergejoin
• Response-timecostmodel
• Partitionedparallelnested-loopjoin
• Parallelviewmaintenance
• Partitioned parallel indexed nested-
• Streamingdata
loopsjoin
• Asymmetricfragment-and-replicate • Lambdaarchitecture
join • Routingofstreams
• Broadcastjoin • Publish-subscribe
• Fragment-and-replicatejoin • Topic-partition
• Symmetricfragment-and-replicate • At-least-oncesemantics
join • At-most-oncesemantics
• Joinskewavoidance • Exactly-oncesemantics
• Dynamichandlingofjoinskew • Federateddatabasesystem
• Workstealing • Globalschema
• Parallelselection • Localschema
• Parallelduplicateelimination • Schemaintegration
• Parallelprojection • Mediator
• Parallelaggregation • Datavirtualization
• Partialaggregation • Externaldata
• Intermediatekey • Foreigntables
• Pipelinedparallelism

--- Page 1118 ---

PracticeExercises 1089
• Datalake • Thetasemijoin
• Global-as-view(GAV) • Bloomfilter
• Local-as-view(LAV) • Falsepositive
• LinkedData • Directoryaccessprotocols
• Semijoinstrategy • DomainNameService(DNS)
• Semijoin • Lightweight Directory Access Proto-
col(LDAP)
Practice Exercises
22.1 What form of parallelism (interquery, interoperation, or intraoperation) is
likelytobethemostimportantforeachofthefollowingtasks?
a. Increasingthethroughputofasystemwithmanysmallqueries
b. Increasingthethroughputofasystemwithafewlargequerieswhenthe
numberofdisksandprocessorsislarge
22.2 Describe how partial aggregation can be implemented for the count and avg
aggregatefunctionstoreducedatatransfer.
22.3 Withpipelinedparallelism,itisoftenagoodideatoperformseveraloperations
inapipelineonasingleprocessor,evenwhenmanyprocessorsareavailable.
a. Explainwhy.
b. Wouldtheargumentsyouadvancedinpartaholdifthemachinehasa
shared-memoryarchitecture?Explainwhyorwhynot.
c. Wouldtheargumentsinpartaholdwithindependentparallelism?(That
is, are there cases where, even if the operations are not pipelined and
there are many processors available, it is still a good idea to perform
severaloperationsonthesameprocessor?)
22.4 Consider join processing using symmetric fragment and replicate with range
partitioning. How can you optimize the evaluation if the join condition is of
the form ∣ r.A−s.B ∣ ≤ k, where k is a small constant? Here, ∣ x ∣ denotes
theabsolutevalueofx.Ajoinwithsuchajoinconditioniscalledabandjoin.
22.5 Supposerelationr isstoredpartitionedandindexedonA,andsisstoredpar-
titionedandindexedonB.Considerthequery:
γ ( (σ (r)) ⋈ s )
r.C count(s.D) A>5 r.B=s.B
a. Give a parallel query plan using the exchange operator, for computing
thesubtreeofthequeryinvolvingonlytheselectandjoinoperators.

--- Page 1119 ---

1090 Chapter22 ParallelandDistributedQueryProcessing
b. Now extend theabove tocompute theaggregate. Make suretouse pre-
aggregationtominimizethedatatransfer.
c. Skew during aggregation is a serious problem. Explain how pre-
aggregationasabovecanalsosignificantlyreducetheeffectofskewdur-
ingaggregation.
22.6 SupposerelationrisstoredpartitionedandindexedonA,andsisstoredparti-
tionedandindexedonB.Considerthejoinr ⋈ s.Supposesisrelatively
r.B=s.B
small, but not small enough to make asymmetric fragment-and-replicate join
thebestchoice,andr islarge,withmostr tuplesnotmatchinganystuple.A
hash-join can be performedbut withasemijoinfilterused toreducethe data
transfer.ExplainhowsemijoinfilteringusingBloomfilterswouldworkinthis
paralleljoinsetting.
22.7 Supposeyouwanttocomputer⟕ s.
r.A=s.A
a. Suppose s is a small relation, while r is stored partitioned on r.B. Give
anefficientparallelalgorithmforcomputingtheleftouterjoin.
b. Now suppose that r is a small relation, and s is a large relation, stored
partitionedonattributes.B.Giveanefficientparallelalgorithmforcom-
putingtheaboveleftouterjoin.
22.8 Suppose you want to compute γ on a relation s which is stored par-
A,B sum(C)
titionedon s.B.Explain how youwould doitefficiently,minimizing/avoiding
repartitioning,ifthenumberofdistincts.Bvaluesislarge,andthedistribution
ofnumberoftupleswitheachs.Bvalueisrelativelyuniform.
22.9 MapReduceimplementationsprovidefaulttolerance,whereyoucanreexecute
only failed mappers or reducers.By default, a partitioned parallel join execu-
tion wouldhave tobe rerun completelyincase ofevenone node failure.Itis
possible tomodifyaparallelpartitionedjoinexecutiontoaddfaulttolerance
in a manner similarto MapReduce, so failure of a node does not require full
reexecution of the query, but only actions related to that node. Explain what
needstobedoneatthetimeofpartitioningatthesendingnodeandreceiving
nodetodothis.
22.10 Ifaparalleldata-storeisusedtostoretworelationsrandsandweneedtojoin
r ands,itmaybeusefultomaintainthejoinasamaterializedview.Whatare
the benefits and overheads in terms of overall throughput, use of space, and
responsetimetouserqueries?
22.11 Explainhoweachofthefollowingjoinalgorithmscanbeimplementedusing
theMapReduceframework:
a. Broadcastjoin(alsoknownasasymmetricfragment-and-replicatejoin).

--- Page 1120 ---

PracticeExercises 1091
b. Indexednestedloopjoin,wheretheinnerrelationisstoredinaparallel
data-store.
c. Partitionedjoin.
Exercises
22.12 Canpartitionedjoinbeusedforr ⋈ s?Explainyouranswer.
r.A<s.A∧r.B=s.B
22.13 Describeagoodwaytoparallelizeeachofthefollowing:
a. Thedifferenceoperation
b. Aggregationbythecountoperation
c. Aggregationbythecountdistinctoperation
d. Aggregationbytheavgoperation
e. Leftouterjoin,ifthejoinconditioninvolvesonlyequality
f. Left outer join, if the join condition involves comparisons other than
equality
g. Full outer join, if the join condition involves comparisons other than
equality
22.14 Supposeyouwishtohandleaworkloadconsistingofalargenumberofsmall
transactionsbyusingshared-nothingparallelism.
a. Is intraquery parallelism required in such a situation? If not, why, and
whatformofparallelismisappropriate?
b. Whatformofskewwouldbeofsignificancewithsuchaworkload?
c. Supposemosttransactionsaccessedoneaccountrecord,whichincludes
anaccount typeattribute,andanassociatedaccount type master record,
whichprovidesinformationabouttheaccounttype.Howwouldyoupar-
tition and/or replicate data to speed up transactions? You may assume
thattheaccount typemaster relationisrarelyupdated.
22.15 Whatisthemotivationforwork-stealingwithvirtualnodesinashared-memory
setting? Why might work-stealing not be as efficient in a shared-nothing set-
ting?
22.16 Theattribute on whicharelationispartitionedcanhave asignificantimpact
onthecostofaquery.
a. Given a workload of SQL queries on a single relation, what attributes
wouldbecandidatesforpartitioning?

--- Page 1121 ---

1092 Chapter22 ParallelandDistributedQueryProcessing
b. Howwouldyouchoosebetweenthealternativepartitioningtechniques,
basedontheworkload?
c. Isitpossibletopartitionarelationonmorethanoneattribute?Explain
youranswer.
22.17 Consider system that is processing a stream of tuples for a relation r with
attributes(A,B,C,timestamp)Supposethegoalofaparallelstreamprocessing
system istocompute thenumberoftuplesforeachAvalue ineach5minute
window(based onthetimestampofthetuple). Whatwouldbe thetopicand
thetopicpartitions?Explainwhy.
Tools
Awidevarietyofopen-sourcetoolsareavailable,inadditiontosomecommercialtools,
forparallelqueryprocessing.Anumberofthesetoolsarealsoavailableonhostedcloud
platforms.
Teradatawasoneofthefirstcommercialparalleldatabasesystems,anditcontinues
to have a large market share. The Red Brick Warehouse was another early parallel
database system; Red Brick was acquired by Informix, which was itself acquired by
IBM. Other commercial parallel database systems include Teradata Aster Data, IBM
Netezza,andPivotalGreenplum.IBMNetezza,PivotalGreenplum,andTeradataAster
Data all use PostgreSQL as the underlying database, running independently on each
node; each of these systems builds a layer on top, to partition data, and parallelize
queryprocessingacrossthenodes.
The open source Hadoop platform (hadoop.apache.org) includesthe HDFS dis-
tributedfilesystemandtheHadoopMapReduceplatform.Systemsthatsupport SQL
on aMapReduceplatformincludeApacheHive (hive.apache.org),whichoriginated
at Facebook, Apache Impala (impala.apache.org), which originated at Cloudera,
and Apache HAWQ (hawq.apache.org), which originated at Pivotal. Apache Spark
(spark.apache.org),whichoriginatedattheUniv.ofCalifornia,Berkeley,andApache
Tez (tez.apache.org) are parallel execution frameworks that support a variety of op-
eratorsbeyondthebasicmapandreduceoperators;andHiveSQLqueriescanbeexe-
cutedonboththeseplatforms.OtherparallelexecutionframeworksincludeApachePig
(pig.apache.org),whichoriginatedatYahoo!,theAsterixsystem(asterix.ics.uci.edu),
which originated at the University of California, Irvine, the Apache Flink system
(flink.apache.org),whichoriginatedastheStratosphereprojectattheTechnicalUni-
versity, Berlin, Humboldt University and the Hasso-Plattner Institute). Apache Spark
andApacheFlinkalsosupportlibrariesforparallelmachinelearning.
These systems can access data stored in multiple different data formats, such as
filesindifferentformatsinHDFS,orobjectsinastoragesystemsuchasHBase.Hadoop
fileformatswereinitiallytextualfiles,buttodayHadoopimplementationssupportsev-
eral optimized file formats such as Sequence files (which allow binary data), Avro

--- Page 1122 ---

FurtherReading 1093
(whichsupportssemi-structuredschemas)andParquet(whichsupportscolumnardata
representation).
Apache Kafka (kafka.apache.org) is widely used for routing tu-
ples in streaming data systems. Systems designed for query process-
ing on streaming data include Apache Storm (storm.apache.org),
Kafka Streams (kafka.apache.org/documentation/streams/) and Heron
(apache.github.io/incubator-heron/), developed by Twitter. Apache Flink
(flink.apache.org), Spark Streaming (spark.apache.org/streaming/),the streaming
componentofApacheSpark,andApacheApex(apex.apache.org)supportanalytics
onstreamingdataalongwithanalyticsonstoreddata.
Manyoftheabovesystemsarealsoofferedascloud-basedservices,aspartofthe
cloud services offered by Amazon AWS, Google Cloud, Microsoft Azure, and other
similarplatforms.
Further Reading
Early work on parallel database systems include GAMMA ([DeWitt (1990)]), XPRS
([Stonebrakeretal.(1989)])andVolcano([Graefe(1990)]).[Graefe(1993)]presents
an excellent survey of query processing, including parallel processing of queries. The
exchange-operatormodelwasadvocatedby[Graefe(1990)]and[GraefeandMcKenna
(1993)].Skewhandlinginparalleljoinsisdescribedby[DeWittetal.(1992)].
[Ganguly et al. (1992)] describe query-optimization techniques based on the
response-time cost model for parallel query execution, while [Zhou et al. (2010)] de-
scribehowtoextendaqueryoptimizertoaccountforpartitioningpropertiesandpar-
allelplans.Viewmaintenanceinparalleldatastoragesystemsisdescribedby[Agrawal
etal.(2009)].
A fault-tolerant implementation of the MapReduce framework at Google, which
lead to the widespread use of the MapReduce paradigm, is described by [Dean and
Ghemawat(2010)].[Kwonetal.(2013)]provideanoverviewofskewhandlinginthe
HadoopMapReduceframework.[HerodotouandBabu(2013)] describehowtoopti-
mize a number of parameters for query execution in the MapReduce framework. An
overviewoftheApacheSparksystemisprovidedby[Zahariaetal.(2016)],while[Za-
hariaetal.(2012)]describeResilientDistributedDatasets,afault-tolerantabstraction
which formed a basis for the Spark implementation. Extensions of the exchange op-
erator to support fault-tolerance, are described by [Shah et al. (2004)], with a focus
on fault-tolerant continuous queries. Fault-tolerant stream processing in the Google
MillWheelsystemisdescribedin[Akidauetal.(2013)].
The morsel-driven approach to parallel query evaluation in shared-memory sys-
tems with multi-core processors is described in [Leis et al. (2014)]. [Kersten et al.
(2018)] provides a comparison of vectorwise query processing using optimizations
suchasSIMDinstructions,withproducer-drivenpipelining.

--- Page 1123 ---

1094 Chapter22 ParallelandDistributedQueryProcessing
[Carbone et al. (2015)] describe stream and batch processing in Apache Flink.
[Ozsu and Valduriez (2010)] provides textbook coverage of distributed database sys-
tems.
Bibliography
[Agrawaletal.(2009)] P. Agrawal, A. Silberstein, B. F. Cooper, U. Srivastava, and R. Ra-
makrishnan, “Asynchronous view maintenance for VLSD databases”, In Proc. of the ACM
SIGMODConf.onManagementofData(2009),pages179–192.
[Akidauetal.(2013)] T. Akidau, A. Balikov, K. Bekiro˘glu, S. Chernyak, J. Haberman,
R. Lax, S. McVeety, D. Mills, P. Nordstrom, and S. Whittle, “MillWheel: Fault-tolerant
StreamProcessingatInternetScale”,ProceedingsoftheVLDBEndowment,Volume6,Num-
ber11(2013),pages1033–1044.
[Carboneetal.(2015)] P. Carbone, A. Katsifodimos, S. Ewen, V. Markl, S. Haridi, and
K.Tzoumas,“ApacheFlink:StreamandBatchProcessinginaSingleEngine”,IEEEData
Eng.Bull.,Volume38,Number4(2015),pages28–38.
[DeanandGhemawat(2010)] J.DeanandS. Ghemawat,“MapReduce:a flexible data pro-
cessingtool”,CommunicationsoftheACM,Volume53,Number1(2010),pages72–77.
[DeWitt(1990)] D. DeWitt, “The Gamma Database Machine Project”, IEEE Transactions
onKnowledgeandDataEngineering,Volume2,Number1(1990),pages44–62.
[DeWittetal.(1992)] D. DeWitt, J. Naughton, D. Schneider, and S. Seshadri, “Practical
SkewHandlinginParallelJoins”,InProc.oftheInternationalConf.onVeryLargeDatabases
(1992),pages27–40.
[Gangulyetal.(1992)] S.Ganguly,W.Hasan,andR.Krishnamurthy,“QueryOptimization
forParallelExecution”,InProc.oftheACMSIGMODConf.onManagementofData(1992),
pages9–18.
[Graefe(1990)] G.Graefe,“EncapsulationofParallelismintheVolcanoQueryProcessing
System”,InProc.oftheACMSIGMODConf.onManagementofData(1990),pages102–111.
[Graefe(1993)] G.Graefe,“QueryEvaluationTechniquesforLargeDatabases”,ACMCom-
putingSurveys,Volume25,Number2(1993).
[GraefeandMcKenna(1993)] G.GraefeandW.McKenna,“TheVolcano OptimizerGen-
erator”,InProc.oftheInternationalConf.onDataEngineering(1993),pages209–218.
[HerodotouandBabu(2013)] H.HerodotouandS.Babu,“AWhat-ifEngineforCost-based
MapReduceOptimization”,IEEEDataEng.Bull.,Volume36,Number1(2013),pages5–14.
[Kerstenetal.(2018)] T. Kersten, V. Leis, A. Kemper, T. Neumann, A. Pavlo, and P. A.
Boncz,“EverythingYouAlwaysWantedtoKnowAboutCompiledandVectorizedQueries
ButWereAfraidtoAsk”,ProceedingsoftheVLDBEndowment,Volume11,Number13(2018),
pages2209–2222.

--- Page 1124 ---

FurtherReading 1095
[Kwonetal.(2013)] Y. Kwon, K. Ren, M. Balazinska, and B. Howe, “Managing Skew in
Hadoop”,IEEEDataEng.Bull.,Volume36,Number1(2013),pages24–33.
[Leisetal.(2014)] V.Leis,P.A. Boncz,A. Kemper,andT.Neumann, “Morsel-driven par-
allelism:aNUMA-awarequeryevaluationframeworkforthemany-coreage”,InProc.ofthe
ACMSIGMODConf.onManagementofData(2014),pages743–754.
[OzsuandValduriez(2010)] T.OzsuandP.Valduriez,PrinciplesofDistributedDatabaseSys-
tems,3rdedition,PrenticeHall(2010).
[Shahetal.(2004)] M. A. Shah, J. M. Hellerstein, and E. A. Brewer, “Highly-Available,
Fault-Tolerant, Parallel Dataflows”, In Proc. of the ACM SIGMOD Conf. on Management of
Data(2004),pages827–838.
[Stonebrakeretal.(1989)] M.Stonebraker,P.Aoki,andM.Seltzer,“ParallelisminXPRS”,
InProc.oftheACMSIGMODConf.onManagementofData(1989).
[Zahariaetal.(2012)] M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma, M. McCauly,
M.J.Franklin,S.Shenker,andI.Stoica,“ResilientDistributedDatasets:AFault-Tolerant
AbstractionforIn-MemoryClusterComputing”,InProcs.USENIXSymposiumonNetworked
SystemsDesignandImplementation,NSDI(2012),pages15–28.
[Zahariaetal.(2016)] M. Zaharia, R. S. Xin, P. Wendell, T. Das, M. Armbrust, A. Dave,
X. Meng, J. Rosen,S. Venkataraman,M. J.Franklin, A. Ghodsi, J.Gonzalez, S. Shenker,
andI.Stoica,“ApacheSpark:aunifiedengineforbigdataprocessing”,Communicationsof
theACM,Volume59,Number11(2016),pages56–65.
[Zhouetal.(2010)] J.Zhou,P.Larson,andR.Chaiken,“Incorporatingpartitioningandpar-
allelplansintotheSCOPEoptimizer”,InProc.oftheInternationalConf.onDataEngineering
(2010),pages1060–1071.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 1126 ---

23
CHAPTER
Parallel and Distributed
Transaction Processing
We studied transaction processing in centralized databases earlier, covering concur-
rencycontrolinChapter18andrecoveryinChapter19.Inthischapter,westudyhow
to carry out transaction processing in parallel and distributed databases. In addition
tosupportingconcurrencycontrolandrecovery,transactionprocessinginparalleland
distributeddatabasesmustalsodealwithissuesduetoreplicationofdata,andoffail-
uresofsomenodes.
Both parallel and distributed databases have multiple nodes, which can fail in-
dependently.Themaindifferencebetweenparallelanddistributeddatabasesfromthe
viewpointoftransactionprocessingisthatthelatencyofremoteaccessismuchhigher,
and bandwidth lower, in a distributed database than in a parallel database where all
nodes are in a single data center. Failures such as network partitioning and message
delaysaremuchlesslikelywithinadatacenterthanacrossgeographicallydistributed
sites, but nevertheless they can occur; transaction processing must be done correctly
eveniftheydooccur.
Thus,mosttechniquesfortransactionprocessingarecommontobothparalleland
distributed databases. In the few cases where there is a difference,we explicitlypoint
out the difference. And as a result, in this chapter, whenever we say that a technique
isapplicabletodistributeddatabases,itshouldbeinterpretedtomeanthatitisappli-
cabletodistributed databases aswellastoparalleldatabases, unlessweexplicitlysay
otherwise.
In Section 23.1, we outline a model for transaction processing in a distributed
database.InSection23.2,wedescribehowtoimplementatomictransactionsinadis-
tributeddatabasebyusingspecialcommitprotocols.
In Section 23.3 we describe how to extend traditional concurrency control tech-
niquestodistributeddatabases.Section23.4describesconcurrencycontroltechniques
for the case where data items are replicated, while Section 23.5 describes further ex-
tensionsincludinghowmultiversionconcurrencycontroltechniquescanbeextended
todealwithdistributeddatabases,andconcurrencycontrolcanbeimplementedwith
1097

--- Page 1127 ---

1098 Chapter23 ParallelandDistributedTransactionProcessing
heterogeneous distributed databases. Replicationwith weak degreesof consistency is
discussedinSection23.6.
Mosttechniquesfordealingwithdistributeddatarequiretheuseofcoordinatorsto
ensureconsistentandefficienttransactionprocessing.InSection23.7wediscusshow
coordinatorscanbechoseninadistributedfashion,robusttofailures.Finally,Section
23.8describesthedistributed consensusproblem,outlinessolutionsfortheproblem,
andthendiscusseshowthesesolutionscanbeusedtoimplementfault-tolerantservices
bymeansofreplicationofalog.
23.1 Distributed Transactions
Accesstothevariousdataitemsinadistributedsystemisusuallyaccomplishedthrough
transactions, which must preserve the ACID properties (Section 17.1). There are two
types of transaction that we need to consider. The local transactions are those that
accessandupdatedatainonlyonelocaldatabase;theglobaltransactionsarethosethat
accessandupdatedatainseverallocaldatabases.EnsuringtheACIDpropertiesofthe
local transactions can be done as described in Chapter 17, Chapter 18, and Chapter
19.However,forglobaltransactions,thistaskismuchmorecomplicated,sinceseveral
nodes may be participating in the execution of the transaction. The failure of one of
thesenodes,orthefailureofacommunicationlinkconnectingthesenodes,mayresult
inerroneouscomputations.
In this section, we study the system structure of a distributed database and its
possiblefailuremodes.Inlatersections,wediscusshowtoensureACIDpropertiesare
satisfied in a distributed database, despite failures. We reemphasize that these failure
modesoccurwithparalleldatabasesaswell,andthetechniqueswedescribeareequally
applicabletoparalleldatabases.
23.1.1 System Structure
Wenowconsiderasystem structure withmultiplenodes,eachofwhichcanfailinde-
pendently of the others. We note that the nodes may be within a single data center,
corresponding to a parallel database system, or geographically distributed, in a dis-
tributed database system. The system structure issimilarin eithercase; the problems
with respect to transaction isolation and atomicity are the same in both cases, as are
thesolutions.
We note that the system structure we consider here is not applicable to a shared-
memoryparalleldatabasesystemwhosecomponentsdonothaveindependentmodes
offailures.Insuchsystemseitherthewholesystemisup,orthewholesystemisdown.
Further,thereisusuallyonlyonetransactionlogusedforrecovery.Concurrencycon-
trolandrecoverytechniquesthataredesignedforcentralizeddatabasesystemscanbe
usedinsuchsystems,andarepreferabletotechniquesdescribedinthischapter.
Eachnodehasitsownlocal transactionmanager,whosefunctionistoensurethe
ACID properties of those transactions that execute at that node. The various trans-

--- Page 1128 ---

23.1 DistributedTransactions 1099
transaction
TC1 TC
n coordinator
transaction
TM1 TM
n manager
computer 1 computer n
Figure 23.1 Systemarchitecture.
action managers cooperate to execute global transactions. To understand how such a
manager can be implemented, consideran abstract model of a transaction system, in
whicheachnodecontainstwosubsystems:
• Thetransactionmanagermanagestheexecutionofthosetransactions(orsubtrans-
actions)thataccessdatastoredinthenode.Notethateachsuchtransactionmay
beeitheralocaltransaction(i.e.,atransactionthatexecutesatonlythatnode)or
partofaglobaltransaction(i.e.,atransactionthatexecutesatseveralnodes).
• Thetransactioncoordinatorcoordinatestheexecutionofthevarioustransactions
(bothlocalandglobal)initiatedatthatnode.
TheoverallsystemarchitectureappearsinFigure23.1.
Thestructureofatransactionmanagerissimilarinmanyrespectstothestructure
ofacentralizedsystem.Eachtransactionmanagerisresponsiblefor:
• Maintainingalogforrecoverypurposes.
• Participatinginanappropriateconcurrency-controlschemetocoordinatethecon-
currentexecutionofthetransactionsexecutingatthatnode.
As we shall see, we need to modify both the recovery and concurrency schemes to
accommodatethedistributedexecutionoftransactions.
The transaction coordinator subsystem is not needed in the centralized environ-
ment,sinceatransactionaccessesdataatonlyasinglenode.Atransactioncoordinator,
asitsnameimplies,isresponsibleforcoordinatingtheexecutionofallthetransactions
initiatedatthatnode.Foreachsuchtransaction,thecoordinatorisresponsiblefor:

--- Page 1129 ---

1100 Chapter23 ParallelandDistributedTransactionProcessing
• Startingtheexecutionofthetransaction.
• Breakingthetransactionintoanumberofsubtransactions anddistributingthese
subtransactionstotheappropriatenodesforexecution.
• Coordinatingtheterminationofthetransaction,whichmayresultinthetransac-
tionbeingcommittedatallnodesorabortedatallnodes.
23.1.2 System Failure Modes
A distributed system may suffer from the same types of failure that a centralized sys-
temdoes(e.g.,softwareerrors,hardwareerrors,ordiskcrashes).Thereare,however,
additional types of failure with which we need to deal in a distributed environment.
Thebasicfailuretypesare:
• Failureofanode.
• Lossofmessages.
• Failureofacommunicationlink.
• Networkpartition.
Thelossorcorruptionofmessagesisalwaysapossibilityinadistributed system.
Thesystemusestransmission-controlprotocols,suchasTCP/IP,tohandlesucherrors.
Informationaboutsuchprotocolsmaybefoundinstandardtextbooksonnetworking.
However,iftwonodesAandBarenotdirectlyconnected,messagesfromonetothe
othermustberoutedthroughasequenceofcommunicationlinks.Ifacommunication
linkfails,messagesthatwouldhavebeentransmittedacrossthelinkmustbererouted.
In some cases, it is possible to find another route through the network, so that the
messages are able to reach their destination. In other nodes, a failure may result in
there being no connection between some pairs of nodes. A system is partitioned if it
hasbeensplitintotwo(ormore)subsystems,calledpartitions,thatlackanyconnection
betweenthem.Notethat,underthisdefinition,apartitionmayconsistofasinglenode.
23.2 Commit Protocols
If we are to ensure atomicity, all the nodes in which a transaction T executed must
agree on the final outcome of the execution. T must either commit at all nodes, or it
mustabortatallnodes.Toensurethisproperty,thetransactioncoordinatorofT must
executeacommitprotocol.
Amongthesimplestandmostwidelyusedcommitprotocolsisthetwo-phasecom-
mitprotocol(2PC),whichisdescribedinSection23.2.1.

--- Page 1130 ---

23.2 CommitProtocols 1101
23.2.1 Two-Phase Commit
We first describe how the two-phase commit protocol (2PC) operates during normal
operation,thendescribehowithandlesfailuresandfinallyhowitcarriesoutrecovery
andconcurrencycontrol.
Consider a transaction T initiated at node N, where the transaction coordinator
i
isC.
i
23.2.1.1 TheCommitProtocol
WhenT completesitsexecution—thatis,whenallthenodesatwhichT hasexecuted
informC thatT hascompleted—C startsthe2PCprotocol.
i i
• Phase1.C addstherecord<prepareT>tothelogandforcesthelogontostable
i
storage.ItthensendsaprepareT messagetoallnodesatwhichT executed.
On receiving such a message, the transaction manager at that node determines
whether it is willing to commit its portion of T. If the answer is no, it adds a
record <no T> to the log and then responds by sending an abort T message to
C. Ifthe answerisyes, itaddsarecord<readyT>to thelogandforcesthe log
i
(withallthelogrecordscorrespondingtoT)ontostablestorage.Thetransaction
managerthenreplieswithareadyT messagetoC.
i
• Phase 2. When C receives ready responses to the prepare T message from all
i
the nodes, or when it receives an abort T message from at least one participant
node,C can determinewhetherthe transaction T can be committedoraborted.
i
Transaction T can be committed if C received a ready T message from all the
i
participatingnodes.Otherwise,transactionT mustbeaborted.Dependingonthe
verdict,eitherarecord <commit T>ora record <abort T>is addedto the log
andthelogisforcedontostablestorage.Atthispoint,thefateofthetransaction
hasbeensealed.
Followingthispoint,thecoordinatorsendseitheracommit T oranabortT
messagetoallparticipatingnodes.Whenanodereceivesthatmessage,itrecords
the result (either <commit T> or <abort T>) in its log, and correspondingly
eithercommitsorabortsthetransaction.
Since nodes may fail, the coordinator cannot wait indefinitely for responses
fromallthenodes.Instead,whenaprespecifiedintervaloftimehaselapsedsince
the prepare T message was sent out, if any node has not responded to the coor-
dinator, the coordinator can decide to abort the transaction; the steps described
forabortingthetransactionmustbefollowed,justasifanodehadsentanabort
messageforthetransaction.
Figure23.2showsaninstanceofsuccessfulexecutionof2PCforatransactionT,
withtwonodes,N andN ,thatarebothwillingtocommittransactionT.Ifanyofthe
1 2

--- Page 1131 ---

1102 Chapter23 ParallelandDistributedTransactionProcessing
Coordinator Node N Node N
1 2
Force log record
< prepare T >
Send message
prepare T
Force log record Force log record
< ready T > < ready T >
Send message Send message
ready T ready T
Force log record
< commit T >
Send message
commit T
Force log record Force log record
< commit T > < commit T >
Figure 23.2 Successfulexecutionof2PC.
nodessendsanoT message,thecoordinatorwillsendanabortT messagetoallthe
nodes,whichwillthenabortthetransaction.
AnodeatwhichT executedcanunconditionallyabortT atanytimebeforeitsends
the message ready T to the coordinator. Once the <ready T> log record is written,
the transaction T is said to be in the ready state at the node. The ready T message
is, in effect, a promise by a node to follow the coordinator’s order to commit T or to
abortT.Tomakesuchapromise,theneededinformationmustfirstbestoredinstable
storage.Otherwise,ifthenodecrashesaftersendingreadyT,itmaybeunabletomake
good on its promise. Further, locks acquired by the transaction must continue to be
helduntilthetransactioncompletes,evenifthereisaninterveningnodefailure,aswe
shallseeinSection23.2.1.3.

--- Page 1132 ---

23.2 CommitProtocols 1103
Sinceunanimityisrequiredtocommitatransaction,thefateofT issealedassoon
as at least one node responds abort T. Since the coordinator node N is one of the
i
nodes at which T executed, the coordinator can decide unilaterally to abort T. The
final verdict regarding T is determined at the time that the coordinator writes that
verdict(commitorabort)tothelogandforcesthatverdicttostablestorage.
In some implementations of the 2PC protocol, a node sends an acknowledge T
message tothecoordinatorattheendofthesecondphaseoftheprotocol.Whenthe
coordinatorreceivestheacknowledgeT messagefromallthenodes,itaddstherecord
<complete T> to the log. Until this step, the coordinator cannot forget about the
commit or abort decision on T, since a node may ask for the decision. (A node that
hasnotreceivedacommitorabortfortransactionT,perhapsduetoanetworkfailure
ortemporarynodefailure,maysendsucharequesttothecoordinator.)Afterthisstep,
thecoordinatorcandiscardinformationabouttransactionT.
23.2.1.2 HandlingofFailures
The2PCprotocolrespondsindifferentwaystovarioustypesoffailure:
• Failureofaparticipatingnode.IfthecoordinatorC detectsthatanodehasfailed,
i
ittakestheseactions:IfthenodefailsbeforerespondingwithareadyT message
toC,thecoordinatorassumesthatitrespondedwithanabortT message.Ifthe
i
nodefailsafterthecoordinatorhasreceivedthereadyT messagefromthenode,
the coordinator executes the rest of the commit protocol in the normal fashion,
ignoringthefailureofthenode.
When aparticipatingnode N recoversfromafailure,itmust examine itslog
k
to determine the fate of those transactions that were in the midst of execution
whenthefailureoccurred.LetT beonesuchtransaction.Weconsidereachofthe
possiblecases:
° The log contains a <commit T> record. In this case, the node executes
redo(T).
° The log contains an <abort T> record. In this case, the node executes
undo(T).
° Thelogcontainsa<readyT>record.Inthiscase,thenodemustconsultC to
i
determinethefateofT.IfC isup,itnotifiesN regardingwhetherT committed
i k
oraborted.Intheformercase,itexecutesredo(T);inthelattercase,itexecutes
undo(T). IfC isdown, N must tryto find thefate of T from othernodes. It
i k
does so by sending a querystatus T message to all the nodes in the system.
Onreceivingsuchamessage,anodemustconsultitslogtodeterminewhether
T has executed there, and if T has, whether T committed or aborted. It then
notifies N about this outcome. If no node has the appropriate information
k
(i.e.,whetherT committedoraborted),thenN canneitherabortnorcommit
k
T. The decision concerning T is postponed until N can obtain the needed
k

--- Page 1133 ---

1104 Chapter23 ParallelandDistributedTransactionProcessing
information. Thus, N must periodically resend the querystatus message to
k
the other nodes. It continues to do so until a node that contains the needed
information hasrecovered.Note that thenode at whichC residesalways has
i
theneededinformation.
° The log contains no control records (abort, commit, ready) concerning T.
Thus, we know that N failed before responding to the prepare T message
k
from C. Since the failure of N precludes the sending of such a response, by
i k
ouralgorithmC mustabortT.Hence,N mustexecuteundo(T).
i k
• Failureofthecoordinator.Ifthecoordinatorfailsinthemidstoftheexecutionof
the commitprotocol fortransaction T,then the participatingnodes mustdecide
the fate of T. We shall see that, in certain cases, the participating nodes cannot
decidewhethertocommitorabortT,andthereforethesenodesmustwaitforthe
recoveryofthefailedcoordinator.
° If an active node contains a <commit T> record in its log, then T must be
committed.
° If an active node contains an <abort T> record in its log, then T must be
aborted.
° If some active node does not contain a <ready T>recordin its log,then the
failed coordinator C cannot have decided to commit T, because a node that
i
doesnothavea<readyT>recordinitslogcannothavesentareadyT mes-
sage to C. However, the coordinatormay have decidedtoabort T,but not to
i
commitT.RatherthanwaitforC torecover,itispreferabletoabortT.
i
° Ifnoneoftheprecedingcasesholds,thenallactivenodesmusthavea<ready
T>recordintheirlogs,butnoadditionalcontrolrecords(suchas<abortT>
or<commitT>).Sincethecoordinatorhasfailed,itisimpossibletodetermine
whetheradecisionhasbeenmade,andifonehas,whatthatdecisionis,until
thecoordinatorrecovers.Thus,theactivenodesmustwaitforC torecover.
i
Since the fate of T remains in doubt, T may continue to hold system re-
sources. For example, if locking is used, T may hold locks on data at active
nodes.Suchasituationisundesirable,becauseitmaybehoursordaysbefore
C is again active. During this time, other transactions may be forced to wait
i
for T. As a result, data items may be unavailable not only on the failed node
(C),butonactivenodesaswell.Thissituationiscalledtheblockingproblem,
i
becauseT isblockedpendingtherecoveryofnodeC.
i
• Networkpartition.Whenanetworkpartitionoccurs,twopossibilitiesexist:
1.Thecoordinatorandallitsparticipantsremaininonepartition.Inthiscase,
thefailurehasnoeffectonthecommitprotocol.

--- Page 1134 ---

23.2 CommitProtocols 1105
2.The coordinatorand itsparticipantsbelong to several partitions. Fromthe
viewpointofthenodesinoneofthepartitions,itappearsthatthenodesin
other partitions have failed. Nodes that are not in the partition containing
the coordinator simply execute the protocol to deal with the failure of the
coordinator.Thecoordinatorandthenodesthatareinthesamepartitionas
thecoordinatorfollowtheusualcommitprotocol,assumingthatthenodes
intheotherpartitionshavefailed.
Thus,themajordisadvantageofthe2PCprotocolisthatcoordinatorfailuremayresult
inblocking,whereadecisioneithertocommitortoabortT mayhavetobepostponed
untilC recovers.Wediscusshowtoremovethislimitationshortly,inSection23.2.2.
i
23.2.1.3 RecoveryandConcurrencyControl
Whenafailednoderestarts,wecanperformrecoverybyusing,forexample,therecov-
eryalgorithmdescribedinSection19.4.Todealwithdistributedcommitprotocols,the
recoveryproceduremusttreatin-doubttransactionsspecially;in-doubttransactionsare
transactions for which a <ready T> log record is found, but neither a <commit T>
logrecordnoran<abortT>logrecordisfound.Therecoveringnodemustdetermine
thecommit–abortstatusofsuchtransactionsbycontactingothernodes,asdescribed
inSection23.2.1.2.
If recovery is done as just described, however, normal transaction processing at
the node cannot begin until all in-doubt transactions have been committed or rolled
back. Finding the status of in-doubt transactions can be slow, since multiple nodes
may have to be contacted. Further, if the coordinator has failed, and no other node
hasinformationaboutthecommit–abortstatusofanincompletetransaction,recovery
potentially could become blocked if 2PC is used. As a result, the node performing
restartrecoverymayremainunusableforalongperiod.
Tocircumventthisproblem,recoveryalgorithmstypicallyprovidesupportfornot-
ing lock information in the log. (We are assuming here that locking is used for con-
currencycontrol.)Instead of writinga <ready T>logrecord,the algorithmwrites a
<ready T, L > log record, where L is a list of all write locks held by the transaction
T whenthelogrecordiswritten.Atrecoverytime,afterperforminglocalrecoveryac-
tions,foreveryin-doubttransactionT,allthewritelocksnotedinthe<readyT,L >
logrecord(readfromthelog)arereacquired.
Afterlockreacquisitioniscompleteforallin-doubttransactions, transaction pro-
cessing can start at the node, even before the commit–abort status of the in-doubt
transactionsisdetermined.Thecommitorrollbackofin-doubttransactionsproceeds
concurrentlywiththeexecutionofnewtransactions.Thus,noderecoveryisfasterand
nevergetsblocked.Notethatnewtransactionsthathavealockconflictwithanywrite
locksheldbyin-doubttransactionswillbeunabletomakeprogressuntiltheconflicting
in-doubttransactionshavebeencommittedorrolledback.

--- Page 1135 ---

1106 Chapter23 ParallelandDistributedTransactionProcessing
23.2.2 Avoiding Blocking During Commit
Theblockingproblemof2PCisaseriousconcernforsystemdesigners,sincethefailure
of a coordinator node could lead to blocking of a transaction that has acquired locks
onafrequentlyuseddataitem,whichinturnpreventsothertransactionsthatneedto
acquireaconflictinglockfromcompletingtheirexecution.
By involving multiple nodes in the commit decision step of 2PC, it is possible to
avoidblockingaslongasamajorityofthenodesinvolvedinthecommitdecisionare
alive and can communicate with each other. This is done by using the idea of fault-
tolerantdistributedconsensus.Detailsofdistributedconsensusarediscussedindetail
later,inSection23.8,butweoutlinetheproblemandsketchasolutionapproachbelow.
Thedistributedconsensusproblemisasfollows:Asetofnnodesneedtoagreeon
adecision;inthiscase,whetherornottocommitaparticulartransaction.Theinputs
to make the decision are provided to all the nodes, and then each node votes on the
decision;inthecaseof2PC,thedecisionisonwhetherornottocommitatransaction.
Thekeygoalofprotocolsforachievingdistributedconsensusisthatthedecisionshould
bemadeinsuchawaythatallnodeswill“learn”thesamevalueforthedecision(i.e.,
allnodeswilllearnthatthetransactionistobecommitted,orallnodeswilllearnthat
the transaction is to be aborted), even if some nodes fail during the execution of the
protocol, orthere are networkpartitions. Further, the distributed consensus protocol
shouldnotblock,aslongasamajorityofthenodesparticipatingremainaliveandcan
communicatewitheachother.
Thereareseveralprotocolsfordistributedconsensus,twoofwhicharewidelyused
today (Paxos and Raft). We study distributed consensus in Section 23.8. A key idea
behind these protocols is the idea of a vote, which succeeds only if a majority of the
participatingnodesagreeonaparticulardecision.
Given an implementation of distributed consensus, the blocking problem due to
coordinatorfailurecanbeavoidedasfollows:Insteadofthecoordinatorlocallydecid-
ing to commit or abort a transaction, it initiates the distributed consensus protocol,
requesting that the value “committed” or “aborted” be assigned to the transaction T.
Therequestissenttoallthenodesparticipatinginthedistributedconsensus,andthe
consensusprotocolisthenexecutedbythosenodes.Sincetheprotocolisfaulttolerant,
it will succeed even if some nodes fail, as long as a majority of the nodes are up and
remainconnected.Thetransactioncanbedeclaredcommittedbythecoordinatoronly
aftertheconsensusprotocolcompletessuccessfully.
Therearetwopossiblefailurescenarios:
• Thecoordinatorfailsatanystagebeforeinformingallparticipatingnodesofthecom-
mitorabortstatusofatransactionT.
Inthiscase,anewcoordinatorischosen(wewillseehowtodosoinSection
23.7).Thenewcoordinatorcheckswiththenodesparticipatinginthedistributed
consensus to see if a decision was made, and if so informs the 2PC participants

--- Page 1136 ---

23.2 CommitProtocols 1107
ofthedecision.Amajorityofthenodesparticipatinginconsensusmustrespond,
tocheckifadecisionwasmadeornot;theprotocolwillnotblockaslongasthe
failed/disconnectednodesareinaminority.
If no decision was made earlier for transaction T, the new coordinator again
checkswiththe 2PCparticipantstocheckiftheyare readytocommitorwish to
abort the transaction, and follows the usual coordinator protocol based on their
responses. Asbefore,ifnoresponse isreceivedfromaparticipant,thenewcoor-
dinatormaychoosetoabortT.
• Thedistributedconsensusprotocolfailstoreachadecision.
Failureoftheprotocolcanoccurduetothefailureofsomeparticipatingnodes.
Itcouldalsooccurbecauseofconflictingrequests,noneofwhichgetsamajorityof
“votes”duringtheconsensusprotocol.For2PC,therequestnormallycomesfrom
a single coordinator, so such a conflict is unlikely. However, conflicting requests
canariseinrarecasesifacoordinatorfailsaftersendingoutacommitmessage,but
itscommitmessageisdeliveredlate;meanwhile,anew2PCcoordinatormakesan
abortdecisionsinceitcouldnotreachsomeparticipatingnodes.Evenwithsucha
conflict,thedistributedconsensusprotocolguaranteesthatonlyoneofthecommit
orabortrequestscansucceed,eveninthepresenceoffailures.Butifsomenodes
aredown,andneitherthecommitnortheabortrequestgetsamajorityvotefrom
nodesparticipatinginthedistributed consensus,itispossible fortheprotocolto
failtoreachadecision.
Regardlessofthereason,ifthedistributedconsensusprotocolfailstoreacha
decision,thenewcoordinatorjustre-initiatestheprotocol.
Note thatintheeventofanetworkpartition,anode thatgetsdisconnectedfrom
the majority of the nodes participating in consensus may not learn about a decision,
even if a decision was successfully made. Thus, transactions running at such a node
maybeblocked.
Failure of 2PC participants could make data unavailable, in the absence of repli-
cation. Distributed consensus can also be used to keep replicas of a data item in a
consistentstate,asweexplainlaterinSection23.8.4.
The ideaof distributed consensus tomake 2PCnonblockingwas proposed in the
1980s;itisused,forexample,intheGoogleSpannerdistributeddatabasesystem.
The three-phase commit (3PC) protocol is an extension of the two-phase commit
protocol that avoids the blockingproblem under certain assumptions. One variant of
theprotocolavoidsblockingaslongasnetworkpartitionsdonotoccur,butitmaylead
toinconsistentdecisionsintheeventofanetworkpartition.Extensionsoftheprotocol
that work safely under network partitioning were developed subsequently. The idea
behindtheseextensionsissimilartothemajorityvotingideaofdistributedconsensus,
buttheprotocolsarespecificallytailoredforthetaskofatomiccommit.

--- Page 1137 ---

1108 Chapter23 ParallelandDistributedTransactionProcessing
23.2.3 Alternative Models of Transaction Processing
With two-phase commit, participating nodes agree to let the coordinator decide the
fate of a transaction, and are forced to waitfor the decisionof the coordinator, while
holdinglocksonupdateddataitems.Whilesuchlossofautonomymaybeacceptable
withinanorganization,noorganizationwouldbewillingtoforceitscomputerstowait,
potentially for a long time, while a computer at another organization makes the deci-
sion.
In this section, we describe how to use persistent messaging to avoid the problem
of distributed commit. To understand persistent messaging, consider how one might
transferfundsbetweentwodifferentbanks,eachwithitsowncomputer.Oneapproach
istohaveatransactionspanthetwonodesandusetwo-phasecommittoensureatomic-
ity.However,thetransactionmayhavetoupdatethetotalbankbalance,andblocking
could have a serious impact on all other transactions at each bank, since almost all
transactionsatthebankwouldupdatethetotalbankbalance.
In contrast, consider how funds transfer by a bank check occurs. The bank first
deducts the amount of the check from the available balance and prints out a check.
Thecheckisthenphysicallytransferredtotheotherbankwhereitisdeposited.After
verifying thecheck,thebank increasesthelocal balanceby theamount of thecheck.
The check constitutes a message sent between the two banks. So that funds are not
lost or incorrectly increased, the check must not be lost and must not be duplicated
anddepositedmorethanonce.Whenthebankcomputersareconnectedbyanetwork,
persistentmessagesprovidethesameserviceasthecheck(butmuchfaster).
Persistent messages are messages that are guaranteed to be delivered to the re-
cipient exactly once (neither less nor more), regardless of failures, if the transaction
sending the message commits, and are guaranteed to not be delivered if the transac-
tionaborts.Databaserecoverytechniquesareusedtoimplementpersistentmessaging
on top of the normal network channels, as we shall see shortly. In contrast, regular
messagesmaybelostormayevenbedeliveredmultipletimesinsomesituations.
Errorhandlingismorecomplicatedwithpersistentmessagingthanwithtwo-phase
commit.Forinstance,iftheaccountwherethecheckistobedepositedhasbeenclosed,
thecheckmustbesentbacktotheoriginatingaccountandcreditedbackthere.Both
nodes must, therefore,be provided with error-handlingcode, along with code to han-
dle the persistent messages. In contrast, with two-phase commit, the error would be
detected by the transaction, which would then never deduct the amount in the first
place.
Thetypesofexceptionconditionsthatmayarisedependontheapplication,soit
isnotpossibleforthedatabasesystemtohandleexceptionsautomatically.Theapplica-
tionprogramsthatsendandreceivepersistentmessagesmustincludecodetohandle
exception conditions and bring the system back to a consistent state. For instance, it
isnotacceptabletojustlosethemoneybeingtransferredifthereceivingaccounthas
beenclosed;themoneymustbecreditedbacktotheoriginatingaccount,andifthatis
notpossibleforsomereason,humansmustbealertedtoresolvethesituationmanually.

--- Page 1138 ---

23.2 CommitProtocols 1109
Atomic Transaction at Sending Node Atomic Transaction at Receiving Node
Perform database updates Process any unprocessed message in
Write message to messages_to_send relation received_messages
Mark message as processed
messages_to_send received _messages
Message Delivery Process Message Receiving Process
Monitor messages_to_send relation On receiving message, execute transaction to
Send any new messages to recipient add message to received_messages relation,
Also periodically resend old messages if not already present
When Acknowledgment received from recipient, After transaction commits, send
for a message, delete message Acknowledgement
Figure 23.3 Implementationofpersistentmessaging.
Therearemanyapplicationswherethebenefitofeliminatingblockingiswellworth
theextraefforttoimplementsystemsthatusepersistentmessages.Infact,feworgani-
zationswouldagreetosupporttwo-phasecommitfortransactionsoriginatingoutside
theorganization,sincefailurescouldresultinblockingofaccesstolocaldata.Persis-
tentmessagingthereforeplaysanimportantroleincarryingouttransactionsthatcross
organizationalboundaries.
We now consider the implementation of persistent messaging. Persistent messag-
ing can be implemented on top of an unreliable messaging infrastructure, whichmay
lose messages or deliver them multiple times. Figure 23.3 shows a summary of the
implementation,whichisdescribedindetailnext.
• Sending node protocol. When a transaction wishes to send a persistent message,
it writes a record containing the message in a special relation messages tosend,
instead of directly sending out the message. The message is also given a unique
messageidentifier.Notethatthisrelationactsasamessageoutbox.
A message delivery process monitors the relation, and when a new message is
found, it sends the message to its destination. The usual database concurrency-
control mechanisms ensure that the system process reads the message only after
thetransactionthatwrotethemessagecommits;ifthetransactionaborts,theusual
recoverymechanismwoulddeletethemessagefromtherelation.
Themessagedeliveryprocessdeletesamessagefromtherelationonlyafterit
receivesanacknowledgmentfromthedestinationnode.Ifitreceivesnoacknowl-
edgment from the destination node, after some time it sends the message again.
Itrepeatsthisuntilanacknowledgmentisreceived.Incaseofpermanentfailures,

--- Page 1139 ---

1110 Chapter23 ParallelandDistributedTransactionProcessing
the system will decide, after some period of time, that the message is undeliver-
able.Exceptionhandlingcodeprovidedbytheapplicationistheninvokedtodeal
withthefailure.
Writingthemessagetoarelationandprocessingitonlyafterthetransactionhas
committedensuresthatthemessagewillbedeliveredifandonlyifthetransaction
commits. Repeatedly sending it guarantees it will be delivered even if there are
(temporary)systemornetworkfailures.
• Receivingnodeprotocol.Whenanodereceivesapersistentmessage,itrunsatrans-
actionthataddsthemessagetoaspecialreceived messagesrelation,provideditis
notalreadypresentintherelation(theuniquemessageidentifierallowsduplicates
to be detected). The relation has an attribute to indicateif the message has been
processed,whichissettofalsewhenthemessageisinsertedintherelation.Note
thatthisrelationactsasamessageinbox.
After the transaction commits, or if the message was already present in the
relation,thereceivingnodesendsanacknowledgmentbacktothesendingnode.
Notethatsendingtheacknowledgmentbeforethetransactioncommitsisnot
safe, since a system failure may then result in loss of the message. Checking
whether the message has been received earlier is essential to avoid multiple de-
liveriesofthemessage.
• Processingofmessage.Receivedmessagesmustbeprocessedtocarryouttheac-
tions specified in the message. A process at the receiving node monitors the re-
ceived messagesrelationtocheckformessagesthathavenotbeenprocessed.When
itfindssuchamessage,themessageisprocessed,andaspartofthesametransac-
tionthatprocessesthemessage,theprocessedflagissettotrue.Thisensuresthat
amessageisprocessedexactlyonceafteritisreceived.
• Deletionofoldmessages.Inmanymessagingsystems,itispossibleformessagesto
getdelayedarbitrarily,althoughsuchdelaysareveryunlikely.Therefore,tobesafe,
themessagemustneverbedeletedfromthereceived messagesrelation.Deletingit
couldresultinaduplicatedeliverynotbeingdetected.Butasaresult,thereceived
messagesrelationmaygrowindefinitely.Todealwiththisproblem,eachmessage
isgivenatimestamp,andifthetimestampofareceivedmessageisolderthansome
cutoff, the message is discarded. All messages recorded in the received messages
relationthatareolderthanthecutoffcanbedeleted.
Workflowsprovideageneralmodelofdistributedtransactionprocessinginvolving
multiplenodesandpossiblyhumanprocessingofcertainsteps,andtheyaresupported
by application software used by enterprises. For instance, as we saw in Section 9.6.1,
when a bank receivesa loan application, there are many steps it must take, including
contactingexternalcredit-checkingagencies,beforeapprovingorrejectingaloanappli-
cation.Thesteps,together,formaworkflow.Persistentmessagingformstheunderlying
basisforsupportingworkflowsinadistributedenvironment.

--- Page 1140 ---

23.3 ConcurrencyControlinDistributedDatabases 1111
23.3 Concurrency Control in Distributed Databases
We now consider how the concurrency-control schemes discussed in Chapter 18 can
bemodifiedsothattheycanbeusedinadistributedenvironment.Weassumethateach
node participates in the execution of a commit protocol to ensure global transaction
atomicity.
Inthissection,weassumethatdataitemsarenotreplicated,andwedonotconsider
multiversiontechniques.Wediscusshowtohandlereplicaslater,inSection23.4,and
wediscussdistributedmultiversionconcurrencycontroltechniquesinSection23.5.
23.3.1 Locking Protocols
The various locking protocols described in Chapter 18 can be used in a distributed
environment.Wediscussimplementationissuesinthissection.
23.3.1.1 SingleLock-ManagerApproach
In the single lock-manager approach, the system maintainsa single lockmanager that
residesinasinglechosennode—sayN.Alllockandunlockrequestsaremadeatnode
i
N. When a transaction needs to lock a data item, it sends a lock request to N. The
i i
lockmanagerdetermineswhetherthelockcanbegrantedimmediately.Ifthelockcan
be granted, the lock manager sends a message to that effect to the node at which the
lockrequestwasinitiated.Otherwise,therequestisdelayeduntilitcanbegranted,at
whichtimeamessage issenttothenodeatwhichthelockrequestwasinitiated.The
transactioncanreadthedataitemfromanyoneofthenodesatwhichareplicaofthe
dataitemresides.Inthecaseofawrite,allthenodeswhereareplicaofthedataitem
residesmustbeinvolvedinthewriting.
Theschemehastheseadvantages:
• Simple implementation. This scheme requires two messages for handling lock re-
questsandonemessageforhandlingunlockrequests.
• Simpledeadlockhandling.Sincealllockandunlockrequestsaremadeatonenode,
thedeadlock-handlingalgorithmsdiscussedinChapter18canbeapplieddirectly.
Thedisadvantagesoftheschemeare:
• Bottleneck.ThenodeN becomesabottleneck,sinceallrequestsmustbeprocessed
i
there.
• Vulnerability. If the node N fails, the concurrency controller is lost. Either pro-
i
cessingmuststop,orarecoveryschememustbeusedsothatabackupnodecan
takeoverlockmanagementfromN,asdescribedinSection23.7.
i

--- Page 1141 ---

1112 Chapter23 ParallelandDistributedTransactionProcessing
23.3.1.2 DistributedLockManager
Acompromisebetweentheadvantagesanddisadvantagescanbeachievedthroughthe
distributed-lock-manager approach, in which the lock-manager function is distributed
overseveralnodes.
Each node maintains a local lock manager whose function is to administer the
lock and unlock requests for those data items that are stored in that node. When a
transaction wishes to lock a data item Q that resides at node N, a message is sent to
i
thelockmanageratnodeN requestingalock(inaparticularlockmode).Ifdataitem
i
Qislockedinanincompatiblemode,thentherequestisdelayeduntilitcanbegranted.
Once ithas determinedthat the lockrequest can be granted, the lockmanager sends
amessagebacktotheinitiatorindicatingthatithasgrantedthelockrequest.
Thedistributed-lock-managerschemehastheadvantageofsimpleimplementation,
anditreducesthedegreetowhichthecoordinatorisabottleneck.Ithasareasonably
lowoverhead,requiringtwomessagetransfersforhandlinglockrequests,andonemes-
sage transfer for handlingunlock requests. However, deadlockhandlingis more com-
plex, since the lock and unlock requests are no longer made at a single node: There
maybeinternodedeadlocksevenwhenthereisnodeadlockwithinasinglenode.The
deadlock-handling algorithms discussed in Chapter 18 must be modified, as we shall
discussinSection23.3.2,todetectglobaldeadlocks.
23.3.2 Deadlock Handling
Thedeadlock-preventionanddeadlock-detectionalgorithmsinChapter18canbeused
inadistributedsystem,withsomemodifications.
Considerfirstthedeadlock-preventiontechniques,whichwesawinSection18.2.1.
• Techniques for deadlock prevention based on lock ordering can be used in a dis-
tributedsystem,withnochangesatall.Thesetechniquespreventcycliclockwaits;
thefactthatlocksmaybeobtainedatdifferentnodeshasnoeffectonprevention
ofcycliclockwaits.
• Techniques based on preemption and transaction rollback can also be used un-
changed in a distributed system. In particular, the wait-die technique is used in
severaldistributedsystems.Recallthatthistechniqueallowsoldertransactionsto
waitforlocksheldbyyounger transactions,butifayounger transactionneedsto
waitforalockheldbyanoldertransaction,theyoungertransactionisrolledback.
Thetransactionthatisrolledbackmaysubsequentlybeexecutedagain;recallthat
it retains its original start time; if it is treated as a new transaction, it could be
rolled back repeatedly, and starve, even as other transactions make progress and
complete.
• Timeout-basedschemes,too,workwithoutanychangesinadistributedsystem.

--- Page 1142 ---

23.3 ConcurrencyControlinDistributedDatabases 1113
T T T T
1 2 2 4
T T T
5 3 3
site S site S
1 2
Figure 23.4 Local wait-forgraphs.
Deadlock-prevention techniques may result in unnecessary waiting and rollback
whenusedinadistributedsystem,justasinacentralizedsystem,
Wenowconsiderdeadlock-detectiontechniquesthatallowdeadlockstooccurand
detect them if they do. The main problem in a distributed system is deciding how to
maintain the wait-for graph. Common techniques for dealing with this issue require
thateachnodekeepalocalwait-forgraph.Thenodesofthegraphcorrespondtoallthe
transactions(localaswellasnonlocal)thatarecurrentlyeitherholdingorrequesting
anyoftheitemslocaltothatnode.Forexample,Figure23.4depictsasystemconsisting
oftwonodes,eachmaintainingitslocalwait-forgraph.NotethattransactionsT and
2
T appearinbothgraphs,indicatingthatthetransactionshaverequesteditemsatboth
3
nodes.
Theselocalwait-forgraphsareconstructed intheusual mannerforlocaltransac-
tionsanddataitems.WhenatransactionT onnodeN needsaresourceinnodeN ,
i 1 2
it sends a request message to node N . If the resource is held by transaction T, the
2 j
systeminsertsanedgeT → T inthelocalwait-forgraphofnodeN .
i j 2
Ifanylocalwait-forgraphhasacycle,adeadlockhasoccurred.Ontheotherhand,
the fact that there are no cycles in any of the local wait-for graphs does not mean
that there are no deadlocks. To illustrate this problem, we consider the local wait-for
graphsofFigure23.4.Eachwait-forgraphisacyclic;nevertheless,adeadlockexistsin
thesystem becausetheunionofthelocalwait-forgraphscontainsacycle.Thisgraph
appearsinFigure23.5.
T T T
1 2 4
T T
5 3
Figure 23.5 Globalwait-forgraphforFigure23.4.

--- Page 1143 ---

1114 Chapter23 ParallelandDistributedTransactionProcessing
In the centralized deadlock detection approach, the system constructs and main-
tains a global wait-for graph (the union of all the local graphs) in a single node: the
deadlock-detectioncoordinator.Sincethereiscommunicationdelayinthesystem,we
mustdistinguishbetweentwotypesofwait-forgraphs.Therealgraphdescribesthereal
butunknownstateofthesystematanyinstanceintime,aswouldbeseenbyanomni-
scientobserver.Theconstructedgraphisanapproximationgeneratedbythecontroller
duringtheexecutionofthecontroller’salgorithm.Obviously,thecontrollermustgen-
erate the constructed graph in such a way that, whenever the detection algorithm is
invoked,thereportedresultsarecorrect.Correctmeansinthiscasethat,ifadeadlock
exists, it is reported promptly, and if the system reports a deadlock, it is indeed in a
deadlockstate.
Theglobalwait-forgraphcanbereconstructedorupdatedundertheseconditions:
• Whenever a new edge is inserted in or removed from one of the local wait-for
graphs.
• Periodically,whenanumberofchangeshaveoccurredinalocalwait-forgraph.
• Wheneverthecoordinatorneedstoinvokethecycle-detectionalgorithm.
When the coordinator invokes the deadlock-detection algorithm, it searches its
global graph. If it finds a cycle, it selects a victim to be rolled back. The coordinator
mustnotifyallthenodesthataparticulartransactionhasbeenselectedasthevictim.
Thenodes,inturn,rollbackthevictimtransaction.
Thisschememayproduceunnecessaryrollbacksif:
• False cycles exist in the global wait-for graph. As an illustration, considera snap-
shotofthesystemrepresentedbythelocalwait-forgraphsofFigure23.6.Suppose
thatT releasestheresourcethatitisholdinginnodeN ,resultinginthedeletion
2 1
of the edge T → T in N . Transaction T then requests a resource held by T
1 2 1 2 3
at node N , resulting in the addition of the edge T → T in N . If the insert
2 2 3 2
T → T messagefromN arrivesbeforetheremoveT → T messagefromN ,
2 3 2 1 2 1
thecoordinatormaydiscoverthefalsecycleT → T → T aftertheinsert(but
1 2 3
before the remove). Deadlock recovery may be initiated, although no deadlock
hasoccurred.
Note that the false-cycle situation could not occur under two-phase locking.
The likelihood of false cycles is usually sufficiently low that they do not cause a
seriousperformanceproblem.
• A deadlock has indeed occurred and a victim has been picked, while one of the
transactionswasabortedforreasonsunrelatedtothedeadlock.Forexample,sup-
posethatnodeN inFigure23.4decidestoabortT .Atthesametime,thecoor-
1 2
dinatorhas discoveredacycleand haspickedT asavictim.Both T and T are
3 2 3
nowrolledback,althoughonlyT neededtoberolledback.
2

--- Page 1144 ---

23.3 ConcurrencyControlinDistributedDatabases 1115
T T
1 1
T T
2 3
S S
1 2
T
1
T T
2 3
coordinator
Figure 23.6 Falsecyclesintheglobalwait-forgraph.
Deadlockdetectioncanbedoneinadistributedmanner,withseveralnodestaking
onpartsofthetask,insteadofitbeingdoneatasinglenode.However,suchalgorithms
aremorecomplicatedandmoreexpensive.Seethebibliographicalnotesforreferences
tosuchalgorithms.
23.3.3 Leases
Oneoftheissueswithusinglockinginadistributedsystemisthatanodeholdingalock
mayfail,andnotreleasethelock.Thelockeddataitemcouldthusbecome(logically)
inaccessible,untilthefailednoderecoversandreleasesthelock,orthelockisreleased
byanothernodeonbehalfofthefailednode.
Ifanexclusivelockhasbeenobtainedonadataitem,andthetransactionisinthe
preparedstate, thelockcannotbe releaseduntilacommit/abortdecisionismadefor
thetransaction.However,inmanyothercasesitisacceptableforalockthathasbeen
grantedearliertoberevokedsubsequently.Insuchcases,theconceptofaleasecanbe
veryuseful.
A lease is a lock that is granted for a specific period of time. If the process that
acquiresaleaseneedstocontinueholdingthelockbeyondthespecifiedperiod,itcan
renewthelease.Aleaserenewalrequestissenttothelockmanager,whichextendsthe
lease and responds with an acknowledgmentas long as the renewal request comes in
time.However,ifthetimeexpires,andtheprocessdoesnotrenewthelease,thelease
issaidtoexpire,andthelockisreleased.Thus,anyleaseacquiredbyanodethateither
fails, or gets disconnected from the lock manager, is automatically released when the

--- Page 1145 ---

1116 Chapter23 ParallelandDistributedTransactionProcessing
leaseexpires. Thenodethatholdsaleaseregularlycomparesthecurrentleaseexpiry
timewithitslocalclocktodetermineifitstillhastheleaseortheleasehasexpired.
Oneoftheusesofleasesistoensurethatthereisonlyonecoordinatorforaproto-
colinadistributedsystem.Anodethatwantstoactascoordinatorrequestsanexclusive
lease on a data item associated with the protocol. If it gets the lease, it can act as co-
ordinatoruntiltheleaseexpires;aslongasitisactive,itrequestsleaserenewalbefore
the lease expires, and it continues to be the coordinator as long as the lock manager
permitstheleaserenewal.
If a node N acting as coordinator dies after the expiry of the lease period, the
1
lease automatically expires, and another node N that requests the lease can acquire
2
itand becomethecoordinator.Inmostprotocolsitisimportantthatthereshould be
onlyonecoordinatoratagiventime.Theleasemechanismguaranteesthis,aslongas
clocksaresynchronized.However,ifthecoordinator’sclockrunsslowerthanthelock
manager’sclock,asituationcanarisewherethecoordinatorthinksitstillhasthelease,
while the lock manager thinks the lease has expired. While clocks cannot be exactly
synchronized,in practicetheinaccuracyisnotvery high.Thelockmanagerwaitsfor
someextrawaittimeaftertheleaseexpirytimetoaccountforclockinaccuraciesbefore
itactuallytreatstheleaseasexpired.
Anodethatchecksthelocalclockanddecidesitstillhasaleasemaythentakea
subsequentactionascoordinator.Itispossiblethattheleasemayhaveexpiredbetween
whentheclockwascheckedandwhenthesubsequentactiontookplace,whichcould
result in the action taking place after the node is no longer the coordinator. Further,
even if the action took place while the node had a valid lease, a message sent by the
node may be delivered after a delay, by which time the node may have lost its lease.
Whileitispossibleforthenetworktodeliveramessagearbitrarilylate,thesystemcan
decideonamaximummessagedelaytime,andanymessagethatisolderisignoredby
therecipient;messageshavetimestampssetbythesender,whichareusedtodetectif
amessageneedstobeignored.
Thetimegapsduetotheabove twoissuescanbetakenintoaccountbychecking
thattheleaseexpiryisatleastsometimet′ intothefuturebeforeinitiatinganaction,
wheret′isaboundonhowlongtheactionwilltakeaftertheleasetimecheck,including
themaximummessagedelay.
We have assumed here that while coordinators may fail, the lock manager that
issuesleasesisable totolerate faults.WestudyinSection23.8.4how tobuildafault-
tolerantlockmanager;wenotethatthetechniquesdescribedinthatsectionaregeneral
purposeandcanbeusedtoimplementfault-tolerantversionsofanydeterministicpro-
cess,modeledasa“statemachine.”
23.3.4 Distributed Timestamp-Based Protocols
Theprincipalideabehindthetimestamp-basedconcurrencycontrolprotocolsinSec-
tion 18.5 is that each transaction is given a unique timestamp that the system uses in

--- Page 1146 ---

23.3 ConcurrencyControlinDistributedDatabases 1117
local unique site
timestamp identifier
global unique
identifier
Figure 23.7 Generationofuniquetimestamps.
deciding the serialization order. Our first task, then, in generalizing the centralized
scheme to a distributed scheme is to develop a scheme for generating unique times-
tamps.Wethendiscusshowthetimestamp-basedprotocolscanbeusedinadistributed
setting.
23.3.5 Generation of Timestamps
Therearetwoprimarymethodsforgeneratinguniquetimestamps,onecentralizedand
one distributed. In the centralized scheme, a single node distributes the timestamps.
Thenodecanusealogicalcounteroritsownlocalclockforthispurpose. Whilethis
schemeiseasytoimplement,failureofthenodewouldpotentiallyblockalltransaction
processinginthesystem.
Inthedistributedscheme,eachnodegeneratesauniquelocaltimestampbyusing
eithera logicalcounter or the local clock.We obtain the unique global timestamp by
concatenatingtheuniquelocaltimestampwiththenodeidentifier,whichalsomustbe
unique(Figure23.7).Ifanodehasmultiplethreadsrunningonit(asisalmostalways
thecasetoday),athreadidentifierisconcatenatedwiththenodeidentifier,tomakethe
timestampunique.Further,weassumethatconsecutivecallstogetthelocaltimestamp
withinanode/thread willreturn differenttimestamps; ifthisisnot guaranteed by the
localclock,thereturnedlocaltimestampvaluemayneedtobeincremented,toensure
twocallsdonotgetthesamelocaltimestamp.
The order of concatenation is important! We use the node identifier in the least
significantpositiontoensurethattheglobaltimestampsgeneratedinonenodearenot
alwaysgreaterthanthosegeneratedinanothernode.
Wemaystillhaveaproblemifonenodegenerateslocaltimestampsataratefaster
thanthatoftheothernodes.Insuchacase,thefastnode’slogicalcounterwillbelarger
thanthatofothernodes.Therefore,alltimestampsgenerated bythefastnodewillbe
larger than those generated by other nodes. What we need is a mechanism to ensure
that local timestamps are generated fairly across the system. There are two solution
approachesforthisproblem.
1. Keeptheclockssynchronizedbyusinganetworktimeprotocol,whichisastan-
dardfeatureincomputerstoday.Theprotocolperiodicallycommunicateswitha

--- Page 1147 ---

1118 Chapter23 ParallelandDistributedTransactionProcessing
servertofindthecurrenttime.Ifthelocaltimeisaheadofthetimereturnedby
theserver,thelocalclockissloweddown,whereasifthelocaltimeisbehindthe
timereturnedby theserver itisspeeded up, tobringitbackin synchronization
withthetimeattheserver.Sinceallnodesareapproximatelysynchronizedwith
theserver,theyarealsoapproximatelysynchronizedwitheachother.
2. WedefinewithineachnodeN alogicalclock(LC),whichgeneratestheunique
i i
local timestamp. The logical clock can be implemented as a counter that is in-
cremented after a new local timestamp is generated. To ensure that the various
logical clocks are synchronized, we require that a node N advance its logical
i
clockwheneveratransaction T withtimestamp < x,y >visits thatnode and x
i
isgreaterthanthecurrentvalueofLC.Inthiscase,nodeN advancesitslogical
i i
clocktothevaluex+1.Aslongasmessagesareexchangedregularly,thelogical
clockswillbeapproximatelysynchronized.
23.3.6 Distributed Timestamp Ordering
The timestamp ordering protocol can be easily extended to a parallel or distributed
databasesetting.Eachtransactionisassignedagloballyuniquetimestampatthenode
where it originates. Requests sent to other nodes include the transaction timestamp.
Eachnodekeepstrackofthereadandwritetimestampsofthedataitemsatthatnode.
Wheneveranoperationisreceivedbyanode,itdoesthetimestampchecksthatwesaw
inSection18.5.2,locally,withoutanyneedtocommunicatewithothernodes.
Timestampsmustbereasonablysynchronizedacrossnodes;otherwise,thefollow-
ing problem can occur. Suppose one node has a time significantlylaggingthe others,
and a transaction T gets its timestamp at that node n . Suppose the transaction T
1 1 1
failsatimestamptestonadataitemd becaused hasbeenupdatedbyatransactionT
i i 2
withahighertimestamp;T wouldberestartedwithanewtimestamp,butifthetime
1
at node n is not synchronized, the new timestamp may still be old enough to cause
1
the timestamp test to fail, and T would be restarted repeatedly until the time at n
1 1
advancesaheadofthetimestampofT .
2
Notethatasinthecentralizedcase,ifatransactionT readsanuncommittedvalue
i
writtenbyanothertransactionT,T cannotcommituntilT commits.Thiscanbeen-
j i j
suredeitherbymakingreadswaitforuncommittedwritestobecommitted,whichcan
be implemented using locking, or by introducing commit dependencies, as discussed
inSection18.5.Thewaitingtimecanbe exacerbated bythetimerequiredtoperform
2PC,ifthetransactionperformsupdatesatmorethanonenode.WhileatransactionT
i
isinthepreparedstate,itswritesarenotcommitted,soanytransactionwithahigher
timestampthatreadsanitemwrittenbyT wouldbeforcedtowait.
i
Wealsonote thatthemultiversion timestamporderingprotocol canbeused locally
ateachnode,withoutanyneedtocommunicatewithothernodes,similartothecase
ofthetimestamporderingprotocol.

--- Page 1148 ---

23.3 ConcurrencyControlinDistributedDatabases 1119
23.3.7 Distributed Validation
Wenowconsiderthevalidation-basedprotocol(alsocalledtheoptimisticconcurrency
control protocol) that we saw in Section 18.6. The protocol is based on three times-
tamps:
• ThestarttimestampStartTS(T).
i
• Thevalidationtimestamp,TS(T),whichisusedastheserializationorder.
i
• ThefinishtimestampFinishTS(T)whichidentifieswhenthewritesofatransac-
i
tionhavecompleted.
While we saw a serial version of the validation protocol in Section 18.6, where only
onetransactioncanperformvalidationatatime,thereareextensionstotheprotocolto
allowvalidationsofmultipletransactionstooccurconcurrently,withinasinglesystem.
Wenowconsiderhowtoadapttheprotocoltoadistributedsetting.
1. Validation is done locally at each node, with timestamps assigned as described
below.
2. In adistributed setting,the validation timestamp TS(T)can be assigned atany
i
of the nodes, but the same timestamp TS(T) must be used at all nodes where
i
validation is to be performed. Transactions must be serializable based on their
timestampsTS(T).
i
3. ThevalidationtestforatransactionT looksatalltransactionsT withTS(T)<
i j j
TS(T), to check if T either finished before T started, or has no conflicts with
i j i
T. The assumption is that once a particular transaction enters the validation
i
phase,notransactionwithalowertimestampcanenterthevalidationphase.The
assumption canbe ensuredinacentralizedsystem byassigningthetimestamps
inacriticalsection,butcannotbeensuredinadistributedsetting.
AkeyprobleminthedistributedsettingisthatatransactionT mayenterthe
j
validationphaseafteratransactionT,butwithTS(T)<TS(T).Itistoolatefor
i j i
T tobevalidatedagainstT.However,thisproblemcanbeeasilyfixedbyrolling
i j
backany transaction if, when itstarts validation ata node, atransaction witha
latertimestamphadalreadystartedvalidationatthatnode.
4. ThestartandfinishtimestampsareusedtoidentifytransactionsT whosewrites
j
would definitely have been seen by a transaction T. These timestamps must
i
be assigned locally at each node, and must satisfy StartTS(T) ≤ TS(T) ≤
i i
FinishTS(T).Eachnodeusesthesetimestampstoperformvalidationlocally.
i
5. When used in conjunction with 2PC, a transaction must first be validated and
thenenterthepreparedstate.Writescannotbecommittedatthedatabaseuntil

--- Page 1149 ---

1120 Chapter23 ParallelandDistributedTransactionProcessing
thetransactionentersthecommittedstatein2PC.SupposeatransactionT reads
j
an item updated by a transaction T that is in the prepared state and is allowed
i
to proceedusing theold value of thedata item (sincethe value generated by T
i
hasnotyetbeenwrittentothedatabase).Then,whentransactionT attemptsto
j
validate,itwillbeserializedafterT andwillsurelyfailvalidationifT commits.
i i
Thus,thereadbyT mayaswellbehelduntilT commitsandfinishesitswrites.
j i
The above behavior is the same as what would happen with locking, with write
locksacquiredatthetimeofvalidation.
Although full implementations of validation-based protocols are not widely used
in distributed settings, optimistic concurrencycontrol without read validation, which
wesawinSection18.9.3,iswidelyusedindistributedsettings.Recallthatthescheme
dependson storingaversionnumberwitheachdataitem,afeature thatissupported
by many key-value stores.1 Version numbers are incrementedeach timethe dataitem
isupdated.
Validation is performed at the time of writing the data item, which can be done
usingatest-and-setfunctionbasedonversionnumbers,thatissupportedbysomekey-
value stores. This function allows an update to a data item to be conditional on the
current version of the data item being the same as a specified version number. If the
currentversionnumberofthedataitemismorerecentthanthespecifiedversionnum-
ber, the update is not performed. For example, a transaction that read version 7 of a
dataitemcanperformawrite,conditionalontheversionstillbeingat7.Iftheitemhas
been updated meanwhile, the current version would not match, and the write would
fail;however,iftheversionnumberisstill7,thewritewouldbeperformedsuccessfully,
andtheversionnumberincrementedto8.
The test-and-set function can thus be used by applications to implement the lim-
ited form of validation-based concurrencycontrol, discussed in Section 18.9.3, at the
level of individual data items. Thereby, a transaction could read a value from a data
item,performcomputationlocally,andupdatethedataitemattheend,aslongasthe
value itreadhasnotchangedsubsequently. Thisapproachdoesnotguarantee overall
serializability,butitdoespreventthelost-updateanomaly.
HBase supports the test-and-set operation based on comparing values (similar to
the hardware test-and-set operation), whichis calledcheckAndPut(). Instead of com-
paringtoasystem-generated versionnumber,thecheckAndPut()invocationcanpass
in a column and a value; the update is performed only if the row has the specified
value for the specified column. The check and the update are performed atomically.
Avariant,checkAndMutate(),allowsmultiplemodificationstoarow,suchasadding
orupdatingacolumn,deletingacolumn,orincrementingacolumn,aftercheckinga
condition,asasingleatomicoperation.
1Notethatthisisnotthesameasmultiversioning,sinceonlyoneversionneedstobestored.

--- Page 1150 ---

23.4 Replication 1121
23.4 Replication
Oneofthegoalsinusingdistributeddatabasesishighavailability;thatis,thedatabase
must function almost all the time.In particular, since failuresare more likelyin large
distributedsystems,adistributeddatabasemustcontinuefunctioningevenwhenthere
arevarioustypesoffailures.Theabilitytocontinuefunctioningevenduringfailuresis
referredtoasrobustness.
Foradistributedsystemtoberobust,datamustbereplicated,allowingthedatato
beaccessibleevenifanodecontainingareplicaofthedatafails.
Thedatabasesystem mustkeeptrackofthelocationsofthereplicasofeachdata
iteminthedatabasecatalog.Replicationcanbeatthelevelofindividualdataitems,in
whichthecatalogwillhaveoneentryforeachdataitem,recordingthenodeswhereitis
replicated.Alternatively,replicationcanbedoneatthelevelofpartitionsofarelation,
withanentirepartitionreplicatedattwoormorenodes.Thecatalogwouldthenhave
oneentryforeachpartition,resultinginconsiderablyloweroverheadthanhavingone
entryforeachdataitem.
Inthissectionwefirstdiscuss(inSection23.4.1)issueswithconsistencyofvalues
betweenreplicas.Wethendiscuss(inSection23.4.2)howtoextendconcurrencycon-
troltechniquestodealwithreplicas,ignoringtheissueoffailures.Furtherextensions
of the techniques to handle failures but modifying how reads and writes are executed
aredescribedinSection23.4.3.
23.4.1 Consistency of Replicas
Giventhatadataitem(orpartition)isreplicated,thesystemshouldideallyensurethat
thecopieshavethesamevalue.Practically,giventhatsomenodesmaybedisconnected
ormayhavefailed,itisimpossibletoensurethatallcopieshavethesamevalue.Instead,
thesystemmustensurethatevenifsomereplicasdonothavethelatestvalue,readsof
adataitemgettoseethelatestvaluethatwaswritten.
More formally, the implementations of read and write operations on the replicas
of a data item must follow a protocol that ensures the following property, called lin-
earizability:Givenasetofreadandwriteoperationsonadataitem,
1. there must be a linear ordering of the operations such that each read in the or-
deringshould see thevalue writtenbythe mostrecentwriteprecedingthe read
(ortheinitialvalueifthereisnosuchwrite),and
2. ifanoperationo finishesbeforeanoperationo begins(basedonexternaltime),
1 2
theno mustprecedeo inthelinearorder.
1 2
Note that linearizability only addresses what happens to a single data item, and it is
orthogonaltoserializability.

--- Page 1151 ---

1122 Chapter23 ParallelandDistributedTransactionProcessing
Wefirstconsiderapproachesthatwriteallcopiesofadataitemanddiscusslimi-
tationsofthisapproach;inparticular,toensureavailabilityduringfailure,failednodes
needtoberemovedfromthesetofreplicas,whichcanbequitetrickyaswewillsee.
It is not possible, in general, to differentiate between node failure and network
partition.Thesystem canusuallydetectthatafailurehasoccurred,butitmaynotbe
able to identify the type of failure. For example, suppose that node N is not able to
1
communicate with N . It could be that N has failed. However, another possibility is
2 2
thatthelinkbetweenN andN hasfailed,resultinginnetworkpartition.Theproblem
1 2
ispartlyaddressedbyusingmultiplelinksbetweennodes,sothatevenifonelinkfails
thenodeswillremainconnected.However,multiplelinkfailurescanstilloccur,sothere
aresituationswherewecannotbesurewhetheranodefailureornetworkpartitionhas
occurred.
Thereareprotocolsfordataaccessthatcancontinueworkingevenifsomenodes
have failed, without any explicit actions to deal with the failures, as we shall see in
Section 23.4.3.1. These protocolsare based on ensuring a majorityof nodes are writ-
ten/read. With such protocols, actions to detect failed nodes and remove them from
the system can be done in the background, and (re)integration of new or recovered
nodesintothesystemcanalsobedonewithoutdisruptingprocessing.
Althoughtraditionaldatabasesystems placeapremiumonconsistency,thereare
many applications today that value availability more than consistency. The design of
replicationprotocolsisdifferentforsuchsystemsandisdiscussedinSection23.6.
In particular, one such alternative that is widely used for maintaining replicated
dataistoperformtheupdateonaprimarycopyofthedataitem,andallowthetrans-
action to commit without updating the other copies. However, the update is subse-
quently propagated to the other copies. Such propagation of updates, referred to as
asynchronousreplicationorlazypropagationofupdates,isdiscussedinSection23.6.2.
Onedrawbackof asynchronousreplicationisthatreplicasmaybe outofdate for
some time following each update. Another drawback is that if the primary copy fails
afteratransactioncommits,butbeforetheupdateswerepropagatedtothereplicas,the
updates of the committed transaction may not be visible to subsequent transactions,
leadingtoaninconsistency.
On the other hand, a major benefit of asynchronous replication is that exclusive
locks can be released as soon as the transaction commits on the primary copy. In
contrast, if other replicas have to be updated before the transaction commits, there
may be a significant delay in committing the transaction. In particular, if data is geo-
graphicallyreplicatedtoensureavailabilitydespitefailureofanentiredatacenter,the
networkround-triptimetoaremotedatacentercouldrangefromtensofmilliseconds
to nearby locations, up to hundreds of milliseconds for data centers that are on the
other side of the world. If a transaction were to hold a lock on a data item for this
duration, thenumberoftransactionsthatcanupdate thatdataitem wouldbelimited
toapproximately10to100transactionspersecond.Forcertainapplications,forexam-
ple,userdatainawebapplication,10to100transactionspersecondforasingledata
item isquite sufficient. However, for applications wheresome data items are updated

--- Page 1152 ---

23.4 Replication 1123
by a large number of transactions each second, holding locks for such a long time is
notacceptable.Asynchronousreplicationmaybepreferredinsuchcases.
23.4.2 Concurrency Control with Replicas
Wediscussseveral alternativeways of dealingwithlockinginthepresenceof replica-
tionofdataitems,inSection23.4.2.1toSection23.4.2.4.
In this section, we assume updates are done on all replicas of a data item. If any
node containingareplicaof adataitem hasfailed,orisdisconnectedfrom the other
nodes,thatreplicacannotbe updated. Wediscusshow toperform readsandupdates
inthepresenceoffailureslater,inSection23.4.3.
23.4.2.1 PrimaryCopy
Whenasystemusesdatareplication,wecanchooseoneofthereplicasofadataitemas
theprimarycopy.ForeachdataitemQ,theprimarycopyofQmustresideinprecisely
onenode,whichwecalltheprimarynodeofQ.
Whenatransaction needstolockadataitemQ, itrequests alockattheprimary
nodeofQ.Asbefore,theresponsetotherequestisdelayeduntilitcanbegranted.The
primary copy enables concurrency control for replicated data to be handled like that
for unreplicated data. Thissimilarityallowsfor a simple implementation. However, if
the primary node of Q fails, lock information for Q would be lost, and Q would be
inaccessible,eventhoughothernodescontainingareplicamaybeaccessible.
23.4.2.2 MajorityProtocol
Themajorityprotocolworksthisway:IfdataitemQisreplicatedinndifferentnodes,
thenalock-requestmessagemustbesenttomorethanone-halfofthennodesinwhich
Q is stored. Each lock manager determines whether the lock can be granted immedi-
ately(asfarasitisconcerned).Asbefore,theresponseisdelayeduntiltherequestcan
begranted.ThetransactiondoesnotoperateonQuntilithassuccessfullyobtaineda
lockonamajorityofthereplicasofQ.
We assume for now that writes are performed on all replicas, requiring all nodes
containingreplicastobeavailable.However,themajorbenefitofthemajorityprotocol
isthatitcanbeextendedtodealwithnodefailures,asweshallseeinSection23.4.3.1.
Theprotocolalsodealswithreplicateddatainadecentralizedmanner,thusavoiding
thedrawbacksofcentralcontrol.However,itsuffersfromthesedisadvantages:
• Implementation.Themajorityprotocolismorecomplicatedtoimplementthanare
thepreviousschemes.Itrequiresatleast2(n∕2 + 1)messagesforhandlinglock
requestsandatleast(n∕2 + 1)messagesforhandlingunlockrequests.
• Deadlockhandling.Inadditiontotheproblemofglobaldeadlocksduetotheuse
ofadistributed-lock-managerapproach,itispossibleforadeadlocktooccureven
if only one data item is being locked. As an illustration, consider a system with
fournodesandfullreplication.Suppose thattransactionsT andT wishtolock
1 2

--- Page 1153 ---

1124 Chapter23 ParallelandDistributedTransactionProcessing
dataitemQinexclusivemode.TransactionT maysucceedinlockingQatnodes
1
N and N , while transaction T may succeed in locking Q at nodes N and N .
1 3 2 2 4
Each then must wait to acquire the third lock; hence, a deadlock has occurred.
Luckily, we can avoid such deadlocks with relative ease by requiring all nodes to
requestlocksonthereplicasofadataiteminthesamepredeterminedorder.
23.4.2.3 BiasedProtocol
The biased protocol is another approach to handling replication. The difference from
the majority protocol is that requests for shared locks are given more favorable treat-
mentthanrequestsforexclusivelocks.
• Shared locks. When a transaction needs to lock data item Q, it simply requests a
lockonQfromthelockmanageratonenodethatcontainsareplicaofQ.
• Exclusive locks. When a transaction needs to lock data item Q, it requests a lock
onQfromthelockmanageratallnodesthatcontainareplicaofQ.
Asbefore,theresponsetotherequestisdelayeduntilitcanbegranted.
Thebiasedschemehastheadvantageofimposinglessoverheadonreadoperations
thandoesthemajorityprotocol.Thissavingsisespeciallysignificantincommoncases
inwhichthefrequencyofreadismuchgreaterthanthefrequencyofwrite.However,
theadditionaloverheadonwritesisadisadvantage.Furthermore,thebiasedprotocol
sharesthemajorityprotocol’sdisadvantageofcomplexityinhandlingdeadlock.
23.4.2.4 QuorumConsensusProtocol
Thequorumconsensus protocolisageneralizationofthemajorityprotocol.Thequo-
rum consensus protocol assigns each node a nonnegative weight. It assigns read and
write operations on an item x two integers, called read quorum Q and write quorum
r
Q , that must satisfy the following condition, where S is the total weight of all nodes
w
atwhichxresides:
Q +Q > S and2 ∗ Q > S
r w w
Toexecuteareadoperation,enoughreplicasmustbelockedthattheirtotalweight
isatleastQ .Toexecuteawriteoperation,enoughreplicasmustbelockedsothattheir
r
totalweightisatleastQ .
w
Abenefitofthequorumconsensusapproachisthatitcanpermitthecostofeither
read or write lockingto be selectivelyreducedby appropriately definingthe read and
write quorums. For instance, with a small read quorum, reads need to obtain fewer
locks, but the write quorum will be higher, hence writes need to obtain more locks.
Also, if higher weights are given to some nodes (e.g., those less likely to fail), fewer

--- Page 1154 ---

23.4 Replication 1125
nodesneedtobeaccessedforacquiringlocks.Infact,bysettingweightsandquorums
appropriately,thequorumconsensusprotocolcansimulatethemajorityprotocoland
thebiasedprotocols.
Likethemajorityprotocol,quorumconsensuscanbeextendedtoworkeveninthe
presenceofnodefailures,asweshallseeinSection23.4.3.1.
23.4.3 Dealing with Failures
Consider the followingprotocol to deal with replicated data. Writes must be success-
fullyperformedatallreplicasofadataitem.Readsmayreadfromanyreplica.When
coupledwithtwo-phaselocking,suchaprotocolwillensurethatreadswillseethevalue
writtenbythemostrecentwritetothesamedataitem.Thisprotocolisalsocalledthe
read one, write all copies protocol since all replicas must be written, and any replica
canberead.
Theproblem withthisprotocolliesinwhattodoifsome nodeisunavailable.To
allowworktoproceedintheeventoffailures,itmayappearthatwecanusea“readone,
writeallavailable”protocol.Inthisapproach,areadoperationproceedsasintheread
one,writeallscheme;anyavailablereplicacanberead,andareadlockisobtainedat
thatreplica.Awriteoperationisshippedtoallreplicas,andwritelocksareacquiredon
allthereplicas.Ifanodeisdown,thetransactionmanagerproceedswithoutwaitingfor
thenodetorecover.Whilethisapproachappearsveryattractive,itdoesnotguarantee
consistencyofwritesandreads.Forexample,atemporarycommunicationfailuremay
causeanodetoappeartobeunavailable,resultinginawritenotbeingperformed,but
whenthelinkisrestored,thenodeisnotawarethatithastoperformsomereintegration
actionstocatchuponwritesithaslost.Further,ifthenetworkpartitions,eachpartition
mayproceedtoupdatethesamedataitem,believingthatnodesintheotherpartitions
arealldead.
23.4.3.1 RobustnessUsingtheMajority-BasedProtocol
The majority-based approach to distributed concurrency control in Section 23.4.2.2
can be modified to work in spite of failures. In this approach, each data object stores
with it a version number to detect when it was last written. Whenever a transaction
writesanobjectitalsoupdatestheversionnumberinthisway:
• Ifdataobjectaisreplicatedinndifferentnodes,thenalock-requestmessagemust
besenttomorethanone-halfofthennodesatwhichaisstored.Thetransaction
doesnotoperateonauntilithassuccessfullyobtainedalockonamajorityofthe
replicasofa.
Updates to the replicascan be committed atomicallyusing 2PC. (We assume
fornowthatallreplicasthatwereaccessiblestayaccessibleuntilcommit,butwe

--- Page 1155 ---

1126 Chapter23 ParallelandDistributedTransactionProcessing
relax this requirement later in this section, where we also discuss alternatives to
2PC.)
• Read operations look at all replicason which a lock has been obtained and read
the value from the replicathat has the highest version number. (Optionally, they
mayalsowritethisvaluebacktoreplicaswithlowerversionnumbers.)Writesread
allthereplicasjustlikereadstofindthehighestversionnumber(thisstepwould
normallyhavebeenperformedearlierinthetransactionbyaread,andtheresult
can be reused). The new version number is one more than the highest version
number.Thewriteoperationwritesallthereplicasonwhichithasobtainedlocks
andsetstheversionnumberatallthereplicastothenewversionnumber.
Failures(whethernetworkpartitions or node failures)can be tolerated as longas (1)
thenodesavailableatcommitcontainamajorityofreplicasofalltheobjectswritten
to and (2) during reads, a majority of replicas are read to find the version numbers.
If these requirements are violated, the transaction must be aborted. As long as the
requirements are satisfied, the two-phase commit protocol can be used, as usual, on
thenodesthatareavailable.
In this scheme, reintegration is trivial; nothing needs to be done. This is because
writeswouldhave updated amajorityof thereplicas,whilereadswillreadamajority
ofthereplicasandfindatleastonereplicathathasthelatestversion.
However,themajorityprotocolusingversionnumbershassomelimitations,which
canbeavoidedbyusingextensionsorbyusingalternativeprotocols.
1. Thefirstproblemishowtodealwiththefailureofparticipantsduringanexecu-
tionofthetwo-phasecommitprotocol.
This problem can be dealt with by an extension of the two-phase commit
protocolthatallowscommittohappenevenifsomereplicasareunavailable,as
long as a majority of replicas of a partition confirm that they are in prepared
state. When participants recover or get reconnected, or otherwise discover that
theydonothavethelatestupdates,theyneedtoqueryothernodestocatchupon
missingupdates.Referencesthatprovidedetailsofsuchsolutionsmaybefound
inthebibliographicnotesforthischapter,availableonline.
2. The second problem is how to deal with the failure of the coordinator during
an execution of two-phase commit protocol, which could lead to the blocking
problem.Consensusprotocols,whichwestudyinSection23.8,providearobust
wayof implementingtwo-phase commitwithouttheriskofblockingeven ifthe
coordinatorfails,aslongasamajorityofthenodesareupandconnected,aswe
willseeinSection23.8.5.
3. Thethirdproblemisthatreadspayahigherprice,havingtocontactamajority
of the copies. We study approaches to reducing the read overhead in Section
23.4.3.2.

--- Page 1156 ---

23.4 Replication 1127
23.4.3.2 ReducingReadCost
Oneapproachtodealingwiththisproblemistousetheideaofreadandwritequorums
fromthequorumconsensusprotocol;readscanreadfromasmallerreadquorum,while
writes have to successfully write to a larger write quorum. There is no change to the
versionnumberingtechniquedescribedearlier.Thedrawbackofthisapproachisthat
ahigherwritequorumincreasesthechanceofblockingofupdatetransactions,dueto
failureordisconnectionofnodes.Asaspecialcaseofquorumconsensus,wegiveunit
weightstoallnodes,setthereadquorumto1,andsetthewritequorumton(allnodes).
Thiscorrespondstotheread-any-write-allprotocolwesawearlier.Thereisnoneedto
use version numbers with this protocol. However, if even a single node containing a
data item fails, no write to the item can proceed, since the write quorum will not be
available.
Asecondapproachistousetheprimarycopytechniqueforconcurrencycontrol
and force all updates to go through the primary copy. Reads can be satisfied by ac-
cessing only one node, in contrast to the majority or quorum protocols. However, an
issuewiththisapproachishowtohandlefailures.Iftheprimarycopynodefails,and
anothernodeisassignedtoactastheprimarycopy,itmustensurethatithasthelatest
versionofalldataitems.Subsequently,readscanbedoneattheprimarycopy,without
havingtoreaddatafromothercopies.
Thisapproachrequiresthattherebeatmostonenodethatcanactasprimarycopy
atatime,evenintheeventofnetworkpartitions.Thiscanbe ensuredusingleasesas
we saw earlier in Section 23.7. Furthermore, this approach requires an efficient way
for the new coordinator to ensure that it has the latest version of all data items. This
can be done by having a log at each node and ensuring the logs are consistent with
each other. This problem is by itself a nontrivial process, but it can be solved using
distributedconsensusprotocolswhichwestudyinSection23.8.Distributedconsensus
internallyusesamajorityschemetoensureconsistencyofthelogs.Butitturnsoutthat
ifdistributedconsensusisusedtokeeplogssynchronized,thereisnoneedforversion
numbering.
In fact, consensus protocols provide a way of implementingfault-tolerant replica-
tionofdata,asweseelaterinSection23.8.4.Manyfault-tolerantstoragesystemimple-
mentationstodayare builtusingfault-tolerantreplicationof databased on consensus
protocols.
Thereisavariantoftheprimarycopyscheme,calledthechainreplicationprotocol,
where the replicasare ordered. Each update is sent to the first replica,whichrecords
itlocallyandforwardsittothenextreplica,andsoon.Theupdateiscompletedwhen
thelast(tail)replicareceivestheupdate.Readsmustbeexecutedatthetailreplica,to
ensurethatonlyupdatesthathavebeenfullyreplicatedareread.Ifanodeinareplica
chain fails, reconfiguration is required to update the chain; further, the system must
ensure that any incomplete updates are completed before processing further updates.
Optimizedversionsofthechainreplicationschemeareusedinseveralstoragesystems.

--- Page 1157 ---

1128 Chapter23 ParallelandDistributedTransactionProcessing
References providing more details of the chain replication protocol may be found in
theFurtherReadingsectionattheendofthechapter.
23.4.4 Reconfiguration and Reintegration
While nodes do fail, in most cases nodes recover soon, and the protocols described
earliercanensurethattheywillcatchupwithanyupdatesthattheymissed.
However, in some cases a node may fail permanently. The system must then be
reconfigured to remove failed nodes, and to allow other nodes to take over the tasks
assigned tothefailednode.Further,the database catalogmust be updated toremove
the failed node from the list of replicas of all data items (or relation partitions) that
werereplicatedatthatnode.
Asdiscussedearlier,anetworkfailuremayresultinanodeappearingtohavefailed,
evenifithasnotactuallyfailed.Itissafetoremovesuchanodefromthelistofreplicas;
reads will no longer be routed to the node even though it may be accessible, but that
willnotcauseanyconsistencyproblems.
If a failed node that was removed from the system eventually recovers, it must
be reintegrated into the system. When a failed node recovers, if it had replicasof any
partition or data item, it must obtain the current values of these data items it stores.
Thedatabaserecoverylogatalivesitecanbeusedtofindandperformallupdatesthat
happenedwhenthenodewasdown,
Reintegrationofanodeismorecomplicatedthanitmayseemtobeatfirstglance,
sincetheremaybeupdatestothedataitemsprocessedduringthetimethatthenode
is recovering. The database recovery log at a live site is used for catchingup with the
latestvaluesforalldataitemsatthenode.Onceithascaughtupwiththecurrentvalue
ofalldataitems,thenodeshouldbeaddedbackintothelistofreplicasfortherelevant
partitions/data items, so it will receive all future updates. Locks are obtained on the
partitions/dataitems,updatesuptothatpointareappliedfromthelog,andthenodeis
addedtothelistofreplicasforthepartitionsordataitems,beforereleasingthelocks.
Subsequent updates will be applied directly to the node, since it will be in the list of
replicas.
Reintegrationismucheasierwiththemajority-basedprotocolsinSection23.4.3.1,
sincetheprotocolcantoleratenodeswithout-of-datedata.Inthiscase,anodecanbe
reintegratedevenbeforecatchinguponupdates,andthenodecancatchupwithmissed
updatessubsequently.
Reconfigurationdependsonnodeshavinganup-to-dateversionofthecatalogthat
records what table partitions (or data items) are replicated at what nodes; thus infor-
mation must be consistent across all nodes in a system. The replication information
in the catalogcould be stored centrally, and consulted on each access, but such a de-
sign would not be scalable since the central node would be consulted very frequently
and would get overloaded. To avoid such a bottleneck, the catalog itself needs to be
partitioned,anditmaybereplicated,forexample,usingthemajorityprotocol.

--- Page 1158 ---

23.5 ExtendedConcurrencyControlProtocols 1129
23.5 Extended Concurrency Control Protocols
Inthissection,wedescribefurtherextensionstodistributedconcurrencycontrolproto-
cols.Wefirstconsidermultiversion2PL andhowitcanbeextendedtogetgloballycon-
sistent timestamps, in Section 23.5.1. Extensions of snapshot isolation to distributed
settings are described in Section 23.5.2. Issues in concurrency control in heteroge-
neous distributed databases, where each node may have its own concurrency control
technique,aredescribedinSection23.5.3.
23.5.1 Multiversion 2PL and Globally Consistent Timestamps
The multiversion two-phase locking (MV2PL) protocol, described in Section 18.7.2,
combines the benefits of lock-free read-only transactions with the serializability guar-
anteesoftwo-phaselocking.Read-onlytransactionsseeasnapshotatapointintime,
while update transactions use two-phase locking but create new versions of each
data item that they update. Recall that with this protocol, each transaction T gets a
i
unique timestamp CommitTS(T) (which could be a counter, instead of actual time)
i
at the time of commit. The transaction sets the timestamp of all items that it up-
dates to CommitTS(T). Only one transaction performs commit at a point in time;
i
this guarantees that once T commits, a read-only transaction T whose StartTS(T)
i j j
is set to CommitTS(T) will see committed values of all versions with timestamp ≤
i
CommitTS(T).
i
MV2PLcanbeextendedtoworkinadistributedsettingbyhavingacentralcoordi-
nator,thatassignsstartandcommittimestampsandensuresthatonlyonetransaction
canperformcommitatapointintime.However,theuseofacentralcoordinatorlimits
scalabilityinamassivelyparalleldatastoragesystem.
TheGoogleSpannerdatastoragesystempioneeredaversionoftheMV2PLsystem
that is scalable and uses timestamps based on real clock time. We study the Spanner
MV2PLimplementationintherestofthissection.
Supposeeverynodehasaperfectlyaccurateclock,andthatcommitprocessingcan
happeninstantlywithnodelaybetweeninitiationofcommitanditscompletion.Then,
when a transaction wants to commit, it gets a commit timestamp by just reading the
clockatanyonenodeatanytimeaftergettingalllocks,butbeforereleasinganylock.
Alldataitemversionscreatedbythetransactionusethiscommittimestamp.Transac-
tionscanbeserializedbythiscommittimestamp.Read-onlytransactionssimplyread
theclockwhentheystart anduseittogetasnapshotofthedatabase asoftheirstart
time.
If the clocks are perfectly accurate, and commitprocessingis instantaneous, this
protocol canbe used toimplement MV2PLwithoutany centralcoordination, making
itveryscalable.
Unfortunately, in the real world, the above assumptions do not hold, which can
leadtothefollowingproblems:

--- Page 1159 ---

1130 Chapter23 ParallelandDistributedTransactionProcessing
1. Clocks are never perfectly accurate, and the clock at each node may be a little
fastoralittleslowcomparedtootherclocks.
Thus, it is possible to have the following situation. Two update transactions
T and T , both write a data item x, with T writing it first, followed by T but
1 2 1 2
T may end up with alowercommittimestamp because it gotthe timestamp at
2
a different node than T . This situation is not consistent with the serialization
1
orderingofT andT ,anditcannothappenwithMV2PLinacentralizedsetting.
1 2
2. Commit processing takes time, which can cause read-only transactions to miss
updatesiftheprotocolisnotcarefullydesigned.Considerthefollowingsituation.
Aread-onlytransactionT withstarttimestampt readsdataitemxatnodeN ,it
1 1 1
ispossiblethatsoonaftertheread,anothertransactionT withCommitTS(T ) ≤
2 2
t (whichgotthecommittimestampatadifferentnodeN )maystillperforma
1 2
writeonx.Then,T shouldhavereadthevaluewrittenbyT ,butdidnotseeit.
1 2
Todealwiththefirstproblem,namely,thelackofclocksynchronization,Spanner
usesthefollowingtechniques.
• Spannerhasafewatomicclocksthatareveryaccurateateachdatacenteranduses
the time they provide, along with time information from the Global Positioning
system (GPS) satellites, which provides very accurate time information, to get a
verygoodestimateoftimeateachnode.Weusethetermtruetimetorefertothe
timethatwouldhavebeengivenbyanabsolutelyaccurateclock.
Each node periodically communicates with time servers to synchronize its
clock;iftheclockhasgonefasteritis(logically)sloweddown,andifitisslower,
itismoved forward to thetime from theserver. Inbetween synchronizationsthe
local clock continues to tick, advancing the local time. A clock that ticks slower
orfasterthanthecorrectrateresultsinlocaltimeatthenodethatisprogressively
behindoraheadofthetruetime.
• Thesecondkeytechniqueistomeasurelocalclockdrifteachtimethenodesyn-
chronizes with a time server and to use it to estimate the rate at which the lo-
cal clock loses or gains time. Using this information, the Spanner system main-
tainsavalueϵsuchthatifthelocalclocktimeist′,thetruetimet isboundedby
t′ −ϵ ≤ t ≤ t′ +ϵ.TheSpannersystem isabletokeeptheuncertaintyvalueϵto
lessthan10msectypically.TheTrueTimeAPIusedbySpannerallowsthesystem
togetthecurrenttimevalue,alongwithanupperboundontheuncertaintyinthe
timevalue.
• Thenextpieceofthesolutionisanideacalledcommitwait.Theideaisasfollows:
Afteralllockshavebeenacquiredatallnodes,thelocaltimet′ isreadatacoordi-
natornode.Wewouldliketousethetruetimeastimestamp,butwedon’thavethe
exactvalue.Instead,thehighestpossiblevalueoftruetime,namely,t′+ϵ,isused
asacommittimestampt .Thetransactionthenwaits,whileholdinglocks,untilit
c

--- Page 1160 ---

23.5 ExtendedConcurrencyControlProtocols 1131
issurethatthetruetimet is≥ t ;thisjustrequireswaitingforatimeinterval2ϵ,
c
calculatedasdescribedearlier.
What the commit wait guarantees is that if a transaction T has a commit
1
timestampt ,atthetruetimet alllockswereheldbyT .
c c 1
• Giventheabove,ifaversionx ofadataitemxhasatimestampt,wecansaythat
t
thatwasindeedthevalueofxattruetimet.Thisallowsustodefineasnapshotof
thedatabaseatatimet,containingthelatestversionsofalldataitemsasoftimet.
Adatabasesystemissaidtoprovideexternalconsistencyiftheserializationorder
isconsistentwiththereal-worldtimeorderinginwhichthetransactionscommit.
Spannerguaranteesexternalconsistencybyensuringthatthetimestampsusedto
define the transaction serialization order correspond to the true time when the
transactionscommit.
• Oneremainingissueisthattransactioncommitprocessingtakestime(particularly
sowhen2PCisused).Whileatransactionwithcommittimestamptiscommitting,
areadofxbyaread-onlytransactionwithtimestampt ≥tmaynotseetheversion
1
x,eitherbecausethetimestamphasnotyetbeenpropagatedtothenodewiththe
t
dataitemx,orthetransactionisinpreparedstate.
Todealwiththisproblem,readsthataskforasnapshotasoftimet aremade
1
to wait until the system is sure that no transactions with timestamp ≤ t are still
1
intheprocessofcommitting.Ifatransactionwithtimestampt ≤ t iscurrentlyin
1
thepreparedphaseof2PC,andwearenotsurewhetheritwillcommitorabort,a
readwithtimestamp t would havetowaituntilweknow thefinal commitstatus
1
ofthetransaction.
Read-onlytransactionscanbegivenasomewhatearliertimestamp,toguaran-
tee that they will not have to wait; the trade-off here is that to avoid waiting, the
transactionmaynotseethelatestversionofsomedataitems.
23.5.2 Distributed Snapshot Isolation
Sincesnapshotisolationiswidelyused,extendingittoworkinadistributedsettingisof
significantpracticalimportance.RecallfromSection18.8thatwhilesnapshotisolation
doesnotguaranteeserializability,itavoidsanumberofconcurrencyanomalies.
Ifeachnodeimplementssnapshotisolationindependently,theresultantschedules
can have anomalies that cannot occur in a centralized system. For example, suppose
two transactions, T and T run concurrently on node N , where T writes x and T
1 2 1 1 2
readsx;thusT wouldnotseeupdatesmadebyT tox.SupposealsothatT updatesa
2 1 1
dataitemyatnodeN ,andcommits,andsubsequentlyT readsyatnodeN .ThenT
2 2 2 2
wouldseethevalueofyupdatedbyT atN ,butnotseeT ’supdatetoxatN .Sucha
1 2 1 1
situationcouldneveroccurwhenusingsnapshotisolationatasinglenode.Thus,just
dependingonlocalenforcementofsnapshotisolationateachnodeisnotsufficientto
enforcesnapshotisolationacrossnodes.

--- Page 1161 ---

1132 Chapter23 ParallelandDistributedTransactionProcessing
Several alternative distributed snapshot isolation protocols have been proposed
in the literature. Since the protocols are somewhat complicated, we omit details, but
references with more details may be found in the bibliographic notes for this chap-
ter,availableonline.Someoftheseprotocolsallowlocaltransactionsateachnodeto
executewithoutanyglobalcoordinationstep;anextracostispaidonlybyglobaltrans-
actions,thatis,transactionsthatexecuteatmorethanonenode.Theseprotocolshave
been prototyped on several databases/data storage systems, such as SAP HANA and
HBase.
Therehasbeensomeworkonextendingdistributedsnapshotisolationprotocolsto
makethemserializable.Approachesexploredincludeaddingtimestampcheckssimilar
totimestampordering,creatingatransactiondependencygraphatacentralserver,and
checkingforcyclesinthegraph,amongotherapproaches.
23.5.3 Concurrency Control in Federated Database Systems
Recall from Section 20.5 that in many cases a distributed database has to be con-
structed by linking together multiple already-existing database systems, each with its
ownschemaandpossiblyrunningdifferentdatabase-managementsoftware.Recallthat
suchsystemsarecalledfederateddatabasesystemsorheterogeneousdistributeddatabase
systems,andtheyconsistofalayerofsoftwareontopoftheexistingdatabasesystems.
Transactionsinafederateddatabasemaybeclassifiedasfollows:
1. Localtransactions.Thesetransactionsareexecutedbyeachlocaldatabasesystem
outsideofthefederateddatabasesystem’scontrol.
2. Global transactions. These transactions are executed under the control of the
federateddatabasesystem.
The federated database system is aware of the fact that local transactions may run at
thelocalnodes,butitisnotawareofwhatspecifictransactionsarebeingexecuted,or
ofwhatdatatheymayaccess.
Ensuringthelocalautonomyofeachdatabasesystemrequiresthatnochangesbe
madetoitssoftware.Adatabasesystem atonenodethusisnotabletocommunicate
directlywithoneatanyothernodetosynchronizetheexecutionofaglobaltransaction
activeatseveralnodes.
Since the federated database system has no control over the execution of local
transactions,eachlocalsystemmustuseaconcurrency-controlscheme(e.g.,two-phase
lockingortimestamping)toensurethatitsscheduleisserializable.Inaddition,inthe
case of locking,the localsystem must be ableto guard againstthe possibilityof local
deadlocks.
Theguaranteeoflocalserializabilityisnotsufficienttoensureglobalserializability.
Asanillustration,considertwoglobaltransactionsT andT ,eachofwhichaccesses
1 2
andupdatestwodataitems,AandB,locatedatnodesN andN ,respectively.Suppose
1 2
thatthelocalschedulesareserializable.Itisstillpossibletohaveasituationwhere,at

--- Page 1162 ---

23.6 ReplicationwithWeakDegreesofConsistency 1133
node N , T follows T , whereas, at N , T follows T , resulting in a nonserializable
1 2 1 2 1 2
global schedule. Indeed, even if there is no concurrency among global transactions
(i.e.,aglobaltransactionissubmittedonlyafterthepreviousonecommitsoraborts),
localserializabilityisnotsufficienttoensureglobalserializability(seePracticeExercise
23.11).
Dependingontheimplementationofthelocaldatabasesystems,aglobaltransac-
tionmaynotbeabletocontrolthepreciselockingbehaviorofitslocalsubtransactions.
Thus, even if all local database systems follow two-phase locking, it may be possible
onlytoensurethateachlocaltransactionfollowstherulesoftheprotocol.Forexam-
ple,onelocaldatabasesystemmaycommititssubtransactionandreleaselocks,while
thesubtransactionatanotherlocalsystemisstillexecuting.Ifthelocalsystemspermit
control of locking behavior and all systems follow two-phase locking, then the feder-
ated database system can ensure that global transactions lock in a two-phase manner
andthelockpointsofconflictingtransactionswouldthendefinetheirglobalserializa-
tionorder.Ifdifferentlocalsystemsfollowdifferentconcurrency-controlmechanisms,
however,thisstraightforwardsortofglobalcontroldoesnotwork.
There are many protocols for ensuring consistency despite the concurrent execu-
tion of global and local transactions in federated database systems. Some are based
on imposing sufficient conditions to ensure global serializability. Others ensure only
a form of consistency weaker than serializability but achieve this consistency by less
restrictivemeans.
Thereareseveralschemestoensureglobalserializabilityinanenvironmentwhere
update transactions as well as read-only transactions can execute. Several of these
schemes are based on the idea of a ticket. A special data item called a ticket is cre-
ated in each local database system. Every global transaction that accesses data at a
node must write the ticket at that node. This requirement ensures that global trans-
actions conflict directly at every node they visit. Furthermore, the global transaction
managercancontroltheorderinwhichglobal transactionsareserialized,bycontrol-
lingtheorderinwhichtheticketsareaccessed.Referencestosuchschemesappearin
thebibliographicnotesforthischapter,availableonline.
23.6 Replication with Weak Degrees of Consistency
The replicationprotocolswehave seen so farguarantee consistency, even ifthereare
nodeandnetworkfailures.However,theseprotocolshaveanontrivialcost,andfurther
theymayblockifasignificantnumberofnodesfailorgetdisconnectedduetoanetwork
partition.Further,inthecaseofanetworkpartition,anodethatisnotinthemajority
partition would not only be unable to perform writes, but it would also be unable to
performevenreads.

--- Page 1163 ---

1134 Chapter23 ParallelandDistributedTransactionProcessing
Manyapplicationswishtohavehigheravailability,evenatthecostofconsistency.
Westudythetrade-offsbetweenconsistencyandavailabilityinthissection.
23.6.1 Trading Off Consistency for Availability
The protocolswe have seen sofar requirea (weighted)majorityof nodesbe in apar-
tition for updates to proceed. Nodes that are in a minority partition cannot process
updates;ifanetworkfailureresultsinmorethantwopartitions,nopartitionmayhave
a majority of nodes. Under such a situation, the system would be completelyunavail-
ableforupdates,anddependingontheread-quorum,mayevenbecomeunavailablefor
reads.Thewrite-all-availableprotocolwhichwesawearlierprovidesavailabilitybutnot
consistency.
Ideally,wewouldliketohaveconsistencyandavailability,eveninthefaceofpar-
titions. Unfortunately, this is not possible, a fact that is crystallized in the so-called
CAP theorem, which states that any distributed database can have at most two of the
followingthreeproperties:
• Consistency.
• Availability.
• Partition-tolerance.
TheproofoftheCAPtheoremusesthefollowingdefinitionofconsistency,withrepli-
cated data: an execution of a set of operations (reads and writes) on replicated data
is said to be consistent if its result is the same as if the operations were executed on
a single node, in a sequential order that is consistent with the ordering of operations
issuedbyeachprocess(transaction).Thenotionofconsistencyissimilartoatomicity
of transactions, but with each operation treated as a transaction, and is weaker than
theatomicitypropertyoftransactions.
In any large-scale distributed system, partitions cannot be prevented, and as a re-
sult, eitheravailabilityor consistency has to be sacrificed.The schemeswe have seen
earliersacrificeavailabilityforconsistencyinthefaceofpartitions.
Consider a web-based social-networking system that replicates its data on three
servers,andanetworkpartitionoccursthatpreventstheserversfromcommunicating
witheachother.Sincenoneofthepartitionshasamajority,itwouldnotbepossibleto
executeupdatesonanyofthepartitions.Ifoneoftheseserversisinthesamepartition
asauser,theuseractuallyhasaccesstodata,butwouldbeunabletoupdatethedata,
sinceanotherusermaybeconcurrentlyupdatingthesameobjectinanotherpartition,
whichcouldpotentiallyleadtoinconsistency.Inconsistencyisnotasgreatariskina
social-networking system as in a banking database. A designer of such a system may
decidethatauserwhocanaccessthesystemshouldbeallowedtoperformupdateson
whateverreplicasareaccessible,evenattheriskofinconsistency.

--- Page 1164 ---

23.6 ReplicationwithWeakDegreesofConsistency 1135
IncontrasttosystemssuchasbankingdatabasesthatrequiretheACIDproperties,
systems suchasthesocial-networkingsystem mentionedabovearesaidtorequirethe
BASEproperties:
• Basicallyavailable.
• Softstate.
• Eventuallyconsistent.
Theprimaryrequirementisavailability,evenatthecostofconsistency.Updatesshould
be allowed, even in the event of partitioning, following, for example, the write-all-
available protocol (which is similar to multimaster replication described in Section
23.6).Softstatereferstothepropertythatthestateofthedatabasemaynotbeprecisely
defined,witheachreplicapossiblyhavingasomewhatdifferentstateduetopartition-
ingofthenetwork.Eventuallyconsistentistherequirementthatonceapartitioningis
resolved,eventuallyallreplicaswillbecomeconsistentwitheachother.
Thislaststeprequiresthatinconsistentcopiesofdataitemsbeidentified;ifoneis
anearlierversionoftheother,theearlierversioncanbereplacedbythelaterversion.
It is possible, however, that the two copies were the result of independent updates to
a common base copy. A scheme for detecting such inconsistent updates, called the
version-vectorscheme,isdescribedinSection23.6.4.
Restoringconsistencyinthefaceofinconsistentupdatesrequiresthattheupdates
be merged in some way thatismeaningful to the application. We discuss possible so-
lutionsforresolutionofconflictingupdates,inSection23.6.5.
In general, no system designer wants to deal with the possibility of inconsistent
updates and the resultant problems of detection and resolution. Where possible, the
system should bekeptconsistent.Inconsistentupdatesareallowedonlywhenanode
isdisconnectedfromthenetwork,inapplicationsthatcantolerateinconsistency.
Somekey-valuestoressuchasApacheCassandraandMongoDBallowanapplica-
tiontospecifyhowmanyreplicasneedtobeaccessibletocarryoutawriteoperation
orareadoperation.Aslongasamajorityofreplicasareaccessible,thereisnoproblem
withconsistencyforwrites.However,iftheapplicationsetstherequirednumberatless
than a majority, and many replicasare inaccessible,updates are allowedto go ahead;
thereis,however,ariskofinconsistentupdates,whichmustberesolvedlater.
Forapplicationswhereinconsistencycancausesignificantproblems,orisharder
toresolve,systemdesignersprefertobuildfault-tolerantsystemsusingreplicationand
distributed consensus that avoid inconsistencies, even at the cost of potential non-
availability.
23.6.2 Asynchronous Replication
Many relational database systems support replication with weak consistency, which
cantakeoneofseveralforms.

--- Page 1165 ---

1136 Chapter23 ParallelandDistributedTransactionProcessing
Withasynchronousreplicationthedatabaseallowsupdatesataprimarynode(also
referredtoasthemasternode)andpropagatesupdatestoreplicasatothernodessub-
sequently; the transaction that performs the update can commit once the update is
performed at the primary, even before replicas are updated. Propagation of updates
aftercommitisalsoreferredtoaslazypropagation.Incontrast,thetermsynchronous
replicationreferstothecasewhereupdatesarepropagatedtootherreplicasaspartof
asingletransaction.
With asynchronous replication, the system must guarantee that once the trans-
action commits at the primary, the updates are eventually propagated to all replicas,
eveniftherearesystemfailuresinbetween.Laterinthissection,weshallseehowthis
propertyisguaranteedusingpersistentmessaging.
Sincepropagation ofupdatesisdoneasynchronously,areadatareplicamaynot
getthelatestversionofadataitem.Asynchronouspropagationofupdatesiscommonly
used to allow update transactions to commit quickly, even at the cost of consistency.
Asystemdesignermaychoosetousereplicasonlyforfaulttolerance.However,ifthe
replicaisavailableonalocalmachine,oranothermachinethatcanbe accessedwith
low latency, it may be much cheaper to read the data item at the replica instead of
reading it from the primary, as long as the application is willingto acceptpotentially
staledatavalues.
Datastorage systems based on asynchronous replicationmay allowdata itemsto
have versions, with associated timestamps. A transaction may then request a version
withrequiredfreshnessproperties,forexamplenotmorethan10minutesold.Ifalocal
replicahasaversionofthedataitemsatisfyingthefreshnesscriterion,itcanbeused;
otherwise,thereadmayhavetobesenttotheprimarynode.
Consider,forexample,anairlinereservationsitethatshowsthepricesofmultiple
flight options. Prices may vary frequently, and the system does not guarantee that a
user willactuallybe able tobook a ticketatthe price shown initially.Thus, itis quite
acceptable to show a price that is a few minutes old. Asynchronous replication is a
good solution for this application: price data can be replicated to a large number of
servers,whichsharetheloadofuserqueries;andpricedataareupdatedataprimary
nodeandreplicatedasynchronouslytoallotherreplicas.
Multiversion concurrency control schemes can be used to give a transaction-
consistent snapshot of the database to read-only transactions that execute at a replica;
thatis,thetransactionshouldseeallupdatesofalltransactionsuptosometransaction
in the serialization order and should not see any updates of transactions later in the
serializationorder.Themultiversion2PLscheme,describedinSection23.5.1,canbe
extended to allow a read-onlytransaction to access a replicathat may not have up-to-
date versions of some data items, but still get a transaction-consistent snapshot view
of the database. To do so, replicas must be aware of what is the latest timestamp t
safe
suchthattheyhavereceivedallupdateswithcommittimestampbeforet.Anyreadof
asnapshotwithtimestampt < t canbeprocessedbythatreplica.Suchaschemeis
safe
usedintheGoogleSpannerdatabase,

--- Page 1166 ---

23.6 ReplicationwithWeakDegreesofConsistency 1137
Asynchronous replication is used in traditional (centralized) databases to create
oneormorereplicasofthedatabase,onwhichlargequeriescanbeexecuted,without
interfering with transactions running on a primary node. Such replication is referred
tomaster-slavereplication,sincethereplicascannotperformanyupdatesontheirown
butmustonlyperformupdatesthatthemasternodeasksthemtoperform.
In such systems, asynchronous propagation of updates istypicallydone in acon-
tinuous fashion to minimize delays until an update is seen at a replica. However, in
datawarehouses,updatesmaybepropagatedperiodically—everynight,forexample—
sothatupdatepropagationdoesnotinterferewithqueryprocessing.
Some database systems support multimaster replication (also called update-
anywherereplication);updatesarepermittedatanyreplicaofadataitemandarepropa-
gatedtoallreplicaseithersynchronously,usingtwo-phasecommit,orasynchronously.
Asynchronous replication is also used in some distributed storage systems. Such
systemspartitiondata,aswehaveseenearlier,butreplicateeachpartition.Thereisa
primary node for each partition, and updates are typically sent to the primary node,
whichcommitstheupdateslocally,andpropagatesthemasynchronouslytotheother
replicas of the partition. Some systems such as PNUTS even allow each data item in
a partition to specify which node should act as the primary node for that data item;
thatnodeisresponsibleforcommittingupdatestothedataitem,andpropagatingthe
update to the other replicas. The motivation is to allow a node that is geographically
closetoausertoactastheprimarynodefordataitemscorrespondingtothatuser.
In any system supporting asynchronous propagation of updates, it is important
thatonceanupdateiscommittedattheprimary,itmustdefinitelybedeliveredtothe
otherreplicas.Iftherearemultipleupdatesataprimarynode,theymustbedelivered
in the same order to the replicas; out-of-order delivery can cause an earlier update to
arrivelateandoverwritealaterupdate.
Persistent messaging, which we saw in Section 23.2.3, provides guaranteed deliv-
eryofmessagesandiswidelyusedforasynchronousreplication.Theimplementation
techniquesforpersistentmessagesdescribedinSection23.2.3canbeeasilymodifiedto
ensurethatmessagesaredeliveredintheorderinwhichtheyweresent.Withpersistent
messaging,eachprimarynodeneedstobeawareofthelocationofallthereplicas.
Publish-subscribe systems, which we saw in Section 22.8.1, offer a more flexible
wayofensuringreliablemessagedelivery.Recallthatpublish-subscribesystemsallow
messagestobepublishedwithanassociatedtopic,andsubscriberscansubscribetoany
desiredtopic.Toimplementasynchronousreplication,atopiciscreatedcorresponding
toeachpartition.Allreplicasofapartitionsubscribetothetopiccorrespondingtothe
partition.Anyupdate(includinginserts,deletes,anddataitemupdates)toapartition
is published as a message with the topic corresponding to the partition. The publish-
subscribesystemensuresthatoncesuchamessageispublished,itwillbedeliveredto
allsubscribersintheorderinwhichitwaspublished.
Publish-subscribesystemsdesignedforparallelsystems,suchastheApacheKafka
system, or the Yahoo Message Bus service used for asynchronous replication in the
PNUTS distributed data storage system, allow a large number of topics, and use mul-

--- Page 1167 ---

1138 Chapter23 ParallelandDistributedTransactionProcessing
tiple servers to handle messages to different topics in parallel. Thus, asynchronous
replicationcanbemadescalable.
Faulttoleranceisanissuewithasynchronouspropagationofupdates.Ifaprimary
node fails, a new node must take over as primary; this can be done either using an
electionalgorithm,aswesawearlierorbyhavingamasternode(whichisitselfchosen
byelection)decidewhichnodetakesoverthejobofafailedprimarynode.
Consider what happens if a primary copy records an update but fails before the
update is sent to the replicas. The new primary node has no way of finding out what
wasthelastupdatecommittedattheprimarycopy.Itcaneitherwaitfortheprimaryto
recover,whichisunacceptable,oritcanproceedwithoutknowingwhatupdateswere
committedjustbeforefailure.Inthelattercase,thereisariskthatatransactiononthe
newprimarymayreadanoldvalueofadataitemorperformanupdatethatconflicts
withanearlierupdateontheoldprimary.
To reduce the chance of such problems, some systems replicate the log records
of the primary node to a backup node and allow the transaction to commit at the
primaryonlyafterthelogrecordhasbeensuccessfullyreplicatedatthebackupnode;
if the primary node fails, the backup node takes over as the primary. Recall that this
is the two-safe protocol from Section 19.7. This protocol is resilient to failure of one
node,butnottothefailureoftwonodes.
Ifanapplicationisbuiltontopofastoragesystemusingasynchronousreplication,
applicationsmaypotentiallyseesomeanomalousbehaviorssuchasareadnotseeing
the effect of an earlier write done by the same application, or a later read seeing an
earlierversionofadataitemthananearlierread,ifdifferentreadsandwritesaresent
todifferentreplicas.Whilesuchanomaliescannotbecompletelypreventedintheevent
of failures,they canbe avoidedduringnormal operation by takingsome precautions.
Forexample,ifreadandwriterequestsforadataitemfromaparticularnodearealways
senttothesamereplica,theapplicationwillseeanywritesithasperformed,andiftwo
reads are performed on the same data item, the later read will see a version at least
as new as the earlier read. This property is guaranteed if a primary replica is used to
performallactionsonadataitem.
23.6.3 Asynchronous View Maintenance
Indices and materialized views are forms of data derived from underlying data, and
can thus be viewed as forms of replicated data. Just like replicas, indices and materi-
alized views could be updated (maintained) as part of each transaction that updates
the underlying data; doing so would ensure consistency of the derived data with the
underlyingdata.
However,manysystemsprefertoperformindexandviewmaintenanceinanasyn-
chronous manner, to reduce the overhead on transactions that update the underlying
data.Asaresult,theindicesandmaterializedviewscouldbeoutofdate.Anytransac-

--- Page 1168 ---

23.6 ReplicationwithWeakDegreesofConsistency 1139
tion that uses such indices or materialized views must be aware that these structures
maybeoutofdate.
We now consider how to maintain indices and materialized views in the face of
concurrentupdates.
• The first requirement for view maintenance is for the subsystem that performs
maintenancetoreceiveinformationaboutupdatestotheunderlyingdatainsuch
awaythateachupdateisdeliveredexactlyonce,despitefailures.
Publish-subscribe systems are a good match for the first requirement above.
All updates to any underlying relation are published to the pub-sub system with
therelationnameasthetopic;theviewmaintenancesubsystemsubscribestothe
topicscorrespondingtoitsunderlyingrelationsandreceivedallrelevantupdates.
As we saw in Section 22.8.1, we can have topics corresponding to each tablet of
astored relation.Foranonmaterializedintermediaterelationthatispartitioned,
wecanhaveatopiccorrespondingtoeachpartition.
• The second requirement is for the subsystem to update the derived data in such
a way that the derived data will be consistent with the underlying data, despite
concurrentupdatestotheunderlyingdata.
Since the underlying data may receive further updates as an earlier update
is being processed, no asynchronous view maintenance technique can guarantee
thatthe view state isconsistent with the state of the underlyingdataat all times.
However, the consistency requirement can be formalized as follows: if there are
no updates to the underlying data for a sufficient amount of time, asynchronous
maintenance must ensure that the derived data is consistent with the underlying
data;sucharequirementisknownasaneventualconsistencyrequirement.
Thetechniqueforparallelmaintenanceofmaterializedviewswhichwesawin
Section 22.7.5 uses the exchange operator model to send updates to nodes and
allows view maintenance to be done locally. Techniques designed for view main-
tenanceinacentralizedsettingcanbeusedateachnode,onlocallymaterialized
input data. Recall from Section 16.5.1 that view maintenance may be deferred,
thatis,itmaybedoneafterthetransactioncommits.Techniquesfordeferredview
maintenanceinacentralizedsettingalreadyneedtodealwithconcurrentupdates;
suchtechniquescanbeusedlocallyateachnode.
• Athirdrequirementisforreadstogetaconsistentviewofdata.Ingeneral,aquery
thatreadsdatafrommultiplenodesmaynotobservetheupdatesofatransaction
T onnodeN ,butmayseetheupdatesthatT performedonnodeN ,thusseeing
1 2
a transactionally inconsistent view of data. Systems that use asynchronous repli-
cationtypicallydonotsupporttransactionallyconsistentviewsofthedatabase.
Further,scansofthedatabasemaynotseeanoperation-consistentviewofthe
database. (Recall the notion of operation consistency from Section 18.9, which
requiresthatanyoperationshouldnotseeadatabasestatethatreflectsonlysome
oftheupdatesofanotheroperation.InSection18.9wesawanexampleofascan

--- Page 1169 ---

1140 Chapter23 ParallelandDistributedTransactionProcessing
usinganindexthatcouldseetwoversions,orneitherversion,ofarecordupdated
byaconcurrenttransaction,iftherelationscandoesnotfollowtwo-phaselocking.
Asimilarproblemoccurswithasynchronouspropagationofupdates,evenifboth
therelationscanandtheupdatetransactionfollowtwo-phaselocking.
Forexample,considerarelationr(A,B,C),withprimarykeyA,whichisparti-
tionedonattributeB.Nowconsideraquerythatisscanningtherelationr.Suppose
thereisaconcurrentupdatetoatuplet ∈ r,whichupdatesattributet .Bfromv
1 1 1
to v . Such an update requires deletion of the old tuple from the partition corre-
2
spondingtovaluev ,andinsertionofthenewtupleinthepartitioncorresponding
1
tov .Theseupdatesarepropagatedasynchronously.
2
Now, the scan of r could possibly scan the node corresponding to v after
1
the old tuple is deleted there but visit the node corresponding to v before the
2
asynchronouspropagationinsertstheupdatedtupleinthatnode.Then,thescan
would completely miss the tuple, even though it should have seen either the old
valueorthenewvalueoft .Further,thescancouldvisitthenodecorresponding
1
tov beforethedeleteispropagatedtothatnode,andthenodecorrespondingto
1
v after the insert is propagated to that node, and thereby see two versions of t ,
2 1
one from before the update and one from after the update. Neither case would
bepossiblewithtwo-phaselocking,ifupdatesarepropagatedsynchronouslytoall
copies.
Ifamultiversionconcurrencycontroltechniqueisused,wheredataitemshave
timestamps, snapshot readsare agood way togetaconsistent scan ofarelation;
thesnapshottimestampshouldbesetasufficientlyoldvaluethatallupdatesasof
thattimestamphavereachedallreplicas.
23.6.4 Detecting Inconsistent Updates
Manyapplicationsdevelopedforsuchhighavailabilityaredesignedtocontinuefunc-
tioning locally even when the node running the application is disconnected from the
othernodes.
Asanexample,whendataarereplicated,andthenetworkgetspartitioned,ifasys-
tem chooses to trade off consistency to get availability, updates may be done concur-
rentlyatmultiplereplicas.Suchconflictingupdatesneedtobedetectedandresolved.
Whenaconnectionisre-established,theapplicationneedstocommunicatewithastor-
age system to send any updates done locally and fetch updates performed elsewhere.
Thereisapotentialforconflictingupdatesfromdifferentnodes.Forexample,nodeN
1
mayupdatealocallycachedcopyofadataitemwhileitisdisconnected;concurrently
anothernodemayhaveupdatedthedataitemonthestorage system,ormayhaveup-
dated itsown local copyof the dataitem. Such conflictingupdates must be detected,
andresolved.
As another example, consider an application on a mobile device that supports
offlineupdates(i.e.,permitsupdatesevenifthemobiledeviceisnotconnectedtothe

--- Page 1170 ---

23.6 ReplicationwithWeakDegreesofConsistency 1141
network).Togivetheuseraseamlessusageexperience,suchapplicationsperformthe
updatesonalocallycachedcopy,andthenapplytheupdatetothedatastorewhenthe
devicegoesbackonline.Ifthesamedataitemmaybeupdatedfrommultipledevices,
theproblemofconflictingupdatesariseshere,too.Theschemesdescribedbelowcan
beusedinthiscontexttoo,withnodesunderstoodtoalsorefertomobiledevices.
Amechanismfordetectingconflictingupdatesisdescribedinthissection.Howto
resolveconflictingupdatesoncetheyaredetectedisapplicationdependent,andthere
is no general technique for doing so. However, some commonly used approaches are
discussedinSection23.6.5.
For data items updated by only one node, it is a simple matter to propagate the
updateswhenthenodegetsreconnectedtothestoragesystem.Ifthenodeonlycaches
read-onlycopiesofdatathatmaybeupdatedbyothernodes,thecacheddatamaybe-
comeinconsistent.Whenthenodegetsreconnected,itcanbesentinvalidationreports
thatinformitofout-of-datecacheentries.
However, if updates can occur at more than one node, detecting conflicting up-
dates is more difficult. Schemes based on version numbering allow updates of shared
data from multiple nodes. These schemes do not guarantee that the updates will be
consistent. Rather, they guarantee that, if two nodes independently update the same
versionofadataitem,theclashwillbedetectedeventually,whenthenodesexchange
informationeitherdirectlyorthroughacommonnode.
Theversion-vectorschemedetectsinconsistencieswhenreplicasofadataitemare
independentlyupdated. Thisschemeallowscopiesofadataitemtobestoredatmul-
tiplenodes.
Thebasicideaisforeachnodeitostore,withitscopyofeachdataitemd,aversion
vector—that is, a set of version numbers {V[j]}, with one entry for each other node j
on which the data item could potentially be updated. When a node i updates a data
itemd,itincrementstheversionnumberV[i]byone.
Forexample,supposeadataitemisreplicatedatnodesN ,N andN .Iftheitem
1 2 3
is initially created at N , the version vector could be [1,0,0]. If it is then replicated
1
at N , and then updated at node N , the resultant version vector would be [1,1,0].
2 2
Suppose now that this version of the data item is replicated to N , and then both N
3 2
andN concurrentlyupdatethedataitem.Then,theversionvectorofthedataitemat
3
N wouldbe[1,2,0],whiletheversionvectoratN wouldbe[1,1,1].
2 3
Whenevertwonodesiandj connectwitheachother,theyexchangeupdateddata
items,sothatbothobtainnewversionsofthedataitems.However,beforeexchanging
dataitems,thenodeshavetodiscoverwhetherthecopiesareconsistent:
1. IftheversionvectorsV andV ofthe copyofthe dataitematnodesi andj are
i j
the same—thatis,foreachk,V[k] = V[k]—then the copiesof dataitemd are
i j
identical.
2. If, for each k, V[k] ≤ V[k] and the version vectors are not identical, then the
i j
copyofdataitemd atnodeiisolderthantheoneatnodej.Thatis,thecopyof

--- Page 1171 ---

1142 Chapter23 ParallelandDistributedTransactionProcessing
dataitemd atnodej wasobtainedbyoneormoremodificationsofthecopyof
the data item at node i. Node i replaces its copy of d, as well as its copy of the
versionvectorford,withthecopiesfromnodej.
Inourexample above,ifN hadthevector[1,0,0] foradataitem,whileN
1 2
hadthevector[1,1,0],thentheversionatN isnewerthantheversionatN .
2 1
3. IfthereareapairofvalueskandmsuchthatV[k] < V[k]andV[m] > V[m],
i j i j
then the copies are inconsistent; that is, the copy of d at i contains updates per-
formed by node k that have not been propagated to node j, and, similarly, the
copyofd atj containsupdatesperformedbynodemthathavenotbeen propa-
gatedtonodei.Then,thecopiesofdareinconsistent,sincetwoormoreupdates
havebeenperformedond independently.
In our example, after the concurrent updates at N and N , the two version
2 3
vectorsshowtheupdatesareinconsistent.LetV andV denotetheversionvec-
2 3
tors at N and N . Then V [2] = 2 while V [2] = 1, whereas V [3] = 0, while
2 3 2 3 2
V [3] = 1.
3
Manualinterventionmayberequiredtomergetheupdates.Aftermergingthe
updates (perhaps manually), the version vectors are merged, by setting V[k] to
themaximumofV[k]andV[k]foreachk.Thenodel thatperformsthewrite
i j
thenincrementsV[l]by1andthenwritesthedataitemanditsversionvectorV.
The version-vector scheme was initially designed to deal with failures in distrib-
uted file systems. The scheme gained importance because mobile devices often store
copiesofdatathatarealsopresentonserversystems.Theschemeisalsowidelyused
in distributed storage systems that allow updates to happen even if a node is not in a
majoritypartition.
The version-vector scheme cannot solve the problem of how to reconcile incon-
sistent copies of data detected by the scheme. We discuss reconciliation in Section
23.6.5.
The version-vector scheme works well for detecting inconsistent updates to a sin-
gledataitem.However,ifastoragesystemhasaverylargenumberofreplicateditems,
finding which items have been inconsistently updated can be quite expensive if done
naively. In Section 23.6.6 we study a data structure called a Merkle tree that can effi-
cientlydetectdifferencesbetweensetsofdataitems.
23.6.5 Resolving Conflicting Updates
Detectionofconflictingupdatesmayhappenwhenareadoperationfetchescopiesof
adataitemfrommultiplereplicasorwhenthesystemexecutesabackgroundprocess
thatcomparesdataitemversions.
At that point, conflicting updates on the same data item need to be resolved, to
createasinglecommonversion.Resolutionofconflictingupdatesisalsoreferredtoas
reconciliation.

--- Page 1172 ---

23.6 ReplicationwithWeakDegreesofConsistency 1143
Thereisnotechniqueforresolutionsothatcanbeusedacrossallapplications.We
discusssometechniquesthathavebeenusedinseveralcommonlyusedapplications.
Manyapplicationscanperformreconciliationautomaticallybyexecutingoneach
node all update operations that had been performed on other nodes during a period
of disconnection. This solution requires that the system keep track of operations, for
example,addinganitemtoashoppingcart,ordeletinganitemfromashoppingcart.
This solution works if operations commute—that is, they generate the same result, re-
gardless of the orderin whichtheyare executed. The additionof itemsto ashopping
cart clearly commutes. Deletions do not commute with additions in general, which
should be clear if you consider what happens if an addition of an item is exchanged
with a delete of the same item. However, as long as deletion always operates only on
itemsalreadypresentinthecart,thisproblemdoesnotarise.
As another example, many banks allow customers to withdraw money from an
ATM even if it is temporarily disconnected from the bank network. When the ATM
gets reconnected, the withdrawal operation is applied to the account. Again, if there
aremultiplewithdrawals,theymaygetmergedinanorderdifferentfromtheorderin
whichtheyhappenedintherealworld,buttheendresult(balance)isthesame.Note
thatsincetheoperationalreadytookplaceinthephysicalworld,itcannotberejected
because of a negative balance; the fact that an account has a negative balance has to
bedealtwithseparately.
Thereareotherapplication-specificsolutionsforresolvingconflictingupdates.In
theworstcase,however,asystemmayneedtoalerthumanstotheconflictingupdates,
andletthehumansdecidehowtoresolvetheconflict.
Dealingwithsuchinconsistencyautomatically,andassistingusersinresolvingin-
consistenciesthatcannotbehandledautomatically,remainsanareaofresearch.
23.6.6 Detecting Differences Between Collections Using Merkle Tree
TheMerkletree(alsoknownashashtree)isadatastructurethatallowsefficientdetec-
tion of differencesbetween sets of dataitems thatmay be stored atdifferentreplicas.
(Toavoidconfusion betweentreenodesandsystem nodes,weshallrefertothelatter
asreplicasinthissection.)
Detecting items that have inconsistent values across replicas due to weak consis-
tencyismerelyoneofmotivationsforMerkletrees.Anothermotivationisperforming
sanitychecksofreplicasthataresynchronouslyupdated,andshouldbeconsistent,but
maybeinconsistentduetobugsorotherfailures.Weconsiderbelowabinaryversion
oftheMerkletree.
We assume that each data item has a key and a value; in case we are considering
collectionsthatdonothaveanexplicitkey,thedataitemvalueitselfcanbeusedasa
key.
Eachdataitemkeyk ishashedbyafunctionh ()togetahashvaluewithnbits,
i 1
where n is chosen such that 2n is within a small factor of the number of data items.
Eachdataitemvaluev ishashedbyanotherfunctionh ()togetahashvalue(which
i 2

--- Page 1173 ---

1144 Chapter23 ParallelandDistributedTransactionProcessing
is typically much longer than n bits). Finally, we assume a hash function h () which
3
takesasinputacollectionofhashvaluesandreturnsahashvaluecomputedfromthe
collection(thishashfunctionmustbecomputedinawaythatdoesnotdependonthe
inputorderofthehashvalues,whichcanbedone,forexample,bysortingthecollection
beforecomputingthehashfunction).
Each node of a Merkle tree has associated with it an identifier and stores a hash
value. Each leaf of the tree can be identified by an n-bit binary number. For a given
leaf identified by number k, consider the set of all data items i whose key k is such
i
thath (k) = k.Then,thehashvalue v storedatleafk iscomputed byapplyingh ()
1 i k 2
on each of the data item values v, and then applying h () on the resultant collection
i 3
ofhashvalues.Thesystemalsomaintainsanindexthatcanretrieveallthedataitems
withagivenhashvaluecomputedbyfunctionh ().
2
Figure23.8showsanexampleofaMerkletreeon8dataitems.Thehashvalueof
thesedataitemsonh areshownontheleft.Notethatifforanitemi,h (i) = k,then
1 j 1 j
thedataitemi isassociatedwiththeleafwithidentifierk.
j
EachinternalnodeoftheMerkletreeisidentifiedbyahashvaluethatisjbitslong
if the node is at depth j; leaves are at depth n, and the root at depth 0. The internal
nodeidentifiedbyanumberk hasaschildrennodesidentifiedby2k and2k+1.The
hashvaluestoredv atnodekiscomputedbyapplyingh ()tothehashvaluestoredat
k 3
nodes2kand2k+1.
Now,supposethisMerkletreeisconstructedonthedataattworeplicas(therepli-
cas may be whole database replicas, or replicas of a partition of the database). If all
itemsatthetworeplicasareidentical,thestoredhashvaluesattherootnodeswillalso
beidentical.
As long as h () computes a long enough hash value, and is suitably chosen, it is
2
very unlikely that h (v ) = h (v ) if v ≠ v , and similarly for h (). The SHA1 hash
2 1 2 2 1 2 3
function with a 160-bit hash value is an example of a hash function that satisfies this
Hash values of Merkle Tree
data items h 2 (v 0 , v 1 )
h1 (i 1 )=00 0 1
h (i )=01
1 2
h h 1 1 ( ( i i 3 4 ) ) = = 1 0 1 0 h 2 (v0 0 , v 0 1 ) h 2 (v 1 0 , v 1 1 )
h1 (i 5 )=10
h1 (i 6 )=11 00 01 10 11
h (i )=10
1 7
h 2 (h3 (i1 ), h3 (i 4 )) h 2 (h 3 (i 2 )) h2 (h3 (i 5 ), h3 (i7 )) h2 (h 3 (i 3 ), h 3 (i 6 ))
Node identifier shown above node, and has value shown inside node,
v denotes stored hash value in node i
i
Figure 23.8 ExampleofMerkletree.

--- Page 1174 ---

23.6 ReplicationwithWeakDegreesofConsistency 1145
requirement.Thus,wecanassumethatiftwonodeshavethesamestoredhashvalues,
allthedataitemsunderthetwonodesareidentical.
If, in fact, there is a difference in the value of any items at the two replicas, or if
anitemispresentatonereplicabutnotattheother,thestoredhashvaluesattheroot
willbedifferent,withhighprobability.
Then, the stored hash values at each of the children are compared with the hash
values at the corresponding child in the other tree. Search traverses down each child
whose hash value differs, until a leaf is reached. The traversal is done in parallel on
bothtreesandrequirescommunicationtosendtreenodecontentsfromonereplicato
theother.
At the leaf, if the hash values differ, the list of data item keys associated with the
leaves, and the corresponding data item values are compared across the two trees, to
finddataitemswhosevaluesdifferaswellasdataitemsthatarepresentinoneofthe
treesbutnotintheother.
One such traversal takes time at most logarithmicin the number of leafnodes of
the tree; since the number of leaf nodes is chosen to be close to the number of data
items, the traversal time is also logarithmic in the number of data items. This cost is
paidatmostonceforeachdataitemthatdiffersbetweenthetworeplicas.Furthermore,
apathtoaleafistraversedonlyifthereis,infact,adifferenceattheleaf.
Thus, the overall cost for finding differencesbetween two (potentially very large)
setsisO(mlog N),wheremisthenumberofdataitemsthatdifferandN isthetotal
2
numberofdataitems.Widertreescanbeusedtoreducethenumberofnodesencoun-
teredinatraversal,whichwouldbelog N ifeachnodehasK children,atthecostof
K
moredatabeingtransferredforeachnode.Widertreesarepreferredifnetworklatency
ishighcomparedtothenetworkbandwidth.
Merkle trees have many applications; they can be used to find the difference in
contentsoftwodatabasesthatarealmostidenticalwithouttransferringlargeamounts
ofdata.Suchinconsistenciescanoccurduetotheuseofprotocolsthatonlyguarantee
weak consistency. They could also occur because of message or network failures that
result in differences in replicas, even if consensus or other protocols that guarantee
consistentreadsareused.
TheoriginaluseofMerkletreeswasforverificationofthecontentsofacollection
thatmayhavepotentiallybeencorruptedbymalicioususers.Here,theMerkletreeleaf
nodesmuststorethehashvaluesofalldataitemsthatmaptoit,oratreevariantthat
only stores one data item at a leaf may be used. Further, the stored hash value at the
root is digitally signed, meaning its contents cannot be modified by a malicious user
whodoesnothavetheprivatekeyusedforsigningthevalue.
To check an entire relation, the hash values can be recomputed from the leaves
upwards,andtherecomputedhashvalueattherootcanbecomparedwiththedigitally
signedhashvaluestoredattheroot.
Tocheckconsistencyofasingledataitem,itshashvalueisrecomputed;andthen
soisthehashvalueforitsleafnoden,usingexistinghashvaluesforotherdataitems
i

--- Page 1175 ---

1146 Chapter23 ParallelandDistributedTransactionProcessing
thathashtothesameleaf.Nextconsidertheparentnoden ofnoden inthetree.The
j i
hash value of n is computed using the recomputed hash value of n and the already
j i
stored hash values of otherchildrenof n. Thisprocess iscontinued upward until the
j
rootofthetree.Iftherecomputedhashvalueattherootmatchesthesignedhashvalue
storedwiththeroot,thecontentsofthedataitemcanbedeterminedtobeuncorrupted.
The above technique works for detecting corruption since with suitably chosen
hash functions, it is very hard for a malicious user to create replacement values for
data items in a way that the recomputed hash value is identical to the signed hash
valuestoredattheroot.
23.7 Coordinator Selection
Several of the algorithms that we have presented require the use of a coordinator. If
the coordinator fails because of a failure of the node at which it resides, the system
can continue execution by restarting a new coordinator on another node. One way
to continue execution is by maintaining a backup to the coordinator that is ready to
assume responsibilityif the coordinator fails. Anotherway isto “elect”a coordinator
from among the nodes that are alive. We outline these options in this section. We
thenbrieflydescribefault-tolerantdistributedservicesthathavebeendevelopedtohelp
developersofdistributedapplicationsperformthesetasks.
23.7.1 Backup Coordinator
Abackupcoordinatorisanodethat,inadditiontoothertasks,maintainsenoughinfor-
mationlocallytoallowittoassumetheroleofcoordinatorwithminimaldisruptionto
the distributed system. All messages directed to the coordinator are received by both
thecoordinatoranditsbackup.Thebackupcoordinatorexecutesthesamealgorithms
andmaintainsthesameinternalstateinformation(suchas,foraconcurrencycoordi-
nator, the lock table) as does the actual coordinator. The only difference in function
between the coordinator and its backup is that the backup does not take any action
thataffectsothernodes.Suchactionsarelefttotheactualcoordinator.
In the event that the backup coordinator detects the failure of the actual coordi-
nator, it assumes the role of coordinator. Since the backup has all the information
available to it that the failed coordinator had, processing can continue without inter-
ruption.
Theprimeadvantageofthebackupapproachistheabilitytocontinueprocessing
immediately. If a backup were not ready to assume the coordinator’s responsibility,
a newly appointed coordinator would have to seek information from all nodes in the
system so that it could execute the coordination tasks. Frequently, the only source
of some of the requisite information is the failed coordinator. In this case, it may be
necessary to abort several (or all) active transactions and to restart them under the
controlofthenewcoordinator.

--- Page 1176 ---

23.7 CoordinatorSelection 1147
Thus,thebackup-coordinatorapproachavoidsasubstantialamountofdelaywhile
thedistributedsystemrecoversfromacoordinatorfailure.Thedisadvantageistheover-
headofduplicateexecutionofthecoordinator’stasks.Furthermore,acoordinatorand
its backup need to communicate regularly to ensure that their activities are synchro-
nized.
Inshort,thebackup-coordinatorapproachincursoverheadduringnormalprocess-
ingtoallowfastrecoveryfromacoordinatorfailure.
23.7.2 Election of Coordinator
Intheabsenceofadesignatedbackupcoordinator,orinordertohandlemultiplefail-
ures,anewcoordinatormaybechosendynamicallybynodesthatarelive.
One possible approach is to have a designated node choose a new coordinator,
when the current coordinator has failed. However, this raises the question of what to
doifthenodethatchoosesreplacementcoordinatorsitselffails.
If we have a fault-tolerant lock manager, a very effective way of choosing a new
coordinatorforataskistouselockleases.Thecurrentcoordinatorhasalockleaseon
adataitem associated withthetask. Ifthecoordinatorfails,theleasewillexpire.Ifa
participant determines that the coordinator may have failed, it attempts to get a lock
lease for the task. Note that multiple participants may attempt to get a lease, but the
lockmanagerensuresthatonlyoneofthemcangetthelease.Theparticipantthatgets
the lease becomes the new coordinator. As discussed in Section 23.3.3, this ensures
thatonlyonenodethatcanbethecoordinatoratagiventime.Lockleasesarewidely
used to ensure that a single node gets chosen as coordinator. However, observe that
thereisanunderlyingassumptionofafault-tolerantlockmanager.
A participant determines that the coordinator may have failed if it is unable to
communicatewiththecoordinator. Participantssend periodicheart-beat messages to
thecoordinatorandwaitforanacknowledgment;iftheacknowledgmentisnotreceived
withinacertaintime,thecoordinatorisassumedtohavefailed.
Note that the participant cannotdefinitivelydistinguish a situation where the co-
ordinator is dead from a situation where the network link between the node and the
coordinatoriscut.Thus,thesystemshouldbeabletoworkcorrectlyevenifthecurrent
coordinator is alive, but another participant determines that the coordinator is dead.
Lock leases ensure that at most one node can be the coordinator at any time; once a
coordinatordies,anothernodecanbecomethecoordinator.However,lockleaseswork
onlyifafault-tolerantlockmanagerisavailable.
Thisraisesthequestionofhowtoimplementsuchalockmanager.Wereturnlater,
in Section 23.8.4, to the question of how to implement a fault-tolerant lock manager.
Butitturnsoutthattodosoefficiently,weneedtohaveacoordinator.And,lockleases
cannot be used to choose the coordinator for the lockmanager! The problem of how
to choose a coordinator without depending on a lock manager is solved by election
algorithms, which enable the participating nodes to choose a new coordinator in a
decentralizedmanner.

--- Page 1177 ---

1148 Chapter23 ParallelandDistributedTransactionProcessing
Suppose thegoal istoelectacoordinatorjustonce.Then,eachnodethatwishes
to become the coordinator proposes itself as a candidate to all the other nodes; such
nodesarecalledproposers.Theparticipatingnodesthenvoteonwhichnodeamongthe
candidates is to be chosen. If a majority of the participating nodes (called acceptors)
vote for a particular candidate, it is chosen. A subset of nodes called learners ask the
acceptor nodes for their vote and determine if a majority have voted for a particular
candidate.
The problem with the above idea is that if there are multiple candidates, none of
themmaygetamajorityofvotes.Thequestioniswhattodoinsuchasituation.There
areatleasttwoapproachesthathavebeenproposed:
• Nodes are given unique numbers; if more than one candidate proposes itself, ac-
ceptorschoosethehighest-numberedcandidate.Eventhenvotesmaybesplitwith
nomajoritydecision,duetodelayedormissingmessages;insuchacase,theelec-
tionisrunagain.ButifanodeN thatwasacandidatefindsthatahigher-numbered
1
nodeN hasproposeditselfasacandidate,thenN withdrawsfromthenextround
2 1
of the election. The highest-numbered candidate will win the election. The bully
algorithmforelectionisbasedonthisidea.
Therearesomesubtledetailsduetothepossibilitythatthehighest-numbered
candidateinoneroundmayfailduringasubsequentround,leadingtotherebeing
no candidates at all! If a proposer observes that no coordinator was selected in
a round where it withdrew itself as a candidate, it proposes itself as a candidate
againinthenextround.
Note also that the election has multiple rounds; each round has a number,
andacandidateattachesaroundnumberwiththeproposal.Theroundnumberis
chosentobethemaximumroundthatithasseen,plus1.Anodecangiveavote
toonlyonecandidateinaparticularround,butitmaychangeitsvoteinthenext
round.
• Thesecondapproachisbasedonrandomizedretry,whichworksasfollows:Ifthere
isnomajoritydecisioninaparticularround,allparticipantswaitforarandomly
chosenamountoftime;ifbythattimeacoordinatorhasbeenchosenbyamajority
of nodes, it is accepted as a coordinator. Otherwise, after the timeout, the node
proposesitselfasacandidate.Aslongasthetimeoutsarechosenproperly(large
enoughcomparedtonetworklatency)withhighlikelihoodonlyonenodeproposes
itselfataparticulartimeandwillgetvotesfromamajorityofnodesinaparticular
round.
If no candidate gets a majority vote in a round, the process is repeated. With
veryhighprobability,afterafewrounds,oneofthecandidatesgetsamajorityand
isthuschosenascoordinator.
The randomized-retry approach was popularized by the Raft consensus algo-
rithm, and it is easier to reason about it and show not just correctness, but also
boundsontheexpectedtimeforanelectionroundtosucceedinchoosingacoor-
dinator,ascomparedtothenode-numbering-basedapproach.

--- Page 1178 ---

23.7 CoordinatorSelection 1149
Notethattheabovedescriptionassumedthatchoosingacoordinatorisaone-time
activity.However,thechosencoordinatormayfail,requiringafreshelectionalgorithm.
Thenotionofatermisusedtodealwiththissituation.Asmentionedabove,eachtime
anodeproposesitselfasacoordinator,itassociatestheproposalwitharoundnumber,
whichis1morethanthehighestroundnumberithasseenearlier,afterensuringthat
inthepreviousroundnocoordinatorwaschosen,orthechosencoordinatorhassubse-
quentlyfailed.Theroundnumberishenceforthreferredtoasaterm.Whentheelection
succeeds,thechosencoordinatoristhecoordinatorforthecorrespondingterm.Ifthe
election fails, the corresponding term does not have any coordinator chosen, but the
electionshouldsucceedinasubsequentterm.
Notealsothattherearesubtleissuesthatarisesinceanodenmaybedisconnected
fromthenetworkforawhile,anditmaygetreconnectedwithouteverrealizingthatit
was disconnected.In the interim, the coordinator may have changed.In particular, if
thenodenwasthecoordinator,itmaycontinuetothinkitisthecoordinator,andsome
othernode,sayN ,whichwasalsodisconnectedmaythinkthatnisstillcoordinator.
1
However,ifacoordinatorwassuccessfullyelected,themajorityofthenodesagreethat
someothernode,sayN ,isthecoordinator.
2
Ingeneral,itispossibleformorethanonenodetothinkthatisthecoordinatorat
thesametime,althoughatmostoneofthemcanhavethemajorityvote atthatpoint
intime.
Toavoidthisproblem,eachcoordinatorcanbegivenaleaseforaspecifiedperiod.
Thecoordinatorcanextendtheleasebyrequestinganextensionfromothernodesand
getting confirmation from a majority of the nodes. But if the coordinator is discon-
nected from a majority of the nodes, it cannot renew its lease, and the lease expires.
A node can vote for a new coordinator only if the last lease time that itconfirmed to
the earliercoordinator has expired. Since a new coordinator needs a majority vote, it
cannotgetthevoteuntiltheleasetimeofthepreviouscoordinatorhasexpired.
However,evenifleasesareusedtoensurethattwonodescannotbecoordinators
atthesametime,delayedmessagescanresultinanodegettingamessagefromanold
coordinatorafteranewonehasbeenelected.
To deal with this problem, the current term of the sender is included with each
message exchanged in the system. Note thatwhen anode n iselected ascoordinator,
it has an associated term t; participant nodes that learn that n is the coordinator are
aware of the current term t. A node may receive a message with an old term either
becauseanoldcoordinatordidnotrealizeithasbeenreplacedorbecauseofmessage
deliverydelay;thelatterproblemcanoccurevenifleasesorothermechanismsensure
thatonlyonenodecanbethecoordinatoratatime.Ineithercase,anodethatreceives
astalemessage,thatis,onewithatermolderthanthecurrenttermofthenode,itcan
ignore the message. If a node receives a message with a higher number, it is behind
the rest of the system, and it needs to find out the current term and coordinator by
contactingothernodes.
Some protocols do not require the coordinator to store any state information; in
such cases, the new coordinator can take over without any further actions. However,

--- Page 1179 ---

1150 Chapter23 ParallelandDistributedTransactionProcessing
otherprotocolsrequirecoordinatorstoretainstateinformation.Insuchcases,thenew
coordinatorhastoreconstructthestateinformationfrompersistentdataandrecovery
logs created by the previous coordinator. Such logs, in turn, need to be replicated to
multiple nodes so that the loss of a node does not result in the loss of access to the
recoverydata. We shall see how to ensure availabilitybymeans ofdata replicationin
subsequentsections.
23.7.2.1 DistributedCoordinationServices
There are a very large number of distributed applications that are in daily use today.
Insteadofeachonehavingtoimplementitsownmechanismforelectingcoordinators
(among other tasks), it makes sense to develop a fault-tolerant coordination service
thatcanbeusedbymultipledistributedapplications.
The ZooKeeper service is one such very widely used fault-tolerant distributed co-
ordination service. The Chubby service developed earlier at Google is another such
service, which is widely used for applications developed by Google. These services
internally use consensus protocols to implement fault tolerance; we study consensus
protocolsinSection23.8.
Theseservicesprovideafile-system-likeAPI,whichsupportsthefollowingfeatures,
amongothers:
• Store (small amounts of) data in files, with a hierarchical namespace. A typical
useforsuchstorageistostoreconfigurationinformationthatcanbeusedtostart
upadistributedapplication,orfornewnodestojoinadistributedapplicationby
findingoutwhichnodeiscurrentlythecoordinator.
• Create and delete files, which can be used to implement locking. For example, to
getalock,aprocesscanattempttocreateafilewithanamecorrespondingtothe
lock.Ifanotherprocesshasalreadycreatedthefile,thecoordinationservicewill
returnanerror,sotheprocessknowsitcouldnotgetthelock.
Forexample,anodethatactsasamasterforatabletinakey-valuestorewould
getalockonafilewhosenameistheidentifierofthetablet.Thisensuresthattwo
nodescannotbemastersforthetabletatthesametime.
Ifanoverallapplicationmasterdetectsthatatabletmasterhasdied,itcouldre-
leasethelock.Iftheservicesupportslockleases,thiscouldhappenautomatically,
ifthetabletmasterdoesnotrenewitslease.
• Watchfor changesonafile, whichcanbe usedbyaprocesstocheckifalockhas
been released, or to be informed about other changes in the system that require
actionbytheprocess.
23.8 Consensus in Distributed Systems
Inthissectionwefirstdescribetheconsensusprobleminadistributedsystem,thatis,
howasetofnodesagreeonadecisioninafault-tolerantway.Distributedconsensusis

--- Page 1180 ---

23.8 ConsensusinDistributedSystems 1151
akeybuildingblockforprotocolsthatupdatereplicateddatainafault-tolerantmanner.
Weoutlinetwoconsensusprotocols,PaxosandRaft.Wethendescribereplicatedstate
machines,whichcanbeusedtomakeservices,suchasdatastorage systemsandlock
managers,faulttolerant.Weendthesectionbydescribinghowconsensuscanbeused
tomaketwo-phasecommitnonblocking.
23.8.1 Problem Overview
Software systems need to make decisions, such as the coordinator’s decision on
whether to commit or abort a transaction when using 2PC, or a decision on which
nodeistoactascoordinator,incaseacurrentcoordinatorfails.
Ifthedecisionismadebyasinglenode,suchasthecommit/abortdecisionmade
byacoordinatornodein2PC,thesystemmayblockincasethenodefails,sinceother
nodes have noway of determiningwhat decisionwas made. Thus, to ensure faulttol-
erance,multiplenodesmustparticipateinthedecisionprotocol;evenifsomeofthese
nodes fail, the protocol must be able to reach a decision. A single node may make a
proposal for a decision, but it must involve the other nodes to reach a decision in a
fault-tolerantmanner.
Themostbasicformofthedistributedconsensusproblemisthusasfollows:asetof
nnodes(referredtoasparticipants)needtoagreeonadecisionbyexecutingaprotocol
suchthat:
• Allparticipants must “learn” the same value forthe decisioneven if some nodes
failduringtheexecutionoftheprotocol,ormessagesarelost,ortherearenetwork
partitions.
• The protocol should not block, and must terminate, as long as some majority of
thenodesparticipatingremainaliveandcancommunicatewitheachother.
Anyrealsystemcannotjustmakeasingledecisiononce,butneedstomakeaseries
of decisions. A good abstract of the process of making multiple consensus decisions
is to treat each decision as adding a record to a log. Each node has a copy of the log,
and records are appended to the log at each node. There can potentially be conflicts
onwhatrecordisaddedatwhatpointinalog.Themultipleconsensusprotocolviewed
fromthisperspectiveneedstoensurethatthelogisuniquelydefined.
Mostconsensusprotocolsallowtemporary divergenceoflogsacrossnodeswhile
theprotocolisbeingexecuted;thatis,thesamelogpositionatdifferentnodesmayhave
different records, and the end of the log may be different at different nodes. Shared-
logconsensusprotocolskeeptrackofanindexintothelogsuchthatanyentrybefore
thatindexhasdefinitelybeenagreedupon.Anyentriesafterthatindexmaybeinthe
process of being agreed upon, or may be entries from failed attempts at consensus.
However, the protocolssubsequently bringthe inconsistent parts of theloglogs back
in synchronization. To do this, log records at some nodes may be deleted after being
inserted;suchlogrecordsareviewedasnotyetcommittedandcannotbeusedtomake

--- Page 1181 ---

1152 Chapter23 ParallelandDistributedTransactionProcessing
decisions.Onlylogrecordsintheprefixofthelogthatareinthecommittedprefixmay
beusedtomakedecisions.
Several protocols have been proposed for distributed consensus. Of these, the
Paxos family of protocols is one of the most popular, and it has been implemented
inmanysystems. WhilethebasicPaxosprotocolisintuitivelyeasytounderstandata
high level,there are a number of detailsin its implementation that are rather compli-
cated,andparticularlysointhemultipleconsensusversion.Toaddressthisissue,the
Raft consensus protocol was developed, with ease of understanding and implementa-
tionbeingkeygoals,andithasbeenadoptedbymanysystems.Weoutlinetheintuition
behindtheseprotocolsinthissection.
A key ideabehind distributed consensus protocolsisthe ideaof voting to make a
decision; a particular decision succeeds only if a majority of the participating nodes
voteforit.Notethatiftwoormoredifferentvaluesareproposedforaparticulardeci-
sion,atmostoneofthemcanbevotedforbyamajority;thus,itisnotpossiblefortwo
differentvaluestobechosen.Evenifsomenodesfail,ifamajorityoftheparticipants
vote for a value, it gets chosen, thus making the voting fault tolerant as long as a ma-
jorityoftheparticipantsareupandconnectedtoeachother.Thereis,however,arisk
thatvotesmaygetsplitbetweentheproposedvalues,andsomenodesmaynotvoteif
theyfail;asaresult,novaluemaybedecidedon.Insuchacasethevotingprocedure
hastobeexecutedagain.
Whiletheaboveintuitioniseasyenoughtounderstand,therearemanydetailsthat
maketheprotocolsnontrivial.Westudysomeoftheseissuesinthefollowingsections.
We note that although we study some of the features of the Paxos and Raft con-
sensusprotocols,weomitanumberofdetailsthatareneededforcorrectoperationto
keepourdescriptionconcise.
Wealsonotethatanumberofotherconsensusprotocolshavebeenproposed,and
someofthemarewidelyused,suchastheZabprotocolwhichispartoftheZooKeeper
distributedcoordinationservice.
23.8.2 The Paxos Consensus Protocol
ThebasicPaxosprotocolformakingasingledecisionhasthefollowingparticipants.
1. One or more nodes that can propose a value for the decision; such nodes are
calledproposers.
2. One or more nodes that act as acceptors. An acceptor may get proposals with
differentvaluesfromdifferentproposersandmustchoose(votefor)onlyoneof
thevalues.
Notethatfailureofanacceptordoesnotcauseaproblem,aslongasamajority
of the acceptors are live and reachable. Failure or disconnection of a majority
wouldblocktheconsensusprotocol.

--- Page 1182 ---

23.8 ConsensusinDistributedSystems 1153
3. A set of nodes, called learners, query the acceptors to find what value each ac-
ceptorvotedforinaparticularround.(Acceptorscouldalsosendthevaluethey
acceptedtothelearners,withoutwaitingforaqueryfromthelearner.)
Notethatthesamenodecanplaytherolesofproposer,acceptor,andlearner.
Ifamajorityoftheacceptorsvotedforaparticularvalue,thatvalueisthechosen
(consensus)valueforthatdecision.Buttherearetwoproblems:
1. It is possible for votes to be split among multiple proposals, and no proposal is
acceptedbyamajorityoftheacceptors.
Ifanyproposedvalueistogetamajority,atleastsomeacceptorsmustchange
theirdecision.Thus,wemustallowanotherroundofdecisionmaking,whereac-
ceptorsmaychooseanewvalue.Thismayneedtoberepeatedaslongasrequired
untilonevaluewinsamajorityvote.
2. Even if a majority of nodes do accept a value, it is possible that some of these
nodes die or get disconnected after accepting a value, but before any learner
finds out about their acceptance, and the remaining acceptors of that value do
notconstituteamajority.
Ifthisistreatedasthefailureofaround,andadifferentvalueischosenina
subsequentround,wehaveaproblem.Inparticular,alearnerthatlearnedabout
the earlier majority would conclude that a particular value was chosen, while
another learner could conclude that a different value was chosen, which is not
acceptable.
Notealsothatacceptorsmustlogtheirdecisionsowhentheyrecovertheyknowwhat
decisiontheymadeearlier.
The first problem above, namely, split votes, does not affect correctness, but it
affects performance. To avoid this problem, Paxos makes use of a coordinator node.
Proposerssendaproposaltothecoordinator,whichpicksoneoftheproposedvalues
and follows the preceding steps to get a majority vote. If proposals come from only
onecoordinator,thereisnoconflict,andtheloneproposedvaluegetsamajorityvote
(modulonetworkandnodefailures).
Note that if the coordinator dies or is unreachable, a new coordinator can be
elected,usingtechniqueswesawearlierinSection23.7,andthenewcoordinatorcan
then do the same job as the earlier coordinator. Coordinators have no local state, so
thenewonecantakeoverwithoutanyrecoverysteps.
Thesecondproblem,namely,differentvaluesgettingmajoritiesindifferentrounds,
isaseriousproblemandmustbe avoidedbytheconsensus protocol.Todoso, Paxos
usesthefollowingsteps:
1. Each proposal in Paxos has a number; different proposals must have different
numbers.

--- Page 1183 ---

1154 Chapter23 ParallelandDistributedTransactionProcessing
2. In phase 1a of the protocol, a proposer sends a prepare message to acceptors,
withitsproposalnumbern.
3. In phase 1b of the protocol, an acceptor that receives a prepare message with
numbernchecksifithasalreadyrespondedtoamessagewithanumberhigher
thann.Ifso,itignoresthemessage.Otherwise,itremembersthenumbernand
responds withthe highestproposal numberm < n thatithas alreadyaccepted,
along with the corresponding value v; if it has not accepted any value earlier, it
indicatessoinitsresponse.(Notethatrespondingisdifferentfromaccepting.)
4. In phase 2a, the proposer checks if it got a response from a majority of the ac-
ceptors. If it does, it chooses a value v as follows: If none of the acceptors has
already accepted any value, the proposer may use whatever value it intended to
propose.Ifatleastoneoftheacceptorsrespondedthatitacceptedavaluevwith
somenumberm,theproposerchoosesthevaluevthathasthehighestassociated
numberm(notethatmmustbe< n).
Theproposernowsendsanacceptrequestwiththechosenvaluevandnumber
n.
5. In phase 2b, when an acceptor gets an accept request with value v and number
n, it checks if it has responded to a prepare message with number n > n; if
1
soitignorestheacceptrequest.Otherwise,itacceptstheproposed valuevwith
numbern.
The above protocol is quite clever, since it ensures the following: if a majority of
acceptors accepted a value v (with any number n), then even if there are further pro-
posals withnumber n > n, thevalue proposed willbe value v.Intuitively,the reason
1
is that a value can be accepted with number n only if a majority of nodes respond to
apreparemessagewithnumbern;letuscallthissetofacceptorsP.Supposeavaluev
hadbeenacceptedearlierbyamajorityofnodeswithnumberm;callthissetofnodes
A. Then A and P must have a node in common, and the common node will respond
withvaluevandnumberm.
Notethatsomeotherproposalwithanumberp > nmayhavebeenmadeearlier,
but if it had been accepted by even one node, then a majority of nodes would have
responded to the proposal with number p, and thus will not respond to the proposal
withnumbern.Thus,ifaproposalwithvaluevisacceptedbyamajorityofnodes,we
canbesurethatanyfurtherproposalwillbeforthealreadychosenvaluev.
Notethatifalearnerfindsthatnoproposalwasacceptedbyamajorityofnodes,
it can ask any proposer to issue a fresh proposal. If a value v had been accepted by a
majority of nodes, it would be found and accepted again, and the learner would now
learnaboutthevalue.Ifnovaluewasacceptedbyamajorityofnodesearlier,thenew
proposalcouldbeaccepted.
The above algorithm is for a single decision. Paxos has been extended to allow a
seriesofdecisions;theextendedalgorithmiscalledMulti-Paxos.Realimplementations

--- Page 1184 ---

23.8 ConsensusinDistributedSystems 1155
alsoneedtodealwithotherissues,suchashowtoaddanodetothesetofacceptors,
or to remove a node from the set of acceptors if it is down for a long time, without
affecting the correctness of the protocol. References with more details about Paxos
and Multi-Paxos may be found in the bibliographic notes for this chapter, available
online.
23.8.3 The Raft Consensus Protocol
Thereareseveralconsensusprotocolswhosegoalistomaintainalog,towhichrecords
canbeappendedinafault-tolerantmanner.Eachnodeparticipatinginsuchaprotocol
hasareplicaofthelog.Log-basedprotocolssimplifythehandlingofmultipledecisions.
TheRaftconsensusprotocolisanexampleofsuchaprotocol,anditwasdesignedto
be(relatively)easytounderstand.
Akeygoaloflog-basedprotocolsistokeepthelogreplicasinsyncbypresentinga
logicalviewofappendingrecordsatomicallytoallcopiesofthelog.Infact,atomically
appending the same entry to all replicas is not possible, due to failures. Recall that
failure modes may include a node being temporarily disconnected and missing some
updates,withouteverrealizingitwasdisconnected.Further,alogappendmaybedone
atjustafewnodes,andtheappendprocessmayfailsubsequently,leavingotherreplicas
without the record. Thus, ensuring all copies of the log are identical at all times is
impossible.Suchprotocolsmustensurethefollowing:
• Even if a log replica is temporarily inconsistent with another, the protocol will
bring it back in sync eventually by deleting and replacing log records on some
copies.
• Alogentrywillnotbetreatedascommitteduntilthealgorithmguaranteesthatit
willneverbedeleted.
Protocols such as Raft that are based on log replication can allow each node to
run a“state machine,”withlogentriesused ascommandstothestate machine;state
machinesaredescribedinSection23.8.4.
TheRaftalgorithmisbasedonhavingacoordinator,whichiscalledaleaderinRaft
terminology.Theotherparticipatingnodesarecalledfollowers. Sinceleadersmaydie
and need to be replaced, time is divided into terms, which are identified by integers.
Each term has a unique leader, although some terms may not have any associated
leader.Latertermshavehigheridentifiersthanearlierterms.
LeadersareelectedinRaftusingtherandomized-retryalgorithmoutlinedinSec-
tion23.7.2.Recallthattherandomized-retryalgorithmalreadyincorporatesthenotion
ofaterm.Anodethatvotesforaleaderdoessoforaspecificterm.Nodeskeeptrack
ofthecurrentTermbasedonmessagesfromleadersorrequestsforvotes.
NotethataleaderN maygettemporarilydisconnected,butgetreconnectedafter
1
other nodes find the leader cannot be reached, and elect a new leader N . Node N
2 1

--- Page 1185 ---

1156 Chapter23 ParallelandDistributedTransactionProcessing
log index 1 2 3 4 5 6 7
1 1 1 2 3 3 3
leader
x < 2 z < 2 x < 3 x < 4 x < 1 y < 6 z < 4
1 1 1 2 3
follower 1
x < 2 z < 2 x < 3 x < 4 x < 1
1 1 1 2 3 3 3
follower 2
x < 2 z < 2 x < 3 x < 4 x < 1 y < 6 z < 4
1 1 1
follower 3
x < 2 z < 2 x < 3
1 1 1 2 3 3
follower 4
x < 2 z < 2 x < 3 x < 4 x < 1 y < 6
committed entries
Figure 23.9 ExampleofRaftlogs.
doesnotknowthatthereisanewleaderandmaycontinuetoexecutetheactionsofa
leader.Theprotocolshouldberobusttosuchsituations.
Figure23.9showsanexampleofRaftlogsataleaderandfourfollowers.Notethat
the log index denotes the position of a particular record in a log. The number at the
top ofeachlogrecordistheterm in whichthelogrecordwascreated,whilethepart
belowitshowsthelogentry,assumedheretorecordassignmentstodifferentvariables.
Anynodethatwishestoappendarecordtothereplicatedlogsendsalogappend
requesttothecurrentleader.Theleaderaddsitstermasafieldofthelogrecordsand
appendstherecordtoitslog;itthensendsanAppendEntriesremoteprocedurecallto
theothernodes;thecallcontainsseveralparameters,includingthese:
• term:thetermofthecurrentleader.
• previousLogEntryPosition:thepositioninthelogoftheprecedinglogentry.
• previousLogEntryTerm:thetermassociatedwiththeprecedinglogentry.
• logEntries:anarrayoflogrecords,allowingthecalltoappendmultiplelogrecords
atthesametime.
• leaderCommitIndex: an index such that all log records at that indexor earlierare
committed.Recallthatalogentryisnotconsideredcommitteduntilaleaderhas
confirmedthatamajorityofnodeshaveacceptedthatlogentry.Theleaderkeeps,
inleaderCommitIndex,apositioninthelogsuchthatalllogrecordsatthatindex
andearlierarecommitted;thisvalueissentalongwiththeAppendEntriescallso
thatthenodeslearnwhichlogrecordshavebeencommitted.

--- Page 1186 ---

23.8 ConsensusinDistributedSystems 1157
If a majority of the nodes respond to the call with a return value true, the leader
canreportsuccessfullogappend(alongwiththepositioninthelog)tothenodethat
initiatedthelogappend.Wewillshortlyseewhathappensifamajoritydonotrespond
withtrue.
EachfollowerthatreceivesanAppendEntriesmessagedoesthefollowing:
1. IftheterminthemessageislessthancurrentTerm,thenReturnfalse.
2. Ifthelogdoesnotcontainanentryatapreviouslogentryposition,whoseterm
matchestheterminthemessage,thenReturnfalse.
3. Ifthereisanexistingentryatthelogposition thatisdifferentfrom thefirstlog
record in the AppendEntriesmessage, the existing entry and all subsequent log
entriesaredeleted.
4. Any log records in the logEntries parameter that are not already in the log are
appendedtothelog.
5. The follower also keeps track of a local commitIndex to track which records
are committed. If the leaderCommitIndex > commitIndex, set commitIndex =
min(leaderCommitIndex,indexoflastentryinlog).
6. Returntrue.
Notethatthelaststepkeepstrackofthelastcommittedlogrecord.Itispossiblethat
the leader’s log is ahead of the local log, so commitIndex cannot be blindly set to
leaderCommitIndex,anditmayneedtobesettothelocalendoflogiftheleaderCom-
mitIndexisaheadofthelocalendoflog.
Figure23.9showsthatdifferentfollowersmayhavedifferentlogstates,sincesome
AppendEntriesmessagesmaynothavereachedthosenodes.Thepartofthelogupto
entry6ispresentatamajorityofnodes(namely,theleader,follower2andfollower4).
Onreceiptofatrue responsetotheAppendEntriescallforthelogrecordatposition
6fromthesefollowers,theleadercansetleaderCommitIndexto6.
ItispossibleforanodeN tobealeaderinsometerm,andontemporarydiscon-
1
nection it may get replaced by a new leader N in the next term. N may not realize
2 1
thatthereisanewleaderforsometimeandmaysendappendEntrymessagestoother
nodes. However, a majority of the other nodes will know about the new leader, and
would have a term higher than that of N . Thus, these nodes would return false, and
1
includetheircurrenttermintheresponse.NodeN wouldthenrealizethatthereisa
1
leaderwithanewterm;itthenswitchesfromtheroleofleadertothatoffollower.
Theprotocolmustdealwiththefactthatsomenodesmayhaveoutdatedlogs.Note
thatinstep2ofthefollowerprotocol,thefollowerreturnsfalseifitslogisoutdated.In
suchacase,theleaderwillretryanAppendEntries,sendingitalllogrecordsfroman
evenearlierpointinthelog.Thismayhappenseveraltimes,untiltheleadersendslog

--- Page 1187 ---

1158 Chapter23 ParallelandDistributedTransactionProcessing
recordsfromapointthatisalreadyinthefollowerlog.Atthispoint,theAppendEntries
commandwouldsucceed.
Akey remainingproblemistoensure thatifaleaderdies,and anotherone takes
over,thelogisbroughttoaconsistentstate.Notethattheleadermayhaveappended
some log entries locally and replicated some of them to some other nodes, but the
newleadermayormaynothavealltheserecords.Todealwiththissituation,theRaft
protocolincludesstepstoensurethefollowing:
1. The protocol ensures that any node elected as leader has all the committed log
entries. Todo so, any candidate must contacta majorityof the nodes and send
information about its log state when seeking a vote. A node will vote for a can-
didate in the election only if it finds that the candidate’s log state is at least as
up-to-dateasits own; note that the definitionof “atleast as up-to-date” isalittle
complicatedsinceitinvolvestermidentifiersinlogrecords,andweomitdetails.
Sincetheabovecheckisdonebyamajorityofthenodesthatvotedforthenew
leader, any committed entry would certainly be present in the log of the newly
electedleader.
2. Theprotocolthenforcesallothernodestoreplicatetheleader’slog.
Note thatthe firststep above doesnotactuallyfind upto whatlogrecordis
committed. Some of the log records at the new leader may not have been com-
mittedearlier,butmaygetcommittedwhenthenewleader’slogisreplicatedin
thisstep.
Thereisalsoasubtledetailinthatthenewleadercannotcountthenumberof
replicaswithaparticularrecordfromanearlierterm,anddeclareitcommittedif
itisatamajorityofthenodes.Intuitively,theproblemisbecauseofthedefinition
of “atleastasup-to-date” andthe possibilitythataleadermayfail,recover,and
be elected as leader again. We omit details, but note that the way this problem
is solved is for the new leader to replicate a new log record in its current term;
when thatlogrecordisdeterminedtobe atamajorityof thereplicas,itand all
earlierlogrecordscanbedeclaredtobecommitted.
It should be clear that although the protocol, like Paxos, seems simple at a high
level,therearemanysubtledetailsthatneedtobetakencareoftoensureconsistency
even inthe faceof multiplefailuresand restarts. Thereare furtherdetailstobe taken
care of, includinghow to change the cluster membership, thatis, the setof nodes that
form the system, whilethe system isrunning (doingso carelesslycan resultin incon-
sistencies). Details of the above steps, including proofs of correctness, may be found
inreferencesinthebibliographicnotesforthischapter,availableonline.
23.8.4 Fault-Tolerant Services Using Replicated State Machines
A key requirement in many systems is for a service to be made fault tolerant. A lock
managerisanexampleofsuchaservice,asisakey-valuestoragesystem.

--- Page 1188 ---

23.8 ConsensusinDistributedSystems 1159
Client
y < 7
Consensus x 3 Consensus x 3 Consensus x 3
Module y 7 Module y 7 Module y 7
z 3 z 3 z 3
Log Log Log
x < 2 z < 2 x < 3 y < 4 y < 7 x < 2 z < 2 x < 3 y < 4 y < 7 x < 2 z < 2 x < 3 y < 4 y < 7
leader follower follower
Leader declares log record committed after it is replicated at a majority of nodes. Update of state machine at each
replica happens only after log record has been committed.
Figure 23.10 Replicatedstatemachine.
A very powerful approach to making services fault tolerant is to model them as
“state machines” and then use the idea of replicated state machines that we describe
next.
A state machine receives inputs and has a stored state; it makes state transitions
oneachinputandmayoutputsomeresultsalongwiththestatetransition.Areplicated
state machine is a state machine that is replicated on multiple nodes to make it fault
tolerant.Intuitively,evenifoneofthenodesfails,thestateandoutputcanbeobtained
fromanyofthenodesthatarealive,providedallthestatemachinesareinaconsistent
state.Thekeytoensuringthatthestatemachinereplicasareconsistentisto(a)require
thestate machinestobe deterministic,and(b) ensure thatallreplicasgetexactlythe
sameinputinthesameorder.
To ensure that all replicas get exactly the same input in the same order, we just
appendtheinputstoareplicatedlog,using,forexample,techniqueswesawearlierin
Section23.8.3.Assoon asalogentryisdeterminedtobe committed,itcanbe given
asinputtothestatemachine,whichcanthenprocessit.
Figure23.10depictsareplicatedstatemachinebasedonareplicatedlog.Whena
clientissuesacommand,suchasy ← 7inthefigure,thecommandissenttotheleader,
wherethe commandisappended tothelog.Theleaderthenreplicatesthecommand
to the logs at the followers. Once a majority have confirmed that the command has
beenreplicatedintheirlogs,theleaderdeclaresthecommandcommittedandapplies
thecommandtoitsstatemachine.Italsoinformsthefollowersofthecommit,andthe
followersthenapplythecommandtotheirstatemachine.
IntheexampleinFigure23.10,thestate machinemerelyrecordsthevalueofthe
updatedvariable;butingeneral,thestatemachinemayexecuteanyotheractions.The
actionsare,however,requiredtobedeterministic,soallstate machinesareinexactly

--- Page 1189 ---

1160 Chapter23 ParallelandDistributedTransactionProcessing
the same state when they have executed the same set of commands; the order of exe-
cutionofcommandswillbethesamesincecommandsareexecutedinthelogorder.
Commandssuchaslockrequestmustreturnastatustothecaller.Thestatuscan
bereturnedfromanyoneofthereplicaswherethecommandisperformed.Mostim-
plementations return the status from the leader node, since the request is sent to the
leader, and the leaderisalso the firstnode to know when a logrecord has been com-
mitted(replicatedtoamajorityofthenodes).
Wenowconsidertwoapplicationsthatcanbemadefault-tolerantusingtherepli-
catedstatemachineconcept.
Wefirstconsiderhowtoimplementafault-tolerantlockmanager.Alockmanager
getscommands,namely,lockrequestsandreleases,andmaintainsastate(locktable).
Italsogivesoutput(lockgrantsorrollbackrequestsondeadlock)onprocessinginputs
(lock requests or releases). Lock managers can easily be coded to be deterministic,
thatis,giventhesameinput,thestate andoutput willbe thesameevenifthecodeis
executedagainonadifferentnode.
Thus, we can take a centralized implementation of a lock manager and run it on
each node. Lock requests and releases are appended to a replicated log using, for ex-
ample,theRaftprotocol.Oncealogentryiscommitted,thecorrespondingcommand
(lockrequestorrelease)canbeprocessed,inorder,bythelockmanagercodeateach
replica.Evenifsomeofthereplicasfail,theotherreplicascancontinueprocessingas
longasamajorityareupandconnected.
Now consider the issue of implementing a fault-tolerant key-value store. A single-
nodestoragesystemcanbemodeledasastatemachinethatsupportsput()andget()
operations.Thestorage system istreatedasastate machine,andthestatemachineis
runonmultiplenodes.
Theput()operationsareappendedtothelogusingaconsensusprotocolandare
processed when the consensus protocol declaresthe corresponding log records to be
committed(i.e.,replicatedtoamajorityofthenodes).
If the consensus protocol uses leaders, get() operations need not be logged, and
needtobeexecutedonlyontheleader.Toensurethataget()operationseesthemost
recent put() on the same data item, all put() operations on the same data item that
precede the get() operation in the logmust be committed before the get() operation
isprocessed.(Ifaconsensusprotocoldoesnotusealeader,get()operationscanalso
be logged and executed by at least one of the replicas which returns the value to the
caller.)
Google’sSpannerisanexampleofasystemthatusesthereplicatedstatemachine
approachtocreatingafault-tolerantimplementationofakey-valuestoragesystemand
alockmanager.
Toensurescalability,Spannerbreaksupdataintopartitions,eachofwhichhasa
subset of the data. Each partition has its data replicated across multiple nodes. Each
node runs two state machines: one for the key-value storage system, and one for the
lockmanager.ThesetofreplicasforaparticularpartitionarecalledaPaxosgroup;one

--- Page 1190 ---

23.8 ConsensusinDistributedSystems 1161
ofthenodesinaPaxosgroupactsasthePaxosgroupleader.Lockmanageroperations,
aswellaskey-valuestoreoperationsforaparticularpartition,areinitiatedatthePaxos
groupleaderforthatpartition.Theoperationsareappendedtoalog,whichisreplicated
totheothernodesin thePaxos groupusingthePaxos consensus protocol.2 Requests
areappliedinorderateachmemberofthePaxosgroup,oncetheyarecommitted.
Asanoptimization,get()operationsarenotlogged,andexecutedonlyattheleader
as described earlier. As a further optimization, Spanner allows reads to run as of a
particularpointintime,allowingreadstobeexecutedatanyreplicaofthepartition(in
otherwords,anyothermemberofthePaxosgroup)thatissufficientlyuptodate,based
onthemultiversiontwo-phaselockingprotocoldescribedearlierinSection23.5.1.
23.8.5 Two-Phase Commit Using Consensus
Givenaconsensusprotocolimplementation,wecanuseittocreateanon-blockingtwo-
phase commit implementation. The idea is simple: instead of a coordinator recording
itscommitorabortdecisionlocally,itusesaconsensusprotocoltorecorditsdecision
inareplicatedlog.Evenifthecoordinatorsubsequentlyfails,otherparticipantsinthe
consensusprotocolknowaboutthedecision,sotheblockingproblemisavoided.
In case the coordinator fails before making a decision for a transaction, a new
coordinator can first check the log to see if a decision was made earlier, and if not
it can make a commit/abort decision and use the consensus protocol to record the
decision.
Forexample,intheSpannersystemdevelopedbyGoogle,atransactionmayspan
multiple partitions. Two-phase commit is initiated by a client and coordinated by the
Paxos group leader at one of the partitions where the transaction executed. All other
partitionswhereanupdatewasperformedactsasaparticipantinthetwo-phasecommit
protocol.PrepareandcommitmessagesaresenttothePaxosgroupleadernodeofeach
of the partitions; recall that two-phase commit participants as well as coordinators
recorddecisionsintheirlocallogs.Thesedecisionsarerecordedbyeachleader,using
consensusinvolvingalltheothernodesinitsPaxosgroup.
IfaPaxosgroup memberotherthan the leaderdies,theleadercancontinue pro-
cessingthetwo-phasecommitsteps,aslongasamajorityofthegroupnodesareupand
connected.IfaPaxosgroupleaderfails,oneoftheothergroupmemberstakesoveras
thegroupleader.Notethatallthestateinformationrequiredtocontinuecommitpro-
cessing is available to the new leader. Log records written during commit processing
areavailablesincethelogisreplicated.Also,recallfromSection23.8.4thatSpanner
makes the lock manager fault tolerant by using the replicated state machine concept.
Thus,aconsistentreplicaofthelocktableisalsoavailablewiththenewleader.Thus,
thetwo-phasecommitstepsofboththecoordinatorandtheparticipantscancontinue
tobeexecutedevenifsomenodesfail.
2TheMulti-PaxosversionofPaxosisused,butweshalljustrefertoitasPaxosforsimplicity.

--- Page 1191 ---

1162 Chapter23 ParallelandDistributedTransactionProcessing
23.9 Summary
• A distributed database system consists of a collection of sites or nodes, each of
whichmaintainsalocaldatabasesystem.Eachnodeisabletoprocesslocaltrans-
actions:thosetransactionsthataccessdatainonlythatsinglenode.Inaddition,a
node may participate in the execution of global transactions: those transactions
that access data in several nodes. Transaction managers at each node manage
access to local data, while the transaction coordinator coordinates execution of
globaltransactionsacrossmultiplenodes.
• A distributed system may suffer from the same types of failure that can afflict a
centralizedsystem.Thereare,however,additionalfailureswithwhichweneedto
dealinadistributed environment,includingthefailureofanode,thefailureofa
link,lossofamessage,andnetworkpartition.Eachoftheseproblemsneedstobe
consideredinthedesignofadistributedrecoveryscheme.
• To ensure atomicity, all the nodes in which a transaction T executed must agree
onthefinaloutcomeoftheexecution.T eithercommitsatallnodesorabortsat
allnodes.Toensurethisproperty,thetransactioncoordinatorofT mustexecutea
commitprotocol.Themostwidelyusedcommitprotocolisthetwo-phasecommit
protocol.
• The two-phase commit protocol may lead to blocking, the situation in which the
fate of a transaction cannot be determined until a failed node (the coordinator)
recovers.Wecanusedistributed consensusprotocols,orthethree-phasecommit
protocol,toreducetheriskofblocking.
• Persistentmessagingprovidesanalternativemodelforhandlingdistributedtrans-
actions.Themodelbreaksasingletransactionintopartsthatareexecutedatdiffer-
ent databases. Persistent messages (which are guaranteed to be delivered exactly
once, regardless of failures), are sent to remote nodes to request actions to be
takenthere.Whilepersistentmessagingavoidstheblockingproblem,application
developershavetowritecodetohandlevarioustypesoffailures.
• Thevariousconcurrency-controlschemesusedinacentralizedsystemcanbemod-
ifiedforuseinadistributedenvironment.Inthecaseoflockingprotocols,theonly
changethatneedstobeincorporatedisinthewaythatthelockmanagerisimple-
mented.Centralizedlockmanagersare vulnerable tooverloadingand tofailures.
Deadlock detection in a distributed-lock-manager environment requires coopera-
tionbetweenmultiplenodes,sincetheremaybeglobaldeadlocksevenwhenthere
arenolocaldeadlocks.
• The timestamp ordering and validation based protocols can also be extended to
work in a distributed setting. Timestamps used to order transactions need to be
madegloballyunique.

--- Page 1192 ---

23.9 Summary 1163
• Protocolsforhandlingreplicateddatamust ensureconsistencyof data.Lineariz-
abilityisakey property thatensuresthatconcurrentreadsand writestoreplicas
ofasingledataitemcanbeserialized.
• Protocolsforhandlingreplicateddataincludetheprimarycopy,majority,biased,
andquorumconsensusprotocols.Thesehavedifferenttrade-offsintermsofcost
andabilitytoworkinthepresenceoffailures.
• Themajorityprotocolcanbeextendedbyusingversionnumberstopermittrans-
actionprocessingtoproceed evenin the presenceof failures.Whiletheprotocol
hasasignificantoverhead,itworksregardlessofthetypeoffailure.Less-expensive
protocolsare available to deal withnode failures, but they assume network parti-
tioningdoesnotoccur.
• Toprovidehighavailability,adistributeddatabasemustdetectfailures,reconfigure
itself so that computation may continue, and recover when a processor or a link
isrepaired.Thetaskisgreatlycomplicatedbythefactthatitishardtodistinguish
betweennetworkpartitionsandnodefailures.
• Globallyconsistentanduniquetimestampsarekeytoextendingmultiversiontwo-
phaselockingandsnapshotisolationtoadistributedsetting.
• TheCAPtheoremindicatesthatonecannothaveconsistencyandavailabilityinthe
faceofnetworkpartitions.Manysystemstradeoffconsistencytogethigheravail-
ability.Thegoal thenbecomeseventualconsistency, ratherthanensuringconsis-
tencyatalltimes.Detectinginconsistencyofreplicascanbedonebyusingversion
vectorschemesandMerkletrees.
• Manydatabasesystemssupportasynchronousreplication,whereupdatesareprop-
agatedtoreplicasoutsidethescopeofthetransactionthatperformedtheupdate.
Such facilitiesmust be used with great care, since they may result in nonserializ-
ableexecutions.
• Some of the distributed algorithms require the use of a coordinator. To provide
highavailability,thesystemmustmaintainabackupcopythatisreadytoassume
responsibilityifthecoordinatorfails.Anotherapproachistochoosethenewcoor-
dinatorafterthecoordinatorhasfailed.Thealgorithmsthatdeterminewhichnode
should act as a coordinator are called election algorithms. Distributed coordina-
tionservicessuch asZooKeepersupport coordinatorselectioninafault-tolerant
manner.
• Distributedconsensusalgorithmsallowconsistentupdatesofreplicas,eveninthe
presence of failures, without requiring the presence of a coordinator. Coordina-
tors may still be used for efficiency, but failure of a coordinator does not affect
correctnessoftheprotocols.PaxosandRaftarewidelyusedconsensusprotocols.
Replicated state machines, which are implemented using consensus algorithms,
canbeusedtobuildavarietyoffault-tolerantservices.

--- Page 1193 ---

1164 Chapter23 ParallelandDistributedTransactionProcessing
Review Terms
• Distributedtransactions ° Biasedprotocol
° Localtransactions ° Quorumconsensusprotocol
° Globaltransactions • Robustness
• Transactionmanager ° Majority-basedapproach
• Transactioncoordinator ° Readone,writeall
• Systemfailuremodes
° Readone,writeallavailable
• Networkpartition
° Node/Sitereintegration
• Commitprotocols
• Two-phasecommitprotocol(2PC) • Externalconsistency
• Commitwait
° Readystate
• CAPtheorem
° In-doubttransactions • BASEproperties
° Blockingproblem • Asynchronousreplication
• Distributedconsensus • Lazypropagation
• Three-phasecommitprotocol • Master–slavereplication
(3PC) • Multimaster(update-anywhere)
• Persistentmessaging replication
• Concurrencycontrol • Asynchronousviewmaintenance
• Singlelockmanager • Eventualconsistency
• Distributedlockmanager • Version-vectorscheme
• Deadlockhandling • Merkletree
• Coordinatorselection
° Localwait-forgraph
• Backupcoordinator
° Globalwait-forgraph • Electionalgorithms
° Falsecycles • Bullyalgorithm
• Lockleases • Term
• Timestamping • Distributedconsensusprotocol
• Replicateddata • Paxos
• Linearizability ° Proposers
• Protocolsforreplicas ° Acceptors
° Primarycopy ° Learners
° Majorityprotocol • Raft

--- Page 1194 ---

PracticeExercises 1165
• Leaders • Faulttolerantlockmanager
• Followers • Non-blockingtwo-phasecommit
• Replicatedstatemachine
Practice Exercises
23.1 What are the key differences between a local-area network and a wide-area
network,thataffectthedesignofadistributeddatabase?
23.2 To build a highly available distributed system, you must know what kinds of
failurescanoccur.
a. Listpossibletypesoffailureinadistributedsystem.
b. Whichitemsinyourlistfrompartaarealsoapplicabletoacentralized
system?
23.3 Considerafailurethatoccursduring2PCforatransaction.Foreachpossible
failurethatyoulistedinExercise23.2a,explainhow2PCensurestransaction
atomicitydespitethefailure.
23.4 Consider a distributed system with two sites, A and B. Can site A distinguish
amongthefollowing?
• Bgoesdown.
• ThelinkbetweenAandBgoesdown.
• Bisextremelyoverloadedandresponsetimeis100timeslongerthannor-
mal.
Whatimplicationsdoesyouranswerhaveforrecoveryindistributedsystems?
23.5 The persistent messaging scheme described in this chapter depends on time-
stamps.Adrawbackisthattheycandiscardreceivedmessagesonlyiftheyare
too old, and may need to keep track of a large number of received messages.
Suggest an alternative scheme based on sequence numbers instead of time-
stamps,thatcandiscardmessagesmorerapidly.
23.6 Explainthedifferencebetweendatareplicationinadistributedsystemandthe
maintenanceofaremotebackupsite.
23.7 Give an example where lazy replication can lead to an inconsistent database
stateevenwhenupdatesgetanexclusivelockontheprimary(master)copyif
datawerereadfromanodeotherthanthemaster.
23.8 Considerthefollowingdeadlock-detectionalgorithm.WhentransactionT,at
i
site S , requests a resource from T, at site S , a request message with time-
1 j 3

--- Page 1195 ---

1166 Chapter23 ParallelandDistributedTransactionProcessing
stamp n is sent. The edge (T,T,n) is inserted in the local wait-for graph of
i j
S . The edge (T,T,n) is inserted in the local wait-for graph of S only if T
1 i j 3 j
hasreceivedtherequestmessageandcannotimmediatelygranttherequested
resource.ArequestfromT toT inthesamesiteishandledintheusualman-
i j
ner;notimestampsareassociatedwiththeedge(T,T).Acentralcoordinator
i j
invokes the detection algorithm by sendingan initiatingmessage to each site
inthesystem.
On receiving this message, a site sends its local wait-for graph to the co-
ordinator. Note that such a graph contains all the local information that the
sitehasaboutthestateoftherealgraph.Thewait-forgraphreflectsaninstan-
taneous state of the site, but it is not synchronized with respect to any other
site.
When the controller has received a reply from each site, it constructs a
graphasfollows:
• Thegraphcontainsavertexforeverytransactioninthesystem.
• Thegraphhasanedge(T,T)ifandonlyif:
i j
° Thereisanedge(T,T)inoneofthewait-forgraphs.
i j
° An edge (T,T,n) (for some n) appears in more than one wait-for
i j
graph.
Showthat,ifthereisacycleintheconstructedgraph,thenthesystemisina
deadlockstate,andthat,ifthereisnocycleintheconstructedgraph,thenthe
systemwasnotinadeadlockstatewhentheexecutionofthealgorithmbegan.
23.9 Considerthechain-replicationprotocol,describedinSection23.4.3.2,which
isavariantoftheprimary-copyprotocol.
a. Iflockingisusedforconcurrencycontrol,whatistheearliestpointwhen
aprocesscanreleaseanexclusivelockafterupdatingadataitem?
b. Whileeachdataitemcouldhaveitsownchain,givetworeasonsitwould
be preferable tohave achaindefined atahigherlevel,such as foreach
partitionortablet.
c. How can consensus protocols be used to ensure that the chain is
uniquelydeterminedatanypointintime?
23.10 If the primary copy scheme is used for replication, and the primary gets dis-
connectedfromtherestofthesystem,anewnodemaygetelectedasprimary.
But the old primary may not realize it has got disconnected, and may get re-
connectedsubsequentlywithoutrealizingthatthereisanewprimary.
a. Whatproblemscanariseiftheoldprimarydoesnotrealizethatanew
onehastakenover?
b. Howcanleasesbeusedtoavoidtheseproblems?

--- Page 1196 ---

Exercises 1167
c. Wouldsuchasituation,whereaparticipantnodegetsdisconnectedand
thenreconnectedwithoutrealizingitwasdisconnected,causeanyprob-
lemwiththemajorityorquorumprotocols?
23.11 Consider a federated database system in which it is guaranteed that at most
oneglobaltransaction isactiveatanytime,andeverylocalsite ensureslocal
serializability.
a. Suggest ways in which the federated database system can ensure that
thereisatmostoneactiveglobaltransactionatanytime.
b. Showbyexamplethatitispossibleforanonserializableglobalschedule
toresultdespitetheassumptions.
23.12 Consider a federated database system in which every local site ensures local
serializability,andallglobaltransactionsarereadonly.
a. Show by example that nonserializable executions may result in such a
system.
b. Showhowyoucoulduseaticketschemetoensureglobalserializability.
23.13 Suppose you have a large relation r(A,B,C) and a materialized view
v = γ (r). View maintenance can be performed as part of each trans-
A sum(B)
action that updates r, on a parallel/distributed storage system that supports
transactions across multiple nodes. Suppose the system uses two-phase com-
mitalongwithaconsensusprotocolsuchasPaxos,acrossgeographicallydis-
tributeddatacenters.
a. Explainwhyitisnotagoodideatoperformviewmaintenanceaspartof
theupdatetransaction,ifsomevaluesofattributeAare“hot”atcertain
pointsintime,thatis,manyupdatespertaintothosevaluesofA.
b. Explainhowoperationlocking(ifsupported)couldsolvethisproblem.
c. Explain the tradeoffs of using asynchronous view maintenance in this
context.
Exercises
23.14 What characteristics of an application make it easy to scale the application
by using a key-value store, and what characteristics rule out deployment on
key-valuestores?
23.15 Giveanexample wherethereadone,writeallavailableapproachleadstoan
erroneousstate.

--- Page 1197 ---

1168 Chapter23 ParallelandDistributedTransactionProcessing
23.16 Inthemajorityprotocol,whatshouldthereaderdoifitfindsdifferentvalues
fromdifferentcopies,to(a)decidewhatisthecorrectvalue,and(b)tobring
the copies back to consistency? If the reader does not bother to bring the
copiesbacktoconsistency,woulditaffectcorrectnessoftheprotocol?
23.17 Ifweapplyadistributedversionofthemultiple-granularityprotocolofChap-
ter 18 to a distributed database, the site responsible for the root of the DAG
maybecomeabottleneck.Supposewemodifythatprotocolasfollows:
• Onlyintention-modelocksareallowedontheroot.
• All transactions are given the strongest intention-mode lock (IX) on the
rootautomatically.
Showthatthesemodificationsalleviatethisproblemwithoutallowinganynon-
serializableschedules.
23.18 Discuss the advantages and disadvantages of the two methods that we pre-
sentedinSection23.3.4forgeneratinggloballyuniquetimestamps.
23.19 Spannerprovidesread-onlytransactionsasnapshotviewofdata,usingmulti-
versiontwo-phaselocking.
a. In the centralized multi-version 2PL scheme, read-only transactions
neverwait.ButinSpanner,readsmayhavetowait.Explainwhy.
b. Using an older timestamp for the snapshot can reduce waits, but has
somedrawbacks.Explainwhy,andwhatthedrawbacksare.
23.20 Merkle trees can be made short and fat (like B+-trees) or thin and tall (like
binarysearchtrees).Whichoptionwouldbebetterifyouarecomparingdata
acrosstwositesthataregeographicallyseparated,andwhy?
23.21 Whyisthenotionoftermimportantwhenanelectionisusedtochooseaco-
ordinator?Whataretheanalogiesbetweenelectionswithtermsandelections
usedinademocracy?
23.22 Forcorrectexecutionofareplicatedstatemachine,theactionsmustbedeter-
ministic.Whatcouldhappenifanactionisnon-deterministic?
Further Reading
Textbook coverage of distributed transaction processing, including concurrency con-
trol and the two-phase and three-phase commit protocols, is provided by [Bernstein
and Goodman(1981)] and[Bernstein andNewcomer(2009)]. Textbook discussions
of distributed databases are offered by [Ozsu and Valduriez (2010)]. A collection of
papersondatamanagementoncloudsystemsisin[OoiandParthasarathy(2009)].

--- Page 1198 ---

FurtherReading 1169
The implementation of the transaction concept in a distributed database is pre-
sentedby[Gray(1981)]and[Traigeretal.(1982)]. The2PCprotocolwasdeveloped
by [Lampson and Sturgis (1976)]. The three-phase commit protocol is from [Skeen
(1981)]. Techniques for non-blocking two-phase commit based on consensus, called
PaxosCommit,aredescribedin[GrayandLamport(2004)].
Chain replication was initially proposed by [van Renesse and Schneider (2004)]
andanoptimizedversionofwasproposedby[TerraceandFreedman(2009)].
Distributedoptimisticconcurrencycontrolisdescribedin[Agrawaletal.(1987)],
whiledistributedsnapshotisolationisdescribedin[Binnigetal.(2014)]and[Schenkel
etal.(1999)].Theexternallyconsistentdistributedmulti-version2PLschemeusedin
Spannerisdescribedin[Corbettetal.(2013)].
The CAP theorem was conjectured by [Brewer (2000)], and was formalized and
proved by [Gilbert and Lynch (2002)]. [Cooper et al. (2008)] describe Yahoo!’s
PNUTS system, including its support for asynchronous maintenance of replicas us-
ingapublish-subscribe system. Parallelviewmaintenanceisdescribedin[Chenetal.
(2004)]and[Zhangetal.(2004)],whileasynchronousviewmaintenanceisdescribed
in [Agrawal et al. (2009)]. Transaction processing in federated database systems is
discussedin[Mehrotraetal.(2001)].
Paxos is described in [Lamport (1998)]; Paxos is based on features from several
earlierprotocols,referencein[Lamport(1998)].Google’sChubbylockservice,which
isbasedonPaxos,isdescribedby[Burrows(2006)].ThewidelyusedZooKeepersys-
temfordistributedcoordinationisdescribedin[Huntetal.(2010)],andtheconsensus
protocol (also known as atomic broadcast protocol) used in ZooKeeper is described
in[Junqueiraetal.(2011)].TheRaftconsensusprotocolisdescribedin[Ongaroand
Ousterhout(2014)].
Bibliography
[Agrawaletal.(1987)] D. Agrawal, A. Bernstein, P. Gupta, and S. Sengupta, “Distributed
optimistic concurrency control with reduced rollback”, Distributed Computing, Volume 2,
Number1(1987),pages45–59.
[Agrawaletal.(2009)] P. Agrawal, A. Silberstein, B. F. Cooper, U. Srivastava, and R. Ra-
makrishnan, “Asynchronous view maintenance for VLSD databases”, In Proc. of the ACM
SIGMODConf.onManagementofData(2009),pages179–192.
[BernsteinandGoodman(1981)] P.A.BernsteinandN.Goodman,“ConcurrencyControl
inDistributedDatabaseSystems”,ACMComputingSurveys,Volume13,Number2(1981),
pages185–221.
[BernsteinandNewcomer(2009)] P.A.BernsteinandE.Newcomer,PrinciplesofTransaction
Processing,2ndedition,MorganKaufmann(2009).
[Binnigetal.(2014)] C. Binnig, S. Hildenbrand, F. FÃ¤rber, D. Kossmann, J. Lee, and
N.May,“Distributedsnapshotisolation:globaltransactionspayglobally,localtransactions

--- Page 1199 ---

1170 Chapter23 ParallelandDistributedTransactionProcessing
paylocally”,VLDBJournal,Volume23,Number6(2014),pages987–1011.
[Brewer(2000)] E.A.Brewer,“TowardsRobustDistributedSystems(Abstract)”,InProc.of
theACMSymposiumonPrinciplesofDistributedComputing(2000),page7.
[Burrows(2006)] M.Burrows,“TheChubbyLockServiceforLoosely-CoupledDistributed
Systems”,InSymp.onOperatingSystemsDesignandImplementation(OSDI)(2006),pages
335–350.
[Chenetal.(2004)] S. Chen, B. Liu, and E. A. Rundensteiner, “Multiversion-based view
maintenanceoverdistributeddatasources”,ACMTransactionsonDatabaseSystems,Volume
29,Number4(2004),pages675–709.
[Cooperetal.(2008)] B.F.Cooper,R.Ramakrishnan,U.Srivastava,A.Silberstein,P.Bo-
hannon, H.-A. Jacobsen, N. Puz, D. Weaver, and R. Yerneni, “PNUTS: Yahoo!’s Hosted
DataServingPlatform”,ProceedingsoftheVLDBEndowment,Volume1,Number2(2008),
pages1277–1288.
[Corbettetal.(2013)] J. C. Corbett et al., “Spanner: Google’s Globally Distributed
Database”,ACMTrans.onComputerSystems,Volume31,Number3(2013).
[GilbertandLynch(2002)] S.GilbertandN.Lynch,“Brewer’sConjectureandtheFeasibil-
ity of Consistent, Available, Partition-Tolerant Web Services”, SIGACT News, Volume 33,
Number2(2002),pages51–59.
[Gray(1981)] J.Gray,“TheTransactionConcept:VirtuesandLimitations”,InProc.ofthe
InternationalConf.onVeryLargeDatabases(1981),pages144–154.
[GrayandLamport(2004)] J. Gray and L. Lamport, “Consensus on transaction commit”,
ACMTransactionsonDatabaseSystems,Volume31,Number1(2004),pages133–160.
[Huntetal.(2010)] P. Hunt, M. Konar, F. Junqueira, and B. Reed, “ZooKeeper: Wait-free
CoordinationforInternet-scaleSystems”,InUSENIXAnnualTechnicalConference(USENIX
ATC)(2010),pages11–11.
[Junqueiraetal.(2011)] F. P. Junqueira, B. C. Reed, and M. Serafini, “Zab: High-perfor-
mance broadcastfor primary-backup systems”,InIEEE/IFIP41stInternational Conference
onDependableSystemsNetworks(DSN)(2011),pages245–256.
[Lamport(1998)] L.Lamport,“ThePart-TimeParliament”,ACMTrans.Comput.Syst.,Vol-
ume16,Number2(1998),pages133–169.
[LampsonandSturgis(1976)] B.LampsonandH.Sturgis,“CrashRecoveryinaDistributed
Data Storage System”, Technical report, Computer Science Laboratory, Xerox Palo Alto
ResearchCenter,PaloAlto(1976).
[Mehrotraetal.(2001)] S. Mehrotra, R. Rastogi, Y. Breitbart, H. F. Korth, and A. Silber-
schatz, “Overcoming Heterogeneity and Autonomy in Multidatabase Systems.”, Inf. Com-
put.,Volume167,Number2(2001),pages137–172.
[OngaroandOusterhout(2014)] D.OngaroandJ.K.Ousterhout,“InSearchofanUnder-
standableConsensusAlgorithm”,InUSENIXAnnualTechnicalConference (USENIXATC)
(2014),pages305–319.

--- Page 1200 ---

FurtherReading 1171
[OoiandParthasarathy(2009)] B.C.OoiandS.Parthasarathy,“SpecialIssueonDataMan-
agementonCloudComputingPlatforms”,IEEEDataEngineeringBulletin,Volume32,Num-
ber1(2009).
[OzsuandValduriez(2010)] T.OzsuandP.Valduriez,PrinciplesofDistributedDatabaseSys-
tems,3rdedition,PrenticeHall(2010).
[Schenkeletal.(1999)] R. Schenkel, G. Weikum, N. Weisenberg, and X. Wu, “Federated
TransactionManagementwithSnapshotIsolation”,InEightInternationalWorkshoponFoun-
dationsofModelsandLanguagesforDataandObjects,TransactionsandDatabaseDynamics
(1999),pages1–25.
[Skeen(1981)] D.Skeen,“Non-blockingCommitProtocols”,InProc.oftheACMSIGMOD
Conf.onManagementofData(1981),pages133–142.
[TerraceandFreedman(2009)] J.TerraceandM.J.Freedman,“ObjectStorageonCRAQ:
High-ThroughputChainReplicationforRead-MostlyWorkloads”,InUSENIXAnnualTech-
nicalConference(USENIXATC)(2009).
[Traigeretal.(1982)] I.L.Traiger,J.N.Gray,C.A.Galtieri,andB.G.Lindsay,“Transac-
tionsandConsistencyinDistributedDatabaseManagementSystems”,ACMTransactionson
DatabaseSystems,Volume7,Number3(1982),pages323–342.
[vanRenesseandSchneider(2004)] R.vanRenesseandF.B.Schneider,“ChainReplication
forSupportingHighThroughputandAvailability”,InSymp.onOperatingSystemsDesignand
Implementation(OSDI)(2004),pages91–104.
[Zhangetal.(2004)] X. Zhang, L. Ding, and E. A. Rundensteiner, “Parallel multisource
viewmaintenance”,VLDBJournal,Volume13,Number1(2004),pages22–48.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 1202 ---

9
PART
ADVANCED TOPICS
Chapter 24 providesfurther detailsabout the indexstructures we coveredin Chapter
14. In particular, this chapter provides detailed coverage of the LSM tree and its vari-
ants,bitmapindices,andspatialindexing,allofwhichwerecoveredinbriefinChapter
14.Thechapteralsoprovidesdetailedcoverageofdynamichashingtechniques.
Chapter25discussesanumberoftasksinvolvedinapplicationdevelopment.Ap-
plications can be made to run significantly faster by performance tuning, which con-
sists of finding and eliminatingbottlenecks and adding appropriate hardware such as
memoryordisks.Applicationperformanceisevaluatedusingbenchmarks,whichare
standardized sets of tasks that help to characterize the performance of database sys-
tems.Anotherimportantaspectofapplicationdevelopmentistesting,whichrequires
the generation of database states and test inputs, followed by checking that the ac-
tual outputs of a query or a program on the test input match the expected outputs.
Lastly, standards are very important for application development. A variety of stan-
dards have been proposed that affect database-application development. We outline
severalofthesestandardsinthischapter.
Chapter26coversblockchaintechnologyfromadatabaseperspective.Thischap-
ter identifies the ways in which blockchain databases differ from the traditional
databases covered elsewhere in this text and shows how these distinguishing features
areimplemented.AlthoughblockchainsystemsareoftenassociatedwithBitcoin,this
chaptergoesbeyondBitcoin-stylealgorithmsandimplementationtofocusonalterna-
tivesthataremoresuitedtoanenterprisedatabaseenvironment.
1173

--- Page 1204 ---

24
CHAPTER
Advanced Indexing Techniques
Westudiedtheconceptofindexing,aswellasanumberofdifferentindexstructuresin
Chapter14.Whilesomeindexstructures,suchasB+-trees,werecoveredindetail,oth-
ers such as hashing, write-optimizedindices,bitmap indices,and spatial indiceswere
onlybrieflyoutlinedinChapter14.Inthischapterweprovidefurtherdetailsofthese
index structures. We provide detailed coverage of the LSM tree and its variants. We
thenprovideadetaileddescriptionofbitmapindices.Next,weprovidemoredetailed
coverageofspatialindexing,coveringquadtreesandR-treesinmoredetail.Finally,we
coverhashing,withdetailedcoverageofdynamichashingtechniques.
24.1 Bloom Filter
A Bloom filter is a probabilistic data structure that can check for membership of a
value in a set using very little space, but at a small risk of overestimating the set of
elementsthatareintheset.ABloomfilterisbasicallyabitmap.Ifthesethasnvalues,
the associated bitmaphasafew timesn (typically10n) bits; theBloom filteralsohas
associated with it several hash functions. We assume initially that there is only one
hashfunctionh().
The bitsinthe bitmapare allinitiallysetto0; subsequently, eachvalue inthe set
isread,andthehashfunctionh(v)iscomputedontheelementv,withtherangeofthe
function being 1 to 10n. The bit at position h(v) is then set to 1. This is repeated for
everyelementv.Tocheckifaparticularvaluevispresentintheset,thehashfunction
h(v)iscomputed.Ifbith(v)intheBloomfilterisequalto0,wecaninferthatvcannot
possibly be in the set. However, if bit h(v) is equal to 1, v may be present in the set.
Notethatwithsomeprobability,thebith(v)maybe1evenifvisnotpresent,ifsome
othervaluev′,presentinthesethash(v′) = h(v).Thus,alookupforvresultsinafalse
positive.
Toreducethechanceoffalsepositives,Bloomfiltersusekindependenthashfunc-
tions h(),i = 1..k, for some k > 1; for each value v in the set, bits corresponding to
i
h(v),i = 1..k are all set to 1 in the bitmap. When querying the Bloom filter with a
i
1175

--- Page 1205 ---

1176 Chapter24 AdvancedIndexingTechniques
givenvaluevthesamekhashfunctionsareusedtoidentifykbitlocations;thevaluev
isdeterminedtobeabsentifevenoneofthesebitshasa0value.Otherwisethevalue
isjudgedtobepotentiallypresent.Forexample,ifthebitmaphas10nbits,wherenis
the number of values in the set, and k = 7 hash functions are used, the false positive
ratewouldbeabout1%.
24.2 Log-Structured Merge Tree and Variants
As we saw in Section 14.8, B+-tree indices are not efficient for workloads with a very
high number of writes, and alternative index structures have been proposed to han-
dle such workloads. We saw a brief description of two such index structures, the log-
structuredmergetreeorLSMtreeanditsvariants,inSection14.8.1,andthebuffertree,
inSection14.8.2.InthissectionweprovidefurtherdetailsoftheLSMtreeanditsvari-
ants.Tohelpwiththediscussions,werepeatsomeofthebasicmaterialwepresented
inSection14.8.1.
Thekeyideaofthelog-structuredmergetree(LSMtree)istoreplacerandomI/O
operations during tree inserts, updates, and deleteswith a smallernumber of sequen-
tial I/O operations. Our initial description focuses on index inserts and lookups; we
describehowtohandleupdatesanddeleteslaterinthesection.
An LSM tree consists of several B+-trees, starting with an in-memory tree, called
L ,andon-disktreesL ,L ,…,L forsomek,wherek iscalledthelevel.Figure24.1
0 1 2 k
depictsthestructureofanLSMtreefork = 3.
Anindexlookupisperformedbyusingseparatelookupoperationsoneachofthe
trees L ,…,L , and merging the results of the lookups. (We assume here that there
0 k
are no updates or deletes; we will discuss how to perform lookups in the presence of
updates/deleteslater.)
L0 Memory
L1
Disk
L2
L3
Figure 24.1 Log-structured mergetreewiththreelevels.

--- Page 1206 ---

24.2 Log-StructuredMergeTreeandVariants 1177
24.2.1 Insertion into LSM Trees
WhenarecordisfirstinsertedintoanLSMtree,itisinsertedintothein-memoryB+-
treestructureL .Afairlylargeamountofmemoryspaceisallocatedforthistree.Asthe
0
treegrowstofillthememoryallocatedtoit,weneedtomovedatafromthein-memory
structuretoaB+-treeondisk.
If tree L is empty, the entire in-memory tree L is written to disk to create the
1 0
initialtreeL .However,ifL isnotempty,theleaflevelofL isscannedinincreasing
1 1 0
key order, and entries are merged with the leaf level entries of L (also scanned in
1
increasing key order). The merged entries are used to create a new B+-tree using the
bottom-upbuildprocess.ThenewtreewiththemergedentriesthenreplacestheoldL .
1
Ineithercase,afterentriesofL havebeenmovedtoL ,allentriesinL aredeleted.
0 1 0
InsertscanthenbemadetothenowemptyL .
0
NotethatallentriesintheleafleveloftheoldL tree,includingthoseinleafnodes
1
thatdonothaveanyupdates,arecopiedtothenewtreeinsteadofbeinginsertedinto
theexistingL treenode.Thisgivesthefollowingbenefits:
1
• The leaves of the new tree are sequentially located, avoiding random I/O during
subsequentmerges.
• The leaves are full, avoiding the overhead of partially occupied leaves that can
occurwithpagesplits.
Thereis,however,acosttousingtheLSMstructure:theentirecontentsofthetreeare
copiedeachtimeasetofentriesfromL arecopiedintoL .
0 1
If the tree structure is implemented on top of a distributed file system (Section
21.6), copying data to a new tree is often unavoidable, since most distributed file sys-
temsdonotsupportupdatestoanalreadycreatedblock.
To ensure we get a benefit for cases where the index size on disk is much bigger
thanthein-memoryindex,themaximumsizeofL ischosenasktimesthetargetsize
1
ofL ,forsomek.Similarly,themaximumsizeofeachL issettoktimesthetarget
0 i+1
sizeofL.OnceaparticularL reachesitsmaximumsize,itsentriesaremergedintothe
i i
nextcomponentL .WhenL reachesitstargetsize,itsentriesareinturnmerged
i+1 i+1
intoL ,andsoon.
i+2
Note that if eachleaf of L has m entries, m∕k entrieswould mapto a single leaf
i
nodeofL .Thevalueofkischosentoensurethatm∕kissomereasonablenumber,
i+1
say 10. Let M denote the size of L . Then, the size of a tree at level L is kiM. The
0 i
totalnumberoflevelsristhusroughlylog (I∕M)whereI isthetotalsizeoftheindex
k
entries.
Let us now consider the number of I/O operations required with a multiple-level
LSM tree. At each L, m∕k inserts are performed using only one I/O operation. On
i
theotherhand,eachentrygetsinserted onceateachlevelL.Thus, thetotalnumber
i
of I/O operations for each insert is (k∕m)log (I∕M). Thus, as long as the number of
k

--- Page 1207 ---

1178 Chapter24 AdvancedIndexingTechniques
levelsr = log (I∕M)islessthanm∕k,theoverallnumberofI/Ooperationsperinsert
k
isreducedbyusinganLSMtreeascomparedtodirectinsertionintoaB+-tree.
If,forexample,r = 10andk = 10,thein-memoryindexneedstobegreaterthan
1% of the total index size to get a benefit in terms of the number of I/O operations
requiredforinserts.(Asbefore,thebenefitofreducedseeksisavailableeveniftheL
0
issignificantlysmaller.)
If the number of levels is greater than m∕k, even if there is no benefit in terms
of number of I/O operations, there can still be savings since sequential I/O is used
insteadofrandomI/O.InSection24.2.4wedescribeavariantoftheLSMtreewhich
further reduces the overhead on write operations, at the cost of adding overhead on
readoperations.
OnewaytoavoidcreatinglargeLSMtreeswithmanylevelsistorangepartitionthe
relation and create separate LSM treeson each partition. Such partitioning isnatural
in a parallel environment, as we saw earlier in Section 21.2. In particular, in such en-
vironments,apartitioncanbedynamicallyrepartitionedintosmallerpieceswhenever
itbecomestoolarge,aswesawinSection21.3.3.Withsuchrepartitioning,thesizeof
eachLSMtreecanbekeptsmallenoughtoavoidhavingalargenumberoflevels.There
isapriceforsuchpartitioning:eachpartitionrequiresitsownL treeinmemory.Asa
0
result, although itcan be used in acentralizedsetting,the partitioning approach best
fitsaparallelenvironmentwhereresourcessuchasprocessingnodescanbeaddedas
theloadincreases.
24.2.2 Rolling Merges
We assumed for simplicity that when a particular level is full, its entries are entirely
merged with the next level. This would result in more I/O load during merges with
an unused I/Ocapacitybetweenmerges. Toavoid thisproblem,mergingisdone on a
continuousbasis;thisiscalledrollingmerge.
Withrollingmerge,afewpagesofL aremergedintocorrespondingpagesofL
i i+1
at a time, and removed from L. This is done whenever L becomes close to its target
i i
size,anditresultsinL shrinkingabittoreturntoitstargetsize.WhenL growsagain,
i i
therollingmergerestartsfromapointattheleaflevelofL justafterwheretheearlier
i
rollingmergestopped,sothescanissequential.WhentheendoftheL treeisreached,
i
thescanstartsagainatthebeginningofthetree.Suchamergeiscalledarollingmerge
sincerecordsaremovedfromoneleveltoanotheronacontinuousbasis.
Thenumberofleavesmergedatatimeiskepthighenoughtoensurethattheseek
timeissmallcomparedtothetimetotransferdatafromandtodisk.
24.2.3 Handling Deletes and Updates
Sofarwehaveonlydescribedinsertsandlookups.Deletesarehandledinaninteresting
manner. Instead of directly finding an index entry and deleting it, deletion results in
insertionofanewdeletionentrythatindicateswhichindexentryistobedeleted.The

--- Page 1208 ---

24.2 Log-StructuredMergeTreeandVariants 1179
L Memory
0
L 0 1 L 0 k Disk
L 1 1 L k 1
L 1 2 L k 2
Figure 24.2 stepped-mergeindex
process of inserting a deletion entry is identical to the process of inserting a normal
indexentry.
However, lookups have to carry out an extra step. As mentioned earlier, lookups
retrieveentriesfromallthetreesandmergetheminsortedorderofkeyvalue.Ifthere
isadeletionentryforsomeentry,bothofthemwouldhavethesamekeyvalue.Thus,
alookupwouldfindboththedeletionentryandtheoriginalentryforthatkey,which
is to be deleted. If a deletion entry is found, the to-be-deleted entry should be filtered
outandnotreturnedaspartofthelookupresult.
When trees are merged, if one of the trees contains an entry, and the other had
a matching deletion entry, the entries get matched up during the merge (both would
havethesamekey),andarebothdiscarded.
Updatesarehandledinamannersimilartodeletes,byinsertingan update entry.
Lookups need to match update entries with the original entries and return the latest
value. The update isactuallyappliedduringamerge, whenone tree hasan entryand
anotherhasitsmatchingupdateentry;theupdateisappliedduringthemerge,andthe
updateentryisdiscarded.
24.2.4 The Stepped-Merge Index
We now consider a variant of the LSM tree, which has multiple trees at each level
instead of one tree per level and performs inserts in a slightly different manner. This
structureisshowninFigure24.2.Wecallthestructureastepped-mergeindex,following
theterminologyinanearlypaperthatintroducedit.Inthedevelopercommunity,the
basicLSMtree,thestepped-mergeindex,andseveralothervariantsareallreferredtoas
LSMtrees.Weusethetermsstepped-mergeindexandbasicLSMtreetoclearlyidentify
whichvariantwearereferringto.

--- Page 1209 ---

1180 Chapter24 AdvancedIndexingTechniques
24.2.4.1 InsertionAlgorithm
Inthestepped-mergeindex,incomingdataareinitiallystoredinmemory,inanL tree,
0
inamannersimilartotheLSMtree.However,whenthetreereachesitsmaximumsize,
instead of merging it into an L tree, the in-memory L tree is written to disk. When
1 0
the in-memory tree again reaches its maximum size, it is again written to disk. Thus,
wemayhave multipleL treesondisk,whichweshallrefertoasL1,L2 andsoforth.
0 0 0
Each of the Li trees is a B+-tree and can be written to disk using only sequential I/O
0
operations.
If this process is repeated, after a while we would have a large number of trees,
eachaslargeasmemory,storedondisk.Lookupswouldthenhavetopayahighprice,
sincetheywouldhavetosearchthrougheachofthetreestructures,incurringseparate
I/Ocostsoneachsearch.
To limit the overhead on lookups, once the number of on-disk trees at a level L
i
reaches some limit k, all the trees at a level are merged together into one combined
new tree structure at the next level L . The leaves of the trees at level L are read
i+1 i
sequentially,andthekeysmergedinsortedorder,andthelevelL treeisconstructed
i+1
usingstandardtechniquesforbottom-upconstructionofB+-trees.Asbefore,themerge
operation avoids random I/O operations, since it reads the individual tree structures
sequentiallyandwritestheresultantmergedtreealsosequentially.
Onceasetoftreesaremergedintoasinglenewtree,futurequeriescansearchthe
mergedtree;theoriginaltreescanthenbedeleted(afterensuringanyongoingsearches
havecompleted).
Thebenefitofthestepped-mergeindexschemeascomparedtothebasicLSMtree
isthatindexentriesarewrittenoutonlyonceperlevel.WiththebasicLSMtree,each
timeatreeatlevelL ismergedintoatreeatlevelL ,theentirecontentsoftheL
i i+1 i+1
treeisreadandwrittenbacktodisk.Thus,onaverage,eachrecordisreadandwritten
backk∕2timesateachlevelofanLSMtreeforatotalofklog (I∕M)I/Ooperations.In
k
contrast, with stepped-merge index, each record is written to disk once per layer, and
read again when merging into the next layer, for a total of approximately 2log (I∕M)
k
I/Ooperations.Thus,thestepped-mergeindexincurssignificantlylesscostforupdates.
The total number of bytes written (across all levels) on account of inserting an
entry, divided by the size of entry, is called the write amplification. To calculate the
write amplificationof the LSMtreesand the stepped-merge index,wecan modifythe
aboveformulaeforI/Ooperationsbyignoringthereads.ForaB+-treewhereeachleaf
getsonaverageonlyoneupdatebeforeitiswrittenback,thewriteamplificationwould
bethesizeofthepagedividedbythesizeoftheindexentry.
ForaB+-tree,ifapagehas100entries,thewriteamplificationwouldbe100.With
k = 5,andI = 100M,wewouldhavelog (100) = 3levels.Thewriteamplificationof
5
anLSMtreewouldthenbe5∕2×3 =7.5.Thewriteamplificationofthestepped-merge
indexwouldbe3.Withk =10,thetreewouldhavelog (100) = 2levels,leadingtoa
10
writeamplificationof2forstepped-mergeindex,and10foranLSMtree.

--- Page 1210 ---

24.2 Log-StructuredMergeTreeandVariants 1181
Note that like the basic LSM tree, the stepped-merge index also requires no ran-
domI/Ooperationsduringinsertion,incontrasttoaB+-treeinsertion.Thus,theper-
formanceofB+-treeswouldbeworsethanwhatthewriteamplificationnumberabove
indicates.
Merging can be optimized as follows: While merging k trees at a particular level
L,intoalevelL tree,treesatlevelsL,j < icanalsobemergedinatthesametime.
i i+1 j
Entries in these trees can thus entirely skip one or more levels of the stepped-merge
index. Further, if the system has idle capacity, trees at a level L can be merged even
i
ifthere arefewerthank treesatthat level.In asituation wherethere isalongperiod
oftimewithveryfewinserts,andthesystem loadislight,treesacrossalllevelscould
potentiallygetmergedintoasingletreeatsomelevelr.
24.2.4.2 LookupOperationsUsingBloomFilters
Lookupoperationsinstepped-mergeindexhavetoseparatelysearcheachofthetrees.
Thus,comparedtothebasicLSMscheme,thestepped-mergeindexincreasesthebur-
den on lookups, since in the worst case lookups need to access k trees at each level,
leadingtoatotalofk ∗ log (I∕M)treelookups,insteadoflog (I∕M)treelookupsin
k k
theworstcasewithabasicLSMtree.
Forworkloadswithasignificantfractionofreads,thisoverheadcanbeunaccept-
able. For example, with the stepped-merge index with I = 100M and k = 5, a single
lookup requires 15 tree traversals, while the LSM tree would require 3 tree traversals.
Notethatforthecommoncasewhereeachkeyvalueoccursinonlyonetree,onlyone
ofthetraversalswouldfindagivensearchkey,whilealltheothertraversalswouldfail
tofindthekey.
Toreducethecost ofpointlookups (i.e.,lookups of agiven key value), most sys-
temsuseaBloomfiltertocheckifatreecanpossiblycontainthegivenkeyvalue.One
Bloom filterisassociated witheach tree,and itisbuilton the setof key values in the
tree.Tocheckifaparticulartreemaycontainasearchkeyv,thekeyvislookedupin
theBloomfilter.IftheBloomfilterindicatesthatthekeyvalueisabsent,itisdefinitely
notpresentinthetree,andlookupcanskipthattree.Otherwise,thekeyvaluemaybe
presentinthetree,whichmustbelookedup.
A Bloom filter with 10n bits, where the tree has n elements, and using 7 hash
functionswouldgiveafalsepositiverateof1percent.Thus,foralookuponakeythat
ispresentintheindex,onaveragejustslightlymorethanonetreewouldbeaccessed.
Thus,lookupperformancewouldbeonlyslightlyworsethanonaregularB+-tree.
TheBloomfiltercheckthusworksverywellforpointlookups,allowingasignificant
fractionofthetreestobeskipped,aslongassufficientmemoryisavailabletostoreall
theBloomfiltersinmemory.WithI keyvaluesintheindex,approximately10I bitsof
memory will be required. To reduce the main memory overhead, some of the Bloom
filtersmaybestoredonflashstorage.
Note that for range lookups, the Bloom filter optimization cannot be used, since
thereisnouniquehashvalue.Instead,alltreesmustbeaccessedseparately.

--- Page 1211 ---

1182 Chapter24 AdvancedIndexingTechniques
24.2.5 LSM Trees For Flash Storage
LSMtreeswereinitiallydesignedtoreducethewriteandseekoverheadsofharddisks.
Flash disks have a relatively low overhead for random I/O operations since they do
not require seek, and thus the benefit of avoiding random I/O that LSM tree variants
provideisnotparticularlyimportantwithflashdisks.
However,recallthatflashmemorydoesnotallowin-placeupdate,andwritingeven
asinglebytetoapagerequiresthewholepagetoberewrittentoanewphysicallocation;
the original location of the page needs to be erased eventually, which is a relatively
expensive operation. The reduction in write amplification using LSMtree variants, as
compared to traditional B+-trees, can provide substantial performance benefits when
LSMtreesareusedwithflashstorage.
24.3 Bitmap Indices
As we saw in Section 14.9, a bitmap index is a specialized type of index designed for
easyqueryingonmultiplekeys.Bitmapsworkbestforattributesthattakeonlyasmall
numberofdistinctvalues.
Forbitmapindicestobeused,recordsinarelationmustbenumberedsequentially,
startingfrom,say,0.Givenanumbern,itmustbeeasytoretrievetherecordnumbered
n.Thisisparticularlyeasytoachieveifrecordsarefixedinsizeandallocatedoncon-
secutiveblocksofafile.Therecordnumbercanthenbetranslatedeasilyintoablock
numberandanumberthatidentifiestherecordwithintheblock.
Recall that column-oriented storage, described in Section 13.6, stores attributes in
arrays,allowingefficientaccessoftheattributeoftheithrecord,foranygiveni.Bitmap
indicesarethusparticularlyusefulwithcolumnarstorage.
Weuseasarunningexamplearelationinstructor info,whichhasanattributegen-
der,whichcantakeonlyvaluesm(male)orf(female),andanattributeincome level,
where income has been broken up into 5 levels: L1: 0-9999, L2: 10,000-19,999, L3:
20,000-39,999,L4:40,000-74,999,andL5:75,000−∞.
24.3.1 Bitmap Index Structure
As we saw in Section 14.9, a bitmap is simply an array of bits. In its simplest form, a
bitmapindexontheattributeAofrelationr consistsofonebitmapforeachvaluethat
Acantake.Eachbitmaphasasmanybitsasthenumberofrecordsintherelation.The
ithbitofthebitmapforvaluev issetto1iftherecordnumberedihasthevaluev for
j j
attributeA.Allotherbitsofthebitmaparesetto0.
In our example, there is one bitmap for the value m and one for f. The ith bit of
thebitmapformissetto1ifthegendervalueoftherecordnumberediism.Allother
bitsofthebitmapformaresetto0.Similarly,thebitmapforfhasthevalue1forbits
corresponding to records with the value f for the gender attribute; all other bits have

--- Page 1212 ---

24.3 BitmapIndices 1183
Bitmaps for gender Bitmaps for
record income_level
m 10010
number ID gender income_level
L1 10100
0 76766 m L1 f 01101
1 22222 f L2 L2 01000
2 12121 f L1 L3 00001
3 15151 m L4
L4 00010
4 58583 f L3
L5 00000
Figure 24.3 Bitmapindicesonrelationinstructorinfo.
the value 0. Figure 24.3 shows an example of bitmap indices on a relation instructor
info
We now consider when bitmaps are useful. The simplest way of retrieving all
recordswithvaluem(orvaluef)wouldbetosimplyreadallrecordsoftherelationand
selectthoserecordswithvaluem(orf,respectively).Thebitmapindexdoesn’treally
help to speed up such a selection. While it would allow us to read only those records
foraspecificgender,itislikelythateverydiskblockforthefilewouldhavetoberead
anyway.
In fact, bitmap indices are useful for selections mainly when there are selections
on multiple keys. Suppose we create a bitmap index on attribute income level, which
wedescribedearlier,inadditiontothebitmapindexongender.
Consider now a query that selects women with income in the range $10,000 to
$19,999.Thisquerycanbeexpressedas
select*
frominstructor info
wheregender='f'andincome level='L2';
To evaluate this selection, we fetch the bitmaps for gender value f and the bitmap for
income level valueL2andperformanintersection(logical-and)ofthetwobitmaps.In
otherwords,wecomputeanewbitmapwherebitihasvalue1iftheithbitofthetwo
bitmaps are both 1 and has a value 0 otherwise. In the example in Figure 24.3, the
intersectionofthebitmapforgender =𝖿 (01101)andthebitmapforincome level = L2
(01000)givesthebitmap01000.
Sincethefirstattributecantaketwovalues,andthesecondcantakefivevalues,we
wouldexpectonlyabout1in10records,onanaverage,tosatisfyacombinedcondition
onthetwoattributes.Iftherearefurtherconditions,thefractionofrecordssatisfying
all the conditions is likely to be quite small. The system can then compute the query
resultbyfindingallbitswithvalue1intheintersectionbitmapandretrievingthecor-

--- Page 1213 ---

1184 Chapter24 AdvancedIndexingTechniques
respondingrecords.Ifthefraction islarge, scanningtheentirerelationwouldremain
thecheaperalternative.
Another important use of bitmaps is to count the number of tuples satisfying a
givenselection.Suchqueriesareimportantfordataanalysis.Forinstance,ifwewish
tofindouthowmanywomenhaveanincomelevelL2,wecomputetheintersectionof
thetwobitmapsandthencountthenumberofbitsthatare1intheintersectionbitmap.
We can thus get the desiredresult from the bitmap index, without even accessingthe
relation.
Bitmapindicesaregenerallyquitesmallcomparedtotheactualrelationsize.Rec-
ordsaretypicallyatleasttensofbytes tohundredsofbytes long,whereasasinglebit
representstherecordinabitmap.Thus,thespaceoccupiedbyasinglebitmapisusually
less than 1 percent of the space occupied by the relation. For instance, if the record
size for a given relation is 100 bytes, then the space occupied by a single bitmap will
be 1 of1percentofthespaceoccupiedbytherelation.IfanattributeAoftherelation
8
can take on only one of eight values, a bitmap index on attribute A would consist of
eightbitmaps,whichtogetheroccupyonly1percentofthesizeoftherelation.
Deletionofrecordscreatesgapsinthesequenceofrecords,sinceshiftingrecords
(or record numbers) to fill gaps would be extremely expensive. To recognize deleted
records,wecanstoreanexistencebitmap,inwhichbitiis0ifrecordidoesnotexistand
1otherwise.WeshallseetheneedforexistencebitmapsinSection24.3.2.Insertionof
recordsshouldnotaffectthesequencenumberingofotherrecords.Therefore,wecan
doinsertioneitherbyappendingrecordstotheendofthefileorbyreplacingdeleted
records.
24.3.2 Efficient Implementation of Bitmap Operations
We can compute the intersection of two bitmaps easily by using a for loop: the ith
iterationoftheloopcomputestheandoftheithbitsofthetwobitmaps.Wecanspeed
upcomputationoftheintersectiongreatlybyusingbit-wiseandinstructionssupported
bymostcomputerinstructionsets.Aword usuallyconsistsof32or64bits,depending
on the architecture of the computer. A bit-wise and instruction takes two words as
inputandoutputsawordwhereeachbitisthelogicalandofthebitsincorresponding
positions of the input words. What is important to note is that a single bit-wise and
instructioncancomputetheintersectionof32or64bitsatonce.
If a relation had 1 million records, each bitmap would contain 1 million bits, or
equivalently 128 kilobytes. Only31,250 instructions are needed to compute the inter-
sectionoftwobitmapsforourrelation,assuminga32-bitwordlength.Thus,computing
bitmapintersectionsisanextremelyfastoperation.
Just as bitmap intersection is useful for computing the and of two conditions,
bitmap union is useful for computing the or of two conditions. The procedure for
bitmapunionisexactlythesameasforintersection,exceptweusebit-wiseorinstruc-
tionsinsteadofbit-wiseandinstructions.

--- Page 1214 ---

24.3 BitmapIndices 1185
Thecomplementoperationcanbeusedtocomputeapredicateinvolvingthenega-
tion of a condition, such as not (income-level = L1). The complement of a bitmap is
generatedbycomplementingeverybitofthebitmap(thecomplementof1is0andthe
complementof0is1).Itmayappearthatnot(income level =L1)canbeimplemented
byjustcomputingthecomplementofthebitmapforincomelevelL1.Ifsomerecords
have been deleted, however, just computing the complement of a bitmap is not suffi-
cient.Bitscorrespondingtosuchrecordswouldbe0intheoriginalbitmapbutwould
become1inthecomplement,althoughtherecordsdon’texist.Asimilarproblemalso
arises when the value of an attribute is null. For instance, if the value of income level
isnull,thebitwouldbe0intheoriginalbitmapforvalueL1and1inthecomplement
bitmap.
To make sure that the bits corresponding to deleted records are set to 0 in the
result, the complement bitmap must be intersected with the existence bitmap to turn
offthebitsfordeletedrecords.Similarly,tohandlenullvalues,thecomplementbitmap
mustalsobeintersectedwiththecomplementofthebitmapforthevaluenull.1
Countingthenumberofbitsthatare1inabitmapcanbedonequicklybyaclever
technique. We can maintain an array with 256 entries, where the ith entry stores the
numberofbitsthatare1inthebinaryrepresentationofi.Setthetotalcountinitially
to 0. We take each byte of the bitmap, use it to index into this array, and add the
storedcounttothetotalcount.Thenumberofadditionoperationsis 1 ofthenumber
8
of tuples, and thus the counting process is very efficient. A large array (using 216 =
65,536 entries), indexed by pairs of bytes, would give even higher speedup, but at a
higherstoragecost.
+
24.3.3 Bitmaps and B -Trees
Bitmaps can be combined with regular B+-tree indices for relations where a few at-
tribute values are extremely common, and other values also occur, but much less fre-
quently.InaB+-treeindexleaf,foreachvaluewewouldnormallymaintainalistofall
records with that value for the indexed attribute. Each element of the list would be a
recordidentifier,consistingofatleast32bits,andusuallymore.Foravaluethatoccurs
inmanyrecords,westoreabitmapinsteadofalistofrecords.
Suppose a particular value v occurs in 1 of the records of a relation. Let N be
i 16
the number of records in the relation, and assume that a record has a 64-bit number
identifyingit.Thebitmapneedsonly1bitperrecord,orN bitsintotal.Incontrast,the
listrepresentationrequires64bitsperrecordwherethevalueoccurs,or64 ∗ N∕16 =
4N bits. Thus, a bitmap is preferable for representing the list of records for value v.
i
In our example (with a 64-bit record identifier), if fewer than 1 in 64 records have a
particular value, the list representation is preferable for identifying records with that
1Handlingpredicatessuchasisunknownwouldcausefurthercomplications,whichwouldingeneralrequireuseofan
extrabitmaptotrackwhichoperationresultsareunknown.

--- Page 1215 ---

1186 Chapter24 AdvancedIndexingTechniques
value, since it uses fewer bits than the bitmap representation. If more than 1 in 64
recordshavethatvalue,thebitmaprepresentationispreferable.
Thus, bitmaps can be used as a compressed storage mechanismat the leaf nodes
ofB+-treesforthosevaluesthatoccurveryfrequently.
24.4 Indexing of Spatial Data
As we saw in Section 14.10.1, indices are required for efficient access to spatial data,
and such indicesmust efficiently support queries such as range and nearest neighbor
queries.Wealsogaveabriefoverviewofk-dtrees,quadtrees,andR-trees;wealsobriefly
describedhowtoanswerrangequeriesusingk-dtrees.Inthissectionweprovidefurther
detailsofquadtreesandR-trees.
AsmentionedinSection14.10.1,inadditiontoindexingofpoints,spatialindices
must alsosupport indexingofregionsofspace such aslinesegments, rectangles,and
otherpolygons.Thereareextensionsofk-dtreesandquadtreesforthistask.However,
alinesegmentorpolygonmaycrossapartitioningline.Ifitdoes,ithastobesplitand
representedineachofthesubtreesinwhichitspiecesoccur.Multipleoccurrencesofa
linesegmentorpolygoncausedbysuchsplitscanresultininefficienciesinstorage,as
wellasinefficienciesinquerying.R-treesweredevelopedtosupportefficientindexing
ofsuchstructures.
24.4.1 Quadtrees
Analternativerepresentationfortwo-dimensionaldataareaquadtree.Anexampleof
thedivisionofspacebyaquadtreeappearsinFigure24.4.Eachnodeofaquadtreeis
Figure 24.4 Divisionofspacebyaquadtree.

--- Page 1216 ---

24.4 IndexingofSpatialData 1187
associatedwitharectangularregionofspace.Thetopnodeisassociatedwiththeentire
target space. Each nonleaf node in a quadtree divides its region into four equal-sized
quadrants,andcorrespondinglyeachsuchnodehasfourchildnodescorrespondingto
the four quadrants. Leaf nodes have between zero and some fixed maximum number
of points. Correspondingly, if the region corresponding to a node has more than the
maximum number of points, childnodesare created forthatnode. In the example in
Figure24.4,themaximumnumberofpointsinaleafnodeissetto1.
ThistypeofquadtreeiscalledaPRquadtree,toindicateitstorespoints,andthat
thedivisionofspaceisdividedbasedonregions,ratherthanontheactualsetofpoints
stored. We can use region quadtrees to store array (raster) information. A node in a
regionquadtreeisaleafnodeifallthearrayvaluesintheregionthatitcoversarethe
same.Otherwise,itissubdividedfurtherintofourchildrenofequalareaandistherefore
aninternalnode.Eachnodeintheregionquadtreecorrespondstoasubarrayofvalues.
Thesubarrayscorrespondingtoleaveseithercontainjustasinglearrayelementorhave
multiplearrayelements,allofwhichhavethesamevalue.
24.4.2 R-Trees
A storage structure called an R-tree is useful for indexing of objects such as points,
line segments, rectangles, and other polygons. An R-tree is a balanced tree structure
withtheindexedobjectsstoredinleafnodes,muchlikeaB+-tree.However,insteadof
a range of values, a rectangular bounding box is associated with each tree node. The
boundingboxofaleafnodeisthesmallestrectangleparalleltotheaxesthatcontains
all objects stored in the leaf node. The bounding box of internal nodes is, similarly,
thesmallestrectangleparalleltotheaxesthatcontainstheboundingboxesofitschild
nodes.Theboundingboxofanobject(suchasapolygon)isdefined,similarly,asthe
smallestrectangleparalleltotheaxesthatcontainstheobject.
Each internal node stores the bounding boxes of the child nodes along with the
pointerstothechildnodes.Eachleafnodestorestheindexedobjectsandmayoption-
allystoretheboundingboxesoftheobjects;theboundingboxeshelpspeedupchecks
for overlaps of the rectangle with the indexed objects—if a query rectangle does not
overlap with the bounding box of an object, it cannot overlap with the object, either.
(Iftheindexedobjectsarerectangles,thereisnoneedtostore boundingboxes, since
theyareidenticaltotherectangles.)
Figure24.5showsanexampleofasetofrectangles(drawnwithasolidline)and
theboundingboxes(drawnwithadashedline)ofthenodesofanR-treeforthesetof
rectangles. Note that the bounding boxes are shown with extra space inside them, to
make them stand out pictorially. In reality, the boxes would be smaller and fit tightly
ontheobjectsthattheycontain;thatis,eachsideofaboundingboxBwouldtouchat
leastoneoftheobjectsorboundingboxesthatarecontainedinB.
TheR-treeitselfisattherightsideofFigure24.5.Thefigurereferstothecoordi-
natesofboundingboxiasBB inthefigure.
i

--- Page 1217 ---

1188 Chapter24 AdvancedIndexingTechniques
A B
1
C
BB BB BB
1 2 3
G
3
H A B C D E F G H I
D I
2
E
F
Figure 24.5 AnR-tree.
We shall now see how to implement search, insert, and delete operations on an
R-tree.
• Search. As the figure shows, the bounding boxes associated with sibling nodes
may overlap; in B+-trees, k-d trees, and quadtrees, in contrast, the ranges do not
overlap. A search for objects containing a point therefore has to follow all child
nodes whose associated bounding boxes contain the point; as a result, multiple
pathsmayhavetobesearched.Similarly,aquerytofindallobjectsthatintersecta
givenobjecthastogodowneverynodewheretheassociatedrectangleintersects
thegivenobject.
• Insert. When weinsertan objectintoan R-tree,weselectaleafnode toholdthe
object.Ideallyweshouldpickaleafnodethathasspacetoholdanewentry,and
whose bounding box contains the bounding box of the object. However, such a
nodemaynotexist;evenifitdid,findingthenodemaybeveryexpensive,sinceit
isnotpossibletofinditbyasingletraversaldownfromtheroot.Ateachinternal
nodewemayfindmultiplechildrenwhoseboundingboxescontainthebounding
box of the object, and each of these children needs to be explored. Therefore, as
a heuristic, in a traversal from the root, if any of the child nodes has a bounding
box containingtheboundingbox oftheobject,theR-treealgorithmchoosesone
of them arbitrarily. If none of the children satisfy this condition, the algorithm
chooses a child node whose bounding box has the maximum overlap with the
boundingboxoftheobjectforcontinuingthetraversal.
Oncetheleafnodehasbeenreached,ifthenodeisalreadyfull,thealgorithm
performsnodesplitting(andpropagatessplittingupwardifrequired)inamanner
verysimilartoB+-treeinsertion.JustaswithB+-treeinsertion,theR-treeinsertion
algorithmensuresthatthetreeremainsbalanced.Additionally,itensuresthatthe

--- Page 1218 ---

24.4 IndexingofSpatialData 1189
bounding boxes of leaf nodes, as well as internal nodes, remain consistent; that
is, bounding boxes of leaves contain all the bounding boxes of the objects stored
atthe leaf, whilethe bounding boxes for internal nodes contain allthe bounding
boxesofthechildrennodes.
The main difference of the insertion procedure from the B+-tree insertion
procedure lies in how the node is split. In a B+-tree, it is possible to find a value
suchthathalftheentriesarelessthanthemidpointandhalfaregreaterthanthe
value.Thispropertydoesnotgeneralizebeyond onedimension;thatis,formore
than one dimension, it is not always possible to split the entries into two sets so
thattheirboundingboxesdonotoverlap.Instead,asaheuristic,thesetofentries
ScanbesplitintotwodisjointsetsS andS sothattheboundingboxesofS and
1 2 1
S havetheminimumtotalarea;anotherheuristicwouldbetosplittheentriesinto
2
twosetsS andS in such away thatS andS have minimumoverlap.The two
1 2 1 2
nodesresultingfromthesplitwouldcontaintheentriesinS andS ,respectively.
1 2
The cost of finding splits with minimum total area or overlap can itself be large,
socheaperheuristics,suchasthequadraticsplitheuristic,areused.(Theheuristic
getsitsnamefromthefactthatittakestimequadraticinthenumberofentries.)
The quadratic split heuristic works this way: First, it picks a pair of entries a
andbfromSsuchthatputtingtheminthesamenodewouldresultinabounding
box withthe maximum wasted space; thatis, the areaof theminimumbounding
box ofaandbminusthesum oftheareasofaandbisthelargest. Theheuristic
placestheentriesaandbinsetsS andS ,respectively.
1 2
Ittheniterativelyaddstheremainingentries,oneentryperiteration,tooneof
thetwosetsS orS .Ateachiteration,foreachremainingentrye,leti denote
1 2 e,1
the increase in the size of the bounding box of S if e is added to S and let i
1 1 e,2
denotethecorrespondingincreaseforS .Ineachiteration,theheuristicchooses
2
oneoftheentrieswiththemaximumdifferenceofi andi andaddsittoS if
e,1 e,2 1
i isless than i , and to S otherwise. That is, an entry with “maximum prefer-
e,1 e,2 2
ence”forS orS ischosenateachiteration.Theiterationstopswhenallentries
1 2
have been assigned, or when one of the sets S or S has enough entries that all
1 2
remainingentrieshavetobeaddedtotheothersetsothenodesconstructedfrom
S andS bothhavetherequiredminimumoccupancy.Theheuristicthenaddsall
1 2
unassignedentriestothesetwithfewerentries.
• Deletion.DeletioncanbeperformedlikeaB+-treedeletion,borrowingentriesfrom
siblingnodes,ormergingsiblingnodesifanodebecomesunderfull.Analternative
approachredistributesalltheentriesofunderfullnodestosiblingnodes,withthe
aimofimprovingtheclusteringofentriesintheR-tree.
Seethebibliographicalreferencesformoredetailsoninsertionanddeletionoperations
onR-trees,aswellasonvariantsofR-trees,calledR∗-treesorR+-trees.
ThestorageefficiencyofR-treesisbetterthanthatofk-dtreesorquadtrees,since
an object is stored only once, and we can ensure easily that each node is at least half

--- Page 1219 ---

1190 Chapter24 AdvancedIndexingTechniques
full.However,queryingmaybeslower,sincemultiplepathshavetobesearched.Spatial
joinsaresimplerwithquadtreesthanwithR-trees,sinceallquadtreeson aregionare
partitionedinthesamemanner.However,becauseoftheirbetterstorageefficiencyand
their similarity to B-trees, R-trees and their variants have proved popular in database
systemsthatsupportspatialdata.
24.5 Hash Indices
We described the concepts of hashing and hash indices in Section 14.5. We provide
furtherdetailsinthissection.
24.5.1 Static Hashing
As in Section 14.5, let K denote the set of all search-key values, and let B denote the
setofallbucketaddresses.AhashfunctionhisafunctionfromK toB.Lethdenotea
hashfunction.Recallthatinahashindex,bucketscontainindexentries,withpointers
torecords,whileinahashfileorganization,actualrecordsarestoredinthebuckets.All
the other details remain the same, so we do not explicitly differentiate between these
twoversionshenceforth.Weusethetermhashindextodenotehashfileorganizations
aswellassecondaryhashindices.
Figure24.6showsasecondaryhashindexontheinstructor file,forthesearchkey
ID. The hash function in the figure computes the sum of the digits of the ID modulo
8.Thehashindexhaseightbuckets,eachofsize2(realisticindiceswouldhavemuch
largerbucketsizes).Oneofthebucketshasthreekeysmappedtoit,soithasanoverflow
bucket.Inthisexample,IDisaprimarykeyforinstructor,soeachsearchkeyhasonly
oneassociatedpointer.Ingeneral,multiplepointerscanbeassociatedwitheachkey.
Hash indices can efficiently answer point queries, which retrieve records with a
specifiedvalueforasearchkey.However,theycannotefficientlyanswerrangequeries,
whichretrieveallrecordswhosesearchkeyvalueliesinarange(lb,ub).Thedifficulty
arisesbecauseagoodhashfunctionassignsvaluesrandomlytobuckets.Thus,thereis
nosimplenotionof“nextbucketinsortedorder.”Thereasonwecannotchainbuckets
together in sorted order on A is that each bucket is assigned many search-key values.
i
Since values are scattered randomly by the hash function, the values in the specified
rangearelikelytobescatteredacrossmanyorallofthebuckets.Therefore,wehaveto
readallthebucketstofindtherequiredsearchkeys.
Recall that deletion isdone as follows: If the search-key value of the record to be
deletedisK,wecomputeh(K),thensearchthecorrespondingbucketforthatrecord,
i i
anddeletetherecordfromthebucket.Deletionofarecordisefficientiftherearenot
many records with a given key value. However, in the case of a hash index on a key
with many duplicates, a large number of entries with the same key value may have to
bescannedtofindtheentryfortherecordthatistobedeleted.Thecomplexitycanin
theworstcasebelinearinthenumberofrecords.

--- Page 1220 ---

24.5 HashIndices 1191
bucket 0
76766
bucket 1
45565
76543
bucket 2
22222 76766 Crick Biology 72000
10101 Srinivasan Comp. Sci. 65000
45565 Katz Comp. Sci. 75000
bucket 3
83821 Brandt Comp. Sci. 92000
10101
98345 Kim Elec. Eng. 80000
12121 Wu Finance 90000
bucket 4 76543 Singh Finance 80000
32343 El Said History 60000
58583 Califieri History 62000
15151 Mozart Music 40000
bucket 5 22222 Einstein Physics 95000
15151 58583 33465 Gold Physics 87000
33456 98345
bucket 6
83821
bucket 7
12121
32343
Figure 24.6 HashindexonsearchkeyIDofinstructor file.
Recallalsothatwithstatichashing,thesetofbucketsisfixedatthetimetheindex
is created. If the relation grows far beyond the expected size, hash indices would be
quite inefficientduetolongoverflow chains.Wecouldrebuildthehash indexusinga
largernumberofbuckets.Suchrebuildingcanbetriggeredwhenthenumberofrecords
exceedstheestimatednumberbysomemargin,andtheindexisrebuiltwithanumber
ofbucketsthatisamultipleoftheoriginalnumberofbuckets(saybyafactorof1.5to
2).Suchrebuildingisinfactdoneinmanysystemswithin-memoryhashindices.
However,doingsocancausesignificantdisruptiontonormalprocessingwithlarge
relations, since a large number of records have to be reindexed; the disruption is par-
ticularly marked with disk-resident data. In this section we discuss dynamic hashing
techniquesthatallowhashindicestogrowgradually,withoutcausingdisruption.

--- Page 1221 ---

1192 Chapter24 AdvancedIndexingTechniques
24.5.1.1 HashFunctions
Theworstpossiblehashfunctionmapsallsearch-keyvaluestothesamebucket.Such
afunctionisundesirablebecausealltherecordshavetobekeptinthesamebucket.A
lookuphastoexamineeverysuchrecordtofindtheonedesired.Anidealhashfunction
distributesthestoredkeysuniformlyacrossallthebuckets,sothateverybuckethasthe
samenumberofrecords.
Since we do not know at design time precisely which search-key values will be
stored inthe file,we wantto choose ahash function thatassigns search-key values to
bucketsinsuchawaythatthedistributionhasthesequalities:
• Thedistributionisuniform.Thatis,thehashfunctionassignseachbucketthesame
numberofsearch-keyvaluesfromthesetofall possiblesearch-keyvalues.
• Thedistributionisrandom.Thatis,intheaveragecase,eachbucketwillhavenearly
the same number of values assigned to it, regardless of the actual distribution of
search-key values. More precisely, the hash value will not be correlated to any
externally visible ordering on the search-key values, such as alphabetic ordering
or ordering by the length of the search keys; the hash function will appear to be
random.
Asanillustrationoftheseprinciples,letuschooseahashfunctionfortheinstructor
file using the search key dept name. The hash function that we choose must have the
desirablepropertiesnotonlyontheexampleinstructorfilethatwehavebeenusing,but
alsoonaninstructor fileofrealisticsizeforalargeuniversitywithmanydepartments.
Assume that we decide to have 26 buckets, and we define a hash function that
maps namesbeginning with theith letterof the alphabet to the ith bucket. This hash
functionhasthevirtueofsimplicity,butitfailstoprovideauniformdistribution,since
weexpectmorenamestobeginwithsuchlettersasBandRthanQandX,forexample.
Nowsupposethatwewantahashfunctiononthesearchkeysalary.Supposethat
theminimumsalaryis$30,000andthemaximumsalaryis$130,000,andweuseahash
function thatdividesthevaluesinto10ranges, $30,000–$40,000, $40,001–$50,000,
and so on. The distribution of search-key values is uniform (since each bucket has
the same number of differentsalary values) but is not random. Records with salaries
between $60,001 and $70,000 are far more common than are records with salaries
between $30,001 and $40,000. As a result, the distribution of records is not uniform
—some buckets receive more records than others do. If the function has a random
distribution, even if there are such correlations in the search keys, the randomness
of the distribution will make it very likely that all buckets will have roughly the same
number of records, as long as each search key occurs in only a small fraction of the
records. (If a single search key occurs in a large fraction of the records, the bucket
containingitislikelytohave morerecordsthan otherbuckets, regardlessof the hash
functionused.)

--- Page 1222 ---

24.5 HashIndices 1193
bucket 0 bucket 4
12121 Wu Finance 90000
76543 Singh Finance 80000
bucket 1 bucket 5
15151 Mozart Music 40000 76766 Crick Biology 72000
bucket 2 bucket 6
32343 El Said History 80000 10101 Srinivasan Comp. Sci. 65000
58583 Califieri History 60000 45565 Katz Comp. Sci. 75000
83821 Brandt Comp. Sci. 92000
bucket 3 bucket 7
22222 Einstein Physics 95000
33456 Gold Physics 87000
98345 Kim Elec.Eng. 80000
Figure 24.7 Hashorganization ofinstructor file,withdeptname asthekey.
Typical hash functions perform computation on the internal binarymachinerep-
resentation of characters in the search key. A simple hash function of this type first
computesthesumofthebinaryrepresentationsofthecharactersofakey,thenreturns
thesummodulothenumberofbuckets.
Figure 24.7 shows the application of such a scheme, with eight buckets, to the
instructorfile,undertheassumptionthattheithletterinthealphabetisrepresentedby
theintegeri.
The following hash function is a better alternative for hashing strings. Let s be a
string of length n, and let s[i] denote the ith byte of the string. The hash function is
definedas:
s[0] ∗ 31(n−1) +s[1] ∗ 31(n−2)+⋯+s[n−1]
Thefunctioncanbeimplementedefficientlybysettingthehashresultinitiallyto0and
iterating from the first to the last character of the string, at each step multiplying the
hashvalueby31andthenaddingthenextcharacter(treatedasaninteger).Theabove
expression would appear to result in a very large number, but it is actually computed
with fixed-size positive integers; the result of each multiplication and addition is thus
automaticallycomputedmodulothelargestpossibleintegervalueplus1.Theresultof
theabovefunctionmodulothenumberofbucketscanthenbeusedforindexing.

--- Page 1223 ---

1194 Chapter24 AdvancedIndexingTechniques
Hash functions require careful design. A bad hash function may result in lookup
takingtimeproportionaltothenumberofsearchkeysinthefile.Awell-designedfunc-
tion gives an average-case lookup time that is a (small) constant, independent of the
numberofsearchkeysinthefile.
24.5.1.2 HandlingofBucketOverflows
Sofar,wehaveassumedthat,whenarecordisinserted,thebuckettowhichitismapped
hasspacetostoretherecord.Ifthebucketdoesnothaveenoughspace,abucketover-
flow issaid to occur. Bucket overflow can occurfor several reasons, as we outlined in
Section14.5.
• Insufficientbuckets.Thenumberofbuckets,whichwedenoten ,mustbechosen
B
such that n > n ∕f , where n denotes the total number of records that will be
B r r r
storedandf denotesthenumberofrecordsthatwillfitinabucket.Thisdesigna-
r
tionassumesthatthetotalnumberofrecordsisknownwhenthehashfunctionis
chosen.
• Skew. Some buckets are assigned more records than are others, so a bucket may
overflow even when otherbuckets still have space. Thissituation is calledbucket
skew.Skewcanoccurfortworeasons:
1.Multiplerecordsmayhavethesamesearchkey.
2.The chosen hash function may result in nonuniform distribution of search
keys.
So that the probability of bucket overflow is reduced, the number of buckets is
chosen to be (n ∕f ) ∗ (1+d), where d is a fudge factor, typically around 0.2. Some
r r
space is wasted: About 20 percent of the space in the buckets will be empty. But the
benefitisthattheprobabilityofoverflowisreduced.
Despite allocation of a few more buckets than required, bucket overflow can still
occur.AswesawinSection14.5,wehandlebucketoverflowbyusingoverflowbuckets.
Wemustalsochangethelookupalgorithmslightlytohandleoverflowchaining,tolook
attheoverflowbucketsinadditiontothemainbucket.
The form of hash structure that we have just described is called closed address-
ing (or, less commonly, closed hashing). Under an alternative approach called open
addressing (or, less commonly, open hashing), the set of buckets is fixed, and there
are no overflow chains. Instead, if a bucket is full, the system inserts records in some
other bucket in the initial set of buckets B. One policy is to use the next bucket (in
cyclicorder)thathasspace;thispolicyiscalledlinearprobing.Otherpolicies,suchas
computingfurtherhashfunctions,arealsoused.Openaddressinghasbeenusedtocon-
structsymboltablesforcompilersandassemblers,butclosedaddressingispreferable
fordatabasesystems.Thereasonisthatdeletionunderopenaddressingistroublesome.
Usually, compilers and assemblers perform only lookup and insertion operations on

--- Page 1224 ---

24.5 HashIndices 1195
theirsymboltables.However,inadatabasesystem,itisimportanttobeabletohandle
deletion as well as insertion. Thus, open addressing is of only minor importance in
databaseimplementation.
An important drawback to the form of hashing that we have described is that
we must choose the hash function when we implement the system, and it cannot be
changedeasilythereafterifthefilebeingindexedgrowsorshrinks.Sincethefunctionh
mapssearch-keyvaluestoafixedsetBofbucketaddresses,wewastespaceifBismade
largetohandlefuturegrowthofthefile.IfBistoosmall,thebucketscontainrecords
ofmanydifferentsearch-keyvalues,andbucketoverflowscanoccur.Asthefilegrows,
performance suffers. We study in Section 24.5.2 how the number of buckets and the
hashfunctioncanbechangeddynamically.
24.5.2 Dynamic Hashing
Aswehaveseen,theneedtofixthesetBofbucketaddressespresentsaseriousproblem
withthestatic hashingtechnique ofthe previoussection.Most databases grow larger
overtime.Ifwearetousestatichashingforsuchadatabase,wehavethreeclassesof
options:
1. Choose ahash function based on thecurrentfilesize.Thisoption willresultin
performancedegradationasthedatabasegrows.
2. Chooseahashfunctionbasedontheanticipatedsizeofthefileatsomepointin
the future. Although performance degradation is avoided, a significant amount
ofspacemaybewastedinitially.
3. Periodicallyreorganizethehashstructureinresponsetofilegrowth.Suchareor-
ganizationinvolveschoosinganewhashfunction,recomputingthehashfunction
oneveryrecordinthefile,andgeneratingnewbucketassignments.Thisreorga-
nizationisamassive,time-consumingoperation.Furthermore,itisnecessaryto
forbidaccesstothefileduringreorganization.
Several dynamic hashing techniques allow the hash function to be modified dy-
namicallytoaccommodatethegrowthorshrinkageofthedatabase.Inthissectionwe
describeoneformofdynamichashing,calledextendablehashing.Thebibliographical
notesprovidereferencestootherformsofdynamichashing.
24.5.2.1 DataStructure
Extendable hashing copes with changes in database size by splitting and coalescing
buckets as the database grows and shrinks. As a result, space efficiency is retained.
Moreover, since the reorganization is performed on only one bucket at a time, the
resultingperformanceoverheadisacceptablylow.

--- Page 1225 ---

1196 Chapter24 AdvancedIndexingTechniques
hash prefix
i
i 1
00..
01..
bucket 1
10..
i
2
11..
bucket 2
i
3
bucket address table bucket 3
…
…
Figure 24.8 Generalextendablehashstructure.
Withextendablehashing,wechooseahashfunctionhwiththedesirableproperties
of uniformity and randomness. However, this hash function generates values over a
relativelylargerange—namely,b-bitbinaryintegers.Atypicalvalueforbis32.
We do not create a bucket for each hash value. Indeed, 232 is over 4 billion, and
thatmanybucketsisunreasonableforallbutthelargestdatabases.Instead,wecreate
bucketsondemand,asrecordsareinsertedintothefile.Wedonotusetheentirebbits
ofthehashvalueinitially.Atanypoint,weusei bits,where0 ≤ i ≤ b.Thesei bits
areusedasanoffsetintoanadditionaltableofbucketaddresses.Thevalueofigrows
andshrinkswiththesizeofthedatabase.
Figure24.8showsageneralextendablehashstructure.Theiappearingabovethe
bucketaddresstableinthefigureindicatesthatibitsofthehashvalueh(K)arerequired
to determine the correct bucket for K. This number will change as the file grows. Al-
thoughi bitsarerequiredtofindthecorrectentryinthebucketaddresstable,several
consecutivetableentriesmaypointtothesamebucket.Allsuchentrieswillhaveacom-
monhashprefix,butthelengthofthisprefixmaybelessthani.Therefore,weassociate
witheachbucketanintegergivingthelengthofthecommonhashprefix.InFigure24.8
theintegerassociatedwithbucketj isshownasi.Thenumberofbucket-address-table
j
entriesthatpointtobucketj is
2(i−i
j
)

--- Page 1226 ---

24.5 HashIndices 1197
24.5.2.2 QueriesandUpdates
We now see how to perform lookup, insertion, and deletion on an extendable hash
structure.
To locate the bucket containing search-key value K, the system takes the first i
l
high-orderbitsofh(K),looks atthecorrespondingtableentryforthisbitstring,and
l
followsthebucketpointerinthetableentry.
Toinsertarecordwithsearch-keyvalueK,thesystemfollowsthesameprocedure
l
for lookup as before, ending up in some bucket—say, j. If there is room in the bucket,
thesystem insertstherecordinthebucket.If,on theotherhand,thebucketisfull,it
must split the bucket and redistribute the current records, plus the new one. To split
the bucket, the system must first determine from the hash value whether it needs to
increasethenumberofbitsthatituses.
• Ifi = i,onlyoneentryinthebucketaddresstablepointstobucketj.Therefore,
j
the system needs to increase the size of the bucket address table so that it can
include pointers to the two buckets that result from splitting bucket j. It does so
byconsideringanadditionalbitofthehashvalue.Itincrementsthevalue ofi by
1, thus doubling the size of the bucket address table. It replaces each entry with
twoentries,bothofwhichcontainthesamepointerastheoriginalentry.Nowtwo
entries in the bucket address table point to bucket j. The system allocates a new
bucket (bucket z) and sets the second entry to point to the new bucket. It sets i
j
and i to i. Next, itrehasheseach record in bucketj and, dependingon the firsti
z
bits(rememberthesystemhasadded1toi),eitherkeepsitinbucketjorallocates
ittothenewlycreatedbucket.
Thesystemnowreattemptstheinsertionofthenewrecord.Usually,theattempt
willsucceed.However,ifalltherecordsinbucketj,aswellasthenewrecord,have
thesamehash-valueprefix,itwillbenecessarytosplitabucketagain,sinceallthe
recordsinbucketjandthenewrecordareassignedtothesamebucket.Ifthehash
functionhasbeenchosencarefully,itisunlikelythatasingleinsertionwillrequire
thatabucketbesplitmorethanonce,unlesstherearealargenumberofrecords
with the same search key. If all the records in bucket j have the same search-key
value,noamountofsplittingwillhelp.Insuchcases,overflowbucketsareusedto
storetherecords,asinstatichashing.
• Ifi > i,thenmorethanoneentryinthebucketaddresstablepointstobucketj.
j
Thus,thesystemcansplitbucketjwithoutincreasingthesizeofthebucketaddress
table.Observethatalltheentriesthatpointtobucketjcorrespondtohashprefixes
thathavethesamevalueontheleftmosti bits.Thesystemallocatesanewbucket
j
(bucketz),andsetsi andi tothevaluethatresultsfromadding1totheoriginal
j z
i value. Next, the system needs to adjust the entries in the bucket address table
j
that previously pointed to bucket j. (Note that with the new value for i, not all
j
theentriescorrespondtohashprefixesthathavethesamevalueontheleftmosti
j
bits.)Thesystemleavesthefirsthalfoftheentriesastheywere(pointingtobucket

--- Page 1227 ---

1198 Chapter24 AdvancedIndexingTechniques
dept_name h(dept_name)
Biology 0010 1101 1111 1011 0010 1100 0011 0000
Comp. Sci. 1111 0001 0010 0100 1001 0011 0110 1101
Elec. Eng. 0100 0011 1010 1100 1100 0110 1101 1111
Finance 1010 0011 1010 0000 1100 0110 1001 1111
History 1100 0111 1110 1101 1011 1111 0011 1010
Music 0011 0101 1010 0110 1100 1001 1110 1011
Physics 1001 1000 0011 1111 1001 1100 0000 0001
Figure 24.9 Hashfunction fordeptname.
j),andsetsalltheremainingentriestopointtothenewlycreatedbucket(bucket
z).Next,asinthepreviouscase,thesystemrehasheseachrecordinbucketj,and
allocatesiteithertobucketj ortothenewlycreatedbucketz.
Thesystemthenreattemptstheinsert.Intheunlikelycasethatitagainfails,it
appliesoneofthetwocases,i = i ori > i,asappropriate.
j j
Notethat,inbothcases,thesystemneedstorecomputethehashfunctionononlythe
recordsinbucketj.
Todeletearecordwithsearch-keyvalueK,thesystemfollowsthesameprocedure
l
forlookupasbefore,endingupinsomebucket—say,j.Itremovesboththesearchkey
fromthebucketandtherecordfromthefile.Thebucket,too,isremovedifitbecomes
empty. Note that, at this point, several buckets can be coalesced, and the size of the
bucketaddresstable can be cut inhalf. The procedurefordecidingon whichbuckets
can be coalesced and how to coalesce buckets is left to you to do as an exercise. The
conditionsunderwhichthebucketaddresstablecanbereducedinsizearealsoleftto
youasanexercise.Unlikecoalescingofbuckets,changingthesizeofthebucketaddress
tableisaratherexpensiveoperationifthetableislarge.Thereforeitmaybeworthwhile
toreducethebucket-address-tablesizeonlyifthenumberofbucketsreducesgreatly.
To illustrate the operation of insertion, we use the instructor file and assume that
thesearchkeyisdept namewiththe32-bithashvaluesasappearinFigure24.9.Assume
that,initially,thefileisempty,asinFigure24.10.Weinserttherecordsonebyone.To
hash prefix
0
0
bucket address table
bucket 1
Figure 24.10 Initialextendablehashstructure.

--- Page 1228 ---

24.5 HashIndices 1199
hash prefix
1
1
15151 Mozart Music 40000
bucket address table
1
10101 Srinivasan Comp. Sci. 65000
12121 Wu Finance 90000
Figure 24.11 Hashstructureafterthreeinsertions.
illustrateallthefeaturesofextendablehashinginasmallstructure,weshallmakethe
unrealisticassumptionthatabucketcanholdonlytworecords.
We inserttherecord (10101, Srinivasan, Comp. Sci.,65000). The bucketaddress
tablecontainsapointertotheonebucket,andthesysteminsertstherecord.Next,we
insert the record (12121, Wu, Finance, 90000). The system also places this record in
theonebucketofourstructure.
Whenweattempttoinsertthenextrecord(15151,Mozart,Music,40000),wefind
that the bucket is full. Since i = i , we need to increase the number of bits that we
0
usefromthehashvalue.Wenowuse1bit,allowingus21 = 2buckets.Thisincrease
inthenumberofbitsnecessitatesdoublingthesizeofthebucketaddresstabletotwo
entries. The system splits the bucket, placing in the new bucket those records whose
search key has a hash value beginning with 1, and leaving in the original bucket the
otherrecords.Figure24.11showsthestateofourstructureafterthesplit.
hash prefix
1
2
15151 Mozart Music 40000
2
12121 Wu Finance 90000
bucket address table
22222 Einstein Physics 95000
2
10101Srinivasan Comp. Sci. 65000
Figure 24.12 Hashstructureafterfourinsertions.

--- Page 1229 ---

1200 Chapter24 AdvancedIndexingTechniques
1
hash prefix
15151 Mozart Music 40000
3
3
22222 Einstein Physics 95000
33456 Gold Physics 87000
3
12121 Wu Finance 90000
bucket address table
2
10101 Srinivasan Comp. Sci. 65000
32343 El Said History 60000
Figure 24.13 Hashstructureaftersixinsertions.
1
15151 Mozart Music 40000
hash prefix
3
3
22222 Einstein Physics 95000
33456 Gold Physics 87000
3
12121 Wu Finance 90000
3
bucket address table 32343 El Said History 60000
3
10101 Srinivasan Comp. Sci. 65000
45565 Katz Comp. Sci. 75000
Figure 24.14 Hashstructureafterseveninsertions.

--- Page 1230 ---

24.5 HashIndices 1201
Next,weinsert(22222,Einstein,Physics,95000).Sincethefirstbitofh(Physics)
is1,wemustinsertthisrecordintothebucketpointedtobythe“1”entryinthebucket
addresstable.Onceagain,wefindthebucketfullandi = i .Weincreasethenumber
1
ofbitsthatweusefromthehashto2.Thisincreaseinthenumberofbitsnecessitates
doublingthesizeofthe bucketaddresstabletofourentries,asinFigure24.12. Since
thebucketofFigure24.11forhashprefix0wasnotsplit,thetwoentriesofthebucket
addresstableof00and01bothpointtothisbucket.
For each record in the bucket of Figure 24.11 for hash prefix 1 (the bucket being
split), the system examines the first two bits of the hash value to determine which
bucketofthenewstructureshouldholdit.
Next, we insert (32343, El Said, History, 60000), which goes in the same bucket
as Comp. Sci. The following insertion of (33456, Gold, Physics, 87000) results in a
bucketoverflow,leadingtoanincreaseinthenumberofbitsandadoublingofthesize
ofthebucketaddresstable(seeFigure24.13).
The insertion of (45565, Katz, Comp. Sci., 75000) leads to another bucket over-
flow; this overflow, however, can be handled without increasing the number of bits,
sincethebucketinquestionhastwopointerspointingtoit(seeFigure24.14).
Next,weinserttherecordsof“Califieri”,“Singh”,and“Crick”withoutanybucket
overflow. The insertion of the third Comp. Sci. record (83821, Brandt, Comp. Sci.,
1
15151 Mozart Music 40000
76766 Crick Biology 72000
hash prefix 3
3 22222 Einstein Physics 95000
33456 Gold Physics 87000
3
12121 Wu Finance 90000
76543 Singh Finance 80000
3
32343 El Said History 60000
58583 Califieri History 62000
bucket address table
3
10101 Srinivasan Comp. Sci. 65000 83821 Brandt Comp. Sci. 92000
45565 Katz Comp. Sci. 75000
Figure 24.15 Hashstructure after11insertions.

--- Page 1231 ---

1202 Chapter24 AdvancedIndexingTechniques
2
15151 Mozart Music 40000
76766 Crick Biology 72000
2
98345 Kim Elec. Eng. 80000
hash prefix
3
3
22222 Einstein Physics 95000
33456 Gold Physics 87000
3
12121 Wu Finance 90000
76543 Singh Finance 80000
bucket address table 3
32343 El Said History 60000
58583 Califieri History 62000
3
10101 Srinivasan Comp. Sci. 65000 83821 Brandt Comp. Sci. 92000
45565 Katz Comp. Sci. 75000
Figure 24.16 Extendablehashstructure fortheinstructor file.
92000), however, leads to another overflow. This overflow cannot be handled by in-
creasing the number of bits, since there are three records with exactly the same hash
value.Hencethesystemusesanoverflowbucket,asinFigure24.15.Wecontinueinthis
manner until we have inserted all the instructor records of Figure 14.1. The resulting
structureappearsinFigure24.16.
24.5.2.3 StaticHashingversusDynamicHashing
We now examine the advantages and disadvantages of extendable hashing, compared
with static hashing. The main advantage of extendable hashing is that performance
does not degrade as the file grows. Furthermore, there is minimal space overhead.
Althoughthebucketaddresstableincursadditionaloverhead,itcontainsonepointer
for each hash value for the current prefix length. This table is thus small. The main
spacesavingofextendablehashingoverotherformsofhashingisthatnobucketsneed
tobereservedforfuturegrowth;rather,bucketscanbeallocateddynamically.
Adisadvantageofextendablehashingisthatlookupinvolvesanadditionallevelof
indirection,sincethesystemmustaccessthebucketaddresstablebeforeaccessingthe

--- Page 1232 ---

24.6 Summary 1203
bucket itself. This extra reference has only a minor effect on performance. Although
the hash structures that we discussed in Section 24.5.1 do not have thisextra level of
indirection, they lose their minor performance advantage as they become full. A fur-
therdisadvantageofextendablehashingisthecostofperiodicdoublingofthebucket
addresstable.
Thebibliographicalnotesalsoprovidereferencestoanotherformofdynamichash-
ing called linear hashing, which avoids the extra level of indirection associated with
extendablehashing,atthepossiblecostofmoreoverflowbuckets.
24.5.3 Comparison of Ordered Indexing and Hashing
Wehaveseenseveralordered-indexingschemesandseveralhashingschemes.Wecan
organizefilesofrecordsasorderedfilesbyusingindex-sequentialorganizationorB+-
treeorganizations.Alternatively,wecanorganizethefilesbyusinghashing.Finally,we
can organize them as heap files, where the records are not ordered in any particular
way.
Eachschemehasadvantagesincertainsituations.Adatabase-systemimplementor
couldprovidemanyschemes,leavingthefinaldecisionofwhichschemestousetothe
databasedesigner.However,suchanapproachrequirestheimplementortowritemore
code,addingbothtothecostofthesystemandtothespacethatthesystemoccupies.
Most database systems support B+-trees for indexing disk-based data, and many
databasesalsosupportB+-treefileorganization.However,mostdatabasesdonotsup-
porthashfileorganizationsorhashindicesfordisk-baseddata.Oneoftheimportant
reasons is the fact that many applications benefit from support for range queries. A
secondreasonisthefactthatB+-treeindiceshandlerelationsizeincreasesgracefully,
via a series of node splits, each of which is of low cost, in contrast to the relatively
high cost of doublingof the bucket addresstable, whichextendable hashingrequires.
Another reason for preferring B+-trees is the fact that B+-trees give good worst-case
boundsfordeletionoperationswithduplicatekeys,unlikehashindices.
However, hash indices are used for in-memory indexing, if range queries are not
common.Inparticular,theyarewidelyusedforcreatingtemporaryin-memoryindices
while processing join operations using the hash-join technique, as we see in Section
15.5.5.
24.6 Summary
• ThekeyideaofthelogstructuredmergetreeistoreplacerandomI/Ooperations
during tree inserts, updates, and deletes with a smaller number of sequential I/O
operations.
• Bitmapindicesarespecializedindicesdesignedforeasyqueryingonmultiplekeys.
Bitmapsworkbestforattributesthattakeonlyasmallnumberofdistinctvalues.

--- Page 1233 ---

1204 Chapter24 AdvancedIndexingTechniques
• A bitmap is an array of bits. In its simplest form, a bitmap index on the attribute
AofrelationrconsistsofonebitmapforeachvaluethatAcantake.Eachbitmap
hasasmanybitsasthenumberofrecordsintherelation.
• Bitmapindicesareusefulforselectionsmainlywhenthereareselectionsonmul-
tiplekeys.
• An important use of bitmaps is to count the number of tuples satisfying a given
selection.Suchqueriesareimportantfordataanalysis.
• Indicesarerequiredforefficientaccesstospatialdataandmustefficientlysupport
queriessuchasrangeandnearestneighborqueries.
• A quadtree is an alternative representation for two-dimensional data where the
space isdividedbyaquadtree.Eachnodeofaquadtreeisassociated witharect-
angularregionofspace.
• AnR-treeisastoragestructurethatisusefulforindexingofobjectssuchaspoints,
linesegments, rectangles,and otherpolygons. An R-treeisabalanced treestruc-
ture with the indexed objects stored in leaf nodes, much like a B+-tree. However,
instead of a range of values, a rectangular bounding box is associated with each
treenode.
• Static hashing uses hash functions in which the set of bucket addresses is fixed.
Suchhashfunctionscannoteasilyaccommodatedatabasesthatgrowsignificantly
largerovertime.
• Dynamichashingtechniquesallowthehashfunctiontobemodified.Oneexample
isextendablehashing,whichcopeswithchangesindatabase sizebysplittingand
coalescingbucketsasthedatabasegrowsandshrinks.
Review Terms
• Log-structuredmergetree(LSMtree) • Regionquadtrees
• Rollingmerge • R-tree
• Deletionentry • Boundingbox
• Stepped-mergeindex • Quadraticsplit
• Writeamplification • Bucketoverflow
• Bloomfilter • Skew
• Bitmap • Closedaddressing
• Bitmapindex • Closedhashing
• Existencebitmap • Openaddressing
• Quadtree • Openhashing

--- Page 1234 ---

PracticeExercises 1205
• Dynamichashing • Linearhashing
• Extendablehashing
Practice Exercises
24.1 BothLSMtreesandbuffertrees(describedinSection14.8.2)offerbenefitsto
write-intensiveworkloads,comparedtonormalB+-trees,andbuffertreesoffer
potentiallybetterlookupperformance.YetLSMtreesaremorefrequentlyused
inBigDatasettings.Whatisthemostimportantreasonforthispreference?
24.2 Considertheoptimizedtechniqueforcountingthenumberofbitsthatareset
inabitmap.Whatarethetradeoffsinchoosingasmallerversusalargerarray
size,keepingcachesizeinmind?
24.3 SupposeyouwanttostorelinesegmentsinanR-tree.Ifalinesegmentisnot
parallel to the axes, the bounding box for it can be large, containing a large
emptyarea.
• Describe the effect on performance of having large bounding boxes on
queriesthataskforlinesegmentsintersectingagivenregion.
• Brieflydescribeatechniquetoimproveperformanceforsuchqueriesand
giveanexampleofitsbenefit.Hint:Youcandividesegmentsintosmaller
pieces.
24.4 GiveasearchalgorithmonanR-treeforefficientlyfindingthenearestneighbor
toagivenquerypoint.
24.5 Give a recursive procedure to efficientlycompute the spatial join of two rela-
tions with R-tree indices. (Hint: Use bounding boxes to check if leaf entries
underapairofinternalnodesmayintersect.)
24.6 Suppose that we are using extendable hashing on a file that contains records
withthefollowingsearch-keyvalues:
2,3,5,7,11,17,19,23,29,31
Showtheextendablehashstructureforthisfileifthehashfunctionish(x) = x
mod8andbucketscanholdthreerecords.
24.7 ShowhowtheextendablehashstructureofExercise24.6changesastheresult
ofeachofthefollowingsteps:
a. Delete11.
b. Delete31.
c. Insert1.

--- Page 1235 ---

1206 Chapter24 AdvancedIndexingTechniques
d. Insert15.
24.8 GivepseudocodefordeletionofentriesfromAVianextendablehashstructure,
including details of when and how to coalesce buckets. Do not bother about
reducingthesizeofthebucketaddresstable.
24.9 Suggestanefficientwaytotestifthebucketaddresstableinextendablehashing
canbereducedinsizebystoringanextracountwiththebucketaddresstable.
Give details of how the count should be maintained when buckets are split,
coalesced, or deleted. (Note: Reducing the size of the bucket address table is
an expensive operation, and subsequent inserts may cause the table to grow
again. Therefore, it is best not to reduce the size as soon as it is possible to
do so, but instead do it only if the number of index entries becomes small
comparedtothebucket-address-tablesize.)
Exercises
24.10 ThesteppedmergevariantoftheLSMtreeallowsmultipletreesperlevel.What
arethetradeoffsinhavingmoretreesperlevel?
24.11 Suppose you wanttouse theideaofaquadtreefordatainthreedimensions.
Howwouldtheresultantdatastructure(calledanocttree)divideupspace?
24.12 Explainthedistinctionbetweenclosedandopenhashing.Discusstherelative
meritsofeachtechniqueindatabaseapplications.
24.13 Whatarethecausesofbucketoverflowinahashfileorganization?Whatcan
bedonetoreducetheoccurrenceofbucketoverflows?
24.14 Why is a hash structure not the best choice for a search key on which range
queriesarelikely?
24.15 Our description of static hashing assumes that a large contiguous stretch of
disk blocks can be allocated to a static hash table. Suppose you can allocate
onlyC contiguousblocks. Suggest how toimplementthe hash table,ifitcan
bemuchlargerthanC blocks.Accesstoablockshouldstillbeefficient.
Further Reading
The log-structured merge (LSM) tree ispresented in[O’Neil etal.(1996)], whilethe
steppedmergetreeispresentedin[Jagadishetal.(1997)].[Vitter(2001)]providesan
extensivesurveyofexternal-memorydatastructuresandalgorithms.
Bitmapindicesaredescribedin[O’NeilandQuass(1997)].Theywerefirstintro-
ducedintheIBMModel204filemanagerontheAS400platform.Theyprovidevery

--- Page 1236 ---

FurtherReading 1207
largespeedupsoncertaintypesofqueriesandaretodayimplementedinmostdatabase
systems.
[Samet (2006)] provides a textbook coverage of spatial data structures. [Bentley
(1975)] describes the k-d tree, and [Robinson (1981)] describes the k-d-B tree. The
R-treewasoriginallypresentedin[Guttman(1984)].
Discussionsofthebasicdatastructuresinhashingcanbefoundin[Cormenetal.
(2009)]. Extendable hashing was introduced by [Fagin et al.(1979)]. Linear hashing
wasintroducedby[Litwin(1978)]and[Litwin(1980)].
Bibliography
[Bentley(1975)] J.L.Bentley,“MultidimensionalBinarySearchTreesUsedforAssociative
Searching”,CommunicationsoftheACM,Volume18,Number9(1975),pages509–517.
[Cormenetal.(2009)] T.Cormen,C.Leiserson,R.Rivest,andC.Stein,IntroductiontoAl-
gorithms,3rdedition,MITPress(2009).
[Faginetal.(1979)] R. Fagin, J. Nievergelt, N. Pippenger, and H. R. Strong, “Extendible
Hashing —AFastAccessMethodforDynamicFiles”,ACMTransactions onDatabaseSys-
tems,Volume4,Number3(1979),pages315–344.
[Guttman(1984)] A.Guttman,“R-Trees:ADynamicIndexStructureforSpatialSearching”,
InProc.oftheACMSIGMODConf.onManagementofData(1984),pages47–57.
[Jagadishetal.(1997)] H. V. Jagadish, P. P. S. Narayan, S. Seshadri, S. Sudarshan, and
R. Kanneganti, “Incremental Organization for Data Recording and Warehousing”, In Pro-
ceedings of the 23rd International Conference on Very Large Data Bases, VLDB ’97 (1997),
pages16–25.
[Litwin(1978)] W.Litwin,“VirtualHashing:ADynamicallyChangingHashing”,InProc.of
theInternationalConf.onVeryLargeDatabases(1978),pages517–523.
[Litwin(1980)] W.Litwin,“LinearHashing:ANewToolforFileandTableAddressing”,In
Proc.oftheInternationalConf.onVeryLargeDatabases(1980),pages212–223.
[O’NeilandQuass(1997)] P. O’Neil and D. Quass, “Improved Query Performance with
VariantIndexes”,InProc.oftheACMSIGMODConf.onManagementofData(1997),pages
38–49.
[O’Neiletal.(1996)] P.O’Neil,E.Cheng,D.Gawlick,andE.O’Neil,“TheLog-structured
Merge-tree(LSM-tree)”,ActaInf.,Volume33,Number4(1996),pages351–385.
[Robinson(1981)] J.Robinson,“Thek-d-BTree:ASearchStructureforLargeMultidimen-
sional Indexes”,InProc.oftheACM SIGMOD Conf.onManagement ofData(1981),pages
10–18.
[Samet(2006)] H.Samet,FoundationsofMultidimensionalandMetricDataStructures,Mor-
ganKaufmann(2006).

--- Page 1237 ---

1208 Chapter24 AdvancedIndexingTechniques
[Vitter(2001)] J.S.Vitter,“ExternalMemoryAlgorithmsandDataStructures:Dealingwith
MassiveData”,ACMComputingSurveys,Volume33,(2001),pages209–271.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 1238 ---

25
CHAPTER
Advanced Application
Development
Thereareanumberoftasksinapplicationdevelopment.WesawinChapter6toChap-
ter9howtodesignandbuildanapplication.Oneoftheaspectsofapplicationdesign
is the performance one expects out of the application. In fact, it is common to find
that once an application has been built, it runs slower than the designers wanted or
handlesfewertransactionspersecondthantheyrequired.Anapplicationthattakesan
excessive amount of time to perform requested actions can cause user dissatisfaction
atbestandbecompletelyunusableatworst.
Applicationscanbemadetorunsignificantlyfasterbyperformancetuning,which
consistsoffindingandeliminatingbottlenecksandaddingappropriatehardwaresuch
asmemoryordisks.Therearemanythingsanapplicationdevelopercandototunethe
application,andtherearethingsthatadatabase-systemadministratorcandotospeed
upprocessingforanapplication.
Benchmarks are standardized sets of tasks that help to characterize the perfor-
mance of database systems. They are useful to get a rough idea of the hardware and
softwarerequirementsofanapplication,evenbeforetheapplicationisbuilt.
Applications must be tested as they are being developed. Testing requires gener-
ation of database states and test inputs, and verifying that the outputs match the ex-
pectedoutputs.Wediscussissuesinapplicationtesting.Legacysystemsareapplication
systemsthatareoutdatedandusuallybasedonolder-generationtechnology.However,
they are often at the core of organizations and run mission-critical applications. We
outline issues in interfacing with and issues in migrating away from legacy systems,
replacingthemwithmoremodernsystems.
Standardsareveryimportantforapplicationdevelopment,especiallyintheageof
theinternet,sinceapplicationsneedtocommunicatewitheachothertoperformuse-
ful tasks. A variety of standards have been proposed that affect database-application
development,whichweoutlineinthischapter.Organizationsoftenstore information
aboutusersindirectorysystems.Applicationsoftenusesuchdirectorysystemstoau-
thenticateusersandtogetbasicinformationaboutusers,suchasusercategories(e.g.,
1209

--- Page 1239 ---

1210 Chapter25 AdvancedApplicationDevelopment
student, instructor, and so on). We briefly describe the architecture of directory sys-
tems.
25.1 Performance Tuning
Tuningtheperformanceofasysteminvolvesadjustingvariousparametersanddesign
choices to improve its performance for a specific application. Various aspects of a
database-systemdesign—rangingfromhigh-levelaspectssuchastheschemaandtrans-
actiondesigntodatabaseparameterssuchasbuffersizes,downtohardwareissuessuch
as number of disks—affect the performance of an application. Each of these aspects
canbeadjustedsothatperformanceisimproved.
25.1.1 Motivation for Tuning
Applicationssometimesexhibitpoorperformance,withqueriestakingalongtimeto
complete, leading to users being unable to carry out tasks that they need to do. We
describeafew real-worldexamples thatwehave seen,includingtheircausesand how
tuningfixedtheproblems.
Inoneoftheapplications,wefoundthatuserswereexperiencinglongdelaysand
time-outsinthewebapplications.Onmonitoringthedatabase,wefoundthattheCPU
usagewasveryhigh,withnegligiblediskandnetworkusage.Furtheranalysisofqueries
runningonthedatabaseshowedthatasimplelookupqueryonalargerelationwasus-
ing a full relation scan, which was quite expensive. Adding an index to the attribute
used in the lookup drastically reduced the execution time of the query and a key per-
formanceproblemvanishedimmediately.
Inasecondapplication,wefoundthataqueryhadverypoorperformance.Examin-
ingthequery,wefoundthattheprogrammerhadwrittenanunnecessarilycomplicated
query, with several nested subqueries, and the optimizer produced a bad plan for the
query,aswerealizedafterobservingthequeryplan.Tofixtheproblem,werewrotethe
queryusingjoinsinsteadofnestedsubqueries,thatis,wedecorrelatedthequery;this
changegreatlyreducedtheexecutiontime.
In a third application, we found that the application fetched a large number of
rows from a query, and issued another database query for each row that it fetched.
Thisresultedinalargenumberofseparatequeriesbeingsenttothedatabase,resulting
in poor performance. It is possible to replace such a large number of queries with a
singlequerythatfetchesallrequireddata,asweseelaterinthissection.Suchachange
improvedtheperformanceoftheapplicationbyanorderofmagnitude.
In a fourth application, we found that while the application performed fine un-
der light load during testing, it completely stopped working when subjected to heavy
load when it was used by actual users. In this case, we found that in some of the in-
terfaces, programmers had forgotten to close JDBC connections. Databases typically
supportonlyalimitednumberofJDBCconnections,andoncethatlimitwasreached,
the application was unable to connect to the database, and thus it stopped working.

--- Page 1240 ---

25.1 PerformanceTuning 1211
Ensuring thatconnections wereclosed fixed thisproblem. While thiswas technically
a bug fix, not a tuning action, we thought it is a good idea to highlight this problem
sincewehavefoundmanyapplicationshavethisproblem.Connectionpooling,which
keepsdatabaseconnectionsopenforusebysubsequenttransactions,isarelatedappli-
cationtuningoptimization,sinceitavoidsthecostofrepeatedopeningandclosingof
databaseconnections.
Itisalsoworthpointingoutthatinseveralcasesabovetheperformanceproblems
did not show up during testing, either because the test database was much smaller
thantheactualdatabasesizeorbecausethetestingwasdonewithamuchlighterload
(number of concurrent users) than the load on the live system. It is important that
performancetestingbedoneonrealisticdatabasesizes,withrealisticload,soproblems
showupduringtesting,ratherthanonalivesystem.
25.1.2 Location of Bottlenecks
The performance of most systems (at least before they are tuned) is usually limited
primarilyby the performance of one or a few components, calledbottlenecks. Forin-
stance, a program mayspend 80 percentof itstime in a smallloop deep in the code,
andtheremaining20percentofthetimeontherestofthecode;thesmallloopthenis
abottleneck.Improvingtheperformanceofacomponentthatisnotabottleneckdoes
little to improve the overall speed of the system; in the example, improving the speed
of the rest of the code cannot lead to more than a 20 percent improvement overall,
whereasimprovingthespeedofthebottleneckloopcouldresultinanimprovementof
nearly80percentoverall,inthebestcase.
Hence, when tuning a system, we must first try to discover what the bottlenecks
are and then eliminate them by improving the performance of system components
causingthebottlenecks.Whenonebottleneckisremoved,itmayturnoutthatanother
component becomes the bottleneck. In a well-balanced system, no single component
isthebottleneck.Ifthesystem containsbottlenecks,componentsthatarenotpartof
the bottleneck are underutilized, and could perhaps have been replaced by cheaper
componentswithlowerperformance.
For simple programs, the time spent in each region of the code determines the
overallexecutiontime.However,databasesystemsaremuchmorecomplex,andquery
executioninvolvesnotonlyCPUtime,butalsodiskI/Oandnetworkcommunication.A
firststepindiagnosingproblemstousemonitoringtoolsprovidedbyoperatingsystems
tofindtheusageleveloftheCPU,disks,andnetworklinks.
It is also important to monitor the database itself, to find out what is happening
in the database system. For example, most databases provide ways to find out which
queries(orquerytemplates,wherethesamequeryisexecutedrepeatedlywithdifferent
constants) are taking up the maximum resources, such as CPU, disk I/O, or network
capacity.Inadditiontohardwareresourcebottlenecks,poorperformanceinadatabase
systemmaypotentiallybeduetocontentiononlocks,wheretransactionswaitinlock

--- Page 1241 ---

1212 Chapter25 AdvancedApplicationDevelopment
Note 25.1 DATABASEPERFORMANCEMONITORINGTOOLS
Most database systems provide view relations that can be queried to monitor
database system performance. For example, PostgreSQL provides view relations
pg stat statements and pgpgrowlocks to monitor resource usage of SQL state-
ments and lock contention respectively. MySQL supports a command show pro-
cessinfothatcanbeusedtomonitorwhattransactionsarecurrentlyexecutingand
theirresourceusage.MicrosoftSQLServerprovidesstoredproceduressp monitor,
sp who,andsp locktomonitorsystemresourceusage.TheOracleDatabaseSQL
TuningGuide,availableonline,providesdetailsofsimilarviewsinOracle.
queues for a long time. Again, most databases provide mechanisms to monitor lock
contention.
Monitoring tools can help detect where the bottleneck lies (such as CPU, I/O, or
locks), and to locate the queries that are causing the maximum performance prob-
lems. In this chapter, we discuss a number of techniques that can be used to fix per-
formance problems, such as adding required indices or materialized views, rewriting
queries,rewritingapplications,oraddinghardwaretoimproveperformance.
To understand the performance of database systems better, it is very useful to
model database systems as queueing systems. A transaction requests various services
fromthedatabasesystem,startingfromentryintoaserverprocess,diskreadsduring
execution, CPU cycles, and locks for concurrency control. Each of these services has
a queue associated withit, and smalltransactions mayspend most of theirtime wait-
ing in queues—especially in disk I/O queues—instead of executing code. Figure 25.1
illustratessomeofthequeuesinadatabasesystem.Notethateachlockableitemhasa
separate queue intheconcurrencycontrolmanager.Thedatabase system mayhavea
singlequeueatthediskmanagerormayhaveseparatequeuesfordifferentdisksincase
thedisksaredirectlycontrolledbythedatabase.Thetransactionqueueisusedbythe
databasesystemtocontroltheadmissionofnewquerieswhenthenumberofrequests
exceedsthenumberofconcurrentqueryexecutiontasksthatthedatabaseallows.
Asaresultofthenumerousqueuesinthedatabase,bottlenecksinadatabasesys-
tem typically show up in the form of long queues for a particular service, or, equiva-
lently, in high utilizations for a particular service. If requests are spaced exactly uni-
formly, and the time to service a request is less than or equal to the time before the
next request arrives, then each request will find the resource idle and can therefore
startexecutionimmediatelywithoutwaiting.Unfortunately,thearrivalofrequestsina
databasesystemisneversouniformandisoftenrandom.
If a resource, such as a disk, has a low utilization, then when a request is made,
the resource is likely to be idle, in which case the waiting time for the request will
be0.Assuminguniformlyrandomlydistributedarrivals,thelengthofthequeue(and

--- Page 1242 ---

25.1 PerformanceTuning 1213
concurrency-control
manager
…
lock lock
request grant
CPU manager
transaction transaction
source manager
transaction page
queue reply
page
request
page disk manager
request
buffer
manager page
reply …
Figure 25.1 Queuesinadatabasesystem.
correspondinglythewaitingtime)goesupexponentiallywithutilization;asutilization
approaches 100 percent, the queue length increases sharply, resulting in excessively
longwaitingtimes.Theutilizationofaresourceshouldbekeptlowenoughthatqueue
length is short. As a rule of the thumb, utilizations of around 70 percent are consid-
eredtobegood,andutilizationsabove90percentareconsideredexcessive,sincethey
will result in significant delays. To learn more about the theory of queueing systems,
generally referred to as queueing theory, you can consult the references cited in the
bibliographicalnotes.
25.1.3 Tuning Levels
Tuningistypicallydoneinthecontextofapplications,andcanbedoneatthedatabase
systemlayer,oroutsidethedatabasesystem.
Tuningatlayersabovethedatabaseisapplicationdependent,andisnotourfocus,
but we mention afew such techniques. Profilingapplication code tofind code blocks
that have a heavy CPU consumption, and rewriting them to reduce CPU load is an
option for CPU intensive applications. Application servers often have numerous pa-
rametersthatcanbetunedtoimproveperformance,ortoensurethattheapplication
doesnotrunoutofmemory.Multipleapplicationserversthatworkinparallelareoften

--- Page 1243 ---

1214 Chapter25 AdvancedApplicationDevelopment
usedtohandlehigherworkloads.Aloadbalancerisusedtorouterequeststooneofthe
applicationservers;toensuresessioncontinuity,requestsfromaparticularsourceare
alwaysroutedtothesameapplicationserver.Connectionpooling(describedinSection
9.7.1)isanotherwidelytechniquetoreducetheoverheadofdatabaseconnectioncre-
ation.Webapplicationinterfacesmaybetunedtoimproveresponsiveness,forexample
byreplacinglegacywebinterfacesbyonesbasedonJavaScriptandAjax(describedin
Section9.5.1.3).
Returningtodatabasetuning,databaseadministratorsandapplicationdevelopers
cantuneadatabasesystematthreelevels.
The highest level of database tuning, which is under the control of application
developers,includestheschemaandqueries.Thedevelopercantunethedesignofthe
schema,theindicesthatarecreated,andthetransactionsthatareexecutedtoimprove
performance.Tuningatthisleveliscomparativelysystemindependent.
The second level consists of the database-system parameters, such as buffer size
and checkpointingintervals. The exact set of database-system parameters that can be
tuneddependsonthespecificdatabasesystem.Mostdatabase-systemmanualsprovide
informationonwhatdatabase-systemparameterscanbeadjusted,andhowyoushould
choose values for the parameters. Well-designed database systems perform as much
tuning as possible automatically, freeing the user or database administrator from the
burden. Forinstance,inmanydatabasesystems thebuffersizeisfixedbuttunable.If
the system automatically adjusts the buffer size by observing indicators such as page-
fault rates, then the database administrator will not have to worry about tuning the
buffersize.
The lowest level is at the hardware level. Options for tuning systems at this level
include replacing hard disks with solid-state drives (which use flash storage), adding
moredisksorusingaRAIDsystemifdiskI/Oisabottleneck,addingmorememoryif
thediskbuffersizeisabottleneck,ormovingtoasystemwithmoreprocessorsifCPU
usageisabottleneck.
The three levels of tuning interact with one another; we must consider them to-
gether when tuning a system. For example, tuning at a higher level may result in the
hardwarebottleneckchangingfrom thedisksystem totheCPU,orviceversa.Tuning
ofqueriesandthephysicalschemaisusuallythefirststeptoimprovingperformance.
Tuningofdatabasesystemparameters,incasethedatabasesystemdoesautomatethis
task,canalsobedoneinparallel.Ifperformanceisstillpoor,tuningoflogicalschema
andtuningofhardwarearethenextlogicalsteps.
25.1.4 Tuning of Physical Schema
Tuning of the physical schema, such as indices and materialized views, is the least
disruptivemodeoftuning,sinceitdoesnotaffectapplicationcodeinanyway.Wenow
studydifferentaspectsoftuningofthephysicalschema.

--- Page 1244 ---

25.1 PerformanceTuning 1215
25.1.4.1 TuningofIndices
Wecantunetheindicesinadatabasesystemtoimproveperformance.Ifqueriesarethe
bottleneck,wecanoftenspeedthemupbycreatingappropriateindicesonrelations.If
updates arethebottleneck,theremaybe toomanyindices,whichhavetobeupdated
whentherelationsareupdated.Removingindicesmayspeedupcertainupdates.
Thechoiceofthetypeofindexalsoisimportant.Somedatabasesystemssupport
different kinds of indices, such as hash indices, B+-tree indices, and write-optimized
indicessuchasLSMtrees(Section24.2).Ifrangequeriesarecommon,B+-treeindices
arepreferabletohashindices.Ifthesystemhasaveryhighwriteload,butarelatively
lowreadload,write-optimizedLSMtreeindicesmaybepreferabletoB+-treeindices.
Whether to make an index a clustered index is another tunable parameter. Only
one index on a relation can be made clustered, by storing the relation sorted on the
indexattributes.Generally,theindexthatbenefitsthegreatestnumberofqueriesand
updatesshouldbemadeclustered.
Tohelpidentifywhatindicestocreate,andwhichindex(ifany)on eachrelation
should be clustered, most commercialdatabase systems provide tuning wizards; these
are described in more detail in Section 25.1.4.4. These tools use the past history of
queriesandupdates(calledtheworkload)toestimatetheeffectsofvariousindiceson
theexecutiontimeofthequeriesandupdatesintheworkload.Recommendationson
whatindicestocreatearebasedontheseestimates.
25.1.4.2 UsingMaterializedViews
Maintaining materialized views can greatly speed up certain types of queries, in par-
ticularaggregatequeries.RecalltheexamplefromSection16.5wherethetotalsalary
foreachdepartment(obtainedbysummingthesalaryofeachinstructorinthedepart-
ment) is required frequently. As we saw in that section, creating a materialized view
storingthetotalsalaryforeachdepartmentcangreatlyspeedupsuchqueries.
Materializedviewsshouldbeusedwithcare,however,sincethereisnotonlyspace
overhead for storing them but, more important, there is also time overhead for main-
taining materialized views. In the case of immediate view maintenance, if the updates
ofatransactionaffectthematerializedview,thematerializedviewmustbeupdatedas
partofthesametransaction.Thetransactionmaythereforerunslower.Inthecaseof
deferred view maintenance, the materialized view is updated later; until it is updated,
thematerializedviewmaybeinconsistentwiththedatabaserelations.Forinstance,the
materializedviewmaybebroughtuptodatewhenaqueryusestheview,orperiodically.
Usingdeferredmaintenancereducestheburdenonupdatetransactions.
The database administrator is responsible for the selection of materialized views
andforview-maintenancepolicies.Thedatabaseadministratorcanmaketheselection
manually by examining the types of queries in the workload and finding out which
queries need to run faster and which updates/queries may be executed more slowly.
From the examination, the database administrator may choose an appropriate set of

--- Page 1245 ---

1216 Chapter25 AdvancedApplicationDevelopment
materialized views. For instance, the administrator may find that a certain aggregate
is used frequently, and choose to materialize it, or may find that a particular join is
computedfrequently,andchoosetomaterializeit.
However, manual choice is tedious for even moderately large sets of query types,
and making a good choice may be difficult, since it requires understanding the costs
of different alternatives; only the query optimizer can estimate the costs with reason-
able accuracy without actually executing the query. Thus, a good set of views may be
found only by trial and error—that is, by materializing one or more views, running
the workload, and measuring the time taken to run the queries in the workload. The
administrator repeats the process until a set of views is found that gives acceptable
performance.
Abetteralternativeistoprovidesupportforselectingmaterializedviewswithinthe
databasesystemitself,integratedwiththequeryoptimizer.Thisapproachisdescribed
inmoredetailinSection25.1.4.4.
25.1.4.3 HorizontalPartitioningofRelationSchema
Horizontal partitioningofrelationsiswidelyused forparalleland distributed storage
andqueryprocessing.However,itcanalsobeusedinacentralizedsystemtoimprove
queriesandupdatesbybreakingupthetuplesofarelationintopartitions.
Forexample,supposethatadatabasestoresalargerelationthathasadateattribute,
andmostoperationsworkondatainsertedwithinthepastfewmonths.Supposenow
thattherelationispartitionedonthedateattribute,withonepartitionforeach(year,
month)combination.Then,queriesthatcontainaselectionondate,suchasdate='2018-
06-01',needaccessonlypartitionsthatcouldpossiblycontainsuchtuples,skippingall
otherpartitions.
Moreimportantly,indicescouldbecreatedindependentlyoneachpartition.Sup-
poseanindexiscreatedonanattributeID,withaseparateindexoneachpartition.A
querythatspecifiesselectiononID,alongwithadateoradaterange,needlookupthe
indexononlythosepartitionsthatmatchthespecifieddateordaterange.Sinceeach
partition is smaller than the whole relation, the indices too are smaller, speeding up
indexlookup.Indexinsertionisalsomuchfaster,sincetheindexsizeismuchsmaller
thananindexontheentirerelation.Andmostimportantly,evenasthetotaldatasize
grows,thepartitionsizenevergrowsbeyondsomelimit,ensuringthattheperformance
ofsuchqueriesdoesnotdegradewithtime.
There is a cost to such partitioning: queries that do not contain a selection on
thepartitioningattributeneedtoindividuallyaccesseachofthepartitions,potentially
slowingdown such queriessignificantly.Ifsuch queriesare rare,the benefitsof parti-
tioningoutweighthecosts,makingthemanattractivetechniqueforoptimization.
Even if the database does not support partitioning internally, it is possible to re-
placearelationrbymultiplephysicalrelationsr ,r ,…,r ,andtheoriginalrelationr
1 2 n
isdefinedbytheviewr = r ∪r ∪…∪r .Supposethatthedatabaseoptimizerknows
1 2 n

--- Page 1246 ---

25.1 PerformanceTuning 1217
the predicate defining each r (in our example, the date range corresponding to each
i
r).Thentheoptimizercanreplaceaqueryonr thatincludesaselectionontheparti-
i
tioningattribute (date, in our example), witha queryon the onlyrelevant rs. Indices
i
wouldhavetobecreatedseparatelyoneachofthers.
i
25.1.4.4 AutomatedTuningofPhysicalDesign
Most commercialdatabase systems today providetoolstohelpthe database adminis-
trator with index and materialized view selection and other tasks related to physical
databasedesignsuchashowtopartitiondatainaparalleldatabasesystem.
These tools examine the workload (the history of queries and updates) and sug-
gestindicesandviewstobematerialized.Thedatabaseadministratormayspecifythe
importance of speeding up different queries, which the tool takes into account when
selectingviewstomaterialize.Oftentuningmustbedonebeforetheapplicationisfully
developed,andtheactualdatabasecontentsmaybesmallonthedevelopmentdatabase
butareexpectedtobemuchlargeronaproductiondatabase.Thus,sometuningtools
alsoallowthedatabaseadministratortospecifyinformationabouttheexpectedsizeof
thedatabaseandrelatedstatistics.
Microsoft’sDatabase TuningAssistant, forexample, allows theuser toask “what
if” questions, whereby the user can pick a view, and the optimizer then estimates the
effectofmaterializingtheviewonthetotalcostoftheworkloadandontheindividual
costsofdifferenttypesofqueriesandupdatesintheworkload.
Theautomaticselectionofindicesandmaterializedviewsisusuallyimplemented
by enumerating different alternatives and using the query optimizer to estimate the
costsandbenefitsofselectingeachalternativebyusingtheworkload.Sincethenumber
ofdesignalternativesandthepotentialworkloadmaybeextremelylarge,theselection
techniquesmustbedesignedcarefully.
The first step is to generate a workload. This is usually done by recording all the
queries and updates that are executed during some time period. Next, the selection
tools perform workload compression, that is, create a representation of the workload
usingasmallnumberofupdates andqueries.Forexample, updatesofthesameform
canberepresentedbyasingleupdatewithaweightcorrespondingtohowmanytimes
the update occurred. Queries of the same form can be similarly replaced by a repre-
sentative with appropriate weight. After this, queries that are very infrequent and do
nothaveahighcostmaybediscardedfromconsideration.Themostexpensivequeries
maybechosentobeaddressedfirst.Suchworkloadcompressionisessentialforlarge
workloads.
With the help of the optimizer,the tool would come up with a set of indicesand
materializedviewsthatcouldhelpthequeriesandupdatesinthecompressedworkload.
Differentcombinationsoftheseindicesandmaterializedviewscanbetriedouttofind
the best combination. However, an exhaustive approach would be totally impractical,
sincethenumberofpotentialindicesandmaterializedviewsisalreadylarge,andeach

--- Page 1247 ---

1218 Chapter25 AdvancedApplicationDevelopment
Note 25.2 TUNINGTOOLS
Tuningtools,suchastheDatabaseEngineTuningAdvisorprovidedbySQLServer
and the SQL Tuning Advisor of Oracle, provide recommendations such as what
indices or materialized views to add, or how to partition a relation, to improve
performance.Theserecommendationscanthenbeacceptedandimplementedby
adatabaseadministrator.
Auto Tuning in Microsoft Azure SQL can automatically create and drop in-
dicestoimprovequeryperformance.Ariskwithautomaticallychangingthephys-
ical schemaisthat some queries may perform poorly. Forexample, an optimizer
may choose a plan using a newly created index, assuming, based on wrong esti-
matesofcost,thatthenewplanischeaperthantheplanusedbeforetheindexwas
created.Inreality,thequerymayrunslowerusingthenewplan,whichmayaffect
users.The“forcelastgoodplan”featurecanmonitorqueryperformanceafterany
changesuchasadditionofanindex,andifperformanceisworse,itcanforcethe
databasetousetheoldplanbeforethechange(aslongasitisstillvalid).
Oracle also provides auto tuning support, for example recommending if an
indexshould be added,ormonitoringtheuse ofaquerytodecideifitshould be
optimizedforfetchingonlyafewrowsorforfetchingallrows(thebestplanmay
beverydifferentifonlythefirstfewrowsarefetchedorifallrowsarefetched).
subset of these is a potential design alternative, leading to an exponential number of
alternatives. Heuristics are used to reduce the space of alternatives, that is, to reduce
thenumberofcombinationsconsidered.
Greedy heuristics for index and materialized view selection operate as follows:
They estimate the benefits of materializing different indices or views (using the op-
timizer’scostestimationfunctionalityasasubroutine).Theythenchoosetheindexor
viewthatgiveseitherthemaximumbenefitorthemaximumbenefitperunitspace(i.e.,
benefitdividedbythespacerequiredtostoretheindexorview).Thecostofmaintain-
ingtheindexorviewmustbetakenintoaccountwhencomputingthebenefit.Oncethe
heuristichasselectedanindexorview,thebenefitsofotherindicesorviewsmayhave
changed,sotheheuristicrecomputestheseandchoosesthenextbestindexorviewfor
materialization.Theprocesscontinuesuntileithertheavailablediskspaceforstoring
indices or materialized views is exhausted or the cost of maintaining the remaining
candidatesismorethanthebenefittoqueriesthatcouldusetheindicesorviews.
Real-world index and materialized-view selection tools usually incorporate some
elements of greedy selection but use other techniques to get better results. They also
supportotheraspectsofphysicaldatabasedesign,suchasdecidinghowtopartitiona
relationinaparalleldatabase,orwhatphysicalstoragemechanismtouseforarelation.

--- Page 1248 ---

25.1 PerformanceTuning 1219
25.1.5 Tuning of Queries
The performance of an application can often be significantly improved by rewriting
queriesorbychanginghowtheapplicationissuesqueriestothedatabase.
25.1.5.1 TuningofQueryPlans
In the past, optimizerson manydatabase systems werenotparticularlygood, so how
aquerywaswrittenwouldhaveabiginfluenceonhowitwasexecuted,andtherefore
on the performance. Today’s advanced optimizers can transform even badly written
queries and execute them efficiently, so the need for tuning individual queries is less
importantthanitusedtobe.However,sometimesqueryoptimizerschoosebadplans
foroneofseveralreasons,whichwedescribenext.
Beforecheckingifsomethingneedstobetunedintheplanforaquery,itisuseful
to find out whatplan isbeing used for the query. Most databases support anexplain
command, which allows you to see what plan is being used for a query. The explain
command also shows the statistics that the optimizer used or computed for different
parts of the query plan, and estimates of the costs of each part of a query plan. Vari-
ants of the explain command also execute the query and get actual tuple counts and
executiontimefordifferentpartsofthequeryplan.
Incorrectstatisticsareoftenthereasonforthechoiceofabadplan.Forexample,
iftheoptimizerthinksthattherelationsinvolvedinajoinhaveveryfewtuples,itmay
choosenestedloopsjoin,whichwouldbeveryinefficientiftherelationsactuallyhave
alargenumberoftuples.
Ideally,databasestatisticsshouldbeupdatedwheneverrelationsareupdated.How-
ever,doingsoaddsunacceptableoverheadtoupdatequeries.Instead,databaseseither
periodically update statistics or leave it to the system administrator to issue a com-
mand to update statistics. Some databases, such as PostgreSQL and MySQL support
acommandcalledanalyze,1 whichcanbeusedtorecomputestatistics.Forexample,
analyze instructor would recompute statistics for the instructor relation, while ana-
lyze with no arguments would recompute statistics for all relations in PostgreSQL. It
is highly recommended to run this command after loading data into the database, or
aftermakingasignificantnumberofinsertsordeletesonarelation.
Some databases such as Oracle and Microsoft SQL Server keep track of inserts
and deletestorelations,and theyupdate statistics whenevertherelationsizechanges
byasignificantfraction,makingexecutionoftheanalyzecommandunnecessary.
Anotherreasonforpoorperformanceofqueriesisthelackofrequiredindices.As
wesawearlier,thechoiceofindicescanbedone aspart ofthetuningofthephysical
schema,butexaminingaqueryhelpsusunderstandwhatindicesmaybeusefultospeed
upthatquery.
Indicesareparticularlyimportantforqueriesthatfetchonlyafewrowsfromalarge
relation,basedonapredicate.Forexample,aquerythatfindsstudentsinadepartment
1ThecommandiscalledanalyzetableinthecaseofMySQL.

--- Page 1249 ---

1220 Chapter25 AdvancedApplicationDevelopment
may benefit from an index on the student relation on the attribute dept name. Indices
on joinattributes areoften veryuseful.Forexample, iftheabove queryalsoincluded
a join of student with takes on the attribute takes.ID, an index on takes.ID could be
useful.
Notethatdatabasestypicallycreateindicesonprimary-keyattributes,whichcanbe
usedforselectionsaswellasjoins.Forexample,inouruniversityschema,theprimary-
key index on takes has ID as its first attribute and may thus be useful for the above
join.
Complexqueriescontainingnestedsubqueriesarenotoptimizedverywellbymany
optimizers.WesawtechniquesfornestedsubquerydecorrelationinSection16.4.4.Ifa
subqueryisnotdecorrelated,itgetsexecutedrepeatedly,potentiallyresultinginagreat
deal ofrandom I/O.In contrast, decorrelationallowsefficientset-oriented operations
such as joins to be used, minimizing random I/O. Most database query optimizers
incorporatesomeformsofdecorrelation,butsomecanhandleonlyverysimplenested
subqueries. Theexecution planchosen bytheoptimizercanbe found asdescribedin
Chapter16.Iftheoptimizerhasnotsucceededindecorrelatinganestedsubquery,the
querycanbedecorrelatedbyrewritingitmanually.
25.1.5.2 ImprovingSetOrientation
WhenSQLqueriesareexecutedfromanapplicationprogram,itisoftenthecasethat
aqueryisexecutedfrequently,butwithdifferentvaluesforaparameter.Eachcallhas
anoverheadofcommunicationwiththeserver,inadditiontoprocessingoverheadsat
theserver.
Forexample,consideraprogramthatstepsthrougheachdepartment,invokingan
embeddedSQLquerytofindthetotalsalaryofallinstructorsinthedepartment:
selectsum(salary)
frominstructor
wheredept name=?
If the instructor relation does not have a clustered indexon dept name, each such
querywillresultinascanoftherelation.Evenifthereissuchanindex,arandomI/O
operationwillberequiredforeachdept namevalue.
Instead,wecanuseasingleSQLquerytofindtotalsalaryexpensesofeachdepart-
ment:
selectdept name,sum(salary)
frominstructor
groupbydept name;
Thisquerycanbeevaluatedwithasinglescanoftheinstructor relation,avoidingran-
domI/Oforeachdepartment.Theresultscanbefetchedtotheclientsideusingasingle
roundofcommunication,andtheclientprogramcanthenstepthroughtheresultsto
findtheaggregateforeachdepartment.CombiningmultipleSQLqueriesintoasingle

--- Page 1250 ---

25.1 PerformanceTuning 1221
PreparedStatementpStmt = conn.prepareStatement(
"insert into instructor values(?,?,?,?)");
pStmt.setString(1,"88877");
pStmt.setString(2,"Perry");
pStmt.setInt(3,"Finance");
pStmt.setInt(4,125000);
pStmt.addBatch();
pStmt.setString(1,"88878");
pStmt.setString(2,"Thierry");
pStmt.setInt(3,"Physics");
pStmt.setInt(4,100000);
pStmt.addBatch();
pStmt.executeBatch();
Figure 25.2 BatchupdateinJDBC.
SQLqueryasabovecanreduceexecutioncostsgreatlyinmanycases—forexample,if
theinstructor relationisverylargeandhasalargenumberofdepartments.
TheJDBCAPIalsoprovidesafeaturecalledbatchupdatethatallowsanumberof
inserts to be performed usinga single communication withthe database. Figure25.2
illustratestheuseofthisfeature.Thecodeshowninthefigurerequiresonlyoneround
ofcommunicationwiththedatabase,whentheexecuteBatch()methodisexecuted,in
contrasttosimilarcodewithoutthebatchupdatefeaturethatwesawinFigure5.2.In
theabsenceofbatchupdate,asmanyroundsofcommunicationwiththedatabaseare
requiredasthereareinstructorstobeinserted.Thebatchupdatefeaturealsoenables
thedatabasetoprocessabatchofinsertsatonce,whichcanpotentiallybedonemuch
moreefficientlythanaseriesofsinglerecordinserts.
Anothertechniqueusedwidelyinclient-serversystemstoreducethecostofcom-
municationandSQLcompilationistousestoredprocedures,wherequeriesarestored
attheserverintheformofprocedures,whichmaybeprecompiled.Clientscaninvoke
thesestoredproceduresratherthancommunicateaseriesofqueries.
25.1.5.3 TuningofBulkLoadsandUpdates
When loading a large volume of data into a database (called a bulk load operation),
performance is usually very poor if the inserts are carried out as separate SQL insert
statements.OnereasonistheoverheadofparsingeachSQLquery;amoreimportant
reasonisthatperformingintegrityconstraintchecksandindexupdatesseparatelyfor
each inserted tuple results in a large number of random I/O operations. If the inserts
weredoneasalargebatch,integrity-constraintcheckingandindexupdatecanbedone

--- Page 1251 ---

1222 Chapter25 AdvancedApplicationDevelopment
inamuchmoreset-orientedfashion,reducingoverheadsgreatly;performanceimprove-
mentsofanorderofmagnitudeormorearenotuncommon.
Tosupportbulkloadoperations,mostdatabasesystemsprovideabulkimportutil-
ity and a corresponding bulk export utility. The bulk-import utility reads data from a
fileandperformsintegrityconstraintcheckingaswellasindexmaintenanceinavery
efficient manner. Common input and output file formats supported by such bulk im-
port/exportutilitiesincludetextfileswithcharacterssuchascommasortabsseparating
attributevalues,witheachrecordinalineofitsown(suchfileformatsarereferredto
as comma-separated values or tab-separated values formats). Database-specific binary
formatsaswellasXMLformatsarealsosupportedbybulkimport/exportutilities.The
namesofthebulkimport/exportutilitiesdifferbydatabase.InPostgreSQL,theutilities
arecalledpgdumpandpgrestore(PostgreSQLalsoprovidesanSQLcommandcopy,
whichprovidessimilarfunctionality).Thebulkimport/exportutilityinOracleiscalled
SQL*Loader,theutilityinDB2iscalledload,andtheutilityinSQLServeriscalledbcp
(SQLServeralsoprovidesanSQLcommandcalledbulkinsert).
We now consider the case of tuning of bulk updates. Suppose we have a relation
fundsreceived(dept name,amount)thatstoresfundsreceived(say,byelectronicfunds
transfer)foreachofasetofdepartments.Supposenowthatwewanttoaddtheamounts
to the balances of the corresponding department budgets. In order to use the SQL
update statement to carry out this task, we have to perform a look up on the funds
received relation for each tuple in the department relation. We can use subqueries in
the update clause to carry out this task, as follows: We assume for simplicitythat the
relationfundsreceived containsatmostonetupleforeachdepartment.
updatedepartmentsetbudget=budget+
(selectamount
fromfundsreceived
wherefundsreceived.dept name=department.dept name)
whereexists(
select*
fromfundsreceived
wherefundsreceived.dept name=department.dept name);
Note that the condition in the where clause of the update ensures that only accounts
withcorrespondingtuplesinfundsreceivedareupdated,whilethesubquerywithinthe
setclausecomputestheamounttobeaddedtoeachsuchdepartment.
There are many applications that require updates such as that illustrated above.
Typically,thereisatable,whichweshallcallthemastertable,andupdatestothemaster
tablearereceivedasabatch.Nowthemastertablehastobecorrespondinglyupdated.
SQL:2003 introduced a special construct, called the merge construct, to simplify the
task of performing such merging of information. For example, the preceding update
canbeexpressedusingmergeasfollows:

--- Page 1252 ---

25.1 PerformanceTuning 1223
mergeintodepartmentasA
using (select*
fromfundsreceived)asF
on(A.dept name=F.deptname)
whenmatchedthen
updatesetbudget=budget+F.amount;
When a record from the subquery in the using clause matchesa record in the depart-
ment relation, the when matched clause is executed, which can execute an update on
therelation;inthiscase,thematchingrecordinthedepartmentrelationisupdatedas
shown.
Themergestatementcanalsohaveawhennotmatchedthenclause,whichpermits
insertionofnewrecordsintotherelation.Intheprecedingexample,whenthereisno
matchingdepartmentforafundsreceivedtuple,theinsertionactioncouldcreateanew
departmentrecord(withanullbuilding)usingthefollowingclause:
whennotmatchedthen
insertvalues(F.deptname,null,F.budget)
Althoughnotverymeaningfulinthisexample,2 thewhennotmatchedthenclausecan
be quite useful in other cases. For example, suppose the local relation is a copy of
a master relation, and we receive updated as well as newly inserted records from the
master relation. The merge statement can update matched records (these would be
updated old records) and insert records that are not matched (these would be new
records).
Not all SQL implementations support the merge statement currently; see the re-
spectivesystemmanualsforfurtherdetails.
25.1.6 Tuning of the Logical Schema
Performance of queries can sometimes be improved by tuning of the logical schema.
Forexample,withintheconstraintsofthechosennormalform,itispossibletoparti-
tionrelationsvertically.Considerthecourserelation,withtheschema:
course(course id,title,dept name,credits)
for which course id is a key. Within the constraints of the normal forms (BCNF and
3NF),wecanpartitionthecourserelationintotworelations:
course credit(course id,credits)
course title dept(course id,title,dept name)
2Abetteractionherewouldhavebeentoinserttheserecordsintoanerrorrelation,butthatcannotbedonewiththe
mergestatement.

--- Page 1253 ---

1224 Chapter25 AdvancedApplicationDevelopment
Thetworepresentationsarelogicallyequivalent,sincecourse id isakey,buttheyhave
differentperformancecharacteristics.
Ifmostaccessestocourseinformationlookatonlythecourse id andcredits,then
they can be run against the course credit relation, and access is likelyto be somewhat
faster, since the title and dept name attributes are not fetched. For the same reason,
more tuples of course credit will fit in the buffer than corresponding tuples of course,
againleadingtofasterperformance.Thiseffectwouldbeparticularlymarkedifthetitle
and dept name attributes were large. Hence, a schema consisting of course credit and
course title deptwouldbepreferabletoaschemaconsistingofthecourserelationinthis
case.
Ontheotherhand,ifmostaccessestocourseinformationrequirebothdept name
and credits,usingthecourse relationwouldbe preferable, sincethecostof thejoinof
course credit and course title dept would be avoided. Also, the storage overhead would
belower,sincetherewouldbeonlyonerelation,andtheattributecourse id wouldnot
bereplicated.
The column store approach to storing data are based on vertical partitioning but
takes it to the limit by storing each attribute (column) of the relation in a separate
file, as we saw in Section 13.6. Note that in a column store it is not necessary to re-
peat the primary-key attribute since the ith row can be reconstructed by taking the ith
entry for each desired column. Column stores have been shown to perform well for
several data-warehouse applications by reducing I/O, improving cache performance,
enablinggreatergainsfromdatacompression,andallowingeffectiveuseofCPUvector-
processingcapabilities.
Anothertricktoimprove performanceistostore adenormalizedrelation, such as
a join of instructor and department, where the information about dept name, building,
and budget is repeated for every instructor. More effort has to be expended to make
sure the relation is consistent whenever an update is carried out. However, a query
thatfetchesthenamesoftheinstructorsandtheassociatedbuildingswillbespeeded
up, since the join of instructor and department will have been precomputed. If such a
query is executed frequently, and has to be performed as efficiently as possible, the
denormalizedrelationcouldbebeneficial.
Materialized views can provide the benefits that denormalized relations provide,
atthecostofsomeextrastorage.Amajoradvantagetomaterializedviewsoverdenor-
malized relations is that maintaining consistency of redundant data becomes the job
of the database system, not the programmer. Thus, materializedviews are preferable,
whenevertheyaresupportedbythedatabasesystem.
Anotherapproach to speed up the computation of the join withoutmaterializing
itistoclusterrecordsthatwouldmatchinthejoinonthesamediskpage.Wesawsuch
clusteredfileorganizationsinSection13.3.3.
25.1.7 Tuning of Concurrent Transactions
Concurrent execution of different types of transactions can sometimes lead to poor
performance because of contention on locks. We first consider the case of read-write

--- Page 1254 ---

25.1 PerformanceTuning 1225
contention, which is more common, and then consider the case of write-write con-
tention.
Asanexampleofread-writecontention,considerthefollowingsituationonabank-
ingdatabase.Duringtheday,numeroussmallupdatetransactionsareexecutedalmost
continuously.Supposethatalargequerythatcomputesstatisticsonbranchesisrunat
thesametime.Ifthequeryperformsascanonarelation,itmayblockoutallupdates
ontherelationwhileitruns,andthatcanhaveadisastrouseffectontheperformance
ofthesystem.
Severaldatabase systems—Oracle, PostgreSQL,andMicrosoftSQLServer,forex-
ample— supportsnapshotisolation,wherebyqueriesareexecutedonasnapshotofthe
data,andupdatescangoonconcurrently.(Snapshotisolationisdescribedindetailin
Section18.8.)Snapshotisolationshouldbeused,ifavailable,forlargequeries,toavoid
lockcontentionintheabovesituation.InSQLServer,executingthestatement
settransactionisolationlevelsnapshot
atthebeginningofatransactionresultsinsnapshotisolationbeingusedforthattrans-
action. In Oracle and PostgreSQL, using the keyword serializable in place of the key-
wordsnapshotintheabovecommandhasthesameeffect,sincethesesystemsactually
use snapshot isolation (serializable snapshot isolation, in the case of PostgreSQL ver-
sion9.1onwards)whentheisolationlevelissettoserializable.
Ifsnapshotisolationisnotavailable,analternativeoptionistoexecutelargequeries
attimeswhenupdatesarefewornonexistent.However,fordatabasessupportingweb
sites,theremaybenosuchquietperiodforupdates.
Anotheralternativeistouseweakerlevelsofconsistency,suchasthereadcommit-
tedisolationlevel,wherebyevaluationofthequeryhasaminimalimpactonconcurrent
updates,butthequeryresultsarenotguaranteedtobeconsistent.Theapplicationse-
manticsdeterminewhetherapproximate(inconsistent)answersareacceptable.
We now consider the case of write-write contention. Data items that are updated
very frequently can result in poor performance with locking, with many transactions
waiting for locks on those data items. Such data items are called update hot spots.
Update hot spots can cause problems even with snapshot isolation, causing frequent
transactionabortsduetowrite-validationfailures.Acommonlyoccurringsituationthat
resultsinanupdatehotspotisasfollows:transactionsneedtoassignuniqueidentifiers
to data items being inserted into the database, and to do so they read and increment
a sequence counter stored in a tuple in the database. If inserts are frequent, and the
sequence counterislockedinatwo-phase manner,thetuple containingthesequence
counterbecomesahotspot.
One way to improve concurrency is to release the lock on the sequence counter
immediatelyafteritisreadandincremented;however,afterdoingso,evenifthetrans-
actionaborts,theupdatetothesequencecountershouldnotberolledback.Tounder-
stand why, suppose T increments the sequence counter, and then T incrementsthe
1 2
sequence counterbeforeT commits;ifT thenaborts, rollingbackitsupdate, either
1 1

--- Page 1255 ---

1226 Chapter25 AdvancedApplicationDevelopment
byrestoringthecountertotheoriginalvalueorbydecrementingthecounter,willresult
inthesequencevalueusedbyT gettingreusedbyasubsequenttransaction.
2
Mostdatabasesprovideaspecialconstructforcreatingsequencecountersthatim-
plementearly,non-two-phaselockrelease,coupledwithspecial-casetreatmentofundo
loggingsothatupdatestothecounterarenotrolledbackifthetransactionaborts.The
SQLstandardallowsasequencecountertobecreatedusingthecommand:
createsequencecounter1;
Intheabovecommand,counter1isthenameofthesequence;multiplesequencescan
be created with different names. The syntax to get a value from the sequence is not
standardized;inOracle,counter1.nextval wouldreturnthenextvalueofthesequence,
afterincrementingit,whilethefunctioncallnextval (’counter1’)wouldhavethesame
effectinPostgreSQL,andDB2usesthesyntaxnextvalforcounter1.
The SQL standard provides an alternative to using an explicit sequence counter,
which is useful when the goal is to give unique identifiersto tuples inserted into a re-
lation. To do so, the keyword identity can be added to the declaration of an integer
attribute of a relation (usually this attribute would also be declared as the primary
key). If the value for that attribute is left unspecified in an insert statement for that
relation,a unique new value iscreated automaticallyfor each newlyinserted tuple. A
non-two-phaselockedsequencecounterisusedinternallytoimplementtheidentitydec-
laration,withthecounterincrementedeachtimeatupleisinserted.Severaldatabases,
including DB2 and SQL Server support the identity declaration, although the syntax
varies. PostgreSQL supports adatatype calledserial, whichprovidesthe same effect;
the PostgreSQL type serial is implemented by transparently creating a non-two-phase
lockedsequence.
Itisworthnotingthatsincetheacquisitionofasequencenumberbyatransaction
cannotberolledbackifthetransactionaborts(forreasonsdiscussedearlier),transac-
tionabortsmayresultingapsinthesequencenumbersintuplesinsertedinthedatabase.
Forexample,theremaybetupleswithidentifiervalue1001and1003,butnotuplewith
value 1002, if the transaction that acquired the sequence number 1002 did not com-
mit. Such gaps are not acceptable in some applications; for example, some financial
applications require that there be no gaps in bill or receipt numbers. Database pro-
videdsequencesandautomaticallyincrementedattributesshouldnotbeusedforsuch
applications,sincetheycanresultingaps.Asequencecounterstoredinnormaltuples,
whichislockedinatwo-phasemanner,wouldnotbesusceptibletosuchgapssincea
transaction abort would restore the sequence counter value, and the next transaction
wouldgetthesamesequencenumber,avoidingagap.
Long update transactions can cause performance problems with system logs and
canincreasethetimetakentorecoverfromsystem crashes.Ifatransactionperforms
manyupdates,thesystemlogmaybecomefullevenbeforethetransactioncompletes,
inwhichcasethetransactionwillhavetoberolledback.Ifanupdatetransactionruns
for a long time (even with few updates), it may block deletion of old parts of the log,

--- Page 1256 ---

25.1 PerformanceTuning 1227
if the logging system is not well designed. Again, this blocking could lead to the log
gettingfilledup.
Toavoid such problems, many database systems impose strictlimitson the num-
ber of updates that a single transaction can carry out. Even if the system does not
imposesuchlimits,itisoftenhelpfultobreakupalargeupdatetransactionintoaset
ofsmallerupdatetransactionswherepossible.Forexample,atransactionthatgivesa
raise to every employee in a large corporation could be split up into a series of small
transactions, each of which updates a small range of employee-ids. Such transactions
arecalledminibatchtransactions.However,minibatchtransactionsmustbeusedwith
care. First, if there are concurrent updates on the set of employees, the result of the
setofsmallertransactionsmaynotbeequivalenttothatofthesinglelargetransaction.
Second, if there is a failure, the salaries of some of the employees would have been
increased by committed transactions, but salaries of other employees would not. To
avoid this problem, as soon as the system recovers from failure, we must execute the
transactionsremaininginthebatch.
Long transactions, whether read-only or update, can also result in the lock table
becomingfull.Ifasinglequeryscansalargerelation,thequeryoptimizerwouldensure
that a relation lock is obtained instead of acquiring a large number of tuple locks.
However, ifa transaction executes a large number of small queries or updates, itmay
acquirealargenumberoflocks,resultinginthelocktablebecomingfull.
Toavoidthisproblem,somedatabasesprovideforautomaticlockescalation;with
thistechnique,ifatransactionhasacquiredalargenumberoftuplelocks,tuplelocks
are upgraded to page locks, or even full relation locks. Recall that with multiple-
granularity locking (Section 18.3), once a coarser-level lock is obtained, there is no
need to record finer-level locks, so tuple lock entries can be removed from the lock
table,freeingupspace.Ondatabasesthatdonotsupportlockescalation,itispossible
forthetransactiontoexplicitlyacquirearelationlock,therebyavoidingtheacquisition
oftuplelocks.
25.1.8 Tuning of Hardware
Hardwarebottleneckscouldincludememory,I/O,CPUandnetworkcapacity.Wefocus
on memory and I/O tuning in this section. The availability of processors with a large
numberofCPUcores,andsupportformultipleCPUsonasinglemachineallowssystem
designerstochoosetheCPUmodelandnumberofCPUstomeettheCPUrequirements
of the application at an acceptable cost. How to tune or choose between CPU and
networkinterconnectoptionsisatopicoutsidethedomainofdatabasetuning.
Eveninawell-designedtransactionprocessingsystem,eachtransactionusuallyhas
todoatleastafewI/Ooperations,ifthedatarequiredbythetransactionareondisk.
Animportantfactorintuningatransactionprocessingsystemistomakesurethatthe
disksubsystemcanhandletherateatwhichI/Ooperationsarerequired.Forinstance,
consideraharddiskthatsupportsanaccesstimeofabout10milliseconds,andaverage
transferrateof25to100megabytespersecond(afairlytypicaldisktoday).Suchadisk

--- Page 1257 ---

1228 Chapter25 AdvancedApplicationDevelopment
wouldsupportalittleunder100random-accessI/Ooperationsof4kilobyteseachper
second.IfeachtransactionrequiresjusttwoI/Ooperations,asinglediskwouldsupport
atmost50transactionspersecond.
Anobviouswaytoimproveperformanceistoreplaceaharddiskwithasolid-state
drive(SSD),sinceasingleSSDcansupporttensofthousandsofrandomI/Ooperations
persecond.AdrawbackofusingSSDsisthattheycostalotmorethanharddisksfor
a given storage capacity. Another way to support more transactions per second is to
increasethenumberofdisks.Ifthesystemneedstosupportntransactionspersecond,
each performing two I/O operations, data must be striped (or otherwise partitioned)
acrossat least n∕50hard disks(ignoring skew), or n∕5000 SSDs,ifthe SSDsupports
10,000randomI/Ooperationspersecond.
Noticeherethatthelimitingfactorisnotthecapacityofthedisk,butthespeedat
whichrandomdatacanbeaccessed(limitedinaharddiskbythespeed atwhichthe
diskarmcanmove).ThenumberofI/Ooperationspertransactioncanbereducedby
storingmoredatainmemory.Ifalldataareinmemory,therewillbenodiskI/Oexcept
for writes. Keeping frequently used data in memory reduces the number of disk I/Os
andisworththeextracostofmemory.Keepingveryinfrequentlyuseddatainmemory
wouldbeawaste,sincememoryismuchmoreexpensivethandisk.
The question is, for a given amount of money available for spending on disks or
memory,whatisthebestwaytospendthemoneytoachievethemaximumnumberof
transactionspersecond?AreductionofoneI/Opersecondsaves:
(priceperdiskdrive)∕(accesspersecondperdisk)
Thus,ifaparticularpageisaccessedonceinmseconds,thesavingduetokeeping
itinmemoryis 1 timestheabovevalue.Storingapageinmemorycosts:
m
(pricepermegabyteofmemory)∕(pagespermegabyteofmemory)
Thus,thebreak-evenpointis:
1 priceperdiskdrive pricepermegabyteofmemory
∗ =
m accesspersecondperdisk pagespermegabyteofmemory
We can rearrange the equation and substitute current values for each of the above
parameters to get a value for m; if a page is accessed more frequently than once inm
seconds,itisworthbuyingenoughmemorytostoreit.
Asof 2018, hard-disktechnology and memoryand diskprices(whichweassume
tobeabout$50fora1-terabytediskand$80for16-gigabytesofmemory)giveavalue
ofmaround4hoursfor4-kilobytespagesthatarerandomlyaccessed;thatis,ifapage
on hard disk is accessed at least once in 4 hours, it makes sense to purchase enough
memory to cache it in memory. Note that if we use larger pages, the time decreases;
forexample,apagesizeof16-kilobyteswillleadtoavalueofmof1hourinsteadof4
hours.

--- Page 1258 ---

25.1 PerformanceTuning 1229
With disk and memory cost and speeds as of the 1980/1990s, the corresponding
value was5minuteswith4-kilobytespages. Thus, awidelyused ruleofthumb,called
thefiveminuterule,whichsaidthatdatashouldbecachedinmemoryifitisaccessed
morefrequentlythanoncein5minutes.
WithSSDtechnologyandpricesasof2018(whichweassumetobearound$500
for a 800 gigabytes SSD, which supports 67,000 random reads and 20,000 random
writespersecond),ifwemakethesamecomparisonbetweenkeepingapageinmemory
versusfetchingitfromSSD,thetimecomestoaround7minuteswith4-kilobytepages.
Thatis,ifapageonSSDisaccessedmorefrequentlythanoncein7minutes,itisworth
purchasingenoughmemorytocacheitinmemory.
For data that are sequentially accessed, significantly more pages can be read per
second.Assuming1megabyteofdataarereadatatime,thebreakevenpointforhard
disk currently is about 2.5 minutes. Thus, sequentially accessed data on hard disk
shouldbecachedinmemoryiftheyareusedatleastoncein2.5minutes.ForSSDs,the
breakeven pointismuch smaller,at 1.6seconds. In otherwords, thereis littlebenefit
incachingsequentiallyaccesseddatainmemoryunlessitisveryfrequentlyaccessed.
TheaboverulesofthumbtakeonlythenumberofI/Ooperationspersecondinto
account and do not consider factors such as response time. Some applications need
tokeepeveninfrequentlyuseddatainmemorytosupportresponsetimesthatareless
thanorcomparabletodisk-accesstime.
Since SSD storage is more expensive than disk, one way to get faster random I/O
for frequently used data, while paying less for storing less frequently used data, is to
use theflash-as-buffer approach.In thisapproach,flash storage isused as apersistent
buffer,witheachblockhavingapermanentlocationondisk,butstoredinflashinstead
of being written to disk as long as it is frequently used. When flash storage is full, a
block that is not frequently used is evicted and flushed back to disk if it was updated
after being read from disk. Disk subsystems that provide hard disks along with SSDs
thatactasbuffersarecommerciallyavailable.Aruleofthumbfordecidinghowmuch
SSDstoragetopurchaseisthata4-kilobytepageshouldbekeptonSSD,insteadofhard
disk, if it is accessed more frequently than once in a day (the computation is similar
to the case of caching in main memory versus fetching from disk/SSD). Note that in
suchasetup,thedatabasesystemcannotcontrolwhatdataresideinwhichpartofthe
storage.
IfthestoragesystemallowsdirectaccesstoSSDsaswellasharddisks,thedatabase
administrator can control the mapping of relations or indices to disks and allocate
frequentlyusedrelations/indicestoflashstorage.Thetablespacefeature,supportedby
mostdatabasesystems,canbeusedtocontrolthemappingbycreatingatablespaceon
flashstorageandassigningdesiredrelationsandindicestothattablespace.Controlling
themappingatafinerlevelofgranularitythanarelation,however,requireschangesto
thedatabase-systemcode.
AnotheraspectoftuningiswhethertouseRAID1orRAID5.Theanswerdepends
onhowfrequentlythedataareupdated,sinceRAID5ismuchslowerthanRAID1on

--- Page 1259 ---

1230 Chapter25 AdvancedApplicationDevelopment
randomwrites:RAID5requires2readsand2writestoexecuteasinglerandomwrite
request.Ifanapplicationperformsrrandomreadsandwrandomwritespersecondto
support aparticularthroughput rate, a RAID 5 implementationwould requirer +4w
I/Ooperationspersecond,whereasaRAID1implementationwouldrequirer+2wI/O
operationspersecond.Wecanthencalculatethenumberofdisksrequiredtosupport
therequiredI/Ooperationspersecondbydividingtheresultofthecalculationby100
I/Ooperationspersecond(forcurrent-generationdisks).Formanyapplications,rand
w are large enough that the (r + w)∕100 disks can easily hold two copies of all the
data.Forsuchapplications,ifRAID1isused,therequirednumberofdisksisactually
lessthantherequirednumberofdisksifRAID5isused! Thus,RAID 5isuseful only
whenthedatastoragerequirementsareverylarge,buttheupdaterates,andparticularly
randomupdaterates,aresmall.
25.1.9 Performance Simulation
Totesttheperformanceofadatabasesystemevenbeforeitisinstalled,wecancreate
aperformance-simulationmodelofthedatabasesystem.EachserviceshowninFigure
25.1,suchastheCPU,eachdisk,thebuffer,andtheconcurrencycontrol,ismodeled
in the simulation. Instead of modelingdetailsof a service, the simulation model may
capture only some aspects of each service, such as the service time—that is, the time
taken to finish processing a request once processing has begun. Thus, the simulation
canmodeladiskaccessfromjusttheaveragedisk-accesstime.
Since requests for a service generally have to wait their turn, each service has an
associatedqueueinthesimulationmodel.Atransactionconsistsofaseriesofrequests.
Therequestsarequeuedupastheyarriveandareservicedaccordingtothepolicyfor
thatservice,suchasfirstcome,firstserved.ThemodelsforservicessuchasCPUand
thedisksconceptuallyoperateinparallel,toaccountforthefactthatthesesubsystems
operateinparallelinarealsystem.
Oncethesimulationmodelfortransactionprocessingisbuilt,thesystemadminis-
tratorcanrunanumberofexperimentsonit.Theadministratorcanuseexperiments
with simulated transactions arriving at different rates to find how the system would
behaveundervariousloadconditions.Theadministratorcouldrunotherexperiments
thatvarytheservicetimesforeachservicetofindouthowsensitive theperformance
istoeachofthem.Systemparameters,too,canbevaried,sothatperformancetuning
canbedoneonthesimulationmodel.
25.2 Performance Benchmarks
As database servers become more standardized, the differentiating factor among the
productsofdifferentvendorsisthoseproducts’performance.Performancebenchmarks
aresuitesoftasksthatareusedtoquantifytheperformanceofsoftwaresystems.

--- Page 1260 ---

25.2 PerformanceBenchmarks 1231
25.2.1 Suites of Tasks
Since most software systems, such as databases, are complex, there is a good deal of
variationintheirimplementationbydifferentvendors.Asaresult,thereisasignificant
amount of variation in their performance on different tasks. One system may be the
mostefficientonaparticulartask;anothermaybethemostefficientonadifferenttask.
Hence, a single task is usually insufficient to quantify the performance of the system.
Instead,theperformanceofasystemismeasuredbysuitesofstandardizedtasks,called
performancebenchmarks.
Combiningtheperformancenumbersfrommultipletasksmustbedonewithcare.
Suppose thatwe have two tasks, T and T , and that we measure the throughput of a
1 2
systemasthenumberoftransactionsofeachtypethatruninagivenamountoftime—
say,1second.SupposethatsystemArunsT at99transactionspersecondandT at
1 2
1transactionpersecond.Similarly,letsystemBrunbothT andT at50transactions
1 2
per second. Suppose also that a workload has an equal mixture of the two types of
transactions.
Ifwetooktheaverageofthetwopairsofnumbers(i.e.,99and1,versus50and50),
itmightappear thatthe twosystems have equal performance.However, itiswrong to
taketheaveragesinthisfashion—ifweran50transactionsofeachtype,systemAwould
takeabout50.5secondstofinish,whereassystemBwouldfinishinjust2seconds!
Theexampleshowsthatasimplemeasureofperformanceismisleadingifthereis
morethanonetypeoftransaction.Therightwaytoaverageoutthenumbersistotake
the time to completion for the workload, rather than the average throughput for each
transactiontype.Wecanthencomputesystemperformanceaccuratelyintransactions
per second for a specified workload. Thus, system A takes 50.5∕100, which is 0.505
secondspertransaction,whereassystem Btakes0.02secondspertransaction,on av-
erage. In terms of throughput, system A runs at an average of 1.98 transactions per
second,whereassystem Brunsat50transactionspersecond.Assumingthattransac-
tionsofallthetypesareequallylikely,thecorrectwaytoaverageoutthethroughputs
on different transaction types is to take the harmonic mean of the throughputs. The
harmonicmeanofnthroughputst ,t ,…,t isdefinedas:
1 2 n
n
1 + 1 +⋯+ 1
t t t
1 2 n
Forourexample,theharmonicmeanforthethroughputsinsystemAis1.98.For
systemB,itis50.Thus,systemBisapproximately25timesfasterthansystemAona
workloadconsistingofanequalmixtureofthetwoexampletypesoftransactions.
25.2.2 Database-Application Classes
Onlinetransactionprocessing(OLTP)anddecisionsupport,includingonlineanalytical
processing(OLAP),aretwobroadclassesofapplicationshandledbydatabasesystems.
These two classes of tasks have different requirements. High concurrency and clever

--- Page 1261 ---

1232 Chapter25 AdvancedApplicationDevelopment
techniques to speed up commit processing are required for supporting a high rate of
update transactions. On the other hand, good query-evaluation algorithms and query
optimizationarerequiredfordecisionsupport.Thearchitectureofsomedatabasesys-
tems has been tuned to transaction processing; that of others, such as the Teradata
seriesofparalleldatabasesystems,hasbeentunedtodecisionsupport.Othervendors
trytostrikeabalancebetweenthetwotasks.
Applicationsusuallyhaveamixtureoftransaction-processinganddecision-support
requirements.Hence,whichdatabasesystemisbestforanapplicationdependsonwhat
mixofthetworequirementstheapplicationhas.
Supposethatwehavethroughputnumbersforthetwoclassesofapplicationssepa-
rately,andtheapplicationathandhasamixoftransactionsinthetwoclasses.Wemust
be careful even about taking the harmonic mean of the throughput numbers because
ofinterferencebetweenthetransactions.Forexample,along-runningdecision-support
transaction mayacquireanumberoflocks,whichmaypreventallprogressofupdate
transactions. The harmonic mean of throughputs should be used only if the transac-
tionsdonotinterferewithoneanother.
25.2.3 The TPC Benchmarks
TheTransactionProcessingPerformanceCouncil(TPC)hasdefinedaseriesofbench-
markstandardsfordatabasesystems.
The TPC benchmarks are defined in great detail. They define the set of relations
and the sizes of the tuples. They define the number of tuples in the relations not as
a fixed number, but rather as a multiple of the number of claimed transactions per
second, to reflect that a larger rate of transaction execution is likely to be correlated
with a larger number of accounts. The performance metric is throughput, expressed
astransactionspersecond(TPS).Whenitsperformanceismeasured,thesystemmust
provide a response time within certain bounds, so that a high throughput cannot be
obtained at the cost of very long response times. Further, for business applications,
cost is of great importance. Hence, the TPC benchmark also measures performance
intermsofpriceperTPS.Alargesystem mayhaveahighnumberoftransactionsper
second,butitmaybeexpensive(i.e.,haveahighpriceperTPS).Moreover,acompany
cannot claim TPC benchmark numbers for its systems without an external audit that
ensures that the system faithfully follows the definition of the benchmark, including
fullsupportfortheACIDpropertiesoftransactions.
ThefirstintheserieswastheTPC-Abenchmark,whichwasdefinedin1989.This
benchmark simulates a typical bank application by a single type of transaction that
models cash withdrawal and deposit at a bank teller. The transaction updates several
relations—suchasthebankbalance,theteller’sbalance,andthecustomer’sbalance—
andaddsarecordtoanaudit-trailrelation.Thebenchmarkalsoincorporatescommuni-
cationwithterminals,tomodeltheend-to-endperformanceofthesystemrealistically.
TheTPC-Bbenchmarkwasdesignedtotest thecoreperformanceofthe database sys-
tem, along with the operating system on which the system runs. It removes the parts

--- Page 1262 ---

25.2 PerformanceBenchmarks 1233
oftheTPC-Abenchmarkthatdealwithusers,communication,andterminals,tofocus
onthebackenddatabaseserver.NeitherTPC-AnorTPC-Bisinusetoday.
The TPC-C benchmark was designed to model a more complex system than the
TPC-A benchmark. The TPC-C benchmark concentrates on the main activities in an
order-entryenvironment,such asenteringand deliveringorders, recordingpayments,
checkingstatusoforders,andmonitoringlevelsofstock.TheTPC-Cbenchmarkisstill
widelyusedforbenchmarkingonlinetransactionprocessing(OLTP)systems.
ThemorerecentTPC-EbenchmarkisalsoaimedatOLTPsystemsbutisbasedon
a model of a brokerage firm, with customers who interact with the firm and generate
transactions.Thefirminturninteractswithfinancialmarketstoexecutetransactions.
The TPC-D benchmark was designed to test the performance of database systems
on decision-support queries. Decision-support systems are becoming increasingly im-
portant today. The TPC-A, TPC-B, and TPC-C benchmarks measure performance on
transaction-processingworkloadsandshouldnotbeusedasameasureofperformance
on decision-support queries. The D in TPC-D stands for decision support. The TPC-D
benchmarkschemamodelsasales/distributionapplication,withparts,suppliers,cus-
tomers,andorders,alongwithsomeauxiliaryinformation.Thesizesoftherelationsare
definedasaratio,anddatabasesizeisthetotalsizeofalltherelations,expressedingiga-
bytes.TPC-Datscalefactor1representstheTPC-Dbenchmarkona1-gigabytedatabase,
whilescalefactor10representsa10-gigabytedatabase.Thebenchmarkworkloadcon-
sistsofasetof17SQLqueriesmodelingcommontasksexecutedondecision-support
systems. Some of the queries make use of complex SQL features, such as aggregation
andnestedqueries.
Thebenchmark’suserssoonrealizedthatthevariousTPC-Dqueriescouldbesig-
nificantly speeded up by using materialized views and other redundant information.
Thereareapplications,suchasperiodicreportingtasks,wherethequeriesareknown
inadvance,andmaterializedviewscanbeselectedcarefullytospeedupthequeries.It
isnecessary,however,toaccountfortheoverheadofmaintainingmaterializedviews.
The TPC-H benchmark (where ˝ represents ad hoc) is a refinement of the TPC-D
benchmark. The schema is the same, but there are 22 queries, of which 16 are from
TPC-D. In addition, there are two updates, a set of inserts, and a set of deletes. TPC-
H prohibits materialized views and other redundant information and permits indices
onlyonprimaryandforeignkeys.Thisbenchmarkmodelsadhocqueryingwherethe
queriesarenotknownbeforehand,soitisnotpossibletocreateappropriatematerial-
izedviewsaheadoftime.Avariant,TPC-R(whereRstandsfor“reporting”),whichisno
longerinuse,allowedtheuseofmaterializedviewsandotherredundantinformation.
The TPC-DS benchmark is a follow-up to the TPC-H benchmark and models the
decision-support functions of a retail product supplier, including information about
customers,orders,andproducts,andwithmultiplesaleschannelssuchasretailstores
andonlinesales.Ithastwosubpartsoftheschema,correspondingtoadhocquerying
andreporting,similartoTPC-HandTPC-R.Thereisaqueryworkload,aswellasadata
maintenanceworkload.

--- Page 1263 ---

1234 Chapter25 AdvancedApplicationDevelopment
TPC-H and TPC-DS measure performance in this way: The power test runs the
queriesandupdatesoneatatimesequentially,and3600secondsdividedbythegeomet-
ricmeanoftheexecutiontimesofthequeries(inseconds)givesameasureofqueries
perhour. The throughputtest runs multiple streamsin parallel,witheachstream exe-
cutingall22queries.Thereisalsoaparallelupdatestream.Herethetotaltimeforthe
entirerunisusedtocomputethenumberofqueriesperhour.
Thecompositequeryperhourmetric,whichistheoverallmetric,isthenobtained
as the square root of the product of the power and throughput metrics. A composite
price/performancemetricisdefinedbydividingthesystempricebythecompositemet-
ric.
There are several other TPC benchmarks, such as a data integration benchmark
(TPC-DI), benchmarks for big data systems based on Hadoop/Spark (TPCx-HS), and
forback-endprocessingofinternet-of-thingsdata(TPCx-IoT).
25.3 Other Issues in Application Development
Inthissection,wediscusstwoissuesinapplicationdevelopment:testingofapplications
andmigrationofapplications.
25.3.1 Testing Applications
Testing of programs involves designing a test suite, that is, a collection of test cases.
Testing is not a one-time process, since programs evolve continuously, and bugs may
appearasanunintendedconsequenceofachangeintheprogram;suchabugisreferred
toasprogramregression.Thus,aftereverychangetoaprogram,theprogrammustbe
testedagain.Itisusuallyinfeasibletohaveahumanperformtestsaftereverychangeto
aprogram.Instead,expectedtestoutputsarestoredwitheachtestcaseinatestsuite.
Regression testing involves running the program on each test case in a test suite and
checkingthattheprogramgeneratestheexpectedtestoutput.
Inthecontextofdatabaseapplications,atestcaseconsistsoftwoparts:adatabase
stateandaninputtoaspecificinterfaceoftheapplication.
SQLqueriescanhavesubtlebugsthatcanbedifficulttocatch.Forexample,aquery
may execute a join when it should have performed an outer join (i.e., r ⋈ s, when it
shouldhaveactuallyperformedr⟕s).Thedifferencebetweenthesetwoquerieswould
be found only if the test database had an r tuple with no matchings tuple. Thus, it is
important to create test databases that can catch commonly occurring errors. Such
errors are referred to as mutations, since they are usually small changes to a query
(orprogram).Atestcasethatproducesdifferentoutputs onanintendedqueryanda
mutant of the query is said to kill the mutant. A test suite should have test cases that
kill(most)commonlyoccurringmutants.
Ifatestcaseperformsanupdateonthedatabase,tocheckthatitexecutedproperly
one mustverifythatthecontentsofthedatabase matchtheexpected contents.Thus,

--- Page 1264 ---

25.3 OtherIssuesinApplicationDevelopment 1235
the expected output consists not only of data displayed on the user’s screen, but also
(updatesto)thedatabasestate.
Sincethedatabasestatecanberatherlarge,multipletestcaseswouldshareacom-
mon database state. Testing is complicated by the fact that if a test case performs an
update on the database, the results of other test cases run subsequently on the same
databasemaynotmatchtheexpectedresults.Theothertestcaseswouldthenbeerro-
neouslyreportedashavingfailed.Toavoidthisproblem,wheneveratestcaseperforms
anupdate,thedatabasestatemustberestoredtoitsoriginalstateafterrunningthetest.
Testingcanalsobeusedtoensurethatanapplicationmeetsperformancerequire-
ments. To carry out such performance testing, the test database must be of the same
size as the real database would be. In some cases, there is already existing data on
which performance testing can be carried out. In other cases, a test database of the
required size must be generated; there are several tools available for generating such
test databases. These tools ensure that the generated data satisfy constraints such as
primary- and foreign-key constraints. They may additionally generate data that look
meaningful, for example, by populating a name attribute using meaningful names in-
stead of random strings. Some tools also allow data distributions to be specified; for
example, a university database may require a distribution with most students in the
rangeof18to25yearsandmostfacultyintherangeof25to65years.
Even if there is an existing database, organizations usually do not want to reveal
sensitive data to an external organization that may be carrying out the performance
tests. In such a situation, a copy of the real database may be made, and the values
inthecopymaybemodifiedinsuchawaythatanysensitivedata,suchascredit-card
numbers,socialsecuritynumbers,ordatesofbirth,areobfuscated.Obfuscationisdone
inmostcasesbyreplacingarealvaluewitharandomlygeneratedvalue(takingcareto
alsoupdateallreferencestothatvalue,incasethevalueisaprimarykey).Ontheother
hand,iftheapplicationexecutiondependsonthevalue,suchasthedateofbirthinan
applicationthatperformsdifferentactionsbasedonthedateofbirth,obfuscationmay
makesmallrandomchangesinthevalueinsteadofreplacingitcompletely.
25.3.2 Application Migration
Legacy systems are older-generation application systems that are still in use despite
being obsolete. They continue in use due to the cost and risk in replacing them. For
example,manyorganizationsdevelopedapplicationsin-house,buttheymaydecideto
replacethemwithacommercialproduct.Insomecases,alegacysystem mayuseold
technologythatisincompatiblewithcurrent-generationstandardsandsystems.Some
legacysystemsinoperationtodayareseveraldecadesoldandarebasedontechnologies
suchasdatabasesthatusethenetworkorhierarchicaldatamodels,oruseCoboland
filesystemswithoutadatabase.Suchsystemsmaystillcontainvaluabledataandmay
supportcriticalapplications.
Replacinglegacyapplicationswithnewapplicationsisoftencostlyintermsofboth
timeandmoney,sincetheyareoftenverylarge,consistingofmillionsoflinesofcode

--- Page 1265 ---

1236 Chapter25 AdvancedApplicationDevelopment
developed by teams of programmers, often over several decades. They contain large
amounts of data that must be ported to the new application, which may use a com-
pletelydifferentschema.Switchoverfromanoldtoanewapplicationinvolvesretrain-
ing large numbers of staff. Switchover must usually be done without any disruption,
withdataenteredintheoldsystemavailablethroughthenewsystemaswell.
Many organizations attempt to avoid replacing legacy systems and instead try to
interoperate them with newer systems. One approach used to interoperate between
relationaldatabasesandlegacydatabasesistobuildalayer,calledawrapper,ontopof
thelegacysystemsthatcanmakethelegacysystemappeartobearelationaldatabase.
ThewrappermayprovidesupportforODBCorotherinterconnectionstandardssuch
asOLE-DB,whichcanbeusedtoqueryandupdatethelegacysystem.Thewrapperis
responsibleforconvertingrelationalqueriesandupdatesintoqueriesandupdateson
thelegacysystem.
Whenanorganizationdecidestoreplacealegacysystemwithanewsystem,itmay
followaprocesscalledreverseengineering,whichconsistsofgoingoverthecodeofthe
legacysystemtocomeupwithschemadesignsintherequireddatamodel(suchasan
E-R model or an object-oriented data model). Reverse engineering also examines the
code to find out what procedures and processes were implemented, in order to get a
high-levelmodelofthesystem.Reverseengineeringisneededbecauselegacysystems
usuallydonothavehigh-leveldocumentationoftheirschemaandoverallsystemdesign.
When coming up with a new system, developers review the design so that it can be
improvedratherthanjustreimplementedasis.Extensivecodingisrequiredtosupport
all the functionality (such as user interface and reporting systems) that was provided
bythelegacysystem.Theoverallprocessiscalledre-engineering.
Whenanewsystemhasbeenbuiltandtested,thesystemmustbepopulatedwith
datafromthe legacysystem, andallfurtheractivitiesmustbe carriedout onthe new
system. However, abruptlytransitioningtoanewsystem, whichiscalledthe big-bang
approach,carriesseveralrisks.First,usersmaynotbefamiliarwiththeinterfacesofthe
new system. Second, there may be bugs or performance problems in the new system
that were not discovered when it was tested. Such problems may lead to great losses
for companies, since their ability to carry out critical transactions such as sales and
purchases may be severely affected. In some extreme cases the new system has even
beenabandoned,andthelegacysystemreused,afteranattemptedswitchoverfailed.
An alternative approach, called the chicken-little approach, incrementally re-
places the functionality of the legacy system. For example, the new user inter-
faces may be used with the old system in the back end, or vice versa. Another
option is to use the new system only for some functionality that can be decou-
pled from the legacy system. In either case, the legacy and new systems coex-
ist for some time. There is therefore a need for developing and using wrappers
on the legacy system to provide required functionality to interoperate with the new
system.Thisapproachthereforehasahigherdevelopmentcost.

--- Page 1266 ---

25.4 Standardization 1237
25.4 Standardization
Standardsdefinetheinterfaceofasoftwaresystem.Forexample,standardsdefinethe
syntax and semantics of a programming language, or the functions in an application-
program interface, or even a data model (such as the object-oriented database stan-
dards). Today,database systems arecomplex,and theyareoften madeupof multiple
independently created parts that need to interact. For example, client programs may
becreatedindependentlyofbackendsystems,butthetwomustbeabletointeractwith
eachother.Acompanythathasmultipleheterogeneousdatabasesystemsmayneedto
exchangedatabetweenthedatabases.Givensuchascenario,standardsplayanimpor-
tantrole.
Formal standards are those developed by a standards organization or by industry
groupsthroughapublicprocess.Dominantproductssometimesbecomedefactostan-
dards,inthattheybecomegenerallyacceptedasstandardswithoutanyformalprocess
ofrecognition.Someformalstandards,likemanyaspectsoftheSQL-92andSQL:1999
standards, are anticipatory standards that lead the marketplace; they define features
that vendors then implement in products. In other cases, the standards, or parts of
the standards, are reactionary standards, in that they attempt to standardize features
thatsomevendorshavealreadyimplemented,andthatmayevenhavebecomedefacto
standards. SQL-89 was in many ways reactionary, since it standardized features, such
as integrity checking,that were already present in the IBM SAA SQL standard and in
otherdatabases.
Formalstandardscommitteesaretypicallycomposedofrepresentativesoftheven-
dorsandofmembersfromusergroupsandstandardsorganizationssuchastheInter-
nationalOrganizationforStandardization(ISO)ortheAmericanNationalStandards
Institute(ANSI),orprofessionalbodies,suchastheInstituteofElectricalandElectron-
ics Engineers (IEEE). Formal standards committees meet periodically, and members
presentproposalsforfeaturestobeaddedtoormodifiedinthestandard.Aftera(usu-
allyextended) period of discussion, modificationstothe proposal, and public review,
membersvoteonwhethertoacceptorrejectafeature.Sometimeafterastandardhas
beendefinedandimplemented,itsshortcomingsbecomeclearandnewrequirements
becomeapparent.Theprocessofupdatingthestandardthenbegins,andanewversion
ofthestandardisusuallyreleasedafterafewyears.Thiscycleusuallyrepeatseveryfew
years,untileventually(perhapsmanyyearslater)thestandardbecomestechnologically
irrelevantorlosesitsuserbase.
Thissection givesavery high-leveloverview of differentstandards, concentrating
onthegoalsofthestandard.Detaileddescriptionsofthestandardsmentionedinthis
sectionappearinthebibliographicnotesforthischapter,availableonline.
25.4.1 SQL Standards
SinceSQListhemostwidelyusedquerylanguage,muchworkhasbeendoneonstan-
dardizing it. ANSI and ISO, with the various database vendors, have played a leading

--- Page 1267 ---

1238 Chapter25 AdvancedApplicationDevelopment
roleinthiswork.TheSQL-86standardwastheinitialversion.TheIBMSystemsAppli-
cationArchitecture(SAA)standardforSQLwasreleasedin1987.Aspeopleidentified
the need for more features, updated versions of the formal SQL standard were devel-
oped,calledSQL-89andSQL-92.
TheSQL:1999versionoftheSQLstandardaddedavarietyoffeaturestoSQL.We
haveseenmanyofthesefeaturesinearlierchapters.
SubsequentversionsoftheSQLstandardincludethefollowing:
• SQL:2003, which is a minor extension of the SQL:1999 standard. Some features
suchastheSQL:1999OLAPfeatures(Section11.3.3)werespecifiedasanamend-
ment to the earlier version of the SQL:1999 standard, instead of waiting for the
releaseofSQL:2003.
• SQL:2006,whichaddedseveralfeaturesrelatedtoXML.
• SQL:2008, which introduced only minor extensions to the SQL language such as
extensionstothemergeclause.
• SQL:2011, which added a number of temporal extensions to SQL, including the
abilitytoassociatetimeperiodswithtuples,optionallyusingexistingcolumnsas
start and end times, and primary key definitions based on the time periods. The
extensionssupportdeletesandupdateswithassociatedperiods;suchdeletesand
updatesmayresultinmodificationofthetimeperiodofexistingtuples,alongwith
deletes or inserts of new tuples. A number of operators related to time periods,
suchasoverlapsandcontains,werealsointroducedinSQL:2011.
In addition, the standard provided a number of other features, such as further
extensionstothemergeconstruct,extensionstothewindowconstructsthatwere
introducedinearlierversionsofSQL,andextensionstolimitthenumberofresults
fetchedbyaquery,usingafetchclause.
• SQL:2016,whichaddedanumberoffeaturesrelatedtoJSONsupport,andsupport
fortheaggregateoperationlistagg,whichconcatenatesattributesfromagroupof
tuplesintoastring.
It is worth mentioningthat most of the new features are supported by only a few
databasesystems,andconverselymostdatabasesystemssupportanumberoffeatures
thatarenotpartofthestandard.
25.4.2 Database Connectivity Standards
TheODBCstandardisawidelyusedstandardforcommunicationbetweenclientappli-
cationsanddatabasesystemsanddefinesAPIsinseverallanguages.TheJDBCstandard
for communication between Java applications and databases was modeled on ODBC
andprovidessimilarfunctionality.
ODBCisbased on theSQL Call LevelInterface(CLI) standards developed bythe
X/OpenindustryconsortiumandtheSQLAccessGroup,butithasseveralextensions.

--- Page 1268 ---

25.4 Standardization 1239
The ODBC API defines a CLI, an SQL syntax definition, and rules about permissible
sequencesofCLIcalls.Thestandard alsodefinesconformancelevelsfortheCLIand
theSQLsyntax.Forexample,thecoreleveloftheCLIhascommandstoconnecttoa
database, to prepare and execute SQL statements, to get back resultsor status values,
andtomanagetransactions.Thenextlevelofconformance(level1)requiressupport
forcataloginformationretrievalandsomeotherfeaturesoverandabovethecore-level
CLI;level2requiresfurtherfeatures, suchastheabilitytosendandretrievearraysof
parametervaluesandtoretrievemoredetailedcataloginformation.
ODBC allows a client to connect simultaneously to multiple data sources and to
switchamongthem,buttransactionsoneachareindependent;ODBCdoesnotsupport
two-phasecommit.
A distributed system provides a more general environment than a client–
server system. The X/Open consortium has also developed the X/Open XA standards
forinteroperationofdatabases.Thesestandardsdefinetransaction-managementprimi-
tives(suchastransactionbegin,commit,abort,andprepare-to-commit)thatcompliant
databasesshouldprovide;atransactionmanagercaninvoketheseprimitivestoimple-
mentdistributedtransactionsbytwo-phasecommit.TheXAstandardsareindependent
of the data model and of the specific interfaces between clients and databases to ex-
changedata.Thus,wecanusetheXAprotocolstoimplementadistributedtransaction
system in which a single transaction can access relational as well as object-oriented
databases,yetthetransactionmanagerensuresglobalconsistencyviatwo-phasecom-
mit.
There are many data sources that are not relational databases, and in fact may
not be databases at all. Examples are flat files and email stores. Microsoft’s OLE-DB
is a C++ API with goals similar to ODBC, but for nondatabase data sources that may
provideonlylimitedqueryingandupdate facilities.Just likeODBC,OLE-DBprovides
constructs for connecting to a data source, starting a session, executing commands,
andgettingbackresultsintheformofarowset,whichisasetofresultrows.
TheActiveXDataObjects(ADO)andADO.NETAPIs,createdbyMicrosoft,provide
aninterfacetoaccessdatafromnotonlyrelationaldatabases,butalsosomeothertypes
ofdatasources,suchasOLE-DBdatasources.
25.4.3 Object Database Standards
Standards in the area of object-oriented databases (OODB) have so far been driven
primarilybyOODBvendors.TheObjectDatabaseManagementGroup(ODMG)wasa
groupformedbyOODBvendorstostandardizethedatamodelandlanguageinterfaces
toOODBs.ODMGisnolongeractive.JDOisastandardforaddingpersistencetoJava.
There were several other attempts to standardize object databases and related
object-based technologies such as services. However, most were not widely adopted,
andtheyarerarelyusedanymore.
Object-relationalmappingtechnologies,whichstoredatainrelationaldatabasesat
thebackendbutprovideprogrammerswithanobject-basedAPItoaccessandmanip-

--- Page 1269 ---

1240 Chapter25 AdvancedApplicationDevelopment
ulatedata,haveprovenquitepopular.Systemsthatsupportobject-relationalmapping
includeHibernate,whichsupportsJava,andthedatalayerofthepopularDjangoWeb
framework, whichisbased on thePython programminglanguage. However,thereare
nowidelyacceptedformalstandardsinthisarea.
25.5 Distributed Directory Systems
Consider an organization that wishes to make data about its employees available to
a variety of people in the organization; examples of the kinds of data include name,
designation, employee-id, address, email address, phone number, fax number, and so
on.Suchdataareoftensharedviadirectories,whichallowuserstobrowseandsearch
fordesiredinformation.
Ingeneral,adirectoryisalistingofinformationaboutsomeclassofobjectssuch
as persons. Directories can be used to find information about a specific object, or in
thereversedirectiontofindobjectsthatmeetacertainrequirement.
Amajorapplicationofdirectoriestodayistoauthenticateusers:applicationscan
collectauthenticationinformationsuchaspasswordsfromusersandauthenticatethem
using the directory. Details about the user category (e.g., is the user a student or an
instructor), as well as authorizations that a user has been given, may also be shared
through a directory. Multiple applications in an organization can then authenticate
usersusingacommondirectoryserviceandusercategoryandauthorizationinforma-
tionfromthedirectorytoprovideusersonlywithdatathattheyareauthorizedtosee.
Directoriescan be used for storing other types of information,much like file sys-
tem directories. For instance, web browsers can store personal bookmarks and other
browser settingsin a directorysystem. A user can thus access the same settings from
multiplelocations,suchasathomeandatwork,withouthavingtoshareafilesystem.
25.5.1 Directory Access Protocols
Directoryinformationcanbemadeavailablethroughwebinterfaces,asmanyorgani-
zations,andphonecompaniesinparticular,do.Suchinterfacesaregoodforhumans.
However,programstooneedtoaccessdirectoryinformation.
Several directory access protocols have been developed to provide a standardized
way of accessing data in a directory. The most widely used among them today is the
LightweightDirectoryAccessProtocol(LDAP).
All the types of data in our examples can be stored without much trouble in a
databasesystemandaccessedthroughprotocolssuchasJDBCorODBC.Thequestion
thenis,whycomeupwithaspecializedprotocolforaccessingdirectoryinformation?
Thereareatleasttwoanswerstothequestion.
• First, directory access protocols are simplified protocols that cater to a limited
typeofaccesstodata.Theyevolvedinparallelwiththedatabaseaccessprotocols.

--- Page 1270 ---

25.5 DistributedDirectorySystems 1241
• Second, and more important, directory systems provide a simple mechanism to
name objects in a hierarchical fashion, similar to file system directory names,
whichcanbeusedinadistributeddirectorysystemtospecifywhatinformationis
storedineachofthedirectoryservers.Forexample,aparticulardirectoryserver
may store information for Bell Laboratories employees in Murray Hill, while an-
othermaystoreinformationforBellLaboratoriesemployeesinBangalore,giving
bothsitesautonomyincontrollingtheirlocaldata.Thedirectoryaccessprotocol
can be used to obtain data from both directories across a network. More impor-
tant,thedirectorysystemcanbesetuptoautomaticallyforwardqueriesmadeat
onesitetotheothersite,withoutuserintervention.
Forthesereasons,severalorganizationshavedirectorysystemstomakeorganiza-
tional information available online through a directory access protocol. Information
in an organizational directory can be used for a variety of purposes, such as to find
addresses, phone numbers, or email addresses of people, to find which departments
peoplearein,andtotrackdepartmenthierarchies.
As may be expected, several directory implementations find it beneficial to use
relationaldatabasestostoredatainsteadofcreatingspecial-purposestoragesystems.
25.5.2 LDAP: Lightweight Directory Access Protocol
Ingeneraladirectorysystemisimplementedasoneormoreservers,whichservicemul-
tipleclients.ClientsusetheAPIdefinedbythedirectorysystemtocommunicatewith
the directoryservers. Directoryaccess protocols also define a data model and access
control.TheX.500directoryaccessprotocol,definedbytheInternationalOrganization
forStandardization(ISO),isastandardforaccessingdirectoryinformation.However,
theprotocolisrathercomplexandisnotwidelyused.TheLightweightDirectoryAccess
Protocol(LDAP)providesmanyoftheX.500features,butwithlesscomplexity,andis
widelyused.Inadditiontoseveralopen-sourceimplementations,theMicrosoftActive
Directorysystem,whichisbasedonLDAP,isusedinalargenumberoforganizations.
In the rest of this section, we shall outline the data model and access protocol
detailsofLDAP.
25.5.2.1 LDAPDataModel
InLDAP,directoriesstoreentries,whicharesimilartoobjects.Eachentrymusthavea
distinguishedname(DN),whichuniquelyidentifiestheentry.ADNisinturnmadeup
ofasequenceofrelativedistinguishednames(RDNs).Forexample,anentrymayhave
thefollowingdistinguishedname:
cn=Silberschatz, ou=Computer Science, o=Yale University, c=USA
Asyoucansee,thedistinguishednameinthisexampleisacombinationofanameand
(organizational)address,startingwithaperson’sname,thengivingtheorganizational
unit (ou), the organization (o), and country (c). The order of the components of a
distinguished name reflects the normal postal address order, rather than the reverse

--- Page 1271 ---

1242 Chapter25 AdvancedApplicationDevelopment
order used in specifying path names for files. The set of RDNs for a DN is defined by
theschemaofthedirectorysystem.
Entries can also have attributes. LDAP provides binary, string, and time types,
andadditionallythetypestelfortelephonenumbers,andPostalAddressforaddresses
(lines separated by a “$” character). Unlike those in the relational model, attributes
are multivalued by default, so it is possible to store multiple telephone numbers or
addressesforanentry.
LDAPallowsthedefinitionofobjectclasseswithattributenamesandtypes.Inher-
itancecanbeusedindefiningobjectclasses.Moreover,entriescanbespecifiedtobe
of one or more object classes. It is not necessary that there be a single most-specific
objectclasstowhichanentrybelongs.
Entriesareorganizedintoadirectoryinformationtree(DIT),accordingtotheirdis-
tinguishednames.Entriesattheleaflevelofthetreeusuallyrepresentspecificobjects.
Entries that are internal nodes represent objects such as organizational units, organi-
zations,orcountries.ThechildrenofanodehaveaDNcontainingalltheRDNsofthe
parent, andone ormore additionalRDNs. Forinstance, an internalnode mayhave a
DNc=USA,andallentriesbelowithavethevalueUSAfortheRDNc.
The entire distinguished name need not be stored in an entry. The system can
generate the distinguished name of an entry by traversing up the DIT from the entry,
collectingtheRDN=valuecomponentstocreatethefulldistinguishedname.
Entriesmayhavemorethanonedistinguishedname—forexample,anentryfora
personinmorethanoneorganization.Todealwithsuchcases,theleaflevelofaDIT
canbeanaliasthatpointstoanentryinanotherbranchofthetree.
25.5.2.2 DataManipulation
Unlike SQL, LDAP does not define either a data-definition language or a data-
manipulation language. However, LDAP defines a network protocol for carrying out
data definition and manipulation. Users of LDAP can either use an application-
programminginterfaceorusetoolsprovidedbyvariousvendorstoperformdatadefini-
tionandmanipulation.LDAPalsodefinesafileformatcalledLDAP DataInterchange
Format(LDIF)thatcanbeusedforstoringandexchanginginformation.
ThequeryingmechanisminLDAPisverysimple,consistingofjustselectionsand
projections,withoutanyjoin.Aquerymustspecifythefollowing:
• A base—that is, a node within a DIT—by giving its distinguished name (the path
fromtheroottothenode).
• A search condition, which can be a Boolean combination of conditions on in-
dividual attributes. Equality, matching by wild-card characters, and approximate
equality (the exact definition of approximate equality is system dependent) are
supported.
• Ascope,whichcanbejustthebase,thebaseanditschildren,ortheentiresubtree
beneaththebase.

--- Page 1272 ---

25.6 Summary 1243
• Attributestoreturn.
• Limitsonnumberofresultsandresourceconsumption.
Thequerycanalsospecifywhethertoautomaticallydereferencealiases;ifaliasderef-
erencesareturnedoff,aliasentriescanbereturnedasanswers.
WeomitfurtherdetailsofquerysupportinLDAPbutnotethatLDAPimplemen-
tationssupportanAPIforquerying/updatingLDAPdataandmayadditionallysupport
webservicesforqueryingLDAPdata.
25.5.2.3 DistributedDirectoryTrees
InformationaboutanorganizationmaybesplitintomultipleDITs,eachofwhichstores
informationaboutsomeentries.ThesuffixofaDITisasequenceofRDN=valuepairs
thatidentifywhatinformationtheDITstores;thepairsareconcatenatedtotherestof
thedistinguishednamegeneratedbytraversingfromtheentrytotheroot.Forinstance,
thesuffixofaDITmaybeo=Nokia, c=USA,whileanothermayhavethesuffixo=Nokia,
c=India.TheDITsmaybeorganizationallyandgeographicallyseparated.
AnodeinaDITmaycontainareferraltoanothernodeinanotherDIT;forinstance,
theorganizationalunitBellLabsundero=Nokia,c=USAmayhaveitsownDIT,inwhich
casetheDITforo=Nokia,c=USAwouldhaveanodeou=BellLabsrepresentingareferral
totheDITforBellLabs.
Referrals are the key component thathelporganize adistributed collectionof di-
rectoriesintoanintegratedsystem.WhenaservergetsaqueryonaDIT,itmayreturn
areferraltotheclient,whichthenissuesaqueryonthereferencedDIT.Accesstothe
referencedDITistransparent,proceedingwithouttheuser’sknowledge.Alternatively,
the server itself may issue the query to the referred DIT and return the results along
withlocallycomputedresults.
The hierarchical naming mechanism used by LDAP helps break up control of in-
formationacrosspartsofanorganization.Thereferralfacilitythenhelpsintegrateall
thedirectoriesinanorganizationintoasinglevirtualdirectory.
AlthoughitisnotanLDAPrequirement,organizationsoftenchoosetobreakupin-
formationeitherbygeography(forinstance,anorganizationmaymaintainadirectory
foreachsitewheretheorganizationhasalargepresence)orbyorganizationalstructure
(for instance, each organizational unit, such as department, maintains its own direc-
tory).ManyLDAPimplementationssupportmaster–slaveandmultimasterreplication
ofDITs.
25.6 Summary
• Tuningofthedatabase-systemparameters,aswellasthehigher-leveldatabasede-
sign—suchastheschema,indices,andtransactions—isimportantforgoodperfor-
mance.Tuningisbestdonebyidentifyingbottlenecksandeliminatingthem.

--- Page 1273 ---

1244 Chapter25 AdvancedApplicationDevelopment
• Database tuning can be done at the level of schema and queries, at the level of
databasesystemparameters,andatthelevelofhardware.Databasesystemsusually
haveavarietyoftunableparameters,suchasbuffersizes.
• Therightchoiceofindicesandmaterializedviews,andtheuseofhorizontalpar-
titioningcanprovidesignificantperformancebenefits.Toolsforautomatedtuning
basedonworkloadhistorycanhelpsignificantlyinsuchtuning.Thesetofindices
andmaterializedviewscanbeappropriatelychosentominimizeoverallcost.Ver-
tical partitioning, and columnar storage can lead to significant benefits in online
analyticalprocessingsystems.
• Transactions can be tuned to minimize lock contention; snapshot isolation and
sequence numbering facilities supporting early lock release are useful tools for
reducingread-writeandwrite-writecontention.
• Hardwaretuningincludeschoiceofmemorysize,theuseofSSDsversusmagnetic
harddisks,andincreasingly,thenumberofCPUcores.
• Performancebenchmarksplayanimportantroleincomparisonsofdatabasesys-
tems, especially as systems become more standards compliant. The TPC bench-
marksuitesarewidelyused,andthedifferentTPCbenchmarksareusefulforcom-
paringtheperformanceofdatabasesunderdifferentworkloads.
• Applications need to be tested extensively as they are developed and before they
aredeployed.Testingisusedtocatcherrorsaswellastoensurethatperformance
goalsaremet.
• Legacysystemsaresystemsbasedonolder-generationtechnologiessuchasnonre-
lationaldatabasesorevendirectlyonfilesystems.Interfacinglegacysystemswith
new-generationsystemsisoftenimportantwhentheyrunmission-criticalsystems.
Migratingfromlegacysystems tonew-generationsystems mustbedonecarefully
toavoiddisruptions,whichcanbeveryexpensive.
• Standardsareimportantbecauseofthecomplexityofdatabasesystemsandtheir
needforinteroperation.FormalstandardsexistforSQL.Defactostandards,such
as ODBC and JDBC, and standards adopted by industry groups have played an
importantroleinthegrowthofclient–serverdatabasesystems.
• Distributeddirectorysystemshaveplayedanimportantroleinmanyapplications,
andcanbeviewedasdistributeddatabases.LDAPiswidelyusedforauthentication
andfortrackingemployeeinformationinorganizations.
Review Terms
• Performancetuning • Queueingsystems
• Bottlenecks • Tuningofphysicalschema

--- Page 1274 ---

PracticeExercises 1245
• Tuningofindices • TheTPCbenchmarks
• Materializedviews
° TPC-C
• Immediateviewmaintenance
° TPC-D
• Deferredviewmaintenance
° TPC-E
• Tuningofphysicaldesign
• Workload ° TPC-H
• Tuningofqueries ° TPC-DS
• Setorientation • Regressiontesting
• Batchupdate(JDBC) • Killingmutants
• Bulkload • Applicationmigration
• Bulkupdate • Legacysystems
• Mergestatement • Reverseengineering
• Tuningoflogicalschema • Re-engineering
• Tunableparameters • Standardization
• Tuningofconcurrenttransactions
° Formalstandards
• Sequences
° Defactostandards
• Minibatchtransactions
• Tuningofhardware ° Anticipatorystandards
• Fiveminuterule ° Reactionarystandards
• Performancesimulation • Databaseconnectivitystandards
• Performancebenchmarks • X/OpenXAstandards
• Servicetime • Objectdatabasestandards
• Throughput • XML-basedstandards
• Database-applicationclasses • LDAP
• OLTP • Directoryinformationtree
• Decisionsupport • Distributeddirectorytrees
Practice Exercises
25.1 Findoutallperformanceinformationyourfavoritedatabasesystemprovides.
Look for at least the following: what queries are currently executing or exe-
cuted recently, what resources each of them consumed (CPU and I/O), what
fractionofpagerequestsresultedinbuffermisses(foreachquery,ifavailable),
andwhatlockshaveahighdegreeofcontention.Alsogetinformationabout
CPU,I/Oandnetworkutilization,includingthenumberofopennetworkcon-
nectionsusingyouroperatingsystemutilities.

--- Page 1275 ---

1246 Chapter25 AdvancedApplicationDevelopment
25.2 Manyapplicationsneedtogeneratesequencenumbersforeachtransaction.
a. If a sequence counter is locked in two-phase manner, it can become a
concurrencybottleneck.Explainwhythismaybethecase.
b. Manydatabase systems support built-insequencecountersthatarenot
locked in two-phase manner; when a transaction requests a sequence
number,thecounterislocked,incrementedandunlocked.
i. Explainhowsuchcounterscanimproveconcurrency.
ii. Explain whytheremaybe gaps inthesequence numbersbelonging
tothefinalsetofcommittedtransactions.
25.3 Supposeyouaregivenarelationr(a,b,c).
a. Give an example of a situation under which the performance of equal-
ity selection queries on attribute a can be greatly affected by how r is
clustered.
b. Suppose you also had range selection queries on attribute b. Can you
clusterr insuchawaythattheequalityselectionqueriesonr.aandthe
rangeselectionqueriesonr.bcanbothbeansweredefficiently?Explain
youranswer.
c. Ifclusteringasaboveisnotpossible,suggesthowbothtypesofqueries
canbeexecutedefficientlybychoosingappropriateindices.
25.4 Whenalargenumberofrecordsareinsertedintoarelationinashortperiod
of time, it is often recommended that all indices be dropped, and recreated
aftertheinsertshavebeencompleted.
a. Whatisthemotivationforthisrecommendation?
b. Dropping and recreationof indicescan be avoided by bulk-updating of
theindices.SuggesthowthiscouldbedoneefficientlyforB+-treeindices.
c. Iftheindiceswerewrite-optimizedindicessuchasLSMtrees,wouldthis
advicebemeaningful?
25.5 Suppose that a database application does not appear to have a single bottle-
neck;thatis,CPUanddiskutilizationarebothhigh,andalldatabase queues
areroughlybalanced.Doesthatmeantheapplicationcannotbetunedfurther?
Explainyouranswer.
25.6 Supposeasystemrunsthreetypesoftransactions.TransactionsoftypeArun
attherateof50persecond,transactionsoftypeBrunat100persecond,and
transactionsoftypeCrunat200persecond.Supposethemixoftransactions
has25percentoftypeA,25percentoftypeB,and50percentoftypeC.

--- Page 1276 ---

Exercises 1247
a. What is the average transaction throughput of the system, assuming
thereisnointerferencebetweenthetransactions?
b. Whatfactorsmayresultininterferencebetweenthetransactionsofdif-
ferenttypes,leadingtothecalculatedthroughputbeingincorrect?
25.7 Supposeanapplicationprogrammerwassupposedtowriteaquery
select*
fromr naturalleftouterjoins;
onrelationsr(A,B)ands(B,C),butinsteadwrotethequery
select*
fromr naturaljoins;
a. Givesampledataforrandsonwhichbothquerieswouldgivethesame
result.
b. Givesampledataforr andswherethetwoquerieswouldgivedifferent
results,therebyexposingtheerrorinthequery,
25.8 List some benefits and drawbacks of an anticipatorystandard comparedto a
reactionarystandard.
25.9 DescribehowLDAPcanbeusedtoprovidemultiplehierarchicalviewsofdata,
withoutreplicatingthebase-leveldata.
Exercises
25.10 Databasetunning:
a. Whatarethethreebroadlevelsatwhichadatabasesystemcanbetuned
toimproveperformance?
b. Givetwoexamplesofhowtuningcanbedoneforeachofthelevels.
25.11 Whencarryingoutperformancetuning,shouldyoutrytotuneyourhardware
(byaddingdisksormemory)first,orshouldyoutrytotuneyourtransactions
(byaddingindicesormaterializedviews)first.Explainyouranswer.
25.12 Suppose that your application has transactions that each access and update
asingletuple inaverylargerelationstoredinaB+-treefileorganization.As-
sumethatallinternalnodesoftheB+-treeareinmemory,butonlyaverysmall
fractionoftheleafpagescanfitinmemory.Explainhowtocalculatethemin-
imum number of disks required to support a workload of 1000 transactions

--- Page 1277 ---

1248 Chapter25 AdvancedApplicationDevelopment
persecond.Alsocalculatetherequirednumberofdisks,usingvaluesfordisk
parametersgiveninSection12.3.
25.13 What is the motivation for splitting a long transaction into a series of small
ones?Whatproblemscouldariseasaresult,andhowcantheseproblemsbe
averted?
25.14 Supposethepriceofmemoryfallsbyhalf,andthespeedofdiskaccess(num-
berofaccessespersecond)doubles, whileallotherfactorsremainthesame.
Whatwouldbetheeffectofthischangeonthe5-minuteand1-minuterule?
25.15 ListatleastfourfeaturesoftheTPCbenchmarksthathelpmakethemrealistic
anddependablemeasures.
25.16 Why was the TPC-D benchmark replaced by the TPC-H and TPC-R bench-
marks?
25.17 ExplainwhatapplicationcharacteristicswouldhelpyoudecidewhichofTPC-
C,TPC-H,orTPC-Rbestmodelstheapplication.
25.18 Given that the LDAP functionality can be implemented on top of a database
system,whatistheneedfortheLDAPstandard?
Further Reading
[Harchol-Balte(2013)]providestextbookcoverageofqueuingtheoryfromacomputer
scienceperspective.
InformationabouttuningsupportinIBMDB2,OracleandMicrosoftSQLServer
maybefoundintheirrespectivemanualsonline,aswellasinnumerousbooks.[Shasha
andBonnet(2002)]providesdetailedcoverageofdatabasetuningprinciples.[O’Neil
andO’Neil(2000)] providesaverygoodtextbook coverage ofperformancemeasure-
mentandtuning.The5-minuteand1-minuterulesaredescribedin[GrayandGraefe
(1997)],[Graefe(2008)],and[Appuswamyetal.(2017)].
An early proposal for a database-system benchmark (the Wisconsin benchmark)
was made by [Bitton et al. (1983)]. The TPC-A, TPC-B, and TPC-C benchmarks are
described in [Gray (1991)]. An online version of all the TPC benchmark descrip-
tions, as well as benchmark results, is available on the World Wide Web at the URL
www.tpc.org;thesitealsocontainsup-to-dateinformationaboutnewbenchmarkpro-
posals.
TheXDatasystem(www.cse.iitb.ac.in/infolab/xdata)providestoolsforgenerat-
ingtestdatatocatcherrorsinSQLqueries,aswellasforgradingstudentSQLqueries.
A number of standards documents, including several parts
of the SQL standard, can be found on the ISO/IEC website
(standards.iso.org/ittf/PubliclyAvailableStandards/index.html). Information
about ODBC, OLE-DB, ADO, and ADO.NET can be found on the web site

--- Page 1278 ---

FurtherReading 1249
www.microsoft.com/data. A wealth of information on XML-based standards
andtoolsisavailableonlineonthewebsitewww.w3c.org.
Bibliography
[Appuswamyetal.(2017)] R. Appuswamy, R. Borovica, G. Graefe, and A. Ailamaki, “The
FiveminuteRuleThirtyYearsLateranditsImpactontheStorageHierarchy”,InProceedings
of the 7th International Workshop on Accelerating Analytics and Data Management Systems
UsingModernProcessorandStorageArchitectures(2017).
[Bittonetal.(1983)] D. Bitton, D. J. DeWitt, and C. Turbyfill, “Benchmarking Database
Systems:ASystematicApproach”,InProc.oftheInternationalConf.onVeryLargeDatabases
(1983),pages8–19.
[Graefe(2008)] G.Graefe,“TheFive-MinuteRule20YearsLater:andHowFlashMemory
ChangestheRules”,ACMQueue,Volume6,Number4(2008),pages40–52.
[Gray(1991)] J. Gray, The Benchmark Handbook for Database and Transaction Processing
Systems,2ndedition,MorganKaufmann(1991).
[GrayandGraefe(1997)] J. Gray and G. Graefe, “The Five-Minute Rule Ten Years Later,
and Other Computer Storage Rules of Thumb”, SIGMOD Record, Volume 26, Number 4
(1997),pages63–68.
[Harchol-Balte(2013)] M.Harchol-Balte,PerformanceModelingandDesignofComputerSys-
tems:QueueingTheoryinAction,CambridgeUniversityPress(2013).
[O’NeilandO’Neil(2000)] P.O’NeilandE.O’Neil,Database:Principles,Programming,Per-
formance,2ndedition,MorganKaufmann(2000).
[ShashaandBonnet(2002)] D. Shasha and P. Bonnet, Database Tuning: Principles, Experi-
ments,andTroubleshootingTechniques,MorganKaufmann(2002).
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 1280 ---

26
CHAPTER
Blockchain Databases
Atthemostbasiclevel,ablockchainprovidesanalternativedataformatforstoringa
database,anditsparadigmfortransactionprocessingenablesahighlevelofdecentral-
ization.
Amajorapplicationofblockchaintechnologyisinthecreationofdigitalledgers.
Aledgerinthefinancialworldisabookoffinancialaccounts,thatkeepstrackoftrans-
actions.Forexample,eachtimeyoudepositorwithdrawmoneyfromyouraccount,an
entry is added to a ledger maintained by the bank. Since the ledger is maintained by
thebank,acustomerofthebankimplicitlytruststhebanktonotcheatbyaddingunau-
thorizedtransactionstotheledger,suchasanunauthorizedwithdrawal,ormodifying
theledgerbydeletingtransactionssuchasadeposit.
Blockchain-based distributed ledgers maintain a ledger cooperatively among sev-
eralparties, insuchawaythateachtransactionisdigitallysignedasproofofauthen-
ticity,andfurther,theledgerismaintainedinsuchawaythatonceentriesareadded,
theycannotbedeletedormodifiedbyoneparty,withoutdetectionbyothers.
Blockchains form a key foundation of Bitcoin and other cryptocurrencies. Al-
though much of the technology underlying blockchainswas initiallydeveloped in the
1980s and 1990s, blockchain technology gained widespread popular attention in the
2010sasaresultofboom(andsubsequentbust)inBitcoinandothercryptocurrencies.
However, beyond the many cryptocurrency schemes, blockchains can provide a
secure data-storage and data-processingfoundation forbusiness applications,without
requiring complete trust in any one party. For example, consider a large corporation
and its suppliers, all of whom maintain data about where products and components
are located at any time as part of the manufacturing process. Even if the organiza-
tionsarepresumedtrustworthy,theremayasituationwhereoneofthemhasastrong
incentive to cheat and rewrite the record. A blockchain can help protect from such
fraudulent updates. Ownership documents, such as real-estate deeds, are another ex-
ample of the potential for blockchainuse. Criminalsmay commitreal-estate fraud by
creating fake ownership deeds, which could allow them to sell a property that they
do not own, or could allow the same property to be sold multiple times by an actual
owner.Blockchainscanhelpverifytheauthenticityofdigitallyrepresentedownership
documents; blockchains can also ensure that once an owner has sold a property, the
1251

--- Page 1281 ---

1252 Chapter26 BlockchainDatabases
owner cannot sell it again to another person without getting detected. The security
providedbytheblockchaindatastructuremakesitpossibletoallowthepublictoview
these real-estate records without putting them at risk. We describe otherapplications
forblockchainslaterinthechapter.
Inthischapter,weshalllookatblockchainfromadatabaseperspective.Weshall
identify the ways in which blockchain databases differ from the traditional databases
wehavestudiedelsewhereinthisbookandshowhowthesedistinguishingfeaturesare
implemented.WeshallconsideralternativestoBitcoin-stylealgorithmsandimplemen-
tationthataremoresuitedtoanenterprisedatabaseenvironment.Withthisdatabase-
orientedfocus,weshallnotconsiderthefinancialimplicationsofcryptocurrencies,nor
theissuesofmanagingone’sholdingofsuchcurrenciesviaacryptocurrencywalletor
exchange.
26.1 Overview
Before we study blockchains in detail, we first give an overview of cryptocurrencies,
whichhavedriventhedevelopmentandusage ofblockchains.Wenote,however,that
blockchainshavemanyusesbeyondcryptocurrencies.
Traditionalcurrencies,alsoknownas“fiatcurrencies”aretypicallyissuedbyacen-
tral bank of a country, and guaranteed by the government of that country. Currency
notesareatoneleveljustapieceofpaper;theonlyreasontheyareofvalueisthatthe
government that issues the currency guarantees the value of the currency, and users
trustthegovernment.Today,althoughfinancialholdingscontinuetobedenominated
intermsofacurrency,mostofthefinancialholdingsarenotphysicallypresentascur-
rencynotes;theyaremerelyentriesintheledgerofabankorotherfinancialinstitution.
Usersofthecurrencyareforcedtotrusttheorganizationthatmaintainstheledger.
A cryptocurrency is a currency created purely online, and recorded in a way that
doesnotrequireanyoneorganization(orcountry)tobetotallytrusted.Thistermarises
fromthefactthatanysuchschemehastobasedonencryptiontechnologies.Sinceany
digital information can be copied easily, unlike currency notes, any cryptocurrency
scheme must be able to prevent “double spending” of money. To solve this problem,
cryptocurrencies use ledgers to record transactions. Further, the ledgers are stored a
secure,distributedinfrastructure,withnorequirementtotrustanyoneparty.Thesetwo
keyconcepts,decentralizationandtrustlessness,arefundamentaltocryptocurrencies.
Cryptocurrenies typically aim, like regular currency, and unlike credit card or debit
card transactions, to provide transaction anonymity, to preserve the privacy of users
of the currency. However, since cryptocurrency blockchains are public data analytics
maybeusedtocompromiseorlimitanonymity.
Bitcoin, which was the first successful cryptocurrency, emerged with the publi-
cation of a paper by Satoshi Nakamoto1 in 2008 and the subsequent publication of
the open-source Bitcoin code in 2009. The ideas in the original bitcoin paper solved
1SatoshiNokamotoisapseudonymforapersonorgroupthatanonymouslycreatedBitcoin.

--- Page 1282 ---

26.1 Overview 1253
a number of problems, and therebyallowed cryptocurrencies,whichhad earlierbeen
consideredimpractical,tobecomeareality.
However,theunderlyingconceptsandalgorithmsinmanycasesgobackdecades
intheirdevelopment.ThebrillianceofNakamoto’sworkwasacombinationofinnova-
tionandwell-architecteduseofpriorresearch.ThesuccessesofBitcoinprovethevalue
ofthiscontribution,butthetarget—ananonymous,trustless,fullydistributedconcur-
rency—drove many technical decisions in directionsthat work less well in a database
setting. The Further Readingsection atthe end of the chapterciteskey historical pa-
persinthedevelopmentoftheseideas.
At its most basic level, a blockchain is a linked list of blocks of data that can be
thoughtofasconstitutingalogofupdatestodata.Whatmakesblockchaintechnology
interestingisthatblockchainscan be managed in adistributed mannerinsuch away
thattheyarehighlytamperresistant,andcannotbeeasilymodifiedormanipulatedby
anyoneparticipant,exceptbyappendingdigitallysignedrecordstotheblockchain.
In a business setting, trustless distributed control is valuable, but absolute
anonymityrunscountertobothprinciplesofaccountingandregulatoryrequirements.
This leads to two main scenarios for the use of blockchains. Bitcoin’s blockchain is
referredtoasapublicblockchain,sinceitallowsanysitetojoinandparticipateinthe
tasksofmaintainingtheblockchain.Incontrast,mostenterpriseblockchainsaremore
restricted and referred to as permissioned blockchains. In a permissioned blockchain,
participationisnotopentothepublic.Accessisgrantedbyapermissioningauthority,
whichmaybeanenterprise,aconsortiumofenterprises,oragovernmentagency.
Bitcoinintroducedanumberofideasthatmadepublicblockchainspractical,but
these have a significant cost in terms of CPU power (and thereby, electrical power)
needed to run the blockchain, as well as latencies in processing transactions. By re-
laxingBitcoin’sstrongassumptionsabouttrustlessnessandanonymity,itispossibleto
overcomemanyoftheinefficienciesandhighlatenciesoftheBitcoinmodelanddesign
blockchainsthatfurtherthegoalsofenterprisedatamanagement.
Inthischapter,webegin bylookingatthe classicblockchainstructure asused in
Bitcoin and use that to introduce the key distinguishing properties of a blockchain.
Achievingmanyofthesepropertiesreliesuponone-waycryptographichashfunctions.
ThesehashfunctionsarequitedifferentfromthoseusedinChapter24asameansof
indexing databases. Cryptographic hash functions need to have some specific mathe-
maticalpropertiessuchasthefollowing:givenadatavaluexandahashfunctionh,it
mustberelativelyeasytocomputeh(x)butvirtuallyimpossibletofindxgivenh(x).
When a blockchain is stored distributed across multiple systems, an important
issueistoensurethattheparticipatingsystems agreeon whatarethecontentsofthe
blockchain,andwhatgetsaddedtoitateachstep.Whenparticipantstrusteachother,
butmaybevulnerabletofailure,consensustechniquesthatwestudiedearlierinSection
23.8 can be used to ensure that all participants agree on the contents of a log (and a
blockchainis,atitscore,alog).However,reachingagreementonwhatdatagetadded
toablockchainismuchmorechallengingwhenparticipantsintheblockchaindonot
trust eachotherand have nocentralizedcontrol.The basic consensus algorithmsare

--- Page 1283 ---

1254 Chapter26 BlockchainDatabases
notapplicableinsuchasetting.Forexample,anattackercouldcreatealargenumberof
systems,eachofwhichjoinstheblockchainasaparticipant;theattackercouldthereby
controlamajorityoftheparticipatingsystems. Anydecisionbasedonamajoritycan
then be controlled by the attacker, who can force decisions that can tamper with the
contents of the blockchain. The tamper resistance property of the blockchain would
thenbecompromised.
Webeginbydescribingtheenergy-intensiveapproachofBitcoin,butwethencon-
sideravarietyofalternative,moreefficientapproachesusedinothercryptocurrencies.
Finally,weconsiderapproachesbasedonByzantine-consensusalgorithms,whichare
consensusalgorithmsthatareresistanttosomefractionoftheparticipatingnodesnot
justfailing,butalsolyingandattemptingtodisruptconsensus.Byzantineconsensusis
well-suitedtoanenterpriseblockchainenvironment,andcanbeusediftheblockchain
is permissioned, that is, some organization controls who can have permission to ac-
cess the blockchain. Byzantine consensus is an old problem and solutions have been
aroundformanyyears.However,thespecialconstraintsofblockchaindatabaseshave
led to some newer approaches to this problem. References to more details on Byzan-
tineconsensustechniquesmaybe foundintheFurtherReadingsectionattheendof
thechapter.
Blockchain databases store more than just currency-based debit-credit transac-
tions.Likeanydatabase,theymaystoreavarietyoftypesofdataabouttheenterprise.
A traditionalblockchaindataorganization makes itdifficultto retrievesuch dataeffi-
ciently,butpairingablockchainwithatraditionaldatabaseorbuildingtheblockchain
on topofadatabase canenablefasterqueryprocessing.Weshallexploreavarietyof
means of speeding up not only queries but also update transactions, both within the
blockchainitselfandbyperformingcertainoperations“offchain”andaddingthemin
bulktotheblockchainatalatertime.
Aftercovering blockchainalgorithms,we shall explore (in Section26.8) some of
themostpromisingapplicationsofblockchaindatabases.
26.2 Blockchain Properties
Atitsmostbasiclevel,ablockchainisalinkedlistofblocksofdata.Adistinguishing
feature of the blockchain data structure is that the pointers in the linked list include
notonlytheidentifierofthenextolderblock,butalsoahashofthatolderblock.This
structureisshowninFigure26.1.Theinitialblock,orgenesisblock,isshownasblock
0inthefigure.Itissetupbythecreatoroftheblockchain.Eachtimeablockisadded
tothechain,itincludesthepairofvalues(pointer-to-previous-block,hash-of-previous-
block). As a result, any change made to block is easily detected by comparing a hash
ofthatblocktothehashvaluecontainedinthenextblockinthechain.Thehashvalue
inthenextblockcouldbechanged,butthentheblockafterthatwouldalsohavetobe
changed,andsoon.

--- Page 1284 ---

26.2 BlockchainProperties 1255
h(block 0) . . . h(block n - 1)
data data data
block 0 block 1 block n
genesis block
Figure 26.1 Blockchaindatastructure.
This hash-validated pointer format in a blockchain makes tampering with a
blockchainhard.Tomaketamperingvirtuallyimpossible,itisnecessarytoensurethat
anytamperingwiththeblockchainiseasilydetectedandthatthecorrectversionofthe
blockchain is easily determined. To achieve this, the hash function must have certain
mathematicalpropertiesthatweshalldiscussshortly.Further,thechainitselfmustbe
replicated and distributed among many independent nodes so that no single node or
small group of nodes can tamper with the blockchain. Since the blockchain is repli-
cated across multiple nodes, a distributed consensus algorithm needs to be used to
maintainagreementregardingthecorrectcurrentstateoftheblockchain.Inthisway,
even if some nodes try to tamper with the blockchain contents, as long as a majority
arehonest, makingdecisionsbased on amajorityvote can ensure theintegrityofthe
blockchain.
Theaboveapproachworksifthesetofnodesthatparticipatesintheblockchainis
controlled in some fashion that makes it difficult for an adversary to control a major-
ity of the nodes. However, such control goes against the goal of not have any central
control,andisviewedasunacceptableinpublicblockchainssuchasBitcoin,whichare
based on public blockchainsin whichthe number of participating nodes may change
continuously.Anycomputermaydownloadtheblockchainandattempttoaddblocks
(the code for implementing blockchains is available in open source). As a result, a
majority-basedapproachcanbeoverwhelmedbyanadversarywhosetsupalargenum-
beroflow-costcomputersasnodes.SuchanattackiscalledaSybilattack.
Thewayinwhichconsensusisachievedamongindependentnodesvariesamong
blockchains. The variations address trade-offs between performance (latency and
throughput) and robustness to adversarial attacks on the consensus mechanism, in-
cluding Sybil attacks. When we addressed distributed consensus in Chapter 23, we
assumedthatasingleorganizationcontrolledtheentiredistributedsystem,andsothe
consensusalgorithmhadtotolerateonlypossiblefailuresofnodesorthenetworkthat
werefail-stop,whereparticipantsdonotbehaveinanadversarialmanner.
In a typical blockchain application, the chain is shared among multiple indepen-
dentorganizations.Intheextremecase,forexampleBitcoin,anyonecansetupanode
and participate, possibly for nefarious purposes. Thisimpliesthat the types of failure
thatmayoccurarenotjustcaseswhereadeviceorsystemstopsworking,butalsocases

--- Page 1285 ---

1256 Chapter26 BlockchainDatabases
whereasystemremainsoperationalbutbehavesinanadversarialmanner.Inmosten-
terprisesettings,theblockchainispermissioned,providingsomecontroloverthesetof
participants,butstillwithoutdirectcontrolstopreventmaliciousbehavior.
A node participating in a blockchain fully needs to participate in the consensus
mechanismandmaintainitsownreplicaoftheblockchain.Suchanodeiscalledafull
node. In some applications, there is a need for low-cost nodes that submit updates to
the blockchain, but do not have the storage or computational power to participate in
theconsensusprocess.Suchanodeiscalledalightnode.
WediscussblockchainconsensusalgorithmsindetailinSection26.4.Blockchain
consensusalgorithmscanbeplacedintooneofseveralbroadcategories:
• Proof of work: Proof of work, which is described in detail in Section 26.4.1, pro-
vides a solution to Sybil attacks by making it very expensive for an attacker to
control a majority of the nodes. Specifically, the nodes agree that the next block
ontheblockchainwillbeaddedbythefirstnodetosolveacertainhardmathemat-
ical problem. This is referred to as mining a block. Proof-of-work algorithms are
robusttoadversarialbehavioraslongastheadversarydoesnotcontrolmorethan
half the computing power in the entire network. To ensure this requirement, the
problems are made intentionally hard, and require a lot of computational effort.
Thus, robustness comes at the price of a huge amount of otherwise useless com-
putationalongwiththepriceofelectricityneededtocarryoutthecomputation.
• Proof of stake: Proof of stake, which is described in Section 26.4.2, provides an-
other solution to Sybil attacks. Here, the nodes agree to select the next node to
add a block to the blockchain based on an amount of the blockchain’s currency
ownedorheldinreservebyanode.
• Byzantineconsensus:ByzantineconsensusdoesnotsolvetheproblemofSybilat-
tacks,butcanbeusedinnon-publicblockchains,whereentryofnodestothesys-
tem can be controlled. While some nodes may behave maliciously, it is assumed
that a substantial majority are honest. In Byzantine consensus, described in Sec-
tion26.4.3,thenextnodetoaddablocktotheblockchainisdecidedbyanalgo-
rithmfromtheclassofalgorithmsreferredtoasByzantine-consensusalgorithms.
Like the basic consensus algorithms we described earlier in Section 23.8, these
algorithms achieve agreement by message passing, but unlike those algorithms,
thesealgorithmscantoleratesomenumberofnodesbeingmaliciousbyeitherdis-
rupting consensus or trying to cause an incorrect consensus to be reached. This
approachrequiressignificantlymoremessagestobeexchangedthaninthecaseof
thebasicconsensusalgorithmsofSection26.4.3,butthisisaworthwhiletrade-off
forthe abilityfor asystem towork correctlyinthe presence of a certain number
ofmaliciousnodes.
• Otherapproaches:Thereareseveralotherlesswidelyusedconsensusmechanisms,
someofwhicharevariantsoftheprecedingmechanisms.Theseincludeproofof

--- Page 1286 ---

26.2 BlockchainProperties 1257
activity,proofofburn,proofofcapacity,andproofofelapsedtime.SeetheFurther
Readingsectionattheendofthechapterfordetails.
Another way to damage a blockchain besides attempting to alter blocks is to add
a new block to a block other than the most recent one. This is called a fork. Forking
mayoccurduetomaliciousactivity,buttherearetwosourcesofnonmaliciousforks:
1. Twodistinctnodesmayaddanewblockafterthemostrecentblock,buttheydo
itsoclosetogetherintimethatbothareaddedsuccessfully,thuscreatingaforked
chain. These accidental forks are resolved by a protocol rule that nodes always
attempttoaddblockstotheendofthelongestchain.Thisprobabilisticallylimits
theseaccidentalforkstoashortlength.Theblocksontheshorterforksaresaid
to be orphaned, and the contents of those blocks will get inserted on the real
chainlaterifthosecontentsarenotalreadythere.
2. A majority of blockchain users may agree to fork the blockchain in order to
change some aspect of the blockchain protocol or data structure. This is a rare
eventandonethat,whenithasoccurredinmajorblockchains,hascausedmajor
controversy.Suchaforkissaidtobeasoftforkifpriorblocksarenotinvalidated
by the fork. That is, the old version of the blockchain software will recognize
blocksfromthenewversionasvalid.Thispermitsagradualtransitionfromthe
oldversionoftheblockchainsoftwaretothenewversion.Inahardfork,theold
versionoftheblockchainsoftware willdeemblocksfrom thenewversiontobe
invalid. After a hard fork, if the old version of the blockchain software remains
inuse,itwillleadtoaseparateblockchainwithdifferentcontents.
Because of the possibility of orphaned blocks, itmay be necessary to wait for several
additionalblockstobeaddedbeforeitissafetoassumesblockwillnotbeorphaned.
Note26.1onpage1258presentsafewexamplesofnotableblockchainforks.
So far, we have not said much about the actual data in the blocks. The contents
ofblocksvarybyapplicationdomain.Inacryptocurrencyapplication,themostcom-
mondatafoundinblocksarebasiccurrency-transfertransactions.Sinceanynodecan
add a block, there needs to be a way to ensure that transactions entered are in fact
genuine.Thisisachievedviaatechniquecalledadigitalsignaturethatallowsauserto
“sign”atransaction andallowseverynode toverifythatsignature.Thispreventsfake
transactionsfrombeingaddedtothechainandpreventsparticipantsinthetransaction
fromsubsequentlydenyingtheirinvolvementinthetransaction.Thislatterpropertyis
referredtoasirrefutability.
Transactions are broadcast to all nodes participating in the blockchain; when a
node adds a block to the chain, the block contains all transactions received by the
nodethathavenotalreadybeenaddedtothechain.
Theuserswhosubmittransactionsmaybeknowntotheblockchainadministrator
inapermissionedblockchain,butinapublicblockchainlikeBitcoin,thereisnodirect

--- Page 1287 ---

1258 Chapter26 BlockchainDatabases
Note 26.1 BlockchainForkExamples
Therehavebeenseveralnotableforksofmajorblockchains.Welistafewhere.
• Hard fork: Bitcoin/Bitcoin Cash: Bitcoin’sbuilt-in block-size limitwas an ac-
knowledged problem in the Bitcoin community but agreeing on a solution
proved controversial. A hard fork in August 2017 created a new cryptocur-
rency, Bitcoin Cash, with a larger block-size limit. Holders of Bitcoin at the
time of the fork received an equal amount of Bitcoin Cash, and thus could
spendboth.
• Softfork:BitcoinSegWit:SegWit(shortforsegregatedwitness)movescertain
transaction-signaturedata(referredtoaswitnessdata)outsidetheblock.This
allowsmoretransactionsperblockwhileretainingtheexistingblocksizelimit.
Therelocatedwitnessdataareneededonlyfortransactionvalidation.SegWit
wasintroducedinAugust2017viaasoftfork.Thiswasasoftforkbecausethe
oldblockswererecognizedasvalidandnodesnotyetupgradedwereableto
retainahighdegreeofcompatibility.
• Hard fork: Ethereum/Ethereum Classic: This fork arose from the failure of
a crowd-funded venture-capital operation running as a smart contract in the
Ethereumblockchain.Itscodecontainedadesignflawthatenabledahackin
2016thatstoleethervaluedinthetensofmillionsofU.S.dollars.Acontrover-
sialhardforkrefundedthestolenfunds,butopponentsofthefork,believing
intheinviolabiltyofblockchainimmutability,retainedtheoriginalblockchain
andcreatedEthereumClassic.
connectionbetweenauserIDandanyreal-worldentity.Thisanonymitypropertyisa
keyfeatureofBitcoin,butitsvalueisdiminishedbecauseofthepossibilitytotieauser
IDtosomeoff-chainactivity,therebyde-anonymizingtheuser.De-anonymizationcan
occuriftheuserentersintoatransactionwithauserwhoseuserIDhasalreadybeen
de-anonymized. De-anonymization can occur also via data mining on the blockchain
dataandcorrelatingon-chainactivitybyaspecificuserIDwiththe“real-world”activity
ofaspecificindividual.
Finally, a feature of blockchains is the ability to store executable code, referred
to as a smart contract. A smart contract can implement complex transactions, take
actionatsomepointinthefuturebasedonspecifiedconditions,and,moregenerally,
encode acomplexagreementamonga setof users. Blockchainsdiffernot onlyinthe
language used for smart contracts but also in the power of the language used. Many
areTuringcomplete,butsome(notably,Bitcoin)havemorelimitedpower.Wediscuss
smartcontracts,includinghowandwhentheircodeisexecuted,inSection26.6.

--- Page 1288 ---

26.3 AchievingBlockchainPropertiesviaCryptographicHashFunctions 1259
Wesummarizethisdiscussionbylistingasetofpropertiesofblockchains:2
• Decentralization:Inapublicblockchain,controloftheblockchainisbymajority
consensus with no central controlling authority. In a permissioned blockchain,
thedegreeofcentralcontrolislimited,typicallyonlytoaccessauthorizationand
identitymanagement.Allotheractionshappeninadecentralizedmanner.
• TamperResistance:Withoutgainingcontroloveramajorityoftheblockchainnet-
work,itisinfeasibletochangethecontentsofblocks.
• Irrefutability:Activitybyauseronablockchainissignedcryptographicallybythe
user. These signatures can be validated easily by anyone and thus prove that the
userindeedisresponsibleforthetransaction.
• Anonymity: Users of a blockchain have user IDs that are not tied directly to any
personallyidentifyinginformation,thoughanonymitymaybecompromisedindi-
rectly.Permissionedblockchainsmayofferonlylimitedanonymityornoneatall.
26.3 Achieving Blockchain Properties via Cryptographic Hash
Functions
In this section, we focus on the use of cryptographic hash functions to ensure some
of the properties of blockchains. We begin with a discussion of special types of hash
function for which it is infeasible to compute the inverse function or find hash colli-
sions. We show how these concepts extend to public-key encryption, which we first
saw in Section 9.9. We then show how cryptographic hash functions can be used to
ensure the anonymity, irrefutability, and tamper-resistance properties. We show how
hashfunctionsareusedinminingalgorithmslaterinSection26.4.1.
26.3.1 Properties of Cryptographic Hash Functions
InSection14.5, hashfunctions wereused asameansofaccessingdata. Here,weuse
hashfunctionsforaverydifferentsetofpurposes,andasaresult,weshallneedhash
functionswithadditionalpropertiesbeyondthosediscussedearlier.
A hash function h takes input from some (large) domain of values and generates
as itsoutput a fixed-lengthbitstring. Typically,the cardinalityof the domainis much
larger than the cardinality of the range. Furthermore, the hash function must have a
uniform distribution, that is, each range value must be equally probable given random
input.Ahashfunctionhiscollisionresistantifitisinfeasibletofindtwodistinctvalues
xandysuchthath(x) = h(y).Byinfeasible,wemeanthatthereisstrongmathematical
2Thesepropertiespertaintoblockchains,butnottomostcryptocurrencyexchanges.Mostexchangesholdnotonly
customers’databutalsotheirkeys,whichmeansthatahackagainsttheexchange’sdatabasecanresultintheftof
users’privatekeys.

--- Page 1289 ---

1260 Chapter26 BlockchainDatabases
evidence,ifnotanactualproof,thatthereisnowaytofindtwodistinctvaluesxandy
suchthath(x) = h(y)thatisanybetterthanrandomguessing.
The current standard choice of a cryptographic hash function is called SHA-256,
a function that generates output 256 bits in length. This means that given a value x,
thechancethatarandomlychosenywillhashtothesamevaluetowhichxhashesis
1∕2256.Thismeansthatevenusingthefastestcomputers,theprobabilityofasuccessful
guessiseffectivelyzero.3
The collision-resistance property contributes to the tamper resistance of a
blockchain in a very important way. Suppose an adversary wishes to modify a block
B.Sincethenext-newerblockafterBcontainsnotonlyapointertoBbutalsothehash
of B, any modification to B must be such thatthe hash of B remainsunchanged after
themodificationinordertoavoidhavingtomodifyalsothatnext-newerblock.Finding
suchamodificationisinfeasibleifthehashfunctionhasthecollision-resistanceprop-
erty, and, therefore, any attempt to tamper with a block requires changing all newer
blocksinthechain.
A second important property that werequire of acryptographic hash function is
irreversibility, which means that given only h(x), it is infeasible to find x. The term
irreversiblecomesfromthepropertythat,givenx,itiseasytocomputeh(x),butgiven
onlyh(x),itisinfeasibletofindh−1(h(x)).Thenextsectionshowshowthisconceptis
appliedtoblockchains.4
26.3.2 Public-Key Encryption, Digital Signatures, and Irrefutability
Section 9.9 described two categories of encryption methods: private-key encryption,
where users share a secret key, and public-key encryption, where each user has two
keys, a public key and a private key. The main problem with private-key encryption
is that users must find a way at the outset to share the secret private key. Public-key
encryption allows users who have never met to communicate securely. This property
of public-key encryption is essential to blockchain applications that serve arbitrarily
largecommunitiesofusersworldwide.
EachuserU hasapublickeyE andaprivatekeyD.AmessageencryptedusingE
i i i i
canbedecryptedonlywiththekeyD,and,symmetrically,amessageencryptedusing
i
D canbedecryptedonlywiththekeyE,Ifuseru wishestosendasecuremessagexto
i i 1
U ,U encryptsxusingthepublickeyE ofuserU .OnlyU hasthekeyD todecrypt
2 1 2 2 2 2
the result. For this to work, the specific function used must have the irreversibility
property so that given a public key E itis infeasible to compute the inverse function,
i
32256islargerthan1077.Ifacomputercouldmakeoneguesspercycleitwouldtakemorethan1067secondstohave
a50percentchanceofguessingcorrectly.Thattranslatestomorethan1059years.Toputthatincontext,astronomers
predictthatthesunwillhavegrowninsizetoenvelopEarthwithin1010years.
4Thispropertyhaslongbeenusedforstoringpasswords.Ratherthanstoringuserpasswordsincleartext,leavingthem
susceptibletobeingstolen,hashesarekeptinstead.Then,whenauserlogsinandentersapassword,thehashofthat
passwordiscomputedandcomparedtothestoredvalue.Wereanattackertostealthehashes,thatattackerwouldstill
lacktheactualpasswords,and,ifthehashfunctioninusehastheirreversibilityproperty,thenitisinfeasibleforthe
hackertoreverse-engineertheuserpasswords.

--- Page 1290 ---

26.3 AchievingBlockchainPropertiesviaCryptographicHashFunctions 1261
that is, to find D. This creates a mechanism for users who have never met to share
i
secretmessages.
Suppose now that instead of seeking to send a secret message, user U wishes to
1
“sign”adocumentx.UserU canencryptxusingtheprivatekeyD .Sincethiskeyis
1 1
private,noonebesidesU couldhavecomputedthatvalue,butanyonecanverifythe
1
signature by decrypting using the public key of U , that is, E . This provides a public
1 1
proofthatuserU hassigneddocumentx.
1
In blockchain applications, the concept of a digital signature is used to validate
transactions.Observethatthelinkageofblocksintheblockchain,usingapointerand
the hash of block to which the pointer points, means that a user can sign an entire
chain simply by signing the hash of the newest block in the chain. See the Further
Readingsectionattheendofthechapterforreferencestothemathematicsofpublic-
keyencryption.
26.3.3 Simple Blockchain Transactions
InourdiscussionofdatabasetransactionsinChapter17,wedescribedatransactionas
asequenceofstepsthatreadand/orwritedatavaluesfromthedatabase.Thatconcept
of a transaction is based on a data model where there is a single store of data values
thatareaccessedbytransactions.Ablockchain,initssimplestform,ismorecloselyan
analogofadatabaseloginthatitrecordstheactualtransactionsandnotjustfinaldata
values.Thatanalogybreaksdown,however,inmostblockchains,becausetransactions
areeitherfullyindependentordependexplicitlyoneachother.Themodelwedescribe
herecorrespondstosimpleBitcointransactions.
Asanexample,considertwousers,AandB,andassumeAwishestopayB10units
ofsomecurrency.Ifthiswereatraditionalbankingapplicationwithafiatcurrencysuch
as the U.S. dollar, the transaction implementing this transfer would read A’s account
balance, decrement it by 10, and write that value to the database, and then read B’s
balance, add 10, and write that value to the database. In a blockchain-based system,
thistransactionisspecifiedinadifferentmanner.
Rather than referencing data items, a Bitcoin-style blockchain transaction refer-
encesusersandothertransactions.UsersarereferencedbytheiruserID.UserAwould
locateatransactionorsetoftransactionsfrompasthistoryT ,T ,…,T thatpaidAa
1 2 n
totalofatleast10unitsofthecurrency.AwouldthencreateatransactionT thattakes
theoutput(i.e.,theamountpaidtoA)bythosetransactionsasinput,andasitsoutput
pays 10 units of the currency to B and the remainder back to A as the “change.” The
originaltransactionsT ,T ,…,T arethentreatedashavingbeenspent.
1 2 n
Thus, each transaction indicates how much money has been paid to whom; the
currency balance of a user A is defined by a set of unspent transactions that have
paid money to A. Assuming A is honest, those transactions’ outputs (i.e., the output
ofT ,T ,…,T )wouldnothavebeenspentalreadybyAinaprevioustransaction.If
1 2 n
A were indeed dishonest and T attempted to spend the output of some T a second
1
time,T wouldbeadouble-spendtransaction.Double-spend transactionsandotherin-

--- Page 1291 ---

1262 Chapter26 BlockchainDatabases
valid transactions are detected in the miningprocess that we discuss in Section 26.4,
bykeepingtrackofallunspenttransactionsandverifyingthateachtransactionT that
i
isinputtoT isunspentwhenT isexecuted.AfterT isexecuted,eachsuchT istreated
i
asspent.
Ethereumusesadifferentandmorepowerful model,wheretheblockchainmain-
tains state (including current balance) for each account in the system. Transactions
updatethestate,andcantransferfundsfromoneaccounttoanother.Themodelused
inEthereumisdiscussedinSection26.5.
ABitcoin-styletransactionT specifies:
• TheinputtransactionsT ,T ,…,T .
1 2 n
• Thesetofusersbeingpaidandtheamounttobepaidtoeach,whichinourexample
is10unitstoBandtheremaindertoA.5
• A’ssignatureofthetransaction,toprovethatAinfactauthorizedthistransaction.
• A more complex transaction might include executable code as part of its specifi-
cation,butweshalldeferthattoSection26.6.
• Data to be stored in the blockchain; the data must be under some size, which is
blockchaindependent.
The transaction model described here is quite distinct from that of a traditional
databasesysteminavarietyofways,including:
• Existing data items are not modified.Instead, transactions add new information.
As a result, not only the current state but also the history leading to the current
statearefullyvisible.
• Conflictsintransactionorderingareprevented.Ifconflictsoccur,thetransaction
causingaconflictisdetectedanddeemedinvalidaspartoftheprocessofadding
ablocktothechain,describedinSection26.4.
• Although the blockchain is a distributed system, a transaction is created locally.
It becomes part of the permanent, shared blockchain only through the mining
process.Thisis,ineffect,aformofdeferredtransactioncommit.
• Dependenciesofonetransactionuponanotherarestatedexplicitlyinatransaction
since a transaction lists those transactions whose outputs it uses as input. If we
viewthisintermsoftheprecedencegraphintroducedinChapter17,ourexample
wouldincludeprecedence-graphedgesT → T,T → T,…,T → T.
1 2 n
• Thereisnoexplicitconcurrencycontrol.Muchoftheneedforconcurrencycontrol
iseliminatedbythemaintenanceofacompletehistoryandthedirectsequencing
5Inarealsystem,theremayalsobeapayouttotheminerofthetransaction,thatis,thenodethataddstheblockto
theblockchain,aswediscussinSection26.4.

--- Page 1292 ---

26.4 Consensus 1263
oftransactions.Thus,thereisnocontentionforthecurrentvalueofanydatabase
dataitem.
ThisBitcoin-basedexampleisnottheonlywayblockchainsystemsmanagetransaction
ordering.We shallsee anotherexample when weconsidersmartcontractsinSection
26.6.
The fact that data may be stored in the blockchain makes the blockchain more
thanjustatamper-resistanttransactionlog.Itallowsfortherepresentationofanysort
of information that might be stored in a traditional database. In Section 26.5.2, we
shallseehowthiscapability,particularlyinblockchainswithaconceptofblockchain
state,makestheblockchainatruedatabase.
26.4 Consensus
Becausetheblockchainisreplicatedatallparticipatingnodes,eachtimeanewblock
isadded,allnodesmusteventuallyagreefirstonwhichnodemayproposeanewblock
andthenagreeontheactualblockitself.
In a traditional distributed database system, the consensus process is simplified
by the fact that all participants are part of one controlling organization. Therefore,
the distributed system can implement global concurrency control and enforce two-
phase commit to decide on transaction commit or abort. In a blockchain, there may
be no controlling organization, as is the case for a public blockchain like Bitcoin. In
the case of a permissioned blockchain, there may be a desire to have a high degree
ofdecentralizedcontrolinallmattersexcepttheactualpermissioningofparticipants,
whichismanagedbytheorganizationcontrollingthepermissionedblockchain.
When transactions are created, they are broadcast to the blockchain network.
Nodesmaycollectasetoftransactionstoplaceinanewblocktobeaddedtothechain.
Theconsensusmechanismsusedinblockchainsfallroughlyintotwocategories:
1. Thosewherethenodesreachagreementononenodetoaddthenextblock.These
typicallyuseByzantineconsensus(Section26.4.3).
2. Those wherethe blockchainis allowedtemporarily to fork by allowingmultiple
nodes to create a block following the last block in the chain. In this approach,
nodesattempttoaddblockstothelongestlinearsubchain.Thoseblocksnoton
that longest chain are orphaned and not considered part of the blockchain. To
avoid a massive number of forks being created, this approach limits the rate at
whichblocksmaybeaddedsothattheexpectedlengthoforphanedbranchesis
short. These typically use proof-of-work (Section 26.4.1) or proof-of-stake (Sec-
tion26.4.2).
Anodethataddsablocktothechainmustfirstcheckthatblockoftransactions.This
entailscheckingthat:

--- Page 1293 ---

1264 Chapter26 BlockchainDatabases
• Eachtransactioniswell-formed.
• Thetransactionisnotdouble-spendingbyusingasinput(i.e.,spending)currency
unitsthathavebeenusedalreadybyapriortransaction.Todoso,eachnodemust
trackthesetofallunspentcurrencyunits(transactions), andlookupthissetfor
each transaction T to ensure that all the currency units that are inputs to T are
unspent.
• Thetransactioniscorrectlysignedbythesubmittinguser.
When a node is selected to add a block to the chain, that block is propagated to all
nodes, and each checks the block for validity before adding it to its local copy of the
chain.
We next need to consider the question of why any node would want to use its
resources for mining, that is to carry out the work needed to append blocks to the
chain. Mining is a service to the blockchain network as a whole, and so miners are
paid (in the currency of the blockchain) for their efforts. There are two sources of
paymenttominers:
1. Afeepaidbythesysteminnewcoinsinthecurrencyoftheblockchain.
2. Afeeincludedbythesubmitterofthetransaction.Inthiscasetheoutputofthe
transaction includes an additional output representing a payment to the miner
oftheblockcontainingthetransaction.Usersareincentedtoincludefeessince
suchfeesincentminerstoincludetheirtransactionspreferentiallyinnewblocks.
Theexactmeansofpayingminersvariesamongblockchains.
Inthissection,welookatvariouswaystoachieveconsensus.Webeginbyassuming
apublicblockchainanddescribeconsensusbasedontwoapproaches:proof-of-workand
proof-of-stake. We then consider permissioned blockchainsthat in many cases choose
touseaconsensusmechanismbasedonByzantineconsensus.
26.4.1 Proof of Work
Proof-of-workconsensusisdesignedforpublicblockchainsinwhichthenumberofpar-
ticipatingnodesischangingcontinuously.Anycomputermaydownloadtheblockchain
andattempttoaddblocks.Asaresult,amajority-basedapproachcanbeoverwhelmed
byanadversarywhosetsupalarge numberoflow-costcomputersasnodes.Asmen-
tionedearlier,suchanattackiscalledaSybilattack.Instead,proof-of-workrequiresa
node to solve a computationally hard, but not infeasible, mathematical problem. An
attackercannotoverwhelmablockchainnetworksimplybyaddinginexpensivenodes.
Rather, the attacker would need to have access to computation capacity that forms a
majorityofthenetwork’stotalcomputationcapacity,ataskthatismuchmoredifficult
andcostlythanlaunchingaSybilattack.

--- Page 1294 ---

26.4 Consensus 1265
Thecomputationallyhardproblemisbasedontheconceptofcryptographichash-
ing.AnodethatwishestomineablockBasthenextblockneedstofindavalue,called
anonce,that,whenconcatenatedtoBandthehashofthepreviousblock,hashestoa
valuelessthanapresettargetvaluespecifiedfortheblockchain.Thenonceistypicallya
32-bitvalue.Ifthetargetissetverylow,sayto4,andassumingtheusual256-bithash,a
minerwouldhaveonlya1∕2254chanceofsucceedingforasinglechoiceforthenonce.
Ifthetargetweresetveryhigh,sayto2255,theminerwouldhavea50percentchance
ofsuccess.Blockchainimplementationsaredesignedtovarythetargetsoastocontrol
therateofminingofblocksacrossthewholesystem.Thisvariabilityallowsthesystem
toadjustascomputationpowerincreaseswhetherduetohardwareadvancesordueto
additional nodes joining the network. The target times vary for differentblockchains.
Bitcoin targets having some node in the system successfully mine a block every 10
minutes. Ethereum targeted a mining time of 10 to 15 seconds with its proof-of-work
mechanism. As of late 2018, Ethereum is moving to a proof-of-stake mechanism and
is expected to target a slightly faster rate. While faster may appear to be better, note
that if mining occurs at a faster rate than the time it takes to propagate a new block
throughoutthenetwork,theprobabilityofforksandorphanedblocksincreases.
Nowthatwehaveseenhowproof-of-workminingworks,letusrecalltheproperties
westated aboutcryptographichashfunctions.Iftherewereanefficientalgorithmfor
findinganoncethatresultsinahashlessthanthetarget,minersmightfindnoncestoo
quickly.Therefore,thehashfunctionmustensurethatthereisnobetterwaytofinda
noncethansimplytryingeachpossiblenoncevalueinturn.Thisleadsustorequireone
additionalpropertyforcryptographichashfunctions,thepuzzle-friendlinessproperty.
Thisproperty requiresthatgiven avalue k,for any n-bitvalue y itisinfeasible tofind
a value x such that h(x‖k) = y in time significantly less that 2n, where ‖ denotes
concatenationofbitstrings.
Proof-of-work mining is controversial. On the positive side, for a large network,
it would be highly costly for an adversary to obtain enough computational power to
dominatemining.However,onthenegativeside,theamountofenergyusedinmining
ishuge.EstimatesasthischapterisbeingwrittensuggestthatBitcoinminingworldwide
consumesabout1percentofthepowerconsumedbytheUnitedStates,ormorethan
the entire consumption of several nations, for example Ireland. The large amount of
computationneededhascreatedincentivestodesignspecial-purposecomputingchips
for mining and incentives to locate large mining installations near sources of cheap
powersources.
These concerns are causing a movement to alternatives, such as proof-of-stake,
which we discuss next. These concerns have led also to interest in alternative forms
of proof-of-work that, for example, require having a large amount of main memory in
order quickly to find a nonce. Memory-intensive schemes retain the cost barrier of
proof-of-workwhilereducingtheenergywaste.Theyareasubjectofcurrentresearch.
Furthermore, we shall see that for enterprise permissioned-blockchain applications,
muchlesscostlymeansofconsensusarepossible.

--- Page 1295 ---

1266 Chapter26 BlockchainDatabases
Inpractice,agroupofusersmayunitetoformaminingpool,whichisaconsortium
thatworkstogethertomineblocksandthensharestheproceedsamongitsmembers.
26.4.2 Proof of Stake
Theconceptofproof-of-stakeistoallownodesholdingalargestakeinthecurrencyof
the blockchain to be chosen preferentiallyto add blocks. This rule cannot be applied
absolutely, since then a single largest stakeholder would control the chain. Instead,
the probability of mining success, using proof-of-work, is made higher for nodes in
proportion to their stake. By adjusting both the stake requirements and the mining
difficulty,itremainspossibletocontroltherateatwhichblocksaremined.
Thereareawidevarietyofproof-of-stakeschemes.Theymayincludemeasurement
notonlyofoverallstake,butalsothetotaltimeastakehasbeenheld.Theymayrequire
that the stake or some fraction of it be held inactive for some period of time in the
future.
Properly tuning a proof-of-stake mechanism is difficult. Not only are there more
parameterstoconsiderthaninproof-of-work,butalsoonemustguardagainstasitua-
tionwherethereistoolittlecostpenaltyforanadversarytoaddblockstoaforkother
thanthelongestone.
26.4.3 Byzantine Consensus
An important alternative to work- or stake-based consensus is message-based consen-
sus. Message-based consensus is widely used in distributed database systems. As we
notedearlier,thebasicconsensusprotocolsdonotworkforblockchainconsensusbe-
causeitcannotbeassumedthattherearenomaliciousnodes.
Message-basedsystemsaimtoachieveconsensusviaamajorityvote.Suchsystems
are vulnerable to a Sybil attack. In an enterprise permissioned blockchain, in which
usershavetobegrantedpermissiontoparticipate,Sybilattacksarenotpossiblesince
thepermissioningauthoritycaneasilydenypermissionwhenamalicioususerattempts
toaddanexcessivenumberofnodes.However,eveninthissetting,onecannotassume
everyuseristotallyhonest.
Forexample,considerasupply-chainblockchaininwhichallsuppliersenterdata
on the chain pertaining to each item being supplied either to another supplier or the
ultimate manufacturer of an end-user product. Some supplier might choose to falsify
data for its own advantage, but, when a fraud investigation begins, that supplier may
thenseektoforktheblockchaintocover-upitsfraud.Thus,evenabsentthepossibility
of Sybil attacks, there remains the possibility of adversarial behavior. It is difficult to
anticipateeverypossibleformofadversarialbehavior.
For this reason, we model this situation using the concept of Byzantine failure in
whichitisassumedthata“failed”nodecanbehaveinanarbitrarymanner,andthenet-
workofnon-failednodesmustberobusttoallsuchmisbehavior,includingmisbehavior
thattakes exactlytheneededsetofsteps tosabotage thenetwork.Theassumption of

--- Page 1296 ---

26.5 DataManagementinaBlockchain 1267
Byzantinefailureisquitedifferentfromtheassumptionmadebyconsensusprotocols,
where the only type of failure considered is the absence of function, that is, the only
wayanodeornetworklinkfailstostopworkingandthusdonothing.Thisisreferred
toasafail-stopmodelandprecludesanymaliciousbehavior.
InSection23.8,wediscusseddistributedconsensusprotocols,notablyPaxosand
Raft. These protocols depend on the fail-stop assumption, but allow agreement using
majorityrule(in contrast, 2PCrequiresunanimityofagreement).ForByzantine con-
sensus, we must seek a form of majority rule that overcomes not only the failure of a
minorityofnodes,butalsothepossiblemaliciousbehaviorofthatminority.Forexam-
ple, a maliciousnode n may tell node n that it desiresto commita transaction, but
1 2
telln thatitdesirestoabortthetransaction.Asonemightexpect,achievingconsensus
3
in the face of such maliciousnodes requiresa highercost in the number of messages
sent to achieve agreement, but in a blockchain, that higher cost is acceptable since it
canbemuchlowerthanthecostofproof-of-workorproof-of-stakemining.
ThedevelopmentofByzantineconsensusalgorithmsbeganintheearly1980s;see
the Further Reading section at the end of the chapter for references. There has been
muchtheoreticalworkrelatingthenumberofroundsofmessaging,thetotalnumberof
messagessent,andthefractionofthenodesthatcanbemaliciouswithoutcausingthe
protocoltofail.Earlyworkmadeassumptionsaboutnetworkbehavior,suchasthetime
ittakestodeliveramessageorthatthenetworkbehavesinahighlysynchronousman-
ner.ModernByzantineconsensusalgorithmsarebasedonreal-worldassumptionsand
incorporatecryptographicsignaturestoguardagainstforgedmessages.Thedegreeof
synchronizationisreduced,buttrulyasychronousfault-tolerantconsensusisprovably
impossible. One widelyused approach, called Practical Byzantine Fault Tolerance, tol-
eratesmaliciousfailureofupto⌊n−1⌋nodesandisviewedasprovidinganacceptable
3
levelofperformance.OtherprotocolsarereferencedintheFurtherReadingsectionat
theendofthechapter.
26.5 Data Management in a Blockchain
Untilnowwehavenotbeenconcernedabouttheefficiencyoflookingupinformation
inablockchain.Whileindividualuserscantracktheirunspenttransactions,thatisnot
sufficienttovalidateablock.Eachnodeneedstobeabletocheckeachtransactionin
ablocktoseeifitwasalreadyspent.Inprinciple,thatcouldbedonebysearchingthe
entireblockchain,butthatisfartoocostlysinceitcouldinvolvesearchingbackwards
totheveryfirstblockinthechain.Inthissection,weshallconsiderdatastructuresto
makesuchlookupsefficient.
Furthermore, not every blockchain uses a transaction model in which transac-
tion inputs are restricted to be the directoutput of other transactions. Some, notably
Ethereum, allow for the maintenance of a state for each user (account, in Ethereum
parlance)thatholdstheaccountbalance(intheEthereumcurrency,Ether)andsome

--- Page 1297 ---

1268 Chapter26 BlockchainDatabases
associatedstorage.Thistransactionanddatamodelcomesclosertothatofadatabase
system.Simplystoringthisinformationinadatabase,however,wouldnotpreservethe
blockchainpropertieswelistedinSection26.2.Inthissection,weconsiderthisricher
model and how it can be represented physically either via specialized data structures
orwiththehelpofdatabasesystemconcepts.
26.5.1 Efficient Lookup in a Blockchain
As we noted earlier, in order to validate a Bitcoin-style transaction, a node needs to
checkthreeitems:
1. The transaction is syntacticallywell formed (proper data format, sum of inputs
equalssumofoutputs,andsoon).Thisisrelativelystraightforward.
2. The transaction is signed by the user submitting it. This is a matter of ensuring
thatthesignature,whichshouldhavebeenproducedbytheusersubmittingthe
transactionusingherorhisprivatekey,canbedecryptedwiththatuser’spublic
keytoobtainthetransactionitself.Thisisnotahighlycostlystep.
3. The transaction’s inputs have not been spent already. This entails looking up
eachindividualinputtransactionintheblockchain.Thesetransactionscouldbe
anywhere in the blockchain since they can be arbitrarily old. Without a good
meansofperformingthislookup,thisstepwouldbeprohibitivelycostly.
Totest foraninputtransaction havingbeen usedalready,itisnecessarytobeable to
checkthat transaction didnot appear earlierasinput to anothertransaction. Thus, it
sufficesforeachnodetomaintainanindexonallunspenttransactions.Entriesinthis
indexpointtothelocationofthecorrespondingtransactionintheblockchain,allowing
thedetailsoftheinputtransactiontobevalidated.
Bitcoin, like many other blockchains, facilitates lookup and validation by storing
transactionswithinablockinaMerkletree,whichwediscussedinSection23.6.6.In
thatsection,wenotedthataMerkletreeenablestheefficientverificationofacollection
(transactions,inthecaseofablockchain)thatmayhavebeencorruptedbyamalicious
user.Inablockchain,thereareoptimizationstotheMerkletreepossible,suchastrun-
catingthetreetoremovesubtreesconsistingsolelyofspenttransactions.Thisreduces
significantly the space requirements for nodes to store the full blockchain. Space is a
majorconsiderationsincemajorblockchainsgrowfasterthatonegigabytepermonth,
aratelikelytoincreaseasblockchainapplicationsgrow.
TheMerkle-treestructure isparticularlyuseful forlightnodes(i.e.,nodesthatdo
not store the entire blockchain) since they need to retain only the root hash of the
tree for verification. A full node can then provide any needed data to the light node
by providing those data plus the hashes needed for the light node to verify that the
provideddataareconsistentwithitsstoredhashvalue(seeSection23.6.6).

--- Page 1298 ---

26.6 SmartContracts 1269
26.5.2 Maintaining Blockchain State
ThesimpleblockchaintransactionmodelofSection26.3.3showedhowabasicBitcoin
transaction works. There are more complex transactions possible in Bitcoin,but they
followthesamepatternofasetofinputtransactionsandasetofpaymentstousers.
In this section, we look at the model used by certain other blockchains, notably
Ethereum, that maintain a state that holds the balance in each account. Transactions
move currency units (ether in Ethereum) among accounts. Since transactions are se-
rializedintoblocksbyminers,thereisnoneedforconcurrency-controlprotocolslike
thoseofChapter18.Eachblockcontainsasequenceoftransactionsbutalsocontains
thestateasitexistedafterexecutionoftransactionsintheblock.Itwouldbewasteful
to replicatethe entire state in each blocksince the modest number of transactions in
oneblockarelikelytochangearelativelysmallfractionoftheoverallstate.Thiscreates
aneedforadatastructureallowingbetteruseofstorage.
RecallthattransactionswithinablockarestoredinaMerkletree.Stateisstored
similarly.Thiswouldappeartoofferthepossibilityofsavingspacebyallowingpointers
(plus the associated hash) back to earlier blocks for those parts of the state that are
unchanged.Theonlychallengehereisthatitmustbepossiblenotonlytochangetree
nodes,butalsotoinsertanddeletethem.AvariantoftheMerkle-treedatastructure,
called a Merkle-Patricia tree, is used for this purpose in some blockchains, including
Ethereum.Thisdatastructureallowsforefficientkey-basedsearchinthetree.Instead
of actually deleting and inserting tree nodes, a new tree root is created and the tree
itselfstructuredsoastoreference(andthusreuse)subtreesofpriortrees.Thoseprior
trees are immutable, so rather than making new parent pointer (which we can’t do),
a leaf-to-root path is generated by reversing a root-to-leaf path that is easily obtained
intheMerkle-Patriciatreestructure.Detailsofthisdatastructurecanbefoundinthe
referencesintheFurtherReadingsectionattheendofthechapter.
Corda,HyperledgerFabric,andBigchainDBareexamplesofblockchainsthatuse
adatabase to store state and allow queryingof thatstate. Fabric and BigchainDBuse
NoSQLdatabases.Cordausesanembedded-SQLdatabase.Incontrast,Ethereumstate
isstoredinakey-valuestore.
26.6 Smart Contracts
Sofar,wehavefocusedonsimplefunds-transfertransactions.Actualblockchaintrans-
actionscanbemorecomplexbecausetheymayincludeexecutablecode.Blockchains
differ not only in the supported language(s) for such code, but also, and more im-
portantly, in the power of those languages. Some blockchains offer Turing-complete
languages, that is, languages that can express all possible computations. Others offer
morelimitedlanguages.
26.6.1 Languages and Transactions
Bitcoin uses a language of limited power that is suitable for defining many standard
types of conditional funds-transfer transactions. Key to this capability is its multisig

--- Page 1299 ---

1270 Chapter26 BlockchainDatabases
instruction,whichrequiresmofnspecifieduserstoapprovethetransfer.Thisenables
escrowtransactionsinwhichatrustedthirdpartyresolvesanydisputebetweenthetwo
partiestotheactualtransfer.Italsoenablesgroupingseveraltransactionsbetweentwo
usersintoonelargertransactionwithouthavingtosubmiteachcomponenttransaction
separatelytotheblockchain.Becauseaddingtransactionstotheblockchainhasatime
delay and a cost in transaction fees, this feature is quite important. This concept has
beenextendedinoff-chainprocessingsystems,whichwediscussinSection26.7.
Ethereum as well as most blockchainstargeting enterprise applications include a
language that is Turing complete. Many use familiar programming languages or vari-
antsbasedheavilyonsuchlanguages.Thiswouldseemlikeanobviousadvantageover
less-powerful languages, but it comes at some risk. Whereas it is impossible to write
an infinite loop in Bitcoin’s language, it is possible to do so in any Turing-complete
language. A malicious user could submit a transaction that encodes an infinite loop,
thereby consuming an arbitrarily large amount of resources for any node attempting
to include that transaction in a newly mined block. Testing code for termination, the
haltingproblem,isaprovablyunsolvableprobleminthegeneralcase.Evenifthema-
licioususeravoidsaninfiniteloop,thatusercouldsubmitcodethatrunsforanexcep-
tionally long time, again consuming miner resources. The solution to this problem is
thatuserssubmittingatransactionagreetopaytheminerforcodeexecution,withan
upperboundplacedonthepayment.Thislimitstheamountoftotalexecutiontosome
boundedamountoftime.
Thedecentralizednatureofablockchainleadstoanincentivesystemforusersto
convinceminerstoincludetheirtransaction and thusexecute theircode.Ethereum’s
solution is based on the concept of gas, so named as to provide an analogy to auto-
mobilefuel.Eachinstruction consumesafixedamountofgas.Gasconsumption ina
transactionisgovernedbythreeparameters:
1. Gasprice:theamountofethertheuserisofferingtopaytheminerforoneunit
ofgas.
2. Transaction gas limit: the upper bound on transaction gas consumption. Trans-
actionsthatexceedtheirgaslimitareaborted.Theminerkeepsthepayment,but
thetransactionactionsarenevercommittedtotheblockchain.
3. Blockgaslimit:alimitintheblockchainsystem itselfonthesumoveralltrans-
actionsinablockoftheirtransactiongaslimits.
A user who sets a gas price too low may face a long wait to find a miner willing to
includethetransaction.Settingthegaspricetoohighresultsintheuseroverpaying.
Another hard choice is that of the gas limit. It is hard to set the limit to the pre-
cise amount of gas that the contract will use. A user who sets the limit too low risks
transactionfailure,whileauserwho,fearing“runningoutofgas,”setsthetransaction
gaslimitexcessivelyhighmayfindthatminersareunwillingtoincludethetransaction
becauseitconsumestoolargeafractionoftheblockgaslimit.Theresultofthisisan

--- Page 1300 ---

26.6 SmartContracts 1271
interestingproblemfortransactiondesignersinoptimizingforbothcostandspeedof
mining.
In a Bitcoin-style transaction, transaction ordering is explicit. In a state-based
blockchainlikeEthereum,thereisnoexplicitconceptofinputtransactions.However,
theremaybeimportantreasonswhyasmartcontractmaywishtoenforceatransaction
order. For transactions coming from the same account, Ethereum forces those trans-
actions to be mined in the order in which the account created them by means of an
accountnonceassociatedwiththetransaction.Anaccountnonceismerelyasequence
numberassociatedwitheachtransactionfromanaccount,andthesetoftransactions
fromanaccountmusthaveconsecutivesequencenumbers.Twotransactionsfroman
account cannot have the same sequence number, and a transaction is accepted only
afterthetransactionwiththeprevioussequencenumberhasbeenaccepted,thuspre-
ventinganycheatingintransactionordering.Ifthetransactionstobeorderedarefrom
different accounts, they need to be designed such that the second transaction in the
orderingwouldfailtovalidateuntilafterthefirsttransactionisprocessed.
The fact that miners must run the smart-contract code of transactions they wish
to include in a block, and that all full nodes must run the code of all transactions in
mined blocks, regardless of which node mined the block, leads to a concern about
security. Code is run in a safe manner, usually on a virtual machine designed in the
style of the Java virtual machine. Ethereum has its own virtual machine, called the
EVM.HyperledgerexecutescodeinDockercontainers.
26.6.2 External Input
A smart contract may be defined in terms of external events. As a simple example,
consideracrop-insurancesmartcontractforafarmerthatpaysthefarmeranamount
ofmoneydependentontheamountofrainfallinthegrowingseason.Sincetheamount
of rainfall in any future season is not known when the smart contract is written, that
valuecannotbehard-coded.Instead,inputmustbetakenfromanexternalsourcethat
is trusted by all parties to the smart contract. Such an external source is called an
oracle.6
Oraclesareessentialtosmartcontractsinmanybusinessapplications.Thefactthat
theoraclemustbetrustedisacompromiseonthegeneraltrustlessnessofablockchain
environment. However, this is not a serious compromise in the sense that only the
parties to a contract need to agree on any oracles used and, once that agreement is
made, the agreement is coded into the smart contract and is immutable from that
pointforward.
Corruptionofanoracleafteritiscodedintoanoperatingsmartcontractisareal
problem. This issue could be left as an externality for the legal system but ideally, a
processforsettlementoffuturedisputeswouldbecodedintothecontractinavariety
of ways. For example, parties to the contract could be required to send the contract
6ThistermisrootedinancientGreekcultureandbearsnorelationshiptothecompanybythesamename.

--- Page 1301 ---

1272 Chapter26 BlockchainDatabases
certification messages periodically, and code could be written defining actions to be
takenincaseapartyfailstorecertifyitsapprovaloftheoracle.
Direct external output from a smart contract is problematic since such output
wouldhavetooccurduringitsexecutionandthusbeforethecorrespondingtransaction
isaddedtotheblockchain.Ethereum,forexample,dealswiththisbyallowingasmart
contract to emit events that are then logged in the blockchain. The public visibilityof
theblockchainthenallowstheactionsofthesmartcontracttotriggeractivityexternal
totheblockchain.
26.6.3 Autonomous Smart Contracts
Inmanyblockchains,includingEthereum,smartcontractscanbedeployedasindepen-
dententities.Suchsmartcontractshavetheirownaccount,balance,andstorage.This
allows users (or other smart contracts) to use services provided by a smart contract
andtosendorreceivecurrencyfromasmartcontract.
Dependingonhowaspecificsmartcontractiscoded,ausermaybeable,bydesign,
tocontrolthesmartcontractbysendingitmessages(transactions).Asmartcontract
may be coded so that it operates indefinitely and autonomously. Such a contract is
referredtoasadistributedautonomousorganization(DAO).7 DAOs,onceestablished,
aredifficulttocontrolandmanage.Thereisnowaytoinstallbugfixes.Inaddition,there
aremanyunansweredquestionsaboutlegalandregulatorymatters.However,theability
tocreatetheseentitiesthatcommunicate,storedata,anddobusinessindependentof
anyuserisoneofthemostpowerfulfeaturesoftheblockchainconcept.Inanenterprise
setting, smart contracts operate under some form of control by an organization or a
consortium.
A smart contract may be used to create a currency on top of another currency.
Ethereumoftenservesasthebaseblockchainasthisallowstherichexistingecosystem
for Ethereum to be leveraged to provide underlying infrastructure. Such higher-level
currencyunitsarecalledtokens,andtheprocessofcreatingsuchcurrenciesisreferred
to as an initial coin offering (ICO). An important added benefit of using an existing
blockchainasthebasisforatokenisthatitisthenpossibletoreusekeyelementsofthe
userinfrastructure,mostimportantlythewalletsoftwareusersneedtostoretokens.The
ERC-20Ethereumstandardfortokensiswidelyused.Morerecentstandards,including
ERC-223, ERC-621, ERC-721, ERC-777, and ERC-827, are discussed in the references in
theFurtherReadingsectionattheendofthechapter.
TherelativeeaseofcreatinganICOhasmadeitanimportantmethodoffunding
new ventures, but this has also led to several scams, resulting in attempts by govern-
mentstoregulatethisfundraisingmethodology.
Beyondfundraising,animportantapplicationofsmartcontractsistocreateinde-
pendent,autonomousserviceproviderswhoseoperation iscontrollednotbyhumans
7ThegeneraluseofDAOisdistinctfromaspecificdistributedautonomousorganizationcalled“TheDAO”.TheDAO
wasacrowdfundedventure-capitaloperationthatfailedduetoabugthatenabledamajortheftoffunds(seeNote26.1
onpage1258).

--- Page 1302 ---

26.6 SmartContracts 1273
butbysourcecode,oftenopen-source.Inthisway,trustlessservicesthatdonotrequire
their users to trust any person or organization can be created. As we noted earlier, a
fullyautonomouscontractcannotbestoppedormodified.Thus,bugslastforever,and
thecontractcan continueaslongasitcanraise enough currencytosupport itsoper-
ation (i.e., for Ethereum, earn enough ether to pay for gas). These risks suggest that
some compromise on the concept of trustlessness may make sense in smart-contract
design,suchasgivingthecontractcreatortheabilitytosendaself-destructmessageto
thecontract.
26.6.4 Cross-Chain Transactions
Up to this point, we have assumed implicitly that a blockchain transaction is limited
toonespecificblockchain.Ifonewishedtotransfercurrencyfromanaccountonone
blockchain to another account that is on a different blockchain, not only is there the
issue that the currencies are not the same, but also there is the problem that the two
blockchainshave toagreeon thestate ofthiscross-chaintransaction ateachpointin
time.
Wehaveseenarelatedproblemfordistributeddatabases.Ifasingleorganization
controlstheentiredistributedsystem,thentwo-phasecommitcanbeused.However,if
thesystemiscontrolledbymultipleorganizationsasinthefederatedsystemsdiscussed
inSection23.5.3,coordinationismoredifficult.Intheblockchainsetting,thehighlevel
of autonomy of each system and the requirement of immutability set an even higher
barrier.
The simplest solution is to use a trusted intermediary organization that operates
muchlikeonethatexchangestraditionalfiatcurrencies.
If both users have accounts on both blockchains, a trustless transaction can be
definedbycreatingtransactionsoneachchainfortherequiredfundstransferthatare
designedsuchthatifonetransactionisaddedtoitsblockchainitssmart-contractcode
reveals a secret that ensures that other transactions cannot be canceled. Techniques
usedincludethefollowing,amongothers:
• Time-lock transactions that reverse after a certain period of time unless specific
eventsoccur.
• Cross-chainexchangeofMerkle-treeheadersforvalidationpurposes.
Ariskinthesetechniquesisthepossibilitythatasuccessfullyminedtransactionwinds
uponanorphanedfork,thoughtherearewaystomitigatetheserisks.Thedetailsare
systemspecific.SeetheFurtherReadingsectionattheendofthechapter.
Amoregeneralsolutionistocreateasmartcontractthatimplementsamarketsim-
ilarconceptuallytoastockexchangeinwhichwillingbuyersandsellersarematched.
Such a contractoperates in the role of trusted intermediaryratherthan ahuman-run
bank or brokerage as would be used for fiat currencies. The technical issues in cross-
chaintransactionsremainanareaofactiveresearch.

--- Page 1303 ---

1274 Chapter26 BlockchainDatabases
26.7 Performance Enhancement
Atahighlevel,ablockchainsystemmaybeviewedashavingthreemajorcomponents:
1. Consensus management: Proof-of-work, proof-of-stake, Byzantine consensus, or
somehybridapproach.Transactionprocessingperformanceisdominatedbythe
performanceofconsensusmanagement.
2. State-access management: Access methods to retrieve current blockchain state,
rangingfromasimpleindextolocatetransactionsfromaspecificaccount-idor
userID,tokey-valuestoresystems,toafullSQLinterface.
3. Smart contract execution: The environment that runs the (possibly compiled)
smart-contractcode,typicallyinavirtualizedenvironmentforsecurityandsafety.
Therateoftransactionprocessing,referredtoasthroughput,inblockchainsystems
issignificantlylowerthanintraditionaldatabasesystems.Traditionaldatabasesystems
areabletoprocesssimplefunds-transfertransactionsatpeakratesontheorderoftens
of thousands of transactions per second. Blockchain systems’ rates are less; Bitcoin
processes less than 10 per second, and Ethereum, at present, only slightly more than
10persecond.8 Thereasonisthattechniquessuchasproof-of-worklimitthenumber
of blocks that can be added to the chain per unit time, with Bitcoin targeting one
blockevery10minutes.Ablockmaycontainmultipletransactions,sothetransaction
processingrateissignificantlymorethan1in10minutes,butisneverthelesslimited.
Inmostapplications,transactionthroughputisnottheonlyperformancemetric.A
secondandoftenmoreimportantmetricistransactionlatency,orresponsetime.Here,
thedistributedconsensusrequiredbyblockchainsystemspresentsaseriousproblem.
As an example, we consider Bitcoin’s design in which the mining rate is maintained
close to 1 block every 10 minutes. That alone creates significant latency, but added
to that is the need to wait for several subsequent blocks to be mined so as to reduce
theprobabilitythataforkwillcausethetransaction’sblocktobeorphaned.Usingthe
usual recommendation of waiting for 6 blocks, we get a true latency of 1 hour. Such
response times are unacceptable for interactive, real-time transaction processing. In
contrast, traditional database systems commit individual transactions and can easily
achievemillisecondresponsetime.
These transaction processing performance issues are primarilyissues due to con-
sensus overhead with public blockchains. Permissioned blockchains are able to use
faster message-based Byzantine consensus algorithms, but other performance issues
stillremain,andarecontinuingtobeaddressed.
8Atthetimeofpublication,Ethereum’sarchitectsarecontemplatingadvocatingaforktoallowfaster,lower-overhead
mining.

--- Page 1304 ---

26.7 PerformanceEnhancement 1275
26.7.1 Enhancing Consensus Performance
Therearetwoprimaryapproachestoimprovetheperformanceofblockchainconsen-
sus:
1. Sharding: distributingthetaskofminingnewblockstoenableparallelismamong
nodes.
2. Off-chaintransactionprocessing:Trustedsystemsthatprocesstransactionsinter-
nally without putting them on the blockchain. These transactions are grouped
into a single transaction that is then placed on the blockchain. This grouping
may occur with some agreed-upon periodicity or occur only at the termination
oftheagreement.
Sharding is the partitioning of the accounts in a blockchain into shards that are
mined separately in parallel. In the case where a transaction spans shards, a separate
transactionisrunoneachshardwithaspecialsystem-internalcross-shardtransaction
recorded to ensure that both parts of the given transaction are committed. The over-
headofthecross-shardtransactionislow.Therearesomerisksresultingfromthefact
that splitting the mining nodes up by shard results in smaller sets of miners that are
then morevulnerable toattacksincethe cost toattackasmallersetof minersisless.
However,therearewaystomitigatethisrisk.
Off-chain transactions require deployment of a separate system to manage those
transactions. The best known of these is the Lightning network, which not only
speeds blockchain transactions via off-chain processing but also can process certain
cross-chain transactions. Lightning promises transaction throughput and latency at
traditional database-system rates, but provides this at the cost of some degree of
anonymityandimmutability(i.e.,transactionsthatcommitoff-chain,butarerejected
at the blockchain). By increasing the frequency of transaction confirmations to the
blockchain, one can decrease the loss of immutability at the price of reduced perfor-
manceimprovement.
26.7.2 Enhancing Query Performance
Someblockchainsystemsofferlittlemorethananindexonuseroraccountidentifiers
to facilitate looking up unspent transactions. This suffices for a simple funds-transfer
transaction.Complex smartcontracts,however,mayneedtoexecute general-purpose
queries against the stored current state of the blockchain. Such queries may perform
the equivalent of join queries, whose optimization we studied at length in Chapter
16. However, the structure of blockchain systems, in which state-access management
may be separate from the execution engine may limit the use of database-style query
optimization. Furthermore, the data structures used for state representation, such as
the Merkle-Patricia tree structure we saw in Section 26.5.2, may limit the choice of
algorithmstoimplementjoin-stylequeries.

--- Page 1305 ---

1276 Chapter26 BlockchainDatabases
BlockchainsystemsbuiltonatraditionaloraNoSQLdatabasekeepstateinforma-
tion within that database and allow smart contracts to run higher-level database-style
queriesagainstthatstate.Thoseadvantagescomeatthecostofusingadatabase-storage
format that may lack the rigorous cryptographic protection of a true blockchain. A
good compromise is for the database to be hosted by a trusted provider with updates
goingnotonlytothedatabasebutalsototheblockchain,thusenablinganyuserwho
sowishestovalidatethedatabaseagainstthesecureblockchain.
26.7.3 Fault-Tolerance and Scalability
Performance in the presence of failures is a critical aspect of a blockchain system.
In traditional database systems, this is measured by the performance of the recovery
managerand,aswesawinSection19.9,theARIESrecoveryalgorithmisdesignedto
optimizerecoverytime.Ablockchainsystem,incontrast,usesaconsensusmechanism
andareplicationstrategydesignedforcontinuousoperationduringfailuresandmali-
ciousattacks,thoughperhapswithlowerperformanceduringsuchperiods.Therefore,
besides measuring throughput and latency, one must also measure how these perfor-
mancestatisticschangeintimesoffailureorattack.
ScalabilityisaperformanceconcerninanydistributedsystemaswesawinChap-
ter 20. The architectural differences between blockchain systems and parallel or dis-
tributeddatabasesystemsintroducechallengesinboththemeasureofscaleupandits
optimization.Weillustratethedifferencesbyconsideringtherelativescalabilityof2PC
andByzantineconsensus.In2PC,atransactionaccessingafixednumberofnodes,say
five, needs onlythe agreementof these five nodes, regardless of the number of nodes
inthesystem.Ifwescalethesystemuptomorenodes,thattransactionstillneedsonly
thosefivenodestoagree(unlessthescalingaddedareplicasite).UnderByzantinecon-
sensus, every transaction needs the agreement of a majority of the non-failed nodes,
andso,thenumberofnodesthatmustagreenotonlystartsmuchlargerbutalsogrows
fasterasthenetworkscales.
TheFurtherReadingsectionattheendofthechapterprovidesreferencesthatdeal
withtheemergingissueofblockchainperformancemeasurementandoptimization.
26.8 Emerging Applications
Having seen how blockchains work and the benefits they offer, we can look at areas
whereblockchaintechnologyiscurrentlyinuseormaybeusedinthenearfuture.
Applications most likely to benefit from the use of a blockchain are those that
havehigh-valuedata,includingpossiblyhistoricaldata,thatneedtobekeptsafefrom
maliciousmodification.Updateswouldconsistmostlyofappendsinsuchapplications.
Anotherclassofapplicationsthatarelikelytobenefitareathosethatinvolvemultiple
cooperating parties, who trust each other to some extent, but not fully, and desire to
have a shared record of transactions that are digitally signed, and are kept safe from
tampering.Inthislattercase,thecooperatingpartiescouldincludethegeneralpublic.

--- Page 1306 ---

26.8 EmergingApplications 1277
Below,weprovidealistofseveralapplicationdomainsalongwithashortexplana-
tionofthevalueprovidedbyablockchainimplementationoftheapplication.Insome
cases,thevalueaddedbyablockchainisanovelcapability;inothers,thevalueadded
istheabilitytodosomethingthatcouldhavebeendonepreviouslyonlyatprohibitive
cost.
• Academiccertificatesandtranscripts:Universitiescanputstudentcertificatesand
transcriptsonapublicblockchainsecuredbythestudent’spublickeyandsigned
digitallyby the university. Onlythe student can readthe records,but the student
can then authorize access to those records. As a result, students can obtain cer-
tificates and transcripts for future study or for prospective employers in a secure
mannerfromapublicsource.ThisapproachwasprototypedbyMITin2017.
• Accounting and audit: Double-entry bookkeeping is a fundamental principle of
accountingthathelpsensureaccurateandauditablerecords.Asimilarbenefitcan
begainedfromcryptographicallysignedblockchainentriesinadigitaldistributed
ledger.Inparticular,theuseofablockchainensuresthattheledgeristamperproof,
even against insider attacks and hackers who may gain control of the database.
Also, if the enterprise’s auditor is a participant, then ledger entries can become
visibleimmediatelytoauditors,enablingacontinuousratherthanperiodicaudit.
• Assetmanagement:Trackingownershiprecordsonablockchainenablesverifiable
accesstoownershiprecordsandsecure,signedupdates.Asanexample,real-estate
ownership records, a matter of public record, could be made accessible to the
public on a blockchain, while updates to those records could be made only by
transactions signed by the parties to the transaction. A similar approach can be
applied to ownership of financial assets such as stocks and bonds. While stock
exchanges manage trading of stocks and bonds, long term records are kept by
depositoriesthatusersmust trust. Blockchaincanhelptracksuch assetswithout
havingtotrustadepository.
• E-government: A single government blockchain would eliminate agency dupli-
cation of records and create a common, authoritative information source. A
highlynotableuserofthisapproachisthegovernmentofEstonia, whichusesits
blockchainfortaxation,voting,health,andaninnovative“e-Residency”program.
• Foreign-currency exchange: International financial transactions are often slow
and costly. Use of an intermediary cryptocurrency can enable blockchain-based
foreign-currency exchange at a relative rapid pace with full, irrefutable traceabil-
ity.RippleisofferingsuchcapabilityusingtheXRPcurrency.
• Health care: Health records are notorious for their nonavailability across health-
care providers, their inconsistency, and their inaccuracy even with the increased
use of electronic health records. Data are added from a large number of sources
andtheprovenanceofmaterialsusedmaynotbewelldocumented(seediscussion
of supply chains below). A unified blockchain is suitable for distributed update,

--- Page 1307 ---

1278 Chapter26 BlockchainDatabases
andcryptographicdataprotection,unlockablebythepatient’sprivatekey,would
enableaccesstoapatient’sfullhealthrecordanytime,anywhereinanemergency.
The actual records may be kept offchain, but the blockchain acts as the trusted
mechanismforaccessingthedata.
• Insuranceclaims:Theprocessingofinsuranceclaimsisacomplexworkflowofdata
from the scene of the claim, various contractors involved in repairs, statements
from witnesses, etc. A blockchain’s ability to capture data from many sources
and distribute it rapidly, accurately, and securely, promises efficiency and accu-
racygainsintheinsuranceindustry.
• Internet of things: The Internet of Things (IoT) is a term that refers to systems
of many interacting devices (“things”), including within smart buildings, smart
cities, self-monitoring civil infrastructure, and so on. These devices could act as
nodes that can pass blockchain transactions into the network without having to
ensurethetransmissionofdatareachesacentralserver.Inthelate2010s,research
is underway to see if this data-collection approach can be effective in lowering
costs and increasing performance. Adding so many entries to a blockchain in a
short period of time may suggest a replacement of the chain data structure with
a directed,acyclic graph. The Iota blockchainis an example of one such system,
wherethegraphstructureiscalledatangle.
• Loyalty programs and aggregation of transactions: There are a variety of situa-
tions where a customer or user makes multiple purchases from the same vendor,
such as withina theme park, inside a videogame, orfrom a large online retailer.
These vendors could create internal cryptocurrencies in a proprietary, permis-
sioned blockchain, with currency value pegged to a fiat currency like the dollar.
Thevendorgainsbyreplacingcredit-cardtransactionswithvendor-internaltrans-
actions. This saves credit-card fees and allows the vendor to capture more of the
valuable customer data coming from these transactions. The same concept can
applytoretailloyaltypoints,exemplifiedbyairlinefrequent-flyermiles.Itiscostly
forvendorstomaintainthesesystemsandcoordinatewithpartnervendorsinthe
program. A blockchain-based system allows the hosting vendor to distribute the
workloadamongthepartnersandallowstransactionstobepostedinadecentral-
ized manner, releaving the vendor from have to run its own online transaction
processingsystem.Inthelate2010s,businessstrategieswerebeingtestedaround
theseconcepts.
• Supplychain:Blockchainenableseveryparticipantinasupplychaintologevery
action. This facilitates tracking the movement of every item in the chain rather
than only aggregates like crates, shipments, etc. In the event of a recall, the set
of affected products can be pinpointed to a smaller set of products and done so
quickly. When a quality issue suggests a recall, some supply-chain members may
betemptedtocoveruptheirrole,buttheimmutabilityoftheblockchainprevents
recordfalsificationafterthefact.

--- Page 1308 ---

26.9 Summary 1279
• Tickets for events: Suppose a person A has bought tickets for an event, but now
wishes to sell them, and B buys the ticket from A. Given that tickets are all sold
online,B would need to trust thatthe ticketgiven by A isgenuine, andA has not
alreadysoldtheticket,thatis,thetickethasnotbeendouble-spent.Iftickettrans-
actions are carried out on a blockchain, double-spending can be detected easily.
Ticketscanbeverifiediftheyaresigneddigitallybytheeventorganizer(whether
ornottheyareonablockchain).
• Tradefinance:Companiesoften depend onloansfrom banks, issued through let-
tersofcredits,tofinancepurchases.Suchlettersofcreditareissuedagainstgoods
based on bills of lading indicating that the goods are ready for shipment. The
ownershipofthegoods(title)isthentransferredtothebuyer.Thesetransactions
involve multiple parties including the seller, buyer, the buyer’s bank, the seller’s
bank,ashippingcompanyandsoforth,whichtrusteachothertosomeextent,but
not fully. Traditionally, these processes were based on physical documents that
havetobesignedandshippedbetweenpartiesthatmaybeanywhereontheglobe,
resulting in significant delays in these processes. Blockchain technology can be
usedtokeepthesedocumentsinadigitalform,andautomatetheseprocessesina
waythatishighlysecureyetveryfast(atleastcomparedtoprocessingofphysical
documents).
Otherapplicationsbeyondthosewehavelistedcontinuetoemerge.
26.9 Summary
• Blockchains provide a degree of privacy, anonymity, and decentralization that is
hardtoachievewithatraditionaldatabase.
• Public blockchains are accessibly openly on the internet. Permissioned
blockchains are managed by an organization and usually serve a specific enter-
priseorgroupofenterprises.
• The main consensus mechanisms for public blockchains are proof-of-work and
proof-of-stake.Minerscompetetoaddthenextblocktotheblockchaininexchange
forarewardofblockchaincurrency.
• Many permissioned blockchains use a Byzantine consensus algorithm to choose
thenodetoaddthenextblocktothechain.
• Nodes adding a block to the chain first validate the block. Then all full nodes
maintainingareplicaofthechainvalidatethenewblock.
• Keyblockchainpropertiesincludeirrefutabilityandtamperresistance.
• Cryptographichashfunctionsmustexhibitcollisionresistance,irreversibility,and
puzzlefriendliness.

--- Page 1309 ---

1280 Chapter26 BlockchainDatabases
• Public-key encryption is based on a user having both a public and private key to
enableboththeencryptionofdataandthedigitalsignatureofdocuments.
• Proof-of-workrequiresalargeamountofcomputationtoguessasuccessfulnonce
that allows the hash target to be met. Proof-of-stake is based on ownership of
blockchaincurrency.Hybridschemesarepossible.
• Smart contracts are executable pieces of code in a blockchain. In some chains,
theymayoperateasindependententitieswiththeirowndataandaccount.Smart
contractsmayencodecomplexbusinessagreementsandtheymayprovideongoing
servicestonodesparticipatingintheblockchain.
• Smartcontractsgetinputfromtheoutsideworldviatrusted oraclesthatserveas
areal-timedatasource.
• Blockchains that retain state can serve in a manner similar to a database system
andmaybenefitfromtheuseofdatabaseindexingmethodsandaccessoptimiza-
tion,buttheblockchainstructuremayplacelimitsonthis.
Review Terms
• Publicandpermissionedblockchain • Doublespend
• Cryptographichash • Orphanedblock
• Mining • Nonce
• Lightandfullnodes • Blockvalidation
• Proof-of-work • Merkletree
• Proof-of-stake • Patriciatree
• Byzantineconsensus • Bitcoin
• Tamperresistance • Ethereum
• Collisionresistance • Gas
• Irreversibility • Smartcontract
• Public-keyencryption • Oracles
• Digitalsignature • Cross-chaintransaction
• Irrefutability • Sharding
• Forks:hardandsoft • Off-chainprocessing
Practice Exercises
26.1 What isablockchainfork? List the twotypesof forkand explain theirdiffer-
ences.

--- Page 1310 ---

Exercises 1281
26.2 Considerahashfunctionh(x) = xmod2256,thatis,thehashfunctionreturns
thelast256bitsofx.
Doesthisfunctionhave
a. collisionresistance
b. irreversibility
c. puzzlefriendliness
Whyorwhynot?
26.3 If you were designing a new public blockchain, why might you choose proof-
of-stakeratherthanproof-of-work?
26.4 If you were designing a new public blockchain, why might you choose proof-
of-workratherthanproof-of-stake?
26.5 Explain the distinction between a public and a permissioned blockchain and
wheneachwouldbemoredesirable.
26.6 Data stored in a blockchain are protected by the tamper-resistance property
ofablockchain.Inwhatwayisthistamperresistancemoresecureinpractice
thanthesecurityprovidedbyatraditionalenterprisedatabasesystem?
26.7 Inapublicblockchain,howmightsomeonedeterminethereal-worldidentity
thatcorrespondstoagivenuserID?
26.8 WhatisthepurposeofgasinEthereum?
26.9 Supposeweareinanenvironmentwhereuserscanbeassumednottobema-
licious. In that case, what advantages, if any, does Byzantine consensus have
over2PC?
26.10 Explainthebenefitsandpotentialrisksofsharding.
26.11 Whydoenterpriseblockchainsoftenincorporatedatabase-styleaccess?
Exercises
26.12 Inwhatorderareblockchaintransactionsserialized?
26.13 Sinceblockchainsareimmutable,howisatransactionabortimplementedso
asnottoviolateimmutability?
26.14 Since pointers in a blockchain include a cryptographic hash of the previous
block, why is there the additional need for replication of the blockchain to
ensureimmutability?
26.15 Supposeauserforgetsorlosesherorhisprivatekey?Howistheuseraffected?

--- Page 1311 ---

1282 Chapter26 BlockchainDatabases
26.16 Howisthedifficultyofproof-of-workminingadjustedasmorenodesjointhe
network, thus increasing the total computational power of the network? De-
scribetheprocessindetail.
26.17 Why is Byzantine consensus a poor consensus mechanism in a public
blockchain?
26.18 Explain how off-chaintransaction processingcan enhancethroughput. What
arethetrade-offsforthisbenefit?
26.19 Choose anenterpriseofpersonalinteresttoyouandexplainhowblockchain
technologycouldbeemployedusefullyinthatbusiness.
Tools
One can download blockchain software to create a full node for public blockchains
suchasBitcoin(bitcoin.org) andEthereum(www.ethereum.org)andbegin mining,
though the economic return for the investment of power may be questionable. Tools
exist also to join mining pools. Browsing tools exist to view the contents of public
blockchains.Forsomeblockchains,notablyEthereum,itispossibletoinstallaprivate
copyoftheblockchainsoftwaremanagingaprivateblockchainasaneducationaltool.
Ethereum also offers a public test network where smart contracts can be debugged
withouttheexpenseofgasontherealnetwork.
Hyperledger (www.hyperledger.org) which is supported by a large consortium
of companies, provides a wide variety of open source blockchain platforms and
tools. Corda (www.corda.net) and BigchainDB (www.bigchaindb.com) are two
other blockchain platforms, with BigchainDB having a specific focus on blockchain
databases.
Blockchain based systems for supporting academic certificates and medical
records, such as Blockcert and Medrec (both from MIT), and several other applica-
tionsare available online.The setof toolsforblockchainare evolvingrapidly.Due to
the rapid rate of change and development, as of late 2018 we are unable to identify a
bestsetoftools,beyondthefewmentionedabove,thatwecanrecommend.Werecom-
mendyouperformawebsearchforthelatesttools.
Further Reading
The newness of blockchain technology and applications means that, unlike the more
established technical topics elsewhere in this text, there are fewer references in the
academic literature and fewer textbooks. Many of the key papers are published only
on the website of a particular blockchain. The URLs for those references are likely
to change often. Thus, web searches for key topics are a highly important source for
furtherreading.Here,wecitesomeclassicreferencesaswellasURLscurrentasofthe
publicationdate.

--- Page 1312 ---

FurtherReading 1283
The original Bitcoin paper [Nakamoto (2008)] is authored under a pseudonym,
withtheidentityoftheauthororauthorsstillthesubjectofspeculation.Theoriginal
Ethereum paper [Buterin (2013)] has been superseded by newer Ethereum white pa-
pers(seeethereum.org),buttheoriginalworkbyEthereum’screator,VitalikButerin,
remainsinterestingreading.Solidity,theprimaryprogramminglanguageforEthereum
smart contracts, is discussed in solidity.readthedocs.io. The ERC-20 standard is de-
scribed in [Vogelsteller and Buterin (2013)] and the proposed (as of the publication
date ofthistext) Casper upgrade tothe performanceofEthereum’sconsensusmech-
anism appears in [Buterin and Griffith (2017)]. Another approach to using proof-of-
stakeisusedbytheCardanoblockchain(www.cardano.org).
Manyofthetheoreticalresultsthatmakeblockchainpossiblewerefirstdeveloped
inthe20thcentury.Theconceptsbehindcryptographichashfunctionsandpublic-key
encryptionwereintroducedin[DiffieandHellman(1976)]and[Rivestetal.(1978)].
A good reference for cryptography is [Katz and Lindell (2014)]. [Narayanan et al.
(2016)]isagoodreferenceforthebasicsofcryptocurrency,thoughitsfocusismainly
on Bitcoin. There is a large body of literature on Byzantine consensus. Early papers
thatlaidthefoundationforthisworkinclude[Peaseetal.(1980)]and[Lamportetal.
(1982)].PracticalByzantinefaulttolerance([CastroandLiskov(1999)])servesasthe
basis for much of the current blockchain Byzantine consensus algorithms. [Mazi`eres
(2016)]describesindetailaconsensusprotocolspecificallydesignedtoallowforopen,
ratherthanpermissioned,membershipintheconsensusgroup.Referencespertaining
to Merkle trees appears in Chapter 23. Patricia trees were introduced in [Morrison
(1968)].
Abenchmarkingframeworkforpermissionedblockchainsappearsin[Dinhetal.
(2017)].Adetailedcomparisonofblockchainsystemsappearsin[Dinhetal.(2018)].
ForkBase, a storage system designed for improved blockchain performance, is dis-
cussedin[Wangetal.(2018)].
TheLightningnetwork(lightning.network)aimstoaccelerateBitcointransactions
and provide some degree of cross-chain transactions. Ripple (ripple.com) provides
a network for international fiat currency exchange using the XRP token. Loopring
(loopring.org) is a cryptocurrency exchange platform that allows users to retain con-
troloftheircurrencywithouthavingtosurrendercontroltotheexchange.
Many of the blockchains discussed in the chapter have their best descriptions
on their respective web sites. These include Corda (docs.corda.net), Iota (iota.org),
andHyperledger(www.hyperledger.org).Manyfinancialfirmsarecreatingtheirown
blockchains,andsomeofthosearepubliclyavailable,includingJ.P.Morgan’sQuorum
(www.jpmorgan.com/global/Quorum).
Bibliography
[Buterin(2013)] V. Buterin, “Ethereum: The Ultimate Smart Contract and Decentralized
ApplicationPlatform”,Technicalreport(2013).

--- Page 1313 ---

1284 Chapter26 BlockchainDatabases
[ButerinandGriffith(2017)] V.ButerinandV.Griffith,“CaspertheFriendlyFinalityGad-
get”,Technicalreport(2017).
[CastroandLiskov(1999)] M.CastroandB.Liskov,“PracticalByzantineFaultTolerance”,
InSymp.onOperatingSystemsDesignandImplementation(OSDI),USENIX(1999).
[DiffieandHellman(1976)] W. Diffie and M. E. Hellman, “New Directions in Cryptogra-
phy”,IEEETransactionsonInformationTheory,Volume22,Number6(1976).
[Dinhetal.(2017)] T. T. A. Dinh, J. Wang, G. Chen, R. Liu, B. C. Ooi, and K.-L. Tan,
“BLOCKBENCH: A Framework for Analyzing Private Blockchains”, In Proc. of the ACM
SIGMODConf.onManagementofData(2017),pages1085–1100.
[Dinhetal.(2018)] T.T.A.Dinh,R.Liu,M.H.Zhang,G.Chen,B.C.Ooi,andJ.Wang,
“UntanglingBlockchain:ADataProcessingViewofBlockchainSystems”,volume30(2018),
pages1366–1385.
[KatzandLindell(2014)] J. Katz and Y. Lindell, Introduction to Modern Cryptography, 3rd
edition,ChapmanandHall/CRC(2014).
[Lamportetal.(1982)] L. Lamport, R. Shostak, and M. Pease, “The Byzantine Generals
Problem”,ACMTransactionsonProgrammingLanguagesandSystems,Volume4,Number3
(1982),pages382–401.
[Mazi`eres(2016)] D.Mazi`eres,“TheStellarConsensusProtocol”,Technicalreport(2016).
[Morrison(1968)] D.Morrison,“PracticalAlgorithmToRetrieveInformationCodedinAl-
phanumeric”,JournaloftheACM,Volume15,Number4(1968),pages514–534.
[Nakamoto(2008)] S. Nakamoto,“Bitcoin: APeer-to-PeerElectronic CashSystem”,Tech-
nicalreport,Bitcoin.org(2008).
[Narayananetal.(2016)] A.Narayanan,J.Bonneau,E.Felten,A.Miller,andS.Goldfeder,
BitcoinandCryptocurrencyTechnologies,PrincetonUniversityPress(2016).
[Peaseetal.(1980)] M. Pease, R. Shostak, and L. Lamport, “Reaching Agreement in the
PresenceofFaults”,JournaloftheACM,Volume27,Number2(1980),pages228–234.
[Rivestetal.(1978)] R. L. Rivest, A. Shamir, and L. Adleman, “A Method for Obtaining
DigitalSignaturesandPublic-KeyCryptosystems”,CommunicationsoftheACM,Volume21,
Number2(1978),pages120–126.
[VogelstellerandButerin(2013)] F.VogelstellerandV.Buterin,“ERC-20TokenStandard”,
Technicalreport(2013).
[Wangetal.(2018)] S. Wang, T. T. A. Dihn, Q. Lin, Z. Xie, M. Zhang, Q. Cai, G. Chen,
B.C.Ooi,andP.Ruan,“ForkBase:AnEfficientStorageEngineforBlockchainandForkable
Applications”,InProc.oftheInternationalConf.onVeryLargeDatabases(2018),pages1085–
1100.
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.

--- Page 1314 ---

10
PART
APPENDIX A
AppendixApresentsthefulldetailsoftheuniversitydatabasethatwehaveusedasour
runningexample, includinganE-Rdiagram,SQLDDL,andsampledatathatwehave
used throughout the book. (The DDL and sample data are also available on the web
siteofthebook,db-book.com,foruseinlaboratoryexercises.)
1285

--- Page 1316 ---

A
APPENDIX
Detailed University Schema
Inthisappendix,wepresentthefulldetailsofourrunning-exampleuniversitydatabase.
InSectionA.1wepresentthefullschemaasusedinthetextandtheE-Rdiagramthat
correspondstothatschema.InSectionA.2wepresentarelativelycompleteSQLdata
definition for our running university example. Besides listing a datatype for each at-
tribute, we include a substantial number of constraints. Finally, in Section A.3, we
presentsampledatathatcorrespondtoourschema.SQLscriptstocreatealltherela-
tionsintheschema,andtopopulate themwithsampledata,areavailableontheweb
siteofthebook,db-book.com.
A.1 Full Schema
The full schema of the university database that is used in the text follows. The corre-
sponding schema diagram, and the one used throughout the text, is shown in Figure
A.1.
classroom(building,room number,capacity)
department(dept name,building,budget)
course(course id,title,dept name,credits)
instructor(ID,name,dept name,salary)
section(course id,sec id,semester,year,building,room number,time slot id)
teaches(ID,course id,sec id,semester,year)
student(ID,name,dept name,tot cred)
takes(ID,course id,sec id,semester,year,grade)
advisor(s ID,i ID)
time slot(time slot id,day,start time,end time)
prereq(course id,prereq id)
1287

--- Page 1317 ---

1288 AppendixA DetailedUniversitySchema
student
takes
ID ID
course_id name
sec_id dept_name
semester tot_cred
year
grade
section course
course_id course_id department advisor
s s y e e e c m a _ r e id ster time_slot t d c i r e t e l p e d t_ it n s ame d bu ep il t d _ i n n a g me s i_ _ i i d d
building budget
room_number time_slot_id
time_slot_id day
start_time
end_time
prereq instructor
classroom
course_id ID
building prereq_id name
room_number dept_name
capacity teaches salary
ID
course_id
sec_id
semester
year
Figure A.1 Schemadiagramfortheuniversitydatabase.
A.2 DDL
In this section, we present a relatively complete SQL data definition for our example.
Besides listing a datatype for each attribute, we include a substantial number of con-
straints.
createtableclassroom
(building varchar(15),
room number varchar(7),
capacity numeric(4,0),
primarykey(building,room number));
createtabledepartment
(dept name varchar(20),
building varchar(15),
budget numeric(12,2)check(budget>0),
primarykey(dept name));

--- Page 1318 ---

A.2 DDL 1289
createtablecourse
(course id varchar(7),
title varchar(50),
deptname varchar(20),
credits numeric(2,0)check(credits>0),
primarykey(course id),
foreignkey(dept name)referencesdepartment
ondeletesetnull);
createtableinstructor
(ID varchar(5),
name varchar(20)notnull,
deptname varchar(20),
salary numeric(8,2)check(salary>29000),
primarykey(ID),
foreignkey(dept name)referencesdepartment
ondeletesetnull);
createtablesection
(course id varchar(8),
sec id varchar(8),
semester varchar(6)check(semester in
(’Fall’,’Winter’,’Spring’,’Summer’)),
year numeric(4,0)check(year >1701andyear <2100),
building varchar(15),
room number varchar(7),
time slot id varchar(4),
primarykey(course id,sec id,semester,year),
foreignkey(course id)referencescourse
ondeletecascade,
foreignkey(building,room number)referencesclassroom
ondeletesetnull);
IntheprecedingDDL,weaddtheondelete cascadespecificationtoaforeignkey
constraintiftheexistence ofthetuple dependson thereferencedtuple.Forexample,
we add the on delete cascade specification to the foreign key constraint from section
(whichwasgeneratedfromweakentitysection),tocourse(whichwasitsidentifyingre-
lationship).Inotherforeignkeyconstraintsweeitherspecifyondeletesetnull,which
allowsdeletionofareferencedtuple bysettingthereferencingvalue tonull,orwedo
notaddanyspecification,whichpreventsthedeletionofanyreferencedtuple.Forex-
ample, ifa department isdeleted,we would notwish to delete associated instructors;

--- Page 1319 ---

1290 AppendixA DetailedUniversitySchema
the foreign key constraint from instructor to department instead sets the dept nameat-
tribute to null. On the other hand, the foreign key constraint for the prereq relation,
shown later,preventsthedeletionofacourse thatisrequiredasaprerequisiteforan-
othercourse.Fortheadvisor relation,shownlater,weallowi IDtobesettonullifan
instructorisdeletedbutdeleteanadvisor tupleifthereferencedstudentisdeleted.
createtableteaches
(ID varchar(5),
course id varchar(8),
sec id varchar(8),
semester varchar(6),
year numeric(4,0),
primarykey(ID,course id,sec id,semester,year),
foreignkey(course id,sec id,semester,year)referencessection
ondeletecascade,
foreignkey(ID)referencesinstructor
ondeletecascade);
createtablestudent
(ID varchar(5),
name varchar(20)notnull,
dept name varchar(20),
tot cred numeric(3,0)check(tot cred >=0),
primarykey(ID),
foreignkey(dept name)referencesdepartment
ondeletesetnull);
createtabletakes
(ID varchar(5),
course id varchar(8),
sec id varchar(8),
semester varchar(6),
year numeric(4,0),
grade varchar(2),
primarykey(ID,course id,sec id,semester,year),
foreignkey(course id,sec id,semester,year)referencessection
ondeletecascade,
foreignkey(ID)referencesstudent
ondeletecascade);

--- Page 1320 ---

A.2 DDL 1291
createtableadvisor
(s ID varchar(5),
i ID varchar(5),
primarykey(s ID),
foreignkey(i ID)referencesinstructor (ID)
ondeletesetnull,
foreignkey(s ID)referencesstudent(ID)
ondeletecascade);
createtableprereq
(course id varchar(8),
prereq id varchar(8),
primarykey(course id,prereq id),
foreignkey(course id)referencescourse
ondeletecascade,
foreignkey(prereq id)referencescourse);
The following create table statement for the table time slot can be run on most
database systems, but it does not work on Oracle (at least as of Oracle version 11),
sinceOracledoesnotsupporttheSQLstandardtypetime.
createtabletimeslot
(time slot id varchar(4),
day varchar(1)check(dayin(’M’,’T’,’W’,’R’,’F’,’S’,’U’)),
start time time,
end time time,
primarykey(time slot id,day,start time));
The syntax for specifying time in SQL is illustrated by these examples: ’08:30’,
’13:55’,and’5:30PM’.SinceOracledoesnotsupportthetimetype,forOracleweuse
thefollowingschemainstead:
createtabletimeslot
(time slot id varchar(4),
day varchar(1),
start hr numeric(2)check(start hr >=0andend hr <24),
start min numeric(2)check(start min>=0andstart min<60),
end hr numeric(2)check(end hr >=0andend hr <24),
end min numeric(2)check(end min>=0andend min<60),
primarykey(time slot id,day,start hr,start min));
The difference is that start time has been replaced by two attributes start hr and
start min, and similarly end time has been replaced by attributes end hr and end min.

--- Page 1321 ---

1292 AppendixA DetailedUniversitySchema
Theseattributesalsohaveconstraintsthatensurethatonlynumbersrepresentingvalid
time values appear in those attributes. This version of the schema for time slot works
on all databases, including Oracle. Note that although Oracle supports the datetime
datatype, datetime includes a specific day, month, and year as well as a time, and is
notappropriateheresincewewantonlyatime.Therearetwoalternativestosplitting
thetimeattributesintoanhourandaminutecomponent,butneitherisdesirable.The
firstalternativeistouseavarchartype,butthatmakesithardtoenforcevaliditycon-
straintsonthestringaswellastoperformcomparisonontime.Thesecondalternative
is to encode time as an integer representing a number of minutes (or seconds) from
midnight,butthisalternativerequiresextracodewitheachquerytoconvertvaluesbe-
tweenthestandardtimerepresentationandtheintegerencoding.Wethereforechoose
thetwo-partsolution.
A.3 Sample Data
Inthissectionweprovidesampledataforeachoftherelationsdefinedintheprevious
section.
building room number capacity
Packard 101 500
Painter 514 10
Taylor 3128 70
Watson 100 30
Watson 120 50
Figure A.2 Theclassroomrelation.
dept name building budget
Biology Watson 90000
Comp.Sci. Taylor 100000
Elec.Eng. Taylor 85000
Finance Painter 120000
History Painter 50000
Music Packard 80000
Physics Watson 70000
Figure A.3 Thedepartment relation.

--- Page 1322 ---

A.3 SampleData 1293
Credits
The photo of the sailboats in the beginning of the chapter is due to ©Pavel Nes-
vadba/Shutterstock.
course id title dept name credits
BIO-101 Intro.toBiology Biology 4
BIO-301 Genetics Biology 4
BIO-399 ComputationalBiology Biology 3
CS-101 Intro.toComputerScience Comp.Sci. 4
CS-190 GameDesign Comp.Sci. 4
CS-315 Robotics Comp.Sci. 3
CS-319 ImageProcessing Comp.Sci. 3
CS-347 DatabaseSystemConcepts Comp.Sci. 3
EE-181 Intro.toDigitalSystems Elec.Eng. 3
FIN-201 InvestmentBanking Finance 3
HIS-351 WorldHistory History 3
MU-199 MusicVideoProduction Music 3
PHY-101 PhysicalPrinciples Physics 4
Figure A.4 Thecourse relation.
ID name dept name salary
10101 Srinivasan Comp.Sci. 65000
12121 Wu Finance 90000
15151 Mozart Music 40000
22222 Einstein Physics 95000
32343 ElSaid History 60000
33456 Gold Physics 87000
45565 Katz Comp.Sci. 75000
58583 Califieri History 62000
76543 Singh Finance 80000
76766 Crick Biology 72000
83821 Brandt Comp.Sci. 92000
98345 Kim Elec.Eng. 80000
Figure A.5 Theinstructor relation.

--- Page 1323 ---

1294 AppendixA DetailedUniversitySchema
course id sec id semester year building room number time slot id
BIO-101 1 Summer 2017 Painter 514 B
BIO-301 1 Summer 2018 Painter 514 A
CS-101 1 Fall 2017 Packard 101 H
CS-101 1 Spring 2018 Packard 101 F
CS-190 1 Spring 2017 Taylor 3128 E
CS-190 2 Spring 2017 Taylor 3128 A
CS-315 1 Spring 2018 Watson 120 D
CS-319 1 Spring 2018 Watson 100 B
CS-319 2 Spring 2018 Taylor 3128 C
CS-347 1 Fall 2017 Taylor 3128 A
EE-181 1 Spring 2017 Taylor 3128 C
FIN-201 1 Spring 2018 Packard 101 B
HIS-351 1 Spring 2018 Painter 514 C
MU-199 1 Spring 2018 Packard 101 D
PHY-101 1 Fall 2017 Watson 100 A
Figure A.6 Thesectionrelation.
ID course id sec id semester year
10101 CS-101 1 Fall 2017
10101 CS-315 1 Spring 2018
10101 CS-347 1 Fall 2017
12121 FIN-201 1 Spring 2018
15151 MU-199 1 Spring 2018
22222 PHY-101 1 Fall 2017
32343 HIS-351 1 Spring 2018
45565 CS-101 1 Spring 2018
45565 CS-319 1 Spring 2018
76766 BIO-101 1 Summer 2017
76766 BIO-301 1 Summer 2018
83821 CS-190 1 Spring 2017
83821 CS-190 2 Spring 2017
83821 CS-319 2 Spring 2018
98345 EE-181 1 Spring 2017
Figure A.7 Theteachesrelation.

--- Page 1324 ---

A.3 SampleData 1295
ID name dept name tot cred
00128 Zhang Comp.Sci. 102
12345 Shankar Comp.Sci. 32
19991 Brandt History 80
23121 Chavez Finance 110
44553 Peltier Physics 56
45678 Levy Physics 46
54321 Williams Comp.Sci. 54
55739 Sanchez Music 38
70557 Snow Physics 0
76543 Brown Comp.Sci. 58
76653 Aoi Elec.Eng. 60
98765 Bourikas Elec.Eng. 98
98988 Tanaka Biology 120
Figure A.8 Thestudent relation.

--- Page 1325 ---

1296 AppendixA DetailedUniversitySchema
ID course id sec id semester year grade
00128 CS-101 1 Fall 2017 A
00128 CS-347 1 Fall 2017 A-
12345 CS-101 1 Fall 2017 C
12345 CS-190 2 Spring 2017 A
12345 CS-315 1 Spring 2018 A
12345 CS-347 1 Fall 2017 A
19991 HIS-351 1 Spring 2018 B
23121 FIN-201 1 Spring 2018 C+
44553 PHY-101 1 Fall 2017 B-
45678 CS-101 1 Fall 2017 F
45678 CS-101 1 Spring 2018 B+
45678 CS-319 1 Spring 2018 B
54321 CS-101 1 Fall 2017 A-
54321 CS-190 2 Spring 2017 B+
55739 MU-199 1 Spring 2018 A-
76543 CS-101 1 Fall 2017 A
76543 CS-319 2 Spring 2018 A
76653 EE-181 1 Spring 2017 C
98765 CS-101 1 Fall 2017 C-
98765 CS-315 1 Spring 2018 B
98988 BIO-101 1 Summer 2017 A
98988 BIO-301 1 Summer 2018 null
Figure A.9 Thetakesrelation.
sid i id
00128 45565
12345 10101
23121 76543
44553 22222
45678 22222
76543 45565
76653 98345
98765 98345
98988 76766
Figure A.10 Theadvisor relation.

--- Page 1326 ---

A.3 SampleData 1297
time slot id day start time end time
A M 8:00 8:50
A W 8:00 8:50
A F 8:00 8:50
B M 9:00 9:50
B W 9:00 9:50
B F 9:00 9:50
C M 11:00 11:50
C W 11:00 11:50
C F 11:00 11:50
D M 13:00 13:50
D W 13:00 13:50
D F 13:00 13:50
E T 10:30 11:45
E R 10:30 11:45
F T 14:30 15:45
F R 14:30 15:45
G M 16:00 16:50
G W 16:00 16:50
G F 16:00 16:50
H W 10:00 12:30
Figure A.11 Thetimeslot relation.
course id prereq id
BIO-301 BIO-101
BIO-399 BIO-101
CS-190 CS-101
CS-315 CS-101
CS-319 CS-101
CS-347 CS-101
EE-181 PHY-101
Figure A.12 Theprereqrelation.

--- Page 1327 ---

1298 AppendixA DetailedUniversitySchema
time slot id day start hr start min end hr end min
A M 8 0 8 50
A W 8 0 8 50
A F 8 0 8 50
B M 9 0 9 50
B W 9 0 9 50
B F 9 0 9 50
C M 11 0 11 50
C W 11 0 11 50
C F 11 0 11 50
D M 13 0 13 50
D W 13 0 13 50
D F 13 0 13 50
E T 10 30 11 45
E R 10 30 11 45
F T 14 30 15 45
F R 14 30 15 45
G M 16 0 16 50
G W 16 0 16 50
G F 16 0 16 50
H W 10 0 12 30
Figure A.13 Thetimeslot relationwithstartandendtimesseparatedintohourand
minute.

--- Page 1328 ---

Index
abortedtransactions,805–807, AdvancedEncryptionStandard queryprocessingand,723
819–820 (AES),448,449 rankingand,219–223
abstraction,2,9–12,15 advancedSQL,183–231 representationof,279
acceptors,1148,1152 accessingfromprogramming rollupandcube,227–231
accessingdata.Seealsosecurity languages,183–198 skewand,1049–1050
fromapplicationprograms, aggregatefeatures,219–231 oftransactions,1278
16–17 embedded,197–198 viewmaintenanceand,
concurrent-accessanomalies, functionsandprocedures, 781–782
7 198–206 windowingand,223–226
difficultiesin,6 JDBCand,184–193 aggregationoperation,57
indicesfor,19 ODBCand,194–197 aggregationswitch,977
recoverysystemsand, Pythonand,193–194 airlines,databaseapplications
910–912 triggersand,206–213 for,3
typesofaccess,15 advertisementdata,469 Ajax,423–426,1015
accesspaths,695 AES(AdvancedEncryption algebraicoperations.See
accesstime Standard),448,449 relationalalgebra
indicesand,624,627–628 aftertriggers,210 aliases,81,336,1242
queryprocessingand,692 aggregatefunctions,91–96 allconstruct,100
storageand,561,566,567, basic,91–92 altertable,71,146
578 withBooleanvalues,96 altertrigger,210
accesstypes,624 defined,91 altertype,159
accountnonces,1271 withgrouping,92–95 Amdahl’slaw,974
ACIDproperties.Seeatomicity; havingclause,95–96 AmericanNationalStandards
consistency;durability; withnullvalues,96 Institute(ANSI),65,1237
isolation aggregation analysispass,944
ActiveServerPage(ASP),405 defined,277 analytics.Seedataanalytics
activetransactions,806 entity-relationship(E-R) andconnective,74
ActiveXDataObjects(ADO), modeland,276–277 andoperation,89–90
1239 intraoperationparallelism anonymity,1252,1253,1258,
adaptivelockgranularity, and,1049 1259
969–970 onmultidimensionaldata, ANSI(AmericanNational
addconstraint,146 527–532 StandardsInstitute),65,
ADO(ActiveXDataObjects), partial,1049 1237
1239 pivotingand,226–227,530 anticipatorystandards,1237
ADO.NET,184,1239 queryoptimizationand,764 anti-joinoperation,108,776
1299

--- Page 1329 ---

1300 Index
anti-semijoinoperation,776–777 standardizationand, lambda,504,1071
Apache 1237–1240 mesh,976
AsterixDB,668 testing,1234–1235 microservices,994
Cassandra,477,489,668, tuningand(seeperformance multiusersystems,962
1024,1028 tuning) Non-UniformMemory
Flinkproject,504,508 URLsand,405–406 Access,981,1063
Giraphsystem,511 userinterfacesand,403–405 overview,961–962
HBase,477,480,489,668, weband,405–411 paralleldatabases,22,
971,1024,1028–1031 applicationmigration, 970–986
Hive,494,495,500 1035–1036 platform-as-a-servicemodel,
JakartaProject,416 applicationprograminterfaces 992–993
Kafkasystem,506,507, (APIs) recoverysystems,932
1072–1073,1075,1137 ADO,1239 serversystem,962–970,
Spark,495–500,508,511, ADO.NET,184,1239 977–978
1061 applicationdesignand,411, shareddisk,979,980,
Stormstream-processing 413,416 984–985
system,506–508 C++,1239 sharedmemory,21–22,
Tez,495 databaseaccessfrom,16–17 979–984,1061–1064
APIs.Seeapplicationprogram Java(seeJava) sharednothing,979,980,
interfaces LDAP,1243 985–986,1040–1041,
applicationdesign,403–453 mapdisplaysand,393 1061–1063
applicationarchitecturesand, MongoDB,477–479,482, single-usersystems,962
429–434 489,668,1024,1028 software-as-a-servicemodel,
authenticationand,441–443 OpenDatabaseConnectivity 993
businesslogicand,23,404, (seeODBC) source-driven,522
411–412,430,431,445 Python(seePython) storageareanetwork,562
client-serverarchitectureand, Spark,495–500,508,511, three-tier,23
404 1061 transaction-serversystems,
client-sidecodeandweb standardsfor,1238–1240 963–968
services,421–429 systemarchitecturesand,962 two-phasecommitprotocol,
commongatewayinterface Tez,495 989,1276
standardand,409 webservicesand,427 two-tier,23
cookiesand,410–415,411n2 applicationprogrammers,24 wide-areanetworks,989
dataaccesslayerand, applicationservers,23,416 archivaldata,561
430–434 architectures,961–995 archivaldump,931
disconnectedoperationand, businesslogicand,23 ARIES
427–428 centralizeddatabases, analysispassand,944
encryptionand,447–453 962–963 compensationlogrecords
HTMLand,404,406–408, client-serversystems,23,971 and,942,945
426 cloud-based,990–995,1026, datastructuresand,942–944
HTTPand,405–413 1027 dirtypagetableand,941–947
JavaScriptand,404–405, databasestorage,587–588 fine-grainedlockingand,947
421–426 data-serversystems,963–964, fuzzycheckpointsand,941
JavaServerPagesand,405, 968–970 logsequencenumberand,
417–418 datawarehousing,522–523 941–946
mobileapplicationplatforms, destination-driven,522 nestedtopactionsand,946
428–429 distributeddatabases,22, optimizationand,947
performanceand,434–437 986–989,1098–1100 physiologicalredoand,941
securityand,437–446 hierarchical,979,980,986 recoveryalgorithm,944–946,
servletsand,411–421 hypercube,976–977 1276

--- Page 1330 ---

Index 1301
redopassand,944–945 recoverysystemsand,803, audittrails,445–446
rollbackand,945–946 912–922 augmentationrule,321
savepointsand,947 storagestructureand, authentication
undopassand,944–946 804–805 application-level,441–443
arity,54 oftransactions,20–21,144, challenge-responsesystem
Armstrong’saxioms,321 481,800–807,819–821 and,451
arraydatabases,367 attributeinheritance,274–275 digitalcertificatesand,
arraytypes,366,367,378 attributes 451–453
ascexpression,84 atomicdomainsand,342–343 digitalsignaturesand,451
asclause,79,81 bitmapindicesand,670–672 encryptionand,450–453
asofperiodfor,157 classifiersand,541–543,545 singlesign-onsystemand,
ASP(ActiveServerPage),405 closureofattributesets, 442–443
ASP.NET,417 322–324 smartcardsand,451,451n9
assertions,152–153 complex,249–252,265–267 two-factor,441–442
assetmanagement,1277 composite,250,252 websessionsand,410
assignmentoperation,55–56, decompositionand,305–313,
authorization
201 330–335,339–340
administratorsand,166
associations derived,251,252
application-level,443–445
dataminingand,541 descriptive,248
databasedesignand,291
entitysets(seeentitysets) designissuesand,281–282
end-userinformationand,443
relationschemafor,42 discriminator,259
grantingprivileges,25,
relationshipsets(see domainof,39–40,249
166–167,170–171
relationshipsets) entity-relationshipdiagrams
lackoffine-grained,443–445
rulesfor,546–547 and,265–267
permissionedblockchains
associativeproperty,749–750 entity-relationship(E-R)
and,1253
AsterixDB,668 modeland,245,248–252,
revokingprivileges,166–167,
asymmetric 274–275,281–282,
171–173
fragment-and-replicate 342–343
rolesand,167–169
joins,1046,1062 entitysetsand,245,265–267,
row-level,173
asymmetric-keyencryption,448 281–282
onschema,170
asynchronousreplication,1122, extraneous,325
SecurityAssertionMarkup
1135–1138 histogramsand,758–760
Languageand,442–443
asynchronousviewmaintenance, multiple-keyaccessand,
SQLDDLand,66
1138–1140 661–663
sqlsecurityinvoker,170
at-least-oncesemantics,1074 multivalued,251,252,342
at-most-oncesemantics,1074 namingof,345–346 storagemanagerand,19
atomiccommit,1029 nullvaluesand,251–252 transferofprivileges,170–171
atomicdomains,40,342–343 partitioning,479 typesof,14,165
atomicinstructions,966–967 primarykeysand,310n4 updatesand,14,170,171
atomicity prime,356 onviews,169–170
cascadelessschedulesand, inrelationalmodel,39 authorizationgraph,171
820–821 relationshipsetsand,248 automaticcommit,144,144n6,
commitprotocolsand, searchkeyand,624 822
1100–1110 simple,250,265 autonomoussmartcontracts,
defined,20,800 single-valued,251 1272–1273
infile-processingsystems,6–7 UnifiedModelingLanguage autonomy,988
isolationand,819–821 and,289 availability
logrecordsand,913–919 uniquifiers,649–650 CAPtheoremand,1134
recoverableschedulesand, valuesetof,249 distributeddatabasesand,
819–820 attribute-valueskew,1008 987

--- Page 1331 ---

1302 Index
highavailability,907, big-bangapproach,1236 efficientimplementationof,
931–933,987,1121 BigchainDB,1269 1184–1185
networkpartitionsand,481, BigData,467–511 existence,1184
989 algebraicoperationsand, intersectionand,671,1183
robustnessand,1121 494–500 processingspeedand,662,
tradingoffconsistencyfor, comparisonwithtraditional 663
1134–1135 databases,468 scansof,698–699
averagelatencytime,566 defined,467 sequentialrecordsand,1182
averageresponsetime,809 distributedfilesystemsfor, structureof,1182–1184
averageseektime,566 472–475,489 usefulnessof,671–672
avgexpression,91–96,723, graphdatabasesand,508–511 bitrot,575
781–782
key-valuesystemsand,471, blindwrites,868
Avro,490,499
473,476–480 B-linktrees,886
axioms,321
MapReduceparadigmand, blobs,156,193,594,652
AzureStreamAnalytics,505
481,483–494 blockchaindatabases,
motivationsfor,467–472 1251–1279
backpropagationalgorithm,545 parallelanddistributed anonymityand,1252,1253,
backup.Seealsorecoverysystems
databasesfor,473, 1258,1259
applicationdesignand,450 480–481 applicationsforuse,
remotesystemsfor,909, queryprocessingand, 1251–1252,1276–1279
931–935 470–472 concurrencycontroland,
replicasystems,212–213
replicationandconsistency 1262–1263
transactionsand,805 in,481–482 consensusmechanismsfor,
backupcoordinators,1146–1147
shardingand,473,475–476 1254,1256–1257,
balancedrange-partitioning
sourcesandusesof,468–470 1263–1267
vector,1008–1009
storagesystems,472–482,668 cryptocurrenciesand,
balancedtrees,634
streamingdata,468,500–508 1251–1253,1257
banking
Bigtable,477,479–480,668, cryptographichashfunctions
analyticsfor,520–521
1024–1025,1028–1030 and,1253,1259–1263,
databaseapplicationsfor,3,
binaryoperations,48 1265
4,7,144
binaryrelationshipsets,249, dataminingand,1256,1258,
BASEproperties,1135
283–285 1264–1266
basequery,217
BingMaps,393 decentralizationand,1251,
batchscaleup,973
Bitcoin 1252,1259,1270
batchupdate,1221
anonymityand,1253,1258 digitalledgersand,1251,1252
Bayesianclassifiers,543–544
dataminingand,1265 digitalsignaturesand,1257,
Bayes’theorem,543
BCNF.SeeBoyce–Coddnormal forkingand,1258 1261
growthanddevelopmentof, encryptionand,1260–1261
form
1251–1253 externalinputand,1271–1272
BCNFdecompositionalgorithm,
331–333,336 languageand,1269–1270 fault-toleranceof,1276
beforetriggers,210 processingspeed,1274 forkingand,1257,1258,1263
beginatomic...end,145,201, aspublicblockchain,1253, genesisblocksand,
208,209,211 1255,1263 1254–1255
begintransactionoperation,799 transactionsand,1261–1263, irrefutabilityand,1257,1259
benchmarks.Seeperformance 1268–1271 languagesand,1258,
benchmarks bit-levelstriping,571–572 1269–1271
bestplanarray,768–770 bitmapindices lookupin,1268
biasedprotocol,1124 attributesand,670–672 managementofdatain,
BI(businessintelligence),521 B+-treesand,1185–1186 1267–1269

--- Page 1332 ---

Index 1303
orphanedblocksand,1257, performancetuningand, nonuniquesearchkeysand,
1263 1211–1213,1215,1227 649–650
performanceenhancementof, singlelock-managerand,1111 organizationof,595,
1274–1276 systemarchitecturesand,981, 650–652,697,697n4
permissioned,1253–1254, 985 parallelkey-valuestoresand,
1256–1257,1263,1266, bottom-upB+-treeconstruction, 1028
1274 654–655 performanceand,634,
propertiesandcomponents bottom-updesign,273 665–666
of,1254–1259,1274 boundingboxes,674–675,1187 querieson,637–641,690
public,1253,1255, Boyce–Coddnormalform recordrelocationand,
1257–1259,1263,1264 (BCNF) 652–653
queryprocessingand,1254, comparisonwiththirdnormal secondaryindicesand,
1275–1276 form,318–319 652–653
scalabilityof,1276 decompositionalgorithmand, spatialdataand,672–673
smartcontractsand,1258, 331–333,336 structureof,634–637
1269–1273 defined,313–315 temporaldataand,676
state-based,1269,1271 dependencypreservationand, tuningof,1215
tamperresistantnatureof, 315–316
updateson,641–649
1253–1255,1259,1260 relationaldatabasedesign
buckets,659–661,1194–1195
transactionsand,1261–1263, and,313–316
bufferblocks,910–912
1268–1271,1273 testingfor,330–331
buffermanager,19,604–607
blockidentifiers,474–475,1020 broadcasting,1055–1056
buffers
blockingedges,728 broadcastjoin,1046
databasebuffering,927–929
blockingfactor,725 BSP(bulksynchronous
defined,604
blockingoperations,728,728n7 processing),510–511
diskblocksand,578,910
blockingproblem,1104–1106 B-trees,comparisonwith
doublebuffering,725
block-interleavedparity B+-trees,655–656
force/no-forcepolicyand,927
organization,573 B+-trees,634–658
forceoutputand,912
block-levelstriping,572 balanced,634
log-record,926–927
blocknested-loopjoin,705–707 bitmapindicesand,
block-orientedinterface,560 1185–1186 managementof,926–930
blocks bottom-upconstructionof, operatingsystemrolein,
buffer,910–912 654–655 929–930
dirty,928–929 bulkloadingof,653–655 outputofblocksand,
disk,566–567,577–580 comparisonwithB-trees, 606–607
evicted,605 655–656 recoverysystemsand,
fileorganizationand,588 deletionand,641,645–649 926–930
genesis,1254–1255 extensionsandvariationsof, reorderingofwritesand
orphaned,1257,1263 650–658 recovery,609–610
overflow,598 fanoutand,635 replacementstrategies,605,
physical,910 onflashstorage,656–657 607–609
pinned,605 indexingstringsand,653 sharedandexclusivelockson,
Bloomfilters,667,1083, insertionand,641–645,647, 605–606
1175–1176,1181 649 steal/no-stealpolicyand,927
Booleanoperations,89,96,103, internalnodesand,635 storageand,604–610
188,201,1242.See leafnodesof,635–656, transactionserversand,965
alsospecificoperations 665–669,673,674 write-aheadloggingruleand,
bottlenecks inmainmemory,657–658 926–929
applicationdesignand,437 nonleafnodesof,635–636, buffertrees,668–670
I/Oparallelismand,1007 642,645–656,663 bugs

--- Page 1333 ---

1304 Index
applicationdesignand,440, coherencyand,969,983–984 centroid,548,548n3
1234,1236 column-orientedstorageand, CEP(complexeventprocessing)
debugging,199n4 612 systems,504
failureclassificationand,908 dataserversand,968–970 CGI(commongatewayinterface)
buildinput,713 locksand,969 standard,409
bulkexportutility,1222 queryplansand,774,965 chainreplicationprotocol,
bulkinsertutility,1222 replicationand,1014n4 1127–1128
bulkloads,653–655,1221–1223 shared-memoryarchitecture challenge-responsesystem,451
bulksynchronousprocessing and,982–984 changeisolationlevel,822
(BSP),510–511 CAD(computer-aideddesign), changerelation,211
bullyalgorithm,1148 390–391,968 char,67
businessintelligence(BI),521 callablestatements,190–191 checkclause
businesslogic,23,198,404, callback,969 assertionsand,152–153
411–412,430–431,445 CallLevelInterface(CLI) integrityconstraintsand,
business-logiclayer,430,431 standards,197,1238–1239 147–149,152–153
businessrules,431 callstatement,201
user-definedtypesand,159
bussystem,975–976 candidatekeys,44
checkconstraints,151,170,315,
Byzantineconsensus,1254, canonicalcover,324–328
800
1256,1266–1267,1276 CAPtheorem,1134
checkpointlogrecords,943
Byzantinefailure,1266–1267 Cartesian-productoperation,
checkpointprocess,965
50–52
checkpoints
C Cartesianproducts
fuzzy,922,930,941
advancedSQLand,183,197, equivalenceand,748,749,
recoverysystemsand,
199,205 755
920–922,930
applicationdesignand,16 joinexpressionsand,135
transactionserversand,965
ODBCand,195–196 queryoptimizationand,748,
checksums,565
structdeclarationsusedby, 749,755,763–764,775
chicken-littleapproach,1236
11n1 SQLand,76–79,81,127n1,
Chubby,1150
UnifiedModelingLanguage 230
circulararcs,388
and,289 cascadelessschedules,820–821
classifiers
C++ cascades,150,172,210
attributesand,541–543,545
advancedSQLand,197,199, cascadingrollback,820–821,
Bayesian,543–544
205,206 841–842
dataminingand,541–546
applicationdesignand,16, cascadingstylesheet(CSS)
417 standard,408 decision-tree,542
object-orientedprogramming caseconstruct,112–113 neural-net,545–546
and,377 Cassandra,477,489,668,1024, predictionand,541–543,
standardsfor,1239 1028 545–546
structdeclarationsusedby, cast,155,159 SupportVectorMachine,
11n1 catalogs 544–545
UnifiedModelingLanguage applicationdesignand,1239 traininginstancesand,541
and,289 indicesand(seeindices) CLI(CallLevelInterface)
cache-consciousalgorithms, queryoptimizationand, standards,197,1238–1239
732–733 758–760,762,764 click-through,469
cacheline,732,983 SQLand,162–163,192, client-serversystems
cachememory,559 196–197 applicationdesignand,404,
cachemisses,982 system,602–604,1009 1221,1239
caching centralizeddatabases,962–963 recoverysystemsand,931
applicationdesignand, centralizeddeadlockdetection, systemarchitectureand,23,
435–437 1114 971

--- Page 1334 ---

Index 1305
client-sidescriptinglanguages, combinefunction,490 column-orientedstorageand,
421–429 comma-separatedvalues,1222 611,612
clobs,156,193,594,652 commitdependency,847 datawarehousingand,526
closedaddressing,659,1194 commitprotocols,1100–1110 ofdiskblockdata,615n8
closedhashing,659,1194 committedtransactions prefix,653
closedpolygons,388n3 defined,806 workloadcompression,1217
closedtimeintervals,675 durabilityand,933–934 computer-aideddesign(CAD),
closureofaset,312,320–324 logrecordsand,917 390–391,968
cloud-baseddatastorage,28, observableexternalwrites conceptual-designphase,17–18,
563,992–993 and,807 242
cloudcomputing partiallycommitted,806 concurrencycontrol,835–894
architecturefor,990–995, schedulingand,810,819–820 accessanomaliesand,7
1026,1027 updatesand,874
blindwritesand,868
benefitsandlimitationsof, committime,933–934
blockchaindatabasesand,
995 commitwait,1130–1131
1262–1263
servicemodels,991–995 commitwork,143–145
commitprotocolsand,1105
storagesystemsand,28,563 commongatewayinterface(CGI)
consistencyand,880–885
CLR(CommonLanguage standard,409
deadlockhandlingand,
Runtime),206 CommonLanguageRuntime
849–853
CLRs(compensationlog (CLR),206
deletionand,857–858
records),922,942,945 commonsubexpression
distributeddatabasesand,
clusteringindices,625, elimination,785
990,1105,1111–1120
632–633,695,697–698 commutativeproperty,747–750
extendedprotocols,
clusterkey,600–601 commute,1143
1129–1133
clustermembership,1158 compare-and-swap,966
falsecyclesand,1114–1115
clusters compatibilityfunction,836
infederateddatabases,
dataminingand,541, compatiblerelations,54
1132–1133
548–549 compensatingoperation,892
indicesand,884–887
hierarchical,548 compensatingtransactions,805
insertionand,857,858
key-valuestoragesystemsand, compensationlogrecords
isolationand,803–804,
477 (CLRs),922,942,945
807–812,823
multitable,595,598–601 completeaxioms,321
leasesand,1115–1116
systemarchitectureand,978 completenessconstraint,275
coalescefunction,114,155, complexattributes,249–252, lockingprotocolsand,
230–231 265–267 835–848(seealsolocks)
coalescingnodes,641,886 complexdatatypes,365–394 logicalundooperationsand,
coarse-grainedparallelism,963, objectorientation,376–382 940–941
970 semi-structured,365–376 long-durationtransactions
Codd,Edgar,26 spatial,387–394 and,890–891
codebreaking.Seeencryption textual,382–387 inmain-memorydatabases,
collisionresistanthashfunctions, user-defined,158 887–890
1259–1260 complexeventprocessing(CEP) multiplegranularityand,
colocationofdata,1068–1069 systems,504 853–857
columnfamily,1025 compositeattributes,250,252 multiversionschemesand,
column-orientedstorage, compositeindices,700 869–872,1129–1131
525–526,588,611–617, compositeprice/performance withoperations,891–894
734,1182 metric,1234 optimistic,869
columnstores,612,615,1025, compositequeryperhourmetric, paralleldatabasesand,990
1224 1234 parallelkey-valuestoresand,
combinatorics,811 compression 1028–1029

--- Page 1335 ---

1306 Index
phantomphenomenonand, proof-of-work,1256, onspecialization,275–276
827,858–861,877–879, 1264–1266 transactionsand,800
877n5,885,887 Raft,1148,1155–1158,1267 UnifiedModelingLanguage
predicatereadsand,858–861 replicationand,1016 and,289
real-timetransactionsystems Zab,1152 containers,992–994
and,894 consistency containsoperation,101
recoverysystemsand,916 BigDataand,481–482 continuousqueries,503,731
replicationand,1123–1125 CAPtheoremand,1134 continuous-streamdata,731
rollbackand,841–844, concurrencycontroland, conversations,883
849–850,853,868–871 880–885 conversions,155–156,469,843
serializabilityand,836, cursorstabilityand,881 cookies,410–415,411n2,
840–843,846–848,856, deadlockand,838–839 439–440
861–871,875–887 defined,20 coordinators,1099,1104,
snapshotisolationand, degree-two,880–881 1106–1107,1146–1150
872–879,882,916, eventual,1016,1139 Corda,1269
1131–1132 external,1131 cores,962–963,970,976,
timestamp-basedprotocols filesystemconsistencycheck, 980–983
and,861–866,882 610 coreswitch,977
trendsin,808 hashingand,1013 correlatedevaluation,775
userinteractionsand, logicaloperationsand, correlatedsubqueries,101
881–883 936–937 correlationname,81,101
validationand,866–869,882, replicationand,1015–1016, correlationvariables,81,775
916 1121–1123,1133–1146 cost-basedoptimizers,766
concurrency-controlmanager,21 requirementof,802 Couchbase,1024
concurrency-controlschemes, tradingoffforavailability, countfunction,91–92,94,96,
809 1134–1135 723,766,781
concurrenttransactions, oftransactions,20,800,802, countvalues,220n11
1224–1227 807–808,821–823 coveringindices,663
confidence,540,547 userinteractionsand, crabbingprotocol,885–886
conflictequivalence,815,815n2 881–883 crashes.Seealsorecovery
conflictserializability,813–816 weaklevelsof,880–883 systems
conformancelevels,196–197 constraints actionsfollowing,923–925
conjunctiveselection,699–700, check,151,170,315 algorithmsfor,922–925
747,762 completeness,275 ARIESand,941–947
connectionpooling,436 consistency,13–14 checkpointsand,920–922
consensusprotocols deadlines,894 failureclassificationand,908
blockchaindatabasesand, decompositionand,336 magneticdisksand,565
1254,1256–1257, dependencypreservationand, storageand,607,609–610
1263–1267 315–316 transactionsand,800
Byzantine,1254,1256, entity-relationship(E-R) crawlingtheweb,383
1266–1267,1276 modeland,253–256, createassertion,153
distributeddatabasesand, 275–276 createcluster,601
1106–1107,1150–1161, foreignkey,45–46 createdistincttype,160
1266,1267 integrity(seeintegrity createdomain,159–160
message-based,1266 constraints) createfunction,200,203,204,
multipleconsensusprotocol, keysand,258 215
1151 mappingcardinalitiesand, createindex,164–165,664
Paxos,1152–1155,1160–1161, 253–256 createorreplace,199n4
1267 notnull,69 createprocedure,200,205
proof-of-stake,1256,1266 primarykey,44 createrecursiveview,218

--- Page 1336 ---

Index 1307
createrole,168 DAOs(distributedautonomous phasesof,17–18,241–243
createschema,163 organizations),1272, physical-designphaseof,18,
createsequenceconstruct,161 1272n7 242–243
createtable Dartlanguage,428–429 redundancyin,243
withdataclause,162 dataabstraction,2,9–12,15 relational(seerelational
defaultvaluesand,156 dataaccesslayer,430–434 databasedesign)
extensionsfor,162 dataanalytics,519–549.Seealso schemaevolutionand,292
integrityconstraintsand, datamining specificationoffunctional
146–149 decision-supportsystemsand, requirementsin,17–18
multitableclusteringand,601 519–522 top-down,273
object-baseddatabasesand, defined,4,519 userrequirementsin,17–18,
378–380 OLAPsystems,520,527–540 241–242,274
shippingSQLstatementsto overview,519–521 workflowand,291–292
databaseand,187 predictivemodelsin,4–5 databasegraph,846–848
SQLschemadefinitionand, statisticalanalysis,520,527 databaseinstance,41
68–71 warehousingand,519–527 database-managementsystems
createtable...as,162 data-at-rest,502 (DBMSs)
createtable...like,162 databaseadministrators(DBAs), defined,1
createtemporarytable,214 24–25 objectivesof,1,24
createtype,158–160,378–380 database-as-a-serviceplatform, organizationaldata
createuniqueindex,165,664 993 processingpriorto,472
databasedesign product-specificcallsneeded
createview,138–143,162,169
alternativesin,243–244, by,186
creditbureaus,521,521n1
285–291 databases
cross-chaintransactions,1273
applicationsand(see abstractionand,2,9–12,15
crossjoin,127n1
applicationdesign) administratorsof,24–25
cross-siterequestforgery
architectureof(see applicationsfor,1–5
(XSRF),439–440
architectures) architecture(see
cross-sitescripting(XSS),
authorizationrequirements architectures)
439–440
and,291 array,367
cross-tabulation,226–227,
bottom-up,273 blockchain(seeblockchain
528–533
buffersand,604–610 databases)
CRUDwebinterfaces,419
client-server(seeclient-server bufferingand,927–929
cryptocurrencies,1251–1253,
systems) centralized,962–963
1257.SeealsoBitcoin
complexityof,241 concurrencycontroland(see
cryptographichashfunctions,
computer-aided,390–391 concurrencycontrol)
1253,1259–1263,1265
conceptual-designphaseof, defined,1
CSS(cascadingstylesheet)
17–18,242 designof(seedatabase
standard,408
directdesignprocess,241 design)
C-Store,615
encryptionand,447–453 document,3
cubeconstruct,227–231,
engines,18–21 dumpingand,930–931
536–538
E-Rmodeland(see efficiencyof,1,2,5,9
currentdate,154
entity-relationshipmodel) embedded,198,962
cursorstability,881
functionalrequirementsof, asfile-processingsystems,5–8
curvefitting,546
291 forceoutputand,912
cylinders,565
incompletenessin,243–244 graph,508–511
Cypherquerylanguage,509
logical-designphaseof,18, historyof,25–28
242 indexingand(seeindices)
DAGs(directedacyclicgraphs), normalizationin,17 languagesfor,13–17
499,506–507,1071–1072 overviewofprocess,241–244 locksand(seelocks)

--- Page 1337 ---

1308 Index
mainmemory(see storageand,67 data-transferfailures,909
main-memorydatabases) datadictionary,14,19,602–604 data-transferrate,566,569
maintenancefor,25 datadistributionskew,1008 datatypes.Seetypes
modificationof,108–114, DataEncryptionStandard datavirtualization,1077
915–916 (DES),448 datavisualization,538–540
object-based(seeobject-based datafiles,19 datawarehousing,519–527
databases) datainconsistency,6 architecturefor,522–523
object-oriented,9,26,377, dataisolation.Seeisolation column-orientedstorageand,
431,1239–1240 data-itemidentifiers,913 525–526
object-relational,377–381 dataitems,968 componentsof,522–524
parallel(seeparallel datalakes,527,1078 databasesupportfor,
databases) data-manipulationlanguage 525–526
purposeof,5–8 (DML) dataintegrationvs.,
queryprocessorcomponents applicationprogramsand,17 1077–1078
of,18,20 compiler,20 datalakesand,527,1078
recoveryof(seerecovery declarative,15 deduplicationand,523
systems) defined,13,15,66 defined,519,522
storagefor(seestorage) procedural,15 ETLtasksand,520,524
transactionmanagerin,18–21 SQLand,16 facttablesand,524
university(seeuniversity storagemanagerand,19 householdingand,523
databases) datamining,540–549 merger-purgeoperationand,
userinteractionwith,4–5,24 associationrulesand, 523
databasesadministrator(DBA), 546–547 multidimensionaldataand,
171 blockchaindatabasesand, 524
databaseschema.Seeschemas 1256,1258,1264–1266 overview,519–520
databasewriterprocess,965 classifiersand,541–546 schemasusedfor,523–525
datacenterfabric,978 clusteringand,541,548–549 transformationandcleansing,
datacenters,970,1014–1015 defined,5,540 523
datacleansing,523 descriptivepatternsand,541 updatesand,523
datacubes,529–530 growthof,27 datetimedatatype,154,531
data-definitionlanguage(DDL) modelsfor,540 DBAs(databaseadministrators),
applicationprogramsand,17 overview,521 24–25
authorizationand,66 predictionand,541 DBMSs.See
basictypessupportedby, regressionand,546 database-management
67–68 rulesfor,540 systems
inconsistencyconstraint tasktypesin,541 DDL.Seedata-definition
specification,13–14 textmining,549 language
defined,13,65 datamodels,8–9.Seealso DDLinterpreter,20
dumpingand,931 specificmodels deadlines,894
grantingandrevoking datanodes,475,1020 deadlocks
privilegesand,166 dataparallelism,1042,1057 consistencyand,838–839
indicesand,67 datapartitioning,989n5 detectionof,849,851–852
integrityand,66 data-serversystems,963–964, distributeddatabasesand,
interpreter,20 968–970 1111–1115
outputof,14 DataSettype,499 handlingof,849–853
schemadefinitionand,24,66, datastorageanddefinition preventionof,849–851
68–71 language,13 recoveryand,849,851,853
securityand,67 datastoragesystems.Seestorage rollbackand,853
setofrelationsin,66–67 datastreams,731 starvationand,853
SQLand,14–15,65–71 datastriping,571–572 victimselectionand,853

--- Page 1338 ---

Index 1309
wait-forgraphsand,851–852, deeplearning,546 descexpression,84
1113–1114 deepneuralnetworks,546 descriptiveattributes,248
debugging,199n4 defactostandards,1237 descriptivepatterns,541
decentralization,1251,1252, defaultvalues DES(DataEncryption
1259,1270 classifiersand,545 Standard),448
decisionsupport,521, privilegesand,167 design.Seedatabasedesign
1231–1233 settingreferencefieldto,150 destination-drivenarchitecture,
decision-supportqueries,521, user-definedtypesand,159 522
971 deferredintegrityconstraints, dicing,530
decision-supportsystems, 151 dictionaryattacks,449
519–522 deferred-modificationtechnique, differentials,780
decision-supporttasks,521 915 digitalcertificates,451–453
decision-treeclassifiers,542 deferredviewmaintenance,779, digitalledgers,1251,1252
declarativeDMLs,15 1215–1216
digitalsignatures,451,1257,
declarativequeries,47, degreeofrelationshipsets,249
1261
1030–1031 degree-twoconsistency,880–881
digitalvideodisks(DVDs),
declarestatement,201–203 deleteauthorization,14
560–561
decode,155–156 deletion
dimensionattributes,524
decomposition B+-treesand,641,645–649
dimensiontables,524
algorithmsfor,330–335 concurrencycontroland,
direct-accessstorage,561
attributesand,305–313, 857–858
directedacyclicgraphs(DAGs),
330–335,339–340 databasemodificationand,
499,506–507,1071–1072
Boyce–Coddnormalform 108–110
directoryaccessprotocols,1084,
and,313–316,330–333 hashingand,1190,
1240–1243
dependencypreservationand, 1194–1195,1198
directoryinformationtrees
315–316,329 integrityconstraintsand,150
(DITs),1242,1243
fourthnormalformand, LSMtreesand,1178–1179
directorysystems,1020,
339–341 ofmessages,1110
1084–1086,1240–1243
functionaldependenciesand, orderedindicesand,624,
dirtyblocks,928–929
308–313,330–341 631–632
dirtypagetable,941–947
highernormalformsand,319 privilegesand,166–167
dirtywrites,822
keysand,309–312 R-treesand,1189
disabletrigger,210
lossless,307–308,307n1, shippingSQLstatementsto
disambiguation,549
312–313 databaseand,187
disconnectedoperation,427–428
lossy,307 SQLschemadefinitionand,
discretizedstreams,508
multivalueddependencies 69,71
and,336–341 transactionsand,801,826 discriminatorattributes,259
normalizationtheoryand, triggersand,208–209 disjointgeneralization,279,290
308 tuplesand,108–110,613 disjointspecialization,272,275
notationalconventionsand, viewsand,142 disjointsubtrees,847
309 deletionentries,668,1178–1179 disjunctiveselection,699,700,
relationaldatabasedesign deltarelation,211 762
and,305–313,330–341 demand-drivenpipeline,726–728 diskarms,565
thirdnormalformand, denial-of-serviceattacks,502 disk-arm–scheduling,578–579
317–319,333–335 denormalization,346 diskblocks,566–567,577–580
decompositionrule,321 denseindices,626–628,630–631 diskbuffer,578,910
decompression,613,615n8 dependencyoftransactions,819 diskcontrollers,565
decorrelation,777–778 dependencypreservation, diskfailure,908
DECRdb,26 315–316,328–330 distincttypes,90,92,98–100,
deduplication,523 derivedattributes,251,252 158–160

--- Page 1339 ---

1310 Index
distinguishedname(DN), validationand,1119–1120 downgrade,843
1241–1242 distributedfilesystems,472–475, drilldown,531,540
distributedautonomous 489,1003,1019–1022 DriverManagerclass,186
organizations(DAOs), distributedhashtables,1013 dropindex,165,664
1272,1272n7 distributed-lockmanager,1112 dropschema,163
distributedconsensusproblem, distributedqueryprocessing, droptable,69,71,190
1106–1107,1151 1076–1086 droptrigger,210
distributeddatabases dataintegrationfrommultiple droptype,159
architectureof,22,986–989, sources,1076–1078 dumping,930–931
1098–1100 directorysystemsand, duplicateelimination,719–720,
autonomyand,988 1084–1086 1049
BigDataand,473,480–481 joinlocationandjoin durability
commitprotocolsand, orderingin,1081–1082 defined,800
1100–1110 acrossmultiplesources, one-safe,933
concurrencycontroland, 1080–1084 remotebackupsystemsand,
990,1105,1111–1120 optimizationand,1084 933–934
consensusin,1106–1107, schemaanddataintegration storagestructureand,
1150–1161,1266,1267 in,1078–1080 804–805
directorysystemsand,1020, semijoinstrategyand, oftransactions,20–21,
1084–1086,1240–1243 1082–1084 800–807
failureand,1104 DITs(directoryinformation two-safe,934
federated,988,1076–1077, trees),1242,1243 two-very-safe,933
1132–1133 Djangoframework,382, DVDs(digitalvideodisks),
filesystemsin,472–475,489, 419–421,433–435,1240 560–561
1003,1019–1022 DKNF(domain-keynormal dynamichandlingofjoinskew,
globaltransactionsand,988, form),341 1048
1098,1132 DML.Seedata-manipulation dynamichashing,661,
heterogeneous,988,1132 language 1195–1203
homogeneous,988 DMLcompiler,20 dynamic-programmingalgorithm,
leasesand,1115–1116 DN(distinguishedname), 767
localtransactionsand,988, 1241–1242 dynamicrepartitioning,
1098,1132 DNS(DomainNameService) 1010–1013
locksand,1111–1116 system,1084,1085 dynamicSQL,66,184,201
nodesand,987 Docker,995 Dynamo,477,489,1024
partitionsand,1104–1105 documentdatabases,3
persistentmessagingand, DocumentObjectModel Eclipse,416
1108–1110,1137 (DOM),423 e-commerce,streamingdataand,
queryoptimizationand,1084 documentstores,477,1023 501
queryprocessingand, domainconstraints,13–14,146 edgeswitches,977
1076–1086 domain-keynormalform efficiencyofdatabases,1,2,5,9
recoveryand,1105 (DKNF),341 e-government,1277
replicationand,987, DomainNameService(DNS) elasticity,992,1010,1024
1121–1128 system,1084,1085 electionalgorithms,1147
sharingdataand,988 domainofattributes,39–40,249 elevatoralgorithm,578
sitesand,986 doublebuffering,725 embeddeddatabases,198,962
snapshotisolationand, double-pipelinedhash-join,731 embeddedmultivalued
1131–1132 double-pipelinedjointechnique, dependencies,341
timestampsand,1116–1118 730–731 embeddedSQL,66,184,
transactionprocessingin, double-spendtransactions, 197–198,965,1269
989–990,1098–1100 1261–1262,1264 emptyrelationstest,101–102

--- Page 1340 ---

Index 1311
encryption UnifiedModelingLanguage entity-relationship(E-R)
AdvancedEncryption and,289–291 modeland,244–246,
Standard,448,449 foruniversityenterprise, 261–264,281–283
applicationsof,447–453 263–264 extensionof,245
asymmetric-key,448 withweakentityset,260 hierarchiesof,273,275
authenticationand,450–453 entity-relationship(E-R)model, identifying,259
blockchaindatabasesand, 244–291 primarykeysand,257
1260–1261 aggregationand,276–277 propertiesof,244–246
challenge-responsesystem alternativenotationsfor relationshipsetsand,
and,451 modelingdata,285–291 246–249,282–283
databasesupportand, atomicdomainsand,342–343 removingredundancyin,
449–450 attributesand,245,248–252, 261–264
dictionaryattacksand,449 274–275,281–282, representationof,265–268
digitalcertificatesand, 342–343 strong,259,265–267
451–453 constraintsand,253–256, subclass,274
digitalsignaturesand,451 275–276 superclass,274
nonrepudiationand,451 databasedesignand(see UnifiedModelingLanguage
primenumbersand,449 databasedesign) and,288–291
private-key,1260–1261 valueand,245
designissuesand,279–285
public-key,448–449, weak,259–260,267–268
developmentof,244
1260–1261 entries,1241
diagrams(see
Rijndaelalgorithmand,448 equality-generatingdependencies,
entity-relationship
symmetric-key,448 337
diagrams)
techniquesof,447–449 equi-depthhistograms,759
entitysetsand,244–246,
endtransactionoperation,799 equi-joins,704,707–713,718,
261–264,281–283
end-userinformation,443 722,730,1043
extendedfeatures,271–279
enterpriseinformation,database equivalence
generalizationand,273–274
applicationsfor,2–4 conflict,815,815n2
mappingcardinalitiesand,
entities,243,244,247–248 costanalysisand,771
252–256
entitygroup,1031 enumerationofexpressions,
normalizationand,344–345
entityrecognition,549 755–757
overview,8
entity-relationship(E-R) joinorderingand,754–755
primarykeysand,256–260
diagrams relationalalgebraand,58,
redundancyand,261–264
aggregationand,279 747–757
relationshipsetsand,
alternativenotationsfor transformationexamplesfor,
246–249,282–285
modelingdata,285–291 752–754
schemasand,244,246,
commonmistakesin, view,818,818n4
269–270,277–279
280–281 equivalencerules,747–752,754,
complexattributesand, specializationand,271–273 771
265–267 UnifiedModelingLanguage equivalentqueries,58
defined,244 and,288–291 equi-widthhistograms,759
entitysetsand,245–246, entitysets eraseblock,568
265–268 alternativenotationsfor, E-Rdiagrams.See
generalizationand,278–279 285–291 entity-relationshipdiagrams
participationillustratedby, attributesand,245,265–267, E-Rmodel.Seeentity-relationship
255 281–282 (E-R)model
reductiontorelational defined,245 escape,83
schema,264–271,277–279 designissuesand,281–283 Ethereum,1258,1262,1265,
relationshipsetsand, entity-relationshipdiagrams 1267–1272,1274
247–250,268–271 and,245–246,265–268 Ethernet,978

--- Page 1341 ---

1312 Index
ETL(extract,transformand externalsort-mergealgorithm, bybuffermanager,19
load)tasks,520,524 701–704 datawarehousingand,526
evaluationprimitive,691 extract,transformandload large-objecttypesand,156,
eventualconsistency,1016,1139 (ETL)tasks,520,524 158
everyfunction,96 extraneousattributes,325 prefetching,969
evictedblocks,605 extraneousfunctional storageand,567,572,587
exactly-oncesemantics,1074 dependencies,324 fiatcurrencies,1252,1273
exceptall,89,97 FiberChannelFCinterface,563
factorials,811
exceptclause,216 FiberChannelProtocol,978
facttables,524
exceptconstruct,102 fifthnormalform,341
failedtransactions,806,907,
exceptionconditions,202 fileheaders,590–591
909
exceptions,187 filemanager,19
fail-stopassumption,908,1267
exceptoperation,88–89 fileorganization,588–602
failurerecovery,21
exchange-operatormodel, blobs,156,193,594,652
falsecycles,1114–1115
1055–1057 blocksand,579,588
falsepositives,1083
exclusivelocks B+-tree,595,650–652,697,
falsevalues,96
biasedprotocoland,1124 697n4
fanout,635
concurrencycontroland, clobs,156,193,594,652
fat-treetopology,977
835–843,888,892,893 distributed,472–475,489,
faulttolerance
degree-twoconsistencyand, 1003,1019–1022
blockchaindatabasesand,
880 fixed-lengthrecordsand,
1276
graph-basedprotocolsand, 589–592
geographicdistributionand,
846–847 hash,595,659
1027
multiplegranularityand, heapfileorganization,
interconnectionnetworks
854–855 595–597
and,978
multiversion,871 indexingand(seeindices)
MapReduceparadigmand,
recoverysystemsand,916 journalingsystems,610
1060–1061
transactionsand,825,928 largeobjectsand,594–595
inquery-evaluationplans,
exclusive-modelocks,835,842 1059–1061 multitableclustering,595,
EXECSQL,197 replicatedstatemachinesand, 598–601
executeprivilege,169–170 1158–1161 nullvaluesand,593
executionskew,1007,1008, shared-diskarchitectureand, partitioningand,601–602
1043 984 pointersand,588,591,
existencebitmaps,1184 withstreamingdata, 594–598,601
existencedependence,259 1074–1076 reorganization,598
existsconstruct,101,102,108 updatesand,1138 sequential,595,597–598
expirationofleases,1115 fault-tolerantkey-valuestore, variable-lengthrecordsand,
explaincommand,746 1160 592–594
explicitlocks,854 fault-tolerantlockmanager,1160 file-processingsystems,5–8
extendablehashing,661,1195, federateddistributeddatabases, filescans,695–697,704–707,
1196 988,1076–1077, 727
ExtensibleMarkupLanguage. 1132–1133 filesystemconsistencycheck,610
SeeXML fetching.Seealsoinformation financialsector,database
extensionofentitysets,245 retrieval applicationsfor,3,1279
extent(blocks),579 advancedSQLand,187–188, fine-grainedlocking,947
externalconsistency,1131 193,195–197,202,205, fine-grainedparallelism,963,970
externaldata,1077 222 firmdeadlines,894
externallanguageroutines, applicationdesignand, firstcommitterwins,874
203–206 421–427,431,437,1218, firstnormalform(1NF),
externalsorting,701 1229 342–343

--- Page 1342 ---

Index 1313
firstupdaterwins,874–875 queryoptimizationand, hash(seehashfunctions)
fiveminuterule,1229 775–777 languageconstructsfor,
fixed-lengthrecords,589–592 renameoperationand,79, 201–203
fixedpointofrecursiveview 81–82 syntaxand,199,201–205
definition,217 setoperationsand,85–89 writinginSQL,198–206
flash-as-bufferapproach,1229 onsinglerelation,71–74 fuzzycheckpoints,922,930,941
flashmemory,567–570 stringoperationsand,82–83 fuzzydump,931
costof,560 subqueriesand,104–105 fuzzylookup,523
eraseblockand,568 fullnodes,1256,1268
hybrid,569–570 fullouterjoins,132–136,722 gasconceptfortransactions,
indexingon,656–657 functionaldependencies 1270–1271
LSMtreesand,1182 algorithmsfordecomposition GAV(global-as-view)approach,
NAND,567–568 using,330–335 1078–1079
NOR,567 attributesetclosureand, generalization
wearlevelingand,568 322–324 attributeinheritanceand,
flashtranslationlayer,568 augmentationruleand,321 274–275
flatMapfunction,496–498 axiomsand,321 bottom-updesignand,273
flexibleschema,366 Boyce–Coddnormalform disjoint,279,290
FlinkCEP,504 and,313–316,330–333 entity-relationship(E-R)
float,67 canonicalcoverand,324–328 modeland,273–274
Flutterframework,428 closureofaset,320–324 overlapping,279,290
followers,1155 decompositionruleand,321 partial,275
forcedoutput,607,912 dependencypreservationand, representationof,278–279
forcepolicy,927 315–316,328–330 subclasssetand,274
forclause,534 extraneous,324 superclasssetand,274
foreachrowclause,207–210, highernormalformsand,319 top-downdesignand,273
212 keysand,309–312 total,275
foreachstatementclause,76, losslessdecompositionand, GeneralizedSearchTree(GiST),
209–210 312–313 670
foreign-currencyexchange,1277 multivalued,336–341 genesisblocks,1254–1255
foreignkeys,45–46,69–70, notationalconventionsand, geographicallydistributed
148–150,267–268,268n5 309 storage,1026–1027
foreigntables,1077 pseudotransitivityruleand, geographicdata
forking,1257,1258,1263 321 applicationsof,391–392
formalstandards,1237 reflexivityruleand,321 examplesof,387
fourthnormalform(4NF),336, inschemadesign,145 overlaysand,393
339–341 theoryof,320–330 rasterdata,392
fragment-and-replicatejoins, thirdnormalformand, representationof,392–393
1046–1047,1062 317–319,333–335 subtypesof,390
fragmentation,579 transitivityruleand,321 topographical,393
freelists,591 trivial,311 vectordata,392–393
free-spacemaps,596–597 unionruleand,321 geographicinformationsystems,
fromclause functionallydetermined 387
aggregatefunctionsand, attributes,322–324 geometricdata,388–390
91–96 functionalquerylanguage,47 getColumnCountmethod,
basicSQLqueriesand,71–79 functions.Seealsospecific 191–192
onmultiplerelations,74–79 functions getConnectionmethod,186,
inmultisetrelationalalgebra, declaring,199–201 186n1
97 externallanguageroutines getFloatmethod,188
nullvaluesand,90 and,203–206 getfunction,477–479

--- Page 1343 ---

1314 Index
GETmethod,440 groupingsetsconstruct,230,538 datastructureand,1195–1196
getStringmethod,188 growingphase,841,843 defined,624
GFS.SeeGoogleFileSystem Gustafson’slaw,974 dynamichashingand,661,
GiST(GeneralizedSearchTree), 1195–1203
hackers.Seesecurity
670 extendablehashingand,661
HadoopFileSystem(HDFS),
Glassfish,416 fileorganizationand,595,
473–475,489–493,971,
global-as-view(GAV)approach, 659
1020–1022
1078–1079 insufficientbucketsand,1194
Halloweenproblem,785
globalindices,1017–1019 linearhashingand,661,1203
handlers,202
GlobalPositioningSystem inmainmemory,658–659
harddeadlines,894
(GPS),1130 harddiskdrives(HDDs).See overflowchainingand,
globalschema,1076,1078–1079 659–660
magneticdisks
globaltransactions,988,1098, harddisks,26 skewand,660,1194
1132
hardforks,1257,1258 statichashingand,661,
globalwait-forgraphs, hardwareRAID,574–576 1190–1195,1202–1203
1113–1114
hardwarethreads,982 tuningof,1215
Google
hardwaretuning,1227–1230 hashjoin
applicationdesignand,
harmonicmean,1231 basicsof,712–714
406–408,410,428–429
hashfileorganization,595,659 buildinputand,713
Bigtable,477,479–480,668,
hashfunctions costof,715–717
1024
Bloomfiltersand,1175–1176 hybrid,717–718
PageRankfrom,385–386,
closed,659,1194 overflowsand,715
493,510
collisionresistant,1259–1260 pipeliningand,728–731
Pregelsystemdevelopedby,
consistent,1013 probeinputand,713
511
cryptographic,1253,
queryoptimizationand,769,
Spanner,1160–1161
1259–1263,1265
771
GoogleFileSystem(GFS),473,
defined,624,659
queryprocessingand,
474,1020,1022
deletion,1190,1194–1195,
712–718,786,1063
GoogleMaps,393
1198
recursivepartitioningand,
GPS(GlobalPositioning
dynamic,661,1195–1203
714–715
System),1130 extendable,661,1195,1196
skewedpartitioningand,715
GPUs(graphicsprocessing insertion,1194–1195,
units),1064 1197–1202 hashpartitioning,476,
1005–1007
grantcommand,170 irreversibilityof,1260
grantedbycurrentrole,172–173 joinsand,1045 hash-tableoverflow,715
grantprivileges,166–167, linear,661,1203
hashtrees.SeeMerkletrees
170–171 lookup,1197,1198, havingclause,95–96,104–105,
graph-basedprotocols,846–848 1202–1203 142
graphdatabases,508–511 open,1194 HBase,477,480,489,668,971,
graphicsprocessingunits partitioningand,1045 1024,1028–1031
(GPUs),1064 passwordsand,1260n4 HDDs(harddiskdrives).See
GraphX,511 queriesand,624,1197–1202 magneticdisks
groupbyclause,92–96,105, static,661,1190–1195, HDFS.SeeHadoopFileSystem
142,221,227–230 1202–1203 head-diskassemblies,565
groupbyconstruct,534, updatesand,624,1197–1202 healthcare,blockchain
536–537 hashindices applicationsfor,1277–1278
groupbycube,536 bucketoverflowand, heapfiles,595–597,1203
groupbyrollup,537 659–660,1194–1195 heart-beatmessages,1147
group-committechnique,925 comparisonwithordered heterogeneousdistributed
groupingfunction,536–537 indices,1203 databases,988,1132

--- Page 1344 ---

Index 1315
heuristics,766,771–774,786, HTTP.SeeHyperTextTransfer IDE(integrateddevelopment
1189 Protocol environment),416
Hibernatesystem,382, hybriddiskdrives,569–570 idempotentoperations,937
431–433,1240 hybridhashjoin,717–718 identifiers
hierarchicalarchitecture,979, hybridmerge-joinalgorithm,712 block,474–475,1020
980,986 hybridOLAP(HOLAP),535 data-item,913
hierarchicalclustering,548 hybridrow/columnstores,615 indicesand,700
hierarchicaldatamodels,26 hypercubes,976–977 logrecordsand,913
hierarchies HyperledgerFabric,1269,1271 queryprocessingand,700
cross-tabulationand,532 hyperlinks,385–386 selectionand,700
ondimensions,531 HyperTextMarkupLanguage transaction,913
ofentitysets,273,275 (HTML) identifyingentitysets,259
relationalrepresentationof, applicationdesignand,404, identifyingrelationship,259–260
533 406–408,426 identitydeclaration,1226
client-sidescriptingand,421
transitiveclosureson,214 identityspecification,161
JavaServerPagesand,
highavailability,907,931–933, identitytheft,447
417–418
987,1121 IDF(inversedocument
securityand,439,440
highavailabilityproxy,932–933 frequency),384
server-sidescriptingand,
higher-levellocks,935–936 IEEE(InstituteofElectricaland
416–418
highernormalforms,319 ElectronicsEngineers),
stylesheetsand,408
histograms 1237
websessionsand,408–411
attributesand,758–760 ifclauses,212
HyperTextTransferProtocol
distributionapproximatedby, if-then-elsestatements,202
(HTTP)
543 immediate-modification
applicationdesignand,
equi-depth,759 technique,915
405–413
equi-width,759 immediateviewmaintenance,
connectionlessnatureof,
examplesof,758–759,1009 779,1215–1216
409–410
joinsizeestimationand, imperativequerylanguage,47
man-in-the-middleattacks
763–764 implicitlocks,854–855
and,442
percentile-based,223 RepresentationStateTransfer incompletenessindatabase
randomsamplesand,761 and,426 design,243–244
range-partitioningvectors securityand,440,452 inconsistentdata,6
and,1009 hyper-threading,982 inconsistentstate,802,803,812
selectionsizeestimationand, hypervisor,994 inconstruct,99
760 incrementalviewmaintenance,
Hive,494,495,500 779–782
IBMDB2
HOLAP(hybridOLAP),535 advancedSQLand,206 incrementlock,892–893
Hollerith,Herman,25 historyof,26 incrementoperation,892
homogeneousdistributed limitclausein,222 independentparallelism,
databases,988 queryoptimizationand,774, 1054–1055
hoppingwindow,505 783 indexednested-loopjoin,
horizontalpartitioning,1004, SpatialExtender,388 707–708,728
1216–1217 statisticalanalysisand,761 indexentries,626
hostlanguage,16,197 triggersyntaxand,212 indexingstrings,653
hot-spareconfiguration,933 typesanddomainssupported index-lockingprotocol,860
hotswapping,575 by,160 index-lockingtechnique,860
householding,523 ICOs(initialcoinofferings), indexrecords,626
HTML.SeeHyperTextMarkup 1272 indexscans,696,698–699,769,
Language IDEF1Xstandard,288 769n2

--- Page 1345 ---

1316 Index
index-sequentialfiles,625, parallel,1017–1019 Ingressystem,26
634–635 performancetuningand,1215 inheritance
indices,623–676,1175–1203 pointersand,700 attribute,274–275
accesstimeand,624, primary,625,695,1017–1018 multiple,275
627–628 queryprocessingand, single,275
accesstypesand,624 695–697 tablesand,379–380
basicconceptsrelatedto, recordrelocationand, typesand,378–379
623–624 652–653 initialcoinofferings(ICOs),
bitmap(seebitmapindices) searchkeysand,624–634 1272
Bloomfiltersand,667, secondary,625,632–633, initializationvector,449
1175–1176,1181 652–653,695–698, initiallydeferredintegrity
B+-tree(seeB+-trees) 1017–1019 constraints,151
buffertreesand,668–670 selectionoperationand, innerjoins,132–136,771
bulkloadingof,653–655 695–697,783 innerrelation,704
clustering,625,632–633, sequential,625,634–635 insertauthorization,14
695,697–698 sortingand,701–704 insertion
comparisonsand,698–699 spaceoverheadand,624, algorithmfor,1180–1181
composite,700 627–628,634,1202 B+-treesand,641–645,647,
concurrencycontroland, sparse,626–632 649
884–887 spatialdataand,672–675, concurrencycontroland,857,
covering,663 1186–1190 858
creationof,664–665, SQLDDLand,67 databasemodificationand,
884–885 stepped-merge,667, 110–111
defined,19 1179–1181 defaultvaluesand,156
definitioninSQL,164–165, oftemporaldata,675–676 hashingand,1194–1195,
664–665 updatesand,630–632 1197–1202
deletiontimeand,624, write-optimizedstructures, LSMtreesand,1177–1178,
631–632,641,645–649 665–670 1180–1181
dense,626–628,630–631 in-doubttransactions,1105 orderedindicesand,624,
onflashstorage,656–657 infeasibility,1259–1260 630–631
GeneralizedSearchTree,670 Infinibandstandard,978 preparedstatementsand,
global,1017–1019 informationextraction,549 188–190
hash(seehashindices) informationretrieval.Seealso privilegesand,166–167
identifiersand,700 queries R-treesand,1188–1189
insertiontimeand,624, defined,382 shippingSQLstatementsto
630–631,641–645,647, keywordsand,383 databaseand,187
649 measuringeffectivenessof, SQLschemadefinitionand,
inverted,721 386 69
key-valuestoresand,1028 PageRankand,385–386 transactionsand,801,826
linearsearchand,695 precisionand,386 viewsand,141–143
local,1017 recalland,386 instances,12,309,547.Seealso
LSMtreesand,666–668, relevancerankingand, traininginstances
1176–1182,1215 383–386 insteadoffeature,143
inmainmemory,657–658 stopwordsand,385 InstituteofElectricaland
materializedviewsand,783 structureddataqueriesand, ElectronicsEngineers
multilevel,628–630 386–387 (IEEE),1237
multiple-keyaccessand, TF-IDFapproachand, insuranceclaims,1278
633–634,661–663 384–385 integrateddevelopment
nonclustering,625,695 infrastructure-as-a-servicemodel, environment(IDE),416
ordered(seeorderedindices) 991 integrityconstraints

--- Page 1346 ---

Index 1317
add,146 joinexpressionsand,125–136 inversedocumentfrequency
altertableand,146 large-objecttypesand,156, (IDF),384
assertionsand,152–153 158 invertedindices,721
assigningnamesto,151 rolesand,167–169 I/Ooperationspersecond
authorization,14 schemas,catalogs,and (IOPS),567,577,578,
checkclauseand,147–149, environments,162–163 693n3
152–153 transactionsand,143–145 I/Oparallelism
createtableand,146–149 typeconversionand hashingand,1005–1007
deferred,151 formattingfunctions, partitioningtechniquesand,
domain,13–14 155–156 1004–1007
examplesof,145 user-definedtypesand, rangeschemeand,1005,1007
infile-processingsystems,6 158–160 round-robinschemeand,
foreignkeysand,148–150 viewsand,137–143 1005,1006
functionaldependencies(see internalnodes,635 IoT(InternetofThings),470,
functionaldependencies) InternationalOrganizationfor 1278
notnull,146,150 Standardization(ISO),65, irrefutability,1257,1259
primarykeysand,147,148 1237, irreversibility,1260
referential,14,46,149–153, 1241
IS(intention-shard)mode,855
207–208,800 Internet.SeeWorldWideWeb
isnotnull,89,90
schemadiagramsof,46–47 InternetofThings(IoT),470,
isnotunknown,90
onsinglerelation,146 1278
isnull,89
spatial,391 interoperationparallelism,1040,
ISO(InternationalOrganization
SQLand,14–15,66,145–153 1052–1055
forStandardization),65,
unique,147 interqueryparallelism,1039
1237,
user-definedtypesand, intersectall,88,97
1241
159–160 intersectionofbitmaps,671,
isolation
violationduringtransactions, 1183
atomicityand,819–821
151–152 intersectionoperation,750,782
cascadelessschedulesand,
integritymanager,19 intersectoperation,54–55,
820–821
Intel,569,1064 87–88
concurrencycontroland,
intention-exclusive(IX)mode, intervaldatatype,154
803–804,807–812,823
855 intra-nodepartitioning,1004
ofdata,6
intentionlockmodes,855 intraoperationparallelism
defined,800
intention-shard(IS)mode,855 aggregationand,1049
factorialsand,811
interconnectionnetworks, defined,1040
improvedthroughputand,
975–979 duplicateeliminationand,
808
interestingsortorder,770 1049
interference,974,1232 mapandreduceoperations inconsistentstateand,803
intermediatekeys,1050 and,1050–1052 levelsof,821–826
intermediateSQL,125–173 parallelexternalsort-merge lockingand,823–825
authorizationand,165–173 and,1042–1043 multipleversionsand,
createtableextensionsand, paralleljoinand,1043–1048 825–826
162 parallelsortand,1041–1043 readcommitted,1225
data/timetypesin,154 projectionand,1049 recoverableschedulesand,
defaultvaluesand,156 range-partitioningsortand, 819–820
generatinguniquekeyvalues 1041–1042 resourceallocationand,808
and,160–161 selectionand,1049 serializabilityand,821–826
indexdefinitionin,164–165 intraqueryparallelism,1039 snapshot(seesnapshot
integrityconstraintsand, invalidationreports,1141 isolation)
145–153 invalidationtimestamps,873n3 timestampsand,825

--- Page 1347 ---

1318 Index
oftransactions,800–804, mappingtodatamodels,480 equi-joins,704,707–713,718,
807–812,819–826 assemi-structureddata 722,730,1043
utilizationand,808 model,8,27 fragment-and-replicate,
waittimeand,808–809 SQLinsupportof,369–370 1046–1047,1062
isunknown,90 fortransferringdata,423 fullouter,132–136,722
iteration,201–202,214–216 JavaServerPages(JSP) hash(seehashjoin)
iterators,727 applicationdesignand,405, hybridmerge,712
IX(intention-exclusive)mode, 417–418 inner,132–136,771
855 securityand,440 innerrelationof,704
server-sidescriptingand, leftouter,131–136,722
JakartaProject,416 417–418 merge-join,708–712,1045
Java.SeealsoJDBC(Java servletsand,417–418 minimizationand,784
DatabaseConnectivity) JavaServlets,411–416,419,424 natural(seenaturaljoins)
advancedSQLand,183,197, JBoss,416 nestedloop(seenested-loop
199,205 JDBC(JavaDatabase join)
applicationdesignand,16, Connectivity),184–193 ordering,754–755
417 blobcolumnand,193 outer,57,131–136,722–723,
metadataand,191–193 765,782
cachingand,435–436
object-orientedprogramming outerrelationof,704
callablestatementsand,
and,377 parallel,1043–1048
190–191
object-relationalmapping partitioned,714–715,
clobcolumnand,193
systemfor,382 1043–1046
connectingtodatabase,
ResilientDistributedDataset queryprocessingand,
185–186
and,496–498 704–719,722–723,
correspondinginterface
UnifiedModelingLanguage 1081–1082
definedby,17
and,289 rightouter,132–136,722
exceptionandresource
JavaDatabaseConnectivity.See semijoinoperation,108,776,
management,187
JDBC 1082–1084
metadatafeaturesand,
Java2EnterpriseEdition sizeestimationand,762–764
191–193
(J2EE),416 skewin,1047–1048
preparedstatementsand,
JavaScript sort-merge-join,708–712
188–190
applicationdesignand, spatial,394
protocolinformation,186
404–405,421–426 spatialdataand,719
retrievingqueryresults,
inputvalidationand,422–423 streamingdataand,506
187–188
interfacingwithwebservices, theta,748–749
423–426 shippingSQLstatementsto, typesandconditions,
RepresentationStateTransfer 186–187 130–131,136
and,426,427 updatableresultsetsand,193 viewmaintenanceand,780
responsiveuserinterfaces websessionsand,409 joinskewavoidance,1048
and,423 joinconditions,130–131 joinusingoperation,129–130
securityand,439 joindependencies,341 journalingfilesystems,610
JavaScriptObjectNotation joinoperation,52–53 JSON.SeeJavaScriptObject
(JSON) joins Notation
applicationsforuse,368–369 ant-ijoinoperation,108,776 JSP.SeeJavaServerPages
defined,368 anti-semijoinoperation, J2EE(Java2Enterprise
emergenceof,27 776–777 Edition),416
encodingresultswith,426 broadcast,1046 jukeboxsystems,561
exampleof,368,369 complex,718
flexibilityof,367–368 costanalysisand,710–712, Kafkasystem,506,507,
key-valuestoresand,1024 767–770 1072–1073,1075,1137

--- Page 1348 ---

Index 1319
k-dBtrees,674 lambdaarchitecture,504,1071 linearscaleup,972–973
KDD(knowledgediscoveryin languageconstructs,201–203 linearsearch,695
databases),540 LanguageIntegratedQuery linearspeedup,972
k-dtrees,673–674 (LINQ),198 linesegments,388–390
kernelfunctions,545 LANs.Seelocal-areanetworks linestrings,388,390
keys largeobjectstorage,594–595 LinkedDataproject,376,1080
candidate,44 large-objecttypes,156,158 LINQ(LanguageIntegrated
clusterkey,600–601 LastLSN,943,946 Query),198
constraintsand,258 latches,886,928 loadbalancers,934–935,1214
encryptionand,448–449, latch-freedatastructure, loadbarrier,983
451–453 888–890 local-areanetworks(LANs),977,
equalityon,697 latency,989 978,985,989
foreign,45–46,69–70, latentfailure,575 local-as-view(LAV)approach,
148–150,267–268,268n5 lateralclause,105 1079
functionaldependenciesand, LAV(local-as-view)approach, localautonomy,988
309–312 1079 localindices,1017
intermediate,1050 lazygenerationoftuples,727 localschema,1076
multipleaccess,633–634, lazypropagationofupdates, localtimestamp,154
661–663 1122,1136 localtransactions,988,1098,
partitioning,475–476 LDAPDataInterchangeFormat 1132
primary(seeprimarykeys) (LDIF),1242 localwait-forgraphs,1113
reduce,485 LDAP(LightweightDirectory lockconversions,843
inrelationalmodel,43–46 AccessProtocol),442, lock-freedatastructure,890
search(seesearchkeys) 1085, lockingprotocols
smartcardsand,451 1240–1243 B-linktree,886
superkeys,43–44,257–258, leaders,1155 concurrencycontroland,
309–310,312 leafnodes,635–656,665–669, 835–848
uniquevalues,160–161 673,674 defined,839
key-valuelocking,887 learners,1148,1153 distributedlock-manager,
key-valuemaps,366–367 leases,1115–1116,1147 1112
key-valuestoragesystems leastrecentlyused(LRU) graph-based,846–848
BigDataand,471,473, strategy,605,607 implementationof,844–846
476–480 ledgers,digital,1251,1252 index,860
clustersand,477 left-deepjoinorders,773 key-value,887
document,477,1023 leftouterjoin,131–136,722 multiplegranularity,856–857
faulttolerant,1160 legacysystems,1035–1036 next-key,887
parallel,1003,1023–1031 legalinstance,309 singlelock-manager,1111
replicationand,476 LevelDB,668 transactionsand,823–825
social-networkingsitesand, Lightningnetwork,1275 two-phase,841–844,871–872,
471 lightnodes,1256,1268 1129–1131
wide-column,1023 LightweightDirectoryAccess lockmanagers,844–845,965,
keywordqueries,383,385–387, Protocol(LDAP),442, 1160
721 1085, lockpoint,841
killingthemutant,1234 1240–1243 locks
knowledgediscoveryindatabases likeoperator,82–83 adaptivegranularityand,
(KDD),540 limitclause,222 969–970
knowledgegraphs,374–375, linearhashing,661,1203 cachingand,969
386–387,549 linearizability,1121 callbackand,969
knowledgerepresentation,368 linearprobing,1194 compatibilityfunctionand,
Kubernetes,995 linearregression,546 836

--- Page 1349 ---

1320 Index
deadlocks(seedeadlocks) logicaloperations parallelkey-valuestoresand,
de-escalationand,970 concurrencycontroland, 1028
distributeddatabasesand, 940–941 performancetuningand,1215
1111–1116 consistencyand,936–937 rollingmergesand,1178
escalationand,857,1227 defined,935 stepped-mergeindicesand,
exclusive(seeexclusivelocks) earlylockreleaseand, 1179–1181
explicit,854 935–941 updatesand,1178–1179
falsecyclesand,1114–1115 idempotent,937 write-optimizedstructureof,
fine-grained,947 logrecordsand,936–940 666–668
grantingof,836,840–841 rollbackand,937–939 logwriterprocess,965
growingphaseand,841,843 logicalroutingoftuples, long-durationtransactions,
higher-level,935–936 506–507,1071–1073 890–891
implicit,854–855 logicalschema,12–13, lookup
increment,892–893 1223–1224 inblockchaindatabases,1268
intentionmodesand,855 logicalundooperations,935–941 Bloomfiltersand,667,1181
leases,1115–1116,1147 logoftransactions,805 concurrencycontroland,
logicalundooperationsand, 884–887
logprocessing,486–488
935–941 data-storagesystemsand,480
logrecords
lower-level,935–936 fuzzy,523
ARIESand,941–946
multiplegranularityand, hashingand,1197,1198,
bufferingand,926–927
853–857 1202–1203
checkpoint,943
multiversionschemesand, indicesand,630,637,
compensation,922,942,945
871–872,1129–1131 640–641,645–651,
databasemodificationand,
predicate,828,861,861n1 656–661,666–669,676
915–916
recoverysystemsand, LSMtreesand,1181
force/no-forcepolicyand,927
935–941 queryoptimizationand,769
identifiersand,913
requestoperationand, queryprocessingand,698,
logicalundooperationsand,
835–841,844–846, 707
936–940
849–853,886 losslessdecomposition,307–308,
old/newvaluesand,913
shared,825,835,854,880, 307n1,312–313
1124 physical,936 lossydecompositions,307
shrinkingphaseand,841,843 recoverysystemsand, lostupdateproblem,1016
starvationand,853 913–919,926–927 lostupdates,874
timeoutsand,850–851 redooperationand,915–919 lower-levellocks,935–936
timestampsand,861–866 steal/no-stealpolicyand,927 loyaltyprograms,1278
transactionserversand, undooperationand,915–919 LRU(leastrecentlyused)
965–968 write-aheadloggingruleand, strategy,605,607
truematrixvalueand,836 926–929 LSMtrees.Seelog-structured
wait-forgraphand,851–852, logsequencenumber(LSN), mergetrees
1113–1114 941–946 LSN(logsequencenumber),
locktable,844,845,967 log-structuredmerge(LSM) 941–946
logdisks,610 trees,1176–1182
logforce,927 basic,1179 machine-learningalgorithms,495
logicalclock,1118 Bloomfiltersand,1181 magneticdisks,563–567
logicalcounter,862 deletionand,1178–1179 accesstimeand,561,566,567
logical-designphase,18,242 forflashstorage,1182 blocksand,566–567
logicalerror,907 insertioninto,1177–1178, capacityof,560
logicallevelofabstraction,9–12 1180–1181 checksumsand,565
logicallogging,936 levelsof,1176 crashesand,565
logicallyimpliedschema,320 lookupand,1181 data-transferrateand,566

--- Page 1350 ---

Index 1321
diskcontrollerand,565 markuplanguages.Seespecific non-volatilerandom-access,
failureclassificationand,908 languages 579–580
hybrid,569–570 massivelyparallelsystems,970 optical,560–561
meantimetofailureand,567 masternodes,1012,1136 overflowsand,715
performancemeasuresof, masterreplica,1016 querycostsand,697
565–567 mastersites,1026 queryprocessingin,731–734
physicalcharacteristicsof, master-slavereplication,1137 recoverysystemsand,
563–565 mastertable,1222 910–912
read-writeheadsand, matchclause,509 storageclass,569,588,948
564–565 materialization,724–725 memorybarrier,983–984
recordingdensityand,565 materializededges,728 merge-join,708–712,1045
sectorsand,564–566 materializedviews merge-purgeoperation,523
seektimeand,566,566n2, aggregationand,781–782 merging
567 defined,140,778 duplicateeliminationand,
719–720
sizesof,563 indexselectionand,783
exchange-operatormodeland,
mainmemory,559–560, joinoperationand,780
1055–1057
657–658 parallelmaintenanceof,
ordered,1056
main-memorydatabases 1069–1070
parallelexternalsort-merge,
accessingdatain,910 performancetuningand,
1042–1043
concurrencycontrolin, 1215–1216
performancetuningand,
887–890 projectionand,780–781
1222–1223
recoveryin,947–948 queryoptimizationand,
queryprocessingand,
storagein,588,615–617 778–783
701–704,708–712
majorityprotocol,1123–1126 selectionand,780–781
random,1056
managementofdata.See viewmaintenanceand,140,
rollingmerge,1178
database-management 779–782
Merkle-Patriciatrees,1269,
systems maxfunction,91–92,105,723,
1275
(DBMSs) 766,782
Merkletrees,1143–1146,1268,
man-in-the-middleattacks,442 maximummarginline,544
1269
manufacturing,database meantimebetweenfailures
meshsystem,976
applicationsfor,3,5 (MTBF),567n3
MESIprotocol,984
many-to-manymapping,253–255 meantimetodataloss,571
message-basedconsensus,1266
many-to-onemapping,252–255 meantimetofailure(MTTF),
messagedeliveryprocess,
mapfunction,483–494,510.See 567,567n3
1109–1110
alsoMapReduceparadigm meantimetorepair,571
metadata,14,191–193,470,
mappingcardinalities,252–256 measureattributes,524 602–604,1020–1022
MapReduceparadigm,483–494 mediators,1077 microservicesarchitecture,994
developmentof,27,481 memcachedsystem,436–437, Microsoft
faulttoleranceand, 482 applicationdesignand,417,
1060–1061 memoization,771 442
inHadoop,489–493 memory.Seealsostorage DatabaseTuningAssistant,
intraoperationparallelism bulkloadingofindicesand, 1217
and,1050–1052 653–655 querylanguagesdevelopedby,
logprocessingand,486–488 cache,559(seealsocaching) 538
parallelprocessingoftasks, dataaccessand,910–912 queryoptimizationand,783
488–489 flash,560,567–570,656–657 StreamInsight,504
SQLon,493–494 forceoutputand,912 MicrosoftSQLServer
wordcountprogramand, magnetic-disk,560,563–567 advancedSQLand,206
483–486,484n2,490–492 main,559–560,657–658 implements,160

--- Page 1351 ---

1322 Index
limitclausein,222 intention-exclusivemodeand, MySQL
performancemonitoring 855 attributesand,149n8
tools,1212 intention-sharedmodeand, growthof,27
performancetuningtools, 855 joinsand,133n4
1218 lockingprotocoland, LSMtreesand,668
procedurallanguages 856–857 performancemonitoring
supportedby,199 requestoperationand,854, tools,1212
snapshotisolationand,1225 855 stringoperationsand,82
spatialdataand,388,390 sharedandintention-exclusive uniquekeyvaluesin,161
stringoperationsand,82 modeand,855
minfunction,91–92,723,766, treearchitectureand, naÃ¯veBayesianclassifiers,543
782 853–857 naÃ¯veusers,24
minibatchtransactions,1227 multipleinheritance,275 namenode,475,1020
minimalequivalencerules,754 multiple-keyaccess,633–634, NANDflashmemory,567–568
miningpools,1266.Seealsodata 661–663 NAS(networkattachedstorage),
mining multiprogramming,809 563,934
minus,88n7 multiqueryoptimization, naturaljoinoperation,57
mirroring,571–573,576,577 785–786 naturaljoins,126–136
mobileapplicationplatforms, multisetexcept,88n7 onconditionand,130–131
428–429 multisetrelationalalgebra,80, conditionsand,130–131
mobilephoneapplications,469 97,108,136,747 fullouter,132–136,722
modelsfordatamining,540 multisettypes,366 inner,132–136,771
model-view-controller(MVC) multisiginstruction,1269–1270 leftouter,131–136,722
architecture,429–430 multitableclusteringfile outer,57,131–136
MOLAP(multidimensional organization,595, rightouter,132–136,722
OLAP),535 598–601 navigationsystems,database
MonetDB,367,615 multitasking,961,963 applicationsfor,3
MongoDB,477–479,482,489, multiusersystems,962 nearest-neighborqueries,394,
668,1024,1028 multivaluedattributes,251,252, 672,674
monotonicqueries,218 342 nearnessqueries,394
Moore’slaw,980n4 multivalueddatatypes,366–367 negation,762
mostrecentlyused(MRU) multivalueddependencies, Neo4jgraphdatabase,509,510
strategy,608–609 336–341 nesteddatatypes,367–368
MRU(mostrecentlyused) multiversionconcurrencycontrol nested-loopjoin
strategy,608–609 (MVCC),869–872 block,705–707
MTBF(meantimebetween multiversiontimestamp-ordering indexed,707–708,728
failures),567n3 scheme,870–871,1118 parallel,1045–1046
MTTF(meantimetofailure), multiversiontwo-phaselocking queryoptimizationand,768,
567,567n3 (MV2PL)protocol, 769,771,773
multidimensionaldata,524, 871–872, queryprocessingand,
527–532 1129–1131 704–708,713–719,722,
multidimensionalOLAP mutations,1234 786
(MOLAP),535 mutualexclusion,965,967 nestedsubqueries,98–107
multilevelindices,628–630 MVCC(multiversionconcurrency fromclauseand,104–105
multimasterreplication,1137 control),869–872 withclauseand,105–106
multipleconsensusprotocol,1151 MVC(model-view-controller) duplicatetuplesand,103
multiplegranularity architecture,429–430 emptyrelationstestand,
concurrencycontroland, MV2PL(multiversiontwo-phase 101–102
853–857 locking)protocol,871–872, optimizationof,774–778,
hierarchyof,854 1129–1131 1220

--- Page 1352 ---

Index 1323
scalar,106–107 ringarchitectureand,976 inconceptual-designprocess,
setoperationsand,98–101 splittingof,641–645,886 17
nesting,854,946 straggler,1060–1061 denormalization,346
NetBeans,416 updatesand,641–647 entity-relationship(E-R)
networkattachedstorage(NAS), virtual,1009–1010 modeland,344–345
563,934 no-forcepolicy,927 performanceand,346
networklatency,969 nonbinaryrelationshipsets, relationaldatabasedesign
networkpartition,481,989, 283–285 and,308
989n5,1104–1105 non-blockingtwo-phasecommit, NoSQLsystems,28,473,477,
networkround-triptime,969 1161 1269,1276
networks nonces,1265,1271 no-stealpolicy,927
deepneural,546 nonclusteringindices,625,695 notconnective,74
interconnection,975–979 nondeclarativeactions,183 notexistsconstruct,101–102,
localarea,977,978,985,989 nonfirst-normal-form(NFNF), 108,218
spatial,390 367 notifications,436
wide-area,989 nonleafnodes,635–636,642, notinconstruct,99,100
neural-netclassifiers,545–546 645–656,663 notnull,69,89–90,142,146,
newvalue,913 nonproceduralDMLs,15 150,159
next-keylockingprotocols,887 nonprocedurallanguages,15,16, notoperation,89–90
nextmethod,188 18,26 notuniqueconstruct,103
nextvalfor,1226 nonrepudiation,451 nullbitmap,593
NFNF(nonfirst-normal-form), Non-UniformMemoryAccess nullrejectingproperty,751
367 (NUMA),981,1063 nullvalues
nodes nonuniquesearchkeys,632,637, aggregationwith,96
inblockchaindatabases, 640,649–650 attributesand,251–252
1255–1257,1263–1268 Non-VolatileMemoryExpress defined,40,67
coalescing,641,886 (NVMe)interface,562 fileorganizationand,593
datanodes,475,1020 non-volatilerandom-access integrityconstraintsand,
defined,468 memory(NVRAM), 145–147,150
distributeddatabasesand, 579–580,948 SQLand,89–90
987 non-volatilestorage,560,562, temporaldataand,347
failureof,1103–1104 587–588,804,908–910, triggersand,209
full,1256,1268 930–931 user-definedtypesand,159
inHadoopFileSystem,474, non-volatilewritebuffers, NUMA(Non-UniformMemory
475 579–580 Access),981,1063
internal,635 NORflashmemory,567 numeric,67,70
leaf,635–656,665–669,673, normalforms nvarchar,68
674 atomicdomainsand,342–343 NVMe(Non-VolatileMemory
leasesand,1115–1116 Boyce–Codd,313–316, Express)interface,562
light,1256,1268 330–333,336 NVRAM(non-volatile
master,1012,1136 domain-key,341 random-accessmemory),
mesharchitectureand,976 fifth,341 579–580,948
multiplegranularityand, first,342–343 N-waymerge,702
853–857 fourth,336,339–341
namenode,475,1020 higher,319 OAuthprotocol,443
nonleaf,635–636,642, joindependenciesand,341 obfuscation,1235
645–656,663 project-join,341 object-baseddatabases
operation,506–507 second,316n8,341–342,356 arraytypesand,378
inparalleldatabases,970 third,317–319,333–335 complexdatatypesand,
primary,1123 normalization 376–382

--- Page 1353 ---

1324 Index
inheritanceand,378–380 OLAP.Seeonlineanalytical openhashing,1194
mappingand,377,381–382 processing OpenIDprotocol,443
overview,9 oldvalue,913 openpolygons,388n3
referencetypesand,380–381 OLE-DB,1239 opentimeintervals,675
objectclasses,1242 OLTP(onlinetransaction operationconsistentstate,
ObjectDatabaseManagement processing),4,521, 936–937
Group(ODMG), 1231–1232 operationnodes,506–507
1239–1240 OMG(ObjectManagement operationserializability,885
ObjectManagementGroup Group),288 operatortrees,724,1040
(OMG),288 oncondition,130–131 opticalstorage,560–561
objectoftriples,372 ondeletecascade,150,210, optimisticconcurrencycontrol,
object-orienteddatabases 268n5 869
(OODB),9,26,377,431, 1NF(firstnormalform), optimisticconcurrencycontrol
1239–1240 342–343 withoutreadvalidation,
one-to-manymapping,252–255 883,
object-relationaldatabases,
one-to-onemapping,252–254 891
377–381
onlineanalyticalprocessing optimizationcostbudget,774
defined,377
(OLAP),527–540 Oracle
referencetypesand,380–381
aggregationon advancedSQLand,206
tableinheritanceand,
multidimensionaldata, applicationserver,416
379–380
527–532 databasedesignand,443n6,
typeinheritanceand,
cross-tabulationand,528–533 444–445
378–379
datacubesand,529–530 decodefunctionin,155
user-definedtypes,378
defined,520,530 EventProcessing,504
object-relationaldatamodels,27,
dicingand,530 GeoRasterextension,367
376–382
drilldownand,531,540 historyof,26
object-relationalmapping
hybrid,535 JDBCinterfaceand,185,186
(ORM),377,381–382,
implementationof,535 keywordsin,81n3,88n7
431–434,
multidimensional,535 limitclausein,222
1239–1240
performancebenchmarks nestedsubqueriesand,104
observableexternalwrites,807
and,1231–1232 performancemonitoring
ODBC(OpenDatabase
relational,535 tools,1212
Connectivity)
reportingandvisualization performancetuningtools,
advancedSQLand,194–197
tools,538–540 1218
APIdefinedby,194–195
rollupand,530–531,536–538 procedurallanguages
applicationinterfacesdefined
slicingand,530 supportedby,199
by,17
inSQL,533–534,536–538 query-evaluationplansand,
cachingand,436
onlineindexcreation,884–885 746
conformancelevelsand, onlinestorage,561 queryoptimizationand,773,
196–197 onlinetransactionprocessing 774,783
standardsfor,1238–1239 (OLTP),4,521, referencetypesand,380
typedefinitionand,196 1231–1232 setandarraytypessupported
websessionsand,409 onupdatecascade,150 by,367
ODMG(ObjectDatabase OODB.Seeobject-oriented snapshotisolationand,1225
ManagementGroup), databases SpatialandGraph,388
1239–1240 openaddressing,1194 statisticalanalysisand,761
off-chaintransactions,1275 OpenDatabaseConnectivity.See syntaxsupportedby,204,
offlinestorage,561 ODBC 212,218,218n9
OGC(OpenGeospatial OpenGeospatialConsortium transactionsand,822,826,
Consortium),388 (OGC),388 872–873,879

--- Page 1354 ---

Index 1325
typesanddomainssupported coarse-grain,963,970 parallelexternalsort-merge,
by,160 concurrencycontroland,990 1042–1043
VirtualPrivateDatabase,173, defined,480 parallelindices,1017–1019
444–445 exchange-operatormodeland, parallelism
oracles,1271–1272 1055–1057 coarse-grained,963
ORC,490,499,613–614 fine-grain,963,970 data,1042,1057
orconnective,74 hierarchical,979,980,986 fine-grained,963
orderbyclause,83–84, indicesin,1017–1019 improvementofperformance
219–222,534 interconnectionnetworks via,571–572
orderedindices,624–634 and,975–979 independent,1054–1055
comparisonwithhash interferenceand,974 interoperation,1040,
indices,1203 interoperationparallelism 1052–1055
defined,624 and,1040,1052–1055 interquery,1039
dense,626–628,630–631 interqueryparallelismand, intraoperation,1040–1052
multilevel,628–630 1039 intraquery,1039
secondary,625,632–633 intraoperationparallelism I/O(seeI/Oparallelism)
sequential,625,634–635 and,1040–1052 SingleInstructionMultiple
sparse,626–632 intraqueryparallelismand, Data,1064
techniquesfor,624 1039 paralleljoins,1043–1048
updatesand,630–632 I/Oparallelismand, fragment-and-replicate,
orderedmerge,1056 1004–1007 1046–1047,1062
ORM.Seeobject-relational key-valuestoresand, hash,1045
mapping 1023–1031 nested-loop,1045–1046
oroperation,89–90 massivelyparallel,970 partitioned,1043–1046
orphanedblocks,1257,1263 motivationfor,970–971 skewin,1047–1048
outer-joinoperation,57, operatortreesand,1040 parallelkey-valuestores,
131–136,722–723,765, partitioningtechniquesand, 1023–1031
782 1004–1007 atomiccommitand,1029
outerrelation,704 performancemeasuresfor, concurrencycontroland,
outerunionoperations,229n16 971–974 1028–1029
outsourcing,28 pipelinesand,1053–1054 datarepresentationand,
overflowavoidance,715 queryoptimizationand, 1024–1025
overflowblocks,598 1064–1070 defined,1003
overflowbuckets,659–660, replicationand,1013–1016 elasticityand,1024
1194–1195 responsetimeand,971–972 failuresand,1029–1030
overflowchaining,659–660 scaleupand,972–974 geographicallydistributed,
overflowresolution,715 shareddisk,979,980, 1026–1027
overlappinggeneralization,279, 984–985 indexstructureand,1028
290 sharedmemory,979–984, managingwithoutdeclarative
overlappingspecialization,272, 1061–1064 queries,1030–1031
275 sharednothing,979,980, overview,1023–1024
overlays,393 985–986,1040–1041, performanceoptimizations
1061–1063 and,1031
page(blocks),567 skewand,974,1007–1013, storingandretrievingdata,
PageLSN,942–945 1043,1062 1025–1028
PageRank,385–386 speedupand,972–974 supportfortransactions,
pageshipping,968 start-upcostsand,974,1066 1028–1030
paralleldatabases throughputand,971 parallelprocessing,437,
architectureof,22,970–986 transactionprocessingin, 488–489
BigDataand,473,480–481 989–990 parallelqueryplans

--- Page 1355 ---

1326 Index
choosing,1066–1068 horizontal,1004,1216–1217 benchmarks(seeperformance
colocationofdataand, intra-node,1004 benchmarks)
1068–1069 joinsand,714–715, ofblockchaindatabases,
costof,1065–1066 1043–1046 1274–1276
evaluationof,1052–1061 network,481,989,989n5, B+-treesand,634,665–666
materializedviewsand, 1104–1105 cachingand,435–437
1069–1070 paralleldatabasesand, data-transferrateand,566
spacefor,1064–1065 1004–1007 denormalizationfor,346
parallelsort,1041–1043 pointqueriesand,1006 improvementviaparallelism,
parameterizedviews,200 queryoptimizationand,1065 571–572
parameterstylegeneral,205 range,476,1005,1007,1178 magneticdiskstorageand,
parametricqueryoptimization, recursive,714–715 565–567
786 ofrelationschema,1216–1217
meantimetofailureand,567,
paritybits,572,574,577 round-robin,1005,1006 567n3
Parquet,490,499 scanningarelationand,1006
monitoringtools,1212
parsing shardingand,473,475–476,
paralleldatabasesand,
applicationdesignand,418 1275
971–974
bulkloadsand,1221–1223 skewand,715,1007–1013
parallelkey-valuestoresand,
queryprocessingand, topic-partition,1073
1031
689–690 vertical,1004
parallelprocessingand,437
partialaggregation,1049 virtualnode,1009–1010
responsetime(seeresponse
partialdependency,356 partitiontables,1011–1014
time)
partialfailure,909 passwords
seektimeand,566,566n2,
partialgeneralization,275 applicationdesignand,403,
567,692,710
partiallycommittedtransactions, 411,414,432,450–451
sequentialindicesand,
806 dictionaryattacksand,449
634–635
partialparticipation,255 distributeddatabasesand,
testing,1235
partialrollback,853 1240
throughput(seethroughput)
partialschedules,819 hashfunctionsand,1260n4
tuning(seeperformance
partialspecialization,275 leakageof,440–441
tuning)
participationinrelationshipsets, man-in-the-middleattacks
webapplicationsand,
247 and,442
405–411
partitioningattribute,479 one-time,441
performancebenchmarks,
partitioningkeys,475–476 singlesign-onsystemand,
1230–1234
partitioningvector,1005 442–443
database-applicationclasses
partitions SQLand,163,186,196
and,1231–1232
balancedrange,1008–1009 storageand,602,603
defined,1230
data,989n5 unencrypted,414n4
defined,1100 pathexpressions,372,381 suitesoftasksand,1231
distributeddatabasesand, patternmatching,504 ofTransactionProcessing
1104–1105 Paxosprotocol,1152–1155, PerformanceCouncil,
distributedfilesystemsand, 1160–1161,1267 1232–1234
473 PCIeinterface,562 performancetuning,1210–1230
dynamicrepartitioning, pendrives,560 automated,1217–1218
1010–1013 performance bottlenecklocationsand,
exchange-operatormodeland, accesstimeand,561, 1211–1213,1215,1227
1055–1057 566–567,578,624, bulkloadsand,1221–1223
fileorganizationand, 627–628,692 ofconcurrenttransactions,
601–602 applicationdesignand, 1224–1227
hash,476,1005–1007,1045 434–437 ofhardware,1227–1230

--- Page 1356 ---

Index 1327
horizontalpartitioningof costperbyte,560,561, concurrencycontroland,
relationschema, 566n2,569,576 886,888,889
1216–1217 disk-blockaccessand, queryprocessingand,697,
indicesand,1215 577–580 698,700,708
levelsof,1213–1214 flashmemory,560,567–570, recoverysystemsand,914,
materializedviewsand, 656–657 945
1215–1216 hierarchyof,561,562 redistributionof,646
motivationfor,1210–1211 indicesand,630n2 SQLbasicsand,193,205
parameteradjustmentand, interfacesfor,562–563 storageand,588,591,
1210,1213–1215,1220, magneticdisks,560,563–567 594–598,601
1228,1230 mainmemory,559–560 pointqueries,1006,1190
physicaldesignand, opticalstorage,560–561 polygons,388–390,388n3,393
1217–1218 RAID,562,570–577 polylines,388–389,388n3
ofqueries,1219–1223 solid-statedrives,18,560 population,547
RAIDand,1214,1229–1230 tapestorage,561 PostgreSQL
ofschema,1214–1218, volatilityof,560,562 advancedSQLand,206
1223–1224 physiologicalredooperations, arraytypeson,378
setorientationand, 941 concurrencycontroland,873,
1220–1221 PigLatin,494 879
simulationand,1230 pincount,605 GeneralizedSearchTreeand,
toolsfor,1218 pinnedblocks,605 670
updatesand,1221–1223, pinoperations,605 growthof,27
1225–1227 pipelinededges,728 heapfileorganizationand,
perioddeclaration,157 pipelinestage,728 596
Perl,206 pipelining,724–731 JDBCinterfaceand,185
permissionedblockchains, benefitsof,726 JSONand,370
1253–1254,1256–1257, forcontinuous-streamdata, performancemonitoring
1263,1266, 731 tools,1212
1274 demand-driven,726–728 PostGISextension,367,388,
persistentmessaging,990,1016, evaluationalgorithmsfor, 390
1108–1110,1137 728–731 procedurallanguages
PersistentStorageModule implementationof,726–728 supportedby,199
(PSM),201 parallelismand,1053–1054 query-evaluationplansand,
phantomphenomenon,827, producer-driven,726–728 746
858–861,877–879,877n5, usesfor,691–692,724,725 queryprocessingand,692,
885,887 pivotattribute,227 694,698–699
PHP,405,417,418 pivotclause,227,534 setandarraytypessupported
physicalblocks,910 pivoting,226–227,530 by,367
physicaldataindependence, pivot-table,226–227,528–529 snapshotisolationand,1225
9–10,13 PJNF(project-joinnormalform), statisticalanalysisand,761
physical-designphase,18, 341 transactionmanagementin,
242–243 plancaching,774 822,826
physicalequivalencerules,771 platform-as-a-servicemodel, typesanddomainssupported
physicallevelofabstraction,9, 992–993 by,160
11,12,15 platters,563,565 uniquekeyvaluesin,161
physicallogging,936 PL/SQL,199,204 P+Qredundancyschema,573,
physicalschema,12,13 pointers.Seealsoindices 574
physicalstoragesystems, blockchaindatabasesand, PracticalByzantineFault
559–580 1254–1255,1261,1269 Tolerance,1267
cachememory,559 B+-tree(seeB+-trees) precedencegraph,816–817

--- Page 1357 ---

1328 Index
precision,386 procedurallanguages,47n3,184, punctuations,503–504
precisionlocking,861n1 199,204 pushingdata,727
predicatelocking,828,861, procedures putfunction,477,478
861n1 declaring,199–201 puzzlefriendliness,1265
predicateoftriples,372 externallanguageroutines PWA(ProgressiveWebApps),
predicatereads,858–861 and,203–206 429
prediction,541–543,545–546 languageconstructsfor, Python
predictivemodels,4–5 201–203 advancedSQLand,183,
preemption,850 syntaxand,199,201–205 193–194,206
prefetching,969 writinginSQL,198–206 applicationdesignand,16,
prefixcompression,653 processmonitorprocess,965 405,416,419
Pregelsystem,511 producer-drivenpipeline, object-orientedprogramming
preparedstatements,188–190 726–728 and,377
presentationlayer,429 programminglanguages.Seealso object-relationalmapping
priceperTPS,1232 specific systemfor,382
primarycopy,1123 languages webservicesand,424
primaryindices,625,695, accessingSQLfrom,183–198
1017–1018 mismatchand,184 quadraticsplitheuristic,1189
primarykeys object-oriented,377 quads,376
attributesand,310n4 variableoperationof,184 quadtrees,392,674,1186–1187
defined,44 ProgressiveWebApps(PWA), queries.Seealsoinformation
entity-relationship(E-R) 429 retrieval
modeland,256–260 projection ADO.NETand,184
functionaldependenciesand, intraoperationparallelism basicstructureofSQL
313 and,1049 queries,71–79
integrityconstraintsand,147, queryoptimizationand,764 onB+-trees,637–641,690
148 queryprocessingand,720 cachingand,435–437
inrelationalmodel,44–46 viewmaintenanceand, Cartesianproductand,
SQLschemadefinitionand, 780–781 76–79,81,230
68–70 project-joinnormalform(PJNF), compilationof,733
primarynodes,1123 341 continuous,503,731
primarysite,931 projectoperation,49–50 correlatedsubqueriesand,
primarystorage,561 proof-of-stakeconsensus,1256, 101
primeattributes,356 1266 costof(seequerycost)
privacy,438,446,1252 proof-of-workconsensus,1256, decision-support,521,971
private-keyencryption, 1264–1266 declarative,1030–1031
1260–1261 proposers,1148,1152 defined,15
privileges proximityofterms,385 deletionand,108–110
all,166 PRquadtrees,1187 equivalent,58
defined,165 pseudotransitivityrule,321 evaluationof(see
execute,169–170 PSM(PersistentStorage query-evaluationplans)
granting,166–167,170–171 Module),201 hashfunctionsand,624,
public,167 publicblockchains,1253,1255, 1197–1202
references,170 1257–1259,1263,1264 indicesand,623,695–697,
revoking,166–167,171–173 public-keyencryption,448–449, 707–708
select,171,172 1260–1261 insertionand,110–111
transferof,170–171 publish-subscribe(pub-sub) intermediateSQLand(see
update,170 systems,507,1072, intermediateSQL)
probeinput,713 1137–1139 JDBCand,184–193
proceduralDMLs,15 pullingdata,727 joinexpressionsand,125–136

--- Page 1358 ---

Index 1329
keyword,383,385–387,721 querycost distributed,1084
languages(seequery optimizationand,745–746, equivalenceand,747–757
languages) 757–766 estimatingstatisticsof
metadataand,191–193 processingand,692–695, expressionresults,757–766
monotonic,218 697,702–704,710–712, heuristicsin,766,771–774,
multiple-keyaccessand, 715–717 786
661–663 query-evaluationengine,20 hybridhashjoinand,717–718
onmultiplerelations,74–79 query-evaluationplans indexednested-loopjoinand,
nearest-neighbor,394,672, choiceof,766–778 707–708
674 costof,1065–1066 joinminimizationand,784
nestedsubqueries,98–107 defined,691 materializedviewsand,
nullvaluesand,89–90 expressionsand,724–731 778–783
ODBCand,194–197 faulttolerancein,1059–1061 multiquery,785–786
optimizationof(seequery materializationand,724–725 nestedsubqueriesand,
optimization) optimizationand(seequery 774–778,1220
PageRankand,385–386 optimization) paralleldatabasesand,
performancetuningof, parallel(seeparallelquery 1064–1070
1219–1223 plans) parametric,786
point,1006,1190 performancetuningof, planchoicefor,766–778
processing(seequery 1219–1220 projectionand,764
processing) pipeliningand,691–692, relationalalgebraand,
programminglanguageaccess 724–731 743–749,752,755
and,183–198 relationalalgebraand, roleinqueryprocessing,689,
Pythonand,193–194 690–691 690
range,638,672,674,1006, resourceconsumptionand, setoperationsand,764–765
1190 694–695,1065–1066 sharedscansand,785–786
readonly,1039 responsetimeand,694–695 top-K,784
recursive,213–218 roleinqueryprocessing,689, transformationsand,747–757
region,393–394 690 updatesand,784–785
renameoperationand,79, viewing,746 queryprocessing,689–734
81–82 query-executionengine,691 adaptive,786–787
ResultSetobjectand,185, query-executionplans,691 aggregationand,723
187–188,191–193, querylanguages.Seealsospecific basicstepsof,689,690
638–639 languages BigDataand,470–472
retrievingresults,187–188 accessingfromprogramming blockchaindatabasesand,
scalarsubqueries,106–107 languages,183–198 1254,1275–1276
securityand,437–446 categorizationof,47 comparisonsand,698–699
servletsand,411–421 Cypher,509 costanalysisof,692–695,
setoperationsand,85–89, defined,15,47 697,702–704,710–712,
98–101 inrelationalmodel,47–48 715–717
onsinglerelation,71–74 SPARQL,375–376 CPUspeedsand,692
spatial,393–394 stream,503–506 DDLinterpreterin,20
spatialgraph,394 queryoptimization,743–787 defined,689
streamingdataand,502–506, adaptive,786–787 distributeddatabasesand,
1070–1071 aggregationand,764 1076–1086
stringoperationsand,82–83 Cartesianproductand,748, DMLcompilerin,20
transactionserversand,965 749,755,763–764,775 duplicateeliminationand,
universalTuringmachines costanalysisand,745–746, 719–720
and,16 757–766 evaluationofexpressions,
viewsand,137–143 defined,20,691,743 724–731

--- Page 1359 ---

1330 Index
filescansand,695–697, range-partitioningvector, buffermanagementand,
704–707,727 1008–1009 926–930
hashingand,712–718,1063 rangequeries,638,672,674, checkpointsand,920–922,
historyof,26–27 1006,1190 930
identifiersand,700 ranking,219–223,383–386 commitprotocolsand,1105
indicesand,695–697 rasterdata,392 concurrencycontroland,916
joinoperationand,704–719, RDDs(ResilientDistributed dataaccessand,910–912
722–723,1081–1082 Datasets),496–499,1061 databasemodificationand,
materializationand,724–725 RDF.SeeResourceDescription 915–916
inmemory,731–734 Framework distributeddatabasesand,
operationevaluationand, RDMA(remotedirectmemory 1105
690–691 access),979 earlylockreleaseand,
parsingandtranslationin, RDNs(relativedistinguished 935–941
689–690 names),1241–1242 fail-stopassumptionand,908,
pipeliningand,691–692, reactionarystandards,1237 1267
724–731 ReactNativeframework,428 failureand,907–909,
PostgreSQLand,692,694, read-ahead,578 930–932
698–699 readauthorization,14 force/no-forcepolicyand,927
projectionand,720 readcommitted,821,880,1225 logicalundooperationsand,
recursivepartitioningand, readcost,1127–1128 935–941
714–715 readone,writeallcopies logrecordsand,913–919,
relationalalgebraand, protocol,1125 926–927
689–691 readone,writeallprotocol,1125 logsequencenumberand,
scalabilityof,471–472 readonlyqueries,1039 941–946
selectionoperationand,
read-onlytransactions,871 main-memorydatabasesand,
695–700
readphase,866 947–948
setoperationsand,720–722
readquorum,1124 redooperationand,915–919,
onshared-memory
readuncommitted,821 922–925
architecture,1061–1064
read-writecontention, remotebackup,909,931–935
sortingand,701–704
1224–1225 rollbackand,916–919,922
SQLand,689–690,701,720
readystate,989,1102 shadow-copyschemeand,914
syntaxand,689
real,doubleprecision,67 snapshotisolationand,916
queryprocessor,18,20
real-timetransactionsystems, steal/no-stealpolicyand,927
query-serversystems,963
894 storageand,908–912,
queueingsystems,1212–1213
rebuildperformance,576 920–922,930–931
queueingtheory,1213
recall,386 successfulcompletionand,
quorumconsensusprotocol,
RecLSN,942–945 909
1124–1125
reconciliationofupdates, transactionsand,21,803,805
Raftprotocol,1148,1155–1158, 1142–1143 triggersand,212–213
1267 reconfiguration,1128 undooperationand,915–919,
RAID.Seeredundantarraysof record-basedmodels,8 922–925
independentdisks recordrelocation,652–653 write-aheadloggingruleand,
randomaccess,567,578 recoverymanager,21 926–929
randomizedretry,1148 recoverysystems,907–948 recoverytime,933
randommerge,1056 actionsfollowingcrashes, recursivepartitioning,714–715
randomsamples,761 923–925 recursivequeries,213–218
rangepartitioning,476,1005, algorithmsfor,922–925, iterationand,214–216
1007,1178 944–946,1276 SQLand,216–218
range-partitioningsort, ARIES,941–947,1276 transitiveclosureand,
1041–1042 atomicityand,803,912–922 214–216

--- Page 1360 ---

Index 1331
recursiverelationshipsets, referencingnewrowasclause, relational-algebraexpressions,50
247–248 207,208 relationaldatabasedesign,
Redis,436–437,482,1024 referencingnewtableasclause, 303–351
redistributionofpointers,646 210 atomicdomainsand,342–343
redo-onlylogrecords,918 referencingoldrowasclause, Boyce–Coddnormalform
redooperation,915–919, 208 and,313–316
922–925,941 referencingoldtableasclause, closureofasetand,312,
redopass,944–945 210 320–324
redophase,923,924 referencingrelation,45–46 decompositionand,305–313,
reduceByKeyfunction,498 referentialintegrity,14,46, 330–341
reducefunction,483–494,510. 149–153,207–208,800 designprocess,343–347
SeealsoMapReduce referer,440 featuresofgooddesigns,
paradigm referrals,1243 303–308
reducekey,485 reffromclause,380 firstnormalformand,
redundancy reflexivityrule,321 342–343
indatabasedesign,243 regionquadtrees,1187 fourthnormalformand,336,
entity-relationship(E-R) regionqueries,393–394 339–341
modeland,261–264 regression,546,1234 functionaldependenciesand,
infile-processingsystems,6 reification,376 308–313,320–330
reliabilityimprovementvia, reintegration,1128 largerschemasand,330,346
570–571 relation,defined,39 multivalueddependencies
ofschemas,269–270 relationalalgebra,48–58 and,336–341
redundantarraysofindependent antijoinoperation,108 namingofattributesand
disks(RAID),570–577 assignmentoperation,55–56 relationshipsin,345–346
bit-levelstripingand,571–572 BigDataand,494–500 normalizationand,308
block-levelstripingand,572 Cartesian-productoperation, secondnormalformand,
hardwareissues,574–576 50–52 316n8,341–342,356
hotswappingand,575 equivalenceand,58,747–757 smallerschemasand,305,
levels,572–574,572n4,573n6, expressiontransformation 308,344
576–577 and,747–757 temporaldatamodelingand,
mirroringand,571–573,576, joinoperation,52–53 347–351
577 motivationfor,495–496 thirdnormalformand,
paritybitsand,572,574,577 multiset,80,97,108,136,747 317–319
performanceimprovementvia predefinedfunctions relationalmodel,37–59
parallelism,571–572 supportedby,48n4 conceptual-designprocessfor,
performancetuningand, projectoperation,49–50 17
1214,1229–1230 queryoptimizationand, disadvantagesof,26
purposeof,562 743–749,752,755 historyof,26
rebuildperformanceof,576 queryprocessingand, keysfor,43–46
recoverysystemsand,909 689–691 object-relational,27,376–382
reliabilityimprovementvia renameoperation,56–57 operationsin,48–58
redundancy,570–571 selectoperation,49 overview,8,37
scrubbingand,575 semijoinoperation,108, querylanguagesin,47–48
softwareRAID,574,575 1082–1084 schemadiagramsfor,46–47
stripingdataand,571–572 setoperations,53–55 schemain(seerelational
re-engineering,1236 inSpark,495–500,508 schema)
referencedrelation,45–46 SQLoperationsand,80 SQLlanguagein,13
references,149–150 onstreams,504,506–508 structureof,37–40
referencesprivilege,170 unaryvs.binaryoperations tablesin,9,10,37–40
referencetypes,380–381 in,48 tuplesin,39,41,43–46

--- Page 1361 ---

1332 Index
relationalOLAP(ROLAP),535 namingof,345–346 key-valuestoragesystemsand,
relationalschema nonbinary,283–285 476
Boyce–Coddnormalform participationin,247 locationof,1014–1015
and,313–316,330–333 primarykeysand,257–259 majorityprotocoland,
canonicalcoverand,324–328 recursive,247–248 1123–1126
databasedesignprocessand, redundancyand,269–270 masterreplica,1016
343–347 representationof,268–269 master-slave,1137
decompositionand,305–313 ternary,249,250,284 multimaster,1137
defined,41 UnifiedModelingLanguage paralleldatabasesand,
infirstnormalform,342–343 and,288–291 1013–1016
fourthnormalformand, relations(tables),8 primarycopy,1123
339–341 relativedistinguishednames quorumconsensusprotocol
functionaldependenciesand, (RDNs),1241–1242 and,1124–1125
308–313,320–330 relevance
reconfigurationand
horizontalpartitioningof, hyperlinksand,385–386 reintegration,1128
1216–1217 PageRankand,385–386
shardingand,476
logicallyimplied,320 TF-IDFapproachand,
statemachinesand,
multivalueddependencies 384–385
1158–1161
and,336–341 relevanceranking,383–386
synchronous,522–523,1136
reductionof reliability,improvementvia
two-phasecommitprotocol
entity-relationship redundancy,570–571
and,1016
diagramsto,264–271, remappingbadsectors,565
update-anywhere,1137
277–279 remotebackupsystems,909,
updatesand,1015–1016
redundancyin,243 931–935
viewmaintenanceand,
temporaldataand,347–351 remotedirectmemoryaccess
1138–1140
thirdnormalformand, (RDMA),979
reportgenerators,538–540
317–319,333–335 renameoperation,56–57,79,
RepresentationStateTransfer
foruniversitydatabases, 81–82
(REST),426–427
41–43,303–305 renewingleases,1115
requestforgery,439–440
relationinstance,39,41 reorganizationoffiles,598
requestoperation
relationscans,769 repeatableread,821
deadlockhandlingand,
relationshipinstance,246–247 repeatinghistory,924
849–853
relationships,defined,246 repeatloop,214–216,323
locksand,835–841,844–846,
relationshipsets repeatstatements,201
849–853,886
alternativenotationsfor, replication
285–291 asynchronous,1122, multiplegranularityand,854,
atomicdomainsand,342–343 1135–1138 855
binary,249,283–285 biasedprotocoland,1124 multiversionschemesand,
combinationofschemasand, BigDataand,481–482 871
270–271 caching,1014n4 snapshotisolationand,874
degreeof,249 chainreplicationprotocol, timestampsand,861
descriptiveattributesand,248 1127–1128 ResilientDistributedDatasets
designissuesand,282–285 concurrencycontroland, (RDDs),496–499,1061
entity-relationshipdiagrams 1123–1125 resolutionofconflictingupdates,
and,247–250,268–271 consistencyand,1015–1016, 1142–1143
entity-relationship(E-R) 1121–1123,1133–1146 resourceconsumption,694–695,
modeland,246–249, datacentersand,1014–1015 1065–1066
282–285 distributeddatabasesand, ResourceDescriptionFramework
mappingcardinalitiesand, 987,1121–1128 (RDF)
252–256 failureand,1125–1128 defined,372

--- Page 1362 ---

Index 1333
graphrepresentationof, ARIESand,945–946 scalarsubqueries,106–107
374–375 cascading,820–821,841–842 scaleup,972–974
n-aryrelationshipsand,376 concurrencycontroland, scanningarelation,1006
overview,368 841–844,849–850,853, scheduling
reificationin,376 868–871 disk-arm,578–579
SPARQLand,375–376 logicaloperationsand, queryoptimizationand,1065
triplerepresentationand, 937–939 transactionsand,810–811,
372–374 partial,853 811n1
resources,inRDF,372 recoverysystemsand, schemadiagrams,46–47
responsetime 916–919,922 schemas
applicationdesignand, remotebackupsystemsand, alternativenotationsfor
434–435,1229,1232 933 modelingdata,285–291
blockchaindatabasesand, timestampsand,862–865 authorizationon,170
1274 total,853 basicSQLquerystructures
paralleldatabasesand, transactionsand,143–145, and,71–79
971–972 193,196,805–806,922, combinationof,270–271
partitioningand,1007 937–939,945–946 compositeattributesin,250
query-evaluationplansand, undooperationand,916–919, concurrencycontroland(see
694–695 937–939 concurrencycontrol)
queryprocessingand, rollbackwork,143–145 creationof,24
694–695 rollingmerge,1178 datamining,540–549
skewand,1066 rollupclause,228 datawarehousing,523–525
storageand,572 rollupconstruct,227–231, defined,12
530–531,536–538
transactionsand,808–809 entity-relationshipdiagrams
rotationallatencytime,566
responsetimecostmodel,1066 and,264–271,277–279
round-robinscheme,1005,1006
responsiveuserinterfaces,423 entity-relationship(E-R)
routers,1012–1013
REST(RepresentationState modeland,244,246,
row-levelauthorization,173
Transfer),426–427 269–270,277–279
row-orientedstorage,611,615
restriction,172,328,339–340 evolutionof,292
rowstores,612,615
ResultSetobject,185,187–188, flexibilityof,366
R-timestamp,862,865,870
191–193,638–639 global,1076,1078–1079
R-trees,663,670,674–676,
resynchronization,575 integrationof,1076,
1187–1190
reverseengineering,1236 1078–1080
RubyonRails,417,419
revokeprivileges,166–167, intermediateSQLand,
rulesfordatamining,540
171–173 162–163
runs,701–702
rightouterjoin,132–136,722 larger,330,346
runstats,761
rigoroustwo-phaselocking local,1076
protocol,842,843 SAML(SecurityAssertion locksand(seelocks)
Rijndaelalgorithm,448 MarkupLanguage), logical,12–13,1223–1224
ringsystem,976 442–443 performancetuningof,
robustness,1121,1125–1126 SAN.Seestorageareanetwork 1214–1218,1223–1224
ROLAP(relationalOLAP),535 sandbox,205 physical,12,13
roles SAPHANA,615,1132 physical-organization
authorizationand,167–169 SAS(SerialAttachedSCSI) modificationof,25
entity,247–248 interface,562 P+Qredundancy,573,574
indicatorsassociatedwith, SATA(SerialATA)interface, recoverysystemsand(see
268 562,568,569 recoverysystems)
UnifiedModelingLanguage savepoints,947 redundancyof,269–270
and,289 scalability,471–472,477,482, relational(seerelational
rollback 1276 schema)

--- Page 1363 ---

1334 Index
relationshipsetsand, audittrailsand,445–446 setmembershipand,98–99
268–269 authentication(see setoperationsand,85–89
shadow-copy,914 authentication) onsinglerelation,71–74
smaller,305,308,344 authorization(see stringoperationsand,82–83
snowflake,524 authorization) selectdistinct,72–73,90,
SQLDDLand,24,66,68–71 ofblockchaindatabases, 99–100,142
star,524–525 1253–1255,1259 select-from-where
strongentitysetsand, concurrencycontroland(see deletionand,108–110
265–267 concurrencycontrol) function/procedurewriting
subschemas,12 cross-sitescriptingand, and,199–206
timestampsand,861–866 439–440 insertionand,110–111
foruniversitydatabases, dictionaryattacksand,449 joinexpressionsand,125–136
1287–1288 encryptionand,447–453 naturaljoinsand,126–130
version-numbering,1141 end-userinformationand,443 nestedsubqueriesand,
version-vector,1141–1142 infile-processingsystems,7 98–107
weakentitysetsand,267–268 GETmethodand,440 updatesand,111–114
SciDB,367 integritymanagerand,19 viewsand,137–143
SCM(storageclassmemory), locksand(seelocks) selection
569,588,948 man-in-the-middleattacks comparisonsand,698–699
SCOPE,494 and,442 complex,699–700
scopeclause,380 passwords(seepasswords) conjunctive,699–700,747,
scriptinglanguages,404–405, privacyand,438,446 762
416–418,421,439 requestforgeryand,439–440 disjunctive,699,700,762
scrubbing,575 singlesign-onsystemand, equivalenceand,747–757
SCSI(small-computer-system 442–443 filescansand,695–697,
interconnect),562,563 SQLDDLand,67 704–707,727
searchkeys SQLinjectionand,438–439 identifiersand,700
B+-treesand,634–650 uniqueidentificationand, indicesand,695–697,783
hashingand,1190–1195, 446,446n8 intraoperationparallelism
1197–1199 SecurityAssertionMarkup and,1049
indexcreationand,664 Language(SAML), linearsearchand,695
nonunique,632,637,640, 442–443 sizeestimationand,760,762
649–650 seektime,566,566n2,567,692, viewmaintenanceand,
orderedindicesand,624–634 710 780–781
storageand,595,597–598 selectall,73 selectivity,762
uniquifiersand,649–650 selectauthorization,privileges selectoperation,49
searchoperation,1188 and,166–167 selectprivilege,171,172
secondaryindices,625, selectclause semijoinoperation,108,776,
632–633,652–653, aggregatefunctionsand, 1082–1084
695–698, 91–96 semi-structureddatamodels,
1017–1019 attributespecificationin,83 365–376
secondarysite,931 basicSQLqueriesand,71–79 flexibleschemaand,366
secondarystorage,561 onmultiplerelations,74–79 historyof,8,27
secondnormalform(2NF), inmultisetrelationalalgebra, JSON,8,27,367–370
316n8,341–342,356 97 knowledgerepresentation
sectors,564–566 nullvaluesand,90 and,368
security OLAPand,534,536–537 motivationsforuseof,
abstractionlevelsand,12 rankingand,220–222 365–366
applicationdesignand, renameoperationand,79, multivalued,366–367
437–446 81–82 nested,367–368

--- Page 1364 ---

Index 1335
overview,366–368 services,994 shared-memoryarchitecture,
RDFandknowledgegraphs, servicetime,1230 21–22,979–984,
368,372–376 servlets,411–421 1061–1064
XML,8,27,367–368, alternativeserver-side shared-modelocks,835
370–372 frameworks,416–421 shared-nothingarchitecture,979,
sensordata,470,501 exampleof,411–413 980,985–986,1040–1041,
sentimentanalysis,549 lifecycleand,415–416 1061–1063
Sequel,65 server-sidescriptingand, sharedscans,785–786
sequencecounters,1226 416–418 Sherpa/PNUTS,477,1024,
sequential-accessstorage,561, sessionsand,413–415 1026,1028–1030
567,578 supportfor,416 showwarnings,746
sequentialcomputation,974 webapplicationframeworks shrinkingphase,841,843
sequentialfileorganization,595, and,418–419 shufflestep,486,1061
597–598 sessionwindow,505 SIMD(SingleInstruction
SerialATA(SATA)interface, setautocommitoff,144 MultipleData),1064
562,568,569 setclause,113 simpleattributes,250,265
SerialAttachedSCSI(SAS)
setdefault,150 simulationmodel,1230
interface,562
set-differenceoperation,55,750 singleinheritance,275
serializability
setnull,150 SingleInstructionMultipleData
blindwritesand,868
setoperations (SIMD),1064
concurrencycontroland,
except,88–89 singlelock-manager,1111
836,840–843,846–848,
intersect,54–55,87–88,750 singlesign-onsystem,442–443
856,861–871,
nestedsubqueriesand, single-usersystems,962
875–887
98–101 single-valuedattributes,251
conflict,813–816
queryoptimizationand, sites,986
isolationand,821–826
764–765 SIX(sharedand
operation,885
queryprocessingand, intention-exclusive)mode,
orderof,817
720–722 855
performancetuningand,1225
setcomparisonand,99–101 skew
precedencegraphand,
setdifference,55 aggregationand,1049–1050
816–817
union,53–54,86–87,750 attribute-value,1008
intherealworld,824
setorientation,1220–1221 datadistribution,1008
snapshotisolationand,
setrole,172 indistributionofrecords,660
875–879
topologicalsortingand, setstatement,201,209 execution,1007,1008,1043
817–818 settransactionisolationlevel hashindicesand,1194
transactionsand,812–819, serializable,822 injoins,1047–1048
821–826 settypes,366,367 paralleldatabasesand,974,
view,818–819,867–868 shadow-copyscheme,914 1007–1013,1043,1062
serializableschedules,811,812 shadowing,571 partitioningand,715,
serializablesnapshotisolation shadowpaging,914 1007–1013
(SSI)protocol,878 SHA-256hashfunction,1260 responsetimeand,1066
server-sidescripting,416–418 sharding,473,475–476,1275 writeskew,876–877
serversystems,962–970 shardkey,479 slicing,530
categorizationof,963–964 sharedandintention-exclusive slidingwindow,505
data-server,963–964, (SIX)mode,855 slotted-pagestructure,593
968–970 shared-diskarchitecture,979, small-computer-system
defined,962 980,984–985 interconnect(SCSI),562,
transaction-server,963–968 sharedlocks,825,835,854, 563
tree-like,977–978 880,1124 smartcards,451,451n9

--- Page 1365 ---

1336 Index
smartcontracts,1258, sparsecolumndata SQL(StructuredQuery
1269–1273 representation,366 Language),65–114
snapshotisolation sparseindices,626–632 advanced(seeadvancedSQL)
concurrencycontroland, spatialdata aggregatefunctionsand,
872–879,882,916, designdatabases,390–391 91–96
1131–1132 geographic,387,390–393 application-level
distributed,1131–1132 geometric,388–390 authorizationand,
performancetuningand,1225 indexingof,672–675, 443–445
recoverysystemsand,916 1186–1190 applicationprogramsand,
serializabilityand,875–879 joinsover,719 16–17
transactionsand,825–826, quadtrees,392,674, attributespecificationin
1136 1186–1187 selectclause,83
validationand,874–875 queriesand,393–394 authorizationand,66
snowflakeschema,524 R-trees,663,670,674–676, basictypessupportedby,
social-networkingsites 1187–1190 67–68
BigDataand,467,470 triangulationand,388,393 blobsand,156,193,594,652
databaseapplicationsfor,2, bulkloadsand,1221–1223
spatialdataindices,672–675
3,27 clobsand,156,193,594,652
spatialgraphqueries,394
key-valuestoreand,471 createtableand,68–71
spatialgraphs,390
streamingdataand,502 databasemodificationand,
spatial-integrityconstraints,391
softdeadlines,894 108–114
spatialjoin,394
softforks,1257,1258 datadefinitionforuniversity
spatialnetworks,390
software-as-a-servicemodel,993 databases,69–71,
specialization
softwareRAID,574,575 1288–1292
attributeinheritanceand,
solid-statedrives(SSDs),18, DDLand,14–15,65–71
274–275
560,568–570,693n3, decision-supportsystemsand,
constraintson,275–276
1229 521
disjoint,272,275
someconstruct,100,100n10 deletionand,108–110
entity-relationship(E-R)
somefunction,96 DMLand,16,66
modeland,271–273
sophisticatedusers,24 dumpingand,931
overlapping,272,275
sorting dynamic,66,184,201
partial,275
costanalysisof,702–704 embedded,66,184,197–198,
singleentitysetand,274
duplicateeliminationand, 965,1269
superclass-subclass
719–720 indexcreationand,164–165,
relationshipand,272
externalsort-mergealgorithm, 664–665
total,275
701–704 injectionand,189,438–439
specificationoffunctional
parallelexternalsort-merge, inputsandoutputsin,747
requirements,17–18,242
1042–1043 insertionand,110–111
speedup,972–974
queryprocessingand, integrityconstraintsand,
701–704 splittingnodes,641–645,886 14–15,66,145–153
range-partitioning,1041–1042 SQLAccessGroup,1238 intermediate(see
topological,817–818 SQLAlchemy,382 intermediateSQL)
sort-merge-joinalgorithm, SQL/DS,26 isolationlevelsand,821–826
708–712 SQLenvironment,163 JSONand,369–370
soundaxioms,321 SQLinjection,189,438–439 limitationsof,468,472
source-drivenarchitecture,522 SQLite,668 onMapReduce,493–494
spaceoverhead,624,627–628, SQLLoader,1222 MySQL(seeMySQL)
634,1202 SQLMED,1077 nestedsubqueriesand,
Spark,495–500,508,511,1061 sqlsecurityinvoker,170 98–107
SPARQL,375–376 sqlstate,205 nonstandardsyntaxand,204

--- Page 1366 ---

Index 1337
NoSQLsystems,28,473,477, databaseconnectivity, bit-levelstripingand,571–572
1269,1276 1238–1239 blockchain(seeblockchain
nullvaluesand,89–90 defacto,1237 databases)
OLAPin,533–534,536–538 defined,1237 block-levelstripingand,572
orderingdisplayoftuples formal,1237 buffersand,19,604–610
and,83–84 ISO,65,1237,1241 byteamountsof,18
overview,65–66 object-oriented,1239–1240 checkpointsand,920–922,
PostgreSQL(see ODBC,1238–1239 930
PostgreSQL) reactionary,1237 cloud-based,28,563,
preparedstatementsand, SQL,65,1237–1238 992–993
188–190 X/OpenXA,1239 column-oriented,525–526,
prevalenceofuse,13 starschema,524–525 588,611–617,734,1182
queryprocessingand, start-upcosts,974,1066 crashesand,607,609–610
689–690,701,720 startwith/connectbyprior dataaccessand,910–912
querystructure,71–79 syntax,218 data-dictionary,602–604
relationalalgebraand,80 starvedtransactions,841,853 dataminingand,27,540–549
renameoperationand,79, state-basedblockchains,1269, data-transferrateand,566,
81–82 1271 569
ResultSetobjectand,185, statemachines,1158–1161 indecision-supportsystems,
187–188,191–193, Statementobject,186–187,189 519–520
638–639 stateofexecution,727 direct-access,561
schemasand,24,66,68–71 statichashing,661,1190–1195, distributed(seedistributed
securityand,438–439 1202–1203 databases)
setoperationsand,85–89 statisticalanalysis,520,527 distributedfilesystemsfor,
standardsfor,65,1237–1238 statistics,757–766 472–475,489,1003,
streamextensionsto, cataloginformationand, 1019–1022
504–506 758–760 dumpingand,930–931
stringoperationsand,82–83 computing,761 durabilityand,804–805
SystemRand,26 joinsizeestimationand, elasticityof,1010
SystemRprojectand,65 762–764 filemanagerfor,19
theoreticalbasisof,48 maintaining,761 fileorganizationand,
transactionsand,66, numberofdistinctvaluesand, 588–602
143–145,965 765–766 forceoutputand,912
updatesand,111–114 selectionsizeestimationand, geographicallydistributed,
viewsand,66,137–143, 760,762 1026–1027
169–170 stealpolicy,927 harddisksfor,26
where-clausepredicatesand, stepped-mergeindices,667, integritymanagerand,19
84–85 1179–1181 key-value,471,473,476–480,
XMLand,372 stockmarket,streamingdata 1003,1023–1031
SSDs.Seesolid-statedrives and,501 oflargeobjects,594–595
SSI(serializablesnapshot stopwords,385 logdisks,610
isolation)protocol,878 storage,587–617 inmain-memorydatabases,
stablestorage,804–805, accesstimeand,561,566, 588,615–617
908–910 567,578 mirroringand,571–573,576,
stalemessages,1149 architecturefor,587–588 577
stallsinprocessing,733 archival,561 non-volatile,560,562,
standards atomicityand,804–805 587–588,804,908–910,
ANSI,65,1237 authorizationand,19 930–931
anticipatory,1237 backup(seebackup) offline,561
CLI,197,1238–1239 BigDataand,472–482,668 online,561

--- Page 1367 ---

1338 Index
outsourcing,28 defined,500 symmetricfragment-and-replicate
parallel(seeparallel faulttolerancewith, joins,1046
databases) 1074–1076 symmetric-keyencryption,448
physical(seephysicalstorage processing,468,1070–1076 synchronousreplication,
systems) querying,502–506, 522–523,1136
pointersand,588,591, 1070–1071 syntax,199,201–205,689
594–598,601 routingoftuplesand, sys contextfunction,173
primary,561 1071–1073 systemarchitecture.See
punchedcardsfor,25 streamquerylanguages, architecture
randomaccess,567,578 503–506 systemcatalogs,602–604,1009
recoverysystemsand, stricttwo-phaselockingprotocol, systemclock,862
908–912,920–922, 842,843 systemerror,907
930–931 stringoperations SystemR,26,65,772–773,
redundantarraysof aggregate,91 772n3
independentdisks,562 escape,83
responsetimeand,572 JDBCand,184–193 tablealias,81
row-oriented,611,615 like,82–83 tablefunctions,200
R-treesand,1189–1190 lowerfunction,82 tableinheritance,379–380
scrubbingand,575 queryresultretrievaland,188 tablepartitioning,601–602
secondary,561 similarto,83 tables
seektimeand,566,566n2, trim,82 defined,1011
567,692,710 upperfunction,82 dimension,524
sequentialaccess,561,567, stripe,613–614 dirtypage,941–947
578 stripingdata,571–572 distributedhash,1013
shardingand,473,475–476 strongentitysets,259,265–267 fact,524
SQLDDLand,67 StructuredQueryLanguage.See foreign,1077
stable,804–805,908–910 SQL partition,1011–1014
stripingdataand,571–572 structuredtypes,158–160 pivot-table,226–227,
structureandaccess-method stylesheets,408 528–529
definition,24 subjectoftriples,372 inrelationalmodel,9,10,
tertiary,561 sublinearscaleup,973 37–40
transactionmanagerfor,19 sublinearspeedup,972 inSQLDDL,14–15
volatile,560,562,804,908 subschemas,12 transition,210
walletsand,450 suffix,1243 tablets,1011,1025
warehousing(seedata sumfunction,91,139,228,536, tabletserver,1025
warehousing) 723,766,781 tab-separatedvalues,1222
storageareanetwork(SAN), superclass-subclassrelationship, taglibrary,418
562,563,570,934,985 272,274 tags,370–372,406–407,418,
storageclassmemory(SCM), superkeys,43–44,257–258, 440
569,588,948 309–310,312 tamperresistance,1253–1255,
storagemanager,18–20 supersteps,510 1259,1260
storebarrier,983 superusers,166 tangles,1278
storedfunctions/procedures, supplychains,1266,1278 tapestorage,561
1031 support,547 Tapestry,419
stragglernodes,1060–1061 SupportVectorMachine(SVM), tasks,1051–1052.Seealso
streamingdata,500–508 544–545 workflow
algebraicoperationsand,504, swapspace,929 Tcl,206
506–508 SybaseIQ,615 telecommunications,database
applicationsof,500–502 Sybilattacks,1255,1256,1264, applicationsfor,3
continuous,731 1266 temporaldata,347–351,347n10

--- Page 1368 ---

Index 1339
temporaldataindices,675–676 ticketsandticketing,1133,1279 traininginstances,541,543,546
temporalvalidity,157 tiles,392 transactioncontrol,66
termfrequency(TF),384 timeintervals,675–676 transactioncoordinators,1099,
terminationoftransactions,806 time-locktransactions,1273 1104,1106–1107
terms,384,1149 timestamps transactionidentifiers,913
ternaryrelationshipsets,249, concurrencycontroland, transactionmanagers,18–21,
250,284 861–866,882 1098–1099
tertiarystorage,561 fordata-storagesystems,480 TransactionProcessing
test-and-set,966 defined,154 PerformanceCouncil
testsuites,1234–1235 distributeddatabasesand, (TPC),1232–1234
textmining,549 1116–1118 transactions,799–828
textualdata,382–387.Seealso generationof,1117–1118 aborted,805–807,819–820
informationretrieval invalidation,873n3 actionsfollowingcrashes,
keywordqueries,383, logicalclock,1118 923–925
386–387 logicalcounterand,862 active,806
overview,382 multiversionschemesand, aggregationof,1278
relevancerankingand, 870–871 alternativemodelsof
383–386 nondeterministic,508n3 processing,1108–1110
Tez,495 orderingschemeand, associationrulesand,
TF-IDFapproach,384–385 862–864,870–871,1118 546–547
TF(termfrequency),384 rollbackand,862–865 atomicityof,20–21,144,481,
thenclause,212 snapshotisolationand,873, 800–807,819–821
theta-joinoperations,748–749 873n2 begin/endoperationsand,
thirdnormalform(3NF), systemclockand,862 799
317–319,333–335 Thomas’writeruleand, blockchain,1261–1263,
Thomas’writerule,864–866 864–866 1268–1271,1273
threads,965,982,1062 transactionsand,825 cascadelessschedulesand,
3D-XPointmemorytechnology, tuplesand,502,503,505 820–821
569 timetocompletion,1231 checkconstraintsand,800
3NFdecompositionalgorithm, timezone,154 commitprotocolsand,
334–335 TIN(triangulatedirregular 1100–1110
3NFsynthesisalgorithm,335 network),393 committed(seecommitted
3NF(thirdnormalform), tokens,1272 transactions)
317–319,333–335 TomcatServer,416 commitworkand,143–145
three-phasecommit(3PC) top-downdesign,273 compensating,805
protocol,1107 topic-partitionsystem,1073 conceptof,799–801
three-tierarchitecture,23 top-K optimization,784 concurrencycontroland(see
throughput topographicalinformation,393 concurrencycontrol)
applicationdesignand, topologicalsorting,817–818 concurrent,1224–1227
1230–1232,1234 toss-immediatestrategy,608 consistencyof,20,800,802,
inblockchaindatabases,1274 totalfailure,909 807–808,821–823
harmonicmeanof,1231 totalgeneralization,275 crashesand,800
improved,808 totalrollback,853 cross-chain,1273
paralleldatabasesand,971 totalspecialization,275 datamining,540–549
rangepartitioningand,1007 TPC(TransactionProcessing defined,20,799
storageand,572 PerformanceCouncil), distributed,989–990,
systemarchitecturesand,963, 1232–1234 1098–1100
971 TPS(transactionspersecond), double-spend,1261–1262,
transactionsand,808 1232 1264
throughputtest,1234 tracks,564 durabilityof,20–21,800–807

--- Page 1369 ---

1340 Index
failureof,806,907,909,1100 time-lock,1273 directoryinformation,1242,
force/no-forcepolicyand,927 timestampsand,861–866 1243
gasconceptfor,1270–1271 two-phasecommitprotocol disjointsubtrees,847
global,988,1098,1132 and,989,1016,1276 GeneralizedSearchTree,670
in-doubt,1105 asunitofprogramexecution, k-d,673–674
integrityconstraintviolation 799 k-dB,674
and,151–152 update,871 left-deepjoin,773
isolationof,800–804, validationand,866–869 LSM,666–668,1028,
807–812,819–826 wait-forgraphand,851–852, 1176–1182,1215
killing,807 1113–1114 Merkle,1143–1146,1268,
local,988,1098,1132 write-aheadloggingruleand, 1269
locksand(seelocks) 926–929 Merkle-Patricia,1269,1275
logof(seelogrecords) writeoperationsand,826 multiplegranularityand,
long-duration,890–891 transactionscaleup,973 853–857
minibatch,1227 transactions-consistentsnapshot, operator,724,1040
multiversionschemesand, 1136 quadraticsplitheuristicand,
869–872,1129–1131 transaction-serversystems, 1189
observableexternalwrites 963–968 quadtrees,392,674,
and,807 transactionspersecond(TPS), 1186–1187
off-chain,1275 1232 R,663,670,674–676,
online,4,521 transactiontime,347n10 1187–1190
performancetuningof, TransactSQL,199 treetopology,977
1224–1227 transferofcontrol,932–933 triangulatedirregularnetwork
persistentmessagingand, transformations (TIN),393
990,1016,1108–1110,1137 datawarehousingand,523 triangulation,388,393
read-only,871 equivalencerulesand, triggers
real-timesystems,894 747–752 alter,210
recoverableschedulesand, examplesof,752–754 defined,206
819–820 joinorderingand,754–755 disable,210
recoverysystemsand,21, queryoptimizationand, drop,210
803,805 747–757 needfor,206–207
remotebackupsystemsand, relationalalgebraand, nonstandardsyntaxand,212
931–935 747–757 recoveryand,212–213
restarting,807 transitiontables,210 inSQL,207–210
rollbackand,143–145,193, transitionvariables,207 transitiontablesand,210
196,805–806,922, transitiveclosure,214–216 whennottouse,210–213
937–939,945–946 transitivedependencies,317n9, trim,82
scalabilityand,471 356 triplerepresentation,372–374
serializabilityand,812–819, transitivityrule,321 trivialfunctionaldependencies,
821–826 translation,queryprocessing 311
shadow-copyschemeand,914 and,689–690 truepredicate,76
simplemodelfor,801–804 translationtable,568 truevalues,96,101
asSQLstatements,826–828 tree-likeserversystems,977–978 try-with-resourcesconstruct,187,
starved,841,853 tree-liketopology,977 187n3
statesof,805–807 treeprotocol,846–848 tumblingwindow,505
steal/no-stealpolicyand,927 trees tuning.Seeperformancetuning
storagestructureand, B(seeB-trees) tuningwizards,1215
804–805 B+(seeB+-trees) tuple-generatingdependencies,
supportfor,1028–1030 B-link,886 337
terminated,806 decision-treeclassifiers,542 tuples

--- Page 1370 ---

Index 1341
aggregatefunctionsand, two-phaselockingprotocol, universitydatabases
91–96 841–844,871–872, abstractionlevelsfor,11–12
inCartesian-product 1129–1131 applicationdesignand,2–3,
operation,51,52 two-tierarchitecture,23 5–7,403–404,431,
defined,39 typeinheritance,378–379 442–444
deletionand,108–110,613 types atomicdomainsand,343
duplicate,103 blobs,156,193,594,652 BigDataand,499–500
eagergenerationof,726,727 clobs,156,193,594,652 blockchain,1277
insertionand,110–111 complex(seecomplexdata buffer-replacementstrategies
joinoperationfor,52–53(see types) and,607–609
alsojoins) large-object,156,158 Cartesianproductand,76–79
lazygenerationof,727 performancetuningand,1226
combinationofschemasand,
logicalroutingof,506–507, reference,380–381 270–271
1071–1073 user-defined,158–160,378
complexattributesand,
orderingdisplayof,83–84
249–252
physicalroutingof, UML(UnifiedModeling concurrencycontroland,879
1072–1073 Language),288–291
consistencyconstraintsfor,6,
pipeliningand,691–692, unaryoperations,48
13–15
724–731 undooperation
decompositionand,305–307,
queryoptimizationand(see concurrencycontroland,
310–312
queryoptimization) 940–941
deletionrequestsand,
queryprocessingand(see logical,936–941
109–110
queryprocessing) recoverysystemsand,
designissuesfor,346–347
rankingand,219–223 915–919,922–925
distributed,988
reconstructioncosts,612–613 rollbackand,916–919,
entitiesin,243–246,
relationalalgebraand, 937–939
265–268,281–283
747–757 undopass,944–946
entity-relationshipdiagram
inrelationalmodel,39,41, undophase,923–925
for,263–264
43–46 UnifiedModelingLanguage
fullschemafor,1287–1288
selectoperationfor,49 (UML),288–291
functionsandproceduresfor,
setoperationsand,54–55, uniformresourcelocators
198–199
85–89 (URLs),405–406
generalizationand,273–274
streamingdataand,501–503, unionall,86,97,217n8
505–507,1071–1073 unionofsets,54,750 hashfunctionsand,
timestampsand,502,503, unionoperation,53–54,86–87, 1190–1193
505 228 incompletenessof,243–244
updatesand,111–114,613 unionrule,321 indicesand,625–628,664,
viewsand,137–143 uniqueconstruct,103,147 1017–1018
windowingand,223–226 uniquekeyvalues,160–161 insertionrequestsand,
tuplevariables,81 unique-roleassumption,345 110–111
Turing-completelanguages, uniquifiers,649–650 integrityconstraintsfor,
1258,1269,1270 UnitedStates 145–153
two-factorauthentication, addressformatusedin,250n1 mappingcardinalitiesand,
441–442 identificationnumbersin,447 253–256
2NF(secondnormalform), primarykeysin,44–45 multivalueddependencies
316n8,341–342,356 privacylawsin,995 and,336
two-phasecommit(2PC) universalfrontend,404 queryoptimizationand,
protocol,989,1016, UniversalSerialBus(USB)slots, 751–755,775–778
1101–1107,1161, 560 queryprocessingand,
1276 universalTuringmachines,16 690–691,704,723–724

--- Page 1371 ---

1342 Index
recursivequeriesand, EXECSQLand,197 commongatewayinterface
213–214,217–218 hashingand,624,1197–1202 standardand,409
redundancyin,243,261–264, inconsistent,1140–1142 cookiesand,410–415,411n2,
269–270 indicesand,630–632 439–440
relationalalgebrafor,49–58 insertiontimeand,641–645, CRUD,419
relationalmodelfor,9,10, 647,649 dataaccesslayerand,
37–47 lazypropagationof,1122, 430–434
relationalschemafor,41–43, 1136 disconnectedoperationand,
303–305 logrecordsand,913–914, 427–428
relationshipsetsand, 917–918 front-endcomponentof,404
246–249,268–269, lost,874 HTTP(seeHyperText
282–283 TransferProtocol)
LSMtreesand,1178–1179
rolesandauthorizationsfor, mobileapplicationplatforms
performancetuningand,
167–169 and,428–429
1221–1223,1225–1227
sampledatafor,1292–1298 fornaÃ¯veusers,24
privilegesand,166–167
specializationand,271–273 presentationlayerand,429
queryoptimizationand,
SQLdatadefinitionfor, responsive,423
784–785
69–71,1288–1292 securityand,437–446
reconciliationof,1142–1143
SQLqueriesfor,16 forsophisticatedusers,24
replicationand,1015–1016
storageand,589–591, storageand,562–563
shippingSQLstatementsto
597–601 Webservices(seeWorld
databaseand,187
transactionsand,144, WideWeb)
snapshotisolationand,
826–827 webservicesand,426–429
873–879
triggersand,211–213 userrequirementsindatabase
triggersand,208,212
triplerepresentationof, design,17–18,241–242,
tuplesand,111–114,613
373–374 274
ofviews,140–143
uniquekeyvaluesfor,160–161 utilizationofresources,808
updatetransactions,871
userinterfacesfor,24
upgrade,843
viewsand,141–143 validation
UniversityofCalifornia, URLs(uniformresource concurrencycontroland,
Berkeley,26 locators),405–406 866–869,882
Unix,83,914 U.S.NationalInstitutefor distributed,1119–1120
unknownvalues,89–90,96 StandardsandTechnology, firstcommitterwinsand,874
288
unpartitionedsite,1056 firstupdaterwinsand,
unpinoperations,605 USB(UniversalSerialBus)slots, 874–875
updatableresultsets,193 560 phasesof,866
update-anywherereplication, user-definedtypes,158–160,378 recoverysystemsand,916
1137 user-interfacelayer,429 snapshotisolationand,
updatehotspots,1225 userinterfaces 874–875
updates applicationarchitecturesand, testfor,868
authorizationand,14,170, 429–434 viewserializabilityand,
171 applicationprogramsand, 867–868
batch,1221 403–405 validationphase,866
onB+-trees,641–649 back-endcomponentof,404 validinterval,870
complexityof,647–649 business-logiclayerand,430, validtime,157,347–350,
databasemodificationand, 431 347n10
111–114 client-serverarchitectureand, valueforentitysetattributes,245
datawarehousingand,523 404 valuesetofattributes,249
deletiontimeand,641, client-sidescriptingand, varchar,67–68,70
645–649 421–429 variable-lengthrecords,592–594

--- Page 1372 ---

Index 1343
varietyofdata,468 volatilestorage,560,562,804, securityand,445
VBScript,417 908 setoperationsand,85–89
vectordata,392–393 volumeofdata,468 onsinglerelation,71–74
vectorprocessing,612 VPD(VirtualPrivateDatabase), stringoperationsand,82–83
Vectorwise,615 173,444–445 transactionsand,824,
velocityofdata,468 826–827
wait-diescheme,850,1112
verificationofcontents,1145 whileloop,196
wait-forgraphs,851–852,
versionnumbering,1141 whilestatements,201
1113–1114
versionsperiodfor,157 wide-areanetworks(WANs),989
WAL(write-aheadlogging),
widecolumndatarepresentation,
version-vectorscheme, 926–929,934
366
1141–1142 WANs(wide-areanetworks),989
wide-columnstores,1023
Vertica,615 weakentitysets,259–260,
windowsandwindowing,
verticalpartitioning,1004 267–268
223–226,502–506
viewdefinition,66 wearleveling,568
WiredTiger,1028
viewequivalence,818,818n4 webapplicationframeworks,
wireframemodels,390
viewlevelofabstraction,10–12 418–419
withcheckoption,143
viewmaintenance,140,779–782, web-basedservices,database
withclause,105–106,217
1138–1140,1215–1216 applicationsfor,3
withdataclause,162
views webcrawlers,383
withgrantoption,170–171
authorizationon,169–170 WeblogicApplicationServer,416
withrecursiveclause,217
withcheckoption,143 WebObjects,419
withtimezonespecification,154
createview,138–143,162, webservers,408–411
witnessdata,1258
169 webservices,423–429
wordcountprogram,483–486,
deferredmaintenanceand, defined,426
484n2,490–492
779,1215–1216 disconnectedoperationand,
workers,1051
427–428
defined,137–138
workflow
interfacingwith,423–426
deletionand,142
mobileapplicationplatforms, business-logiclayerand,431
immediatemaintenanceand,
428–429 databasedesignand,291–292
779,1215–1216
websessions,408–411 distributedtransaction
insertionand,141–143
WebSphereApplicationServer, processingand,1110
materialized(seematerialized
416 managementsystemsfor,990
views)
whenclause,212 workload,783,1215,1217
performancetuningand,
whenstatement,208 workloadcompression,1217
1215–1216
whereclause workstealing,1048,1062
SQLqueriesand,138–139 aggregatefunctionsand, WorldWideWeb
updateof,140–143 91–96 applicationdesignand,
viewserializability,818–819, basicSQLqueriesand,71–79 405–411
867–868 betweencomparison,84 cookiesand,410–415,411n2,
virtualmachines(VMs),970, onmultiplerelations,74–79 439–440
991–994 inmultisetrelationalalgebra, encryptionand,447–453
virtualnodes,1009–1010 97 growthof,467
VirtualPrivateDatabase(VPD), notbetweencomparison,84 HTMLand(seeHyperText
173,444–445 nullvaluesand,89–90 MarkupLanguage)
virtualprocessorapproach, predicates,84–85 HTTPand(seeHyperText
1010n3 queryoptimizationand, TransferProtocol)
VisualBasic,184,206 774–777 impactondatabasesystems,
visualizationtools,538–540 rankingand,222 27
VMs(virtualmachines),970, renameoperationand,79, securityand,437–446
991–994 81–82 serversandsessions,408–411

--- Page 1373 ---

1344 Index
URLsand,405–406 writequorum,1124 fortransferringdata,423
WORM(writeonce,read-many) writeskew,876–877 X/OpenXAstandards,1239
disks,561,1022 write-writecontention,1225 XORoperation,448
wound-waitscheme,850 W-timestamp,862,865,870 XPath,372
wrappers,1077,1236 XQuery,372
X.500directoryaccessprotocol, XSRF(cross-siterequest
write-aheadlogging(WAL),
1241 forgery),439–440
926–929,934
XML(ExtensibleMarkup XSS(cross-sitescripting),
writeamplification,1180
Language) 439–440
writeonce,read-many(WORM) emergenceof,27
disks,561,1022 flexibilityof,367–368 YahooMessageBusservice,
writeoperations,826 assemi-structureddata 1137–1138
write-optimizedindexstructures, model,8,27
665–670 SQLinsupportof,372 Zabprotocol,1152
writephase,866 tagsand,370–372 ZooKeeper,1150,1152